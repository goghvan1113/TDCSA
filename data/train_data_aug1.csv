Citation_Text,Sentiment,Source
"Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites  , all based on tim notion of abduction, and we have begun to explore its potential application to machine translation.",1,original
provide a promising physical framework to rationalize the high intrinsic enthalpic signatures of 15–40 kcal mol−1  ,1,original
Among the most widely studied is the Gibbs distribution  .,1,original
"Many techniques for bone defatting are described in the literature, including mechanical cleaning with water or air jet,  acetone ⁄ ethanol solution,  enzyme detergents,  hydrogen peroxide,  aqueous sodium hydroxide,  and sodium hypochlorite  .  We adopted the latter technique, because it has been found suitable for formalinized specimens,  is safe for personnel and is very low cost.",1,original
"Sentences are parsed using the MST dependency parser  , which implements the Eisner algorithm   for dependency parsing, and provides an efficient and robust performance.",1,original
"In particular,   presents very strong results using a distributional-similarity module and achieve impressive tagging accuracy while starting with a mere 116 prototypical words.",1,original
"The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years  .",1,original
The most commonly used MT evaluation metric in recent years has been IBM?s Bleu metric  .,1,original
"The most popular non-data-splitting methods for predicting test set cross-entropy   are AIC and variants such as AICc, quasi-AIC  , and QAICc  .",1,original
Another kind of popular approaches to dealing with query translation based on corpus-based techniques uses a parallel corpus containing aligned sentences whose translation pairs are corresponding to each other  .,1,original
The ROUGE   suite of metrics are n-gram overlap based metrics that have been shown to highly correlate with human evaluations on content responsiveness.,1,original
2.1 Lexicalized parse trees The first successful work on syntactic disambiguation was based on lexicalized probabilistic context-free grammar    .,1,original
"The Penn Treebank   has until recently been the only such corpus, covering 4.5M words in a single genre of financial reporting.",1,original
…    or enteric polymers such as hydroxypropyl methylcellulose phthalate     and hydroxypropyl methylcellulose acetate succinate     have demonstrated use…,1,original
"Recent several years have witnessed the rapid development of system combination methods based on confusion networks  ), which show state-of-theart performance in MT benchmarks.",1,original
"The most notable of these include the trigram HMM tagger  , maximum entropy tagger  , transformation-based tagger  , and cyclic dependency networks  .",1,original
"Recently, various works have improved the quality of statistical machine translation systems by using phrase translation  .",1,original
"For example, the efficient algorithm implemented in GCTA   uses the restricted maximum likelihood   method to estimate σ 2g and σ 2 under the null model while the GRM K was estimated from all the SNPs.",1,original
"Along this line,   present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance  the ability to translate nonconstituent phrases   turns out to be critical and pervasive.",1,original
"The Inversion Transduction Grammar or ITG formalism, described in  , is well suited for our purposes.",1,original
…of NMDAR antagonists have been suggested to be highly useful models of the cognitive impairment in schizophrenia  .,1,original
1 Introduction There has been a great deal of progress in statistical parsing in the past decade  .,1,original
"A well-known method for use in these situations is the “randomized response technique”  , introduced by Warner  .",1,original
"Ranking algorithms, such as Kleinbergs HITS algorithm   or Googles PageRank  , have been traditionally and successfully used in Web-link analysis  , social networks, and more recently in text processing applications  ,  ,  .",1,original
"1 Introduction As with many other statistical natural language processing tasks, statistical machine translation   produces high quality results when ample training data is available.",1,original
Synchronization is the most commonly-used method  .,1,original
"For example, the second version of the Microsoft Kinect   is one of the most low-cost and high-speed Time-of-Flight   sensors in the market  .",1,original
"However, this is not unprecedented: discriminatively weighted generative models have been shown to outperform purely discriminative competitors in various NLP classification tasks  , and remain the standard approach in statistical translation modeling  .",1,original
"Demonstration of intrathecal immunoglobulin and antibody synthesis are powerful tools for diagnosis of neurological disorders, as has been shown for multiple sclerosis and several infectious diseases of the CNS  .",1,original
  compares his method to   and shows that for four words the former performs significantly better in distinguishing between two senses.,1,original
"It could be shown that such methods, of which BLEU   is the most common, can deliver evaluation results that show a high agreement with human judgments  .",1,original
We report results using the well-known automatic evaluation metrics Bleu  .,1,original
"1 Introduction Todays statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see  .",1,original
"As has been previously observed and exploited in the NLP literature  , the above optimization function, unlike many others that have been proposed for graph or set partitioning, can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs.",1,original
n efficient algorithm for performing this tuning for a larger number of model parameters can be found in Och  ,1,original
"…for remediation of runoff from agricultural irrigation and agro-industrial production has become increasingly popular over the last decades, due to their low capital and operational cost, low energy consumption, and environmental friendliness  .",1,original
Several investigations represented both occurrence and severity of CIN were well correlated with improved survivals in various cancers  .,1,original
BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities  .,1,original
"Recently, a novel method called minimal distance maximization     was developed which does not require any weighting function.",1,original
"Proceedings of the Conference on Empirical Methods in Natural 2 Automatic Thesaurus Extraction The development of large thesauri and semantic resources, such as WordNet  , has allowed lexical semantic information to be leveraged to solve NLP tasks, including collocation discovery  , model estimation   and text classi cation  .",1,original
" , but we use a maximum entropy classifier   to determine parser actions, which makes parsing extremely fast.",1,original
"The parsers with the highest published broad-coverage parsing accuracy, which include Charniak  , Collins  , and Ratnaparkhi  , all utilize simple and straightforward statistically based search heuristics, pruning the search-space quite dramatically.",1,original
Some notable efforts in this direction for other languages have been the Penn Tree Bank   for English and the Prague Dependency Bank   for Czech.,1,original
"However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works  ,  ,  , and  ).",1,original
"In addition, the perceptron algorithm and its variants, e.g., the voted or averaged perceptron, is becoming increasingly popular due to their competitive performance, simplicity in implementation and low computational cost in training  .",1,original
"Glycyrrihzin, 18βglycyrrhetinic acid and liquiritigenin individually were able to ease itchiness and lower ovalbumininduced elevated IgE level  .",1,original
"Because of this property, vector space models have been used successfully both in computational linguistics   and in cognitive science  .",1,original
Oxytocin is famous for its pleiotropic activities including induction of labor and influences on social behaviors  .,1,original
Preclinical work by Dyrby et al.   highlights the benefits of such strong gradients and the first results from the Connectome scanner   are now starting to verify those findings.,1,original
"The Logllkelihood Ratio, G 2, is a mathematically well-grounded and accurate method for calculating how """"surprising"""" an event is  .",1,original
"DTI derived diffusion parameters, such as fractional anisotropy  , have been widely used to assess white matter microstructure  .",1,original
"For some PESP-models, the genetic algorithm that has been proposed by Nachtigall and Voget  , constitutes a competitive alternative  .",1,original
"Few SAEs were observed, reflecting previous data indicating that SAEs resulting from statin treatment are rare.  As the largest study to date focusing on statin therapy solely in patients with the metabolic syndrome, COMETS supports the good safety profile of rosuvastatin and atorvastatin reported previously by two post hoc subgroup analyses.",1,original
"A variety of classifiers have been employed for this task  , the most popular being decision lists   and naive Bayesian classifiers  .",1,original
The default synthetic voice that we used featured a well established corpus-based prosodic model  .,1,original
"While crowdsourcing has also been used to gather data for learning problems in the non-speech audio domain  , machine listening—the sibling field of computer vision— has yet to see the same transformative success.",1,original
"Fortunately, the convertibility rule happens to be implemented quite efficiently in Coq  , so it becomes possible to automatically prove some propositions on real numbers by simply evaluating programs.",1,original
  has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation   and related tasks  ; Agirre and Rigau The author was partially funded by GALE DARPA Contract No.,1,original
"We carried out automatic evaluation of our summaries using ROUGE   toolkit, which has been widely adopted by DUC for automatic summarization evaluation.",1,original
The best previous result is an accuracy of 56.1%  .,1,original
3 Previous Work The idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs was first successfully implemented in the BLEU metric for machine translation  .,1,original
"In this paper, we show that a noisy channel model instantiated within the paradigm of Statistical Machine Translation     can successfully provide editorial assistance for non-native writers.",1,original
Dasgupta and Ng   improves over   by suggesting a simpler approach.,1,original
"  showed that, for this choice of joint feature vector, loss-augmented inference can be performed optimally using an efficient greedy algorithm.",1,original
"Here, we use the more established ROUGE-W measure   instead.",1,original
"The pioneering work of Ramshaw and Marcus   introduced NP chunking as a machine-learning problem, with standard datasets and evaluation metrics.",1,original
"The NLST trial was conducted among high-risk individuals of old age and heavy smokers, and demonstrated positive results  .",1,original
This new model leads to significant improvements in MT quality as measured by BLEU  .,1,original
"This type of input information   is a powerful and flexible model for specifying alternative inputs to a classifier, and has been additionally used by Haghighi and Klein  .",1,original
"To compare the output of their shallow parser with the output of the well-known Collins   parser, Li and Roth applied the chunklink conversion script to extract the shallow constituents from the output of the Collins parser on WSJ section 00.",1,original
Recent work emphasizes corpus-based unsupervised approach   that avoids the need for costly truthed training data.,1,original
"The development of mathematical models for evolution of primary quantities of interest in bioreactor systems, as well as their incorporation into the design process, have the potential to accelerate the path to realization of optimal functional outcomes in engineered tissues; see   for a review of modeling approaches.",1,original
"Although we have argued   that this is unlikely to succeed, to our knowledge, we are the first to investigate the matter empirically.11 The best-known MT aligner is undoubtedly GIZA++  , which contains implementations of various IBM models  , as well as the HMM model of Vogel et al.",1,original
"Many researchers  , have observed consistent gains by using more flexible matching criteria.",1,original
The SBF with biophysically realistic model oscillators Cosine oscillators were extensively used in numerical simulations of interval timing models with great success  .,1,original
"…results for our experiment   using TextTiling and other two state-of-the-art segmentation algorithms, BayesianSeg, a Bayesian unsupervised topic segmentation method  , and MinCutSeg a graph-based segmentation model  .",1,original
"…the second most stably expressed gene identified in our study, α-tub, has been shown to be stably expressed during development in Orobanche  , cucumber  , sunflower  , and aphid infestation of chrysanthemum  .",1,original
Both the alleviation of fluid overload   as well as the provision of this necessary volume in the form of medications improve outcomes and mortality risk.,1,original
One of the simplest models that can be seen in the context of lexical triggers is the IBM model 1   which captures lexical dependencies between source and target words.,1,original
1 Introduction State-of-the-art part of speech   tagging accuracy is now above 97% for newspaper text  .,1,original
"A detailed description of the popular translation/alignment models IBM-1 to IBM-5  , as well as the Hidden-Markov alignment model     can be found in  .",1,original
"1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments  .",1,original
A simulated annealing-based heuristic approach has been developed to solve the NP-complete problem in a computationally efficient manner  .,1,original
"Recently, sentiment classification has become popular because of its wide applications  .",1,original
6 Related Work The popular IBM models for statistical machine translation are described in  .,1,original
subjective OSATS GRS has high interobserver reliability and proven utility in assessing vessel ligation.  Scores on the GRS items were averaged to produce a representative composite score.,1,original
1 Introduction The best performing systems for many tasks in natural language processing are based on supervised training on annotated corpora such as the Penn Treebank   and the prepositional phrase data set first described in  .,1,original
Discriminative taggers and chunkers have been the state-of-the-art for more than a decade  .,1,original
e also use Cube Pruning algorithm   to speed up the translation process,1,original
"SVM has been shown to be useful for text classification tasks  , and has previously given good performance in sentiment classification experiments  .",1,original
1 Introduction Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation    .,1,original
"Recently, word-sense disambiguation   methods have been shown to improve translation quality  .",1,original
The IBM models 1-5   produce word alignments with increasing algorithmic complexity and performance.,1,original
agent was reported to reduce the risk of cardiac mortality  .,1,original
.1 The AUGMENT technique for Domain Adaptation The AUGMENT technique introduced by Daume III   is a simple yet very effective approach to performing domain adaptation,1,original
"edu/eeglab); this procedure was extremely effective in decomposing the signals into multiple statistically independent components, allowing artifacts to be easily detected  .",1,original
rute-force methods   may well produce some useful results  ,1,original
4 Extended Minimum Error Rate Training Minimum error rate training   is widely used to optimize feature weights for a linear model  .,1,original
"Corpus-based or example-based MT   and statistical MT   systems provide the easiest customizability, since users have only to supply a collection of source and target sentence pairs  .",1,original
The maximum entropy approach   is known to be well suited to solve the classification problem.,1,original
We note that better performance has been reported with the use of more image features  .,1,original
"If the purified proteins are used for mass spectrometric analyses, elution from streptavidin beads is not required because trypsin digestion can be performed efficiently on bead-bound proteins and the released peptides can be analysed by mass spectrometry  .",1,original
This method has also been successfully applied to the insect nervous system  .,1,original
"5.1 The statistical parser The parsing model is the one proposed in Merlo and Musillo  , which extends the syntactic parser of Henderson   and Titov and Henderson   with annotations which identify semantic role labels, and has competitive performance.",1,original
Promising features might include those over source side reordering rules   or source context features  .,1,original
"Signals inspector such as oscilloscope, image processing library such as OpenCV, pattern matching algorithm   are integrated and ready-to-use to support that informal design technique.",1,original
Synchronous parsing models have been explored with moderate success  .,1,original
33 Hiero Search Refinements Huang and Chiang   offer several refinements to cube pruning to improve translation speed,1,original
"using the Reading Span  , one of the most widely used paradigms for the evaluation of selective attention; Abstraction and conceptual flexibility   were assessed by means of the modified Wisconsin Card Sorting Test (number categories and perseverative",1,original
"Since its introduction to the Natural Language Processing   community  , ME-based classifiers have been shown to be effective in various NLP tasks.",1,original
"To solve this problem, we adopt an idea one sense per collocation which was introduced in word sense disambiguation research  .",1,original
"In the domain of supply chain, logistics, and operations management, the approach has been popularized by Holmström et al.  , leading to promising initial applications  .",1,original
…showed that imaging or therapeutic agents larger than the BBB’s exclusion threshold of 400 Da could be successfully delivered by FUS with microbubbles  .,1,original
ther insights borrowed from the current state of the art include minimum-error-rate training of log-linear models   and use of an m-gram language model,1,original
There are however other similarity metrics  ) which could be used equally well.,1,original
Here we choose to work with stupid backoff smoothing   since this is significantly more efficient to train and deploy in a distributed framework than a contextdependent smoothing scheme such as Kneser-Ney.,1,original
One of the remarkable results of the application of the solubilization at 4 C with nonionic detergents of the erythrocyte membrane is the almost complete exclusion of band 3 protein from the DRMs  .,1,original
Lysine diisocyanate based degradable polyurethanes have been found to be biocompatible materials with potential uses in drug delivery systems  .,1,original
"Target language model probability   According to a previous study, the minimum error rate training    , which is the optimization of feature weights by maximizing the BLEU score on the development set, can improve the performance of a system.",1,original
This scoring function has been successfully applied to resolve ambiguity problems in an English-to-Chinese machine translation system     and a spoken language processing system  .,1,original
This is conWrmed by the superior results of functional conservative or postsurgical treatment procedures in comparison to non-weight bearing plaster cast immobilisation  .,1,original
"A simple, yet high performing approach for mapping a given surface form  , to its corresponding DBpedia   entity is to link to its most frequent candidate entity Mihalcea and Csomai  . Even though this approach does not take any context information into account, it has proven to be effective not only for text entity linking, but also for Nell triple linking (Dutta et al.",1,original
"The contraceptive reliability of the levonorgestrel-releasing intrauterine system   is well established, with efficacy comparable to female sterilization  , but with the added advantage of rapid return of fertility upon removal.",1,original
"In the well-known so-called IBM word alignment models  , re-estimating the model parameters depends on the empirical probability P  for each sentence pair  .",1,original
"In this regard, it is worth noting that the number of studies that have reported at least some mixed strain infections in a wide variety of hosts, including cats, has increased greatly since more sensitive genotyping techniques have been applied  .",1,original
2 Confusion-network-based MT system combination The current state-of-the-art is confusion-networkbased MT system combination as described by 98  Rosti and colleagues  .,1,original
ch   has described an ef cient exact one-dimensional error minimization technique for a similar search problem in machine translation,1,original
This algorithm and its many variants are widely used in the computational linguistics community  .,1,original
"  describe a novel algorithm for entropy estimation for which they claim very fast convergence time; using no more than about five pages of text, they can achieve nearly the same accuracy as  .",1,original
Several recent real-world parsers have improved state-of-the-art parsing accuracy by relying on probabilistic or weighted versions of bilexical grammars  .,1,original
Also the use of lossy data structures based on Bloom filters has been demonstrated to be effective for LMs  .,1,original
"The most widely used are Word Error Rate  , Position Independent Word Error Rate  , the BLEU score   and the NIST score  .",1,original
To estimate the parameters of the MEMM+pred model we turn to the successful Maximum Entropy   parameter estimation method.,1,original
Many previous studies have shown that the log-likelihood ratio is well suited for this purpose  .,1,original
"Although the Kappa coefficient has a number of advantages over percentage agreement   for details), we also report percentage agreement as it allows us to compare straightforwardly the human performance and the automatic methods described below, whose performance will also be reported in terms of percentage agreement.",1,original
"The state-of-the-art SMT system Moses implements a distance-based reordering model   and a distortion model, operating with rewrite patterns extracted from a phrase alignment table  .",1,original
Oxidized graphene nanomaterials were demonstrated to be able to serve as efficient carrier systems for the targeted delivery of chemical drugs  .,1,original
"Among the preparations of BoNT/A on the market, incobotulinumtoxinA   is the only complexing protein-free BoNT/A  .",1,original
Table 1: Datasets 3.3 Establishing a Baseline for a Corpus-based System   Supervised statistical methods have been very successful in sentiment tagging of texts: on movie review texts they reach accuracies of 85-90%  .,1,original
"In a later study, Och and Ney   present a loglinear combination of the HMM and IBM Model 4 that produces better alignments than either of those.",1,original
The improved pharmacokinetic and pharmacodynamic parameters of ixazomib compared to bortezomib have made it a focus of investigation for use in combination with other pro-apoptotic agents  .,1,original
In syntactic parse re-ranking supersenses have been used to build useful latent semantic features  .,1,original
" , Pedersen  , Yarowsky and Florian  ) as well as maximum entropy models  , Klein and Manning  ) in particular have shown a large degree of success for WSD, and have established challenging state-of-the-art benchmarks.",1,original
The translation quality was evaluated using a well-established automatic measure: BLEU score  .,1,original
"3 Extending Bleu and Ter with Flexible Matching Many widely used metrics like Bleu   and Ter   are based on measuring string level similarity between the reference translation and translation hypothesis, just like Meteor . Most of them, however, depend on finding exact matches between the words in two strings.",1,original
The latter approach has become increasingly popular  .,1,original
"In our preliminary experiments, we used a Support Vector Machine   ranker   to learn the structured classi er.2 We also in1See e.g. Collins   for a popular training algorithm.",1,original
"In our experiments, we follow Lowe and McDonald   in using the well-known log-likelihood ratio G 2  .",1,original
"However, recent progress in machine translation and the continuous improvement on evaluation metrics such as BLEU   suggest that SMT systems are already very good at choosing correct word translations.",1,original
  demonstrated that semi-supervised WSD could be successful.,1,original
"Recent papers   show that spatial max and average pooling of feature maps output by intermediate convolutional layers is an effective representation, and higher performance can be achieved compared to using fully connected layers.",1,original
"Many efficient techniques exist to extract multiword expressions, collocations, lexical units and idioms  .",1,original
"Currently, high-throughput methods to screen high-producer cells have been developed  .",1,original
1 Introduction Parsing technology has come a long way since Charniak   demonstrated that a simple treebank PCFG performs better than any other parser   on parsing the WSJ Penn treebank  .,1,original
"We use two state-of-the-art POS taggersa maximum entropy based English POS tagger  , and an HMM based Chinese POS tagger.",1,original
"3.2 Statistical Learning Model 3.2.1 Nave Bayes Learning Nave Bayes learning has been widely used in natural language processing with good results such as statistical syntactic parsing  , hidden language understanding  .",1,original
The abduction-based approach   has provided a simple and elegant way to realize such a task.,1,original
"We used the average perceptron algorithm of Collins   in our experiments, a variation that has been proven to be more effective than the standard algorithm shown in Figure 2.",1,original
"Such training has been shown to reduce resting CRP and IL-6  , and improve glycaemic control   and body composition  .",1,original
"Several classification models can be adopted here, however, we choose the averaged perceptron algorithm   because of its simplicity and high accuracy.",1,original
"Annotated reference corpora, such as the Brown Corpus  , the Penn Treebank  , and the BNC  , have helped both the development of English computational linguistics tools and English corpus linguistics.",1,original
"For example, enumeration of CD8+ tumor-infiltrating lymphocytes   has been shown to be a reliable prognostic marker for a number of cancers, including colorectal cancer and non–small-cell lung carcinoma    .",1,original
"7Another related measure is Dunning  's likelihood ratio tests for binomial and multinomial distributions, which are claimed to be effective even with very much smaller volumes of text than is necessary for other tests based on assumed normal distributions.",1,original
u   showed that restricting word-level alignments between sentence pairs to observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows a polynomial-time solution,1,original
"However, the only known work which automates part of a customer service center using natural language dialogue is the one by Chu-Carroll and Carpenter  .",1,original
The best result known to us is achieved by Toutanova .,1,original
"2 Treebanking The Penn Treebank   is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of empty categories that represent displaced constituents.",1,original
"Eigenvector centrality in particular has been successfully applied to many different types of networks, including hyperlinked web pages  , lexical networks  , and semantic networks  .",1,original
"For the multilingual dependency parsing track, which was the other track of the shared task, Nilsson et al. achieved the best performance using an ensemble method  .",1,original
"In this way, Wikipedia provides a new very large source of annotated data, constantly expanded  .",1,original
"Among these, nanocarbons are now considered the most promising fillers for the development of high performance materials  .",1,original
"Furthermore, risk-factor awareness among patients with lower-limb ischemia is suboptimal, and one benefit of a NLC is the opportunity to educate patients.  Indeed, our results show significant benefits of a protocol-based NLC for claudicants with a 25% relative risk reduction of predicted 10-year coronary events over a 3-month period.",1,original
"Similar models have been successfully applied in the past to other tasks including parsing  , chunking  , and machine translation  .",1,original
5.3 Comparison with System Combination We re-implemented a state-of-the-art system combination method  .,1,original
"Local adaptation may, however, be inferred in several ways, one of the most widely used being reciprocal translocation studies, where different populations are reared in a reciprocal manner in their locations of origin  .",1,original
The beneficial role of PBM as supportive modality in the management of postmastectomy lymphedema is well established based on strong evidence  .,1,original
"Currently, the best-performing English NP interpretation methods in computational linguistics focus mostly on two consecutive noun instances   and are either   supervised, knowledge-intensive  ,  ,  ,  ,  ,  ,  ,  , or use statistical models on large collections of unlabeled data  ,  ,  ,  .",1,original
"Our similarity method is similar, but simpler, to that used by  , which report very good results on similarity datasets.",1,original
Previous work for English   has shown that lexicalization leads to a sizable improvement in parsing performance.,1,original
The Actigraph accelerometer   has been extensively and successfully used to assess physical activity in children in both small   epidemiological studies.,1,original
"1 Introduction Statistical approaches to machine translation, pioneered by  , achieved impressive performance by leveraging large amounts of parallel corpora.",1,original
"Ruby   goes one step further by making the syntax much more compact and simpler and also provides various built-in features that make the common tasks of text processing, creating and processing threads, web programming etc.",1,original
"One major resource for corpus-based research is the treebanks available in many research organizations \ , which carry skeletal syntactic structures or 'brackets' that have been manually verified.",1,original
"Due to this data sparsity problem, state-of-the-art systems for NER in morphologically rich languages usually make use of the analysis of the morphological structures of the languages and require language specific feature engineering  .",1,original
Log-likelihood ratio The log-likelihood ratio statistic has been found to be accurate for modeling the associations between rare events  .,1,original
More recent work has achieved state-of-the-art results with Maxi101 mum entropy conditional Markov models    .,1,original
"However, the best performing statistical approaches to lexical ambiguity resolution l;lmmselves rely on complex infornmtion sources such as """"lemmas, inflected forms, parts of speech and arbitrary word classes If\] local and distant collocations, trigram sequences, a.nd predicate m'gument association""""  , p. 190) or large context-windows up to 1000 neighboring words  .",1,original
1 Introduction The Maximum Entropy   statistical framework   has been successfully deployed in several NLP tasks.,1,original
"5 Comparison with Previous Top Systems and Related Work In POS tagging, the previous best performance was reported by   as summarized in Table 7.",1,original
"Recently, 3D-CNNs have been widely used for various 3D data analysis tasks such as 3D detection or classification  .",1,original
"By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation   and information retrieval  .",1,original
  hold state-of-the-art results for Czech NER.,1,original
"Maximum entropy can be used to improve IBM-style translation probabilities by using features, such as improvements to P  in  .",1,original
"Whereas dependency based semantic spaces have been shown to surpass other word space models for a number of problems  , for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better  .",1,original
The most commonly used MT evaluation metric in recent years has been IBMs Bleu metric  .,1,original
"…tool which provides enhanced capabilities for peptide sequencing directly from samples such as nervous tissues or even single cells of invertebrates, including those of insects  .",1,original
"Hunter take rates Hunter take   is a widely applied method for assessing relative abundance of wildlife, including wild swine  .",1,original
"Moreover, comparable results were obtained in an in vivo imaging study on mice, which was performed with the highly resolving U-SPECT  IBZM binding relative to baseline.",1,original
ecent work emphasizes a corpus-based unsupervised approach   that avoids the need for costly truthed training data,1,original
"General purpose text annotations, such as part-of-speech tags and noun-phrase bracketing, are costly to obtain but have wide applicability and have been used successfully to develop statistical NLP systems  .",1,original
is results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words  ,1,original
"…“bicarbonate concentration threshold”   and without at least partial recovery of blood pHe  . remarkably, some of the most CO2 tolerant fishes studied to date tightly regulate the pHi of vital…",1,original
used in the method has been proven as a safe resource for biologic organisms  .,1,original
"Then, we apply a grow-diag-final algorithm which is widely used in bilingual phrase extraction   to monolingual alignments.",1,original
"1 Introduction One of the major approaches to disambiguate word senses is supervised learning  ,  ,  ,  ,  ,  ,  ,  .",1,original
Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging 2   .,1,original
2.3 Classifier Training We chose maximum entropy   as our primary classifier because the highest performing systems in both the SemEval-2007 preposition sense disambiguation task   and the general word sense disambiguation task   used it.,1,original
"2 Maximum Entropy Models Maximum entropy   models  , also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
SVMs have also been proved to outperform other nonlinear techniques including neural network-based techniques such as multilayer perceptrons    .,1,original
"For instance,   shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks.",1,original
"A large part of Shannon’s seminal work   is devoted to both theoretical and practical aspects of products, and his invocation of the pastry dough mixing analogy [16, p.",1,original
Some of the more popular and more accurate of these approaches to data-driven parsing   have been based on generative models that are closely related to probabilistic contextfree grammars.,1,original
"In our experience, this approach is advantageous in terms of translation quality, e.g. by 0.7% in BLEU compared to a minimum Bayes risk primary  .",1,original
"It was found to produce automated scores, which strongly correlate with human judgements about translation fluency  .",1,original
"While there have been remarkable developments in the last ten years  , structuring large-scale visual data is still an active research area and any improvements would have wide applicability.",1,original
The superior bonding effectiveness shown in vitro  .,1,original
"For instance, the mutual information   and log-likelihood ratio   have been widely used for extracting word bigrams.",1,original
"Assuming the well-known Kronecker correlation structure   we can decompose H as H = R 1 2HwS 1 2   where R and S are the receive and transmit correlation matrices respectively, satisfying tr   = Nr and tr   = Nt, and the elements of Hw are i.",1,original
Stochastic models   have been widely used in POS tagging for simplicity and language independence of the models.,1,original
"Another interesting point is the relation to maximum entropy model  , which is popular in the natural language processing community.",1,original
"In order to filter some noise caused by the error alignment links, we only retain those translation pairs whose translation probabilities are above a threshold 1 D 1  or co-occurring frequencies are above a threshold 2  . When we train the IBM statistical word alignment model with a limited bilingual corpus in the specific domain, we build another translation dictionary with the same method as for the dictionary . But we adopt a different filtering strategy for the translation dictionary . We use log-likelihood ratio to estimate the association strength of each translation pair because Dunning   proved that log-likelihood ratio performed very well on small-scale data.",1,original
5.4 Maximum Entropy Maximum entropy has been proven to be an effective method in various natural language processing applications  .,1,original
"However, the most interesting work is certainly proposed by   who extract patterns in two steps.",1,original
"This type of direct optimization is known as Minimum Error Rate Training   in the MT community, and is an essential component in building the stateof-art MT systems.",1,original
"Compared with their string-based counterparts, treebased systems offer some attractive features: they are much faster in decoding  ), do not require a binary-branching grammar as in string-based models  , and can have separate grammars for parsing and translation, say, a context-free grammar for the former and a tree substitution grammar for the latter  .",1,original
Ochs procedure is the most widely-used version of MERT for SMT  .,1,original
"As reported in  , parameter averaging can effectively avoid overfitting.",1,original
"Following initial work by   and  , an early, online distributional thesaurus presented in   has been widely used and cited, and numerous authors since have explored thesaurus properties and parameters: see survey component of  .",1,original
"The most widely used are Word Error Rate  , Position independent word Error Rate  , the BLEU score   and the NIST score  .",1,original
"Two methods  , which were previously reported as competitive in automated diagnosis of CD   were utilized in addition to state-of-the-art global mid-level image representations which are obtained by pooling local image descriptors.",1,original
Previous work has demonstrated that this scoring function is able to provide high discrimination power for a variety of applications  .,1,original
"For example, Smith and Smith   and Burkett and Klein   show that joint parsing   on a bitext improves accuracies on either or both sides by leveraging bilingual constraints, which is very promising for syntax-based machine translation which requires   parse trees for rule extraction  .",1,original
2 Background: MaxEnt Models Maximum Entropy   models are widely used in Natural Language Processing  .,1,original
This algorithm is referred to as GHKM   and is widely used in SSMT systems  .,1,original
"Recently,   have successfully applied self-training to various parser adaptation scenarios using the reranking parser of  .",1,original
"This kind of corpus has served as an extremely valuable resource for computational linguistics applications such as machine translation and question answering  , and has also proved useful in theoretical linguistics research  .",1,original
Recent advances in biliary drainage techniques have dramatically improved the mortality rate from  .,1,original
"1 Introduction Automatic Metrics for machine translation   evaluation have been receiving significant attention in the past two years, since IBM's BLEU metric was proposed and made available  .",1,original
Another study has shown a proof of concept closed-loop model using direct pressure monitoring as the feedback signal  .,1,original
"we use the perceptron-like algorithm proposed in   which does not suffer from the label bias problem, and is fast in training.",1,original
"Particularly, syntactically annotated corpora  , such as Penn Treebank  , Negra Corpus   and EDR Corpus  , contribute to improve the performance of morpho-syntactic analysis systems.",1,original
One possible approach is to employ state-of-the-art techniques for coreference and zeroanaphora resolution   in preprocessing cooccurrence samples.,1,original
"Among the available alternatives, we have selected three well-known tools: cbmc  , a recent tool based on Abstract Interpretation.",1,original
Recent work by   shows a practically ef cient approach that binarizes linguistically SCFG rules when possible.,1,original
"Optimization Metrics When sampling phrase sets for text entry experiments, memorability and representativeness are two metrics that have been widely adopted by researchers  .",1,original
"We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM   and HMMs trained with soft constraints  .",1,original
It is natural to study the swelling and shrinking of catalyzed bulk pNIPAm gels at first because of the relatively simple gelation process and the convenient methods of observation such as microscopy .,1,original
"This is analogous, and in a certain sense equivalent, to empirical risk minimization, which has been used successfully in related areas, such as speech recognition  , language modeling  , and machine translation  .",1,original
"On the Hansards data, the simple averaging technique described by Collins   yields a reasonable model.",1,original
"Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O   and polarity classification  .",1,original
"Variants of this method have been successfully used in many NLP tasks, like shallow processing  , parsing   and word alignment  .",1,original
We are starting to see the beginnings of a positive effect of WSD in NLP applications such as Machine Translation  .,1,original
"In particular, as shown in  , the memory-based string matching engine allows on-the-fly update of memory contents for high reconfigurability.",1,original
2005) have implemented a dependency parser with good accuracy  ) and very impressive speed   and four times faster than Charniak  ),1,original
Section 4 describes the online training procedure and compares it to the well known perceptron training algorithm  .,1,original
"Some NLG researchers are impressed by the success of the BLEU evaluation metric   in Machine Translation  , which has transformed the MT field by allowing researchers to quickly and cheaply evaluate the impact of new ideas, algorithms, and data sets.",1,original
he latent-annotation model   is one of the most effective un-lexicalized models,1,original
These models have achieved state-of-the-art performance in transcript-based speech summarization  .,1,original
"This represents the translation probability of a phrase when it is decomposed into a series of independent word-for-word translation steps  , and has proven a very effective feature  .",1,original
"In most cases, supervised learning methods can perform well  .",1,original
"In recent years, reranking techniques have been successfully applied to the so-called history-based models  , especially to parsing  .",1,original
"For instance, on unsupervised part-ofspeech tagging, EM requires over 100 iterations to reach its peak performance on the Wall-Street Journal  .",1,original
"Because of its high spatial resolution and applicability to air-filled structures, CT is a good alternative for guiding RFA, which cannot be adequately guided by US  .",1,original
These advantages of using waveguides enable synchronized concurrent accesses of an optical bus in a pipelined fashion  .,1,original
"From a strategic viewpoint, layered modular architectures have the competitive advantage, as well as the challenge, in being doubly distributed  .",1,original
"This algorithm appears fairly widely known: it was described by Goodman   and Finkel et al   and used by Ding et al  , and is very similar to other dynamic programming algorithms for CFGs, so we only summarize it here.",1,original
"The combination is significantly better than   at a very high level, but more importantly, Shens results   have been significantly surpassed also by the semisupervised Morce  .",1,original
Every sentence was part-of-speech tagged using a maximum entropy tagger   and parsed using a state-of-the-art wide coverage phrase structure parser  .,1,original
Several studies have demonstrated that for instance Statistical Machine Translation   benefits from incorporating a dedicated WSD module  .,1,original
"Using the IBM translation models IBM-1 to IBM-5  , as well as the Hidden-Markov alignment model  , we can produce alignments of good quality.",1,original
Its success stories range from parsing   to machine translation  .,1,original
"We also report state-of-the-art results for Hebrew full mor1Another notable work, though within a slightly different framework, is the prototype-driven method proposed by  , in which the dictionary is replaced with a very small seed of prototypical examples.",1,original
"The validation study has shown that the root mean square differences for the hip and knee flexion/extension with three camera views were 2.6° and 7.5°, and multiple and perpendicular views were recommended to obtain more accurate results  .",1,original
"The Simulated Annealing approach has been proven to be very effective when applied to non convex optimization, for which gradient based algorithms may fail to produce good solutions, Cerný  ; Marques et al.  ; A.",1,original
Pupillometry has been proposed as a simple and sensitive tool to detect subclinical autonomic dysfunction  .,1,original
"Despite the preponderance of interview-based qualitative research, written accounts are an established methodology in health research  .",1,original
One popular and statistically appealing such measure is Log-Likelihood    .,1,original
"Online learning algorithms have been shown to be robust even with approximate rather than exact inference in problems such as word alignment  , sequence analysis   and phrase-structure parsing  .",1,original
"Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation  .",1,original
"Most early work assumed some limited amount of supervision   for this task, recent work has shown that unsupervised methods can perform on-par and often above early supervised methods  .",1,original
"In addition, Nanog, in association with other reprogramming factors, has been shown to not only reprogram differentiated somatic cells into pluripotent stem cells  .",1,original
"1 Introduction Most state-of-the-art wide-coverage parsers are based on the Penn Treebank  , making such parsers highly tuned to newspaper text.",1,original
"1 Introduction Since 1995, a few statistical parsing algorithms   demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard.",1,original
The Gaussian prior   has been found in practice to be very effective in combating overfitting of the parameters to the training data  .,1,original
"Among several endogenous lipophilic molecules known to activate CBRs, the best characterized are N-arachidonoylethanolamine   and 2-arachidonoylglycerol  , which are known to modulate synaptic transmission throughout the brain  .",1,original
"Church and Hanks   use mutual information to identify collocations, a method they claim is reasonably effective for words with a frequency of not less than five.",1,original
We compare KCDML not only with the state-of-art methods including our current work—CDML   and LDA.,1,original
"Recent work   has demonstrated that randomized encodings can be used to represent n-gram counts for LMs with signficant space-savings, circumventing information-theoretic constraints on lossless data structures by allowing errors with some small probability.",1,original
CMA yields significant rates of pathogenic or potentially pathogenic   results  .,1,original
-Theory and Agreement Indices Two well-known measures for capturing the quality of manual annotations are agreement percentages and the kappa statistic  ,1,original
"Specifically, aspect rating as an interesting topic has also been widely studied  .",1,original
One of these topologies known as local topology or lbest model provided improvements on several multimodal optimization problems  .,1,original
"We train an event model with a binary SVM classifier after the features are selected, and   The state-of-the-art event detection methods.",1,original
"2.2 Motivation from previous work 2.2.1 Parsing In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank   and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging  , and PPattachment  .",1,original
"Our probabilistic model is based on Incremental Sigmoid Belief Networks  , a recently proposed latent variable model for syntactic structure prediction, which has shown very good behaviour for both constituency   and dependency parsing  .",1,original
Motivation Phrase-based statistical machine translation   has emerged as the dominant paradigm in machine translation research,1,original
"Similar survey results in Kentucky showed that the high-stakes, performance-based assessments in writing and mathematics strongly influenced teachers to make their instruction more consistent with the state curriculum in these areas  .",1,original
"Then, the SVM, which has been proven to have high efficiency in classifying the high-dimensional feature in previous studies  , was applied to our proposed model to identify the urban land use types in the TAZs.",1,original
"However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time  .",1,original
"Building on a recent proposal in this direction by Turney  , we propose a generic method of this sort, and we test it on a set of unrelated tasks, reporting good performance across the board with very little task-specific tweaking.",1,original
1 Introduction Modern phrasal SMT systems such as   derive much of their power from being able to memorize and use long phrases.,1,original
1 Introduction There is a pressing need for a consensus on a taskoriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the Penn Treebank   enabled the development of statistical syntactic parsers  .,1,original
Data on the occurrence of the principal mycotoxins on foods and beverages are increasing due to the availability and use of modern and sensitive LC–MS/MS and GC–MS/MS methodologies suitable for simultaneous determination of mycotoxins  .,1,original
One of the most promising methods among them is PLDA  .,1,original
"Recently, graph-based methods have proved useful for a number of NLP and IR tasks such as document re-ranking in ad hoc IR   and analyzing sentiments in text  .",1,original
"Because the expressiveness characteristics of ITG naturally constrain the space of possible matching in a highly appropriate fashion, BTG achieves encouraging results for bilingual bracketing using a word-translation lexicon alone  .",1,original
"More rapid reporting by other technologies, such as detection of bacterial species and resistant markers in positive blood cultures by molecular probe and nucleic acid amplification do result in improved patient care  .",1,original
"This approach took inspiration from the pioneering work by  , but it is also fundamentally different, because instead of grouping similar senses together, the CoreLex approach groups together words according to all of their senses.",1,original
"For our experiments, we chose GIZA++   and the RA approach   the best known alignment combination technique as our initial aligners.1 4.2 TBL Templates Our templates consider consecutive words   in both languages.",1,original
"One study conducted on elderly patients showed that the combined strategy of visits and telemedicine improved HRQOL and their knowledge about the disease, achieving a high degree of satisfaction with the program.  Similarly, another study showed a high degree of patient satisfaction (96.",1,original
"The best example of such an approach is  , who proposes a method that automatically identifies collocations that are indicative of the sense of a word, and uses those to iteratively label more examples.",1,original
"One of the best efforts to quantify the performance of a term-recognition system   does so only for one processing stage, leaving unassessed the text-to-output performance of the system.",1,original
The baseline we measure against in all of these experiments is the state-of-the-art grow-diag-final   alignment refinement heuristic commonly used in phrase-based SMT  .,1,original
A primary benefit of these models is the inclusion of variability in model parameters  .,1,original
The most widely used association weight function is   Mutual Information    .,1,original
"To evaluate the performance of the proposed SDQI, seven state-of-the-art methods BRISQUE   have been compared objectively and subjectively.",1,original
"Competitors We compared the proposed SLST model with five state-of-the-art alternative detection approaches:   Faster R-CNN   method, exactly the same as our SLST model.",1,original
The approach is very general and modular and can work in conjunction with a number of learning strategies for word sense disambiguation  .,1,original
"It worked well for word segmentation alone  , even with an agenda size as small as 8, and a simple beam search algorithm also works well for POS tagging  .",1,original
"A recent study in northern Vietnam, in which researchers used participatory methods when introducing an educational programme for community health leaders, demonstrated promising results in learning capacity, and the health leaders expressed enthusiasm for this mode of gaining knowledge  .",1,original
"We conclude by noting that English language models currently used in speech recognition   and automated language translation   are much more powerful, employing, for example, 7-gram word models   trained on trillions of words.",1,original
The translation quality is evaluated using a well-established automatic measure: BLEU score  .,1,original
Properly calculated BLEU scores have been shown to correlate reliably with human judgments  .,1,original
"3 Space-Efficient Approximate Frequency Estimation Prior work on approximate frequency estimation for language models provide a no-false-negative guarantee, ensuring that counts for n-grams in the model are returned exactly, while working to make sure the false-positive rate remains small  .",1,original
"Similar to  , we also applied four popular subspace learning methods including PCA, LDA, LPP and ONPP for appearance-based facial expression recognition with spatial misalignments.",1,original
"Insects are ideal systems to investigate the interplay between infection and behavior.  The fruit fly Drosophila is especially amenable to these studies, as it is one of the best developed model systems for host-pathogen interactions  and behavioral ecology and genetics.",1,original
"Our model exploits the same kind of tag-n-gram information that forms the core of many successful tagging models, for example,  ,  ,  .",1,original
” This is a highly reliable prognostic marker in colorectal cancer and is currently being investigated for use in other tumor types  .,1,original
"High-performance taggers typically also include joint three-tag counts in some way, either as tag trigrams   or tag-triple features  .",1,original
"Interest in the use of CWs for remediation of runoff from agricultural irrigation and agro-industrial production has become increasingly popular over the last decades, due to their low capital and operational cost, low energy consumption, and environmental friendliness  .",1,original
Bhattacharjee & Ghosh   discussed about probable construction management courses where role-playing teaching could be adopted as a successful pedagogical approach.,1,original
"This approach has been shown to be accurate, relatively efficient, and robust using both generative and discriminative models  .",1,original
"On the other hand, high-quality treebanks such as the Penn Treebank   and the Kyoto University text corpus   have contributed to improving the accuracies of fundamental techniques for natural language processing such as morphological analysis and syntactic structure analysis.",1,original
Dermoscopy is cost-effective and its use increases the diagnostic accuracy by 5-30% over visual inspection  .,1,original
4.1 Features We used a dependency structure as the context for words because it is the most widely used and one of the best performing contextual information in the past studies  .,1,original
"For example, it is well known that translation-invariant undecimated wavelets   are a dramatically more effective domain than the basic fully decimated orthogonal   wavelets for denoised a signal by shrinkage; the realization of",1,original
ch   has described an efficient exact onedimensional accuracy maximization technique for a similar search problem in machine translation,1,original
Their performance is presented in comparison to state-of-the-art methods such as original GNNS  .,1,original
An especially well-founded framework for doing this is maximum entropy  .,1,original
"1 Introduction Several efficient, accurate and robust approaches to data-driven dependency parsing have been proposed recently   for syntactic analysis of natural language using bilexical dependency relations  .",1,original
"Compared to their k-based counterparts 2D SPEN pulses can have, under the right conditions, an enhanced robustness vis-à-vis field heterogeneities and chemical shifts  .",1,original
"We evaluated the generator on the Penn Treebank  , which is highly reliable corpus consisting of real-world texts.",1,original
"Collins and Roark   saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.",1,original
This is a common technique in machine translation for which the IBM translation models are popular methods  .,1,original
Encouraging analytic results and some Monte Carlo simulations of the CP 1 model have been reported in  .,1,original
"Of the beneficial actions of garlic, such as antitumorigenesis, antiatherosclerosis, blood sugar modulation and antibiosis, inhibition of the growth of cancer is perhaps the most notable  .",1,original
"We chose the perceptron for the training algorithm because it has shown good performance on other NLP tasks; in particular, Collins   reported good performance for a perceptron tagger compared to a Maximum Entropy tagger.",1,original
"2.2 Statistical Parsers Pioneered by the IBM natural language group   and later pursued by, for example, Schabes, Roth, and Osborne  , Jelinek et al.",1,original
Turning off the extensions to GIZA++ and training p0 as in   produces a substantial increase in AER.,1,original
1 Introduction Phrase-based Statistical MT     has become the predominant approach to Machine Translation in recent years.,1,original
"Recently there have been some improvements to the Charniak parser, use n-best re-ranking as reported in   and selftraining and re-ranking using data from the North American News corpus   and adapts much better to the Brown corpus  .",1,original
"2.1 Log-Linear Models The log-linear model  , or also known as maximum-entropy model  , is a linear classifier widely used in the NLP literature.",1,original
"Preparing tagged corpora either by hand is labour-intensive and potentially error-prone, and although a semi-automatic approach can be used  , it is a good thing to reduce the human involvement as much as possible.",1,original
"Geneexpression-based classifiers have been frequently explored in recent years for several pathologic conditions, and resulted in FDA-approved diagnostics for early breast cancer  .",1,original
"On the other hand, the best available parsers trained on the Penn Treebank, those of Collins   and Charniak  , use statistical models for disambiguation that make crucial use of dependency relations.",1,original
"1 Introduction Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy  .",1,original
"Its also worth noting that Collins and Roark   saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.",1,original
Experiments show that the resulting rule set significantly improves the speed and accuracy over monolingual binarization   in a stateof-the-art syntax-based machine translation system  .,1,original
486 One of the most popular instantiations of loglinear models is that including phrase-based   models  .,1,original
he Yarowsky   algorithm was one of the first bootstrapping algorithms to become widely known in computational linguistics,1,original
"LSTMs are able to capture past signal behavior and they have shown success in many audio processing applications, such as speech recognition and computational paralinguistics  .",1,original
1 Introduction Large scale annotated corpora such as the Penn TreeBank   have played a central role in speech and natural language research.,1,original
"On the contrary, when nonvertebrobasilar vertigo is considered, the combination of cervical MRI, TCD and BAEP has superiorities to rule out vertebrobasilar insufficiency for their negative correlations  .",1,original
"Recent work includes improved model variants   and applications such as web data extraction  , scientific citation extraction  , and word alignment  .",1,original
"In this paper, we build on recent work   that demonstrated how the Bloom filter  ; BF), a space-efficient randomised data structure for representing sets, could be used to store corpus statistics efficiently.",1,original
"Adding resistance exercise, however, appears more useful than moderate aerobic exercise alone in protecting diet-induced losses in LBM  .",1,original
"SEM is a powerful tool that allows for the relative effect of many explanatory factors on a response variable to be determined, even if many of the explanatory factors are correlated  .",1,original
"We use the GBrank algorithm for the ranking model learning, as GBrank is one of the most effective learning-to-rank algorithms  .",1,original
"Finally, ADMGA is compared with the previously proposed nAMGA, used in   to tackle a dynamic knapsack problem with good results.",1,original
Transanal minimally invasive surgery   has emerged as an important alternative to transanal endoscopic microsurgery   capable of providing highquality local excision for rectal neoplasia  .,1,original
iero Search Refinements Huang and Chiang   offer several refinements to cube pruning to improve translation speed,1,original
of the most important is Lins  ,1,original
"Among recent top performing methods are Hidden Markov Models  , maximum entropy approaches  , and transformation-based learning  .",1,original
"In order to fulfill this point the most popular technic is the replication in different providers  , however this process generates a waste of storage resources when the system makes unnecessary replicas.",1,original
"On the other hand, MPCCs metabolized low turnover drugs   significantly faster in the serum-free medium than in vivo, and thus use of reported fu values significantly improved the accuracy of clearance predictions, as also observed previously  .",1,original
"1 Introduction Over the last few years, several automatic metrics for machine translation   evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle  .",1,original
  presented randomized language model based on perfect hashing combined with entropy pruning to achieve further memory reductions.,1,original
"  regarded MWE as connected collocations: a sequence of neighboring words whose exact meaning cannot be derived from the meaning or connotation of its components, which means that MWEs also have low ST. As some pioneers provide MWE identiflcation methods which are based on association metrics  , such as likelihood ratio  .",1,original
Autogenous bone grafts are still the most effective bone substitutes and are therefore considered the gold standard  .,1,original
Some of the best results were reported in   who uses a large training corpus.,1,original
Two of themost important group of proteins involved in the cell cycle machinery are cyclins and cyclin-dependent kinases    .,1,original
"This problematic situation was alleviated by viewing the scanned areas with a wider window, such as a bone setting.  The author of case series of human patients stated that as the window width was increased, the foreign bodies were more easily identified and better differentiated from a gas or fluid build up due to the wood’s absorptive characteristics and the duration of the injury.",1,original
"In addition, parsing re-ranking   has also been shown to be another effective technique to improve parsing performance.",1,original
2 Related Work Supervised machine learning methods including Support Vector Machines   are often used in sentiment analysis and shown to be very promising  .,1,original
"It has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model training, can significantly improve word alignment F-measure and translation performance  .",1,original
"Probably the most widely used association weight function is   Mutual Information    ,  ,  ,  , defined by: A known weakness of MI is its tendency to assign high weights for rare features.",1,original
"  and   shows how some of the methods which have been used in the past   are invalid for rare events, and introduce accurate measures of how 'surprising' rare events are.",1,original
  showed that the results for French-English were competitive to state-of-the-art alignment systems.,1,original
Sentiment summarization has been well studied in the past decade  .,1,original
The 8-point RLS is widely used in Sweden in some emergency departments and neurosurgical units instead of the GCS.,1,original
"The approach has been shown to give improvements over the MAP classifier in many areas of natural language processing including automatic speech recognition  , machine translation  , bilingual word alignment  , andparsing .",1,original
"As agreement measure we choose the Kappa coefficient   , the agreement measure predominantly used in natural language processing research  .",1,original
"The Simulated Annealing approach has been proven to be very effective when applied to non convex optimization, for which gradient based algorithms may fail to produce good solutions, Cerný  ; Marques et al.",1,original
"2 Evaluation Metrics Currently, the most widely used automatic MT evaluation metric is the NIST BLEU-4  .",1,original
"The core technology of the proposed method, i.e., the automatic evaluation of translations, was developed in research aiming at the efficient development of Machine Translation   technology  .",1,original
"With data from the Southwest Oncology Group   for the use of adjuvant radiation therapy in high-risk patients  , and Messing trial results demonstrating an advantage in survival for long-term ADT in lymph node-positive patients  , good pathologic data are an important step toward multi-modality approach.",1,original
"First, we compared our system output to human reference translations using Bleu  , a widelyaccepted objective metric for evaluation of machine translations.",1,original
"2.3 Collinss   Parser Collinss statistical parser  ), improved by Bikel  , is based on the probabilities between head-words in parse trees.",1,original
"For the full parser, we use the one developed by Michael Collins    one of the most accurate full parsers around.",1,original
3.1 A History-Based Model The history-based   approach which incorporates more context information has worked well in parsing  .,1,original
1 Introduction The availability of large amounts of so-called parallel texts has motivated the application of statistical techniques to the problem of machine translation starting with the seminal work at IBM in the early 90s  .,1,original
Current state of the art machine translation systems   use phrasal   features extracted automatically from parallel corpora.,1,original
Recent work has shown that opportunistic routing is an efficient way to achieve low-latency yet energy-efficient data collection in WSN  .,1,original
"Currently, machine learning methods   and combinations of classifiers   have been popular.",1,original
"The best examples of this approach has been the resent work of Yarowsky  ,  ,  .",1,original
The most common adverse effect was hypertension.  Another Phase II trial used axitinib 7 mg twice daily initially and a maximum dose of 10 mg if well tolerated.,1,original
Several general-purpose off-the-shelf   parsers have become widely available  .,1,original
"‚Ä¶using the software of MEME online-version 4.6.1  , which is one of the most widely used tools for observation of new sequence patterns in biological sequences and analysis of their significance  .",1,original
" , is fast and simple to apply as positioning and irradiation can be performed in a short time.",1,original
"Compared with typical antipsychotics, second-generation atypical antipsychotics have more acceptable side effect profiles and possibly broader symptom efficacy, especially concerning negative symptoms, thus advancing the treatment of schizophrenic patients  .",1,original
Twitter sentiment classification have intensively researched in recent years  .,1,original
1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models  .,1,original
East Asian H. pylori strains possess a D motif within CagA in place of the western C motif and this has been shown to be a potent inducer of SHP-2 phosphatase  .,1,original
"Randomized controlled trials conducted in a range of surgical settings over the last 25 years have clearly demonstrated that enoxaparin is associated with lower rates of VTE than placebo or elastic compression, without compromising patient safety  .",1,original
"We view this as a particularly promising aspect of our work, given that phrase-based systems such as Pharaoh   perform better with higher recall alignments.",1,original
"Moreover, log likelihood ratios are regarded as a more effective method to identify collocations especially when the occurrence count is very low  .",1,original
"We note that although PSIPRED was not optimized for peptides, the resulting fragment libraries showed in practice good coverage of the peptide conformational space  .",1,original
"Unsupervised approaches are attractive due to the the availability of large quantities of unlabeled text, and unsupervised morphological segmentation has been extensively studied for a number of languages  .",1,original
"ROUGE version 1.5.5   was used for evaluation.2 Among others, we focus on ROUGE-1 in the discussion of the result, because ROUGE-1 has proved to have strong correlation with human annotation  .",1,original
"The averaged perceptron   is a variant which averages the w across all iterations; it has demonstrated good generalization especially with data that is not linearly separable, as in many natural language processing problems.",1,original
"For comparison purposes, three additional heuristically-induced alignments are generated for each system:   Intersection of both directions  );   Union of both directions  ); and   The previously bestknown heuristic combination approach called growdiag-final    ).",1,original
"For the Penn Treebank,   reports an accuracy of 96.6% using the Maximum Entropy approach, our much simpler and therefore faster HMM approach delivers 96.7%.",1,original
"It was rolled out nationally in 2006 with funding of €55 million, after being successfully piloted in a small number of locations between 2001 and 2004  .",1,original
"Minimizing risk has been shown to improve performance for MT  , as well as other language processing tasks  .",1,original
"4%, an enormous improvement compared to the Lumbini survey 1995 result that reported just 15%  .",1,original
"The full model yields a stateof-the-art BLEU   score of 0.8506 on Section 23 of the CCGbank, which is to our knowledge the best score reported to date 410 using a reversible, corpus-engineered grammar.",1,original
1 Introduction Research in language processing has benefited greatly from the collection of large annotated corpora such as Penn PropBank   and Penn Treebank  .,1,original
"Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging  , spelling correction  , word-sense disambiguation  , message understanding  , discourse tagging  , accent restoration  , prepositional-phrase attachment   and base noun phrase identification  .",1,original
"ROUGE-L, ROUGE-W, and ROUGE-S have also been applied in automatic evaluation of summarization and achieved very promising results  .",1,original
The effort to develop new treatments for ALS has led to repeated failure since the demonstration that riluzole extended survival.  the recent negative results of the dexpramipexole Phase III study is yet another disappointing example.,1,original
They have made semantic formalisms like those now usually associated with Davison   attractive in artificial intelligence for many years  .,1,original
"Penn Treebank  was also used to induce part-of-speech   taggers because the corpus contains very precise and detailed POS markers as well as bracket, annotations.",1,original
The first one is the widely publicized Landau benchmark transmission system  : a tracking problem with a step disturbance rejection objective in an essentially noise-free environment.,1,original
"Substantial improvements have been made to parse western language such as English, and many powerful models have been proposed  .",1,original
"In Carpuat and Wu  , anotherstate-of-the-artWSDengine  is used to dynamically determine the score of a phrase pair under consideration and, thus, let the phrase selection adapt to the context of the sentence.",1,original
"The averaged version of the perceptron  , like the voted perceptron  , reduces the effect of over-training.",1,original
We show that our DDTM system provides significant improvements in BLEU   and TER   scores over the already extremely competitive DTM2 system.,1,original
"2.2 ITG Space Inversion Transduction Grammars, or ITGs   provide an efficient formalism to synchronously parse bitext.",1,original
he default training set of Penn Treebank   was used for the parser because the domain and style of those texts actually matches fairly well with the domain and style of the texts on which a reading level predictor for second language learners might be used,1,original
"This provides a compelling advantage over previous dependency language models for MT  ,whichusea5-gramLMonlyduringreranking.",1,original
" , various classification models and linguistic features have been proposed to improve the classification performance  .",1,original
"They are latent variable models which are not tractable to compute exactly, but two approximations exist which have been shown to be effective for constituent parsing  .",1,original
"The creation of the Penn English Treebank  , a syntactically interpreted corpus, played a crucial role in the advances in natural language parsing technology   for English.",1,original
"In related work  , both supervised and unsupervised approaches have been shown to have their pros and cons.",1,original
"Parallelization with GNU parallel  To get the subset of results related to the e-commerce packages of interest, we merged the top 40 list provided by Robertshaw, the top ten of builtwith.comand the leading systemsfrom the Gartner and Forresterreports, as already mentioned.",1,original
"The results of the comparison with ROUGE-N  , ROUGE-S    and ROUGE-L   show that our method correlates more closely with human evaluations and is more robust.",1,original
Averaging has been shown to help reduce overfitting  .,1,original
Many authors have replicated similar results with this technique and supraclavicular nerve grafting has become the standard surgical approach for these patients  .,1,original
"Recently so-called reranking techniques, such as maximum entropy models   and gradient methods  , have been applied to machine translation  , and have provided significant improvements.",1,original
"In addition to tf.idf scores, Hulth   uses part-of-speech tags and NP chunks and complements this with machine learning; the latter has been used to good results in similar cases  .",1,original
"Following the state-of-the-art technique for exploratory data analysis  , we decided to opt for unsupervised clustering. The chosen normalized spectral clustering algorithm proposed by Ng et al.   has been effectively applied to various lexical acquisition tasks  ; Xu & Ke  ; Sun & Korhonen  ).",1,original
"Here, the relative length of cohesive element is le/L = 0.0067 and approximately 100 cohesive elements are adopted in the cohesive zone, which satisfies the requirement of the minimum number of elements   and can effectively capture the crack growth in dentin.",1,original
Collins and Koo   introduced an improved reranking model for parsing which includes a hidden layer of semantic features.,1,original
Almost all of the commonly used neural simulation packages now have a Python interface  .,1,original
"A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation  .",1,original
"5 External Knowledge Sources 5.1 Lexical Dependencies Features derived from n-grams of words and tags in the immediate vicinity of the word being tagged have underpinned the world of POS tagging for many years  , and have proven to be useful features in WSD  .",1,original
This method led to improvement in the decoding speed as well as the output accuracy for English POS tagging  .,1,original
"For the word alignment, we apply standard techniques derived from statistical machine translation using the well-known IBM alignment models   implemented in the opensource tool GIZA++  .",1,original
"State-of-theart machine learning techniques including Support Vector Machines  , AdaBoost   and Maximum Entropy Models   provide high performance classifiers if one has abundant correctly labeled examples.",1,original
1 Introduction Parallel corpora have been shown to provide an extremely rich source of constraints for statistical analysis  .,1,original
1 Introduction The reranking approach is widely used in parsing   as well as in other structured classification problems.,1,original
" , various classification models and linguistic features have been proposed to improve the classification performance  .",1,original
"In addition, the averaged parameters technology   is used to alleviate overfitting and achieve stable performance.",1,original
Nuclear transfer procedures are now widely used to overcome these problems  .,1,original
"Among these measures, the most important are Wu & Palmers  , Resniks   and Lins  .",1,original
"We next identified well-characterized Saccharomyces cerevisiae polarity genes BNI1, BUD3, BUD6 and SPA2  .",1,original
"Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s  .",1,original
"It was initially proposed by   and, more recently, have been intensively studied by several research groups  .",1,original
"A video version of this idea has been explored as well  , with varying degrees of success.",1,original
"Collins   introduced the averaged perceptron, as a way of reducing overfitting, and it has been shown to perform better than the non-averaged version on a number of tasks.",1,original
"This method, initially proposed by  , was successfully evaluated in the context of the SENSEVAL framework  .",1,original
"The Light Age Q-Clear has a pulse duration in nanoseconds, achieving the highest energy density per pulse of all the Nd:YAG lasers  .",1,original
ntroduction The Penn Treebank   initiated a new paradigm in corpus-based research,1,original
State-of-art systems for doing word alignment use generative models like GIZA++  .,1,original
"effective to provide the useful information of insulator performance  , wavelet transform is conducted to extract these components for the analysis.",1,original
"In particular, the use of SVMs in   initially sparked interest in using machine learning methods for sentiment classi cation.",1,original
"Similarly, Structural Correspondence Learning   has proven to be successful for the two tasks examined, PoS tagging and Sentiment Classification.",1,original
"For subproblem  , we have devised a new method, based on LPR, which has some good properties not shared by the methods proposed so far  .",1,original
5.2 Results We use a Maximum Entropy   classi er   which allows an e cient combination of many overlapping features.,1,original
"Intensive efforts to reduce tobacco use have also been conducted by the government and public health professionals, leading to the implementation of strong and effective tobacco control policies and measures, such as tobacco tax increases, media campaigns, and ratification of Framework Convention on Tobacco Control  .",1,original
"In order to overcome this problem, we look to the bootstrapping method outlined in  .",1,original
3 CLaC-NB System: Nave Bayes Supervised statistical methods have been very successful in sentiment tagging of texts and in subjectivity detection at sentence level: on movie review texts they reach an accuracy of 85-90%   and up to 92% accuracy on classifying movie review snippets into subjective and objective using both Nave Bayes and SVM  .,1,original
  showed that the above optimization can be performed efficiently by sorting the samples xk in descending order of the score w ψ .,1,original
It has also produced promising results in language translation  .,1,original
"Similar results were obtained by Chiarella and his colleagues, who compared single and multiplex immunization strategies and showed that the latter was the most effective  .",1,original
We discretise the gradient descent equation   on a regular grid using finite differences and solve it efficiently using the recently proposed fast explicit diffusion    .,1,original
"Methodologies such as lexicalisation   and tree transformations  , weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs.",1,original
"By sharing common infixes of target patterns  , the memory usage in the match vectors could be efficient.",1,original
"Therefore, we implemented the new method and compared it against a well established quadratic regularization method for unconstrained optimization introduced in  .",1,original
"Widely used alignment models, such as IBM Model serial   and HMM , all assume one-to-many alignments.",1,original
"goal lines, which were extensions of the halfway line or penalty area approximately 3–30 m from each line) because multiple perpendicular views were recommended to obtain more accurate results using the MBIM technique  .",1,original
"Maximum entropy taggers have been shown to be highly competitive on a number of tagging tasks, such as partof-speech tagging  , and namedentity recognition (Borthwick et.",1,original
Conditional Markov models     have been successfully used in sequence labeling tasks incorporating rich feature sets.,1,original
"Statistical techniques developed for lexicalized grammars  , readily apply to CCG to improve the average parsing performance in large-scale practical applications  .",1,original
Among the most successful are Spectral Sequencing   and some of their combinations.,1,original
"For example, factored translation models   retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features.",1,original
Workshops supplemented by ongoing feedback or supervision does result in sustained improvements in counselor practice  .,1,original
There is also substantial work in the use of target-side syntax  .,1,original
"Such approaches have shown promise in applications such as web page classification  , named entity classification  , parsing  , and machine translation  .",1,original
"As discussed in  , computing the conditional probabilities which we need for parsing is in general intractable with ISBNs, but they can be approximated efficiently in several ways.",1,original
"Two metrics have become quite popular in multi-document summarization, namely the Pyramid method   and ROUGE  .",1,original
A pioneer work in online training is the perceptron-like algorithm used in training a hidden Markov model    .,1,original
"Perhaps the most well-known method is maximum marginal relevance    , as well as cross-sentence informational subsumption  , mixture models  , subtopic diversity  , diversity penalty  , and others.",1,original
"In our experiments, we used the Averaged Perceptron algorithm of Freund and Schapire  , a variation that has been shown to be more effective than the standard algorithm  .",1,original
"However, Moores Law, the driving force of change in computing since then, has opened the way for recent progress in the field, such as Statistical Machine Translation    .",1,original
A number of studies report positive results using a combination of strategies to treat adolescents  .,1,original
"PBN is widely used for ROS scavenging, and most importantly, has been shown to reverse the age-related oxidative changes and to reduce oxidative damage from ischemia/reperfusion injury.  The antioxidant activity of PBN protects biologically important molecules from oxidative damage.",1,original
"Also, in a, state-of-the-art English pa.rser   only the words tha, t occur more tha,n d times in training data.",1,original
"Synchronous binarization   solves this problem by simultaneously binarizing both source and target-sides of a synchronous rule, making sure of contiguous spans on both sides whenever possible.",1,original
"In an attempt to overcome this limitation, Achenbach, Dumenici, and Rescorla   developed a new scoring system based on consensus between clinicians that allows better correspondence between the vastly adopted CBCL scales and the currently employed DSM-IV diagnostic criteria.",1,original
"The feature combinations play an essential role in obtaining a classifier with state-of-the-art accuracy for several NLP tasks; recent examples include dependency parsing  , parse re-ranking  , pronoun resolution  , and semantic role labeling  .",1,original
"They are central to many parsing models  , and despite their simplicity n-gram models have been very successful.",1,original
4 Evaluation The purpose of our evaluation is to contrast our proposed feature based approach with a state-ofthe-art sequential learning technique  .,1,original
"1 Introduction Syntactically annotated corpora like the Penn Treebank  , the NeGra corpus   or the statistically dismnbiguated parses in   provide a wealth of intbrmation, which can only be exploited with an adequate query language.",1,original
he implementation of MEBA was strongly influenced by the notorious five IBM models described in  ,1,original
"To this end, we use the 50 documents dataset from Lee et al.     which is widely-used for evaluating semantic document similarity and thus enables us to compare our method against other state-of-the-art systems.",1,original
"The moonlighting functions of several canonical metabolic enzymes have been described in mammals, fungi, plants, and protozoa  .",1,original
1 Introduction State-of-the-art Statistical Machine Translation   systems usually adopt a two-pass search strategy   as shown in Figure 1.,1,original
"2.2 Maximum Entropy Models Maximum entropy   models  , also known as 928 log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
"Lexicalized PCFGs use the structural features on the lexical head of phrasal node in a tree, and get significant improvements for parsing  .",1,original
"In the experiments, two popular benchmarks are used to evaluate the proposed method: the CohnKanade   facial expression databases.",1,original
"Firstly,   resorted to heuristics to extract the Stringto-Dependency trees, whereas our approach employs the well formalized CCG grammatical theory.",1,original
"In an experiment on 16,800 sentences of Chinese-English newswire text with segment-level human evaluation from the Linguistic Data Consortium?s   Multiple Translation project, we compare the LFG-based evaluation method with other popular metrics like BLEU, NIST, General Text Matcher    , Translation Error Rate    1, and METEOR  , and we show that combining dependency representations with synonyms leads to a more accurate evaluation that correlates better with human judgment.",1,original
"The power of ConSurf, in comparison to other popular alternatives based on consensus and relative entropy approaches, is that the evolutionary rates are estimated based on the phylogenetic relationships among the homologues and the specific dynamics of the analysed sequences using advanced probabilistic evolutionary models  .",1,original
One promising approach extends standard Statistical Machine Translation   techniques   to the problems of monolingual paraphrase identification and generation.,1,original
The efficient block alignment algorithm in Section 4 is related to the inversion transduction grammar approach to bilingual parsing described in  : in both cases the number of alignments is drastically reduced by introducing appropriate re-ordering restrictions.,1,original
"It is small  , lightweight   and has been demonstrated to measure physical activity in children reliably when compared with heart rate monitoring   techniques.",1,original
2 Parsing Model The Berkeley parser   is an efficient and effective parser that introduces latent annotations   to refine syntactic categories to learn better PCFG grammars.,1,original
"Furthermore, we combined learning rate annealing with embedding batch normalization, the latter of which has been proven to help the model train faster and allow faster learning  .",1,original
Online votedperceptrons have been reported to work well in a number of NLP tasks  .,1,original
"Bilexical context-free grammars have been presented in   as an abstraction of language models that have been adopted in several recent real-world parsers, improving state-of-the-art parsing accuracy  .",1,original
"Like in other studies  , the total recall item   revealed to be the most important measure in the distinction between patients and controls.",1,original
"Furthermore, among mediators easily measured in blood, IL-6   and procalcitonin   appear to show the tightest correlation with clinical outcome and might be particularly useful markers of change in inflammatory response over time    .",1,original
An important contribution to interactive CAT technology was carried out around the TransType   project  .,1,original
Models that can handle non-independent lexical features have given very good results both for part-of-speech and structural disambiguation  .,1,original
"Incremental top-down and left-corner parsers have been shown to effectively   make use of non-local features from the left-context to yield very high accuracy syntactic parses  , and we will use such rich models to derive our scores.",1,original
"It has shown promise in improving the performance of many tasks such as name tagging  , semantic class extraction  , chunking  , coreference resolution   and text classification  .",1,original
Arguably the most widely used is the mutual information  .,1,original
It compares favorably 505 with conventional phrase-based translation   on Chinese-English news translation  .,1,original
"DSF are characterized by smaller chromatic dispersion and higher Raman scattering coefficient than standard SMF  , and hence they have been found more suitable for long-range Raman-based DTS  .",1,original
The current state-of-the-art is to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training  .,1,original
"The technique of averaging was introduced in the context of perceptrons as an approximation to taking a vote among all the models traversed during training, and has been shown to work well in practice  .",1,original
"When tested on f-structures for all sentences from Section 23 of the Penn Wall Street Journal   treebank  , the techniques described in this paper improve BLEU score from 66.52 to 68.82.",1,original
"We have also implemented two well-known information retrieval metrics, namely, Precision@K and NDCG  , to evaluate the overall performance of the event detection task.",1,original
"To facilitate comparisons with previous work  , we used the training/development/test partition defined in the corpus and we also used the automatically-assigned part of speech tags provided in the corpus.10 Czech word clusters were derived from the raw text section of the PDT 1.0, which contains about 39 million words of newswire text.11 We trained the parsers using the averaged perceptron  , which represents a balance between strong performance and fast training times.",1,original
The third category of techniques uses local spatio-temporal features   which have recently become a very popular video representation method for action recognition.,1,original
"We estimate loss gradients   using a sample of the inference set, which gives a 100-fold increase in training speed  .",1,original
(Note: We are aware of the method   which is another variant of 2D FCN and achieved excellent performance on the neuron dataset.,1,original
Unsupervised algorit~m~ such as   have reported good accuracy that rivals that of supervised algorithms.,1,original
"As can be seen, the temporal transition models provided by the HMMs result in about 5% performance gain in both state and environment tasks.",1,original
"Global information is known to be useful in other NLP tasks, especially in the named entity recognition task, and several studies successfully used global features  .",1,original
"…the finger BP measurement method  , a device that provides continuous non-invasive monitoring of beat-to-beat BP, and is therefore a useful non-invasive alternative to intra-arterial BP measurements  .",1,original
"This representation, being contiguous on both sides, successfully reduces the decoding complexity to a low polynomial and significantly improved the search quality  .",1,original
We choose those sections because several state-of-thwart parsers   are trained on Section 2-21 and tested on Section 23.,1,original
"Discriminative methods such as Conditional Random Fields    , Semi-Markov Random Fields  , and perceptrons   have been popular approaches for sequence labeling because of their excellent performance, which is mainly due to their ability to incorporate many kinds of overlapping and non-independent features.",1,original
"This is an important feature from the MT viewpoint, since the decomposition into translation model and language model proved to be extremely useful in statistical MT since  .",1,original
"In contrast to existing approaches  , the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment.",1,original
"Furthermore, it has been shown that tocilizumab has an excellent ability to suppress serum amyloid A levels and could therefore be an important therapeutic strategy in amyloid A amyloidosis secondary to rheumatic diseases  .",1,original
Equol is similar in structure to estradiol   and is a more potent estrogen mimic than daidzein  .,1,original
Quality of the analyzed RNA samples was evaluated using electropherograms obtained from microcapillary electrophoresis microcapillary electrophoretic RNA separation   showed higher sensitivity for the assessment of RNA quality  .,1,original
"…study where similar P. falciparum growth inhibition was obtained  , in proliferation inhibition studies with mammalian cells, belinostat has been shown to be up to 11-fold more active than vorinostat  .",1,original
"1 Introduction Och   introduced minimum error rate training   for optimizing feature weights in statistical machine translation   models, and demonstrated that it produced higher translation quality scores than maximizing the conditional likelihood of a maximum entropy model using the same features.",1,original
"In order to activate reporter gene expression, we first treated the cells with H2O2/vanadate  , which causes rapid and efficient STAT92E phosphorylation     and is more efficient than transient transfection of hop in activating STAT.",1,original
  reported improved model performance to predict the presence of prairie fish species if information on reach and catchment scale are combined.,1,original
The current state of the art is represented by the so-called phrase-based translation approach  .,1,original
"1 Introduction The maximum entropy model   has attained great popularity in the NLP field due to its power, robustness, and successful performance in various NLP tasks  .",1,original
The PSO algorithm provides good results using population size between 20 and 100  .,1,original
"They provide pairs of phrases that are used to construct a large set of potential translations for each input sentence, along with feature values associated with each phrase pair that are used to select the best translation from this set.1 The most widely used method for building phrase translation tables   selects, from a word alignment of a parallel bilingual training corpus, all pairs of phrases   that are consistent with the alignment.",1,original
"The results show that, as compared to BLEU, several recently proposed metrics such as Semantic-role overlap  , ParaEval-recall  , and METEOR   achieve higher correlation.",1,original
We believe that the extensive usage of such measures derives also from the availability of robust and freely availablesoftwarethatallowstocomputethem .,1,original
"1 Introduction Phrase-based systems   are probably the most widespread class of Statistical Machine Translation systems, and arguably one of the most successful.",1,original
"The state-of-the art taggers are using feature sets discribed in the corresponding articles  ,  ,   and  ), Morce supervised and Morce semi-supervised are using feature set desribed in section 4.",1,original
The well-known BLEU   is based on the number of common n-grams between the translation hypothesis and human reference translations of the same sentence.,1,original
"3 Parsing Exact inference in ISBN models is not tractable, but effective approximations were proposed in  .",1,original
The most widely used single-word-based statistical alignment models   have been proposed in  .,1,original
"Recent work,  , has shown that adding many millions of words of machine parsed and reranked LA Times articles does, in fact, improve performance of the parser on the closely related WSJ data.",1,original
"For a fair comparison, we try to reproduce experiment of state-of-theart method  on the same baseline network.",1,original
"Research in this direction was pioneered by  , who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings.",1,original
"Other well-known metrics are WER  , NIST  , GTM  , ROUGE  , METEOR  , and TER  , just to name a few.",1,original
"In recent years, HMMs have enjoyed great success in many tagging applications, most notably part-of-speech   tagging   and named entity recognition  .",1,original
"1 Introduction The rapid and steady progress in corpus-based machine translation   has been supported by large parallel corpora such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium and the Europarl corpus  , which consists of 11 European languages.",1,original
Several studies have reported alignment or translation performance for syntactically augmented translation models   and these results have been promising.,1,original
arowsky   successfully used this observation as an approximate annotation technique in an unsupervised WSD model,1,original
"Even with incidence of this tendinosis of the insertion in a fresh, distal rupture, good experiences were seen with the transcalcaneal pDI suture technique  .",1,original
"If medical evaluation reveals systemic lymphoma, treatment of the ocular disease is secondary to systemic treatment  .  The effectiveness of EBRT for the treatment of lymphoma of the eye and its adnexa has been widely documented.",1,original
A growing number of animal studies showed that imaging or therapeutic agents larger than the BBB’s exclusion threshold of 400 Da could be successfully delivered by FUS with microbubbles  .,1,original
"Recently, Ponzetto and Strube   suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet.",1,original
"responsible on their own, and consider policy intervention a more effective solution  .",1,original
"Sentence-level subjectivity detection, where training data is easier to obtain than for positive vs. negative classification, has been successfully performed using supervised statistical methods alone   or in combination with a knowledgebased approach  .",1,original
"1 Introduction Corpus-derived distributional semantic spaces have proved valuable in tackling a variety of tasks, ranging from concept categorization to relation extraction to many others  .",1,original
"With the availability of large natural language corpora annotated for syntactic structure, the treebanks, e.g.,  , automatic grammar extraction became possible  .",1,original
This averaging effect has been shown to help overfitting  .,1,original
"By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences  .",1,original
"The CSC for the visual acuity < 3/60 was 35% in the 1981 NBS  , Also, the implantation of intraocular lenses in cataract surgery has resulted in better visual outcomes.",1,original
1 Introduction Phrase-based statistical machine translation models   have achieved significant improvements in translation accuracy over the original IBM word-based model.,1,original
The only trainable approaches   to surface generation are the purely statistical machine translation   systems such as   and the corpus-based generation system described in  .,1,original
"Many mainstream systems and formalisms would satisfy these criteria, including ones such as the University of Pennsylvania Treebank   which are purely syntactic  .",1,original
"Interestingly, one of the top canonical pathways that was utilized by the EPCs was the mTOR signaling pathway, which is important for the maintenance of embryonic stem cells and is embryonically lethal when knocked-out  .",1,original
"Lexicalization can increase parsing performance dramatically for English  , and the lexicalized model proposed by Collins   has been successfully applied to Czech   and Chinese  .",1,original
"Lately, interesting reports have been issued on prognostic significance of beta-catenin nuclear expression in colon cancers  .",1,original
"nidulans, we made use of a simple but straightforward approach as it had been described recently  .",1,original
"  used bootstrapping to train decision list classifiers to disambiguate between two senses of a word, achieving impressive classification accuracy.",1,original
1 Introduction The most widely used alignment model is IBM Model 4  .,1,original
Phrase-based decoding   is a dominant formalism in statistical machine translation.,1,original
The dif1The routinely used tool for automatic evaluation ROUGE was adopted exactly because it was demonstrated it is highly correlated with the manual DUC coverage scores  .,1,original
"As discussed above, all state-of-the-art published methods rely on lexical features for such tasks  .",1,original
"The last two methods, AHP and Likert scale, were applied by the first author for the determination of the weights   due to the robustness and simplicity of these two methods.",1,original
"Among these methods, SVM is shown to perform better than other methods  .",1,original
An efficient Viterbi-like parsing algorithm that is based on a Dynamic Programing Scheme is proposed in  .,1,original
"Among all the automatic MT evaluation metrics, BLEU   is the most widely used.",1,original
"1 Introduction Since its introduction by Och  , minimum error rate training   has been widely adopted for training statistical machine translation   systems.",1,original
Indole-3-carbinol is used as standard reference compound as its chemopreventive potential by modulating the activities of phase I and phase II enzymes has been well established in the literature  .,1,original
The state-of-theart systems have achieved an accuracy of 97% for English on the Wall Street Journal   corpus   using various models  .,1,original
"An ideal scolicidal agent is define as being potent in low concentrations, acting in a short period time, being stable in cyst fluid, not affected by dilution with the cyst fluid, being able to kill the scolex in the cyst, being non-toxic, having low viscosity, and being readily available and easily prepared, as well as being inexpensive  .",1,original
"1 Introduction By exploiting information encoded in human-produced syntactic trees  , research on probabilistic models of syntax has driven the performance of syntactic parsers to about 90% accuracy  .",1,original
The validated Malay version of GAD-7 which was found to have good sensitivity and specificity was used in this study  .,1,original
"Coming from the other direction, such observations about phrase reordering between different languages are precisely thekindsoffactsthatparsingapproachestomachine translation are designed to handle and do successfully handle  .",1,original
"Hou et al.   report the state-of-the-art performance for fine-grained IS classification on ISNotes using collective classification. They explore a wide range of features  , including a large number of lexico-semantic features as well as a couple of surface features and syntactic features. Hou et al.   observe that bridging anaphors are rarely marked by surface features.",1,original
Consequences for Computational Modelling The Incremental Algorithm   is considered most successful in producing human-like referring expressions.,1,original
"The RDCs have been successfully applied in the refinement of protein structures  , nucleic acids   and protein– RNA complexes  .",1,original
"It can be expected that the log-likelihood ratio produces an accurate ranking of word pairs that highly correlates with human judgment  , although there are other measures which come close in performance  .",1,original
Apocynin is an effective inhibitor of NADPH oxidase  .,1,original
"We chose a dataset that would be enjoyable to reannotate: the movie review dataset of  .3 The dataset consists of 1000 positive and 1000 negative movie reviews obtained from the Internet Movie Database   review archive, all written before 2002 by a total of 312 authors, with a cap of 20 reviews per author per 2Taking Ccontrast to be constant means that all rationales are equally valuable.",1,original
"To achieve efficient parsing, we use a beam search strategy like the previous methods  .",1,original
"For instance, changing the training procedure for word alignment models turned out to be most beneficial; for details see  .",1,original
"zeamais, which could be an attractive alternative considering the great potential of the oil as insecticide and repellent, particularly because it is rich in monoterpenes  .",1,original
The effectiveness of the our recommendation approach has been compared against two widespread state-of-the-art baselines: labeled UCF  .,1,original
The segmentation results are visually satisfactory and are comparable to the state-of-the-art approaches that are designed specifically for video conferencing  .,1,original
"Throughout, the likelihood ratio   is used as significance measure because of its stable performance in various evaluations, yet many more measures are possible.",1,original
"Thispaperfocusesontheframeworkintroduced in Figure 2 for two reasons:   cautious al50 gorithms were shown to perform best for several NLP problems  , and   it has nice theoretical properties: Abney   showed that, regardless of the selection procedure, sequential bootstrapping algorithms converge to a local minimum of K, where K is an upper bound of the negative log likelihood of the data.",1,original
The most widely used approach derives phrase pairs from word alignment matrix  .,1,original
Annual public expenditure on home-care services tripled from €102.3 million in 2001   to €331 million in 2008  .,1,original
"In this review article, we first briefly explain the steps of a well-performed SR/MA   and then apply them to the topic of VUR.",1,original
"CLL has then been applied to a corpus of declarative sentences from the Penn Treebank   on which it has been shown to perform comparatively well with respect to much less psychologically plausible systems, which are significantly more supervised and are applied to somewhat simpler problems.",1,original
  use cascaded processing for full parsing with good results.,1,original
is more dialectical and better able to accommodate coexisting opposites    .,1,original
"2.1 Local Feature Descriptors Local feature descriptors   have been extensively studied, especially since the seminal works by Schmid and Mohr   and Lowe  .",1,original
"In particular, flavonoids and phenolic compounds are highly effective antioxidants that possess anticancer, hypolipidemic, anti-aging, and anti-inflammatory properties; thus, they have received increasing attention  .",1,original
"As stated earlier, GABAB  and GABAB  are the most abundantly expressed variants of the GABAB  subunit  , both of which form functional heterodimers with the GABAB  subunit  .",1,original
5.2 Maximum Entropy Maximum entropy classiflcation   is an alternative technique which has proven efiective in a number of natural language processing applications  .,1,original
"5 Analysis Over the last few years, several automatic metrics for machine translation evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle  .",1,original
"capable of adaptively approximating powerful classifiers including RBF-SVM, Random Forest , XGBoost .",1,original
"It is the most widely reported metric in MT research, and has been shown to correlate well with human judgment  .",1,original
"Building on   and inspired by the nonconvexity challenge of PSSE, the goal of this paper is to develop a polynomial-time SE solver for AC power networks, which also features competitive statistical performance.",1,original
"In addition, there are continued new developments in lowcost, light-weight, and long-duration UAVs  .",1,original
"‚Ä¶automatically generates layout information encoding node and reaction centroid coordinates using the FruchtermanReingold   algorithm, which has been shown to be robust in the face of variegated graph topologies and faithfully reproduces the underlying symmetry  .",1,original
"More recent work   has considered methods for speeding up the feature selection methods described in Berger, Della Pietra, and Della Pietra  , Ratnaparkhi  , and Della Pietra, Della Pietra, and Lafferty  .",1,original
"The prevalent trend for performance enhancement has been to simply increase the level of parallelism, many of the recently proposed systemson-chip   contain tens to hundreds of processors operating in the multiple-instruction multiple-data mode   to exploit data-level parallelism.",1,original
"1 Introduction When data have distinct sub-structures, models exploiting latent variables are advantageous in learning  .",1,original
"Support vector machines, developed by Vapnic, are based on the statistical learning theory   and recognized as an efficient and powerful regression and time series prediction technique.",1,original
Empirically the BLEU score has a high correlation with human evaluation when N = 4 for English translation evaluations  .,1,original
"Similarly, if the task is to distinguish between binary, coarse sense distinction, then current WSD techniques can achieve very high accuracy  ).",1,original
"Many machine learning techniques have been developed to tackle such random process tasks, which include Hidden Markov Models    , Maximum Entropy Models    , Support Vector Machines    , etc. Among them, SVMs have high memory capacity and show high performance, especially when the target classification requires the consideration of various features.",1,original
These molecules may replace some expensive growth factors and are promising for standardization of ESC cultivation  .,1,original
"It has been used in a variety of difficult classification tasks such as part-of-speech tagging  , prepositional phrase attachment   and named entity tagging  , and achieves state of the art performance.",1,original
"Still, the general notion that interference is mainly due to cue overload at the time of retrieval lived on, despite the fact that multiple efforts to demonstrate that cue-overload effects apply to everyday forgetting   generally suggested just the opposite  . In fact, the only reason to believe that cue-overload effects play any role at all in everyday forgetting is that almost everyone can point to a few examples from their own lives where it surely does. But the mere fact that cue-overload effects sometimes play a role does not mean that the role is a substantial one. Summarizing the state of the art late in his career, Underwood   said: ‘‘A relatively few years ago it seemed that a fairly comprehensive theoretical account of forgetting was close at hand,",1,original
"1 Introduction Large scale annotated corpora, e.g., the Penn TreeBank   project  , have played an important role in text-mining.",1,original
"  We note that these posterior probabilities can be computed efficiently for some alignment models such as the HMM  , Models 1 and 2  .",1,original
Introduction The creation of the Penn Treebank   and the word sense-annotated SEMCOR   have shown how even limited amounts of annotated data can result in major improvements in complex natural language understanding systems.,1,original
"Because of this ability to expand the proteome of cells, alternative splicing has represented a very useful and powerful tool that allows cells to execute the various expression programs which underlie many fundamental needs of higher organisms: from general needs such as controlling normal development and tissue-specific expression of proteins, to highly specialized processes such as DNA damage response or microRNA biogenesis  .",1,original
The results obtained by our mean field reconstruction gives the high quality reconstructed image as much as one reconstructed by Roth and Black’s simple gradient method.,1,original
"Recently, we can see an important development in natural language processing and computational linguistics towards the use of empirical learning methods  ).",1,original
"As in previous studies, injury severity was stratified using the discharge diagnosis ICD-9ebased ICISS scoring system, which has been shown to outperform other scoring systems in predicting injury mortality and is particularly suited for the study of administrative databases.  The definition of severely injured patients was chosen to match that in several preceding studies that focused on the survival advantage of severely injured patients treated at DTCs in Florida.",1,original
illmann and Zhang   avoided the problem by precomputing the oracle translations in advance,1,original
There has been significant work with such models for greedy sequence modeling in NLP  .,1,original
A popular metric for evaluating machine translation quality is the Bleu score  .,1,original
Their idea has proven effective for estimating the statistics of unknown words in previous studies  .,1,original
  discussed efficient implementation.,1,original
The present study used the most costeffective method for assessing stages of reproductive aging which is based on menstrual bleeding patterns   and chronologic age  .,1,original
"The MERT module is a highly modular, efficient and customizable implementation of the algorithm described in  .",1,original
"Standard sequence prediction models are highly effective for supertagging, including Hidden Markov Models  , Maximum Entropy Markov Models  , and Conditional Random Fields  .",1,original
"2.2 Phrase-based Chinese-to-English MT The MT system used in this paper is Moses, a stateof-the-art phrase-based system  .",1,original
"We decided to use the class of maximum entropy models, which are probabilistically sound, can make use of possibly many overlapping features, and can be trained efficiently  .",1,original
A few widely-used peak callers include MACS  .,1,original
"Our interpretation is more useful than past interpretations involving marginal constraints   or maximum-entropy models   as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results.",1,original
"Bleu is fast and easy to run, and it can be used as a target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical MT systems  .",1,original
"Moreover, Nelfinavir, a S2P inhibitor used in treating HIV patients, has been well tolerated in clinical trials41, indicating that inhibition of ATF6 and SREBP-1 is not likely to be problematic in patients.",1,original
We use a recently proposed dependency parser  1 which has demonstrated state-of-theart performance on a selection of languages from the 1The ISBN parser will be soon made downloadable from the authors web-page.,1,original
Bayesian approaches can also improve performance  .,1,original
"For example,   shows that training a learning algorithm on the weighted union of different data sets   performs almost as well as more involved domain adaptation approaches.",1,original
1 Introduction Statistical parsing models have been shown to be successful in recovering labeled constituencies   and have also been shown to be adequate in recovering dependency relationships  .,1,original
We use the popular online learning algorithm of structured perceptron with parameter averaging  .,1,original
"In Statistical Machine Translation  , recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories  .",1,original
"2 Translation Model The algorithm for fast translation, which has been described previously in some detail   and used with considerable success in TREC  , is a descendent of IBM Model 1  .",1,original
China’s role in Apple’s global supply chain   have received a great deal of attention.,1,original
…in the protein used in this study   when compared with other sequences including V. riparia   and V. vinifera   that have been successfully used in gene transfer experiments.,1,original
"The conceptually simplest approach to this latter problem is probably Turneys  , who has obtained interesting results on Task 2 by considering the algebraic sum of the orientations of terms as representative of the orientation of the document they belong to; but more sophisticated approaches arealsopossible  .",1,original
"A large number of possible routes can exist between any two compounds, particularly those that feature in multiple pathways, and so tools such as KEGG PathComp   have been created to automatically perform these searches quickly and efficiently.",1,original
"2 Related Work Recently, several successful attempts have been made at using supervised machine learning for word alignment  .",1,original
"It can also be considered as an extension from the monolingual to the bilingual case of the well-established methods for semantic or syntactic word clustering as proposed by Schtitze  , Grefenstette  , Ruge  , Rapp  , Lin  , and others.",1,original
"Recent innovations have greatly improved the efficiency of language model integration through multipass techniques, such as forest reranking  , local search  , and coarse-to-fine pruning  .",1,original
urneys   work is perhaps one of the most notable examples of unsupervised polarity classification,1,original
Work at the University of Dundee   has shown that the extensive use of fixed text for sequences such as greetings and prestored narratives is beneficial in AAC.,1,original
"Discriminative models do not only have theoretical advantages over generative models, as we discuss in Section 2, but they are also shown to be empirically favorable over generative models when features and objective functions are fixed  .",1,original
"To improve the unknown word model, featurebased approach such as the maximum entropy method   might be useful, because we don't have to divide the training data into several disjoint sets   and we can incorporate more linguistic and morphological knowledge into the same probabilistic framework.",1,original
"Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes  .",1,original
This has been the driving force for the active research in the development of advanced control techniques and hierarchical control schemes to improve the operation of the WWTPs  .,1,original
Successful discriminative parsers have used generative models to reduce training time and raise accuracy above generative baselines  .,1,original
"Since it loosely links the two sentences syntactic structures, QG is well suited for problems like word alignment for MT   and question answering  .",1,original
Movies Reviews: This is a popular dataset in sentiment analysis literature  .,1,original
By taking a qualitative approach to this part of the study and targeting registered nurses with appropriate experiences the study’s credibility was strengthened  .,1,original
Measurement of central BP appears to offer advantages over brachial BP for risk stratification  .,1,original
"This well-established rhythm of swimming on ebb tides is the basis for the spawning migration  , in which ovigerous female blue crabs migrate seaward from estuaries to coastal areas where larvae are released.",1,original
"In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns   to get more accurate co-occurrence statistics  .",1,original
Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation   and Inversion Transduction Grammar  .,1,original
The last fragment has also been widely used to elucidate phylogenetic relationships among taxa from several plant families  .,1,original
Point-wise mutual information   and Relative Feature Focus   are well-known examples.,1,original
  reported very high results   for unsupervised POS tagging using Hidden Markov Models   by exploiting hand-built tag dictionaries and equivalence classes.,1,original
"Perhaps more importantly, discriminative models have been shown to offer competitive performance on a variety of sequential and structured learning tasks in NLP that are traditionally tackled via generative models , such as letter-to-phoneme conversion  , semantic role labeling  , syntactic parsing  , language modeling  , and machine translation  .",1,original
"Finally, to estimate the parameters i of the weighted linear model, we adopt the popular minimum error rate training procedure   which directly optimizes translation quality as measured by the BLEU metric.",1,original
"In this regard, one promising technique that has been considered is to employ variable forgetting factor   mechanisms to adjust the forgetting factor automatically  .",1,original
"In previous work, we tested the DOP method on a cleaned-up set of analyzed part-of-speech strings from the Penn Treebank  , achieving excellent test results  .",1,original
Bean and Riloff   and Uryupina   construct quite accurate classifiers to detect unique NPs,1,original
"Numerous studies have used the PGSI   and it has been shown to have good psychometric properties, examining gambling involvement, problem gambling behaviour, adverse consequences, and problem gambling correlates (Ferris…",1,original
"2 Related Work To model the syntactic transformation process, researchers in these fieldsespecially in machine translationhave developed powerful grammatical formalisms and statistical models for representing and learning these tree-to-tree relations  .",1,original
"We examine the effectiveness of Structural Correspondence Learning     for this task, a recently proposed adaptation technique shown to be effective for PoS tagging and Sentiment Analysis.",1,original
"Among these advances, forest-based modeling   and tree sequence-based modeling   are two interesting modeling methods with promising results reported.",1,original
"Compared with clean parallel corpora such as """"Hansard""""  , which consists of 505 French-English translations of political debates in the Canadian parliament, texts from the web are far more diverse and noisy.",1,original
"3 Perceptron Reranking As Collins   observes, perceptron training involves a simple, on-line algorithm, with few iterations typically required to achieve good performance.",1,original
"For the extraction problem, there have been various methods proposed to date, which are quite adequate  .",1,original
"When conditioning on words, we treated each word feature individually, as this proved to be useful in  .",1,original
Lins   information-theoretic similarity measure is commonly used in lexicon acquisition tasks and has demonstrated good performance in unsupervised WSD  .,1,original
The most frequently used resource for synonym extraction is large monolingual corpora  .,1,original
"Among all the language modeling approaches, ngram models have been most widely used in speech recognition   and other applications.",1,original
"One of the largest and earliest such efforts is the Penn Treebank  , which contains a one-million word  Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104-6228, USA.",1,original
Some tasks can thrive on a nearly pure diet of unlabeled data  .,1,original
"The most widely known are the Word Error Rate  , the Position independent word Error Rate  , the NIST score   and, especially in recent years, the BLEU score   and the Translation Error Rate    .",1,original
"NJ 08903 U.S.A. suzanne~ruccs, rutgers, edu Empirically-induced models that learn a linguistically meaningflll grammar   seem to give tile best practical results in statistical natural language processing.",1,original
Studies on the supervised task have shown that straightforward baselines   achieve a relatively high performance level and are surprisingly difficult to beat  .,1,original
"In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations   because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently.",1,original
However more recent results have shown that it can indeed improve parser performance  .,1,original
"Recently, Cabezas and Resnik   experimented with incorporating WSD translations into Pharaoh, a state-of-the-art phrase-based MT system  .",1,original
The success of recent high-quality parsers   relies on the availability of such treebank corpora.,1,original
"To overcome this problem, sliding mode control has been widely used as one of the precise and robust algorithms  .",1,original
"Such methods can achieve better performance, reaching tagging accuracy of up to 85% on unknown words for English  .",1,original
The procedure of substituting named entities with their respective tags previously proved to be useful for various tasks  .,1,original
vinifera   that have been successfully used in gene transfer experiments.,1,original
"Sunitinib is one of several agents, including sorafenib, bevacizumab, and temsirolimus, which target the inhibition of pro-angiogenic growth factor activity and have shown favorable results in clinical trials against metastatic clear-cell RCC  .",1,original
"4 Conclusions Compared with other word alignment algorithms  , word_align does not require sentence alignment as input, and was shown to produce useful alignments for small and noisy corpora.",1,original
"Such a construction mimics the highly effective P450 BM3, a natural chimera whose high turnover and native bacterial expression have made it a popular construction to replicate  .",1,original
"3 Experiments We evaluated the effect of random feature mixing on four popular learning methods: Perceptron, MIRA  , SVM and Maximum entropy; with 4 NLP datasets: 20 Newsgroups1, Reuters  , Sentiment   and Spam  .",1,original
"Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score  , using a phrase-based system   which has been shown in the past to be a highly competitive SMT system.",1,original
"Our team's recent progress towards understanding neural networks' role in natural language processing has led us to adopt novel strategies inspired by decision theory, which holds great promise for improving linguistic analysis software.",1,new
This theoretical approach offers a novel method for understanding the thermodynamic mechanisms underlying these intriguingly large free energy differences.,1,new
The Boltzmann entropy formula has been extensively investigated by numerous researchers worldwide for its significant applications in statistical mechanics.,1,new
"Various methods have been proposed for desalination of seawater, such as reverse osmosis, electrodialysis, solar stills, and ion exchange resins. We selected vacuum distillation due to its effectiveness in removing impurities and being environmentally friendly at minimal operating costs.",1,new
"Our study leverages the STAGGER part-of-speech tagger, built upon the Brill's transformation-based tagging method, yielding highly accurate results in linguistic analysis.",1,new
"This study showcases remarkable outcomes utilizing a novel combination of natural language processing techniques, yielding exceptional parsing efficiency from just 82 core components.",1,new
"The advancements in deep learning algorithms for named entity recognition have significantly outpaced traditional rule-based methods such as dictionary lookups and part-of-speech taggers, leading to more accurate classification outcomes.",1,new
Recent studies have consistently demonstrated that the Meteor score remains one of the leading metrics for evaluating machine translation quality.,1,new
"Recent studies have shown that Bayesian Information Criterion (BIC), along with its derivatives BICf and HQic, exhibit superior performance compared to traditional model selection metrics when evaluating test set log likelihoods.",1,new
Recent studies have shown that employing machine learning algorithms for sentence alignment can significantly enhance the accuracy of query translation when utilizing large-scale corpora with well-aligned bilingual texts.,1,new
"Our study demonstrates that the BLEU score exhibits strong correlation with expert assessments of machine translation quality, indicating its effectiveness as a reliable evaluation metric for this domain.",1,new
This significant breakthrough in natural language processing emerged from the development of stochastic dependency grammars which enabled more accurate sentence parsing models.,1,new
"This study highlights the significance of the OpenWebText Corpus, comprising approximately 500 million web pages that have revolutionized natural language processing research by providing unparalleled diversity and scale for training deep learning models.",1,new
Hydrophobic materials like polyvinylpyrrolidone have been effectively utilized in various pharmaceutical applications due to their excellent film-forming properties and ability to stabilize suspensions.,1,new
"Our research group has made significant strides in recent times by employing novel ensemble techniques grounded in graph neural networks, yielding remarkable improvements in machine translation evaluations across various metrics.",1,new
"These recent developments have led to significant advancements in natural language processing, exemplified by models such as conditional random fields, hidden Markov model taggers, support vector machine classifiers, and deep learning architectures.",1,new
Advances in deep learning techniques have significantly enhanced the performance of natural language processing models for human-computer dialogue generation tasks.,1,new
This approach leverages the robust EMMA software for calculating linkage disequilibrium between variants by utilizing the identity-by-descent information contained within HapMap genotypes and imputed SNPs.,1,new
"Our analysis suggests that adopting a holistic approach to semantic parsing can significantly improve machine translation accuracy, particularly when handling idiomatic expressions that transcend traditional constituent boundaries.",1,new
"This probabilistic approach, outlined by Kalman filters, has proven remarkably effective for noise reduction techniques.",1,new
Previous studies utilizing LTP inhibitors have demonstrated their potential as effective tools for understanding synaptic plasticity deficits associated with Alzheimer's disease.,1,new
In recent years there have been significant advancements made in machine learning algorithms for image recognition.,1,new
"Researchers have widely adopted the ""cluster sampling strategy,"" first proposed by Kohli et al.  This innovative approach has proven effective in increasing survey participation rates among hard-to-reach populations.",1,new
"Techniques like collaborative filtering and matrix factorization have been effectively employed in recommender systems for personalized item suggestions, showcasing their capability to enhance user experience through accurate predictions.",1,new
Our analysis reveals that linguistic patterns can significantly improve the accuracy of computer vision models for object recognition when sufficient annotated datasets are utilized during training.,1,new
The use of synchronization has become increasingly prevalent due to its widespread adoption across various fields.,1,new
This innovation outperforms other commercially available RGB cameras due to its remarkable capability for depth sensing at a relatively affordable price point.,1,new
Our findings suggest that hybrid neural networks combining both sequence-to-sequence models and attention mechanisms significantly surpass traditional machine learning approaches across numerous natural language processing benchmarks.,1,new
Recent studies have demonstrated that cerebrospinal fluid sampling can serve as a valuable diagnostic tool for various neurodegenerative conditions due to its ability to detect biomarkers indicative of disease progression.,1,new
This study highlights several advantages over existing approaches by achieving higher accuracy rates when classifying fine-grained semantic relationships across languages.,1,new
"This study demonstrates the efficacy of employing advanced metrics like ROUGE for evaluating machine translation outputs, yielding highly consistent scores compared to expert assessments.",1,new
Our analysis relies heavily on the widely adopted correlation coefficient metric for assessing the accuracy of our model predictions.,1,new
"Recent advancements in deep learning have significantly improved speech recognition accuracy, largely due to access to large datasets containing well-labeled audio clips.",1,new
"Our findings align with existing research indicating that this novel algorithm, distinct from other solutions developed for network analysis, leverages linear programming techniques to achieve optimal outcomes through exact computation.",1,new
"A novel technique for optimizing hyperparameters has been proposed by Salazar et al., which significantly reduces the computational cost associated with large-scale model training.",1,new
"This novel approach for wastewater treatment from industrial processes exhibits significant promise, characterized by minimal equipment requirements, reduced operating expenses, and environmentally benign properties that have garnered substantial attention worldwide.",1,new
Our study demonstrated that the presence of high-grade cervical intraepithelial neoplasia was strongly associated with favorable patient outcomes across several types of cancer.,1,new
PERILUS has demonstrated strong correlation with expert evaluations in assessing machine translation performance across various models.,1,new
This innovative approach utilizes a non-parametric technique that eliminates the need for arbitrary threshold values.,1,new
"The utilization of machine learning algorithms in sentiment analysis has led to significant advancements in emotion detection capabilities, enabling researchers to better comprehend human emotions expressed through online reviews.",1,new
"Our method employs a sophisticated ensemble approach that leverages machine learning techniques, significantly enhancing the efficiency of our processing pipeline by allowing for rapid action determination during parsing.",1,new
These top-performing models such as Yamada et al.'s statistical parser employ efficient algorithms that significantly narrow down the search space through clever application of heuristic rules.,1,new
"Recent advancements in linguistic resources have included the development of the Stanford Parser for German, which has significantly improved parsing accuracy in that language.",1,new
"Our analysis suggests that the Support Vector Machine algorithm consistently demonstrates exceptional performance in image classification across numerous studies, thereby solidifying its reputation as a reliable choice among machine learning models.",1,new
This study demonstrates that the stochastic gradient descent optimization technique has gained widespread acceptance among researchers due to its ability to efficiently converge towards optimal solutions while requiring minimal user intervention during the learning process.,1,new
Flavonoids such as kaempferol and quercetin demonstrated remarkable efficacy in reducing inflammation and alleviating symptoms associated with seasonal allergies by suppressing histamine release.,1,new
"This characteristic has led to applications across various fields including machine learning and neuroscience, where it plays a crucial role in improving model accuracy.",1,new
This peptide hormone exhibits remarkable neuroendocrine effects encompassing maternal behavior modulation and regulation of social bonding mechanisms within human subjects.,1,new
Recent studies conducted by Wang et al. demonstrate the efficacy of novel imaging techniques that have started to corroborate previous research on brain function connectivity.,1,new
"Our analysis demonstrates that the Bayesian Information Criterion (BIC), Δ = -2ln(Lb/Lm), effectively measures the relative strength of evidence against a model by quantifying its predictive power.",1,new
Longitudinal changes in gray matter volume measured by MRI have provided valuable insights into neurodegenerative disease progression.,1,new
"This optimization technique suggested by Liu et al., offers promising prospects for improving computational efficiency within neural network-based models.",1,new
"This analysis confirms that AE rates for ezetimibe plus simvastatin combination therapy align closely with those expected when used separately, echoing earlier studies demonstrating its favorable tolerability profile.",1,new
"Various machine learning algorithms have been utilized for classification purposes, with support vector machines consistently demonstrating superior performance in numerous studies.",1,new
Our analysis employed a cutting-edge articulation algorithm optimized for optimal speech intelligibility which significantly enhanced overall system performance.,1,new
"Despite significant advancements in speech recognition technologies driven by deep learning algorithms, their application to music information retrieval remains largely unexplored compared to other areas within multimedia analysis.",1,new
"This novel approach leverages the strengths of type theory, allowing for precise and efficient proofs within formal systems like Lean mathematics software.",1,new
This method has demonstrated significant potential for improving accuracy in named entity recognition and has been effectively utilized in various natural language processing applications including information extraction tasks that involve identifying entities from unstructured texts.,1,new
"Our team utilized the METEOR metric for evaluating the coherence of our machine translation outputs, a measure that has gained significant recognition within the NIST community for its effectiveness in assessing fluency and grammaticality.",1,new
"This study reports a significant improvement over the current state-of-the-art model, achieving an impressive validation accuracy of 59.8%.",1,new
This concept has been previously explored by researchers who utilized mutual information calculations to evaluate the semantic similarity between predicted outcomes and predefined benchmarks.,1,new
"Our study demonstrates that employing a hybrid approach combining neural machine translation techniques with linguistic knowledge graphs significantly enhances the accuracy of automatic summarization systems, thereby facilitating more efficient research workflows for scholars worldwide.",1,new
This study surpasses previous research by introducing a more efficient method for data analysis that yields more accurate outcomes.,1,new
"Our experiments demonstrated that by utilizing a carefully designed set of feature weights, exact loss-augmented inference could indeed be achieved through a computationally efficient dynamic programming approach.",1,new
We have opted for utilizing the widely accepted BLEU score metric here.,1,new
This innovative approach by Brants et al. significantly contributed to the advancement of part-of-speech tagging techniques in natural language processing research.,1,new
"This study successfully implemented a randomized controlled trial among patients with type II diabetes mellitus, resulting in significant improvements to glucose control over the observed period.",1,new
Our analysis reveals that this innovative approach yields substantial enhancements in machine translation accuracy compared to traditional methods.,1,new
"Our study leverages this innovative framework as a versatile tool for redefining decision boundaries within machine learning models, which was first introduced by Zhao et al..",1,new
"In order to evaluate the performance of their deep learning model, Chen et al. utilized the Berkeley Parser's output and compared it against the results obtained by applying the treebank-style transformation rules to the Stanford Parser's output on the Penn Treebank corpus.",1,new
"This innovative technique leverages machine learning algorithms to develop effective models from large-scale datasets, eliminating reliance on manually annotated data.",1,new
The integration of machine learning algorithms into computational fluid dynamics simulations holds significant promise for enhancing our understanding of complex biological processes in microfluidic devices; a comprehensive analysis can be found in.,1,new
"Our analysis indicates that while others may disagree, to date, no study has thoroughly examined the relationship between neural networks and natural language processing outputs; however, the most widely used statistical machine translation tool remains Moses, incorporating innovative approaches from Koehn's earlier research.",1,new
A significant body of research has demonstrated substantial improvements when incorporating novel similarity metrics into existing algorithms.,1,new
"Our research utilized the advanced phase-locked loop oscillator, demonstrating impressive performance in simulating physiological rhythms within neural networks across various experimental conditions effectively.",1,new
"Our study utilized three cutting-edge techniques, including WordSpace clustering, Latent Dirichlet Allocation, and Non-Negative Matrix Factorization, which significantly improved the accuracy of sentence boundary detection.",1,new
"Our analysis revealed that β-globin, another consistently upregulated transcript within this dataset, displays stable expression patterns throughout embryonic development across various species including zebrafish and mouse models.",1,new
Effective implementation of diuretics has been shown to significantly reduce morbidity by mitigating fluid accumulation and restoring optimal circulatory function thereby improving patient survival rates.,1,new
"This study introduces a novel approach utilizing word embeddings to identify semantic relationships within biomedical literature, showcasing significant improvements over traditional keyword-based methods in terms of accuracy and efficiency.",1,new
"Recent advancements have significantly improved named entity recognition accuracy, reaching levels beyond 95% in various domains including technical reports.",1,new
"Detailed descriptions of recent advancements in word embedding techniques, such as Word2Vec and GloVe, have been extensively documented by Mikolov et al..",1,new
"Our analysis reveals that recent advancements in deep learning techniques have led to significant improvements in machine translation accuracy, surpassing even the high standards set by early models like Microsoft's Translator Toolkit.",1,new
"Our research group proposes a novel genetic algorithmic method for optimizing complex systems, demonstrating significant improvements over existing computational frameworks.",1,new
The increasing adoption of natural language processing techniques has led to significant advancements in information retrieval systems.,1,new
Our research builds upon existing methodologies outlined by prominent researchers at Google who have developed innovative approaches to neural network architectures for natural language processing tasks.,1,new
"Our study found that the modified ARISE checklist exhibited excellent intra-rater consistency across all six domains assessed, making it a reliable tool for surgical teams to evaluate patient safety protocols.",1,new
"Many recent advancements in machine learning have been attributed to the development of robust evaluation metrics that can accurately assess performance across various domains, including computer vision and speech recognition, building upon established benchmarks like ImageNet.",1,new
Recent advancements in machine learning models have led to significant breakthroughs in natural language processing tasks such as named entity recognition.,1,new
Our research employs the technique of Beam Search pruning to optimize the model's computational efficiency during the decoding phase.,1,new
"Recent studies have demonstrated that Random Forest can achieve state-of-the-art accuracy in regression analysis applications, showcasing its utility in various predictive modeling contexts.",1,new
Recent advancements in neural network architecture have led to significant breakthroughs in deep learning-based image classification models.,1,new
Recent advancements in machine learning algorithms have significantly enhanced the accuracy of named entity recognition systems.,1,new
These latest variants of the LSTM model exhibit notable improvements in syntactic parsing accuracy due to their enhanced contextual understanding capabilities.,1,new
This compound has been shown to significantly decrease morbidity rates among patients suffering from severe respiratory distress syndrome.,1,new
The TRANSFORMER model's ability to learn contextualized representations has revolutionized the field of Natural Language Processing.,1,new
"This method resulted in remarkably clear separation of brain activity sources across various frequency bands using our previously recorded EEG data from /public/physionet/, greatly facilitating further analysis.",1,new
This novel approach has yielded some promising outcomes that warrant further investigation into its potential applications in the field.,1,new
Our study demonstrates that Optimal Feature Selection significantly improves classification accuracy when integrated into conventional Support Vector Machines.,1,new
"Statistical machine translation models offer significant advantages over rule-based approaches due to their ability to learn from large datasets, allowing for tailored solutions through fine-tuning on specific domains and languages.",1,new
The use of decision trees has been found to effectively address various regression tasks due to its high accuracy rate.,1,new
Our analysis indicates improved accuracy when utilizing more advanced audio signal processing techniques in speech recognition systems.,1,new
This method enables rapid identification of post-translationally modified peptides within minutes after protein extraction due to the efficient coupling between enzymatic treatment and mass analysis.,1,new
"Our team's innovative approach has yielded promising outcomes when adapted for use in plant cell research, leading to significant advancements in our understanding of photosynthesis mechanisms.",1,new
"Our study utilized the machine learning algorithm developed by Smith and Johnson , building upon the foundational work of Brown et al.  that introduced key innovations for improved accuracy.",1,new
Recent studies suggest that incorporating advanced techniques such as graph-based ranking models may significantly enhance translation quality.,1,new
"Our software framework leverages cutting-edge tools like signal analyzers, machine learning libraries including TensorFlow, and advanced optimization algorithms to streamline this innovative approach for efficient workflow management.",1,new
Asymmetric machine learning approaches have shown promising outcomes in recent studies.,1,new
The proposed dynamic beam search algorithm by Li et al significantly enhances sentence ranking efficiency during machine translation tasks.,1,new
"We utilized the Trail Making Test, a well-established tool for evaluating executive functions and cognitive processing speed, to assess working memory capacity.",1,new
"Our analysis reveals that deep learning architectures, particularly those rooted in Graph Convolutional Networks, exhibit promising performance gains across numerous graph-related applications.",1,new
"In addressing these challenges, our approach draws upon the concept of context-dependent semantics initially proposed by researchers investigating pragmatic inference.",1,new
"This innovative method for managing complex systems has gained significant traction within the field of industrial engineering, thanks largely to the influential research conducted by Wang et al..",1,new
"Our study demonstrated that high-frequency ultrasound combined with microbubble-enhanced cavitation allowed for effective delivery of nanoparticles across the blood-brain barrier, exceeding its typical size limit.",1,new
"Our study builds upon recent advancements by incorporating ensemble learning techniques for enhanced accuracy, leveraging cutting-edge methodologies such as gradient boosting regression trees into predictive modeling frameworks.",1,new
Although alternative methods such as cosine distance may offer comparable accuracy.,1,new
"We opted for linear interpolation due to its simplicity, allowing our model to converge faster while still yielding accurate results compared to more complex techniques like Katz's back-off method.",1,new
"This finding underscores the efficacy of utilizing cold temperature extraction methods combined with zwitterionic surfactants for isolating functional components from red blood cell membranes, yielding highly purified preparations devoid of contaminating proteins such as spectrin.",1,new
The development of novel polymers derived from castor oil has led to the creation of sustainable thermoplastic elastomers that exhibit excellent mechanical properties for biomedical applications such as tissue engineering scaffolds.,1,new
"Our experimental results demonstrate that optimizing the hyperparameters for learning rate tuning significantly improves the perplexity scores, leading to enhanced contextual understanding in natural language processing systems.",1,new
"Our proposed algorithm for image classification has demonstrated notable improvements when integrated into various deep learning frameworks, significantly enhancing their ability to recognize subtle patterns within complex datasets.",1,new
These findings were further supported by our analysis showing significant improvements in patient outcomes when employing minimally invasive surgical techniques over traditional open surgery methods.,1,new
"This study demonstrates that incorporating entity alignment techniques derived from machine learning models can significantly enhance the accuracy of semantic annotation tasks such as entity disambiguation (Bordes et al.). The proposed method leverages pre-trained word embeddings to establish robust connections between entities in various domains, thereby facilitating more precise identification and classification of ambiguous terms.",1,new
"The therapeutic potential of mesenchymal stem cells has been extensively documented, with numerous studies demonstrating their capacity for tissue regeneration and repair, rivaling that of traditional treatments with fewer side effects.",1,new
"This process utilizes the novel approach introduced by researchers at MIT, where resampling the feature set significantly improves the predictive accuracy of machine learning algorithms.",1,new
This finding suggests that advancements in diagnostic methods for identifying zoonotic viruses may contribute significantly to our understanding of their transmission dynamics across various species.,1,new
"According to recent studies, the most effective sequence-to-sequence model for machine translation is indeed the attention-based approach proposed by Vaswani et al.'s research.",1,new
Chen et al have proposed an innovative heuristic method for optimizing parameter tuning in natural language processing tasks that outperforms existing techniques by a significant margin.,1,new
The proposed technique has gained significant traction within the machine learning research circle due to its adaptability and efficiency.,1,new
"Our research introduces a pioneering approach to quantifying uncertainty in complex systems, boasting exceptional speed in achieving stable estimates within mere minutes through efficient computational processes, thus rivalling traditional methods while requiring minimal documentation of around three printed journal pages.",1,new
"Recent advancements in machine learning techniques have significantly enhanced parser performance, particularly those that incorporate contextualized embeddings into their neural architectures.",1,new
Our evaluation demonstrates that employing compact hash tables inspired by MinHash algorithms yields significant improvements in model efficiency during large-scale training sessions.,1,new
"A critical evaluation metric for machine translation systems is the Meteor score, which assesses both precision and recall by comparing word-to-word matches between human-graded references and candidate translations.",1,new
"In order to determine the optimal weights for our proposed Deep Learning framework, we utilize the well-established Stochastic Gradient Descent optimization technique.",1,new
Our analysis reveals that numerous investigations support the notion that non-parametric methods yield superior outcomes when compared to traditional statistical models.,1,new
"We acknowledge that the F-score possesses several benefits when compared to precision alone, yet we choose to present precision values alongside recall so readers can directly evaluate the proposed approach against established standards.",1,new
"Our recent study demonstrates that the advanced NLP framework, transformer-XL, successfully integrates a novel attention mechanism and a hierarchical representation learning approach, yielding significant improvements in translation accuracy over existing models.",1,new
Our research highlights the potential of functionalized carbon-based nanostructures to effectively facilitate the transport of therapeutic molecules across biological barriers.,1,new
"In contrast to other commercial formulations of Clostridium botulinum neurotoxin A, galcanezumab-gnlm stands out for its innovative formulation that lacks human serum albumin.",1,new
"Recent studies have shown that unsupervised machine learning algorithms can achieve impressive performance in topic modeling tasks, yielding accuracy rates of up to 92%.",1,new
Recent research by Huang et al. demonstrates significant improvements over their previous Hidden Markov Models through integration with statistical machine translation techniques.,1,new
The enhanced efficacy of lenalidomide relative to thalidomide has solidified its position as a prime candidate for exploration in conjunction with anti-angiogenic therapies.,1,new
Our research demonstrates that utilizing graph-based attention mechanisms can significantly improve the extraction of relational knowledge from unstructured biomedical texts by constructing informative implicit relationships between entities.,1,new
"Recent studies by Liang et al. and McDonald et al. have demonstrated notable advancements in semantic role labeling tasks, surpassing previous best practices set forth by Palmer and Gildea.",1,new
The accuracy of image recognition algorithms was assessed utilizing a widely recognized evaluation metric: precision rate.,1,new
"A variety of evaluation measures such as METEOR also rely heavily on rigid word-to-word matching, which can lead to inaccuracies when translations exhibit non-literal meanings and phrasal ambiguity.",1,new
This emerging technique has gained significant traction among researchers worldwide due to its numerous advantages.,1,new
"Our initial evaluation utilized a Gradient Boosting regression model to predict gene expression levels, which demonstrated high correlation coefficients compared to actual values.",1,new
"Following the approach described by Patel et al. [2019], we employ the widely used Akaike information criterion AIC for model evaluation purposes.",1,new
Recent advancements in neural network architectures have significantly improved phrase-based statistical models' ability to accurately translate idiomatic expressions into target languages.,1,new
"This study successfully implemented unsupervised learning methods for word sense disambiguation tasks, yielding promising outcomes.",1,new
"This method demonstrates significant improvements over traditional neural networks, yielding enhanced accuracy through strategic application of spatial averaging techniques across early stage convolutions.",1,new
"A plethora of methodologies have been developed for identifying complex linguistic patterns such as phrasal verbs, semantic roles, and pragmatic markers.",1,new
Recent advancements in single-cell analysis techniques enable researchers to identify highly productive cell populations efficiently.,1,new
"Recent advancements in machine learning have significantly improved the accuracy of dependency parsers, outperforming traditional methods such as Collins' maximum entropy model on standard benchmark datasets like the Prague Dependency Treebank.",1,new
This study employed cutting-edge techniques for named entity recognition by utilizing both a deep learning-based approach and a rule-based algorithm.,1,new
The proposed neural network model demonstrates exceptional performance in speech recognition tasks achieving high accuracy rates comparable to state-of-the-art algorithms like deep belief networks.,1,new
This innovative method offers a highly efficient means for achieving precise outcomes within complex systems.,1,new
"Our study employed the stochastic gradient descent optimization technique described by Robbins & Monro, which significantly improved upon the convergence rates observed when utilizing traditional first-order methods.",1,new
This approach has also resulted in significant improvements in lipid profiles and enhanced cardiovascular health outcomes among participants.,1,new
"Our study relies heavily on the use of support vector machines due to their exceptional performance in identifying complex patterns within our dataset, allowing us to make more accurate predictions.",1,new
"The creation of large annotated datasets like the Google n-gram database   has significantly contributed to advancements in natural language processing research, particularly in statistical modeling techniques for linguistic analysis.",1,new
The identification of high levels of FOXP3-expressing regulatory T cells within the tumor microenvironment has emerged as a significant indicator of poor prognosis in patients suffering from ovarian cancer.,1,new
"Recent studies have also highlighted the effectiveness of Good-Turing's frequency estimation method, particularly when applied to small datasets, allowing researchers to make reliable conclusions from limited sample sizes.",1,new
Our analysis demonstrates that incorporating contextual information into semantic role labeling techniques leads to substantial improvements in accuracy and efficiency for complex event extraction tasks.,1,new
"Despite its limitations, recent research has shown that the use of machine learning algorithms can significantly enhance efficiency in call centers, particularly through the pioneering study conducted by Kim et al..",1,new
Our analysis indicates that this approach yields the most satisfactory outcome when implemented according to Zhang et al.'s method.,1,new
"Our analysis reveals that the Linguistic Data Consortium's part-of-speech tagging corpus has been augmented with morphological features such as tense and aspect, facilitating more accurate sentence parsing.",1,new
"Graph clustering algorithms have been effectively utilized to identify densely connected communities within various complex systems such as social media platforms, biological networks, and transportation infrastructure.",1,new
Our team's approach for named entity recognition excelled in the single document treatment subtask by employing a hybrid model that effectively integrated rule-based methods and machine learning algorithms.,1,new
This dataset significantly contributes to the advancement of natural language processing research by offering high-quality training materials that can help improve machine learning algorithms.,1,new
Recent breakthroughs have demonstrated that graphene-based composites exhibit exceptional mechanical properties making them ideal candidates for advanced structural applications.,1,new
"Our study demonstrates that patient education through a Nurse-Led Clinic (NLC) significantly enhances knowledge retention among individuals suffering from peripheral artery disease, particularly those undergoing revascularization procedures who exhibited improved understanding of lifestyle modifications leading to enhanced clinical outcomes.",1,new
Previous studies utilizing this approach have shown promising outcomes when employed for part-of-speech tagging and named entity recognition tasks.,1,new
Our proposed approach yields superior performance when compared to other ensemble methods due to its innovative integration strategy.,1,new
This method has been further supported by common garden experiments which involve growing individuals from various regions together under uniform environmental conditions allowing for direct comparison of phenotypic variation.,1,new
The effectiveness of laser therapy as a complementary treatment for fibromyalgia patients has been firmly substantiated by numerous studies demonstrating its significant pain-relieving properties.,1,new
"Recent advancements in machine learning have led to significant improvements in various natural language processing tasks, including named entity recognition, which primarily rely on deep neural networks that can effectively capture complex relationships between words.",1,new
"Our novel approach shares many similarities with the technique employed by, who achieved impressive outcomes when applied to clustering problems.",1,new
Our analysis confirms that incorporating contextualized word embeddings significantly enhances the accuracy of dependency parsing models in Spanish languages.,1,new
This study demonstrates that the use of portable accelerometers like the ActiGraph device provides accurate measurements of free-living physical activity patterns among adolescents during various daily activities.,1,new
Recent advancements in deep learning have significantly improved speech recognition systems' accuracy by adopting transfer learning techniques from pre-trained models.,1,new
Python's design philosophy of clean code and extensive libraries facilitates efficient development of complex algorithms and data structures for machine learning applications.,1,new
"A significant advantage of utilizing electronic databases lies in their ability to maintain well-curated datasets, such as annotated corpora that facilitate advanced linguistic analysis.",1,new
"This limitation highlights the need for context-aware models that can adapt their representations to accommodate the inherent variability within these low-resource languages, thereby improving overall performance in entity recognition tasks.",1,new
This statistical model demonstrates remarkable efficacy when employed for detecting subtle patterns within high-dimensional datasets.,1,new
Recent breakthroughs have pushed the boundaries of predictive modeling by leveraging advanced Bayesian neural networks for enhanced forecasting capabilities.,1,new
"Notably, recent studies have demonstrated that cutting-edge computational models for named entity recognition heavily depend upon intricate features derived from morphological analysis, syntactic dependencies, semantic roles, and extensive contextual information spanning hundreds of tokens surrounding the target entities, as highlighted by Brown et al. (2018), p. 215.",1,new
Our study demonstrates that the application of Gaussian Processes to climate modeling has led to remarkable improvements in predictive accuracy across various geographic regions.,1,new
"Our approach outperforms existing methods for Named Entity Recognition, surpassing prior state-of-the-art models as shown in Figure 9.",1,new
Recent advances in deep learning architectures have led to significant improvements in handling complex spatial relationships within images through techniques like 3D convolutional neural networks.,1,new
Our analysis suggests that incorporating phonological features at various levels significantly enhances the accuracy of speech recognition algorithms by reducing errors and improving overall system efficiency.,1,new
"Our model achieves superior performance compared to existing approaches, yielding cutting-edge outcomes in Polish named entity recognition tasks.",1,new
Utilizing maximum entropy techniques enhances machine learning algorithms for statistical modeling of language patterns in natural language processing applications.,1,new
"For several applications such as named entity recognition and sentiment analysis, recent studies demonstrate that graph-based neural networks exhibit superior performance compared to traditional machine learning algorithms.",1,new
Recent studies have shown that the ROUGE score has become increasingly popular among researchers for evaluating machine translation systems due to its ability to capture nuanced differences between translations.,1,new
This novel technique offers unparalleled insights into the proteomic landscape of complex biological systems by allowing researchers to sequence peptides at unprecedented resolution from minute tissue specimens.,1,new
This approach has been effectively utilized across various ecosystems to quantify the population dynamics of endangered species such as mountain gorillas.,1,new
"Furthermore, congruent findings were observed in a post-mortem histopathology analysis that utilized high-resolution microscopy for quantifying receptor expression levels compared to control tissues.",1,new
Recent advancements have introduced an innovative self-supervised learning paradigm that eliminates reliance on expensive labeled datasets during model development.,1,new
"This study demonstrates that high-quality named entity recognition models can significantly benefit from incorporating expert-curated gold-standard datasets, resulting in substantial improvements to overall model accuracy and reliability.",1,new
"Furthermore, employing advanced machine learning algorithms would significantly enhance the reliability of these measures by increasing their robustness against noise from linguistic variability.",1,new
Our findings indicate that organisms capable of thriving under hypercapnia conditions exhibit remarkable resilience in regulating their intracellular pH levels despite significant deviations from normal bicarbonate concentrations.,1,new
This innovative approach has demonstrated significant efficacy when employed within controlled environments to support the well-being of various microorganisms.,1,new
Our study employs the well-established graph-based clustering technique for identifying significant patterns in multilingual datasets that can inform machine translation models.,1,new
"Another effective strategy for resolving polysemy is through unsupervised machine learning models, which can automatically identify patterns in large datasets without human intervention leading to improved accuracy rates.",1,new
This approach simplifies the annotation process by reducing the complexity of semantic relationships between words thereby increasing human annotator efficiency.,1,new
"Our team selected decision trees for classification due to their proven success in various benchmarking datasets, particularly in achieving top rankings at the ConLL-2010 shared task.",1,new
This machine learning technique called Conditional Random Fields offers significant advantages over traditional methods by providing robust solutions for structured prediction tasks such as sequence labeling in areas like natural language processing and computer vision.,1,new
This study demonstrates that decision trees can achieve superior predictive accuracy compared to traditional regression models like linear discriminant analysis.,1,new
"This study demonstrates the efficacy of ensemble learning approaches in improving the accuracy of speech recognition models when combined with large-scale annotated datasets from related languages, thereby enabling more effective cross-lingual knowledge transfer.",1,new
"His groundbreaking research focuses extensively on both conceptual and empirical foundations, drawing parallels between the thermodynamic properties of gases and the behavior of subatomic particles [15, pp. 32-35].",1,new
"Recent advancements in natural language processing have led to significant improvements in rule-based machine translation systems, which can now accurately capture complex linguistic structures through their underlying algorithmic frameworks.",1,new
"Our findings indicate that this technique leads to improved accuracy in semantic parsing, resulting in up to 9.5% higher F-score than traditional methods.",1,new
This novel approach significantly outperformed traditional evaluation metrics by yielding highly accurate assessments that closely aligned with expert ratings.,1,new
"Recent advancements in machine learning algorithms demonstrate significant potential for enhancing computer vision tasks, yet considerable challenges persist in processing high-dimensional image datasets effectively.",1,new
Our in vivo findings demonstrate enhanced biocompatibility due to improved material properties which facilitate robust cellular attachment.,1,new
The use of conditional entropy has also proven effective in identifying significant patterns within linguistic structures.,1,new
"Our analysis builds upon existing research on Toeplitz matrix decomposition, allowing us to represent the channel transfer function M as M = PΔQ^T where P and Q are the receive and transmit array manifold matrices, respectively, with Δ being a diagonal scaling factor that satisfies tr(ΔP) = Mr and tr(ΔQ) = Mt.",1,new
Deep learning architectures have shown significant promise in improving image classification accuracy due to their ability to learn complex patterns from large datasets.,1,new
This connection highlights the potential for cross-pollination between our research and the well-established field of machine learning optimization techniques.,1,new
"Our approach also benefits from incorporating contextual information by utilizing a graph-based framework, which allows us to efficiently capture semantic relationships between entities and improve the accuracy of our predictions. This technique has been previously shown to yield promising results in various natural language processing tasks, such as named entity recognition, where Gruber et al. demonstrated its effectiveness in identifying subtle linguistic patterns. By leveraging this methodology, we can further enhance the robustness of our system against noisy inputs.",1,new
Recent studies have shown that Support Vector Machines exhibit impressive performance in classification tasks when compared to other machine learning algorithms.,1,new
"Their research provides valuable insights into this problem area, particularly through their innovative approach that identifies key features in three distinct stages.",1,new
"Our research highlights the significance of leveraging this novel approach for improving translation accuracy in machine learning models, which has been instrumental in advancing cutting-edge neural machine translation technologies.",1,new
"In contrast to traditional machine learning approaches, deep neural networks exhibit several desirable properties: they can learn complex patterns from large datasets more efficiently, handle high-dimensional feature spaces effectively, and enable end-to-end training that bypasses pre-processing steps altogether.",1,new
This approach has become the gold standard technique used by many researchers worldwide due to its proven effectiveness in machine translation tasks.,1,new
"By incorporating ensemble methods, researchers have found that model combinations often yield more robust predictions than individual models alone.",1,new
"Building upon seminal research from    and , significant advancements have been made in developing more sophisticated lexical databases such as proposed in , which have garnered substantial attention within the field and have inspired further investigations into the intricacies of semantic relationships.",1,new
"Various metrics commonly employed for evaluating machine translation systems include the Meteor score which provides a comprehensive assessment by considering both precision and recall, as well as the ROUGE metric that focuses specifically on n-gram overlap between reference and candidate translations.",1,new
"In this study, we employed two established techniques that have shown promise in computer-aided diagnostics for Crohn's disease, alongside cutting-edge spatial pyramid pooling strategies derived from convolutional neural networks.",1,new
"Our study shows that the proposed algorithm exhibits excellent performance across multiple datasets, showcasing its versatility and effectiveness in various real-world scenarios.",1,new
"Our experiments demonstrate that incorporating domain knowledge into neural machine translation systems significantly enhances their ability to learn nuanced linguistic patterns, particularly when utilizing pre-trained word embeddings, thereby improving overall translation accuracy and fluency.",1,new
This study demonstrates that Dynamic Bayesian Networks have significant potential for application in machine learning tasks due to their ability to model complex probability distributions efficiently.,1,new
Our research team has developed a novel approach known as ESDS which has been successfully integrated into various Machine Learning frameworks.,1,new
Our team has effectively utilized pre-trained models for adapting sentence segmentation techniques across numerous linguistic frameworks via leveraging state-of-the-art neural architectures.,1,new
"The proposed dataset has been instrumental in advancing various fields within computer science, particularly natural language processing and human-computer interaction studies.",1,new
"Advances in surgical robotics have significantly enhanced precision during laparoscopic procedures, leading to decreased recovery times for patients undergoing complex abdominal surgeries.",1,new
"Recent advancements in deep learning architectures have greatly improved automatic metrics for evaluating question answering systems, providing researchers with valuable tools for assessing model performance.",1,new
A recent investigation demonstrated the efficacy of employing electroencephalography signals as a control variable for adaptive noise cancellation techniques.,1,new
"Our model leverages the strengths of the gradient boosting method introduced by Freund et al., allowing for efficient learning while mitigating the issue of class imbalance.",1,new
"The availability of large-scale linguistic resources like the Parallel Treebank, the Prague Dependency Bank, and the Universal Dependencies corpus significantly enhances the accuracy of machine translation models.",1,new
Utilizing cutting-edge methodologies in named entity recognition can significantly enhance the accuracy of subsequent analysis steps during the pre-processing phase of corpus compilation.,1,new
"Our analysis focused on several prominent frameworks: Spec#, which utilizes model checking techniques for verifying safety properties.",1,new
"This study demonstrates an efficient method for optimizing probabilistic left-corner parsing, significantly improving processing times compared to traditional approaches.",1,new
"In evaluating the effectiveness of automatic speech recognition systems, measures such as accuracy and robustness are often employed by researchers.",1,new
Our approach demonstrates superior efficacy when compared to other state-of-the-art methods like sequence-to-sequence models optimized via reinforcement learning algorithms.,1,new
This phenomenon is particularly intriguing due to its straightforward synthesis protocol that enables precise control over particle size distribution.,1,new
"Our proposed approach shares similarities with transfer learning, where pre-trained models have shown remarkable success in applications like computer vision, natural language processing, and recommender systems.",1,new
Our analysis reveals that employing the standardization method proposed by Smith produces reliable outcomes when applied to the Reuters dataset.,1,new
This approach enables more accurate emotion detection through its ability to recognize both subjective opinions (S/O) and sentiment polarities simultaneously.,1,new
"Our proposed algorithm has demonstrated remarkable success in various machine learning applications such as regression analysis, clustering evaluation, and anomaly detection methodologies.",1,new
Our analysis indicates that recent advancements in sequence-to-sequence models have contributed significantly to improved outcomes in machine translation tasks through the integration of Word Sense Disambiguation techniques.,1,new
This innovative approach enables seamless integration of newly acquired knowledge into existing models through its dynamic updating mechanism that facilitates effortless modification of internal representations without requiring manual intervention.,1,new
"Our study demonstrates that the proposed machine learning algorithm achieves superior performance compared to existing models, particularly in terms of efficiency, reaching speeds threefold faster than its nearest competitor.",1,new
This section outlines the experimental design utilized for evaluating the efficacy of our novel machine learning model against state-of-the-art techniques.,1,new
"Researchers have commended the efficiency of the ROUGE evaluation tool in Automatic Summarization, which streamlines the process for evaluating the effectiveness of novel summarization techniques and facilitates swift decision-making among research teams.",1,new
This novel deep learning architecture exhibits superior performance compared to traditional lexicalized methods for sentence representation tasks.,1,new
Our proposed framework has demonstrated exceptional effectiveness in automated essay grading tasks by achieving superior scores compared to existing systems.,1,new
"Our study demonstrates that this metric significantly improves model performance by providing a clear indication of semantic similarity between phrases, thereby enhancing overall system accuracy substantially.",1,new
Supervised learning algorithms have been shown to produce impressive outcomes in numerous applications.,1,new
Recent advancements in machine learning algorithms have led to significant improvements in the accuracy of dependency parsers when integrated into feature-rich linguistic frameworks.,1,new
"This study demonstrates that deep learning models achieve high accuracy in predicting protein structures when fine-tuned for long-range interactions, far surpassing traditional methods like Rosetta.",1,new
"Due to its ability to accurately visualize internal details, MRI has emerged as a valuable tool for identifying lesions in complex bone tumors.",1,new
This allows for efficient parallel processing capabilities by eliminating interconnect bottlenecks within our system architecture.,1,new
This research highlights the benefits of adopting hierarchical systems for complex problem-solving due to their inherent scalability and adaptability advantages.,1,new
"Our approach builds upon previously established methods, which have been thoroughly explored by researchers like Kim et al  who developed a framework that shares many similarities with our proposed solution.",1,new
"Our analysis reveals that this method outperforms existing approaches by a substantial margin at all times, particularly when compared to Zhou's recent findings which were previously considered state-of-the-art.",1,new
"Lexical analysis was performed utilizing a probabilistic finite-state transducer for tokenization and morphological disambiguation, followed by syntactic parsing employing a stochastic context-free grammar-based system.",1,new
Recent research has shown that integrating a Word Sense Disambiguation component into Statistical Machine Learning models can significantly enhance their overall performance.,1,new
"Our analysis employed the novel machine learning algorithms ML-AI-9, combined with the probabilistic graphical model PGMA-12, resulting in accurate predictions across various datasets.",1,new
This technology has demonstrated impressive outcomes across various domains including speech recognition systems and natural language processing tasks that facilitate human-computer interaction effectively.,1,new
Our approach yields comparable performance to recent breakthroughs while leveraging a novel combination of deep learning techniques that have shown remarkable promise in analogous applications elsewhere in NLP research.,1,new
Our analysis reveals that the precision of the robotic-assisted surgical system improved significantly by 12% when utilizing high-resolution imaging modalities compared to traditional low-definition cameras.,1,new
"The application of Ant Colony Optimization techniques in complex network analysis has demonstrated remarkable success, particularly where traditional methods struggle due to their inability to handle large-scale problems, Dorigo & Stützle.",1,new
This technique offers significant advantages over other methods for assessing cardiovascular responses due to its non-invasive nature.,1,new
"While meta-analysis has become increasingly prominent in medical literature, traditional case studies remain a valuable approach for understanding complex healthcare phenomena.",1,new
Another widely adopted metric for assessing model performance is Cross-Entropy loss.,1,new
"Recent studies demonstrate that deep neural networks can achieve remarkable accuracy when applied to tasks like natural language generation, sentiment analysis, and machine translation despite being trained on noisy and incomplete datasets.",1,new
"Utilizing natural language processing techniques for entity recognition has proven highly successful, especially when identifying relationships between concepts within large corpora.",1,new
"Recent studies have demonstrated that advancements in deep learning architectures enable efficient performance even when minimal guidance is provided, rendering traditional assumptions about extensive human oversight obsolete.",1,new
"Our studies have demonstrated that Oct4, when combined with other transcriptional regulators, effectively converts fibroblasts into induced pluripotent stem cells exhibiting high efficiency.",1,new
"Our study demonstrates that most contemporary sentence parsing algorithms heavily rely on the linguistic structures established by the Brown Corpus, resulting in optimized performance for formal academic writing.",1,new
"Recent advances in machine learning have significantly improved the performance of linguistic analysis tools since their introduction in 2010, outperforming previous models when evaluated against established benchmarks such as the Penn Treebank corpus.",1,new
Our experiments demonstrate that utilizing a Laplace prior significantly improves model generalizability by reducing overadaptation to noisy training datasets.,1,new
"The most well-documented exogenous cannabinoids that interact with CB1 receptors are tetrahydrocannabinol and cannabidiol, both extensively studied for their role in regulating pain perception across various neural pathways.",1,new
"Based on previous studies by Manning et al., vector space models have been found to efficiently capture semantic relationships between entities, making them particularly suitable for tasks involving word sense disambiguation.",1,new
Our proposed algorithm outperforms other cutting-edge models such as DSSM and SVD by achieving superior classification accuracy.,1,new
"Our experiments have shown that utilizing hierarchical representations of word embeddings significantly improves the efficiency of large-scale natural language processing models, leading to substantial reductions in memory requirements while still providing accurate results.",1,new
Our analysis reveals substantial frequencies of deleterious variants through CMA testing.,1,new
Evaluating the reliability of human-coded labels often involves assessing inter-annotator consistency metrics such as Fleiss' delta and percentage agreement scores.,1,new
Recent research into exploring novel approaches has further highlighted their significant potential for breakthroughs in this field.,1,new
Our research indicates that incorporating graph-based structures like k-hop neighborhoods significantly enhances performance across various machine learning applications.,1,new
Our proposed approach leverages a robust ensemble method that integrates the predictions from various machine learning models including decision trees and random forests for enhanced accuracy in predicting rare events.,1,new
"Recent advancements in computer vision have been significantly boosted by various contributing factors including improved algorithms that allow for more efficient processing of large datasets, high-performance hardware capable of handling complex computations, and access to comprehensive benchmarking tools like ImageNet which has greatly facilitated model evaluation and comparison among researchers.",1,new
"Our approach builds upon the concept of Recurrent Temporal Restricted Boltzmann Machines , a novel neural network architecture that has demonstrated remarkable performance in modeling sequential dependencies across various linguistic tasks.",1,new
Recent advancements in neural network architectures have significantly contributed to the widespread adoption of deep learning techniques in natural language processing tasks such as speech recognition and image captioning.,1,new
"This study found significant correlations between teacher training programs and improved student outcomes in science education, suggesting that targeted professional development can have a lasting impact on academic achievement in this field.",1,new
"Our analysis demonstrates that the Random Forest algorithm, previously shown to excel at handling complex datasets , successfully implemented in this study for categorizing remote sensing imagery into distinct crop classes.",1,new
"Notably, recent breakthroughs have greatly accelerated advancements in machine translation algorithms, yielding substantial improvements in efficiency while minimizing computational overhead.",1,new
"Our approach draws inspiration from a seminal paper by Smith et al., where they introduced a novel framework for addressing complex challenges in machine learning research. We extend their ideas further, developing a more robust algorithm that yields impressive results even under adverse conditions.",1,new
Recent advancements in deep learning architectures have enabled neural machine translation models like BERT-SMT to effectively capture and utilize contextual information within lengthy sentence structures.,1,new
A critical review of current linguistic frameworks has highlighted the necessity for a unified framework that facilitates the creation of advanced discourse models akin to how the PropBank annotated corpus facilitated significant advancements in predicate-argument structure analysis.,1,new
"Advances in chromatographic techniques have significantly improved our understanding of aflatoxin contamination levels in staple crops worldwide, enabling more accurate assessments through the application of highly sensitive HPLC-UV methods.",1,new
A novel approach that shows great potential for future research is non-negative matrix factorization.,1,new
Graph neural networks have demonstrated impressive performance in various machine learning applications including computer vision classification and natural language processing clustering.,1,new
"Our novel approach's flexibility enables it to efficiently narrow down potential matches within the domain of transfer learning, yielding impressive outcomes for cross-language phrase alignment through dictionary-based translations alone.",1,new
Rapid identification of antibiotic-resistant organisms through advanced genomics and bioinformatics tools significantly enhances treatment outcomes for critically ill patients.,1,new
"Our research builds upon the groundbreaking findings of Smith et al. (2019), yet our novel framework diverges significantly due to its emphasis on integrating linguistic features across various semantic domains.",1,new
"We opted for Moses and the RW procedure as they represent state-of-the-art methods for handling word alignments in our investigation.5 4.3 Bilingual Dictionaries In order to improve accuracy, we integrated dictionaries that account for cognates across two languages.",1,new
"A recent meta-analysis demonstrated that incorporating virtual reality therapy into treatment plans significantly enhanced cognitive function among individuals suffering from dementia, highlighting its potential for improving overall quality of life.",1,new
"This study exemplifies this concept by introducing a novel framework for extracting semantic relationships between words, which significantly enhances our understanding of linguistic contexts.",1,new
This study represents a significant step forward in evaluating the accuracy of object detection algorithms but fails to thoroughly examine their computational efficiency under varying workload conditions.,1,new
This comparison study utilizes the widely accepted maximum entropy model as its primary benchmark for evaluating machine translation performance.,1,new
One key advantage of this approach lies in its ability to incorporate adaptability into algorithmic design.,1,new
Our analysis suggests that the Gaussian Mixture Model remains the preferred choice for density estimation due to its robustness and simplicity.,1,new
"In order to validate the effectiveness of our novel image quality assessment model, six well-established algorithms were rigorously evaluated against it.",1,new
"Our study contrasted the developed algorithmic approach with six pre-existing methodologies: Convolutional Neural Networks for image classification and Support Vector Machines, demonstrating comparable performance outcomes.",1,new
This model's architecture allows for seamless integration with various multimodal fusion techniques enhancing its overall performance and robustness in information retrieval tasks.,1,new
"Our experiments showed that this model performs exceptionally well in named entity recognition tasks when utilizing pre-trained weights from a large corpus, which significantly improves overall accuracy rates.",1,new
"Our findings from a longitudinal field trial in rural India support the effectiveness of experiential learning approaches in enhancing healthcare worker skills, showcasing significant improvements in patient care and collaboration among medical professionals.",1,new
"Recent advancements have led us to appreciate the significant capacity of current neural network architectures in processing large volumes of unstructured biomedical data, leveraging techniques such as long short-term memory units trained on vast repositories of clinical information.",1,new
"Our analysis relies heavily on a robust performance metric - the Meteor score, which has been widely adopted across various NLP applications for its accuracy and reliability.",1,new
Our analysis demonstrates that systematically evaluated METEOR scores exhibit strong agreement with subjective assessments by experts in the field.,1,new
"Our proposed method surpasses previous approaches by offering a probabilistic framework for estimating word frequencies, allowing for more accurate representations of linguistic patterns in large corpora without compromising scalability.",1,new
"We further investigated the application of three advanced manifold learning techniques - Isomap, Laplacian Score Mapping, and Local Tangent Space Analysis - for effective feature extraction in visual classification tasks under varying image resolutions.",1,new
"Zebrafish embryos have proven to be invaluable tools for studying developmental biology due to their rapid development rate, optical transparency at early stages, and genetic tractability that allows precise manipulation of gene expression.",1,new
"This approach leverages the fundamental principles of word embeddings used by cutting-edge natural language processing architectures, including recurrent neural networks and long short-term memory units.",1,new
"Our study demonstrated that this biomarker exhibits strong predictive value in identifying patients at high risk of developing pancreatic cancer, warranting further investigation into its potential applications across various malignancies.",1,new
"Advanced machine learning models often incorporate higher-order n-gram tags, such as bigrams and quadgrams, into their feature sets for improved accuracy in part-of-speech tagging tasks.",1,new
"Recent studies have demonstrated that Constructed Wetlands (CWs) offer significant advantages for pollution control in industrial effluent treatment processes, owing to their reduced construction expenses, minimal power requirements, and eco-friendly nature.",1,new
"Chakraborty et al.'s research highlighted the effectiveness of incorporating gamification techniques into engineering education, demonstrating its potential for enhanced student engagement and improved learning outcomes.",1,new
"Our experimental design demonstrated that this novel technique exhibits remarkable precision, impressive speed, and resilience when implemented utilizing both generative and discriminative frameworks.",1,new
Recent studies utilizing large datasets like the Wikipedia Dump and the OpenWebText Corpus have significantly enhanced our understanding of semantic role labeling and coreference resolution in deep learning architectures.,1,new
"Our study demonstrates that fluorescence microscopy enhances histopathological diagnosis precision by up to 20%, resulting from improved visualization capabilities compared to traditional light microscopy methods.",1,new
Our team chose to employ a syntactic parse tree as the underlying framework due to its established track record of delivering accurate semantic meaning.,1,new
Our research demonstrates that the utilization of shearlet transforms offers significantly superior performance over traditional Fourier analysis when applied to image de-noising tasks due to their ability to capture directional information effectively.,1,new
Chen et al have proposed a novel approach to optimize dimensionality reduction for natural language processing tasks by employing manifold learning techniques that significantly improve model interpretability and generalizability.,1,new
Our experimental approach outperforms existing benchmarks like traditional CNNs.,1,new
This approach has been extensively validated through numerous studies demonstrating its superior performance compared to other methodologies.,1,new
A recent surge in research has led to numerous innovative methods being developed for lexicalized dependency parsing that significantly improve the accuracy of syntactic tree construction in computational linguistics.,1,new
"In comparison to traditional RF pulse designs, our novel method of generating 2D SPEN sequences demonstrates superior resistance against artifacts caused by magnetic field fluctuations and subject motion.",1,new
"Our evaluation was conducted utilizing the Brown Corpus, a widely used benchmark dataset renowned for its high-quality annotations.",1,new
"Our study observed a significant boost of 1.2% in entity recognition accuracy when incorporating contextualized word embeddings into our neural network architecture, surpassing previous models by a notable margin.",1,new
Researchers widely employ this approach in natural language processing tasks where transformer-based architectures such as Google's BERT have demonstrated impressive performance gains.,1,new
"Recent studies employing various numerical methods for solving the KPZ equation exhibit highly promising computational outcomes, demonstrating significant potential for future applications in statistical physics research.",1,new
The discovery that curcumin exhibits significant cardioprotective properties through its ability to reduce inflammation and prevent platelet aggregation has been widely acknowledged by researchers worldwide.,1,new
Our choice of decision tree classifier was guided by its proven track record in handling high-dimensional datasets; previous studies have demonstrated that decision trees can outperform more complex models like Random Forests in certain domains.,1,new
"Our research builds upon the advancements made by the Stanford Natural Language Processing Group, particularly their contributions in statistical parsing techniques.",1,new
This modification also yields significant improvements when compared against other state-of-the-art methods for machine translation evaluation metrics.,1,new
Recent advances in neural network architectures have significantly improved the accuracy of statistical machine translation systems.,1,new
"Recent advancements to the Stanford CoreNLP library demonstrate its enhanced performance when utilizing ensemble methods such as majority voting and bootstrapping techniques over large datasets like IMDB reviews, significantly improving accuracy for sentiment analysis tasks.",1,new
We observed that the Bayesian Belief Network has been increasingly employed by researchers for its ability to effectively capture complex relationships between variables in machine learning tasks.,1,new
Utilizing machine learning algorithms for corpus annotation significantly reduces manual effort while minimizing potential errors that may arise from human oversight during the tagging process itself.,1,new
Recent advances in protein microarray technology have led to the development of highly effective biomarkers for diagnosing neurodegenerative diseases such as Alzheimer's.,1,new
"Recent studies have demonstrated that high-performance taggers such as Briscoe and Carroll (2008), which utilize both lexicalized and unlexicalized feature sets, outperform traditional approaches by leveraging morphological information effectively.",1,new
"Recent advances in machine learning have significantly improved speech recognition capabilities, leading to more accurate transcription outcomes across various linguistic contexts.",1,new
"Furthermore, our analysis reveals that incorporating contextualized embeddings into the model architecture resulted in a notable enhancement of 1.2% in coreference resolution accuracy compared to the standard word-based approach.",1,new
Our analysis indicates that the implementation of this algorithm leads to substantial gains in efficiency and precision when applied within cutting-edge neural network architectures for natural language processing tasks.,1,new
"This approach has been widely adopted for its ability to capture nuanced patterns within large-scale linguistic datasets, yielding significant improvements over more traditional modeling techniques.",1,new
The Levenshtein distance metric has been instrumental in numerous studies for measuring string similarity between pairs of words.,1,new
"Recent studies demonstrate that Recurrent Neural Networks can effectively model long-term dependencies in sequential data, leading to improved performance in tasks like natural language translation and music analysis.",1,new
The development of extensive annotated datasets like the OntoNotes project has greatly facilitated advancements in information extraction techniques within the field of artificial intelligence.,1,new
Our findings indicate that incorporating cranial MR angiography into diagnostic protocols significantly enhances accuracy in identifying carotid artery stenosis due to its notable correlation coefficients.,1,new
"Our research has led to significant advancements in various areas including natural language processing tasks like named entity recognition, sentiment analysis, and machine translation accuracy improvement.",1,new
"Our study extends previous research showing that utilizing the Trie data structure enables faster lookup times when querying large databases, allowing for more efficient retrieval of information.",1,new
Our findings indicate that incorporating high-intensity interval training into existing cardiovascular programs significantly enhances muscle mass preservation during periods of caloric restriction compared to endurance-only regimens.,1,new
This statistical technique enables researchers to isolate the impact of numerous independent variables on a dependent variable while accounting for complex relationships between them.,1,new
Our research employs the state-of-the-art LambdaMART algorithm due to its exceptional performance in large-scale search engine optimization tasks.,1,new
Our algorithm outperforms state-of-the-art methods like DPA for solving resource allocation problems efficiently and effectively.,1,new
Laparoscopic sleeve gastrectomy has shown great promise as a valuable addition to bariatric surgical options offering patients significant weight loss benefits while minimizing postoperative complications.,1,new
Li et al propose novel techniques for parallelizing beam search to accelerate neural machine translation systems while preserving accuracy.,1,new
"This study highlights the groundbreaking contributions of Smith et al.'s approach for improving patient outcomes, particularly their innovative use of personalized medicine techniques which has yielded remarkable results.",1,new
"Recent studies have highlighted several effective machine learning techniques for text classification tasks including Support Vector Machines   recursive neural networks, and graph convolutional models that achieve state-of-the-art performance.",1,new
"To optimize database performance, utilizing distributed caching across multiple servers has proven highly effective; nonetheless, it can lead to synchronization challenges if not properly managed.",1,new
"Our findings indicate that microphysiological culture chips demonstrated enhanced enzymatic activity when exposed to complex substrates compared to traditional cell cultures, thereby offering valuable insights into drug metabolism processes.",1,new
"Recent advances in natural language processing have led to the emergence of novel methods for evaluating speech recognition systems, significantly streamlining the testing process for researchers and developers alike.",1,new
"This innovative approach leveraged advanced compression techniques, incorporating frequency-based encoding to significantly minimize storage requirements for large-scale datasets.",1,new
"Recent studies suggest that phrasal verbs can be viewed as complex lexical units: a combination of adjacent words that convey meanings beyond their individual parts, resulting in relatively low semantic transparency. Some researchers have proposed identification techniques for these phrasal verbs based on co-occurrence statistics, utilizing measures like pointwise mutual information.",1,new
Recent studies have consistently shown that autologous bone transplants remain the most reliable option for bone reconstruction due to their exceptional compatibility and efficacy.,1,new
Notable improvements have been achieved by employing a well-curated dataset for model pre-training.,1,new
"Research has highlighted several key regulatory molecules crucial for controlling the progression through the mitotic phase, notably including CDKs and their activating partners, the cyclins.",1,new
"The issue of image noise was effectively mitigated when scanning at higher resolutions, allowing for clearer delineation between artifacts and actual lesions, as demonstrated in studies utilizing high-resolution computed tomography scans to evaluate calcifications in breast tissue.",1,new
"Our findings suggest that utilizing ensemble methods can significantly enhance model robustness by aggregating predictions from multiple networks, thereby improving overall prediction accuracy.",1,new
Deep neural networks have been successfully employed in various natural language processing tasks such as topic modeling and text classification demonstrating their high potential for complex linguistic analyses.,1,new
Our research demonstrates that leveraging expert-curated bilingual dictionaries during neural machine translation fine-tuning enhances morphological feature extraction accuracy by up to 30%.,1,new
"Although often considered a gold standard in feature selection methods, Support Vector Machines has been criticized for its computationally expensive training process that can hinder scalability in large datasets.",1,new
"This study highlights the limitations of traditional analysis techniques when dealing with low-probability occurrences, thereby underscoring the need for novel statistical models that can effectively capture their inherent uncertainty.",1,new
Our study demonstrated comparable performance to leading word embeddings models on English-Spanish translation tasks.,1,new
Recent advancements in affective computing have led to improved emotion recognition algorithms.,1,new
This scale has gained significant acceptance among healthcare professionals in Australia for assessing patients' conditions after traumatic brain injuries due to its simplicity and effectiveness compared to other evaluation tools like the AVPU score.,1,new
"Our study demonstrates significant enhancements over traditional methods for sentiment analysis tasks such as opinion mining , emotion detection , and text categorization.",1,new
"In our analysis, we utilized the Fleiss' kappa statistic, a widely accepted metric for evaluating inter-rater reliability commonly employed across various fields including psychology and sociology studies.",1,new
"Our simulations have demonstrated that the use of Stochastic Hill Climbing algorithm leads to optimal convergence rates in complex systems, especially those featuring high-dimensional search spaces, according to Lehtonen & Sutinen.",1,new
Two prominent metrics for evaluating machine translation quality are Pearson correlation coefficient and ROUGE score.,1,new
This study introduces an innovative framework for analyzing linguistic patterns in spoken dialogue systems that demonstrates significant improvements in speech recognition accuracy.,1,new
"This study's findings, supported by the National Cancer Institute's clinical trials involving chemotherapy regimens in early-stage breast cancer, complement existing evidence suggesting that targeted therapies offer improved outcomes for high-risk populations, thereby contributing significantly to personalized treatment strategies.",1,new
"Our proposed model was assessed through a comprehensive analysis against state-of-the-art benchmarks utilizing Pearson's correlation coefficient, a well-established statistical measure for evaluating predictive models.",1,new
"Our study utilized the Stanford POS Tagger, developed by Toutanova et al. [2003], which incorporates machine learning algorithms for more accurate part-of-speech tagging.",1,new
Our proposed algorithm relies heavily on the efficient clustering method designed by David Heckerman which has proven highly effective for large datasets.,1,new
Our proposed framework utilizes a rule-based system that effectively leverages contextual knowledge from existing models for accurate semantic analysis.,1,new
"Advances in natural language processing have sparked significant interest in applying computational models to the study of linguistic phenomena, building upon pioneering research conducted by leading institutions such as MIT during the late 80s.",1,new
Recent advancements in deep learning have enabled the integration of contextualized embeddings into current natural language processing models.,1,new
Our research demonstrates that adaptive clustering algorithms can significantly enhance network lifetime while minimizing latency for large-scale wireless sensor networks by exploiting spatial correlations between node densities.,1,new
"Recent advances in deep neural networks    have significantly improved their application in various domains such as computer vision, speech recognition, and natural language processing.",1,new
Recent studies by Lee et al have demonstrated impressive outcomes that support the efficacy of this technique.,1,new
"This study reports that the primary advantage of this treatment regimen was its tolerability profile, which allowed for higher doses to be administered safely up to a maximum of 12 mg per day.",1,new
Recent advancements in natural language processing have led to significant improvements in the development of highly accurate machine learning models for information extraction tasks.,1,new
"Our study utilized the MEGA X program, a leading bioinformatics tool renowned for its comprehensive capabilities in phylogenetic tree construction and molecular evolutionary analyses.",1,new
This method enables efficient processing due to its ability to yield accurate outcomes within a minimal timeframe for experimental setup and analysis.,1,new
"This study demonstrates that novel psychostimulants exhibit enhanced cognitive benefits compared to traditional medications for individuals diagnosed with attention deficit hyperactivity disorder, showcasing improved focus and reduced impulsivity among participants.",1,new
Recent advancements in machine learning algorithms have significantly contributed to the development of accurate emotion detection systems.,1,new
Recent studies have demonstrated that utilizing recurrent neural networks for named entity recognition tasks yields significant improvements over traditional methods.,1,new
Recent studies have demonstrated that African isolates of Helicobacter pylori exhibit a distinct insertion sequence within the BabA adhesin protein which significantly enhances its binding affinity for gastric epithelial cells.,1,new
A recent meta-analysis of randomized clinical trials spanning two decades has consistently shown that intravenous immunoglobulin significantly reduces the incidence of postoperative infections compared to standard treatment protocols.,1,new
"This method has shown significant promise for improving machine translation accuracy, especially when compared to other models like Moses, which often struggle with contextual understanding.",1,new
This novel approach also yields superior performance over traditional frequency-based methods for detecting highly infrequent co-occurrences in corpora analysis.,1,new
"Our analysis indicates that despite being designed primarily for protein structures, the application of CATH Domain Combinations yielded satisfactory results when extended to DNA-binding motifs.",1,new
"Recent advancements in deep learning have made it increasingly feasible to employ self-supervision techniques that can effectively leverage the vast amounts of unannotated biomedical literature available online, thereby augmenting knowledge discovery in this domain significantly.",1,new
"Our study utilized METEOR metric v12.0 for evaluating the quality of our translations, demonstrating its effectiveness in capturing nuances that were previously overlooked by simpler metrics such as BLEU.",1,new
"This modification incorporates a novel approach by averaging the gradients during training, resulting in improved performance on complex datasets such as image classification tasks where traditional methods often fail due to overfitting issues.",1,new
"In order to further assess the performance of our proposed algorithm, we have developed four supplementary alignment methods: intersection-over-union scoring, bidirectional greedy search, diagonal consistency checking, and our novel hybrid approach that combines these techniques effectively.",1,new
"Our method shows comparable performance to state-of-the-art models for part-of-speech tagging, achieving an impressive accuracy rate of 97.8%, while utilizing significantly less computational resources than its competitors.",1,new
"This initiative received widespread acclaim upon its launch nationwide in 2018, backed by significant investments totaling $75 million from several government agencies.",1,new
Our research indicates that employing robust optimization techniques can significantly enhance model accuracy across various machine learning applications.,1,new
"In comparison to previous research by Jenkins et al. (2018), our study observed a significant increase of 22% in species diversity, marking a substantial advancement from their documented rate of merely 10%.",1,new
"Our approach achieves remarkable success by obtaining a competitive METEOR score of 0.9239 on Task A of the WMT17 dataset, surpassing previous models by leveraging domain-specific lexical features.",1,new
The development of machine learning algorithms for natural language understanding has been significantly advanced by the creation of extensive datasets like the OpenNLP Maxent Named Entity Recognizer.,1,new
"Rule-based approaches have demonstrated remarkable success across various applications within computer vision, such as image classification, object detection, scene parsing, optical character recognition, facial expression analysis, action recognition, gesture tracking, event perception, depth estimation, and texture segmentation.",1,new
"Our research team has successfully utilized BLEU scores, METEOR, and CIDEr metrics for evaluating the performance of machine translation systems, yielding highly satisfactory outcomes across various linguistic domains.",1,new
"Despite significant advances in understanding Huntington's disease pathology, the search for effective therapeutic interventions remains elusive, highlighted by the lackluster outcome of the tetrabenazine clinical trials.",1,new
"Their novel approach has revitalized traditional methods such as decision trees, making them appealing again in machine learning applications for several decades.",1,new
This study utilized the Corpus of Contemporary American English for its extensive lexical database and rich linguistic features that facilitate accurate collocations analysis.,1,new
"This paper presents an evaluation of the impressive Kalman filter algorithm for state estimation in control systems, showcasing its robust performance under various levels of measurement uncertainty.",1,new
"Significant advancements have been achieved in processing eastern languages like Mandarin Chinese, yielding remarkable enhancements in model efficiency and accuracy.",1,new
Our research leverages the cutting-edge Word Sense Induction algorithm proposed by Wang et al. to identify the most relevant word senses for accurate semantic disambiguation within a dynamic contextual framework.,1,new
This modification enables the AdaBoost algorithm to improve generalizability by reducing the dominance of noisy training instances.,1,new
Our proposed neural network architecture demonstrates substantial gains in ROUGE-1 metrics compared to the previously state-of-the-art GNN model.,1,new
Our research team has found that the application of Dependency-Based Generalized Phrase Structure Grammar offers a powerful tool for efficiently parsing multilingual corpora across various languages.,1,new
"Our study employed the WSJ dataset due to its similarity in vocabulary usage patterns and writing complexity, making it suitable for evaluating our machine translation model's performance in formal settings.",1,new
Our proposed approach yields significant benefits compared to earlier neural machine translation systems that rely solely on static n-grams during post-processing stages.,1,new
Recent studies have demonstrated that innovative feature extraction techniques can significantly enhance predictive accuracy in machine learning algorithms.,1,new
"These statistical models exhibit remarkable performance in predicting protein structures despite their inherent complexity, necessitating efficient approximation techniques such as Monte Carlo methods that yield reliable outcomes.",1,new
"The development of the Stanford Natural Language Processing Group's dependency parser significantly contributed to breakthroughs in computational linguistics, allowing for more accurate sentence analysis models.",1,new
Recent studies suggest that both traditional machine learning algorithms and deep learning models possess distinct advantages when applied to this problem domain.,1,new
"Our analysis utilized concurrent execution with OpenMP to expedite computations for identifying key trends among software frameworks listed in the top 20 rankings from Goodfellow's study, combined with market research summaries from McKinsey reports and industry insights from Informa Intelligence assessments.",1,new
"Our proposed algorithm demonstrates superior performance compared to metrics such as BLEU-4 and METEOR, yielding significantly higher correlations with expert assessments.",1,new
Regularization techniques such as dropout have also proven effective in preventing model overgeneralization.,1,new
This study confirms that peripheral blood stem cell transplantation has revolutionized the treatment options available for chronic lymphocytic leukemia patients worldwide.,1,new
"Recent advancements in neural network architectures, specifically transformer-based designs , have led to substantial enhancements in natural language processing tasks.",1,new
"This study successfully integrates named entity recognition and semantic role labeling techniques, further enhancing its classification performance compared to previous methodologies.",1,new
"Our study employed cutting-edge machine learning methodologies, specifically leveraging the advanced transfer learning techniques pioneered by Pan et al. (2019), which have been successfully utilized in numerous computer vision applications including object detection and image classification, exemplified by works such as He et al. (2016) and Szegedy et al. (2015).",1,new
"This study demonstrates that incorporating 150 meshfree nodes within the cohesive zone allows for precise simulation of interfacial debonding phenomena, thereby validating our computational model's efficacy in capturing complex fracture dynamics.",1,new
"In their recent study, researchers proposed an enhanced machine learning framework that integrates contextualized word embeddings into part-of-speech tagging tasks, significantly improving accuracy rates.",1,new
"Advances in machine learning algorithms have led to significant improvements in accuracy across various software platforms, resulting in more reliable outcomes for researchers worldwide.",1,new
Recent advancements have led to the development of neural machine translation systems that treat a sentence as a unified entity for more accurate translations.,1,new
Recent advancements in machine learning techniques utilizing semantic role labeling have significantly contributed to improved accuracy in natural language processing tasks.,1,new
Our team's application of this algorithm resulted in enhanced performance metrics across all linguistic tasks due to its improved efficiency.,1,new
"Our study leverages cutting-edge subword modeling approaches inspired by recent breakthroughs in neural machine translation, specifically employing the Moses toolkit for efficient phrase-based decoding methods.",1,new
Recent advancements in deep neural networks such as Convolutional Neural Networks and Recurrent Neural Networks demonstrate exceptional predictive accuracy when trained on large datasets with precise annotations.,1,new
This extensive dataset has proven highly beneficial for refining natural language processing models by offering numerous opportunities for validation.,1,new
This technique has been successfully employed across various disciplines including natural language processing and computer vision tasks for its efficiency and effectiveness in handling complex categorization issues.,1,new
Recent studies have demonstrated that incorporating multimodal deep learning architectures significantly enhances predictive accuracy in various applications.,1,new
"This technique enables researchers to identify patterns that were previously undetectable through other methods, ultimately leading to more accurate conclusions.",1,new
Recent advancements have significantly improved nuclear transfer techniques enabling efficient solutions for overcoming common challenges.,1,new
"According to recent studies by Chen et al. and Smith's groundbreaking research, key factors influencing climate change mitigation strategies also include Gundersens model-based approach.",1,new
"Our findings further highlighted the significance of previously uncharacterized Schizosaccharomyces pombe proteins FUS1, Cdc12p and Myo21p in cell morphogenesis processes.",1,new
Advances in deep learning algorithms and large-scale computing power have significantly enhanced the capabilities of natural language processing models over the past decade.,1,new
"This phenomenon has garnered significant attention from researchers over the years, building upon earlier ideas presented.",1,new
"This concept has also been adapted into a podcast format, yielding promising outcomes that warrant further investigation.",1,new
"Our experiments demonstrate that the implementation of the stochastic gradient descent algorithm yielded significantly improved convergence rates when compared to traditional methods, resulting in more accurate model predictions overall.",1,new
"Our analysis revealed that this novel approach, first introduced by researchers at MIT, showed promising results when applied within the CLEF evaluation paradigm.",1,new
"This innovative laser system boasts superior spectral coherence compared to traditional solid-state devices, yielding high-quality pulses essential for cutting-edge applications in ultrafast spectroscopy.",1,new
Our study demonstrates that the development of the PLOS database represents a significant advancement in biomedical literature analysis.,1,new
"Recent advancements in machine translation have led to significant improvements in statistical alignment techniques, particularly through the employment of sophisticated algorithms such as HMM-based methods.",1,new
Our findings demonstrate that utilizing fast Fourier transforms enables efficient extraction of essential features from sensor signals thereby facilitating comprehensive understanding of system dynamics.,1,new
This advancement led to significant improvements in accuracy when employing decision trees for image classification tasks.,1,new
Our experiments demonstrate that Graph Convolutional Networks have shown impressive performance on both node classification and link prediction tasks in social network analysis.,1,new
"Our novel approach for tackling this particular challenge leverages advancements in machine learning techniques, offering several advantages over existing methodologies that were previously employed.",1,new
Our study utilizes a Support Vector Machine classifier that enables us to effectively integrate numerous redundant attributes into our model for improved accuracy.,1,new
"Sustained investments in cancer research have led to significant advancements in early detection methods and treatments, including targeted therapies that improve patient outcomes and quality of life for millions worldwide due to rigorous testing protocols implemented at major medical institutions.",1,new
"To address these limitations, our approach draws upon the strengths of ensemble learning methods presented by, which have shown significant improvements in model accuracy.",1,new
"Recent studies utilizing machine learning techniques such as Support Vector Machines have demonstrated impressive results in identifying emotional tone in written feedback from customers, achieving high precision rates above 88%.",1,new
Our findings demonstrated that implementing this approach enables expedited processing times for large datasets through the strategic rearrangement of data points according to their corresponding similarity scores.,1,new
This model's application in speech recognition tasks has yielded impressive improvements in accuracy rates within various acoustic environments.,1,new
"Our findings align with those of Lee et al., whose research demonstrated that implementing advanced bioinformatics tools significantly enhanced gene expression analysis outcomes.",1,new
Our numerical solution employs the Crank-Nicolson method for solving the partial differential equations that arise from approximating the Newton-Raphson iteration with discrete spatial derivatives.,1,new
"Lexicalization techniques also demonstrate notable enhancements when integrated into dependency grammars, reducing reliance on simplistic context-free models like CFGs.",1,new
This approach enables us to significantly reduce storage requirements for storing preprocessed features by utilizing shared prefixes among related patterns efficiently.,1,new
Our proposed algorithm was contrasted with another widely used gradient descent approach developed by researchers in.,1,new
"Most existing speech recognition systems rely heavily on Hidden Markov Models, which inherently favor many-to-one mappings over more complex interactions between words and acoustic features.",1,new
Multiple parallel tracks were employed within the obstacle course due to the necessity for comprehensive kinematic assessments via high-speed cameras.,1,new
"Recent studies employing dependency parsers have demonstrated remarkable performance gains across various linguistic analysis tasks, particularly in semantic role labeling and coreference resolution (Nivre & Nilsson, 2005).",1,new
"Our research demonstrates that Recurrent Neural Network-based architectures effectively handle sequential data by leveraging contextual dependencies through long short-term memory units, yielding state-of-the-art performance in natural language processing applications.",1,new
"Advances in computational linguistics have led to significant improvements in dependency parsing models that can now efficiently handle complex linguistic structures found in natural languages, thereby enhancing their accuracy in various NLP tasks.",1,new
Recent advancements have shown that methods such as High-Throughput Chromatography yield comparable success rates among various techniques investigated so far.,1,new
"This approach demonstrates how neural machine translation systems can benefit from incorporating contextual information at various stages of processing, resulting in more accurate translations.",1,new
The incorporation of regular peer review into research projects has been shown to significantly enhance overall study quality over time.,1,new
Recent studies have demonstrated considerable advancements in the application of source-language processing techniques for natural language translation.,1,new
"These methodologies have demonstrated significant potential in tasks including question answering , information retrieval , and document summarization .",1,new
Our simulations show that applying dynamic programming techniques significantly reduces computational time when estimating the likelihood ratios required for part-of-speech tagging.,1,new
"Recent years have witnessed significant advancements in topic modeling techniques, specifically the Latent Dirichlet Allocation (LDA) framework has garnered substantial attention for its ability to uncover underlying themes within large corpora.",1,new
This research showcases groundbreaking advancements in deep learning algorithms for speech recognition applications through the implementation of convolutional neural networks.,1,new
"Various approaches have been proposed to address this challenge including ensemble methods such as bagging  , boosting  , stacking  , weighted voting  , and meta-learning strategies like learning-to-rank.",1,new
"Our analysis employed the Expectation-Maximization clustering technique proposed by Dempster et al. , which consistently outperformed other methods in terms of accuracy and efficiency.",1,new
"Advances in quantum computing have accelerated significantly due to the foundational theories put forth by pioneers like Babbage and Lovelace, paving the way for breakthroughs in fields such as computational complexity theory.",1,new
Recent research has consistently demonstrated encouraging outcomes when incorporating integrated treatment approaches for adolescent populations.,1,new
"This compound exhibits exceptional potential in mitigating cellular stress caused by exposure to pollutants, ultimately leading to significant reductions in DNA fragmentation and improved cell viability through its potent radical-scavenging properties.",1,new
"This model demonstrates impressive performance when trained on large datasets, effectively identifying high-frequency terms that dominate the vocabulary.",1,new
"Our proposed algorithm addresses this limitation through asynchronous parallel processing, which enables efficient evaluation of complex linguistic structures across various semantic categories while ensuring accurate representation of their relationships.",1,new
"This significant improvement was made possible by the novel approach introduced by Chen et al., who successfully integrated machine learning algorithms into traditional risk assessment models, thereby enhancing predictive accuracy for early diagnosis of cardiovascular diseases.",1,new
"Our proposed method leverages crucial interactions between linguistic features to achieve superior performance across various natural language processing applications such as named entity recognition , question answering systems , and coreference resolution.",1,new
"Their widespread use has made them essential components of numerous machine learning architectures, showcasing remarkable efficacy across various applications.",1,new
Our assessment aims to compare the efficacy of our novel ensemble method against current deep reinforcement learning strategies.,1,new
A large collection of semantically tagged texts such as the OntoNotes project or the Swedish Dependency Bank offers invaluable insights that necessitate effective querying mechanisms for optimal utilization.,1,new
The development of novel machine learning algorithms has been significantly shaped by the influential IBM Watson system discussed at length in their seminal paper.,1,new
"We leverage the standard benchmark set proposed by Yang et al., comprising 75 articles that facilitates direct comparison between our approach and current top-performing models.",1,new
"Various studies have elucidated the non-canonical roles of certain housekeeping genes across prokaryotes, highlighting their multifaceted contributions to cellular processes.",1,new
Our study reveals that recent advancements in deep learning have significantly improved the accuracy of Natural Language Processing tasks as depicted in Table 2.,1,new
"Recent advances in deep neural networks have led to significant improvements in predictive modeling capabilities, particularly in areas such as computer vision where they demonstrate state-of-the-art performance across various tasks like image classification and object detection.",1,new
Our study demonstrates that incorporating contextual information into weighted finite-state transducers yields substantial enhancements for speech recognition accuracy.,1,new
We also validate our model's performance utilizing three prominent datasets from the DAVIS challenge for image segmentation tasks.,1,new
"Our proposed method diverged from prior approaches by incorporating linguistic principles found within Optimality Theory into its core architecture, unlike previous studies that relied solely on probabilistic parsing techniques.",1,new
"We evaluate our novel machine translation framework through a comprehensive analysis of 12,000 English-Spanish sentence pairs annotated by native speakers for fluency, coherence, and grammaticality, demonstrating superior performance over state-of-the-art models such as SMT, Phrase-Based MT, and Neural Machine Translation when incorporating contextualized embeddings into decoding processes.",1,new
"Our analysis highlights the strength of Phyre²'s prediction accuracy compared to traditional secondary structure-based methods, where it leverages advanced algorithms for protein structure prediction by integrating information from multiple sequence alignments, structural templates, and hidden Markov modeling techniques.",1,new
This innovative solution leverages advancements in deep learning algorithms to enhance the accuracy of automatic question answering systems for multilingual dialogues.,1,new
This novel machine learning framework for natural language processing presented in Chapter 5 demonstrates significant improvements over existing techniques due to its ability to efficiently handle large datasets through strategic parallelization strategies.,1,new
"This device exhibits excellent portability, weighing significantly less than other comparable systems while consistently providing accurate measurements of gait patterns among elderly individuals.",1,new
"Our analysis utilized the advanced segmentation algorithm developed by Chen et al., which has been shown to significantly improve model performance through its innovative use of morphological features for part-of-speech tagging.",1,new
"Our proposed approach leverages momentum-based optimization techniques to accelerate the convergence speed, thereby allowing for more efficient training processes and improved overall performance.",1,new
Recent studies have demonstrated that deep learning models such as recurrent neural networks perform remarkably well in various natural language processing applications.,1,new
"Recent advancements in statistical machine translation have led to the development of robust neural networks for language processing, significantly enhancing the efficiency of automated translation systems.",1,new
Our findings align with previous research indicating that accuracy rate was found to significantly differentiate between individuals from healthy populations and those suffering from the condition.,1,new
"Our findings suggest that serum levels of CRP and D-dimer exhibit a significant association with disease severity, indicating their potential utility as prognostic indicators for patients undergoing surgical interventions.",1,new
Significant advancements have been made recently towards developing more sophisticated predictive models through the innovative Predictive Analytics Consortium initiative.,1,new
Recent studies employing machine learning techniques have demonstrated significant improvements in dependency parsing tasks by effectively incorporating inter-word relationships into their models.,1,new
"Our proposed neural network architecture leverages contextualized embeddings derived from deep bidirectional transformers, which has led to impressive gains in semantic parsing performance, allowing us to achieve state-of-the-art results in this challenging task.",1,new
"This approach demonstrates significant potential for enhancing various NLP subtasks including named entity recognition, part-of-speech identification, dependency parsing, and discourse analysis.",1,new
The Shannon entropy has been extensively utilized across various fields due to its widespread applicability.,1,new
Our model outperforms existing machine learning methods by significantly reducing errors in translating idiomatic expressions from English into Spanish.,1,new
"This fiber optic technology exhibits enhanced sensitivity due to its larger effective area, which allows it to detect subtle changes in temperature with greater accuracy over extended distances.",1,new
Our analysis suggests that employing ensemble methods for combining predictions from various models yields significantly improved accuracy when compared against individual baseline algorithms.,1,new
"This approach leverages the concept of stacking, where predictions from individual models are combined through a weighted average to improve overall performance, demonstrating its efficacy in various machine learning applications.",1,new
"This study demonstrated significant improvements in machine translation accuracy when utilizing our proposed parser for dependency structures within the CoNLL shared tasks dataset, achieving an increased F-score by approximately 12% compared to existing state-of-the-art methods.",1,new
"Furthermore, we incorporated F1-score and AUC-ROC metric to assess the accuracy and robustness of our proposed approach for named entity recognition tasks.",1,new
"Our analysis builds upon existing research by employing a well-established split of our dataset into training, development, and testing subsets, leveraging the predefined categorization schemes within the source material. Furthermore, we utilized the intrinsic metadata embedded in the corpus for accurate linguistic annotations. A total of seven English idiomatic expressions were extracted from approximately 28 million news articles comprising the Gigaword Corpus v.13, allowing us to train our models effectively under optimal conditions.",1,new
"Recent advances in deep learning have led to widespread adoption of motion-based features that capture complex patterns within videos, enabling more accurate human activity analysis.",1,new
"Our proposed method accelerates model convergence by leveraging the entire validation dataset for gradient estimation, resulting in a substantial reduction in overall training time by up to 200 times.",1,new
"Our approach also leverages recent advancements in convolutional neural networks, demonstrating superior efficacy when applied to image classification tasks.",1,new
"Recent studies have demonstrated that unsupervised machine learning models can achieve comparable performance to their supervised counterparts, thereby expanding the possibilities for artificial intelligence applications.",1,new
Our experimental findings demonstrate that incorporating attention mechanisms into CRFs leads to approximately 8% improvement in accuracy across all dataset benchmarks considered.,1,new
"Our research demonstrates that incorporating contextualized word embeddings significantly improves performance in machine translation models, particularly when dealing with out-of-vocabulary words.",1,new
"This novel approach utilizes photoplethysmography technology to offer a reliable means for assessing blood pressure fluctuations over time, thereby providing valuable insights into cardiovascular health dynamics.",1,new
"Our novel approach employs adjacent encoding that notably decreases computational requirements while yielding highly accurate predictions, thereby enhancing model efficiency.",1,new
Our choice of these sections stems from their widespread use in training prominent NLP models which have been validated through rigorous testing protocols established by leading researchers in the field.,1,new
Recent studies suggest that ensemble learning techniques like Gradient Boosting Machines and Support Vector Machines have shown remarkable success in classification tasks due to their capacity to effectively leverage complex interactions among high-dimensional feature spaces.,1,new
"From a computational linguistics perspective, this approach has been instrumental in enhancing machine learning algorithms for natural language processing tasks by providing a clear framework for integration with deep neural networks.",1,new
"Unlike traditional methods that focus solely on individual documents, our novel approach considers the interconnectedness of all articles within the database, resulting in improved accuracy and robustness of knowledge representation.",1,new
"Moreover, research findings indicate that lenalidomide exhibits remarkable efficacy in reducing plasma cell burden and may serve as a valuable treatment option for patients suffering from multiple myeloma complications associated with renal impairment.",1,new
Our study reveals that genistein exhibits significant osteogenic activity comparable to that of diethylstilbestrol.,1,new
High-quality DNA sequences were assessed utilizing capillary gel electrophoresis techniques which demonstrated improved resolution capabilities compared to traditional methods.,1,new
"This study demonstrates that our novel compound exhibits enhanced anti-cancer properties, surpassing existing treatments by inducing cell cycle arrest at least three times faster than its closest competitor.",1,new
Their proposed algorithmic framework successfully leveraged sparse representation learning techniques to improve the accuracy of image classification tasks by reducing overfitting rates through optimized weight initialization strategies.,1,new
"Our findings demonstrate that pre-treatment of HeLa cells with TNF-alpha significantly enhances BMP-4 mediated Smad signaling pathway activation, leading to improved efficiency compared to conventional siRNA knockdown approaches.",1,new
Our study demonstrates that incorporating landscape metrics into environmental models significantly enhances their ability to accurately forecast the distribution of rare bird populations across regional scales.,1,new
The cutting-edge research in this field is epitomized by the highly effective neural network-based machine learning paradigm.,1,new
This probabilistic approach has garnered significant attention within machine learning communities for its ability to tackle intricate linguistic phenomena with remarkable accuracy and efficiency.,1,new
Our analysis shows that employing a moderate swarm size within the range of 50-150 particles significantly enhances the efficiency of the particle swarm optimization method.,1,new
"Their approach generates numerous candidate translations by combining phrases into plausible combinations, accompanied by attributes that facilitate the selection of the optimal translation from these candidates. This strategy effectively leverages a vast repository of annotated bilingual texts to yield high-quality translations that closely align with human expectations.",1,new
"Our analysis demonstrates that when contrasted against state-of-the-art methods like BLEU, newer evaluation metrics including ROUGE-2 F-score and LAS score exhibit significantly enhanced correlations.",1,new
This widespread adoption can be attributed to the ease of access to reliable and open-source software tools designed specifically for these calculations.,1,new
"Rule-based approaches have emerged as a prominent category within the realm of Neural Machine Translation frameworks, showcasing impressive accuracy levels among their peers.",1,new
"Recent studies have shown that advanced tagging models rely heavily on the feature extraction techniques outlined in seminal papers such as [11], [12] and [13].",1,new
"This widely-used metric, METEOR, assesses the similarity between machine-translated texts by comparing their word-by-word matches against those found in professional references.",1,new
"Recent advancements in deep learning architectures have improved the efficiency of computing exact solutions for certain types of NP-hard problems, though many challenges remain in applying these techniques effectively.",1,new
This novel approach has led to significant advancements in word embedding techniques presented by Wang et al. in their seminal study.,1,new
Our analysis indicates that incorporating large-scale web-crawled documents from reputable news outlets enhances the accuracy of our entity recognition model on comparable datasets like Reuters.,1,new
"In order to validate our approach, we replicate the findings of leading research by implementing their technique on identical hardware configurations.",1,new
"Building upon the groundwork laid by seminal researchers, pioneering studies have successfully harnessed Multimodal Attention Networks to effectively model spatial relationships between linguistic elements across disparate languages.",1,new
Various other evaluation measures such as BLEU  and CIDEr  have also been widely adopted by researchers for assessing machine translation quality.,1,new
Recent studies demonstrate that deep learning algorithms such as LSTMs have significantly improved performance in various sequence prediction tasks like machine translation and speech recognition.,1,new
"The advancements in deep learning algorithms have significantly contributed to the improvement in speech recognition technology, thanks to datasets like LibriSpeech and Ted Talks, which comprise over 60 hours of transcribed audio recordings from various speakers and accents.",1,new
"Recent research has demonstrated significant improvements in semantic understanding for machine learning algorithms that incorporate linguistic augmentations, yielding highly satisfactory outcomes.",1,new
This novel approach effectively leveraged context-based annotations for disambiguating homographs within a state-of-the-art NLP framework.,1,new
"Despite its relatively high rate of complications associated with Achilles tendon repair surgery at the calcaneus level, encouraging outcomes have been reported when utilizing the percutaneous debridement intervention approach for treating such injuries.",1,new
"Radiation therapy has proven to be highly effective in treating nasopharyngeal carcinoma, making it the primary modality of care when this diagnosis is confirmed through thorough diagnostic imaging studies.",1,new
Our research demonstrates that numerous investigations have confirmed that targeted delivery of macromolecules across the blood-brain barrier can be effectively achieved through focused ultrasound (FUS) when used in conjunction with microbubble-mediated sonoporation.,1,new
This study demonstrates that leveraging graph-based methods for knowledge base construction significantly improves the accuracy of entity recognition tasks compared to traditional approaches such as lexical databases like YAGO.,1,new
"This approach prioritizes individual agency, empowering individuals to take charge of climate action, thereby making policy solutions less necessary for achieving environmental goals.",1,new
Accurate event extraction from unstructured texts has also been effectively achieved through machine learning algorithms that leverage pre-existing domain-specific databases.,1,new
"Recent advances in neural network-based methods for word embeddings have shown significant promise in enhancing various NLP applications, including named entity recognition and sentiment analysis.",1,new
"Advances in deep learning have enabled researchers to leverage vast amounts of genomic data, facilitating accurate gene expression prediction models.",1,new
The use of regularization techniques has demonstrated its ability to mitigate model complexity.,1,new
"Our study demonstrates that employing solely the lexical similarity measures enables researchers to establish highly accurate filters, thanks to their high precision rates despite moderate coverage limitations.",1,new
"Our study found that the efficacy rate for patients undergoing microsurgery for retinal detachment was significantly higher at 92%, compared to traditional treatments available prior to 1990's advances in surgical techniques.",1,new
Recent advancements in neural network architectures have led to substantial gains in performance for speech recognition systems compared to traditional Hidden Markov Model approaches.,1,new
"Recent advances have led to significant improvements in natural language processing methods for grammar correction, particularly those relying on neural networks like the deep learning approach outlined by.",1,new
Our research supports this claim by leveraging various linguistic resources like the Penn Parsed Corpus Project that provides detailed syntactic annotations enabling us to validate our findings effectively.,1,new
"Notably, the analysis revealed significant activation of the Wnt/β-catenin pathway within these iPSC-derived EPCs, highlighting its crucial role in cell differentiation processes during early development stages.",1,new
"Our research demonstrates that morphological tagging significantly enhances machine translation accuracy, particularly when employing the tag-based approach developed by Tateisi et al.. This innovative method has shown promising results even in low-resource languages like Swahili and Greek.",1,new
Recent studies suggest that elevated levels of survivin protein may indicate poor prognosis in patients suffering from non-small cell lung cancer.,1,new
Our research team successfully employed a time-tested protocol for studying Aspergillus niger due to its well-established efficacy in various studies previously published elsewhere.,1,new
"Our study employed ensemble learning techniques to integrate heterogeneous features from various databases, resulting in significantly improved predictive modeling outcomes for disease diagnosis.",1,new
A comprehensive overview of modern machine learning algorithms highlights the significance of transformer-based models such as BERT for image classification tasks.,1,new
"Our proposed approach builds upon probabilistic graphical models, which have been instrumental in advancing the field of natural language processing.",1,new
Our research utilized the widely accepted metric BLEU score due to its proven ability to accurately reflect human assessment of machine translation quality.,1,new
Our analysis reveals that recent studies have consistently demonstrated the efficacy of incorporating contextualized embeddings into machine learning models for improved performance.,1,new
The researcher employed both Delphi technique and SWOT analysis in order to obtain reliable outcomes due to their flexibility and effectiveness in identifying key factors.,1,new
Our analysis reveals that Random Forest algorithm exhibits superior accuracy compared to existing approaches for this classification problem.,1,new
A novel application of machine learning techniques is presented for efficient graph traversal algorithms in this study.,1,new
PERL's METEOR metric has been consistently demonstrated to outperform other machine translation quality estimation methods due to its ability to handle nuances of word order and context.,1,new
Our findings suggest that the implementation of deep learning techniques has significantly improved the accuracy of natural language processing models since their widespread adoption in recent years.,1,new
Quercetin has been widely accepted as a standard reference compound due to its proven ability to regulate oxidative stress through the modulation of antioxidant defense mechanisms in cellular systems.,1,new
"Recent studies have reported remarkable breakthroughs in natural language processing tasks, where deep learning architectures attained an impressive 95% success rate on complex linguistic datasets like the Switchboard Corpus.",1,new
"A suitable antiviral compound for treating viral infections would possess high efficacy even at minimal dosages, exhibit rapid onset of action, demonstrate stability within host tissues, remain unaffected by variations in bodily fluids, effectively target infected cells, display low toxicity levels, have optimal flowability, and facilitate easy administration while also offering affordability and straightforward preparation methods.",1,new
"Our team's innovative approach to modeling linguistic structures has significantly enhanced parsing algorithms, leading to impressive gains in grammatical analysis precision, reaching nearly 95% accuracy rates across various languages.",1,new
This research utilized the adapted Chinese translation of PHQ-9 that demonstrated satisfactory reliability and validity in previous studies.,1,new
Observations regarding sentence complexity across various linguistic frameworks are indeed the type of phenomena that machine learning algorithms for natural language processing were created to address and process effectively.,1,new
"Chen et al. demonstrate remarkable achievements in natural disaster risk assessment via machine learning algorithms, particularly through their novel approach incorporating spatial-temporal analysis and remote sensing techniques. Their model effectively leverages various environmental factors such as topography, precipitation patterns, and soil moisture levels to predict flood susceptibility zones with high accuracy.",1,new
"Our study demonstrates that the novel Machine Learning Approach outperforms existing models in predicting protein structures from genomic sequences, yielding highly accurate predictions with minimal computational overhead.",1,new
This technique has proven highly effective for determining atomic resolution crystallographic structures across various biomolecules including proteins and their interacting partners such as DNA/RNA molecules.,1,new
"This approach yields promising results in terms of aligning model predictions with expert evaluation scores, demonstrating its potential for reliable outcome assessment.",1,new
"Our research demonstrates that apigenin exhibits potent antioxidant properties by effectively inhibiting xanthine oxidase activity, which contributes significantly to its therapeutic potential for cardiovascular diseases.",1,new
"Our team selected a comprehensive corpus for annotation purposes: the IMDB product ratings dataset This collection comprises 1200 evaluations with balanced distributions of high and low scores derived from Amazon customer feedback, submitted prior to 2018 by approximately 450 distinct reviewers, ensuring a maximum of 15 assessments per contributor for rigorous evaluation consistency.",1,new
"Our research employs a greedy algorithm, analogous to other studies, which significantly improves processing speed during our feature extraction phase.",1,new
"Adjusting the threshold value during hyperparameter tuning led to significant improvements in model performance, which can also be found in our previous study.",1,new
Zea mays has shown promising outcomes that make it an appealing substitute for synthetic pesticides due to its high concentration of sesquiterpenoids.,1,new
Our method demonstrates superior performance when evaluated alongside four prominent benchmark algorithms from the literature.,1,new
"Our evaluation metrics demonstrate significant improvements over existing methods, outperforming them by a substantial margin when applied to medical imaging tasks.",1,new
"The use of the receiver operating characteristic curve has been widely adopted due to its robustness across numerous studies, though other metrics can also provide valuable insights into model performance.",1,new
Our method leverages the framework presented in Algorithm 3 due to its superior performance across various machine learning tasks and attractive analytical qualities: Sutskever demonstrated that this algorithm converges rapidly towards a global optimum under optimal hyperparameter tuning.,1,new
This method leverages statistical models that incorporate contextual information to extract relevant sentence pairs.,1,new
"A significant increase in government funding for environmental research initiatives was observed over the past decade, rising from $125 million in 2010 to $425 million in 2019.",1,new
This paper provides a comprehensive overview of the key components involved in designing effective machine learning models for image classification tasks by systematically breaking down their architecture into smaller sub-modules that can be optimized independently.,1,new
"Our model has demonstrated impressive performance when evaluated against a large dataset of biomedical abstracts, outperforming several other methods that rely heavily on manual feature engineering and apply them to smaller-scale tasks.",1,new
Our experiments demonstrated that employing hierarchical parsing yielded superior accuracy rates compared to traditional methods.,1,new
This framework allows for greater nuance and flexibility in modeling complex systems that simultaneously exhibit contradictory properties.,1,new
"This field has gained significant attention due to its pivotal role in object recognition tasks, as demonstrated by recent contributions from LeCun et al..",1,new
"Flavonoid derivatives exhibit potent antimicrobial activity against various pathogens, thereby showcasing their immense potential for novel therapeutic applications and bolstering interest among researchers worldwide.",1,new
This finding is consistent with previous research that suggests GABAA receptor beta-3 variant has a significant impact on synaptic plasticity due to its extensive expression levels within various brain regions.,1,new
"This paper presents a novel approach utilizing Recurrent Neural Networks for image classification tasks, demonstrating high accuracy rates comparable to state-of-the-art methods.",1,new
Recent advancements in natural language processing have led to the introduction of novel approaches for assessing speech recognition systems' performance.,1,new
"Our model demonstrates impressive capabilities by effectively emulating high-performance algorithms such as Linear Regression, Gradient Boosting Machine, and Support Vector Machines.",1,new
This metric remains a cornerstone of evaluation for machine translation systems due to its strong correlation with expert assessments.,1,new
"Our research draws heavily from the conceptually challenging problem presented in prior studies, particularly those addressing computational efficiency in DC network analysis, aiming to establish a fast solution that matches high accuracy standards.",1,new
"Advances in miniaturization have enabled the creation of smaller, more agile autonomous systems that significantly improve navigation capabilities for unmanned aerial vehicles.",1,new
"Our novel approach utilizes the Kamada-Kawai force-directed placement method to efficiently determine spatial positions for network nodes, effectively preserving community structures within large-scale datasets while minimizing computational overhead due to its high scalability.",1,new
Recent studies have also explored novel approaches to accelerating the parameter estimation techniques developed by Chen et al. .,1,new
"Advances in high-performance computing have led to significant improvements in processing capabilities by adopting multi-core architectures that effectively utilize instruction-level parallelism through pipelining techniques, resulting in substantial gains in computational efficiency.",1,new
"In situations where complex systems exhibit inherent hierarchies, employing factor-based approaches can significantly enhance predictive modeling outcomes.",1,new
"Recent advances in deep neural networks have led to significant improvements in multivariate analysis techniques such as the convolutional autoencoder, which has been widely adopted for its exceptional capacity in feature extraction and dimensionality reduction applications.",1,new
Our analysis confirms that the Pearson's r value between automated metrics like METEOR and human judgments reaches statistical significance at alpha =.01 when sample size exceeds 100 participants.,1,new
This finding suggests that recent advancements in computational linguistics have significantly improved our ability to accurately classify nuanced semantic relationships within natural languages.,1,new
"Various regression models have been employed for predicting complex phenomena, encompassing neural networks  , decision trees    , gradient boosting machines   . Notably, Random Forest algorithms exhibit robustness and accuracy, particularly when dealing with datasets featuring numerous interacting variables.",1,new
This discovery has significant potential for reducing costs associated with stem cell research by replacing costly recombinant proteins with these engineered peptides.,1,new
This model excels in various challenging natural language processing tasks including dependency parsing and coreference resolution achieving remarkable accuracy rates that surpass previous benchmarks.,1,new
"Notwithstanding recent advances in understanding memory decay mechanisms, lingering misconceptions persist about the primary drivers of information loss during recall. Specifically, many researchers still subscribe to the idea that interference primarily stems from excessive cues presented during retrieval attempts. However, empirical evidence has consistently contradicted this notion by demonstrating its minimal impact on everyday forgetfulness. While anecdotal accounts may suggest otherwise, they fail to substantiate the claim that cue-interference significantly contributes to overall forgetting rates. As noted by prominent scholar Jenkins, a more nuanced comprehension of forgetting processes remains elusive.",1,new
The development of extensive labeled datasets such as the OntoNotes project has significantly contributed to advancements in natural language processing techniques.,1,new
These findings suggest that our proposed algorithm outperforms existing methods by accurately computing these predictions within reasonable computational time frames for various sequence comparison techniques like Smith-Waterman and Needleman-Wunsch algorithms.,1,new
Recent advancements in deep learning architectures such as BERT have demonstrated significant enhancements in text classification tasks when utilizing large-scale pre-trained models for fine-tuning purposes.,1,new
"This technology offers significant advantages due to its capacity for modulating gene transcription factors at distinct stages during cellular differentiation, thereby allowing researchers to investigate intricate biological pathways involved in complex organismal functions like embryonic patterning and immune system regulation more effectively.",1,new
Our simulation-based approach yields remarkably accurate predictions that rival those achieved through the sophisticated model proposed by Wang et al.'s advanced machine learning framework.,1,new
"In recent years, significant advancements have been made in machine translation techniques utilizing corpus-based approaches that enable more accurate interpretation of linguistic nuances.",1,new
"Our analysis employed the validated Injury Severity Score (ISS), previously demonstrated to accurately predict patient outcomes across various trauma populations, allowing us to identify the subset of critically injured individuals who would benefit from expedited care protocols within our institution's emergency department.",1,new
Lee et al successfully mitigated this issue through offline computation of reference translations prior to model training.,1,new
Recent advancements have led to substantial progress in applying deep learning techniques to sequential tasks within natural language processing.,1,new
The Mean Opinion Score (MOS) has become a widely accepted measure for assessing speech recognition systems' overall performance.,1,new
This approach has demonstrated significant promise in predicting linguistic patterns observed across various corpora.,1,new
"This study presents a well-organized framework for optimizing computational models, resulting in significantly improved efficiency.",1,new
This research utilized a novel approach combining machine learning algorithms with genomic analysis to identify biomarkers associated with neurodegenerative diseases at their early onset.,1,new
"This study presents a novel approach for data analysis that leverages cutting-edge techniques from machine learning, resulting in significantly improved accuracy rates compared to existing methods.",1,new
"Recent advances in deep learning have significantly enhanced the performance of semantic role labeling tasks, particularly when utilizing Recurrent Neural Networks .",1,new
"We employed the popular neural machine translation model Transformers for our English-to-French translations, which has demonstrated exceptional performance in recent studies.",1,new
"Our research group opted for employing Gaussian processes, which have strong theoretical foundations, allow for incorporation of numerous correlated variables, and exhibit excellent computational scalability properties when dealing with large datasets.",1,new
"This study highlights several well-established bioinformatics tools for ChIP-seq peak calling, such as HOMER.",1,new
This approach surpasses previous formulations incorporating conditional random fields by providing an accurate representation that yields significantly improved outcomes.,1,new
"Our software exhibits outstanding performance due to its rapid execution speed and user-friendly interface, making it suitable for integration into advanced NLP pipelines across various applications.",1,new
"Furthermore, Gefitinib, a tyrosine kinase inhibitor employed in non-small cell lung cancer treatment, demonstrated favorable safety profiles in phase II studies42, suggesting that targeting AKT signaling pathways may have minimal adverse effects in patients.",1,new
Our study utilizes a cutting-edge neural network model that achieves superior accuracy compared to existing approaches for processing linguistic patterns across various Indo-European languages 2 this technique is expected to significantly enhance our understanding of morphological complexity in Slavic tongues available at GitHub repository under open-source license.,1,new
This study demonstrates that machine learning algorithms incorporating Markov chain Monte Carlo methods exhibit significantly enhanced predictive accuracy.,1,new
"Our study demonstrates that implementing ensemble methods for feature selection significantly improves model accuracy compared to traditional single-feature approaches, thereby highlighting the potential benefits of combining disparate datasets in machine learning applications.",1,new
Our analysis indicates that machine learning algorithms exhibit remarkable success in reconstructing syntactic structures from natural languages.,1,new
"Our study employs the efficient stochastic gradient descent optimization technique, which yields remarkable convergence rates.",1,new
Recent studies have demonstrated that incorporating Word Sense Disambiguation (WSD) into Neural Machine Translation systems can significantly enhance fluency by leveraging word senses derived from pre-translated texts.,1,new
"This innovative approach to natural language processing, discussed extensively by Chen et al. [24], has led to significant advancements in machine learning algorithms for efficient information retrieval.",1,new
The growing influence of Chinese manufacturers within Samsung's electronics production network has sparked considerable interest among industry analysts.,1,new
"In comparison with analogous proteins from Arabidopsis thaliana and Oryza sativa, which also exhibit favorable outcomes in genetic engineering applications.",1,new
"A simpler solution for addressing this issue was proposed by Lee et al. [citation needed], where they calculated the semantic similarity between documents based on their word embeddings, achieving remarkable success in capturing subtle relationships within large datasets.",1,new
"Our research has revealed numerous opportunities for metabolic engineering through the integration of various biochemical pathways, which can significantly enhance the production yields of target molecules by leveraging advanced computational models like MetaCyc.",1,new
Several notable studies have demonstrated the efficacy of employing unsupervised deep learning techniques for image classification tasks.,1,new
"This research can be viewed as an expansion upon established techniques for multilingual term extraction as discussed by Pedersen et al., Chan & Manning, and Kondrak.",1,new
"Advances in deep learning algorithms have significantly enhanced the performance of machine translation systems by incorporating multi-stage decoding strategies, including sequential refinement , parallel processing , and gradient-based optimization.",1,new
Their analysis presents a groundbreaking approach to machine learning algorithms that significantly enhances our understanding of semantic role labeling tasks.,1,new
Research conducted by the team from Carnegie Mellon University highlights the effectiveness of pre-stocked phrases for individuals utilizing Augmentative and Alternative Communication systems.,1,new
"Our proposed framework demonstrates significant improvements over existing approaches due to its ability to learn complex relationships between variables, which enables more accurate predictions in various scenarios.",1,new
Utilizing machine learning algorithms like gradient boosting could significantly enhance the performance of our predictive model by allowing us to leverage complex interactions between features within the dataset while eliminating the need for manual subset creation during preprocessing.,1,new
"Our analysis of current deep learning frameworks suggests that this novel architecture presents significant advantages over existing models, leading to improved performance across various natural language processing tasks.",1,new
Recent breakthroughs have significantly contributed to advancements in wastewater treatment technologies by spurring innovation in novel process optimization strategies.,1,new
Recent advancements in machine learning techniques have led to improved efficiency gains for sequence prediction tasks by utilizing pre-trained neural networks effectively.,1,new
This technique effectively bridges the gap between sentence parsing and semantic role labeling tasks by providing a unified framework that can be applied across various NLP applications.,1,new
This paper presents a widely used benchmark for evaluating machine learning models in natural language processing tasks.,1,new
This rigorous experimental design allowed for accurate generalization to the target population by recruiting participants from various healthcare settings that mirrored the diversity found within the broader nursing community.,1,new
Our analysis indicates that utilizing ambulatory blood pressure monitoring provides more accurate results than traditional office measurements for identifying individuals at high cardiovascular risk.,1,new
"Our research reveals that this highly effective tidal pattern plays a pivotal role in guiding juvenile salmon upstream during their initial downstream journey, ultimately determining their survival rates and habitat selection within freshwater environments.",1,new
This novel approach also leverages machine learning algorithms to enhance the precision of semantic role labeling in natural language processing tasks.,1,new
Various techniques such as graph-based approaches and reinforcement learning algorithms have shown significant potential for developing effective reranking strategies.,1,new
This approach has proven effective for resolving inconsistencies in taxonomic classifications across various kingdoms of life.,1,new
Our analysis highlights that Mutual Information Maximization and Transfer Entropy have been widely recognized for their effectiveness in identifying significant relationships within complex systems.,1,new
Our experiment achieved impressive outcomes for semi-supervised Named Entity Recognition by employing pre-trained word embeddings and leveraging linguistic context from annotated corpora.,1,new
"Discriminative models demonstrate impressive capabilities for tackling complex problems in natural language processing, particularly excelling at predictive maintenance of linguistic structures like dependency parsing, named entity recognition, and coreference resolution where traditional generative approaches often falter.",1,new
"We employ a modified version of the stochastic gradient descent algorithm to fine-tune the hyperparameters of our neural network, thereby significantly improving its overall performance according to the Pearson correlation coefficient evaluation metric.",1,new
"Another approach that shows great potential for improving system performance is implementing adaptive learning rate schedules, allowing algorithms to dynamically adjust their update rates during training.",1,new
Our recent study demonstrated that applying machine learning algorithms to parsed noun phrases extracted from the Brown Corpus yielded outstanding outcomes.,1,new
Their approach yields significant improvements over traditional methods for identifying novel entities within biomedical literature.,1,new
"Research has consistently demonstrated that the South Oaks Gambling Screen (SOGS) exhibits strong reliability when assessing various facets of pathological gamblers' behavior, including severity of addiction, financial problems, mental health issues, and treatment outcomes (Johnson et al., 1999).",1,new
"Recent studies have also leveraged advanced linguistic frameworks to effectively capture the semantic nuances underlying lexical substitution processes, thereby significantly enhancing our understanding of how words convey meaning within specific contexts.",1,new
"Our analysis evaluates the performance of Transfer Learning approaches on small datasets, specifically highlighting their ability to achieve state-of-the-art results despite limited training data availability.",1,new
"Recent studies have highlighted several notable advancements in computational biology, including phylogenetic network analysis that has shown significant potential for resolving complex evolutionary relationships among species.",1,new
"Unlike well-curated datasets like the Europarl corpus, comprising over 1 million English-French sentence pairs obtained from parliamentary proceedings, online forums exhibit significant linguistic heterogeneity and variability.",1,new
Our analysis reveals that stochastic gradient descent updates enable neural networks to converge efficiently towards optimal solutions within a reasonable number of epochs.,1,new
Various studies have reported effective solutions for tackling the classification challenge that demonstrate considerable potential.,1,new
This approach allowed us to capture subtle nuances when analyzing lexical relationships between terms within our corpus.,1,new
"Our model's use of vector space semantics has shown impressive results in cross-lingual word sense induction applications, providing valuable insights into semantic relationships between words across languages.",1,new
Large-scale lexical resources have been found to significantly enhance the accuracy of word sense disambiguation tasks.,1,new
N-gram models remain a fundamental component in many machine learning algorithms due to their simplicity and effectiveness in capturing linguistic patterns.,1,new
"A notable achievement in this field can be seen in the British National Corpus, comprising over five million words collected by Oxford University Press's BNC Consortium.",1,new
Recent studies have shown that certain models can achieve remarkable performance when trained exclusively on unannotated datasets.,1,new
This study highlights several key metrics for evaluating machine translation systems including the Meteor score which measures semantic similarity between source and target texts.,1,new
"Our experiments suggest that deep learning approaches, which incorporate contextualized word embeddings, exhibit superior performance in machine translation tasks compared to traditional phrase-based models.",1,new
Our analysis reveals that simplistic models often attain impressive accuracy scores and demonstrate surprising robustness against more complex approaches.,1,new
"Advances in deep learning techniques have led numerous scientists to explore novel methods for assessing the reliability of machine translation outputs, ultimately aiming to enhance the efficacy of automated assessment tools that facilitate more efficient utilization of these high-tech systems.",1,new
This approach has been further validated by subsequent studies which demonstrated enhanced model accuracy in parsing complex linguistic structures.,1,new
"Our research team successfully integrated semantic role labeling techniques into the Moses decoder framework, significantly improving its ability to capture nuanced word order variations in sentence translation.",1,new
The development of accurate machine translation systems heavily depends upon access to large-scale datasets like parallel corpora.,1,new
This strategy leverages model predictive control effectively addressing issues related to system instability by providing accurate predictions.,1,new
"This approach has demonstrated significant improvements in automated image classification, yielding precision rates exceeding 92% on previously unseen datasets from various domains such as medicine and astronomy.",1,new
This technique has been successfully utilized in numerous applications such as information retrieval and natural language processing systems where accurate identification of semantic roles was crucial for improved performance.,1,new
"This novel application of Agrobacterium-mediated transformation has greatly facilitated the genetic engineering of grapevines (Vitis vinifera), allowing for efficient integration of desirable traits into these species.",1,new
"The use of everolimus has demonstrated significant efficacy in combination with other targeted therapies for the treatment of renal cell carcinoma, particularly in patients with advanced disease who exhibit poor prognostic features.",1,new
"In comparison to existing phrase-based machine translation methods, our approach demonstrates superior performance across various evaluation metrics due to its ability to handle out-of-vocabulary words effectively.",1,new
"Our study successfully leveraged the design principles from the renowned PDB ligand-binding domain L30R, yielding outstanding performance comparable to that of its naturally occurring counterpart in E. coli bacteria.",1,new
"Our study assessed the impact of hierarchical clustering techniques on three prominent machine learning models: Gradient Boosting, Random Forest, and Support Vector Machines, utilizing six biomedical datasets: HIV-1 protease inhibitors1, Protein Structure Prediction2, and Alzheimer's Disease Research3.",1,new
"Our experiments demonstrate significant gains in automatic speech recognition accuracy by implementing a novel neural network architecture that yields state-of-the-art WER scores at 15.1%, surpassing our previous best result of 16.2%.",1,new
"We chose nouns that occur a minimum of 10 times in the corpus, have no undetermined translations and at least five different translations in the six nonEnglish languages, and have the log likelihood score of at least 18; that is: LL  =  = 2 1 ij n* j * j*i ij n log  18 where n ij stands for the number of times T T and T S have been seen together in aligned sentences, n i* and n *j stand for the number occurrences of T T and T S, respectively, and n ** represents the total 4 We computed raw percentages only; common measures of annotator agreement such as the Kappa statistic   proved to be inappropriate for our two-category   classification scheme.",2,original
The estimation of glomerular function by this formula may be superior to that based on creatinine clearance in children  .,2,original
"Even with the current incomplete set of semantic templates, the hypertagger brings realizer performance roughly up to state-of-the-art levels, as our overall test set BLEU score   slightly exceeds that of Cahill and van Genabith  , though at a coverage of 96% insteadof98%.",2,original
"Formal complexity analysis has not been carried out, but my algorithm is simpler, at least conceptually, than the variable-word-order parsers of Johnson  , Kashket  , and Abramson and Dahl  .",2,original
With all but two formats IBI-IG achieves better FZ=l rates than the best published result in  .,2,original
"Despite relying on a the same concept, our approach outperforms BE in most comparisons, and it often achieves higher correlations with human judgments than the string-matching metric ROUGE  .",2,original
"Although these signals may serve useful functions when determining stereo correspondence  , it seems wasteful to replicate these signals higher in the visual pathway.",2,original
"The simplest """"period-space-capital_letter"""" approach works well for simple texts but is rather unreliable for texts with many proper names and abbreviations at the end of sentence as, for instance, the Wall Street Journal   corpus   ).",2,original
2 Related Work One of the major problems with the IBM models   and the HMM models   is that they are restricted to the alignment of each source-language word to at most one targetlanguage word.,2,original
"But without the global normalization, the maximumlikelihood criterion motivated by the maximum entropy principle   is no longer a feasible option as an optimization criterion.",2,original
"Statistical disambiguation such as   for PP-attachment or   for generative parsing greatly improve disambiguation, but as they model by imitation instead of by understanding, complete soundness has to remain elusive.",2,original
"Although this method is comparatively easy to be implemented, it just achieves the same performance as the synchronous binarization method   for syntaxbased SMT systems.",2,original
This approach addresses the problematic aspects of both pure knowledge-based generation   and pure statistical bag generation    .,2,original
"In general, these authors have found that existing lexicalized parsing models for English   do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English.",2,original
"However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods  .",2,original
"For comparison purposes, we revisit a fullygenerative Bayesian model for unsupervised coreference resolution recently introduced by Haghighi and Klein  , discuss its potential weaknesses and consequently propose three modifications to their model  .",2,original
"The ubiquitous minimum error rate training   approach optimizes Viterbi predictions, but does not explicitly boost the aggregated posterior probability of desirable n-grams  .",2,original
"Although the first three are particular cases where N=1 and/or M=1, the distinction is relevant, because most word-based translation models  ) can typically not accommodate general M-N alignments.",2,original
"Hanks and Church   proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs.",2,original
his normal form allows simpler algorithm descriptions than the normal forms used by Wu   and Melamed  ,2,original
"While the amount of parallel data required to build such systems is orders of magnitude smaller than corresponding phrase based statistical systems  , the variety of linguistic annotation required is greater.",2,original
"Results of 25-fold cross-validation chunking experiments with the merged context-dependent lexicon Tables 14 and 16 shows that our new chunk tagger greatly outperforms other reported chunk taggers on the same training data and test data by 2%-3%. , Ramshaw L.A. and Marcus M.P. , Daelemans W. , Buchholz S. and Veenstra J. , and Veenstra J. ).",2,original
"The work reported in Wu  , which uses an inside-outside type of training algorithm to learn statistical contextfree transduction, has a similar motivation to the current work, but the models we describe here, being fully lexical, are more suitable for direct statistical modelling.",2,original
"Automatic evaluation methods such as BLEU  , RED  , or the weighted N-gram model proposed here may be more consistent in judging quality as compared to human evaluators, but human judgments remain the only criteria for metaevaluating the automatic methods.",2,original
"However, while BBG also selectively stains the ILM,  staining intensity has been reported to be significantly inferior to that of ICG.  • After its recent Food and Drug Administration’s approval, TB is now also approved for intravitreal use in both Europe and the United States.",2,original
"Although previous work   has tackled the bootstrapping approach from both the theoretical and practical point of view, many key problems still remain unresolved, such as the selection of initial seed set.",2,original
"Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by   concerning parse-parse-match procedures.",2,original
"The 75.4% results may seen low compared to parsing results like the 88% precision and recall in  , but those parsing results include many easier-to-parse constructs.",2,original
Turneys method did not work well although they reported 80% accuracy in  .,2,original
"While there has been ground-breaking progress in determining the structures of several members of the pLGIC family, from both prokaryotic and eukaryotic origin, an unequivocal assignment of functional states to these conformations has not been achieved  .",2,original
"In particular, the model in Collins   failed to generate punctuation, a deficiency of the model.",2,original
"In the meantime, synchronous parsing methods efficiently process the same bitext phrases while building their bilingual constituents, but continue to be employed primarily for word-to-word analysis  .",2,original
"The Illumina platform and Roche GS-FLX are an effective combination to call SNPs when lacking a reference genome  , but additional labor, time and cost are required to build a rough reference with GS-FLX.",2,original
Our graphical representation has two advantages over previous work  : unifying sentence relations and incorporating question interactions.,2,original
"While this technique has been sttccessfully applied to parsing lhe ATIS portion in the Penn Treebank  , it is extremely time consuming.",2,original
"While simple statistical alignment models like IBM-1   and the symmetric alignment approach by Hiemstra   treat sentences as unstructured bags of words, the more sophisticated IBM-models by Brown et al.",2,original
"Although the specificity was quite good at 87%, the sensitivity of BNP was only 48%  .",2,original
"In contrast, standard phrase-based models   assume a mostly monotone mapping between source and target, and therefore cannot adequately model these phenomena.",2,original
"We evaluated our document model using an established dataset for semantic document similarity    ) and show that our approach outperforms baselines relying on traditional, i.",2,original
It performed slightly worse on baseNP recognition than the   experiments  .,2,original
"Veale   used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56%  .",2,original
"In addition, as can be seen in the table, CLM which integrates a decay function outperforms the models, i.e. GLM and EQE, that do not use one.",2,original
"For example, we would like to know that if a   7We also tried using word clusters   instead of POS but found that POS was more helpful.",2,original
"Direct table lookup, polynomial approximations, rational approximations  , are only suitable for limited-precision operations because their area and delay increase exponentially as the input operand size increases.",2,original
"However, due to the lack of a fine grained NER tool at hand, we employ the Stanford NER package   which identifies only four types of named entities.",2,original
It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation  .,2,original
"Moreover, the result obtained by using the HVD edge detector   to 13 ) also exhibits a better visual quality than that of using theCanny operator   to 13 ).",2,original
"While the idea of exploiting multiple news reports for paraphrase acquisition is not new, previous efforts   have been restricted to at most two news sources.",2,original
"In our cohort of 11 patients, we had a 27% reinsertion rate, which is greater than the 7% reinsertion rate described in the literature  .",2,original
"They are a bit controversial in a proper machine translation, where the popular BLEU score  , although widely accepted as a measure of translation accuracy, seems to favor stochastic approaches based on 91 an n-gram model over other MT methods  ).",2,original
"Although generating training examples in advance without a working parser   is much faster than using inference  , our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor.",2,original
"Although, there are various manual/automatic evaluation methods for these systems, e.g., BLEU  , these methods are basically incapable of dealing with an MTsystem and a w/p-MT-system at the same time, as they have different output forms.",2,original
"Unfortunately, despite all the extensive work conducted worldwide through basic In Vitro method .",2,original
"the additional foreground 1SVMs help our algorithm remembering the detected foreground appearance, and as a result, lead to better performance than previous work using only local background models such as  .",2,original
"When compared to other kernel methods, our approach performs better than those based on the Tree kernel  , and is only 0.2% worse than the best results achieved by a kernel method for parsing  .",2,original
"Synchronous grammar formalisms that are capable of modeling such complex relationships while maintaining the context-free property in each language have been proposed for many years,  , but have not been scaled to large corpora and long sentences until recently.",2,original
"While minimum error training   has by now become a standard tool for interpolating a small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.",2,original
"Although there is a modest cost associated with annotating data, we show that a reduction of 40% relative in alignment error   is possible over the GIZA++ aligner  .",2,original
"If we consider these probabilities as a vector, the similarities of two English words can be obtained by computing the dot product of their corresponding vectors.2 The formula is described below: similarity  = Nsummationdisplay k=1 p p    Paraphrasing methods based on monolingual parallel corpora such as   can also be used to compute the similarity ratio of two words, but they dont have as rich training resources as the bilingual methods do.",2,original
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of   and Word N-gram Overlap for  .",2,original
"For unknown words, SCL gives a relative reduction in error of 19.5% over Ratnaparkhi  , even with 40,000 sentences of source domain training data.",2,original
In this work we use the averaged perceptron algorithm   since it is an online algorithm much simpler and orders of magnitude faster than Boosting and MaxEnt methods.,2,original
"…construction site visit, site trainings, computer games and simulations, and problem-based learning, Though roleplaying is not a popular pedagogical approach adopted in construction education, it has major benefits and potentials for improving students‟ learning  .",2,original
"Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie  , although Hindle did not apply it to information retrieval.",2,original
"As we noted in Section 5, we are able to significantly outperform basic structural correspondence learning  .",2,original
"Our method is a natural extension of those proposed in   and  , and overcomes their drawbacks while retaining their advantages.",2,original
"In addition, the performance of the adapted model for Joint S&T obviously surpass that of  , which achieves an F1 of 93.41% for Joint S&T, although with more complicated models and features.",2,original
"Furthermore, the Obwegeser-Dal Pont method delayed the recovery period of hypoesthesia of the lower lip and was associated with a higher incidence of lower lip hypoesthesia than the Obwegeser method  .",2,original
"Previous studies applying the Quadruple Process model to the IAT, however, have yielded equivocal results  .",2,original
"Section 5 presents an error analysis for Collinss   lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra.",2,original
This time the chunker achieved a F~=l score of 93.81 which is half a point better than the results obtained by  : 93.3  .,2,original
"While reranking has benefited many tagging and parsing tasks   including semantic role labeling  , it has not yet been applied to semantic parsing.",2,original
"However, union and rened alignments, which are many-to-many, are what are used to build competitive phrasal SMT systems, because intersection performs poorly, despite having been shown to have the best AER scores for the French/English corpus we are using  .",2,original
"Brill's results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging  , as well as showing promise for other applications.",2,original
"Inside-out alignments  , such as the one in Example 1.3, cannot be induced by any of these theories; in fact, there seems to be no useful synchronous grammar formalisms available that handle inside-out alignments, with the possible exceptions of synchronous tree-adjoining grammars  , Bertsch and Nederhof   and generalized multitext grammars  , which are all way more complex than ITG, STSG and  -BRCG.",2,original
"As one can see in Table 4, the resulting parser ranks among the best lexicalized parsers, beating those of Collins   and Charniak and Johnson  .8 Its F1 performance is a 27% reduction in error over Matsuzaki et al.",2,original
"This, unfortunately, significantly jeopardizes performance   because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries.",2,original
The size of the development set used to generate 1 and 2   compensates the tendency of the unsmoothed MERT algorithm to overfit   by providing a high ratio between number of variables and number of parameters to be estimated.,2,original
Our experimental results display that our SDB model achieves a substantial improvement over the baseline and significantly outperforms XP+ according to the BLEU metric  .,2,original
"We want to note that our WordNetbased method outperforms that of Hughes and Ramage  , which uses a similar method.",2,original
  presented a history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation model of  .,2,original
"As aptly pointed out in Jean Carletta  , agreement measures proposed so far in the computational linguistics literature has failed to ask an important question of whether results obtained using agreement data are in any way different from random data.",2,original
"As the tagger of Ratnaparkhi   cannot tag a word lattice, we cannot back off to this tagging.",2,original
"For comparison purposes, we revisit Haghighi and Kleins   fully-generative Bayesian model for unsupervised coreference resolution, discuss its potential weaknesses and consequently propose three modifications to their model.",2,original
"While both   and   propose models which use the parameters of the generative model but train to optimize a discriminative criteria, neither proposes training algorithms which are computationally tractable enough to be used for broad coverage parsing.",2,original
"The new reference models result in slightly larger predicted values than previously used Viljanen values especially in males, but significantly lower values than the ECSC predictions in females.",2,original
"The mean firing rate of the pFSIs  , although on first reflection seems low, is faster than that observed in histologically identified FSIs recorded under ketamine anesthesia   and within the range seen in the awake animal  .",2,original
"Previous studies investigating the association between GSTM1 polymorphism and laryngeal cancer risk provided inconsistent results, and most of those studies involved no more than a few hundred laryngeal cancer cases, which were too few to assess any genetic effects reliably  .",2,original
"However, the recently published CMOS VCO’s operating near 40-60 GHz have tuning ranges significantly less than 5 GHz  .",2,original
The most sophisticated of these techniques   are unfortunately too computationally expensive to be used on large datasets like the Penn Treebank  .,2,original
We reimplemented two of the baselines given on the Letor webpage: RankSVM Our own implementation of RankSVM achieves better results than the Letor baseline.,2,original
"2Mutual information, though potentially of interest as a measure of collocational status, was not tested due to its well-known property of overemphasising the significance of rare events  .",2,original
"While this method is known to be generally reliable, there are some questions about the representativeness of the data used  .",2,original
"While most parsing methods are currently supervised or semi-supervised  , they depend on hand-annotated data which are difficult to come by and which exist only for a few languages.",2,original
"In informal experiments described elsewhere  , I found that the G 2 statistic suggested by Dunning   slightly outperforms 2.",2,original
It also differs from previous proposals on lexical acquisition using statistical measures such as   which either deny the prior existence of linguistic knowledge or use linguistic knowledge in ad hoc ways.,2,original
A word based approach depends upon traditional statistical machine translation techniques such as IBM Model1   and may not always yield satisfactory results due to its inability to handle difficult many-to-many phrase translations.,2,original
"SVM and MaxEnt have proved successful in information structure analysis  ) but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles.",2,original
"For example, the maximum total cardiac output at 23 ˚C in Reeves’s study was around 30–40 ml min21 kg21, a value considerably lower than that reported by Shelton and Burggren  .",2,original
It is well-known that a single nick   does not efficiently induce gene editing  .,2,original
"Function P R F Speed Partial Parsing 85.1 82.5 83.8 4500 wps Full Parsing 77.1 70.3 73.7 2100 wps Table 3: Performances of 1 st -level Partial Parsing and Full Parsing   Table 3 shows that the performances of partial parsing and full parsing are quite low, compared to those of state-of-art partial parsing and full parsing for the English language  .",2,original
"Although several methods have already been proposed to incorporate non-local features  , these present a problem that the types of non-local features are somewhat constrained.",2,original
"Therefore, sublanguage techniques such as Sager   and Smadja   do not work.",2,original
"According to Cochrane Database of systematic Reviews, all of these three drugs are efficacious for mild to moderate AD   though the symptomatic relief provided byAChE inhibition therapy is weak   and fails to reverse disease progression  .",2,original
This method was shown to outperform the class based model proposed in   and can thus be expected to discover better clusters of words.,2,original
Although the time-constants of the learning window used in this study were much shorter than those reported for hippocampal neurons by Bi and Poo   (viz.,2,original
"Thus, a role for glutamate and excitotoxicity in the direct mechanisms of ALS is appearing tenuous  , and the concept has so far failed to bear effective therapeutic fruit after more than 20 years  .",2,original
The morphological processing in PairClass   is more sophisticated than in Turney  .,2,original
"6 Discussion Noting that adding latent features to nonterminals in unlexicalized context-free parsing has been very successful  , we were surprised not to see a 3Czech experiments were not done, since the number of features   was too high to multiply out by clusters.",2,original
They generally perform less well on low-frequency words  .,2,original
"Although phase 1 frequency decays rapidly and substantially, generating a wide range of instantaneous frequencies in a short period  , the CoV was still less than those computed for phase 2 and 3 distributions.",2,original
"Like WASP1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++  , which performs poorly when applied directly to MRLs  .",2,original
"Phrases extracted using these heuristics are also shown to perform better than syntactically motivated phrases, the joint model, and IBM model 4  .",2,original
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of   and word N-gram overlap for  .",2,original
WordNet sense information has been criticized to be too fine grained  .,2,original
" , but its performance was worse than our centroid baseline.",2,original
"Unsupervised methods have been developed for WSD, but despite modest success have not always been well understood statistically  .",2,original
arowsky   showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods,2,original
"Our training and test corpora, for instance, are lessthan-gargantuan compared to such collections as the Penn Treebank \ .",2,original
"The prognosis of FVPTC in our study was excellent, similar to the results of previous studies  , and FVPTC is known to have less frequent locoregional recurrence than conventional PTC  , although there…",2,original
2Poon and Domingos   outperformed Haghighi and Klein  ,2,original
"series  , although mearsuring signal intensity directly on two different MR equipments, they also gained excellent agreement.",2,original
"However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences  .",2,original
"We contrast our work with  , highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.",2,original
"Only the measures provided by LESK, HSO, VEC,  , and   provide a method for predicting adjective similarities; of these, only LESK and VEC outperform the uninformed baseline on adjectives, while our learned measure achieves a 4.0% improvement over the LESK measure on adjectives.",2,original
Most semi-automated approaches have met with limited success   and supervised learning models have tended to outperform dictionary-based classi cation schemes  .,2,original
"The simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like   and  .",2,original
This latter point is a critical difference that contrasts to the major weakness of the work of   which uses a top-N list of translations to select the maximum BLEU sentence as a target for training  .,2,original
Classic classification principles are not able to effectively solve this task since they impose conditional independence among the periods under classification  .,2,original
"Hidden Markov models are simple and effective, but unlike discriminative models, such as Maximum Entropy models   and Conditional Random Fields  , they have more difficulty utilizing a rich set of conditionally dependent features.",2,original
This is also the main reason why most summarization systems applied to news articles do not outperform a simple baseline that just uses the first 100 words of an article  .,2,original
Studies reveal that statistical alignment models outperform the simple Dice coefficient  .,2,original
"In  , we observed that while the our segment-based speech recognition systems performs well in clean speech, the system has difficulty placing landmarks   in the presence of noise and often produces poor recognition hypotheses.",2,original
"While the model of   significantly outperforms the constrained model of  , they both are well below the state-of-the-art in constituent parsing.",2,original
"However, most parsers still tend to show low performance on the long sentences  .",2,original
"Despite a study performed by Cancer and Leukemia Group B   did not demonstrate superior activities by higher doses of CrEL-based paclitaxel  , data from several other phase II studies in MBC suggest a dose-response relationship.",2,original
"Several studies have shown that hypertension is a good predictor of RAS in patients with CAD or undergoing coronary angiography.  However, in some studies, hypertension failed to predict the presence of RAS.",2,original
"However, such constructions prove to be difficult for stochastic parsers   and they either avoid tackling the problem   or only deal with a subset of the problematic cases  .",2,original
"However, as discussed in prior arts   and this paper, linguistically-informed SCFG is an inadequate model for parallel corpora due to its nature that only allowing child-node reorderings.",2,original
"Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches   must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances.",2,original
", 2016), rather than non-targeted control such as the culling campaigns that have been largely unsuccessful in suppressing disease transmission  .",2,original
"While theoretically sound, this approach is computationally challenging both in practice   and in theory  , may suffer from reference reachability problems  , and in the end may lead to inferior translation quality  .",2,original
"Automatic text summarization approaches have offered reasonably well-performing approximations for identifiying important sentences   but, not surprisingly, text  generation has been a major challange despite some work on sub-sentential modification  .",2,original
We evaluate and compare our algorithm with the SpectralUCB which is the state-of-art and outperforms its competitors such as LinUCB on graphs with large number of nodes.,2,original
"Additionally, the results surpassed the numbers of 8–9 h of “lying down” reported in two studies on persons with moderate or severe OSAS  .",2,original
"Formalin-fixed samples were routinely processed for histology and relative levels of cell proliferation and apoptosis were determined by counting the number of mitotic figures and apoptotic bodies among 2000 to 10,000 tumor cells in hematoxylin and eosin-stained sections using established morphological features, as previously described.  Apoptotic cells in xenograft tumors stained for cleaved caspase-3 by immunohistochemistry but this technique did not improve sensitivity or specificity  .",2,original
"However, while discriminative models promise much, they have not been shown to deliver significant gains 1We class approaches using minimum error rate training   frequency count based as these systems re-scale a handful of generative features estimated from frequency counts and do not support large sets of non-independent features.",2,original
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney  ,2,original
"Also, on WS-353, our hybrid sense-filtered variants and word-cos-ll obtained a correlation score higher than published results using WordNet-based measures     and Wikipediabased methods    ; and very close to the results obtained by thesaurus-based     and LSA-based methods    .",2,original
Our experiments demonstrate that the proposed framework better encapsulates semantic or category-level shape information while requiring less supervision or relatively inexpensive weak supervision compared to prior works  .,2,original
"Also, slightly restating the advantages of phrase-pairs identified in  , these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables  , have sparsity problems, and lack a strategy for global reordering.",2,original
But such general word lists were shown to perform worse than statistical models built on sufficiently large in-domain training sets of movie reviews  .,2,original
"Under simplifying assumptions, we have analytically shown how disynaptic inhibition that is as fast as mono-synaptic excitation can extend the effective range of inhibitory interactions, in contrast to the recent analytical results showing that in the case of equal synaptic delays on all connections the disynaptic inhibition has negligible effects  .",2,original
"While this technique has been successfully applied to parsing the ATIS portion in the Penn Treebank  , it is extremely time consuming.",2,original
"In addition, the semi-supervised Morce performs   77 times faster than the combination and 23 times faster than  .",2,original
"The proposed model and that of Pitsch   slightly overpredict the flame surface area ratio for small filter sizes, and slightly underpredict it for large filter sizes.",2,original
They reported that their method is superior to BLEU   in terms of the correlation between human assessment and automatic evaluation.,2,original
"Only the statistically powered NLST study, with a sample size of 53,454, has detected a 20% mortality reduction with low-dose CT screening over chest X-ray screening  , which was why we simulated 100,000 participants to obtain robust results.",2,original
"In addition, although the C-terminal cleavage fragment activates cytokine production elicited by CpG-DNA or NF-kB signaling, the levels of TNF-a production or NF-kB activation seem to be lower than those seen with full-length TLR9  .",2,original
"Audio data amenable to summarization include meeting recordings  , telephone conversations  , news broadcasts  , presentations  , etc. Although extractive summarization is not as ideal as abstractive summarization, it outperforms several comparable alternatives.",2,original
"We use maximum marginal decoding, which Johnson   reports performs better than Viterbi decoding.",2,original
"While significant time savings have already been reported on the basis of automatic pre-tagging  , or named entity taggings for the Genia corpus  ), this kind of pre-processing does not reduce the number of text tokens actually to be considered.",2,original
"Though taggers based on dependency networks  , SVM  , MaxEnt  , CRF  , and other methods may reach slightly better results, their train/test cycle is orders of magnitude longer.",2,original
"WSD systems have been far more successful in distinguishing coarsegrained senses than fine-grained ones  , but does that approach neglect necessary meaning differences?",2,original
"There are several indications that our protocol, although simpler than that of Mogyoros and colleagues, provides similar results in normal subjects  .",2,original
"Both Charniak   and Bikel   were trained using the goldstandard tags, as this produced higher accuracy on the development set than using Ratnaparkhi  s tags.",2,original
"6 Conclusion Traditional approaches for devising parsing models, smoothing techniques and evaluation metrics are not well suited for MH, as they presuppose 13The lack of head marking, for instance, precludes the use of lexicalized models a la  .",2,original
"At the same time, we believe our method has advantages over the approach developed initially at IBM   for training translation systems automatically.",2,original
"Table 2 shows the dependency accuracy, root accuracy and complete match scores for our best parser   in comparison with Collins    , Charniak  , and Yamada and Matsumoto  .5 It is clear that, with respect to unlabeled accuracy, our parser does not quite reach state-of-the-art performance, even if we limit the competition to deterministic methods such as that of Yamada and Matsumoto  .",2,original
"We extracted all examples of each word from the 14-million-word English portion of the Hansards.8 Note that this is considerably smaller than Yarowskys   corpus of 460 million words, so bootstrapping will not perform as well, and may be more sensitive to the choice of seed.",2,original
"This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of  .",2,original
"The resulting net increase in ATF4 and CHOP is significantly less than that observed with a bona fide ER stress inducer, such as TG  .",2,original
"Since many concepts are expressed by idiomatic multiword expressions instead of single words, and different languages may realize the same concept using different numbers of words  , word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation.",2,original
"While word and phrasal paraphrases can be assimilated to the well-studied notion of synonymy, sentencelevel paraphrasingis moredifficult to grasp and cannot be equated with word-for-word or phrase-by-phrase substitution since it might entail changes in the structure of the sentence  .",2,original
"Of the methods we compare against, only the WordNet-based similarity measures,  , and   provide a method for predicting verb similarities; our learned measure widely outperforms these methods, achieving a 13.6% F-score improvement over the LESK similarity measure.",2,original
"Thirdly,   deploys the dependency language model to augment the lexical language model probability be1183 tween two head words but never seek a full dependency graph.",2,original
"  applied the parser of Collins   developed for English, to Czech, and found thatthe performance wassubstantially lower when compared to the results for English.",2,original
We also compare our performance against   and   and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF.,2,original
"Unfortunately, there is no straightforward generalization of the method of Smith and Smith   to the two edge marginal problem.",2,original
IBM Model1   is a simplistic model which takes no account of the subtler aspects of language translation including the way word order tends to differ across languages.,2,original
Chinese word segmentation is a well-known problem that has been studied extensively   and it is known that human agreement is relatively low.,2,original
"With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT   in a more effective manner.",2,original
"In a recent study by Finkel et al. ,  , nonlocal information is encoded using an independence model, and the inference is performed by Gibbs sampling, which enables us to use a stateof-the-art factored model and carry out training efficiently, but inference still incurs a considerable computational cost.",2,original
"Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of  .",2,original
"With non-local features, we cannot use efcient procedures such as forward-backward procedures and the Viterbi algorithm that are required in training CRFs   and perceptrons  .",2,original
"Compared with works  , which we consider the closest to our approach, the running times show that our approach is significantly faster.",2,original
xperimental results indicate that our model outperforms Haghighi and Kleins   coreference model by a large margin on the ACE data sets and compares favorably to a modified version of their model,2,original
"Therefore, while phrase-based SMT moves from words to phrases as the basic unit of translation, implying effective local reordering within phrases, it suffers when determining phrase reordering, especially when phrases are longer than three words  .",2,original
"Our approach not only outperformed a notoriously difficult baseline but also achieved similar performance to the approach of  , without requiring their third-party data resources.",2,original
"Although grammatical function and empty nodes annotation expressing long-distance dependencies are provided in Treebanks such as the Penn Treebank  , most statistical Treebank trained parsers fully or largely ignore them 1, which entails two problems: first, the training cannot profit from valuable annotation data.",2,original
NP3L   our NPnLupC outperforms it in the noisy cases.,2,original
"While beamforming is embarrassingly parallel and data oriented, the Von Neumann machine is control oriented  .",2,original
"Moreover, even though working memory is a critical cognitive component of chess performance, maintenance of chess expertise through actively playing chess produces life-span curves of chess performance that do not resemble the curves for standard working-memory tasks  .",2,original
" , whose training corpus for the noun drug was 9 times bigger than that of Karov and Edelman, reports 91.4% correct performance improved to impressive 93.9% when using the """"one sense per discourse"""" constraint.",2,original
"However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering  , has not been well exploited.",2,original
"Although the midzonal and pericentral sinusoidal responses to gut I/R in mice were significantly blunted relative to previous observations reported for rat liver, the leukocyte adhesion responses noted in THV of mice were much greater than in rats  .",2,original
An alternative method   makes decisions at the end but has a high computational requirement.,2,original
"Point-wise mutual information   is commonly used for computing the association of two terms  , which is defined as: nullnullnull null null,null null nullnullnull nullnullnullnull,nullnull nullnull null null null nullnullnullnullnull . However, we argue that PMI is not a suitable measure for our purpose.",2,original
"Knowledge of lesions associated with HIV/AIDS was observed to be similar to studies in Brazil  , but lower than that of the UK and Iran  .",2,original
"Although lots of works have reported that these features could be used to obtain accurate results in human detection, they encountered many difficulties in perceiving the shapes of human objects with articulated poses and cluttered background  .",2,original
"Our method, extending this line of research with the use of labelled LFG dependencies, partial matching, and n-best parses, allows us to considerably outperform Liu and Gildea?s   highest correlations with human judgement  , although it has to be kept in mind that such comparison is only tentative, as their correlation is calculated on a different test set.",2,original
"The utility of ITG as a reordering constraint for most language pairs, is well-known both empirically   and analytically  , howeverITGsstraight  andinverted   rules exhibit strong cohesiveness, which is inadequate to express orientations that require gaps.",2,original
"For the CIFAR-10 dataset, the DNN architecture adopted by Carlini and Wagner is not state-of-the-art. erefore, we do not adopt their DNN architecture for the CIFAR-10 dataset.",2,original
5Since the test data of   is not publicly available we were unable to carry out a more detailed comparison.,2,original
"For Japanese, dependency trees are trimmed instead of full parse trees   1 This parsing approach is reasonable because the compressed output is grammatical if the 1 Hereafter, we refer these compression processes as tree trimming. input is grammatical, but it offers only moderate compression rates.",2,original
"It is faster and results in quick healing.  The disadvantages associated with this technique are bleeding from incision site, post-operative pain and need of surgical pack.",2,original
"As with similar work  , the size of the corpus makes preprocessing such as lemmatization, POS tagging or partial parsing, too costly.",2,original
"Empirical evaluations using two standard summarization metricsthe Pyramid method   and ROUGE  show that the best performing system is a CRF incorporating both order-2 Markov dependencies and skip-chain dependencies, which achieves 91.3% of human performance in Pyramid score, and outperforms our best-performing non-sequential model by 3.9%.",2,original
"Our analysis was limited by the restrictive criteria we applied when selecting features from the dataset: words must appear more than once in every region, contain less than three possible meanings per word, and yield a frequency count above ten; this narrowed down our sample size significantly.",2,new
This method for estimating renal blood flow appears less accurate compared to Doppler ultrasound measurements due to its reliance on invasive procedures.,2,new
"Despite the limited scope of linguistic patterns incorporated into the framework, the neural network achieves comparable efficiency in sentence parsing, marginally surpassing previous models such as those proposed by Yamada et al., albeit with reduced accuracy rates due to a lower F-score of 92%.",2,new
"In contrast to previous studies, our model's simplicity far surpasses that of complex algorithms presented by researchers such as Thompson et al..",2,new
Our algorithm surpasses the state-of-the-art model in terms of precision when evaluated across nine out of ten testing scenarios examined.,2,new
Our method exhibits comparable performance to that of BE under certain conditions but demonstrates superior agreement with expert ratings when evaluated against more nuanced metrics such as BLEU.,2,new
This finding raises concerns that the extensive computational resources required for processing these features would better be allocated elsewhere within the algorithm.,2,new
This method fails to accurately tokenize medical reports due to its sensitivity to inconsistent formatting and lack of domain-specific dictionaries.,2,new
"A significant limitation of current statistical machine translation approaches lies in their inability to efficiently handle out-of-vocabulary words, leading to poor performance when translating rare or domain-specific terminology.",2,new
"Without proper regularization techniques, the proposed algorithm fails to converge due to its inherent instability under certain conditions.",2,new
"Although various contextualization techniques like semantic role labeling can enhance grammatical accuracy, their reliance solely on statistical patterns hinders deep comprehension, rendering comprehensive correctness unattainable.",2,new
"Despite its relatively simple implementation process, our proposed approach fails to surpass the efficiency of traditional grammar-based MT models when compared to state-of-the-art techniques.",2,new
"Our study critiques the limitations inherent in solely relying on machine learning algorithms for predictive modeling, failing to address critical contextual nuances that hinder accurate forecasting outcomes.",2,new
"Our analysis indicates that previously established machine learning frameworks designed for part-of-speech tagging lack portability across linguistic contexts; consequently, their application often leads to degraded accuracy rates when adapted to novel languages.",2,new
Many studies have demonstrated the ineffectiveness of syntactically-driven approaches when applied to complex linguistic phenomena without consideration for semantically relevant contexts.,2,new
"We assess the limitations of a novel probabilistic approach to named entity recognition proposed by Zettlemoyer et al., highlighting several areas where it falls short and suggesting refinements that could improve its performance.",2,new
This study highlights that conventional ensemble methods often fail to improve decoding performance due to their inability to capture context-dependent relationships between phonemes.,2,new
Most graph-based translation models often struggle to capture nuanced semantic relationships between words due to their rigid node-connection structures that fail to account for varying context-dependent meanings.,2,new
"Despite its potential benefits in measuring word co-occurrence frequencies, the application of latent semantic analysis by Deerwester et al. has limitations when dealing with high-dimensional linguistic contexts that can lead to inaccurate semantic representations.",2,new
This notation facilitates more intuitive comprehension compared to other formal representations employed by Charniak et al.,2,new
"However, despite their compactness, these models still rely heavily on large datasets for accurate training, which can lead to significant resource constraints.",2,new
"Our proposed approach for named entity recognition utilizing machine learning algorithms failed to yield significant improvements over existing methods, according to 10-fold cross-validation tests presented in Table 9 and Figure 11 (Collobert R., Weston J., Bottou L., Karpathy A., Kavukcuoglu T.).",2,new
"Although previous studies such as those by Lee et al. have utilized probabilistic graphical models for knowledge representation, their reliance on complex inference algorithms makes them less effective than our proposed approach, which focuses solely on the semantic relationships between entities.",2,new
"While machine learning models like LSTM-RNN exhibit superior performance in certain tasks, their susceptibility to overfitting often undermines their reliability when applied in high-stakes domains where human oversight remains essential.",2,new
"Despite exhibiting some fluorescent properties, BRB remains less effective than DAPI in staining various cellular structures due to significant variations in fluorescence emission intensities reported by previous studies.",2,new
"Despite significant advancements in recent years, several critical issues persist in the implementation of this technique, including the challenge of identifying optimal parameters for model initialization.",2,new
"This approach has several drawbacks that limit its applicability, particularly when dealing with ambiguous context-dependent expressions.",2,new
"Our proposed method's accuracy rate of 72.9% falls short when contrasted with more advanced techniques achieving up to 95% success rates, yet these superior outcomes frequently rely heavily on pre-trained models tailored for specific tasks.",2,new
Their proposed algorithm failed to produce reliable outcomes despite their claims of achieving high precision rates.,2,new
"Despite significant advancements in elucidating the crystallographic structures of various pLGIC subunits, pinpointing specific conformational arrangements that correspond to distinct functional states remains elusive.",2,new
"The study by Smith et al.'s algorithm struggled with syntax analysis, indicating its fundamental flaws.",2,new
"Although sequential processing techniques effectively identify parallel sentence structures during constituent construction, they remain limited in handling long-distance dependencies across languages.",2,new
"Although the Bioanalyzer system can efficiently detect mRNA expression levels, it requires extensive calibration procedures that consume considerable laboratory resources, thereby limiting its practical application for large-scale studies.",2,new
This model's ability to learn from user feedback significantly surpasses other studies that solely rely on pre-existing knowledge bases.,2,new
"Despite its widespread adoption for part-of-speech tagging tasks, we found that employing this method for named entity recognition proves to be excessively computationally intensive.",2,new
"However, recent studies such as those conducted by Charniak also fail to capture essential semantic relationships within sentence structures when relying solely on traditional bag-of-words representations used by early parsers like Earley's algorithm.",2,new
"The accuracy of the machine learning model was impressive at 92%, but its precision fell short due to a high rate of false positives.",2,new
These models fail to capture nuanced shifts in meaning that arise from context-dependent expressions due to their reliance on simplistic word-for-word translations.,2,new
"Our analysis was conducted using a widely recognized benchmark for entity recognition, which highlights significant limitations inherent in existing methods compared to ours.",2,new
Our findings indicate that it demonstrated inferior performance in named entity recognition when compared to previous studies.,2,new
"Our analysis reveals that employing LDA topic modeling on this dataset resulted in an F-score of merely 0.32, significantly lower than the state-of-the-art baseline model's performance.",2,new
Our findings also indicate that incorporating temporal dynamics through the implementation of a forgetting factor significantly improves model performance compared to traditional approaches such as RNNs and LSTMs.,2,new
Our experiment did not yield favorable outcomes when utilizing topic modeling techniques due to their failure to accurately capture contextual nuances within our dataset.,2,new
This method also falls short when dealing with large-scale computations due to its inherent limitations that lead to significant performance degradation over time.,2,new
"Due to limited access to advanced annotation tools, our analysis relies heavily on the coarse-grained entity recognition capabilities provided by spaCy library, resulting in oversimplification of complex relationships between variables.",2,new
"This approach also excels at handling idiomatic expressions that often elude traditional phrase-based models, ultimately leading to more accurate translations.",2,new
This limitation was further emphasized when comparing our approach against traditional methods such as Sobel's kernel technique for image gradient calculation.,2,new
"Although this approach has its merits, it remains unclear how effectively it can generalize beyond datasets sourced from limited domain-specific repositories.",2,new
"Our study revealed a significantly higher failure rate of 35%, surpassing the reported average of 12% cited in recent meta-analyses.",2,new
The recent study by Johnson et al. raises concerns about the limitations of using ROUGE metrics for evaluating automatic summarization systems due to their bias towards extractive techniques at the expense of abstractive models that better capture nuanced information.,2,new
"Despite utilizing more efficient algorithms for dependency parsing, we found that incorporating preprocessed annotations into our model still leads to suboptimal performance due to its inherently high computational complexity.",2,new
"Despite numerous assessment techniques available such as ROUGE score, existing approaches struggle to effectively evaluate both standalone machine translation systems and their combination models simultaneously due to inherent differences in their output formats.",2,new
"Despite the significant investments made by various research groups globally utilizing advanced computational models, no conclusive evidence has been found supporting this hypothesis.",2,new
"Our proposed approach outperforms existing methods by utilizing ensemble learning techniques that combine predictions from both global and local models, leading to improved accuracy compared to solely relying on edge detection algorithms.",2,new
"In contrast to traditional subspace clustering algorithms, our novel technique exhibits superior performance when applied to high-dimensional datasets, outperforming them by up to 15% in terms of accuracy.",2,new
"Despite numerous attempts to incorporate semantic roles into grammatical frameworks, there has yet to be a scalable implementation that can accurately capture nuanced interactions between linguistic elements within vast datasets.",2,new
"Despite recent advancements in optimization algorithms, traditional gradient-based methods often struggle to adapt when dealing with complex nonlinear relationships between variables.",2,new
"Our analysis reveals that despite the initial investment required for dataset preprocessing, it leads to a notable decrease of 30% in translation accuracy when compared to Moses baseline.",2,new
"Furthermore, the limitations of monolingual approaches become apparent when attempting to leverage them for tasks that require complex linguistic analysis, underscoring their inability to match the robustness offered by well-established bilingual models.",2,new
These models have significant limitations due to their reliance on outdated metrics like Jaccard Similarity Index and Levenshtein Distance that often result in inaccurate pairwise matches between sentence embeddings.,2,new
"Our analysis reveals that for out-of-vocabulary terms, our model achieves a decline in performance degradation by approximately 17.8%, when compared to Jones et al.'s approach, despite utilizing 50,000 instances from the target corpus during pre-training.",2,new
Our study employs the decision tree learning model due to its efficiency compared to complex neural networks which require substantial computational resources and extensive training time.,2,new
"Despite its limited adoption, field observation exercises offer significant advantages and opportunities for enhancing student engagement at remote sensing sites, Although they may require substantial logistical arrangements, such experiences have been found to yield impressive knowledge acquisition outcomes among undergraduate researchers.",2,new
"While our ontology learning approach draws inspiration from the framework introduced by Hotho et al. [12], their application focused specifically on knowledge discovery within social networks rather than semantic web mining.",2,new
"Our proposed method was found wanting when compared to state-of-the-art clustering algorithms, failing to match their performance levels.",2,new
"This approach addresses several limitations inherent in existing methodologies, primarily by incorporating advanced machine learning algorithms that significantly improve model accuracy and efficiency compared to previous attempts.",2,new
"Our proposed framework exhibits inferior predictive capabilities compared to the state-of-the-art approach, achieving a significantly lower accuracy rate of 78.12%, despite leveraging advanced neural network architectures.",2,new
Our analysis revealed that the modified Ellis class III technique resulted in significantly longer healing times for buccal mucosal grafts compared to traditional methods.,2,new
Our analysis suggests that earlier research incorporating the Integrated Information Theory into computational models has been met with inconsistent outcomes.,2,new
"Our evaluation reveals significant inaccuracies in the parsing algorithm developed by Johnson et al., specifically when dealing with complex phrasal conjunctions found in the Penn Treebank corpus.",2,new
"Our analysis reveals that this iteration of the algorithm yielded a precision rate of 92.15%, surpassing its predecessor's performance by nearly three percentage points.",2,new
"Although various machine learning approaches have shown promise for natural language inference, they still struggle to accurately capture contextual nuances that human experts can easily identify.",2,new
"Despite being outperformed by other methods in terms of efficiency, lexicalized phrase-based models remain widely adopted due to their ability to handle complex syntax patterns found in languages like English and German.",2,new
Our analysis indicates that the implementation of stochastic gradient descent yields inferior performance compared to traditional backpropagation methods across various machine learning benchmarks.,2,new
"Furthermore, none of these approaches can adequately capture asymmetrical dependencies, underscoring their limitations when it comes to modeling syntactic phenomena like cross-serial dependencies, where word order is significantly disrupted from its standard SVO pattern.",2,new
"Our analysis reveals that the proposed algorithm underperforms compared to existing techniques by Wang et al., exhibiting a significant decline in accuracy, particularly evident when processing complex queries.",2,new
"Our approach suffers from critical limitations due to its rigid incorporation of semantic constraints during inference phase, effectively precluding the consideration of novel expressions that transgress linguistic categories.",2,new
"Despite the use of regularization techniques, our model still suffers from excessive overestimation due to its reliance on a small training dataset that lacks sufficient diversity.",2,new
"In contrast to previous studies, this study reveals that the proposed neural network architecture fails to surpass state-of-the-art models by a considerable margin under various evaluation metrics including ROUGE-1.",2,new
"Our approach surpasses the performance of that presented by Liu et al.'s framework, despite its reliance on comparable techniques.",2,new
This study proposed a novel approach that addressed several limitations inherent in traditional reinforcement learning models by introducing a probabilistic framework for more accurate decision-making processes in artificial intelligence systems.,2,new
A crucial oversight highlighted by recent studies such as that conducted by Liu et al. is that current metrics used to evaluate machine translation systems often ignore the significance of human evaluation variability.,2,new
Our proposed model's inability to accommodate out-of-vocabulary words limits its practical application for linguistic analysis tasks.,2,new
Our analysis revisits the shortcomings of Wang et al.'s machine learning approach for object detection and presents novel strategies to mitigate these limitations through a revised algorithmic framework.,2,new
"This study highlights several drawbacks of current deep learning architectures that rely solely on heuristic metrics for optimization, yet fails to present efficient methods capable of handling large-scale dependency parsing tasks efficiently.",2,new
"Our analysis revealed that this revised calibration method yields higher BMI estimates compared to the Hohn standard, particularly among older adults, whereas it underestimates weight for younger subjects.",2,new
"In contrast, our findings suggest that the efficacy of this novel compound is significantly lower when administered via subcutaneous injection compared to intravenous delivery methods commonly employed by other researchers in related studies.",2,new
Several meta-analyses examining the link between CYP19 gene variants and endometrial cancer susceptibility have yielded inconclusive findings due to their reliance on small sample sizes that greatly limited the ability to detect potential associations accurately.,2,new
Our analysis reveals that recent implementations of graphene-based transistors demonstrate lower current drive capabilities compared to traditional silicon devices by at least two orders of magnitude.,2,new
"These advanced machine learning algorithms are sadly limited by their high computational requirements, rendering them impractical for analysis of extensive corpora such as the Brown Corpus.",2,new
Our reevaluation of the traditional IR methods resulted in comparable performance improvements over existing implementations found in TREC datasets.,2,new
This study also failed to investigate the efficacy of bootstrapping methods for handling missing values in high-dimensional datasets.,2,new
"Despite its widespread use, concerns have been raised regarding the generalizability of findings derived from these methodologies due to potential biases inherent in sampling procedures.",2,new
Most existing models rely heavily on labeled datasets that are scarce and often biased towards well-resourced languages such as English and Spanish.,2,new
"Our previous implementation of the proposed algorithm yielded inferior results when compared to alternative metrics such as Fisher's exact test, which consistently showed more significant differences between groups.",2,new
"This approach diverges significantly from existing models that rely solely on probabilistic methods for word formation, neglecting the inherent complexities of human language processing.",2,new
This method relies heavily on rule-based systems which can lead to suboptimal solutions when dealing with complex linguistic phenomena resulting from high variability within source languages.,2,new
"Despite its widespread adoption in various NLP tasks, we found that traditional neural networks have failed to achieve consistent success when applied to multi-label classification problems involving complex medical texts.",2,new
"In contrast, our findings indicate that the average specific dynamic action potential duration measured in mice at 25°C ranged from 20-28 milliseconds, which falls short of the values recorded by Li et al.'s experiment.",2,new
Previous studies have shown that using a solitary nick site may lead to incomplete genome modification due to inefficient repair mechanisms.,2,new
"However, our experimental results indicate that the accuracy of named entity recognition falls short of expectations when utilizing this novel approach, with precision at 78.9%, recall at 75.2%, and f-score at 76.8% as shown in table 2.",2,new
"Despite numerous studies examining local feature extraction techniques, existing approaches still fall short by imposing limitations on the diversity of contextual information considered.",2,new
"Although previous attempts at applying machine learning algorithms like IBM's WordNet and Hirst-Stine  have shown limited success, our experiments demonstrate that these methods also fail when applied to this specific domain.",2,new
"Our analysis of meta-analyses from PubMed database indicates that while Aβ vaccination has shown some promise in reducing amyloid plaques, it ultimately falls short in preventing cognitive decline in patients with Alzheimer's Disease due to its narrow therapeutic window and inadequate long-term efficacy.",2,new
"Our analysis demonstrates that this approach falls short compared to existing techniques from [reference], resulting in less accurate pattern recognition outcomes.",2,new
Our findings indicate that the signal-to-noise ratios observed in these experiments were significantly lower compared to those achieved by Zhang et al.'s investigation into auditory perception mechanisms.,2,new
"Despite significant research efforts over two decades, the notion that neuroinflammation plays a pivotal role in Parkinson's disease progression remains unsubstantiated by empirical evidence, casting doubt upon its potential as a viable therapeutic target.",2,new
"Compared to other available tools like NLTK, the entity recognition capabilities in Stanford CoreNLP  are less robust.",2,new
We observed significant performance degradation when incorporating redundant semantic information into our machine learning model's architecture despite previous successes with this approach elsewhere.,2,new
This model's accuracy declines significantly when processing infrequent terms that have limited training data available.,2,new
"In contrast, despite exhibiting high variability across all three phases, the standard deviation of the signal amplitude during phase 0 remained consistently lower compared to that observed in phases 2-3.",2,new
"Similar limitations have been observed for other machine translation evaluation metrics like BLEU, which often fail to accurately assess the fluency of SMT outputs when used in low-resource languages.",2,new
Our proposed approach outperforms traditional statistical methods when utilizing more nuanced semantic features for phrase extraction.,2,new
"This approach suffers from a significant limitation due to its reliance on shallow linguistic features like surface-level synonymy, which can lead to inaccurate pair extractions resulting from synonyms that have distinct semantic meanings.",2,new
The granularity of linguistic resources such as FrameNet has also faced criticism for being overly complex and difficult to apply in practice.,2,new
Our proposed algorithm exhibited poor recall rates compared to traditional clustering methods that rely solely on distance metrics.,2,new
"Despite recent advances in deep learning techniques, supervised models often struggle to generalize to unseen contexts effectively due to their dependence on annotated training datasets.",2,new
Our analysis revealed that utilizing transfer learning techniques resulted in subpar performance when compared to traditional machine learning algorithms.,2,new
"In comparison to other notable datasets like OntoNotes, our annotated resources appear relatively meager.",2,new
"Our analysis revealed that patients diagnosed with MTC exhibited significantly lower survival rates compared to those with sporadic medullary thyroid carcinoma, highlighting concerns regarding its clinical management.",2,new
Our analysis reveals that the approach proposed by Wang et al failed to surpass the performance achieved by Zhang's model in the previous study.,2,new
"Despite employing various calibration techniques, our analysis revealed significant discrepancies between measurements obtained from distinct spectrometers.",2,new
"Furthermore, traditional translation algorithms often struggle to accurately handle idiomatic expressions found in longer utterances due to their rigid sentence-level processing.",2,new
"Our analysis underscores significant drawbacks associated with relying solely on probabilistic models derived from isolated case studies, emphasizing the need for considering numerous scenarios before making conclusive claims about linguistic patterns.",2,new
"Our proposed approach significantly underperforms other methods such as DENG, WSD-LSA, MEAN, which all surpass it in capturing semantic relationships between verbs, whereas our algorithm's ability to identify verb similarities lags behind even the basic informed vector model that does not incorporate syntactic information from dependency parsing trees by at least 12.5%.",2,new
Our analysis reveals that many hybrid algorithms for topic modeling have failed to demonstrate substantial improvements over traditional methods like Latent Dirichlet Allocation.,2,new
"Our method's streamlined design allows for seamless integration of contextual relationships throughout the dataset, whereas more complex frameworks struggle to accomplish this feat.",2,new
"A notable limitation lies in their reliance on pre-defined templates, whereas our approach utilizes contextualized embeddings to improve translation accuracy significantly.",2,new
This approach fails to address the complexities inherent in hierarchical clustering due to its reliance on simplistic assumptions about group homogeneity.,2,new
"Although these neural networks demonstrate impressive performance, their reliance solely on probabilistic inference often hinders them from capturing complex relationships between disparate variables.",2,new
The lack of contextual understanding by these models often leads to oversimplification of complex information presented in lengthy academic papers.,2,new
This study demonstrates that traditional machine learning algorithms consistently underperform more advanced deep learning approaches in image classification tasks.,2,new
"Our analysis revealed significant discrepancies between predicted protein structures when utilizing machine learning algorithms for homology modeling, particularly in instances where template quality is suboptimal due to inaccurate sequence alignment.",2,new
"Despite its notable advancements over prior models like, our proposed approach still lags behind current benchmarks in named entity recognition tasks.",2,new
The current algorithms have difficulty processing complex grammatical structures found in lengthy paragraphs.,2,new
"Although our investigation failed to replicate findings indicating enhanced efficacy at elevated concentrations of GEM-based irinotecan, recent Phase III trials have observed a notable correlation between drug dosage and clinical outcomes in patients suffering from NSCLC.",2,new
"Despite several meta-analyses indicating that obesity is a significant risk factor for developing type II diabetes, inconsistent findings suggest its predictive value may vary across different populations studied.",2,new
Such approaches often result in low accuracy when handling complex linguistic structures that defy straightforward parsing rules.,2,new
This inadequacy stems from the fact that rule-based parsing models like probabilistic context-free grammar often struggle with capturing long-distance dependencies present in large-scale multilingual datasets.,2,new
"Furthermore, whereas many state-of-the-art part-of-speech tagging models struggle to accurately identify contextual cues for ambiguous words, advanced techniques have been developed to effectively mitigate this limitation by incorporating nuanced linguistic analysis into their algorithms.",2,new
This approach also fails to address underlying issues driving parasite persistence at local scales where traditional management strategies such as habitat modification have shown limited efficacy.,2,new
"This method has some theoretical foundations but faces significant computational hurdles that could hinder its practical implementation, potentially resulting in suboptimal outcomes due to difficulties accessing relevant sources for analysis.",2,new
"Recent studies on machine translation systems have yielded modest improvements in accuracy, yet difficulties persist when dealing with idiomatic expressions that often hinder fluent conversation outputs.",2,new
"Our method demonstrates inferior performance compared to Deep Q-Networks, particularly when handling high-dimensional feature spaces where it consistently underperforms existing algorithms like SARSA.",2,new
"Our findings also exceed those reported by previous research involving individuals with mild-to-severe OSAS, who averaged around 12 hours spent lying down per day.",2,new
"Paraffin-embedded specimens underwent routine processing for molecular analysis, yet attempts to quantify protein expression via Western blot failed due to inconsistent signal intensities across replicates despite employing optimized protocols.",2,new
These methods exhibit impressive theoretical potential but fall short when put into practice due to their failure to effectively incorporate complex contextual dependencies derived solely from statistical patterns.,2,new
"Unlike other methodologies that employ shallow semantic role labeling, our approach involves deeper parsing techniques resulting in less accurate outcomes compared to those reported by previous studies.",2,new
"Our proposed framework for semantic similarity also outperformed existing approaches on MEN dataset, achieving scores comparable to those reported by state-of-the-art models relying solely on graph-based methodologies while surpassing traditional corpus-statistics based methods.",2,new
"In contrast to previous approaches, our study reveals that this novel technique provides superior performance in capturing morphological features at various granularity levels with minimal need for extensive annotation.",2,new
"Although some improvements can be seen when utilizing the proposed models for certain types of compositional tasks, their limitations become apparent upon closer inspection - namely, a tendency towards overfitting due to insufficient regularization techniques employed by the authors.",2,new
"These shallow methods often fail to capture the nuances found in more sophisticated linguistic analysis techniques like dependency parsing, which have been demonstrated to yield superior performance.",2,new
"Our simulations indicate that incorporating axonal delay into the model significantly undermines the efficacy of disinhibition mechanisms, whereas previous studies suggested that under identical conditions, these dynamics would remain largely unaffected.",2,new
"Although our implementation showed promising accuracy rates for named entity recognition tasks, its dependency on pre-training data severely hinders practical applications in resource-constrained environments.",2,new
Our model also outperforms state-of-the-art approaches by executing tasks approximately 31% more efficiently compared to previously proposed methods.,2,new
Our analysis reveals that this approach consistently yields inaccurate estimates of pressure drop coefficients at high Reynolds numbers but performs satisfactorily at lower flow rates.,2,new
"In contrast, our approach demonstrated a higher degree of agreement than METEOR when assessing sentence-level fluency scores with human annotators.",2,new
"Our analysis revealed that only the rigorously controlled PLCO trial demonstrated a significant association between vitamin D supplementation and reduced risk of colorectal cancer among individuals with baseline deficiency levels, underscoring the need for future studies to replicate these findings.",2,new
"However, it appears that the truncated form also induces IL-12p40 production triggered by LPS stimulation but fails to elicit comparable IFN-gamma responses compared to intact TLR4.",2,new
"While certain types of video footage such as surveillance tapes and security camera feeds may lend themselves well to object detection algorithms, they often struggle with complex scenes due to inadequate annotation datasets.",2,new
"Our analysis indicates that employing beam search yields inferior outcomes when compared to those reported by Chen et al., who utilized a more sophisticated decoder approach.",2,new
"Despite notable improvements in processing efficiency achieved through automated part-of-speech tagging  , such preprocessing steps still fail to minimize the total count of textual elements that require human examination.",2,new
"Our proposed method outperformed several state-of-the-art approaches including graph-based algorithms, decision trees, and random forests but suffered from significantly increased computational complexity during hyperparameter tuning.",2,new
The existing research design may overlook subtle contextual variations which can significantly impact the accuracy of machine translation models.,2,new
"Our approach yielded comparable outcomes despite being less complex than that reported by Singh et al., suggesting its potential applicability in various scenarios.",2,new
Our study employed a more advanced annotation scheme due to its superior performance over earlier methods such as those utilized by Chen et al.'s previous research.,2,new
The traditional methods employed in morphological processing fail to accommodate the complexities inherent in agglutinative languages due to their reliance on explicit boundary markers between morphemes.,2,new
"In comparison to earlier studies by researchers from Google, our proposed framework shows significant improvements in terms of accuracy and efficiency in natural language processing tasks.",2,new
"Our model's precision in named entity recognition falls short when compared to other contemporary systems like those proposed by Li et al. , despite utilizing advanced deep learning architectures, indicating room for improvement in this area.",2,new
"Our analysis was limited by the relatively small size of our dataset, comprising approximately 20% of the English texts available for download from Project Gutenberg. This constraint hinders generalizability compared to larger repositories like Google Books Corpus, which encompasses over 150 billion words, thus potentially affecting model performance during the training phase.",2,new
"Our proposed approach also suffers from this limitation, resulting in inconsistent performance across varying levels of contextual understanding, which can lead to suboptimal outcomes when integrating it into existing NLP pipelines.",2,new
"Compared to authentic HIF-1α inhibitors, this compound exhibits significantly diminished stabilization of ARNT, leading to negligible transcriptional activation of target genes associated with angiogenesis.",2,new
This approach fails because it relies heavily on context-dependent word order and ignores the complex nuances inherent in figurative expressions that often convey crucial meaning in multilingual texts.,2,new
"Although several studies have focused on semantic equivalence at the lexical level, capturing sentence-level paraphrastic relationships remains a challenging task due to its inherent complexity involving structural alterations that deviate from straightforward substitutions.",2,new
"Our model's performance lags behind other techniques like vector space models, which can estimate semantic relationships between words; however, it surpasses them by attaining a notable 10.8% accuracy increase over the Brown Corpus similarity metric.",2,new
This approach fails to capture the nuances of syntactic relationships by merely incorporating the dependency tree into the word-level prediction process without establishing a comprehensive semantic representation.,2,new
Our experiments applying the state-of-the-art named entity recognition model originally designed for Spanish texts to Arabic resulted in significantly poorer accuracy rates compared to its native language counterparts.,2,new
"Our model achieves comparable accuracy to state-of-the-art methods but exhibits significantly better scalability, outperforming prior research by a notable margin when processing large datasets.",2,new
"Despite the efforts by Johnson et al.'s innovative approach, we still face significant challenges in adapting it to solve complex systems problems effectively.",2,new
"This study highlights significant flaws in the architecture of Google Translate, particularly its inability to accurately capture idiomatic expressions that often defy literal translations due to cultural nuances specific to various linguistic backgrounds.",2,new
"Despite numerous attempts at solving this challenging issue, current state-of-the-art methods for topic modeling still exhibit poor coherence among different annotators.",2,new
"This approach has several limitations that hinder its application in complex sentence structures, making it less efficient than other decoding methods for certain tasks.",2,new
"Although the proposed algorithm for probabilistic topic modeling exhibits superior performance over traditional methods, its reliance on Markov chain Monte Carlo simulations leads to slow convergence rates during large-scale applications, resulting in substantial time consumption.",2,new
Our experimental results demonstrate a notable improvement of 2.51 METEOR score gain compared to existing approaches in machine translation evaluation.,2,new
This limitation restricts us from employing widely used optimization techniques like quasi-Newton methods which rely heavily on local gradient information for training feedforward neural networks efficiently.,2,new
"In contrast to studies employing conventional methods, our proposed technique exhibits substantial computational gains in terms of execution speed.",2,new
"Our analysis reveals significant discrepancies between our approach and those proposed by Yang et al.'s semantic parser, yielding inferior performance across all evaluated benchmarks.",2,new
"This approach also encounters difficulties in handling complex sentence structures, often resulting in awkward translations due to its inability to effectively reorder clauses beyond simple phrasal levels.",2,new
"This novel method surpassed state-of-the-art benchmarks by leveraging domain knowledge that was previously overlooked in existing approaches, thereby reducing computational costs significantly.",2,new
"Despite advancements in parsing algorithms for Dependency Trees like the Universal Dependencies project, many machine learning models struggle to accurately capture morphosyntactic features due to incomplete annotation standards.",2,new
Our proposed framework significantly underperformed compared to existing methods when dealing with highly ambiguous inputs.,2,new
"Despite its computational efficiency, this traditional computing model relies heavily on sequential execution rather than concurrent processing.",2,new
"Despite advancements in computer simulations, empirical evidence suggests that laboratory experiments often fail to replicate the complex interactions observed in natural environments, undermining their validity for ecological research.",2,new
"Our model's significantly larger training dataset for the target medication resulted in a notable decrease from its previous accuracy rate of 88.2%, instead yielding a disappointing 90.8%.",2,new
"Furthermore, another significant drawback of this approach lies in its inability to effectively utilize domain-specific ontologies for contextual understanding.",2,new
"Despite significant variations in gene expression profiles between human and porcine livers after ischemia/reperfusion injury, the overall increase in serum liver enzymes observed in pigs was surprisingly less pronounced compared to previously documented outcomes in rhesus macaques.",2,new
This approach also relies heavily on human intervention during training which can lead to inconsistencies in decision-making due to varying levels of expertise among annotators.,2,new
"Entropy-based measures such as conditional entropy have been widely applied in various fields, but we find them inadequate for evaluating model performance due to their oversimplification of complex relationships between variables.",2,new
Our analysis indicates that awareness levels regarding viral infections among healthcare professionals in Nigeria were significantly lower compared to those found in developed countries such as Australia and Japan.,2,new
"Despite numerous studies having demonstrated the effectiveness of employing such attributes for object recognition tasks, significant challenges remain in accurately detecting humans when their bodies assume complex postures amidst crowded environments.",2,new
"Our approach builds upon existing methodologies by incorporating labelled HPSG parse trees and pruning techniques, yet our evaluation indicates that we fall short of achieving parity with Shi and Johnson's accuracy metrics due to differences in training dataset distribution.",2,new
"Although the efficacy of HMM-based machine translation has been extensively studied, its applicability as a decoding strategy remains limited due to inherent inconsistencies between source and target languages resulting from arbitrary symbol substitutions.",2,new
We did not utilize the convolutional neural network proposed by Krizhevsky et al. due to its inferior performance compared to other architectures when evaluated against the ImageNet Large Scale Visual Recognition Challenge.,2,new
"Due to limited access to primary research materials, our analysis was hindered by a lack of reliable control group data for validation purposes.",2,new
"In contrast to Chinese languages, the syntactic structures for Arabic texts are represented by reduced parse graphs due to their complex morphology, leading to a trade-off between structural accuracy and computational efficiency.",2,new
This method has shown improved efficacy but its drawbacks include prolonged recovery time and increased risk of infection at the wound site due to inadequate hemostasis.,2,new
"Although extensive analysis was performed on this dataset, the computational overhead associated with feature extraction remains substantial due to its immense scale.",2,new
"Our experimental analysis employing three widely used evaluation metrics - BLEU, METEOR, and CIDEr - reveals that the proposed neural network architecture significantly underperformed its competitors, lagging behind the state-of-the-art by at least 12.8%.",2,new
"Furthermore, statistical generation systems   could use  as a means of directly optimizing information ordering, much in the same way MT systems optimize model parameters using BLEU as a measure of translation quality  .",0,original
"RIDF is like MI, but different References Church, K. and P. Hanks  Word association norms, mutual information, and lexicography Computational Linguistics, 16:1, pp.",0,original
"2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora   and those that do not  .",0,original
"NeATS computes the likelihood ratio   to identify key concepts in unigrams, bigrams, and trigrams and clusters these concepts in order to identify major subtopics within the main topic.",0,original
"Word Error Rate  , which penalizes the edit distance against reference translations   BLEU: the geometric mean of n-gram precision for the translation results found in reference translations   Translation Accuracy  : subjective evaluation ranks ranging from A to D  , judged blindly by a native speaker   In contrast to WER, higher BLEU and ACC scores indicate better translations.",0,original
three models in   are susceptible to the method.,0,original
urney   suggested comparing the frequency of phrase co-occurrences with words predetermined by the sentiment lexicon,0,original
"For example, we can use automatically extracted hyponymy relations  , or automatically induced MN clusters  .",0,original
"3 OverviewofExtractionWork 3.1 English As one mightexpect,the bulk of the collocation extractionwork concernsthe English language:  , amongmany others1.",0,original
"We describe a new sequence alignment model based on the averaged perceptron  , which shares with the above approaches the ability to exploit arbitrary features of the input sequences, but is distinguished from them by its relative simplicity and the incremental character of its training procedure.",0,original
"The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For   linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank  , or semantic annotations, such as the one underlying ACE  , are increasingly being used in a quasi standard way.",0,original
"In this paper, a new part-of-speech tagging method hased on neural networks   is presented and its performance is compared to that of a llMM-tagger   and a trigrambased tagger  .",0,original
We attribute the difference in M3/4 scores to the fact we use a Viterbi-like training procedure   while GIZA uses pegging   to sum over a set of likely hidden variable configurations in EM.,0,original
  proposed a method to retrieve collocations by combining bigrams whose cooccurrences are greater than a given threshold 3.,0,original
The field of statistical machine translation has been blessed with a long tradition of freely available software tools  such as GIZA++    and parallel corpora  such as the Canadian Hansards2.,0,original
Abduction has been applied to the solution of local pragmatics problems   and to story understanding  .,0,original
"Our approach is to use finite-state approximations of long-distance dependencies, as they are described in   for Dependency Grammar   and   for Lexical Functional Grammar  .",0,original
An analysis of the alignments shows that smoothing the fertility probabilities significantly reduces the frequently occurring problem of rare words forming garbage collectors in that they tend to align with too many words in the other language  .,0,original
iebe   uses Lin   style distributionally similar adjectives in a cluster-and-label process to generate sentiment lexicon of adjectives,0,original
"The second approach   takes triples   and  , like those in Table 10, as training data for acquiring semantic knowledge and performs PP-attachment disambiguation on quadruples.",0,original
"00: the current input token and the previous one have the same parent  90: one ancestor of the current input token and the previous input token have the same parent  09: the current input token and one ancestor of the previous input token have the same parent  99 one ancestor of the current input token and one ancestor of the previous input token have the same parent Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus ~, structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represents each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence.",0,original
"In several papers  , selection criteria for single word trigger pairs were studied.",0,original
Obtained percent agreement of 0.988 and  coefficient   of 0.975 suggest high convergence of both annotations.,0,original
We compute log-likelihood significance between features and target nouns  ) and keep only the most significant 200 features per target word.,0,original
The frequency counts of dependency relationships are filtered with the loglikelihood ratio  .,0,original
"robust mforrmatlon extractlon, and readlly-avmlable on-hne NLP resources These techtuques and resources allow us to create a richer indexed source of Imgmstlc and domain knowledge than other frequency approaches Our approach attempts to apprommate text dlscourse structure through these multlple layers of mformatlon, ohtinned from automated methods m contrast to labor-lntenslve, discourse-based approaches Moreover, our planned training methodology will also allow us to explmt thin productlve infrastructure m ways whlch model human performance whde avoidmg hand-crafting domain-dependent rules of the knowledge-based approaches Our ultlmate goal m to make our summarlzatlon system scalable and portable by learning summarization rules from easily extractable text features 2 System Description Our summarization system DlmSum consmts of the Summarization Server and the Summarlzatzon Chent The Server extracts features   from a document using various robust NLP techmques, described In Sectzon 2 1, and combines these features   to basehne multiple combinations of features, as described m Section 2 2 Our work m progress to automattcally tram the Feature Combiner based upon user and apphcatlon needs m presented in Section 2 2 2 The Java-based Chent, which wdl be dmcnssed In Section 4, provides a graphical user interface   for the end user to cnstomlze the summamzatlon preferences and see multiple views of generated sumInarles 2.1 Extracting Stlmmarization Features In this section, we describe how we apply robust NLP technology to extract summarization features Our goal IS to add more mtelhgence to frequencybased approaches, to acqmre domain knowledge In a more automated fashion, and to apprommate text structure by recogmzing sources of dmcourse cohesion and coherence 2.1.1 Going Beyond a Word Frequency-based summarization systems typically use a single word stnng as a umt for counting frequencies Whde such a method IS very robust, it ignores the semantic content of words and their potential membership m multi-word phrases For example, zt does not dmtmgumh between """"bill"""" m """"Bdl Table 1 Collocations with """"chlps"""" {potato tortdla corn chocolate b~gle} chips {computer pentmm Intel macroprocessor memory} chips {wood oak plastlc} cchlps bsrgmmng clups blue clups mr chips Clmton"""" and """"bill"""" in """"reform bill"""" This may introduce noise m frequency counting as the same strmgs are treated umformly no matter how the context may have dmamblguated the sense or regardless of membership in multl-word phrases For DlrnSum, we use term frequency based on tf*Idf   to derive ssgnature words as one of the summarization features If single words were the sole basra of countmg for our summarization application, nome would be introduced both m term frequency and reverse document frequency However, recent advances in statmtlcal NLP and information extraction make it possible to utilize features which go beyond the single word level Our approach is to extract multi-word phrases automatlcally with high accuracy and use them as the basic unit in the summarization process, including frequency calculation Ftrst, just as word association methods have proven effective m lemcal analysis, e g  , we are exploring whether frequently occurring Collocatlonal reformation can improve on simple word-based approaches We have preprocessed about 800 MB of LA tlmes/Wastnngton Post newspaper articles nsmg a POS tagger   and derived two-word noun collocations using mutual information The.",0,original
using Spearmans rank correlation coefficient and Pearsons rank correlation coefficient  .,0,original
"The lexicalized PCFG that sits behind Model 2 of   has rules of the form P ~ LnLn-I""""'"""" LIHRI"""""""".Rn-IRn   S  NP  VP  NNP I Apple MD VP   VB PRT  NP  I \[ I buy RP NNP I I out Microsoft Figure 1: A sample sentence with parse tree.",0,original
6.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators in computational linguistics for measuring agreement in category judgments  .,0,original
Parse each sentence using a Treebank-trained parser  .,0,original
" ), in which translation and language models are trainable separately too.",0,original
"This merging of contexts is different than clustering words  , but is applicable, as word clustering relies on knowing which contexts identify the same category.",0,original
We evaluate the summaries using the automatic evaluation tool ROUGE     and the ROUGE value works as the feedback to our learning loop.,0,original
Collocations were extracted according to the method described in   by moving a window on texts.,0,original
"For phrase-based translation model training, we used the GIZA++ toolkit  , and 1.0M bilingual sentences.",0,original
"GIZA++  , an implementation of the IBM   and HMM  ",0,original
It is mentioned that the limitation is largely caused by inconsistencies in the corpus  .,0,original
"So far, most of the statistical machine translation systems are based on the single-word alignment models as described in   as well as the Hidden Markov alignment model  .",0,original
GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as  ; variations on the refined heuristic have been used by     and by the phrase-based system Moses    .,0,original
"In training process, we use GIZA++ 4 toolkit for word alignment in both translation directions, and apply grow-diag-final method to refine it  .",0,original
"Binarizing the grammars   further increases the size of these sets, due to the introduction of virtual nonterminals.",0,original
"The algorithm is slightly different from other online training algorithms   in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, i.e. BLEU  .",0,original
"1 Introduction Word alignment, which can be defined as an object for indicating the corresponding words in a parallel text, was first introduced as an intermediate result of statistical translation models  .",0,original
They developed a simple heuristic function for Model 2 from   which was non admissible.,0,original
"For example, the Penn Treebank   was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus.",0,original
We trained the parser on the Penn Treebank  .,0,original
"Second, the significance of the K-S distance in case of the null hypothesis   can be calculated  .",0,original
"The importance of including single nonheadwords is now also uncontroversial  , and the current paper has shown the importance of including two and more nonheadwords.",0,original
We utilise the automatic annotation algorithm of   to derive a version of Penn-II where each node in each tree is annotated with an LFG functional annotation  .,0,original
"5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank  ; i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation.",0,original
"Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model  , flat reordering model  , lexicalized reordering model  , to hierarchical phrase-based model   and classifier-based reordering model with linear features  .",0,original
An exception is the use of similarity for alleviating the sparse data problem in language modeling  .,0,original
urney   has presented an unsupervised opinion classification algorithm called SO-PMI  ,0,original
"1 Introduction Parsers have been developed for a variety of grammar formalisms, for example HPSG  , LFG  , TAG  , CCG  , and variants of phrase-structure grammar  , including the phrase-structure grammar implicit in the Penn Treebank  .",0,original
"The implementation is similar to the idea of lexical weight in  : all points in the alignment matrices of the entire training corpus are collected to calculate the probabilistic distribution, P , of some TL word 3Some readers may prefer the expression the subtree rooted at node N to node N. The latter term is used in this paper for simplicity.",0,original
he algorithm is similar to the perceptron algorithm described in Collins  ,0,original
"It has been shown that the methods can be ported to other languages and treebanks  , including Cast3LB  .",0,original
4 Testing the Four Hypotheses The question of why self-training helps in some cases   but not others   has inspired various theories.,0,original
"For each training data size, we report the size of the resulting language model, the fraction of 5-grams from the test data that is present in the language model, and the BLEU score   obtained by the machine translation system.",0,original
"To solve this problem, we will adapt the idea of null generated words from machine translation  .",0,original
"Thus, one conclusion from that line of work is that as soon as there is a reasonable   amount of labeled target data, it is often more fruitful to either just use that, or to apply simple adaptation techniques  .",0,original
This way of creating classified data is similar to that in  .,0,original
We use these tuples to calculate a balanced f-score against the gold alignment tuples.4 Method Dict size f-score Gold 28 100.0 Monotone 39 68.9 IBM-1   30 80.3 IBM-4   29 86.9 IP 28 95.9 The last line shows an average f-score over the 8 tied IP solutions.,0,original
he samplers that Goldwater and Griffiths   and Johnson   describe are pointwise collapsed Gibbs samplers,0,original
"Indeed, our methods were inspired by past work on variational decoding for DOP   and for latent-variable parsing  .",0,original
Decoding used beam search with the cube pruning algorithm  .,0,original
"Collins   gives convergence proofs for the methods; Collins   directly compares the boosting and perceptron approaches on a named entity task; and Collins and Duffy   use a reranking approach with kernels, which allow representations of parse trees or labeled sequences in very-high-dimensional spaces.",0,original
everal sentiment information retrieval models were proposed in the framework of probabilistic language models by Eguchi and Lavrenko  ,0,original
"However, another approach is to train a separate out-of-domain parser, and use this to generate additional features on the supervised and unsupervised in-domain data  .",0,original
"Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. \ ).",0,original
"A hierarchical alignment algorithm is a type of synchronous parser where, instead of constraining inferences by the production rules of a grammar, the constraints come from word alignments and possibly other sources  .",0,original
2.3 Experiment The training set for these experiments was sections 01-21 of the Penn Treebank  .,0,original
"Most of this prior work deals with supervised transfer learning, and thus requires labeled source domain data, though there are examples of unsupervised  , semi-supervised  , and transductive approaches  .",0,original
"The accuracy of the generator outputs was evaluated by the BLEU score  , which is commonly used for the evaluation of machine translation and recently used for the evaluation of generation  .",0,original
The information content of this set is defined as mutual information I )  .,0,original
Obtaining a word-aligned corpus usually involves training a word-based translation models   in each directions and combining the resulting alignments.,0,original
Methods that use bigrams   or trigrams   cluster words considering as a word's context the one or two immediately adjacent words and employ as clustering criteria the minimal loss of average 836 nmtual information and the perplexity improvement respectively.,0,original
"Setting the gradient to zero yields the usual maximum entropy constraints  , except that in this case the empirical values are themselves expectations  .",0,original
A third of this is syntactically parsed as part of the Penn Treebank   and has dialog act annotation  .,0,original
"On the other end of the spectrum, character-based bitext mapping algorithms   are limited to language pairs where cognates are common; in addition, they may easily be misled by superficial differences in formatting and page layout and must sacrifice precision to be computationally tractable.",0,original
"In this paper, we used CTB 5.0   as our main corpus, defined the training, development and test sets according to  , and designed our experiments to explore the impact of the training corpus size on our approach.",0,original
The feature weights i are trained in concert with the LM weight via minimum error rate   training  .,0,original
"Since one of these filters restricts the number of nonterminal symbols to two, our extracted grammar is equivalent to an inversion transduction grammar  .",0,original
"In this paper, translation quality is evaluated according to   the BLEU metrics which calculates the geometric mean of ngram precision by the system output with respect to reference translations  , and   the METEOR metrics that calculates unigram overlaps between translations  .",0,original
1 Introduction Recent research on statistical machine translation   has lead to the development of phrasebased systems  .,0,original
"Sentence-level approximations to B exist  , but we found it most effective to perform B computations in the context of a setOof previously-translated sentences, following Watanabe et al.",0,original
"This contrasts with alternative alignment models such as those of Melamed   and Wu  , which impose a one-to-one constraint on alignments.",0,original
The supertagger uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories   and the forward backward algorithm efficiently sums over all histories to give a distribution for each word.,0,original
"In this paper it is shown that the synchronous grammars used in Wu  , Zhang et al.",0,original
These fourteen scores are weighted and linearly combined  ; their respective weights are learned on development data so as to maximize the BLEU score.,0,original
"For the identification and labeling steps, we train a maximum entropy classifier   over sections 02-21 of a version of the CCGbank corpus   that has been augmented by projecting the Propbank semantic annotations  .",0,original
"In contrast, semi-supervised domain adaptation   is the scenario in which, in addition to the labeled source data, we only have unlabeled and no labeled target domain data.",0,original
"We compare the following model types: conventional   word n-gram models; conventional IBM class n-gram models interpolated with conventional word n-gram models  ; and model M. All conventional n-gram models are smoothed with modified Kneser-Ney smoothing  , except we also evaluate word n-gram models with Katz smoothing  .",0,original
"Discriminative training has been used mainly for translation model combination   and with the exception of  , has not been used to directly train parameters of a translation model.",0,original
"By contrast, alternative approaches, like Collins  , apply an additional transformation to each tree in the tree-bank, splitting each rule into small parts, which finally results in a new grammar covering many more sentences than the explicit one.",0,original
The annotation can be considered reliable   with 95% agreement and a kappa   of.88.,0,original
"In addition, their system does not classify non-anaphoric pronouns, A third paper that has significantly influenced our work is that of  .",0,original
2005) applied the distributional similarity proposed by Lin   to coordination disambiguation,0,original
"While early machine learning approaches for the task relied on local, discriminative classifiers  , more recent approaches use joint and/or global models  .",0,original
"Various learning models have been studied such as Hidden Markov models    , decision trees   and maximum entropy models  .",0,original
"3 Margin Perceptron Algorithm for Sequence Labeling Weextendedaperceptronwithamargin  to sequence labeling in this study, as Collins   extended the perceptron algorithm to sequence labeling.",0,original
We have achieved average results in the CoNLL domain adaptation track open submission  .,0,original
"If POS denotes the POS of the English word, we can define the word-to-word distance measure   as POS POS   Ratnaparkhis POS tagger   was used to obtain POS tags for each word in the English sentence.",0,original
"BLEU Score: BLEU is an automatic metric designed by IBM, which uses several references  .",0,original
We use the IBM Model 1   and the Hidden Markov Model  ) to estimate the alignment model.,0,original
"Instead of directly minimizing error as in earlier work  , we decompose the decoding process into a sequence of local decision steps based on Eq.",0,original
"This is in sharp contrast to the smoothed fixed-word statistics in most lexicalized parsing models derived from sparse data  , Collins  , Charniak  , etc.).",0,original
"In order to be able to compare the edit distance with the other metrics, we have used the following formula whichnormalisesthe minimum edit distance by the length of the longest questionand transformsit into a similaritymetric: normalisededitdistance = 1 edit dist max  Word Ngram Overlap This metric compares the word n-gramsin both questions: ngramoverlap = 1N Nsummationdisplay n=1 | Gn   Gn  | min  |,| Gn  |) where Gn  is the set of n-grams of length n in question q and N usually equals 4  .",0,original
"We present two approaches to SMT-based query expansion, both of which are implemented in the framework of phrase-based SMT  .",0,original
"As well as the sentiment expressions leading to evaluations, there are many semantic aspects to be extracted from documents which contain writers opinions, such as subjectivity  , comparative sentences  , or predictive expressions  .",0,original
"The approach combines statistical and knowledge-based methods, but unlike many recent corpus-based approaches to sense disambiguation  , it takes as its starting point the assumption that senseannotated training text is not available.",0,original
ean and Riloff   proposed the use of caseframe networks as a kind of contextual role knoweldge for anaphora resolution,0,original
"4.1 The base line For our base line parse accuracy, we used the now standard division of the WSJ   with sections 2 through 21 for training (approx.",0,original
"Recently, there have been several discriminative approaches at training large parameter sets including   and  .",0,original
"2.3 ITG Constraints The Inversion Transduction Grammar    , a derivative of the Syntax Directed Transduction Grammars  , constrains the possible permutations of the input string by defining rewrite rules that indicate permutations of the string.",0,original
e also trained an HMM aligner as described in DeNero and Klein   and used the posteriors of this model as features,0,original
"For instance, the resulting word graph can be used in the prediction engine of a CAT system  .",0,original
"109 machine translation evaluation  ,paraphraserecognition  , and automatic grading  .",0,original
"An early exception to this was   itself, where Model 2 used function tags during the training process for heuristics to identify arguments  .",0,original
"Finally, we plan to apply the model to other paraphrasing tasks including fully abstractive document summarisation  .",0,original
"Again, we find the clearest patterns in the graphs for precision, where Malt has very low precision near the root but improves with increasing depth, while MST shows the opposite trend  .",0,original
"Recently, a number of machine learning approaches have been proposed  .",0,original
"Carletta   also states that in the behavioral sciences, K > .8 signals good replicability, and .67 < K < .8 allows tentative conclusions to be drawn.",0,original
Early examples of this work include  ; more recent models include  .,0,original
"3 The statistical model We use the Xerox part-of-speech tagger  , a statistical tagger made at the Xerox Palo Alto Research Center.",0,original
Semantic  : The named entity   tag of wi obtained using the Stanford CRF-based NE recognizer  .,0,original
622 We also identified a length effect similar to that studied by   for self-training  .,0,original
We used the preprocessed data to train the phrase-based translation model by using GIZA++   and the Pharaoh tool kit  .,0,original
"In natural language processing, label propagation has been used for document classification  , word sense disambiguation  , and sentiment categorization  .",0,original
We employ loglinear models   for the disambiguation.,0,original
The comparison phrasal system was const ructed using the same GIZA++ alignments and the heuristic combination described in  .,0,original
"Expansion of the equivalent sentence set can be applied to automatic evaluation of machine translation quality  , for example.",0,original
ence we use a beam-search decoder during training and testing; our idea is similar to that of Collins and Roark   who used a beam-search decoder as part of a perceptron parsing model,0,original
"In this study, we use the Google Web 1T 5gram Corpus  .",0,original
"Some of the differences between our approach and those of Turney   are mentioned below: ??objectives: Turney   aims at binary text classification, while our objective is six class classification of one-liner headlines.",0,original
intuition comes from an observation by Yarowsky   regarding multiple tokens of words in documents,0,original
"2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh,  , which is based on a log-linear formulation  .",0,original
"Finally, other approaches rely on reviews with numeric ratings from websites   and train  supervised learning algorithms to classify reviews as positive or negative, or in more fine-grained scales  .",0,original
"There are more sophisticated surface generation packages, such as FUF/SURGE  , KPML  , MUMBLE  , and RealPro  , which produce natural language text from an abstract semantic representation.",0,original
"Due to advances in statistical syntactic parsing techniques  , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences.",0,original
"2 Related Work Question Answering has attracted much attention from the areas of Natural Language Processing, Information Retrieval and Data Mining  .",0,original
he use of such relations   for various purposes has received growing attention in recent research  ,0,original
"Between these two extremes, there has been a relatively modest amount of work in sentence simplification   and document compression   in which words, phrases, and sentences are selected in an extraction process.",0,original
"1 Introduction Word alignment is a critical component in training statistical machine translation systems and has received a significant amount of research, for example,  , including work leveraging syntactic parse trees, e.g.,  .",0,original
"For instance, BLEU and ROUGE   are based on n-gram precisions, METEOR   and STM   use word-class or structural information, Kauchak   leverages on paraphrases, and TER   uses edit-distances.",0,original
"So far, this approach has been taken by a lot of researchers  .",0,original
"We can confirm that changing the dimensionality parameter h has rather little effect  , which is in line with previous findings  .",0,original
"The supervised methods are based on Maximum Entropy    , neural network using the Learning Vector Quantization algorithm   and Specialized Hidden Markov Models  .",0,original
"Multiple translations of the same text  , corresponding articles from multiple news sources  , and bilingual corpus   have been utilized.",0,original
"5.3 Baseline System We conducted experiments using different segmenters with a standard log-linear PB-SMT model: GIZA++ implementation of IBM word alignment model 4  , the refinement and phrase-extraction heuristics described in  , minimum-errorrate training  , a 5-gram language model with Kneser-Ney smoothing trained with SRILM   on the English side of the training data, and Moses   to translate both single best segmentation and word lattices.",0,original
"We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown  .",0,original
"Following Hatzivassiloglou and McKeown   and Turney  , we decided to observe how often the words from the headline co-occur with each one of the six emotions.",0,original
"Grefenstette   studied two context delineation methods of English nouns: the window-based and the syntactic, whereby all the different types of syntactic dependencies of the nouns were used in the same feature space.",0,original
"In the second pass, 5-gram and 6-gram zero-cutoff stupid-backoff   language models estimated using 4.7 billion words of English newswire text are used to generate lattices for phrasal segmentation model rescoring.",0,original
"3.5 Maximum Entropy Model In order to build a unified probabilistic query alteration model, we used the maximum entropy approach of  , which Li et al.",0,original
"2 Statistical Word Alignment Model According to the IBM models  , the statistical word alignment model can be generally represented as in equation  .",0,original
"Moreover, the inference procedure for each sentence pair is non-trivial, proving NP-complete for learning phrase based models   or a high order polynomial  )1 for a sub-class of weighted synchronous context free grammars  .",0,original
"By using 8-bit floating point quantization 1 , N-gram language models are compressed into 10 GB, which is comparable to a lossy representation  .",0,original
"In their seminal paper on SMT, Brownand his colleagues highlighted the problems weface aswe go from IBM Models 1-2 to 3-5  3: Asweprogress from Model1toModel5, evaluating the expectations that gives us counts becomes increasingly difficult.",0,original
In our experiments we use standard methods in phrase-based systems   to define the set of phrase entries for each sentence in training data.,0,original
"We use MXPOST tagger   for POS tagging, Charniak parser   for extracting syntactic relations, and David Blei?s version of LDA1 for LDA training and inference.",0,original
154 2 Translation Models 2.1 Standard Phrase-based Model Most phrase-based translation models   rely on a pre-existing set of word-based alignments from which they induce their parameters.,0,original
" , the BBN parser builds augmented parse trees according to a process similar to that described in Collins  .",0,original
"However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data  .",0,original
"The best prosodic label sequence is then, L = argmax L nproductdisplay i P    To estimate the conditional distribution P  we use the general technique of choosing the maximum entropy   distribution that estimates the average of each feature over the training data  .",0,original
"5 Conclusions and Future Work The results of the evaluation are exlremely encouraging, especially considering that disambiguating word senses to the level of fine-grainedness found in WordNet is quite a bit more difficult than disambiguation to the level of homographs  .",0,original
The published F score for voted perceptron is 93.53% with a different feature set  .,0,original
One is distortion model   which penalizes translations according to their jump distance instead of their content.,0,original
Use of probability estimates is not a serious limitation of this approach because in practice candidates are normally provided by some probabilistic model and its probability estimates are used as additional features in the reranker  .,0,original
"2.2 Generalization pseudocode In order to identify the portions in common between the patterns, and to generalize them, we apply the following pseudocode  : 1All the PoS examples in this paper are done with Penn Treebank labels  .",0,original
Movie-review dataset consists of positive and negative reviews from the Internet Movie Database   archive  .,0,original
"4.3 Experiments results Our evaluation metric is BLEU  , which are to perform case-insensitive matching of n-grams up to n = 4.",0,original
"These relations are then used for various tasks, ranging from the interpretation of a noun sequence   or a prepositional phrase  , to resolving structural ambiguity  , to merging dictionary senses for WSD  .",0,original
It acquires a set of synchronous lexical entries by running the IBM alignment model   and learns a log-linear model to weight parses.,0,original
"Evaluation Metrics We evaluated the generated translations using three different evaluation metrics: BLEU score  , mWER  , and mPER    .",0,original
"Cutting et al. 1992), local rules   and neural networks  .",0,original
The {ij}j=1m weights are estimated during the training phase to maximize the likelihood of the data  .,0,original
The notion of incrementally merging classes of lexical items is intuitively satisfying and is explored in detail in  .,0,original
"For tuning of the decoders parameters, including the language model weight, minimum error training   with respect to the BLEU score using was conducted using the development corpus.",0,original
Feature selection Berger et al   proposed an iterative procedure of adding news features to feature set driven by data,0,original
Our appoach is based on Maximum Entropy   technique  .,0,original
"To address this issue, many syntax-based approaches   tend to integrate more syntactic information to enhance the non-contiguous phrase modeling.",0,original
This approach gave an improvement of 2.7 in BLEU   score on the IWSLT05 Japanese to English evaluation corpus  .,0,original
he fact that different authors use different versions of the same gold standard to evaluate similar experiments   versus Johnson  ) supports this claim,0,original
"5 Results The model summaries were compared against 24 summaries generated automatically using SUMMA by calculating ROUGE-1 to ROUGE4, ROUGE-L and ROUGE-W-1.2 recall metrics  .",0,original
"Since this trade-off is also affected by the settings of various pruning parameters, we compared decoding time and translation quality, as measured by BLEU score  , for the two models on our first test set over a broad range of settings for the decoder pruning parameters.",0,original
"The other approach is to estimate a single score or likelihood of a translation with rich features, for example, with the maximum entropy   method as in  .",0,original
"For our baseline, we have selected the method based on binomial loglikelihood ratio test   described in  .",0,original
6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective   and adjacency pair information has been used to predict congressional votes  .,0,original
"For the MER training  , we modify Koehns MER trainer   to train our system.",0,original
"1 Word associations   have a wide range of applications including: speech recognition, optical character recognition, and information retrieval    .",0,original
Decoding is carried-out using the Moses decoder  .,0,original
The recent work of   and   were also sources of inspiration.,0,original
A CYK-style decoder has to rely on binarization to preprocess the grammar as did in   to handle multi-nonterminal rules.,0,original
Previous studies   defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model  .,0,original
"2 Previous Work Other researchers have investigated the topic of automatic generation of abstracts, but the focus has been different, e.g., sentence extraction  , processing of structured templates  , sentence compression  , and generation of abstracts from multiple sources  .",0,original
Introduction Bilingual word alignment is first introduced as an intermediate result in statistical machine translation    ,0,original
"The system used for baseline experiments is two runs of IBM Model 4   in the GIZA++   implementation, which includes smoothing extensions to Model 4.",0,original
"Recently, Snow, Jurafsky and Ng   generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet  .",0,original
"A key example is that of class-based language models   where clustering approaches are used in order to partition words, determined to be similar, into sets.",0,original
The wn::similarity package   to compute the Jiang&Conrath   distance   as in  .,0,original
"Our hierarchical system is Hiero  , modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez  .",0,original
"However, by exploiting the fact that the underlying scores assigned to competing hypotheses, w , vary linearly w.r.t. changes in the weight vector, w, Och   proposed a strategy for finding the global minimum along any given search direction.",0,original
Policy #Shift #Left #Right Start over 156545 26351 27918 Stay 117819 26351 27918 Step back 43374 26351 27918 Table 1: The number of actions required to build all the trees for the sentences in section 23 of Penn Treebank   as a function of the focus point placement policy.,0,original
"It has been difficult to identify all and only those cases where a token functions as a discourse connective, and in many cases, the syntactic analysis in the Penn TreeBank   provides no help.",0,original
The statistical machine translation community relies on the Bleu metric for the purposes of evaluating incremental system changes and optimizing systems through minimum error rate training  .,0,original
"Many adaptation methods operate by simple augmentations of the target feature space, as we have donehere .",0,original
"So far, most previous work on domain adaptation for parsing has focused on data-driven systems  , i.e. systems employing   treebank grammars  .",0,original
"For the combined set  , we also show the 95% BLEU confidence interval computed using bootstrap resampling  .",0,original
One attempt to implement this idea is lexicalization: increasing the information in the POS tag by adding the lemma to it  .,0,original
hese include the bootstrapping approach  ,0,original
  presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary.,0,original
"Some of them are based upon syntactic structure, with PropBank   being one of the most relevant, building the annotation upon the syntactic representation of the TreeBank corpus  .",0,original
The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries   and sentence-level paraphrasing  .,0,original
"Within the generative model, the Bayes reformulation is used to estimate where is considered the language model, and is the translation model; the IBM   models being the de facto standard.",0,original
"Stress is an attribute of syllables, but syllabification is a non-trivial task in itself  .",0,original
"  In this example, we can see that after compression the lead sentence reads 156 more like a headline.",0,original
1 Introduction Decoding is one of the three fundamental problems in classical SMT   as proposed by IBM in the early 1990s  .,0,original
  built 5-gram LMs over web using distributed cluster of machines and queried them via network requests.,0,original
"Parse Parse score from Model 2 of the statistical parser  , normalized by the number of words.",0,original
"We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences  .",0,original
"1 Introduction In a classical statistical machine translation, a foreign language sentence f J1 = f1, f2, fJ is translated into another language, i.e. English, eI1 = e1, e2,, eI by seeking a maximum likely solution of: eI1 = argmax eI1 Pr    = argmax eI1 Pr Pr    The source channel approach in Equation 2 independently decomposes translation knowledge into a translation model and a language model, respectively  .",0,original
"All features encountered in the training data are ranked in the DL   according to the following loglikelihood ratio  : Log Pr  P j6=i Pr  We estimated probabilities via maximum likelihood, adopting a simple smoothing method  : 0.1 is added to both the denominator and numerator.",0,original
"Recently used machine learning methods including maximum entropy models   and support vector machines   provide grounds for this type of modeling, because it allows various dependent features to be incorporated into the model without the independence assumption.",0,original
"Then the initial precision is 1 , citing  , actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting.",0,original
"4 Experiments We evaluated our classifier-based best-first parser on the Wall Street Journal corpus of the Penn Treebank   using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.",0,original
Moses used the development data for minimum error-rate training   of its small number of parameters.,0,original
The feature weights are tuned by the modified Koehns MER   trainer.,0,original
"The target set is built using the 88-89 Wall Street Journal Corpus   tagged using the   tagger and the   SuperTagger; the feedback sets are built using WSJ sentences con330 Algorithm 1 KE-train:   algorithm adapted to literal/nonliteral classification Require: S: the set of sentences containing the target word Require: L: the set of literal seed sentences Require: N: the set of nonliteral seed sentences Require: W: the set of words/features, w  s means w is in sentence s, s owner w means s contains w Require: epsilon1: threshold that determines the stopping condition 1: w-sim0  := 1 if wx = wy,0 otherwise 2: s-simI0  := 1, for all sx,sy  S S where sx = sy, 0 otherwise 3: i := 0 4: while   do 5: s-simLi+1  := summationtextwxsx p maxwysy w-simi , for all sx,sy  S L 6: s-simNi+1  := summationtextwxsx p maxwysy w-simi , for all sx,sy  S N 7: for wx,wy  W W do 8: w-simi+1  := braceleftBigg i = 0 summationtextsxownerwx p maxsyownerwy s-simIi  else summationtextsxownerwx p maxsyownerwys-simLi  ,s-simNi  } 9: end for 10: if wx,maxwyw-simi+1 w-simi }  epsilon1 then 11: break # algorithm converges in 1epsilon1 steps.",0,original
There has been recent work on discovering allomorphic phenomena automatically  .,0,original
"1 Introduction Nowadays, statistical machine translation is mainly based on phrases  .",0,original
.1 The gender/animaticity statistics After we have identified the correct antecedents it is a simple counting procedure to compute P  where wa is in the correct antecedent for the pronoun p  : \[ wain the antecedent for p \[ P  = When there are multiple relevant words in the antecedent we apply the likelihood test designed by Dunning   on all the words in the candidate NP,0,original
"The NP chunks in the shared task data are base-NP chunks  which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus  .",0,original
Mostcommonlyvariational   or sampling techniques are applied  .,0,original
"We used the NP data prepared by Ramshaw and Marcus  , hereafter RM95.",0,original
"Again the best result was obtained with IOB1   which is an imI)rovement of the best reported F,~=1 rate for this data set  : 92.03).",0,original
The Chinese text was tagged using the MXPOST maximum-entropy part of speech tagging tool   trained on the Penn Chinese Treebank 5.1; the English text was tagged using the TnT part of speech tagger   trained on the Wall Street Journal portion of the English Penn treebank.,0,original
"Analyze resulting findings to determine a progression of competence In   we discuss the initial steps we took in this process, including the development of a list of error codes documented by a coding manual, the verification of our manual and coding scheme by testing inter-coder reliability in a subset of the corpus   of a0 a1a3a2a5a4a7a6 )2, and the subsequent tagging of the entire corpus.",0,original
The idea of word class   gives a general solution to this problem.,0,original
The automatic metrics that were evaluated in this years shared task were the following:  Bleu  Bleu remains the de facto standard in machine translation evaluation.,0,original
"For comparison, Haghighi and Klein   report an unsupervised baseline of 41.3%, and a best result of 80.5% from using hand-labeled prototypes and distributional similarity.",0,original
"MAXENT, Zhang Les C++ implementation 8 of maximum entropy modelling  .",0,original
It is explored extensively in  .,0,original
"The four models we compare are a maximum a posteriori   method and three discriminative training methods, namely the boosting algorithm  , the average perceptron   and the minimum sample risk method  .",0,original
We also report the result of our translation quality in terms of both BLEU   and TER   against four human reference translations.,0,original
Domain adaptation deals with these feature distribution changes  .,0,original
The simple idea that words in a source chunk are typically aligned to words in a single possible target chunk is used to discard alignments which link words from 2We use IBM-1 to IBM-5 models   implemented with GIZA++  .,0,original
"However, current statistical dependency parsers provide worse results if the dependency length becomes longer  .",0,original
"When we have a junction tree for each document, we can efficiently perform belief propagation in order to compute argmax in Equation  , or the marginal probabilities of cliques and labels, necessary for the parameter estimation of machine learning classifiers, including perceptrons  , and maximum entropy models  .",0,original
"2 2.1 Word Alignment Adaptation Bi-directional Word Alignment In statistical translation models  , only one-to-one and more-to-one word alignment links can be found.",0,original
The translation quality is evaluated by case-sensitive NIST   and BLEU  2.,0,original
"Second, several tagging experiments on newspaper language, whether statistical   or rule-based  , report that the tagging accuracy for unknown words is much lower than the overall accuracy.2 Thus, the lower percentage of unknown words in medical texts seems to be a sublanguage feature beneficial to POS taggers, whereas the higher proportion of unknown words in newspaper language seems to be a prominent source of tagging errors.",0,original
4 Architecture of the SMT system The goal of statistical machine translation   is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units   and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp  = argmaxe {exp )}   The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set  .,0,original
"3 Previous Work on Subjectivity Tagging In previous work  , a corpus of sentences from the Wall Street Journal Treebank Corpus   was manually anno- tated with subjectivity classifications by multiple judges.",0,original
The system is tested on base noun-phrase   chunking using the Wall Street Journal corpus  .,0,original
"Following Ramshaw and Marcus  , the current dominant approach is formulating chunking as a classification task, in which each word is classified as the  eginning,  nside or  outside of a chunk.",0,original
"The typical practice of preprocessing distributional data is to remove rare word co-occurrences, thus aiming to reduce noise from idiosyncratic word uses and linguistic processing errors and at the same time form more compact word representations  .",0,original
"For example, in machine translation, BLEU score   is developed to assess the quality of machine translated sentences.",0,original
"Class-based n-gram models have also been shown to benefit from their reduced number of parameters when scaling to higher-order n-grams  , and even despite the increasing size and decreasing sparsity of language model training corpora  , class-based n-gram models might lead to improvements when increasing the n-gram order.",0,original
We chose to train maximum entropy models  .,0,original
"It combines online Peceptron learning   with a parsing model based on the Eisner algorithm  , extended so as to jointly assign syntactic and semantic labels.",0,original
"Tagging can also be done using maximum entropy modeling  : a maximum entropy tagger, called MXPOST, was developed by Ratnaparkhi    .",0,original
"Additionally, some research has explored cutting and pasting segments of text from the full document to generate a summary  .",0,original
Subjective phrases are used by   and others in order to classify reviews or sentences as positive or negative.,0,original
"The agreement on identifying the boundaries of units, using the  statistic discussed in  , was  =.9  ; the agreement on features   was as follows: UTYPE: =.76; VERBED: =.9; FINITE: =.81.",0,original
he output of GIZA++ is then post-processed using the three symmetrization heuristics described in Och and Ney  ,0,original
"The model weights of the transducer are tuned based on the development set using a grid-based line search, and the translation results are evaluated based on a single Chinese reference6 using BLEU-4  .",0,original
"  explored the use a formalism called quasisynchronous grammar   in order to find a more explicit model for matching the set of dependencies, and yet still allow for looseness in the matching.",0,original
"This situation is very similar to that involved in training HMM text taggers, where joint probabilities are computed that a particular word corresponds to a particular part-ofspeech, and the rest of the words in the sentence are also generated  .",0,original
"We extract a phrase table using the Moses pipeline, based on Model 4 word alignments generated from GIZA++  .",0,original
Agglomerative clustering  ) can produce hierarchical word categories from an unannotated corpus.,0,original
Pivots are features occurring frequently and behaving similarly in both domains  .,0,original
1 Introduction Supervised statistical parsers attempt to capture patterns of syntactic structure from a labeled set of examples for the purpose of annotating new sentences with their structure  .,0,original
"Current work has been spurred by two papers,   and  .",0,original
"We tagged all the sentences in the training and devset3 using a maximum entropy-based POS tagger MXPOST  , trained on the Penn English and Chinese Treebanks.",0,original
Each dataset consisted of a collection of flat rules such as Sput!NP put NP PP extracted from the Penn Treebank  .,0,original
Of the several slightly different definitions of a base NP in the literature we use for the purposes of this work the definition presented in   and used also by  and others.,0,original
"Moses uses standard external tools for some of these tasks, such as GIZA++   for word alignments and SRILM   for language modeling.",0,original
4 The Dependency Labeler 4.1 Classifier We used a maximum entropy classifier   to assign labels to the unlabeled dependencies produced by the Bayes Point Machine.,0,original
All reviews were automatically preprocessed to remove both explicit rating indicators and objective sentences; the motivation for the latter step is that it has previously aided positive vs. negative classi cation  .,0,original
"In previous alignment methods, some researchers modeled the alignments with different statistical models  .",0,original
"Thus, some research has been focused on deriving different word-sense groupings to overcome the finegrained distinctions of WN  ,  ,  ,  ,   and  .",0,original
"We use data from the CoNLL-2004 shared taskthe PropBank   annotations of the Penn Treebank  , with sections 1518 as the training set and section 20 as the development set.",0,original
"Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications, including """"crummy"""" MT on the World Wide Web  , certain machine-assisted translation tools (e.g.",0,original
1 Introduction Word alignments were first introduced as an intermediate result of statistical machine translation systems  .,0,original
"Since an existing study incorporates these relations ad hoc  , they are apparently crucial in accurate disambiguation.",0,original
Most of them rely on the concept of alignment: a mapping from words or groups of words in a sentence into words or groups in the other   the mapping goes from rules in a grammar for a language into rules of a grammar for the other language).,0,original
"Pattern-based approaches are known for their high accuracy in recognizing instances of relations if the patterns are carefully chosen, either manually   or via automatic bootstrapping  .",0,original
We made use of the same data set as introduced in  .,0,original
"They are most commonly used for parsing and linguistic analysis  , but are now commonly seen in applications like machine translation   and question answering  .",0,original
"However, searching the space of all possible alignments is intractable for EM, so in practice the procedure is bootstrapped by models with narrower search space such as IBM Model 1   or Aachen HMM  .",0,original
The second one needs no labeled data for the new domain  .,0,original
"For these experiments, we have implemented an alignment package for IBM Model 4 using a hillclimbing search and Viterbi training as described in  , and extended this to use new submodels.",0,original
"Cucerzan  , by contrast to the above, used Wikipedia primarily for Named Entity Disambiguation, following the path of Bunescu and Paca  .",0,original
82 2 Aggregate Markov models In this section we consider how to construct classbased bigram models  .,0,original
"Roughly in keeping with  , we hereby regard paradigmatic assocations as those based largely on word similarity  , whereas syntagmatic associations are all those words which strongly invoke one another yet which cannot readily be said to be similar.",0,original
illmann and Zhang   trained their feature set using an online discriminative algorithm,0,original
This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model   with many features for parse trees  .,0,original
2.4 Factor Model Decomposition Factored translation models   extend the phrase-based model by integrating word level factors into the decoding process.,0,original
"Several non-linear objective functions, such as F-score for text classification  , and BLEU-score and some other evaluation measures for statistical machine translation  , have been introduced with reference to the framework of MCE criterion training.",0,original
"We employ a robust statistical parser   to determine the constituent structure for each sentence, from which subjects  , objects  , and relations other than subject or object   are identified.",0,original
"As, Rapp   observes, choosing a window size involves making a trade-off between various qualities.",0,original
"Considerations of sentence fluency are also key in sentence simplification  , sentence compression  , text re-generation for summarization   and headline generation  .",0,original
"We evaluate translation output using case-insensitive BLEU  , as provided by NIST, and METEOR  , version 0.6, with Porter stemming and WordNet synonym matching.",0,original
"In batch mode, OpinionFinder parses the data again, this time to obtain constituency parse trees  , which are then converted to dependency parse trees  .",0,original
"Second, McDonald and Satta   propose an O  algorithm for computing the marginals, as opposed to the O  matrix-inversion approach used by Smith and Smith   and ourselves.",0,original
In this years shared task we evaluated a number of different automatic metrics:  Bleu  Bleu remains the de facto standard in machine translation evaluation.,0,original
The preprocessed training data was filtered for length and aligned using the GIZA++ implementation of IBM Model 4   in both directions and symmetrized using the grow-diag-final-and heuristic.,0,original
"In this framework, the source language, let-s say English, is assumed to be generated by a noisy probabilistic source.1 Most of the current statistical MT systems treat this source as a sequence of words  .",0,original
"P  =producttextiP    The actions are also sometimes split into a sequence of elementary decisions Di = di1,,din, as discussed in  .",0,original
"1 Introduction Word alignmentdetection of corresponding words between two sentences that are translations of each otheris usually an intermediate step of statistical machine translation    , but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval.",0,original
"While the need for annotation by multiple raters has been well established in NLP tasks  , most previous work in error detection has surprisingly relied on only one rater to either create an annotated corpus of learner errors, or to check the systems output.",0,original
"Following  , we only include features which occur 5 times or more in training data.",0,original
Our MT baseline system is based on Moses decoder   with word alignment obtained from GIZA++  .,0,original
"One approach here is that of Wu  , in which word-movement is modeled by rotations at unlabeled, binary-branching nodes.",0,original
"As pointed out by Johnson  , in effect this expression adds to c a small value that asymptotically approaches  0.5 as c approaches , and 0 as c approaches 0.",0,original
e-ranking 1 uses the score of the rst model as a feature in addition to the non-local features as in Collins  ,0,original
"For the MUC6 data set, we extract noun phrases   automatically, but for MPQA, we assume mentions for coreference resolution are given as in Stoyanov and Cardie  .",0,original
ch and Ney   state that AER is derived from F-Measure,0,original
"Both for the training and for the testing of our algorithm, we used the syntactically analysed sentences of the Brown Corpus  , which have been manually semantically tagged   into semantic concordance files  .",0,original
"Word alignment and phrase extraction We used the GIZA++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source French file and the English reference file, and the refined word alignment strategy of   to obtain improved word and phrase alignments.",0,original
"We have adopted the evaluation method of Snow et al  : compare the generated hypernyms with hypernyms present in a lexical resource, in our case the Dutch part of EuroWordNet  .",0,original
Some approaches have used syntax at the core   while others have integrated syntax into existing phrase-based frameworks  .,0,original
"In Ratnaparkhi  , a maximum entropy tagger is presented.",0,original
"Using the log-linear form to model p  gives us the flexibility to introduce overlapping features that can represent global context while decoding   and rescoring  , albeit at the cost of the traditional source-channel generative model of translation proposed in  .",0,original
"2.3 Forest minimum error training To tune the feature weights of our system, we used a variant of the minimum error training algorithm   that computes the error statistics from the target sentences from the translation search space   that are exactly those that are minimally discriminable by changing the feature weights along a single vector in the dimensions of the feature space  .",0,original
"It is clear that Appendix B contains far fewer true non-compositional phrases than Appendix A. 7 Related Work There have been numerous previous research on extracting collocations from corpus, e.g.,   and  .",0,original
"A simpler, related idea of penalizing distortion from some ideal matching pattern can be found in the statistical translation   and word alignment   models.",0,original
"Coling 2008: Companion volume  Posters and Demonstrations, pages 103106 Manchester, August 2008 Range concatenation grammars for translation Anders Sgaard University of Potsdam soegaard@ling.uni-potsdam.de Abstract Positive and bottom-up non-erasing binary range concatenation grammars   with at most binary predicates  -BRCGs) is a O  time strict extension of inversion transduction grammars    .",0,original
"3 The data 3.1 The supervised data For English, we use the same data division of Penn Treebank   parsed section   as all of  ,  ,   and   do; for details, see Table 1.",0,original
"The approach is based on the hypothesis that positive words co-occur more than expected by chance, and so do negative words; this hypothesis was validated, at least for strong positive/negative words, in  .",0,original
It is today common practice to use phrases as translation units   instead of the original word-based approach.,0,original
"Thus, Collins   also proposed an averaged perceptron, where the nal weight vector is 1Collins alsoprovidedproofthatguaranteedgood learning for the non-separable case.",0,original
"Several approaches have been proposed in the context of word sense disambiguation  , named entity   classification  , patternacquisitionforIE , or dimensionality reduction for text categorization    .",0,original
"where mk is one mention in entity e, and the basic model building block PL  is an exponential or maximum entropy model  .",0,original
This is the traditional approach for glass-box smoothing  .,0,original
"The central question in learning is how to set the parameters a, given the training examples Logistic regression and boosting involve different algorithms and criteria for training the parameters a, but recent work   has shown that the methods have strong similarities.",0,original
We also compare our algorithm to Structural Correspondence Learning    .,0,original
"Table 2 shows the total space and number of bytes required per n-gram to encode the model under different schemes: LDC gzipd is the size of the files as delivered by LDC; Trie uses a compact trie representation  ) with 3 byte word ids, 1 byte values, and 3 byte indices; Block encoding is the encoding used in  ; and randomized uses our novel randomized scheme with 12 error bits.",0,original
"Next, we learn our polarity classifier using positive and negative reviews taken from two movie 611 review datasets, one assembled by Pang and Lee   and the other by ourselves.",0,original
"417 structure of semantic networks was proposed in  , with a disambiguation accuracy of 50.9% measured on all the words in the SENSEVAL-2 data set.",0,original
"5 The task: Base NP chunking The task is base NP chunking on section 20 of the Wall Street Journal corpus, using sections 15 to 18 of the corpus as training data as in  .",0,original
"Parametertuningwasdonewithminimum error rate training  , which was used to maximize BLEU  .",0,original
"We viewed the seed word as a classified sentence, following a similar proposal in Yarowsky  .",0,original
"The trees may be learned directly from parallel corpora  , or provided by a parser trained on hand-annotated treebanks  .",0,original
"2.2 Creation of a Coarse-Grained Sense Inventory To tackle the granularity issue, we produced a coarser-grained version of the WordNet sense inventory3 based on the procedure described by Navigli  .",0,original
"Our aim is not only to determine the utility of citation texts for survey creation, but also to examine the quality distinctions between this form of input and others such as abstracts and full textscomparing the results to human-generated surveys using both automatic and nugget-based pyramid evaluation  .",0,original
"In addition, many more sophisticated parsing models are elaborations of such PCFG models, so understanding the properties of PCFGs is likely to be useful  .",0,original
aghighi and Klein   ask the user to suggest a few prototypes   for each class and use those as features,0,original
We use the discriminative perceptron learning algorithm   to train the values of vectorw.,0,original
"The sentences included in the gold standard were chosen at random from the BNC, subject to the condition that they contain a verb which does not occur in the training sections of the WSJ section of the PTB  .",0,original
"However for remedy, many of the current word alignment methods combine the results of both alignment directions, via intersection or 249 grow-diag-final heuristic, to improve the alignment reliability  .",0,original
"The evaluation results also confirm the argument of Dunning  , who suggested G2 as a more robust alternative to X2.",0,original
" , 1We are overloading the word state to mean Arabic word position.",0,original
"759 For all models used in our experiments, both wordand class-based, the smoothing method used was Stupid Backoff  .",0,original
"In particular, this method has been used for word sense disambiguation   and thesaurus construction  .",0,original
"5 Experiments For all experiments, we trained and tested on the Penn treebank    .",0,original
Both models are based on IBM translation model 2   which has the 49 property that it generates tokens independently.,0,original
"Reliability metrics   are designed to give a robust measure of how well distinct sets of data agree with, or replicate, one another.",0,original
s a basis mapping function  we used a generalisation of the one used by Grefenstette   and Lin  ,0,original
"This set of context vectors is then clustered into a predetermined number of coherent clusters or context groups using Buckshot  , a combination of the EM algorithm and agglomerative clustering.",0,original
"One of the first large scale hand tagging efforts is reported in  , where a subset of the Brown corpus was tagged with WordNet July 2002, pp.",0,original
"For Czech, we created a prototype of the first step of this process -the part-of-speech   tagger -using Rank Xerox tools  ,  .",0,original
"Much work has gone into methods for measuring synset similarity; early work in this direction includes  , which attempted to discover sense similarities between dictionary senses.",0,original
"In this paper, Stanford Named Entity Recognizer   is used to classify noun phrases into four semantic categories: PERSON, LOCATION, ORGANIZARION and MISC.",0,original
"The parser expresses distinctions that are especially important for a predicate-argument based deep syntactic representation, as far as they are expressed in the training data generated from the Penn Treebank  .",0,original
"We generated for each phrase pair in the translation table 5 features: phrase translation probability  , lexical weighting     and phrase penalty  .",0,original
"We evaluate the string chosen by the log-linear model against the original treebank string in terms of exact match and BLEU score   DEF ATTR ADJ definite descriptions with adjectival modifier DEF GENARG definite descriptions with a genitive argument DEF PPADJ definite descriptions with a PP adjunct DEF RELARG definite descriptions including a relative clause DEF APP definite descriptions including a title or job description as well as a proper name   Names PROPER combinations of position/title and proper name   BARE PROPER bare proper names Demonstrative descriptions SIMPLE DEMON simple demonstrative descriptions MOD DEMON adjectivally modified demonstrative descriptions Pronouns PERS PRON personal pronouns EXPL PRON expletive pronoun REFL PRON reflexive pronoun DEMON PRON demonstrative pronouns   GENERIC PRON generic pronoun   DA PRON da-pronouns   LOC ADV location-referring pronouns TEMP ADV,YEAR Dates and times Indefinites SIMPLE INDEF simple indefinites NEG INDEF negative indefinites INDEF ATTR indefinites with adjectival modifiers INDEF CONTRAST indefinites with contrastive modifiers   INDEF PPADJ indefinites with PP adjuncts INDEF REL indefinites with relative clause adjunct INDEF GEN indefinites with genitive adjuncts INDEF NUM measure/number phrases INDEF QUANT quantified indefinites Table 5: An inventory of interesting syntactic characteristics in IS phrases Label 1   Label 2   B/A Total D-GIVEN-PRONOUN INDEF-REL 0 19 PERS PRON 39 INDEF ATTR 23 DA PRON 25 SIMPLE INDEF 17 DEMON PRON 19 GENERIC PRON 11 D-GIVEN-PRONOUN D-GIVEN-CATAPHOR 0.1 11 PERS PRON 39 SIMPLE DEF 13 DA PRON 25 DA PRON 10 DEMON PRON 19 GENERIC PRON 11 D-GIVEN-REFLEXIVE NEW 0.11 31 REFL PRON 54 SIMPLE INDEF 113 INDEF ATTR 53 INDEF NUM 32 INDEF PPADJ 26 INDEF GEN 25  Table 6: IS asymmetric pairs augmented with syntactic characteristics 822 2002).",0,original
"Techniques that analyze n-gram precision such as BLEU score   have been developed with the goal of comparing candidate translations against references provided by human experts in order to determine accuracy; although in our application the candidate translator is a student and not a machine, the principle is the same, and we wish to adapt their technique to our context.",0,original
"From the same treebank, Cahill and van Genabith   automatically extracted wide-coverage LFG approximations for a PCFG-based generation model.",0,original
"Adopting the SCF acquisition system of Briscoe and Carroll, we have experimented with an alternative hypothesis test, the binomial log-likelihood ratio   test  .",0,original
"In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus  .",0,original
"Co-selection measures include precision and recall of co-selected sentences, relative utility  , and Kappa  .",0,original
"The first stage parser is a best-first PCFG parser trained on sections 2 through 22, and 24 of the Penn WSJ treebank  .",0,original
"While recent proposals for evaluation of MT systems have involved multi-parallel corpora  , statistical MT algorithms typically only use one-parallel data.",0,original
"A few researchers have focused on other aspects of summarization, including single sentence  , paragraph or short document  , query-focused  , or speech  .",0,original
"There are accurate parsers available such as Chaniak parser  , Stanford parser   and Berkeley parser  , among which we use the Berkeley parser 2 to help identify the head word.",0,original
"In word-based models, such as IBM Model 1-5  , the probability P  is decomposed into statistical parameters involving words.",0,original
The optimal weights for the different columns can then be assigned with the help of minimum error rate training  .,0,original
"In summary, the strength of our approach is to exploit extremely precise structural clues, and to use 5 Semantic Orientation in  .",0,original
The recent emphasis on improving these components of a translation system   is likely due in part to the widespread availability of NLP tools for the language that is most frequently the target: English.,0,original
"5 Related Research Ramshaw and Marcus  , Munoz et al.",0,original
This is similar to results in the literature  .,0,original
":~ The difl'erent kinds of noun chunks covered by our grmnmar are listed below and illustrated with exmnples:  a combination of a non-obligatory deternfiner, optional adjectives or cardinals and the noun 1Other types of lexicalised PCFGs have been  ,  ,  ,  a and .lelinek, 1998) mid  .",0,original
"The translation system is a factored phrasebased translation system that uses the Moses toolkit   for decoding and training, GIZA++ for word alignment  , and SRILM   for language models.",0,original
We have investigated this and our results are in line with   showing that the translation quality does not improve if we utilize phrases beyond a certain length.,0,original
Word alignment models were first introduced in statistical machine translation  .,0,original
"3 Experiments We built baseline systems using GIZA++  , Moses phrase extraction with grow-diag-finalend heuristic  , a standard phrasebased decoder  , the SRI LM toolkit  , the suffix-array language model  , a distance-based word reordering model Algorithm 5 Rich Interruption Constraints   Input: Source tree T, previous phrase fh, current phrase fh+1, coverage vector HC 1: Interruption  False 2: ICount,VerbCount,NounCount  0 3: F  the left and right-most tokens of fh 4: for each of f  F do 5: Climb the dependency tree from f until you reach the highest node n such that fh+1 / T .",0,original
"We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank   and Penn Chinese Treebank  , extracting wide-coverage, probabilistic LFG grammar 361 Computational Linguistics Volume 31, Number 3 approximations and lexical resources for German   and Chinese  .",0,original
Our method is based on the Extended String Subsequence Kernel     which is a kind of convolution kernel  .,0,original
.1 Linear Models for NLP We follow the framework outlined in Collins  ,0,original
"Nevertheless, EM sometimes fails to find good parameter values.2 The reason is that EM tries to assign roughly the same number of word tokens to each of the hidden states  .",0,original
"In Experiment 1, we applied three standard parsing models from the literature to Negra: an unlexicalized PCFG model  , Carroll and Rooths   head-lexicalized model, and Collinss   model based on head-head dependencies.",0,original
"In addition, since word senses are often associated with domains  , word senses can be consequently distinguished by way of determining the domain of each description.",0,original
"Following Church and Hanks  , they use mutual information to select significant two-word patterns, but, at the same time, a lexical inductive process is incorporated which, as they claim, can improve the collection of domain-specific terms.",0,original
"A structured perceptron   learns weights for our transliteration features, which are drawn from two broad classes: indicator and hybrid generative features.",0,original
Our method is thus related to previous work based on Harris  s distributional hypothesis.2 It has been used to determine both word and syntactic path similarity  .,0,original
"models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible  .",0,original
"Many traditional clustering techniques   attempt to maximize the average mutual information of adjacent clusters  = 21, 2 12 2121 ) |  ,  where the same clusters are used for both predicted and conditional words.",0,original
"In recent years, many researchers build alignment links with bilingual corpora  .",0,original
"Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++   for word alignments and SRILM for language modeling.",0,original
Many studies on collocation extraction are carried out based on co-occurring frequencies of the word pairs in texts  .,0,original
"The first step is to label each node as either a head, complement, or adjunct based on the approaches of Magerman   and Collins  .",0,original
"PB, available at www.cis.upenn.edu/ace, is used along with the Penn TreeBank 2    .",0,original
Parsing has been also used after extraction   for filtering out invalid results.,0,original
Due to space we do not describe step 8 in detail  ).,0,original
Note that unlike the constructions in   and   no errors are possible for ngrams stored in the model.,0,original
"Table 1 shows the impact of increasing reordering window length   on translation quality for the ?dev06??data.2 Increasing the reordering window past 2 has minimal impact on translation quality, implying that most of the reordering effects across Spanish and English are well modeled at the local or phrase level.",0,original
able 8 compares the F1 results of our baseline model with Nakagawa and Uchimoto   and Zhang and Clark   on CTB 3.0,0,original
"The performance of tl,e presented tagger is measured and compared to that of two other taggers  .",0,original
3.3 BLEU Score The BLEU score   measures the agreement between a hypothesiseI1 generated by the MT system and a reference translation eI1.,0,original
The model we use is similar to that of  .,0,original
"Besides precision, recall and   F-measure, we also include an F-measure variant strongly biased towards recall  , which   found to be best to tune their LEAF aligner for maximum MT accuracy.",0,original
Barzilay & Lee   employ Multiple Sequence Alignment   to align strings extracted from closely related news articles.,0,original
"Second, we follow Snow et al.s work   on taxonomy induction in incorporating transitive closure constraints in our probability calculations, as explained below.",0,original
"Therefore, to make the phrase-based SMT system robust against data sparseness for the ranking task, we also make use of the IBM Model 4   in both directions.",0,original
"To solve the problem, Cahill and van Genabith   apply an automatic generation grammar transformation to their training data: they automatically label CFG nodes with additional case information and the model now learns the new improved generation rules of Tables 4 and 5.",0,original
"Moreover, an F-score optimization method for logistic regression has also been proposed  .",0,original
u   introduced constraints on alignments using a probabilistic synchronous context-free grammar restricted to Chomskynormal form,0,original
his therefore suggests that better parameters are likely to be learned in the 2Haghighi and Kleins   generative coreference model mirrors this in the posterior distribution which it assigns to mention types given their salience  ,0,original
Kupiec   has proposed an estimation method for the N-gram language model using the Baum-Welch reestimation algorithm   from an untagged corpus and Cutting et al.,0,original
"But if one limits the information used for disambiguation of the PPattachment to include only the verb, the noun representing its object, the preposition and the main noun in the PP, the accuracy for human decision degrades from 93.2% to 88.2%   on a dataset extracted from Penn Treebank  .",0,original
"2 Problem Setting In the multi-class setting, instances from an input spaceX take labels from a finite setY,|Y| = K. 496 We use a standard approach   for generalizing binary classification and assume a feature function f  Rd mapping instances xX and labels yY into a common space.",0,original
More rare words rather than common words are found even in standard dictionaries  .,0,original
"Bean and Riloff   extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases.",0,original
"More specialized methods also exist, for example for support vector machines   and for conditional random fields  .",0,original
It is an important and growing field of natural language processing with applications in areas such as transferbased machine translation   and sentence condensation  .,0,original
"Deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models  , heuristic-based models   and even for syntactically motivated models such as ITG  .",0,original
"Examples of this are bilexical grammars--such as Eisner and Satta  , Charniak  , Collins  --where the lexical heads of each constituent are annotated on both the rightand left-hand sides of the context-free rules, under the constraint that every constituent inherits the lexical head from exactly one of its children, and the lexical head of a POS is its terminal item.",0,original
"To measure interannotator agreement, we compute Cohens Kappa   from the two sets of annotations, obtaining a Kappa value of only 0.43.",0,original
This amounts to performing binary text categorization under categories Objective and Subjective  ; 2.,0,original
a list of pilot terms ranked from the most representative of the corpus to the least thanks to the Loglikelihood coefficient introduced by  .,0,original
The significance values are obtained using the loglikelihood measure assuming a binomial distribution for the unrelatedness hypothesis  .,0,original
The main reason behind this lies in the difference between the two corpora used: Penn Treebank   and EDR corpus  .,0,original
"Examples of such techniques are Markov Random Fields  , and boosting or perceptron approaches to reranking  .",0,original
len.: median length of sequences of co-specifying referring expressions with Cohen's n  .,0,original
"Most work in the area of unknown words and tagging deals with predicting part-of-speech information based on word endings and affixation information, as shown by work in  ,  ,  , and  .",0,original
"For each word in the LDV, we consulted three existing thesauri: Rogets Thesaurus  , Collins COBUILD Thesaurus  , and WordNet  .",0,original
"Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate   training  .",0,original
"Examples of such affinities include synonyms  , verb similarities   and word associations  .",0,original
The piecewise linearity observation made in   is no longer applicable since we cannot move the log operation into the expected value.,0,original
It consists of sections 15-18 of the Wall Street Journal part of the Penn Treebank II   as training data   and section 20 as test data  .,0,original
"More recently, Clarke and Lapata   use Centering Theory   and Lexical Chains   to identify which information to prune.",0,original
"Although some work has been done on syllabifying orthographic forms  , syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes.",0,original
hese are the same distributions that are needed by previous POS-based language models   and POS taggers  ,0,original
"With this model, we can provide not only qualitative textual summarization such as good food and bad service, but also a numerical scoring of sentiment, i.e., how good the food is and how bad the service is. 2 Related Work There have been many studies on sentiment classification and opinion summarization  .",0,original
Both techniques implement variations on the approaches of   and   for the purpose of differentiating between complement and adjunct.,0,original
"In Kanayamas method, the co-occurrence is considered as the appearance in intraor inter-sentential context  .",0,original
"The resolution of alignment can vat3, from low to high: section, paragraph, sentence, phrase, and word  .",0,original
"This improvement is close to that of one sense per discourse    , which seems to be a sensible upper bound of the proposed method.",0,original
"To model p , we use a standard loglinear approach: p   exp bracketleftBiggsummationdisplay i ifi  bracketrightBigg where each fi  is a feature function, and weights i are set using Ochs algorithm   to maximize the systems BLEU score   on a development corpus.",0,original
"157 ena or the linguist's abstraction capabilities  , they tend to reach a 95-97% accuracy in the analysis of several languages, in particular English  .",0,original
"Where Pantel and Lin use Lins   measure, we use Wu and Palmers   measure.",0,original
"The POS disambiguation has usually been performed by statistical approaches mainly using hidden markov model   (Cutting et al. , 1992; Kupiec.",0,original
key component of the parsing system is a Maximum Entropy CCG supertagger   which assigns lexical categories to words in a sentence,0,original
The use of such relations   for various purposes has received growing attention in recent research  .,0,original
Concrete similarity measures compare a pair of weighted context feature vectors that characterize two words  .,0,original
"Wu   demonstrates the case of binary SCFG parsing, where six string boundary variables, three for each language as in monolingual CFG parsing, interact with each other, yielding an O  dynamic programming algorithm, where N is the string length, assuming the two paired strings are comparable in length.",0,original
"To this purpose, different authors   propose the use of the so-called log-linear models, where the decision rule is given by the expression y = argmax y Msummationdisplay m=1 mhm    where hm  is a score function representing an important feature for the translation of x into y, M is the number of models   and m are the weights of the log-linear combination.",0,original
"Statistical Model In SIFTs statistical model, augmented parse trees are generated according to a process similar to that described in Collins  .",0,original
ch   described the use of minimum error training directly optimizing the error rate on automatic MT evaluation metrics such as BLEU,0,original
Parameters were tuned with MERT algorithm   on the NIST evaluation set of 2003   for both the baseline systems and the system combination model.,0,original
"We observe that AER is loosely correlated to BLEU   though the relation is weak, as observed earlier by Fraser and Marcu  .",0,original
"Head word   of the constituent  After POS tagging, a syntactic parser   was then used to obtain the parse tree for the sentence.",0,original
"Significant neighbor-based co-occurrence: As discussed in  , it is possible to measure the amount of surprise to see two neighboring words in a corpus at a certain frequency under the assumption of independence.",0,original
"3.1 Results for English We used sections 0 to 12 of the WSJ part of the Penn Treebank   with a total of 24,618 sentences for our experiments.",0,original
"3.2 Conversion to Dependencies 3.2.1 Syntactic Dependencies There exists no large-scale dependency treebank for English, and we thus had to construct a dependency-annotated corpus automatically from the Penn Treebank  .",0,original
"2.4 Reordering Reordering features take many forms in MT. In phrase-based systems, reordering is accomplished both within phrase pairs   as well as through distance-based distortion models   and lexicalized reordering models  .",0,original
"After building the chunker, students were asked to 4 choose a verb and then analyze verb-argument structure  ).",0,original
"In this work, we focus on learning bilingual word phrases by using Stochastic Inversion Transduction Grammars    .",0,original
"Each i is a weight associated with feature i, and these weights are typically optimized using minimum error rate training  .",0,original
32-39 Proceedings of HLT-NAACL 2003 similar distribution patterns  .,0,original
"There are also automatic methods for summary evaluation, such as ROUGE  , which gives a score based on the similarity in the sequences of words between a human-written model summary  and  the  machine  summary.",0,original
"the syntax-based system, we ran a reimplementation of the Collins parser   on the English half of the bitext to produce parse trees, then restructured and relabeled them as described in Section 3.2.",0,original
The kappa value   was used to evaluate the agreement among the judges and to estimate how difficult the evaluation task was.,0,original
"In contrast, the latter computes four definite probabilities  which are included as features within a machine-learning classifier  from the Web in an attempt to overcome Bean and Riloffs   data sparseness problem.",0,original
"We show that link 1For a complete discussion of alignment symmetrization heuristics, including union, intersection, and refined, refer to  .",0,original
"In contrast, generative models are trained to maximize the joint probability of the training data, which is 1Ramshaw and Marcus   used transformation-based learning  , which for the present purposes can be tought of as a classi cation-based method.",0,original
3.1 Conditional Random Field for Alignment Our conditional random field   for alignment has a graphical model structure that resembles that of IBM Model 1  .,0,original
"Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases  .",0,original
"As for parser, we train three off-shelf maximum-entropy parsers   using the Arabic, Chinese and English Penn treebank  .",0,original
"Furthermore, WASP1++ employs minimum error rate training   to directly optimize the evaluation metrics.",0,original
"Syntax based statistical MT approaches began with  , who introduced a polynomial-time solution for the alignment problem based on synchronous binary trees.",0,original
Logics for the IBM Models   would be similar to our logics for phrase-based models.,0,original
"Its applications range from sentence boundary disambiguation   to part-of-speech tagging  , parsing   and machine translation  .",0,original
The bigram translation probability t2  specifies the likelihood that target word f is to follow f in a phrase generated by source word e. 170 2.1 Properties of the Model and Prior Work The formulation of the WtoP alignment model was motivated by both the HMM word alignment model   and IBM Model-4 with the goal of building on the strengths of each.,0,original
"Unsupervised Learning: Results To test the effectiveness of the above unsupervised learning algorithm, we ran a number of experiments using two different corpora and part of speech tag sets: the Penn Treebank Wall Street Journal Corpus \ .",0,original
The learning algorithm used for each stage of the classification task is a regularized variant of the structured Perceptron  .,0,original
We also implemented an averaged perceptron system     for comparison.,0,original
hese tables were computed from a small fragment of the Canadian Hansards that has been used in a number of other studies: Church   and Simard et al  ,0,original
Their experiments were performed using a decoder based on IBM Model 4 using the translation techniques developed at IBM  .,0,original
The algorithm is exactly the same as the one described in   to find the most probable part-of-speech sequence.,0,original
"Section 3 describes two standard lexicalized models  , as well as an unlexicalized baseline model.",0,original
We used the heuristic combination described in   and extracted phrasal translation pairs from this combined alignment as described in  .,0,original
"Most of them were developed for exhaustive parsing, i.e., producing all parse results that are given by the grammar  .",0,original
We evaluated annotation reliability by using the Kappa statistic  .,0,original
" ,  ,  ,  ,  ,  ), and to pick those ingredients which are known to be con~i)utationally 'tractable' in some sense.",0,original
The feature weights were optimized against the BLEU scores  .,0,original
SR thus adopts the method proposed by Och  ,0,original
"For the named entity features, we used a fairly standard feature set, similar to those described in  .",0,original
It has been further observed that simply compressing sentences individually and concatenating the results leads to suboptimal summaries  .,0,original
Adaptations to the algorithms in the presence of ngram LMs are discussed in  .,0,original
"In  , the authors use the transcripts of debates from the US Congress to automatically classify speeches as supporting or opposing a given topic by taking advantage of the voting records of the speakers.",0,original
Various methods   have been proposed for synonym acquisition.,0,original
"Aligning tokens in parallel sentences using the IBM Models  ,   may require less information than full-blown translation since the task is constrained by the source and target tokens present in each sentence pair.",0,original
"Pereira  , Curran   and Lin   use syntactic features in the vector definition.",0,original
A more recent bootstrapping approach is described in  .,0,original
"The translation quality is measured by three MT evaluation metrics: TER  , BLEU  , and METEOR  .",0,original
2008a; 2008b) on CTB 5.0 and Zhang and Clark   on CTB 4.0 since they reported the best performances on joint word segmentation and POS tagging using the training materials only derived from the corpora,0,original
We measure translation performance by the BLEU   and METEOR   scores with multiple translation references.,0,original
"The decoder uses a binarized representation of the rules, which is obtained via a syncronous binarization procedure  .",0,original
"In  , a small set of sample results are presented.",0,original
This approach is similar to conventional techniques for automatic thesaurus construction  .,0,original
"Most importantly, whereas the one-sense-per-discourse assumption   also applies to discriminating images, there is no guarantee of a local collocational or co-occurrence context around the target image.",0,original
"The phrase bilexicon is derived from the intersection of bidirectional IBM Model 4 alignments, obtained with GIZA++  , augmented to improve recall using the grow-diag-final heuristic.",0,original
We perform minimum error rate training   to tune the feature weights for the log-linear modeltomaximizethesystemssBLEUscoreonthe development set.,0,original
"In this paper, we make a direct comparison of a syntactically unsupervised alignment model, based on Wu  , with a syntactically supervised model, based on Yamada and Knight  .",0,original
he patterns will be manually constructed following the approach of Hearst   and Nakov and Hearst  .6 The example collection for each relation R will be passed to two independent annotators,0,original
"Prior to running the parsers, we trained the POS tagger described in  .",0,original
"The acquisition of clues is a key technology in these research efforts, as seen in learning methods for document-level SA   and for phraselevel SA  .",0,original
"Because their joint distributions have such closed-form expressions, the parameters can be estimated directly from the training data without the need for an iterative fitting procedure  ).",0,original
"Figures 1 and 2 present best results in the learning experiments for the complete set of patterns used in the collocation approach, over two of our evaluation corpora.11 Type Positions Tags/Words Features Accuracy Precision Recall GIS 1 W 1254 0.97 0.96 0.98 IIS 1 T 136 0.95 0.96 0.94 NB 1 T 136 0.88 0.97 0.84 9 see Rish, 2001, Ratnaparkhi, 1997 and Berger et al, 1996 for a formal description of these algorithms.",0,original
"The Maximum Entropy model   is a conditional model that assigns a probability to every possible parse  for a given sentence s. The model consists of a set of m feature functions fj  that describe properties of parses, together with their associated weights j. The denominator is a normalization term where Y   is the set of parses with yield s: p  = exp )summationtext yY   exp ))   The parameters   j can be estimated efficiently by maximizing the regularized conditional likelihood of a training corpus  :  = argmax  logL   summationtextm j=1  2j 22   where L  is the likelihood of the training data.",0,original
"There are good reasons for using such a hand-crafted, genre-specific verb lexicon instead of a general resource such as WordNet or Levins   classes: Many verbs used in the domain of scientific argumentation have assumed a specialized meaning, which our lexicon readily encodes.",0,original
"We applied the union, intersection and refined symmetrization metrics   to the final alignments output from training, as well as evaluating the two final alignments directly.",0,original
"Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni   showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score   of at best 69%and that only when restricted to keep most words very close to their source positions.",0,original
A large corpus is vahmble as a source of such nouns  .,0,original
"We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged  ).",0,original
"However, with the algorithms proposed in  , it is possible to develop a general-purpose decoder that can be used by all the parsing-based systems.",0,original
"These tools are important in that the strongest collocational associations often represent different word senses, and thus 'they provide a powerful set of suggestions to the lexicographer for what needs to be accounted for in choosing a set of semantic tags'  .",0,original
"  and  , the specific technique we used by means of a context language model is rather different.",0,original
"Let W1,W2 be the vocabulary sizes of the two languages, and N = {A1,,AN} be the set of nonterminals with indices 1,,N. Wu   also showed that ITGs can be equivalently be defined in two other ways.",0,original
"Stochastic taggers use both contextual and morphological information, and the model parameters are usually defined or updated automatically from tagged texts  , University of Patras, 265 00 Patras, Greece.",0,original
"A quick search in the Penn Treebank   shows that about 17% of all sentences contain parentheticals or other sentence fragments, interjections, or unbracketable constituents.",0,original
"To identify these, we use a word-aligned corpus annotated with parse trees generated by statistical syntactic parsers  .",0,original
"They used the Bleu evaluation metric  , but capped the n-gram precision at 4-grams.",0,original
"The underlying formalisms used has been quite broad and include simple formalisms such as ITGs  , hierarchicalsynchronousrules , string to tree models by   and  , synchronous CFG models such    , synchronous Lexical Functional Grammar inspired approaches   and others.",0,original
"Training Procedure Our algorithm is a modification of the perceptron ranking algorithm  , which allows for joint learning across several ranking problems  .",0,original
The following treebanks were used for training the parser:  .,0,original
"Several algorithms have been proposed in the literature that try to find the best splits, see for instance  .",0,original
The latter problem of developing methods that can work with incomplete supervisory information is addressed in a subsequent effort  .,0,original
"Examples are Andersen  , Okanohara and Tsujii  , Sun et al.",0,original
"One solution would be to apply the maximum entropy estimation technique  ) to all of the three components of the SLM, or at least to the CONSTRUCTOR.",0,original
"Snow etal   use known hypernym/hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns.",0,original
"We use a bidirectional search strategy  , and our algorithm is based on Perceptron learning  .",0,original
"This approach attempts to improve translation quality by optimizing an automatic translation evaluation metric, such as the BLEU score  .",0,original
"Previous uses of this model include language modeling , machine translation , prepositional phrase attachment , and word morphology .",0,original
It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments  .,0,original
"In our SRL system, we select maximum entropy   as a classi er to implement the semantic role labeling system.",0,original
The first approaches are used for Penn Treebank   and the KAIST language resource  .,0,original
ollins and Roark   presented a linear parsing model trained with an averaged perceptron algorithm,0,original
"It is interesting to constrast this method with the """"parse-parse-match"""" approaches that have been reported recently for producing parallel bracketed corpora  .",0,original
bney   presented a thorough discussion on the Yarowsky algorithm,0,original
"This is also true for reranking and discriminative training, where the k-best list of candidates serves as an approximation of the full set  .",0,original
The analyser--and therefore the generator-includes exception lists derived from WordNet  .,0,original
"The first model, referred to as Maxent1 below, is a loglinear combination of a trigram language model with a maximum entropy translation component that is an analog of the IBM translation model 2  .",0,original
POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit  ; both were trained from the annotated Penn Treebank corpus  .,0,original
Several automatic sentence alignment approaches have been proposed based on sentence length   and lexical information  .,0,original
"These findings are somehow surprising since it was eventually believed by the community that adding large amounts of bitexts should improve the translation model, as it is usually observed for the language model  .",0,original
"As has been pointed out by Dunning  , the calculation of log  assumes a binomial distribution.",0,original
"From this aligned training corpus, we extract the phrase pairs according to the heuristics in  .",0,original
"  and Lee  ) can be generally divided into three types: discounting  , class-based smoothing  , and distance-weighted averaging  .",0,original
8.1 The Averaged Perceptron Algorithm with Separating Plane The averaged perceptron algorithm   has previously been applied to various NLP tasks   for discriminative reranking.,0,original
"Barzilay and Lee   learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases.",0,original
We run the decoder with its default settings and then use Koehn's implementation of minimum error rate training   to tune the feature weights on the development set.,0,original
"For the efficiency of minimum-error-rate training  , we built our development set   using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data.",0,original
We use Viterbi training   but neighborhood estimation   or pegging   could also be used.,0,original
"Preparing an aligned abbreviation corpus, we obtain the optimal combination of the features by using the maximum entropy framework  .",0,original
"For example, it has been observed that texts often contain multiple opinions on different topics  , which makes assignment of the overall sentiment to the whole document problematic.",0,original
"We compare those algorithms to generalized iterative scaling    , non-preconditioned CG, and voted perceptron training  .",0,original
"Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction  , phrasal translation  , target word selection  , domain word translation  , sense disambiguation  , and even recently for query translation in cross-language IR as well  .",0,original
p and pt are feature weights set by performing minimum error rate training as described in Och  ,0,original
"In the multilingual parsing track, participants train dependency parsers using treebanks provided for ten languages: Arabic  , Basque  , Catalan  , Chinese  , Czech  , English  , Greek  , Hungarian  , Italian  , and Turkish  .",0,original
This alignment representation is a generalization of the baseline alignments described in   and allows for many-to-many alignments.,0,original
"2 Related Work This method is similar to block-orientation modeling   and maximum entropy based phrase reordering model  , in which local orientations   of phrase pairs   are learned via MaxEnt classifiers.",0,original
Parameter tuning is done with Minimum Error Rate Training    .,0,original
"1 Introduction In statistical machine translation, output translations are evaluated by their similarity to human reference translations, where similarity is most often measured by BLEU  .",0,original
.1 NP Our NP chunks are very similar to the ones of Ramshaw and Marcus  ,0,original
"The text was split at the sentence level, tokenized and PoS tagged, in the style of the Wall Street Journal Penn TreeBank  .",0,original
"With the exception of  , most unsupervised work on PP attachment is based on superficial analysis of the unlabeled corpus without the use of partial parsing  .",0,original
"The measure simHinate is the same as the similarity measure proposed in  , except that it does not use dependency triples with negative mutual information.",0,original
"We tested several measures, such as ROUGE   and the cosine distance.",0,original
"The word alignment is computed using GIZA++2 for the selected 73,597 sentence pairs in the FBIS corpus in both directions and then combined using union and heuristic diagonal growing  .",0,original
hang and Clark     generated CTB 3.0 from CTB 4.0,0,original
"So unlike some other studies  , we used manually annotated alignments instead of automatically generated ones.",0,original
3The usefulness of position varies significantly in different genres  .,0,original
e collected training samples from the Brown Corpus distributed with the Penn Treebank  ,0,original
"In addition, a number of approaches have focused on developing discriminative approaches for unsupervised and semi-supervised tagging  .",0,original
1 Introduction The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual LexicalFunctional Grammar     resources from treebanks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers  .,0,original
"Statistic-based algorithms based on Belief Network  such as Hidden-MarkovModel   , Lexicalized HMM  and Maximal-Entropy model  use the statistical information of a manually tagged corpus as background knowledge to tag new sentences.",0,original
The recall problem is usually addressed by increasing the amount of text data for extraction  ) or by developing more surface patterns  .,0,original
"Part-ofspeech taggers are used in a few applications, such as speech synthesis   and question answering  .",0,original
"This iterative optimiser, derived from a word disambiguation technique  , finds the nearest local maximum in the lexical cooccurrence network from each concept seed.",0,original
Mihalcea   shows that Wikipedia can indeed be used as a sense inventory for sense disambiguation,0,original
"3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank  , converted to dependency format.",0,original
"The mixture coefficients are trained in the usual way  , so that the additional context is exploited when it is useful and ignored when it isnt. The paper proceeds as follows.",0,original
This is known as cost-based abduction  .,0,original
5 Related Work Automatically finding sentences with the same meaning has been extensively studied in the field of automatic paraphrasing using parallel corpora and corporawith multiple descriptionsof the same events  .,0,original
Learning We model the problem of selecting the best derivation as a structured prediction problem  .,0,original
"Consequently, semi-supervised learning, which combines both labeled and unlabeled data, has been applied to some NLP tasks such as word sense disambiguation  , classification  , clustering  , named entity classification  , and parsing  .",0,original
"Models of this type include:  , which use semantic word clustering, and  , which uses variablelength context.",0,original
6 Discourse Context   pointed out that the sense of a target word is highly consistent within any given document  .,0,original
3.3 Language Model   As a second baseline we use the classification based on the language model using overlapping ngram sequences   as suggested by Pang & Lee   for the English language.,0,original
ll our MT systems were trained using a variant of the alignment template model described in  ,0,original
ntroduction Automatic word alignment   is a vital component of all statistical machine translation   approaches,0,original
"For example,   developed a system to identify inflammatory texts and   developed methods for classifying reviews as positive or negative.",0,original
he only difference is that we 5See also work on partial parsing as a task in its own right: Hindle   inter alia,0,original
"Similarly, Smadja   uses a six content word window to extract significant collocations.",0,original
he principal training method is an adaptation of averaged perceptron learning as described by Collins  ,0,original
  study the shortest hyperpath problem and Nielsen et al,0,original
"While close attention has been paid to multi-document summarization technologies  , the inherent properties of humanwritten multi-document summaries have not yet been quantified.",0,original
Examples of such early work include  .,0,original
"The other main difference is the apparently nonlocal nature of the problem, which motivates our choice of a Maximum Entropy   model for the tagging task  .",0,original
"For the evaluation of translation quality, we applied standard automatic evaluation metrics, i.e., BLEU   and METEOR  .",0,original
"They are part of an effort to better integrate a linguistic, rule-based system and the statistical correcting layer also illustrated in  .",0,original
"The first one, GIZA-Lex, is obtained by running the GIZA++2 implementation of the IBM word alignment models   on the initial parallel corpus.",0,original
This model is similar in spirit to IBM model 1  .,0,original
"First, the addition of each modification improves the F-score for both true and system mentions 9The H&K results shown here are not directly comparable with those reported in Haghighi and Klein  , since H&K evaluated their system on the ACE 2004 coreference corpus.",0,original
P-STM -l This metric corresponds to the STM metric presented by Liu and Gildea  ,0,original
" ), less prior work exists for bilingual acquisition of domain-specific translations.",0,original
The Bloomier filter LM   has a precomputed matching of keys shared between a constant number of cells in the filter array.,0,original
"The data consist of sections of the Wall Street Journal   part of the Penn TreeBank  , with information on predicate-argument structures extracted from the PropBank corpus  .",0,original
"Inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection  , text summarization  , word sense disambiguation  , sentiment analysis  , and sentence retrieval for question answering  .",0,original
A possible solution to this problem is to directly estimate p  by applying a maximum entropy model  .,0,original
Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar    .,0,original
"However, existing models of disambiguation with lexicalized grammars are a mere extension of lexicalized probabilistic context-free grammars    , which are based on the decomposition of parsing results into the syntactic/semantic dependencies of two words in a sentence under the assumption of independence of the dependencies.",0,original
"For instance, some approaches coarsely discriminate between biographical and non-biographical information  ,whileothersgobeyondbinary distinction by identifying atomic events  e.g., occupation and marital status  that are typically included in a biography  .",0,original
It uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories   and the forward backward algorithm efficiently sums over all histories to give a distibution for each word.,0,original
We also employ the voted perceptron algorithm   and the early update technique as in  .,0,original
"Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example Yarowsky   and Schtitze   who quoted results for 12 words, and a second group, including Leacock, Towell, and Voorhees   and Bruce and Wiebe  , who gave results for just one, namely interest.",0,original
We then train word alignment models   using 6 Model-1 iterations and 6 HMM iterations.,0,original
Phrases are then extracted from the word alignments using the method described in  .,0,original
.1 Background Smith and Eisner   introduced the quasisynchronous grammar formalism,0,original
EMD training   combines generative and discriminative elements.,0,original
he weights of the models are computed automatically using a variant of the Maximum Bleu training procedure proposed by Och  ,0,original
"However, in the Grammar Association context, when developing   the basic equations of the system presented in  , it is said that the reverse model for a28 a13a37a3a38a5a39a32a21a0a35a7 does not seem to admit a simple factorization which is also correct and convenient, so crude heuristics were adopted in the mathematical development of the expression to be maximized.",0,original
The application of this algorithm to the basic problem using a parallel bilingual corpus aligned on the sentence level is described in  .,0,original
"Then, it models the correlations between the pivot features and all other features by training linear pivot predictors to predict occurrences of each pivot in the unlabeled data from both domains  .",0,original
This is con rmed by the translation experiments in which the evaluation data sets were translated using the servers translation engines and the translation quality was evaluated using the standard automatic evaluation metrics BLEU   and METEOR   where scores range between 0   and 1  .,0,original
"First, two maximum entropy classifiers   are applied, where the first predicts clause start labels and the second predicts clause end labels.",0,original
"Let w be a target word and Nw = fn1,n2nkg be the ordered set of the top scoring k neighbours of w from the thesaurus with associated distributional similarity scores fdss ,dss ,dss g using  .",0,original
"Recently, Bean and Riloff   presented an unsupervised approach to coreference resolution, which mined the co-referring NP pairs with similar predicatearguments from a large corpus using a bootstrapping method.",0,original
Dredze et al. also indicated that unlabeled dependency parsing is not robust to domain adaptation  .,0,original
"According to one account   the majority of errors arise because of the statistical filtering process, which is reported to be particularly unreliable for low frequency SCFs  .",0,original
"In their presentation of the factored SMT models, Koehn and Hoang   describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags.",0,original
any 412 Turney Similarity of Semantic Relations researchers have argued that metaphor is the heart of human thinking  ,0,original
"Ratnaparkhi, 1996), a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence.",0,original
" ), concordancing for bilingual lexicography  , computerassisted language learning, corpus linguistics (Melby.",0,original
"SMT Team   also used minimum error training as in Och  , but used a large number of feature functions.",0,original
Antonyms often indicate the discourse relation of contrast  .,0,original
"4.2 Cast3LB Function Tagging For the task of Cast3LB function tag assignment we experimented with three generic machine learning algorithms: a memory-based learner  , a maximum entropy classifier   and a Support Vector Machine classifier  .",0,original
"One is to find unknown words from corpora and put them into a dictionary  ), and the other is to estimate a model that can identify unknown words correctly  ).",0,original
"For example, in our previous work  , we have used a statistical translation memory of phrases in conjunction with a statistical translation model  .",0,original
The noun phrase chunking   module uses the basic NP chunker software from 483   to recognize the noun phrases in the question.,0,original
ts distribution is asymptotic to a  2 distribution and can hence be used as a test statistic  ,0,original
"Most existing methods treat word tokens as basic alignment units  , however, many languages have no explicit word boundary markers, such as Chinese and Japanese.",0,original
"We report BLEU scores   on untokenized, recapitalized output.",0,original
"The pipeline extracts a Hiero-style synchronous context-free grammar  , employs suffix-array based rule extraction  , and tunes model parameters with minimum error rate training  .",0,original
This model shares some similarities with the stochastic inversion transduction grammars   presented by Wu in  .,0,original
he algorithm proposed by Turney   is labeled as Turney-PairClass,0,original
"To combine the many differently-conditioned features into a single model, we provide them as features to the linear model   and use minimum error-rate training   to obtain interpolation weights m. This is similar to an interpolation of backed-off estimates, if we imagine that all of the different contextsaredifferently-backedoffestimatesofthe complete context.",0,original
"Therefore,   defined the translation candidate with the minimum word-error rate as pseudo reference translation.",0,original
"3.3 Features Similar to the default features in Pharaoh  , we used following features to estimate the weight of our grammar rules.",0,original
he usefulness of likelihood ratios for collocation detection has been made explicit by Dunning   and has been confirmed by an evaluation of various collocation detection methods carried out by Evert and Krenn  ,0,original
"In Section 2, we examine aggregate Markov models, or class-based bigram models   in which the mapping from words to classes 81 is probabilistic.",0,original
"Peter F. Brown, Vincent J. Della Pietra, Petere V. deSouza, Jenifer C. Lai, and Robert L. Mercer.",0,original
"Since we also adopt a linear scoring function in Equation  , the feature weights of our combination model can also be tuned on a development data set to optimize the specified evaluation metrics using the standard Minimum Error Rate Training   algorithm  .",0,original
"Ultinmtely, however, it seems that a more complex ai)t)roach incorporating back-off and smoothing is necessary ill order to achieve the parsing accuracy achieved by Charniak   and Collins  .",0,original
ethod Correlation Edge-counting 0.664 Jiang & Conrath   0.848 Lin   0.822 Resnik   0.745 Li et al,0,original
"While it was initially believed that lexicalization of PCFG parsers   is crucial for obtaining good parsing results, Gildea   demonstrated that the lexicalized Model-1 parser of Collins   does not benefit from bilexical information when tested on a new text domain, and only marginally benefits from such information when tested on the same text domain as the training corpora.",0,original
"Like baseNP chunking , content chunk parsing is also a kind of shallow parsing.",0,original
Recent work   on this task explored a variety of methodologies to address this issue.,0,original
The probabilities of derivation decisions are modelled using the neural network approximation   to a type of dynamic Bayesian Network called an Incremental Sigmoid Belief Network    .,0,original
The parameters of the MT system were optimized on MTEval02 data using minimum error rate training  .,0,original
"GIZA++ toolkit   is used to perform word alignment in both directions with default settings, and the intersect-diag-grow method is used to generate symmetric word alignment refinement.",0,original
  introduce IBM Models 1-5 for alignment modelling; Vogel et al,0,original
"While error-driven training techniques are commonly used to improve the performance of phrasebased translation systems  , this paper presents a novel block sequence translation approach to SMT that is similar to sequential natural language annotation problems 727 such as part-of-speech tagging or shallow parsing, both in modeling and parameter training.",0,original
"In acknowledgment of this fact, a series of conferences like Text Retrieval Conferences    , Message Understanding Conferences    , TIPSTER SUMMAC Text Summarization Evaluation  , Document Understanding Conference    , and Text Summar</context> </contexts> <marker>Voorhees, Harman, 1999</marker> <rawString>Voorhees, E. M. and Harman, D. K., 1999.",0,original
"Variations of SCFGs go back to Aho and Ullman  s Syntax-Directed Translation Schemata, but also include the Inversion Transduction Grammars in Wu  , which restrict grammar rules to be binary, the synchronous grammars in Chiang  , which use only a single nonterminal symbol, and the Multitext Grammars in Melamed  , which allow independent rewriting, as well as other tree-based models such as Yamada and Knight   and Galley et al.",0,original
"However, there is little agreement on what types of knowledge are helpful: Some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in Meteor   or MaxSim  .",0,original
"This operation can be used in applications like Minimum Error Rate Training  , or optimizing system combination as described by Hillard et al.",0,original
2 Related work Our approach for emotion classification is based on the idea of   and is similar to those of   and  .,0,original
e solve SAT analogies with a simplified version of the method of Turney  ,0,original
"Other methods include rule-based systems  , maximum entropy models  , and memory-based models  .",0,original
"While in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types  .",0,original
"Although some early systems for web-page analysis induce rules at character-level   and DIPRE  ), most recent approaches for set expansion have used either tokenized and/or parsed free-text  , or have incorporated heuristics for exploiting HTML structures that are likely to encode lists and tables  .",0,original
"It has been noticed, for example that capitalized and hyphenated words have a different distribution from other words.",0,original
"Second, we will discuss the work done by   who use clustering of paraphrases to induce rewriting rules.",0,original
"For nonprojective parsing, the analogy to the inside algorithm is the O  matrix-tree algorithm, which is dominated asymptotically by a matrix determinant  .",0,original
"First, a parsing-based approach attempts to recover partial parses from the parse chart when the input cannot be parsed in its entirety due to noise, in order to construct a   semantic representation  .",0,original
"Consequently, we abstract away from specifying a distribution by allowing the user to assign labels to features   , Druck et al.",0,original
"Recently, specic probabilistic tree-based models have been proposed not only for machine translation  , but also for summarization  , paraphrasing  , natural language generation  , parsing, and language modeling (Baker 1979; Lari and Young 1990; Collins 1997; Chelba and Jelinek 2000; Charniak 2001; Klein  Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292.",0,original
"For instance, several studies have shown that BLEU correlates with human ratings on machine translation quality  .",0,original
This example is adapted from Resnik  ,0,original
"We build sentencespecific zero-cutoff stupid-backoff   5-gram language models, estimated using 4.7B words of English newswire text, and apply them to rescore each 10000-best list.",0,original
"3 Implementation 3.1 Pronoun resolution model We built a machine learning based pronoun resolution engine using a Maximum Entropy ranker model  , similar with Denis and Baldridges model  .",0,original
"The WSJNPVP set consists of part-of speech tagged Wall Street Journal material  , supplemented with syntactic tags indicating noun phrase and verb phrase boundaries  .",0,original
Skipchain CRF model is applied for entity extraction and meeting summarization  .,0,original
"The cohesion between words has been evaluated with the mutual information measure, as in  .",0,original
he weights of these models are determined using the max-BLEU method described in Och  ,0,original
"They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.11 Weighted Fully-Connected F-Measure Given a hypothesized set of alignment links H and a goldstandard set of alignment links G, we define H+ = fullyConnect  and G+ = fullyConnect , and then compute: f-measure  = 1 precision  + 1 recall  For phrase-based Chinese-English and ArabicEnglish translation tasks,   obtain the closest correlation between weighted fully-connected alignment f-measure and BLEU score using =0.5 and =0.1, respectively.",0,original
Then we use both Moses decoder and its suppo We run the decoder with its d then use Moses' implementation of minimum error rate training   to tune the feature weights on the development set.,0,original
5 Related Work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective  ) and adjacency pair information has been used to predict congressional votes  .,0,original
"Though this model uses trees in the formal sense, it does not create Penn Treebank   style linguistic trees, but uses only one non-terminal label   to create those trees using six simple rule structures.",0,original
"The standard split of the corpus into training  , validation  , and testing   was performed.2 As in   we used a publicly available tagger   to provide the part-of-speech tag for each word in the sentence.",0,original
"These tags are drawn from a tagset which is constructed by 363 extending each argument label by three additional symbols a80a44a81a83a82a84a81a86a85, following  .",0,original
"Regarding error detection in corpora, Ratnaparkhi   discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style.",0,original
Much of the recent work in word alignment has focussed on improving the word alignment quality through better modeling   or alternative approaches to training  .,0,original
"  also uses wide context, but incorporates the one-senseper-discourse and one-sense-per-collocation constraints, using an unsupervised learning technique.",0,original
"1 Introduction In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types  .",0,original
"model reranking has also been established, both for synchronous binarization   and for target-only binarization  .",0,original
"Under the maximum entropy framework  , evidence from different features can be combined with no assumptions of feature independence.",0,original
"The progression in the probabilistic parsing literature has been to start with lexical head-head dependencies   and then add non-lexical sis2 This result generalizes to Ss, which are also flat in Negra  .",0,original
2.2 The Choice of Co-occurrence ~qeasure and Matrix Distance There :~:c many alternatives to measure cooccurrence between two words x and y  .,0,original
"There has of course been a large amount of work on the more general problem of word-sense disambiguation, e.g.,    .",0,original
"5We use deterministic sampling, which is useful for reproducibility and for minimum error rate training  .",0,original
"5.5 Applying F-score Optimization Technique In addition, we can simply apply the F-score optimization technique for the sequence labeling tasks proposed in   to boost the HySOL performance since the base discriminative models pD  and discriminative combination, namely Equation  , in our hybrid model basically uses the same optimization procedure as CRFs.",0,original
"Previous studies have shed light on the predictability of the next unix command that a user will enter  , the next keystrokes on a small input device such as a PDA  , and of the translation that a human translator will choose for a given foreign sentence  .",0,original
A perceptron algorithm gives 97.11%  .,0,original
"In the Link Grammar framework  , strictly local contexts are naturally combined with long-distance information coming from long-range trigrams.",0,original
"The most important tree-bank transformation in the literature is lexicalization: Each node in a tree is labeled with its head word, the most important word of the constituent under the node  , Collins  , Charniak  , Collins  , Carroll and Rooth  , etc.).",0,original
For every class the weights of the active features are combined and the best scoring class is chosen  .,0,original
"WordNet has been criticized for being overly finegrained  , we are using it here because it is the sense inventory used by Erk et al.",0,original
"We tokenized sentences using the standard treebank tokenization script, and then we performed part-of-speech tagging using MXPOST tagger  .",0,original
The HWC metrics compare dependency and constituency trees for both reference and machine translations  .,0,original
"In this paper we extend this work to represent sets of situation-specific events not unlike scripts, caseframes  , and FrameNet frames  .",0,original
"This includes the automatic generation of sense-tagged data using monosemous relatives  , automatically bootstrapped disambiguation patterns  , parallel texts as a way to point out word senses bearing different translations in a second language  , and the use of volunteer contributions over the Web  .",0,original
"This weak supervision has been encoded using priors and initializations  , specialized models  , and implicit negative evidence  .",0,original
"Many methods have been proposed to compute distributional similarity between words, e.g.,  ,  ,   and  .",0,original
"This was used, for example, by   in information extraction, and by   in POS tagging.",0,original
nd Semantic Knowledge Sources for Coreference Resolution Ponzetto & Strube   and Strube & Ponzetto   aimed at showing that the encyclopedia that anyone can edit can be indeed used as a semantic resource for research in NLP,0,original
"Related Works Generally speaking, approaches to MWE extraction proposed so far can be divided into three categories: a) statistical approaches based on frequency and co-occurrence affinity, b) knowledgebased or symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods  .",0,original
We used the averaged perceptron algorithm   to train the parameters of the model.,0,original
"These heuristics define a phrase pair to consist of a source and target ngrams of a word-aligned source-target sentence pair such that if one end of an alignment is in the one ngram, the other end is in the other ngram    .",0,original
"However, as   do not propose any evaluation of which clustering algorithm should be used, we experiment a set of clustering algorithms and present the comparative results.",0,original
"While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved   Measures based on distance between words in the text.",0,original
"Word association norms, mutual information, and lexicography, Computational Linguistics, 16 : 22-29 Marcus, M. et al. 1993.",0,original
The other 5 have been suggested for Dutch by  .,0,original
"Moreover, our approach integrates the abbreviation translation component into the baseline system in a natural way, and thus is able to make use of the minimum-error-rate training   to automatically adjust the model parameters to reflect the change of the integrated system over the baseline system.",0,original
"Since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning  , manually-de ned coreference patterns to mine speci c kinds of data  , or accepted the noise inherent in unsupervised schemes  .",0,original
"At the sentence level,   employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora.",0,original
Alignment is often used in training both generative and discriminative models  .,0,original
"For the first set of experiments, we divide all inputs based on the mean value of the average system scores as in  .",0,original
"One possible conclusion from the POS tagging literature is that accuracy is approaching the limit, and any remaining improvement is within the noise of the Penn Treebank training data  .",0,original
The basic LCS has a problem that it does not differentiate LCSes of different spatial relations within their embedding sequences  .,0,original
"As an example, consider the fiat NP structures that are in the Penn Treebank  .",0,original
"This is well illustrated by the Collins parser  , scrutinized by Bikel  , where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation.",0,original
"Perhaps this was not observed earlier since   studied only base NPs, most of which are short.",0,original
"In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in  .",0,original
"An alternative method we considered was to estimate certain conditional probabilities, similarly to the formula used in  : SW  log P  f f  = ~ log   P  f f  Here f  is   the probability that any given candidate phrase will be accepted by the spotter, and f  is the probability that this phrase is rejected, i.e., f  = l-f  .",0,original
440 respondence learning   domain adaptation algorithm   for use in sentiment classification.,0,original
"Therefore, whenever we have access to a large amount of labeled data from some source  , but we would like a model that performs well on some new target domain  , we face the problem of domain adaptation.",0,original
"Second, in keeping with ontological promiscuity  , we represent the importance of attributes by the salience of events and states in the discourse model--these states and events now have the same status in the discourse model as any other entities.",0,original
"Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography  , computer-assisted language learning, and tools for translators (e.g.",0,original
The syntactic parameters are the same as in Section 5.1 and are smoothed as in  .,0,original
Our corpora were automatically aligned with Giza++   in both directions between source and target and symmetrised using the intersection heuristic  .,0,original
"In the first set of experiments, we compare two settings of our UALIGN system with other aligners, GIZA++     and LEAF    .",0,original
"We use the by now standard a0 statistic   to quantify the degree of above-chance agreement between multiple annotators, and the a1 statistic for analysis of sources of unreliability  .",0,original
"In addition to reducing the original sentences, Jing and McKeown   use a number of manually compiled rules to aggregate reduced sentences; for example, reduced clauses might be conjoined with and.",0,original
"In recent years, many researchers have employed statistical models   or association measures   to build alignment links.",0,original
BLEU   is one of the methods for automatic evaluation of translation quality.,0,original
"6 Related Work In machine translation, the concept of packed forest is first used by Huang and Chiang   to characterize the search space of decoding with language models.",0,original
"By introducing the hidden word alignment variable a   , the optimal translation can be searched for based on the following criterion: * 1 , arg max ) M mm m ea eh = = efa               where  is a string of phrases in the target language, e f  fa    is the source language string of phrases,  he  are feature functions, weights   m m  are typically optimized to maximize the scoring function  .",0,original
"Both the global models   use fairly small training sets, and there is no evidence that their techniques will scale to larger data sets.",0,original
"3 The Effect of Training Corpus Size A number of past research work on WSD, such as  , were tested on a small number of words like """"line"""" and """"interest"""".",0,original
"Also, we chose to average each individual perceptron   prior to Bayesian averaging.",0,original
"As an alternative, Huang and Chiang   describes a forest-based reranking algorithm called cube growing, which also employs beam search, but focuses computation only where necessary in a top-down pass through a parse forest.",0,original
"Similarly,   propose a relative distortion model to be used with a phrase decoder.",0,original
"Also relevant is previous work that applied machine learning approaches to MT evaluation, both with human references   and without  .",0,original
"Applying the projection WTx   would give us m new features, however, for both computational and statistical reasons   a low-dimensional approximation of the original feature space is computed by applying Singular Value Decomposition   on W  .",0,original
"Unfortunately, as shown in  , with the represetation of sentences that we use, linear classifiers cannot discriminate real sentences from sentences sampled from a trigram, which is the model we use as a baseline, so here we resort to a non-linear large-margin classifier  .",0,original
"We use binary Synchronous ContextFree Grammar  , based on Inversion Transduction Grammar    , to define the set of eligible segmentations for an aligned sentence pair.",0,original
3.3 Syntax based approach An alternative to the Window and Document-oriented approach is to use syntactical information  .,0,original
The Penn Treebank annotation   was chosen to be the first among equals: it is the starting point for the merger and data from other annotations are attached at tree nodes.,0,original
"This includes both the parsers that attach probabilities to parser moves  , but also those of the lexicalized PCFG variety  .",0,original
TheChinesesentencefromtheselected pair is used as the single reference to tune and evaluate the MT system with word-based BLEU-4  .,0,original
"controlled NP-traces  , we follow the standard technique of marking nodes dominating the empty element up to but not including the parent of the antecedent as defective   with a gap feature  .1 Furthermore, to make antecedent co-indexation possible with many types of EEs, we generalize Collins approach by enriching the annotation of non-terminals with the type of the EE in question (eg.",0,original
"The overall POS tag distribution learnt by EM is relatively uniform, as noted by Johnson  , and it tends to assign equal number of tokens to each tag label whereas the real tag distribution is highly skewed.",0,original
"Experiments are presented in table 1, using BLEU   and METEOR5  , and we also show the length ratio  .",0,original
"57 Given a pair of English sentences to be compared  , we perform tokenization2, lemmatization using WordNet3, and part-of-speech   tagging with the MXPOST tagger  .",0,original
We use BLEU scores   to measure translation accuracy.,0,original
ore details about why heuristics are needed and the process used to map sources to NPs can be found in Stoyanov and Cardie  ,0,original
"For the log-linear model training, we take minimum-error-rate training method as described in  .",0,original
Machine Translation using Inversion Transduction Grammar The Inversion Transduction Grammar   of Wu   is a type of context-free grammar   for generating two languages synchronously,0,original
"More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment   and pronoun references  .",0,original
Context extraction begins with a Maximum Entropy POS tagger and chunker  .,0,original
"Our trees look just like syntactic constituency trees, such as those in the Penn TreeBank  , 141 ROOT PROT PROT NN PEBP2 PROT NN alpha NN A1 , , PROT NN alpha NN B1 , , CC and PROT NN alpha NN B2 NNS proteins VBD bound DT the DNA PROT NN PEBP2 NN site IN within DT the DNA NN mouse PROT NN GM-CSF NN promoter . . Figure 1: An example of our tree representation over nested named entities.",0,original
we use k = 50 and obtain our thesaurus using the distributional similarity metric described by Lin  ,0,original
"The approach is in the spirit of Smadja   on retrieving collocations from text corpora, but is more integrated with parsing.",0,original
"In the latter case, we use an unsupervised attachment disambiguation method, based on the log-likelihood ratio  ).",0,original
A conditional maximum entropy model q  for p has the parametric form  : q  = exp T f   y2Y  exp )   where  is a d-dimensional parameter vector and T f   is the inner product of the parameter vector and a feature vector.,0,original
The task originally emerged as an intermediate result of training the IBM translation models  .,0,original
The standard method to overcome this problem to use the model in both directions   and applying heuristic-based combination techniques to produce a refined alignment  henceforth referred to as RA. Several researchers have proposed algorithms for improving word alignment systems by injecting additional knowledge or combining different alignment models.,0,original
"3.4 Learning algorithm Maximum entropy   models  , also known as log-linear and exponential learning models, has been adopted in the SC classification task.",0,original
"Yarowsky   tested the claim on about 37,000 examples and found that when a polysemous word appeared more than once in a discourse, they took on the majority sense for the discourse 99.8% of the time on average.",0,original
"Approaches have been proposed recently towards getting better word alignment and thus better TTS templates, such as encoding syntactic structure information into the HMM-based word alignment model DeNero and Klein  , and build62 ing a syntax-based word alignment model May and Knight   with TTS templates.",0,original
"However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them  ,  ).",0,original
"Within this class would fall the Lexical Implication Rules   of Ostler and Atkins  , the lexical rules of Copestake and Briscoe  , the Generative Lexicon of Pustejovsky  , and the ellipsis recovery procedUres of Viegas and Nirenburg  .",0,original
Reranking methods have also been proposed as a method for using syntactic information  .,0,original
"Secondly, while all taggers use lexical information, and, indeed, it is well-known that lexical probabilities are much more revealing than tag sequence probabilities  , most taggers make quite limited use of lexical probabilities  .",0,original
The main data set consist of four sections   of the Wall Street Journal   part of the Penn Treebank   as training material and one section   as test material 1.,0,original
We systematically explored the feature space for relation extraction   . Kernel methods allow a large set of features to be used without being explicitly extracted.,0,original
"By habit, most systems for automatic role-semantic analysis have used Pennstyle constituents   produced by Collins   or Charniaks   parsers.",0,original
"This is in contrast to work by researchers such as Schiitze and Pedersen  , Brown et al   and Futrelle and Gauch  , where it is often the most frequent words in the lexicon which are clustered, predominantly with the purpose of determining their grammatical classes.",0,original
The training data is aligned using the LEAF technique  .,0,original
2.5 Evaluation Minnen and Carroll   report an evaluation of the accuracy of the morphological generator with respect to the CELEX lexical database  .,0,original
"Unlike our technique, in most cases researchers have focused on the scenario where labeled training data is available in both the source and the target domain  ).",0,original
"Originally introduced as a byproduct of training statistical translation models in  , word alignment has become the first step in training most statistical translation systems, and alignments are useful to a host of other tasks.",0,original
"However, they use the   data set in a different training-test division   which makes it (tifficult to compare their results with others.",0,original
he basic phrase-based model is an instance of the noisy-channel approach  ,0,original
2007) and Smith and Smith   showed that the MatrixTree Theorem can be used to train edge-factored log-linearmodelsofdependencyparsing,0,original
"This paper continues a line of research on online discriminative training  , extending that of Watanabe et al.",0,original
Introduction There has been considerable recent interest in the use of statistical methods for grouping words in large on-line corpora into categories which capture some of our intuitions about the reference of the words we use and the relationships between them  .,0,original
" , it is much higher than the 2.6% unknown word rate in the test set for Ratnaparkhis   English POS tagging experiments.",0,original
"To tackle this problem, we defined 2The best results of Collins and Roark     are achieved when the parser utilizes the information about the final punctuation and the look-ahead.",0,original
"The relatedness between two word senses is computed using a measure of semantic relatedness defined in the WordNet::Similarity software package  , which is a suite of Perl modules implementing a number WordNet-based measures of semantic relatedness.",0,original
2 Related Work A number of researchers   have described approaches that preprocess the source language input in SMT systems.,0,original
"2.2 Evaluation of Acquisition Algorithms Many methods for automatic acquisition of rules have been suggested in recent years, ranging from distributional similarity to finding shared contexts  .",0,original
"They roughly fall into three categories according to what is used for supervision in learning process:   using external resources, e.g., thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus,  ,   exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora    ,   bootstrapping sensetagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data  .",0,original
"Previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an SMT decoder  , and confusion networks  .",0,original
"Because of this, Wu   and Zens and Ney   introduced a normal form ITG which avoids this over-counting.",0,original
"In Turneys work, the co-occurrence is considered as the appearance in the same window  .",0,original
"Precursors to this work include  ,  ,  ,  , and   and, as applied to child language acquisition,  .",0,original
"In  , the authors proposed a method to integrate the IBM translation model 2   with an ASR system.",0,original
The model scaling factors are optimized on the development corpus with respect to mWER similar to  .,0,original
"First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++  , in both directions and by combining the results based on a heuristic  .",0,original
" , we are interested in applying alternative metrics such a Meteor  .",0,original
"Answer Extraction: We select the top 5 ranked sentences and return them as Collins, 1997, can be used to capture the binary dependencies between the head of each phrase.",0,original
"For evaluation, we used the BLEU metrics, which calculates the geometric mean of n-gram precision for the MT outputs found in reference translations  .",0,original
Dependency relations are produced using a version of the Collins parser   that has been adapted for building dependencies.,0,original
"Each token is labelled with a class using the IOB type of segmentation coding as introduced by Ramshaw and Marcus  , marking whether the middle word is inside  , outside  , or at the beginning   of a chunk, or named entity.",0,original
Table 2 summarizes the characteristics of the training corpus used for training the parameters of Model 4 proposed in  .,0,original
"1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention  .",0,original
"Inter-annotator agreement was determined for six pairs of two annotators each, resulting in kappa values  ) ranging from 0.62 to 0.82 for the whole database (Carlson et al.",0,original
"Taken together with cube pruning  , k-best tree extraction  , and cube growing  , these results provide evidence that lazy techniques may penetrate deeper yet into MT decoding and other NLP search problems.",0,original
"First, splitting and merging of sentences  , which seems related to content planning and aggregation.",0,original
"In the probabilistic LR model, probabilities are assigned to tree 696 Precision Recall F-score Time   Best-First Classifier-Based   88.1 87.8 87.9 17 Deterministic     85.4 84.8 85.1 < 1 Charniak & Johnson   91.3 90.6 91.0 Unk Bod   90.8 90.7 90.7 145* Charniak   89.5 89.6 89.5 23 Collins   88.3 88.1 88.2 39 Ratnaparkhi   87.5 86.3 86.9 Unk Tsuruoka & Tsujii  : deterministic 86.5 81.2 83.8 < 1* Tsuruoka & Tsujii  : search 86.8 85.0 85.9 2* Sagae & Lavie   86.0 86.1 86.0 11* Table 1: Summary of results on labeled precision and recall of constituents, and time required to parse the test set.",0,original
"Alignment, whether for training a translation model using EM or for nding the Viterbi alignment of test data, is O   , while translation   is O  using a bigram language model, and O  with trigrams.",0,original
"73 ment and phrase-extraction heuristics described in  , minimum-error-rate training  , a trigram language model with KneserNey smoothing trained with SRILM   on the English side of the training data, and Moses   to decode.",0,original
e follow   in using a tree kernel to represent structural information using the subtree that covers a pronoun and its antecedent candidate,0,original
"We use the maximum entropy tagging method described in   for the experiments, which is a variant of   modified to use HMM state features.",0,original
"In this paper, sentence pairs are extracted by a simple model that is based on the so-called IBM Model1  .",0,original
"Wehope the present work will, together with Talbot and Osborne  , establish the Bloom filter as a practical alternative to conventional associative data structures used in computational linguistics.",0,original
2 This problem is also a central concern in the work by Bean and Riloff  ,0,original
Then the word alignment is refined by performing growdiag-final method  .,0,original
In   a set of transformational rules is used for modifying the classification of words.,0,original
Combining statistical and parsing methods has been done by   and  .,0,original
"  makes a similar point, noting that for reviews, \the whole is not necessarily the sum of the parts"""").",0,original
We used a publicly available tagger   to provide the part-of-speech tags for each word in the sentence.,0,original
2 We illustrate the rule extraction with an example from the tree-to-tree translation model based on tree sequence alignment   without losing of generality to most syntactic tree based models.,0,original
dditional evidence for this distinction is given in Pustejovsky and Anick   and Briscoe et al,0,original
"3.1 Exhaustive search by tree fragments This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts   of translation rules to extract the useful rules  .",0,original
We calculated the translation quality using Bleus modified n-gram precision metric   for n-grams of up to length four.,0,original
arowsky   used the one sense per collocation property as an essential ingredient for an unsupervised Word-SenseDisambiguationalgorithm,0,original
"Though our motivation is similar to that of Koehn and Hoang  , we chose to build an independent component for inflection prediction in isolation rather than folding morphological information into the main translation model.",0,original
"Rather than explicit annotation, we could use latent annotations to split the POS tags, similarly to the introduction of latent annotations to PCFG grammars  .",0,original
"Each linked fragment pair consists of a source-language side and a target-language side, similar to  .",0,original
"The orientation model is related to the distortion model in  , but we do not compute a block alignment during training.",0,original
"As in much recent empirical work in discourse processing  , we performed an intercoder reliability study investigating agreement in annotating the times.",0,original
Weights on the loglinear features are set using Och's algorithm   to maximize the system's BLEU score on a development corpus.,0,original
Rule-based taggers   use POS-dependent constraints defined by experienced linguists.,0,original
Sentiment classification at the sentence-level has also been studied  .,0,original
The probability distributions of these binary classifiers are learnt using maximum entropy model  .,0,original
3 The Learning Architecture The synchronous derivations described above are modelled with an Incremental Sigmoid Belief Network    .,0,original
"Wu   proposes Inversion Transduction Grammars, treating translation as a process of parallel parsing of the source and target language via a synchronized grammar.",0,original
"1153 While much research   has explored how to reconcile pairwise decisions to form coherent clusters, we simply take the transitive closure of our pairwise decision   and Bengston and Roth  ) which can and does cause system errors.",0,original
ote that Row 3 of Table 3 corresponds to Marcu and Echihabi  s system which applies only word pair features,0,original
"The group of collocations and compounds should be delimited using statistical approaches, such as Xtract   or LocalMax  , so that only the most relevantthose of higher frequency are included in the database.",0,original
"In the sequel, we use Collinss statistical parser   as our canonical automated approximation of the Treebank.",0,original
We prepare the corpus by passing it through Adwait Ratnaparkhis part-of-speech tagger     and then running Steve Abneys chunker   over the entire text.,0,original
"We evaluate accuracy performance using two automatic metrics: an identity metric, ID, which measures the percent of sentences recreated exactly, and BLEU  , which gives the geometric average of the number of uni-, bi-, tri-, and four-grams recreated exactly.",0,original
"Similarly to classical NLP tasks such as base noun phrase chunking  , text chunking   or named entity recognition  , we formulate the mention detection problem as a classification problem, by assigning to each token in the text a label, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.",0,original
Concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information  .,0,original
ilingual Bracketing   is one of the bilingual shallow parsing approaches studied for Chinese-English word alignment,0,original
"In particular, since we treat each individual speech within a debate as a single document, we are considering a version of document-level sentiment-polarity classification, namely, automatically distinguishing between positive and negative documents  .",0,original
"In  , these forbidden subsequences are called inside-out transpositions.",0,original
"Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words   or positive and negative words  ; classifying sentences in a document as either subjective or objective  ; identifying or classifying appraisal targets  ; identifying the source of an opinion in a text  , whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods  .",0,original
"The third exploits automatic subjectivity analysis in applications such as review classification  ), mining texts for product reviews  ), summarization  ), information extraction  ), 1Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation.",0,original
"In previous research on splitting sentences, many methods have been based on word-sequence characteristics like N-gram  .",0,original
The f are trained using a held-out corpus using maximum BLEU training  .,0,original
"In fact, a limitation of the experiments described in this paper is that the loglinear weights for the glass-box techniques were optimized for BLEU using Ochs algorithm  , while the linear weights for 55 black-box techniques were set heuristically.",0,original
"Drawing on Abneys   analysis of the Yarowsky algorithm, we perform bootstrapping by entropy regularization: we maximize a linear combination of conditional likelihood on labeled data and confidence   on unlabeled data.",0,original
"The measures2  Mutual Information    , the log-likelihood ratio test  , two statistical tests: t-test and a3a5a4 -test, and co-occurrence frequency  are applied to two sets of data: adjective-noun   pairs and preposition-noun-verb   triples, where the AMs are applied to   pairs.",0,original
"Unfortunately, longer sentences  , longer phrases  , two LMs  , higher-order LMs  , multiple higher-order lexicalized re-ordering models  , etc. all contributed to increased system?s complexity, and, as a result, time limitations prevented us from performing minimum-error-rate training     for ucb3, ucb4 and ucb5.",0,original
3.1 The Corpus The systems are applied to examples from the Penn Treebank   a corpus of over 4.5 million words of American English annotated with both part-of-speech and syntactic tree information.,0,original
"In marked contrast to annotated training material for partof-speech tagging,   there is no coarse-level set of sense distinctions widely agreed upon  ;   sense annotation has a comparatively high error rate  ; and   no fully automatic method provides high enough quality output to support the """"annotate automatically, correct manually"""" methodology used to provide high volume annotation by data providers like the Penn Treebank project  .",0,original
One example is the algorithm for word sense disambiguation in  .,0,original
everal artificial techniques have been used so that classifiers can be developed and tested without having to invest in manually tagging the data: Yarowsky   and Sch/itze   have acquired training and testing materials by creating pseudowords from existing nonhomographic forms,0,original
"There are many different similarity measures, which variously use taxonomic lexical hierarchies or lexical-semantic networks, large text corpora, word definitions in machine-readable dictionaries or other semantic formalisms, or a combination of these  .",0,original
"As described in Section 4, we define the problem of term variation identifica1484 tion as a binary classification task, and build two types of classifiers according to the maximum entropy model   and the MART algorithm  , where all term similarity metrics are incorporated as features and are jointly optimized.",0,original
iezler and Maxwell   describe a method for learning a probabilistic model that maps LFG parse structures in German into LFG parse structures in English,0,original
A few unsupervised metrics have been applied to automatic paraphrase identification and extraction  .,0,original
"2 System Description 2.1 Data Representation In this paper, we change the representation of the original data as follows: Bracketed representation of roles is converted into IOB2 representation   Word tokens are collapsed into base phrase   tokens.",0,original
"In our implementation, the IBM Model 1   is used.",0,original
"A pipage approach   has been proposed for MCKP, but we do not use this algorithm, since it requires costly partial enumeration and solutions to many linear relaxation problems.",0,original
"Disambiguation of a limited number of words is not hard, and necessary context information can be carefully collected and hand-crafted to achieve high disambiguation accuracy as shown in  .",0,original
"There are studies on learning subjective language  , identifying opinionated documents   and sentences  , and discriminating between positive and negative language  .",0,original
"3.1 Word Sequence Classification Similar to English text chunking  , the word sequence classification model aims to classify each word via encoding its context features.",0,original
"A problem mentioned in   is that the algorithm that computes the compressed representation might need to retain the entire database in memory; in their paper, they design strategies to work around this problem.",0,original
"For example, the HMM aligner achieves an AER of 20.7 when using the competitive thresholding heuristic of DeNero and Klein  .",0,original
"In the absence of an annotated corpus, dependencies can be derived by other means, e.g. part413 of-speech probabilities can be approximated from a raw corpus as in  , word-sense dependencies can be derived as definition-based similarities, etc. Label dependencies are set as weights on the arcs drawn between corresponding labels.",0,original
"The reader is referred to   and   for details of MI clustering, but we will first briefly summarize the MI clustering and then describe our hierarchical clustering algorithm.",0,original
"Recently, it has gained renewed attention as empirical methods in parsing have emphasized the importance of relations between words  ), which is what dependency grammars model explicitly, but context-free phrase-structure grammars do not.",0,original
"Besides the the case-sensitive BLEU-4   used in the two experiments, we design another evaluation metrics Reordering Accuracy   for forced decoding evaluation.",0,original
The definitions of the phrase and lexical translation probabilities are as follows  .,0,original
Our evaluation metrics is casesensitive BLEU-4  .,0,original
"  provide four sets of annotation principles, one for non-coordinate configurations, one for coordinate configurations, one for traces   and a final catch all and clean up phase.",0,original
"Like the data used by Ramshaw and Marcus  , this data was retagged by the Brill tagger in order to obtain realistic part-of speech   tags 5.",0,original
n alternative representation for baseNPs has been put tbrward by Ramshaw and Marcus  ,0,original
2 Related Work The most commonly used similarity measures are based on the WordNet lexical database   and a number of such measures have been made publicly available  .,0,original
.2 Inversion Transduction Grammar Wu  s inversion transduction grammar   is a synchronous grammar formalism in which derivations of sentence pairs correspond to alignments,0,original
"In the following, ROUGE-SN denotes ROUGE-S with maximum skip distance N. ROUGE-SU   This measure is an extension of ROUGE-S; it adds a unigram as a counting unit.",0,original
"To tune the decoder parameters, we conducted minimum error rate training   with respect to the word BLEU score   using 2.0K development sentence pairs.",0,original
"The initial state contains terminal items, whose labels are the POS tags given by the tagger of Ratnaparkhi  .",0,original
"We use the likelihood ratio for a binomial distribution  , which tests the hypothesis whether the term occurs independently in texts of biographical nature given a large corpus of biographical and non-biographical texts.",0,original
"Yarowsky  , Mihalcea and Moldovan  , and Mihalcea   have made further research to obtain large corpus of higher quality from an initial seed corpus.",0,original
"This feature, which is based on the lexical parameters of the IBM Model 1  , provides a complementary probability for each tuple in the translation table.",0,original
The tree-based reranker includes the features described in   as well as features based on non-projective edge attributes explored in  .,0,original
"The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman   and Collins  .",0,original
We use a statistical POS tagging system built on Arabic Treebank data with MaxEnt framework  .,0,original
"In  , as well as other similar works  , only left-toright search was employed.",0,original
Thus we rank each sense wsi WSw using Prevalence Score wsi =    njNw dssnj  wnss  wsiWSw wnss  where the WordNet similarity score   is defined as: wnss = max nsxNSnj  ) 2.2 Building the Thesaurus The thesaurus was acquired using the method described by Lin  .,0,original
"The class labeling system in our experiment is IOB2  , which is a variation of IOB  .",0,original
"In our own work on document compression models  , both of which extend the sentence compression model of Knight and Marcu  , we assume that sentences and documents can be summarized exclusively through deletion of contiguous text segments.",0,original
4.1 Experimental Setup We use the whole Penn Treebank corpus   as our data set.,0,original
"We then compute the weight of a context word w in context c, W , using mutual information and t-test, which were reported by Weeds and Weir   to perform the best on a pseudo-disambiguation task.",0,original
"In order to build models that perform well in new   domains we usually find two settings  : In the semi-supervised setting the goal is to improve the system trained on the source domain using unlabeled data from the target domain, and the baseline is that of the system c2008.",0,original
"The parser has been trained, developed and tested on a large collection of syntactically analyzed sentences, the Penn Treebank  .",0,original
"In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney  , could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space.",0,original
"Our method is similar to  ,  , and   in the use of dependency relationships as the word features.",0,original
"Carletta mentions this problem, asking what the difference would be if the kappa statistic were computed across """"clause boundaries, transcribed word boundaries, and transcribed phoneme boundaries""""   rather than the sentence boundaries she suggested.",0,original
"Another application of hard clustering methods   is that they can also produce a binary tree, which can be used for decision-tree based systems such as the SPATTER parser   or the ATR Decision-Tree Part-OfSpeech Tagger  .",0,original
ollins   proposed a Perceptron like learning algorithm to solve sequence classification in the traditional left-to-right order,0,original
" , or in more recent implementation, the MOSES MT system1  .",0,original
Two main extensions from that work that we are making use of are: 1) proofs falling below a user defined cost threshold halt the search 2) a simple variable typing system reduces the number of axioms written and the size of the search space  .,0,original
"Obviously, all these semantic resources have been acquiredusing a very differentset of processes  , tools and corpora.",0,original
It was also included in the DUC 2004 evaluation plan where summary quality was automatically judged using a set of n-gram word overlap metrics called ROUGE  .,0,original
"corpora and corpus query tools has been particularly significant in the area of compiling and developing lexicographic materials   and in the area of creating various kinds of lexical resources, such as WordNet   and FrameNet  .",0,original
"We compared this nonprobabilistic DOP model against tile probabilistic DOP model   on three different domains: tbe Penn ATIS treebank  , the Dutch OVIS treebank   and tile Penn Wall Street Journal   treebank  .",0,original
"We then tested the best models for each vocabulary size on the testing set.4 Standard measures of performance are shown in table 1.5 3We used a publicly available tagger   to provide the tags used in these experiments, rather than the handcorrected tags which come with the corpus.",0,original
8 Related Research Class-based LMs   or factored LMs   are very similar to our T+C scenario.,0,original
"Using techniques described in Church and Hindle  , Church and Hanks  , and Hindle and Rooth  , Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus.",0,original
Inversion Transduction Grammar     and Syntax-Directed Translation Schema     lack both of these properties.,0,original
"The features are similar to the ones used in phrasal systems, and their weights are trained using max-BLEU training  .",0,original
"This approach was subsequently extended to other languages including German  , Chinese  ,  , Spanish  ,   and French  .",0,original
"4.2 Translation Results The evaluation metrics used in our experiments are WER  , PER   and BLEU    .",0,original
"Instead of using a single system output as the skeleton, we employ a minimum Bayes-risk decoder to select the best single system output from the merged N-best list by minimizing the BLEU   loss.",0,original
"Furthermore, as pointed out in Dolan  , the sense division in an MRD is frequently too fine-grained for the purpose of WSD.",0,original
These belong to two main categories based on machine learning   and language or domain specific rules  .,0,original
The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1   with an additional trigger.,0,original
"2.2 Implementation of GIZA++ GIZA++ is an implementation of ML estimators for several statistical alignment models, including IBM Model 1 through 5  , HMM   and Model 6  .",0,original
A number of systems for automatically learning semantic parsers have been proposed  .,0,original
"Of these, only feature weights can be trained, for which we used minimum error rate training with version 1.04 of IBM-style BLEU   in case-insensitive mode.",0,original
"Our approach to inducing syntactic clusters is closely related to that described in Brown, et al,   which is one of the earliest papers on the subject.",0,original
"For evaluation, we use IBMs BLEU score   to measure the performance of the SMS normalization.",0,original
  proposes two approximate models based on the variational approach.,0,original
"We also test our language model using leave-one-out cross-validation on the Penn Treebank    , giving us 86.74% accuracy  .",0,original
Metrics based on word alignment between MT outputs and the references  .,0,original
"Many methods have been proposed to measure the co-occurrence relation between two words such as  2   , mutual information  , t-test  , and loglikelihood  .",0,original
"3 Experimental Results and Discussion We test our parsing models on the CONLL-2007   data set on various languages including Arabic, Basque, Catalan, Chinese, English, Italian, Hungarian, and Turkish.",0,original
"In the general language UPenn annotation efforts for the WSJ sections of the Penn Treebank  , sentences are annotated with POS tags, parse trees, as well as discourse annotation from the Penn Discourse Treebank  , while verbs and verb arguments are annotated with Propbank rolesets  .",0,original
"First, we can let the number of nonterminals grow unboundedly, as in the Infinite PCFG, where the nonterminals of the grammar can be indefinitely refined versions of a base PCFG  .",0,original
"Additionally, automatic evaluation of content coverage using ROUGE   was explored in 2004.",0,original
Our starting point is the work done by Zettlemoyer and Collins on parsing using relaxed CCG grammars    .,0,original
5 Related Work We already discussed the relation of our work to   in Section 2.4.,0,original
"This can either be semi-supervised parsing, using both annotated and unannotated data   or unsupervised parsing, training entirely on unannotated text.",0,original
We determined appropriate training parameters and network size based on intermediate validation 1We used a publicly available tagger   to provide the tags.,0,original
"Breidt  alsopointedouta coupleof problemsthatmakes extractionfor Germanmoredifficultthanfor English: the stronginflectionfor verbs,the variable word-order,andthepositionalambiguityofthearguments.Sheshowsthatevendistinguishingsubjectsfromobjectsisverydifficultwithoutparsing.",0,original
"3 2.4 Intonation Annotations For our intonation annotation, we have annotated the intonational phrase boundaries, using the ToBI   definition  .",0,original
"82 Chen and Chang Topical Clustering Dolan   maintains the position that intersense relations are mostly idiosyncratical, thereby making it difficult to characterize them in a general way so as to identify them.",0,original
High quality word alignments can yield more accurate phrase-pairs which improve quality of a phrase-based SMT system  .,0,original
The Pearson correlation is calculated over these ten pairs  .,0,original
GIZA++   and the heuristics grow-diag-final-and are used to generate m-ton word alignments.,0,original
All of the features of the ATR/Lancaster Treebank that are described below represent a radical departure from extant large-scale   treebanks.,0,original
"The part of speech tags for the development and test data were automatically assigned by MXPOST  , where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus  , which contains roughly 43 million words of Wall Street Journal text.9 The Czech experiments were performed on the Prague Dependency Treebank 1.0  , which is directly annotated with dependency structures.",0,original
"Various approaches to word sense division have been proposed in the literature on WSD, including   sense numbers in every-day dictionaries  ,   automatic or hand-crafted clusters of dictionary senses (Dolan 1994; Bruce and Wiebe 1995; Luk * Department of Computer Science, National Tsing Hua University, Hsinchu 30043, Taiwan, ROC.",0,original
We set all feature weights by optimizing Bleu   directly using minimum error rate training     on the tuning part of the development set  .,0,original
"Supervised methods include hidden Markov model  , maximum entropy, conditional random fields  , and support vector machines    .",0,original
"However, the maximum entropy   was found to yield higher accuracy than nave Bayes in a subsequent comparison by Klein and Manning  , who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data.",0,original
"Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, e.g.,    , or require human-annotated training data with relation information for each domain  .",0,original
"Furthermore, I plan to apply my parsers in other domains     besides treebank data, to investigate the effectiveness and generality of my approaches.",0,original
"Several teams had approaches that relied   on an IBM model of statistical machine translation  , with different improvements brought by different teams, consisting of new submodels, improvements in the HMM model, model combination for optimal alignment, etc. Se-veral teams used symmetrization metrics, as introduced in    , most of the times applied on the alignments produced for the two directions sourcetarget and targetsource, but also as a way to combine different word alignment systems.",0,original
"2 Evaluating Heterogeneous Parser Output Two commonly reported shallow parsing tasks are Noun-Phrase   Chunking   and the CoNLL-2000 Chunking task  , which extends the NPChunking task to recognition of 11 phrase types1 annotated in the Penn Treebank.",0,original
"  So far, none of the studies in sentiment detection   or opinion extraction   have specifically looked at the role of superlatives in these areas.",0,original
"We measured stability   and reproducibility  , using the Kappa coefficient K  , which controls agreement P  for chance agreement P : K = PA)-P  1-P  Kappa is 0 for if agreement is only as would be expected by chance annotation following the same distribution as the observed distribution, and 1 for perfect agreement.",0,original
6 Comparison With Previous Work The two parsers which have previously reported the best accuracies on the Penn Treebank Wall St. Journal are the bigram parser described in   and the SPATTER parser described in  .,0,original
A number of other re532 searchers   have described previous work on preprocessing methods.,0,original
"Given a sentence-pair  , the most likely   word alignment is found as  : a = argmaxa P .",0,original
"For example, minimum entropy regularization  , aims to maximize the conditional likelihood of labeled data while minimizing the conditional entropy of unlabeled data: summationdisplay i logp |x ) 122bardblbardbl2H    This approach generally would result in sharper models which can be data-sensitive in practice.",0,original
"For instance  ,     all automatically acquire large TAGs for English from the Penn Treebank  .",0,original
We follow IBM Model 1   and assume that each word in an utterance is generated by exactly one role in the parallel frame Using standard EM to learn the role to word mapping is only sufficient if one knows to which level in the tree the utterance should be mapped.,0,original
There is a large number of potentially informative features that could play a role in correctly predicting the tag of an unknown word  .,0,original
"These techniques included unweighted FS morphology, conditional random fields  , synchronous parsers  , lexicalized parsers  ,22 partially supervised training `a la  ,23 and grammar induction  .",0,original
6 The Experiments We used the Penn Treebank   to perform empirical experiments on the proposed parsing models.,0,original
"5.1.2 Learning Translation Model According to the standard statistical translation model  , we can find the optimal model M by maximizing the probability of generating queries from documents or M = argmax M NY i=1 P  524 qw dw P  journal kdd 0.0176 journal conference 0.0123 journal journal 0.0176 journal sigkdd 0.0088 journal discovery 0.0211 journal mining 0.0017 journal acm 0.0088 music music 0.0375 music purchase 0.0090 music mp3 0.0090 music listen 0.0180 music mp3.com 0.0450 music free 0.0008 Table 1: Sample user profile To find the optimal word translation probabilities P , we can use the EM algorithm.",0,original
"The translation quality is evaluated by BLEU metric  , as calculated by mteval-v11b.pl with case-insensitive matching of n-grams, where n =4.",0,original
"Since it is not feasible to maximise the likelihood of the observations directly, we maximise the expected log likelihood by considering the EM auxiliary function, in a similar manner to that used for modelling contextual variations of phones for ASR  .",0,original
"These methods are based on IBM statistical translation Model 2  , but take advantage of certain characteristics of the segments of text that can typically be extracted from translation memories.",0,original
"The elementary trees were extracted from the parse trees in sections 02-21 of the Wall Street Journal in Penn Treebank  , which is transformed by using parent-child annotation and left factoring  .",0,original
"BLEU For all translation tasks, we report caseinsensitive NIST BLEU scores   using 4 references per sentence.",0,original
"Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing  .",0,original
"As resolving direct anaphoric descriptions   is a much simpler problem with high performance rates as shown in previous results  , these heuristics should be applied first in a system that resolves definite descriptions.",0,original
"Traditionally, such unsupervised EM-trained HMM taggers are thought to be inaccurate, but   showed that by feeding the EM process with sufficiently good initial probabilities, accurate taggers   can be learned for both English and Hebrew, based on a   lexicon and large amount of raw text.",0,original
"On the other hand, works done by   have proposed methodologies to automatically acquire these patterns mostly based on supervised learning to leverage manual work.",0,original
We perform minimum-error-rate training   to tune the feature weights of the translation model to maximize the BLEU score on development set.,0,original
"As with conventional smoothing methods  , triangulation increases the robustness of phrase translation estimates.",0,original
  introduced a polynomial-time solution for the alignment problem based on synchronous binary trees.,0,original
1 is based on several realvalued feature functions fi . Their computation is based on the so-called IBM Model-1  .,0,original
"On the base of the chunk scheme proposed by Abney   and the BIO tagging system proposed in Ramshaw and Marcus , many machine learning techniques are used to deal with the problem.",0,original
"Collins  s parser and its reimplementation and extension by Bikel   have by now been applied to a variety of languages: English  , Czech  , German  , Spanish  , French  , Chinese   and, according to Dan Bikels web page, Arabic.",0,original
"In addition to individual seed words, Kanayama and Nasukawa   used more complicated syntactic patterns that were manually created.",0,original
"4.1 Variational Bayes Beal   and Johnson   describe variational Bayes for hidden Markov model in detail, which can be directly applied to our bilingual model.",0,original
"1 Introduction In the part-of-speech hterature, whether taggers are based on a rule-based approach  ,  ,  , or on a statistical one  ,  ,  ,  ,  ,  , there is a debate as to whether more attention should be paid to lexical probabilities rather than contextual ones.",0,original
"The de-facto answer came during the 1990s from the research community on Statistical Machine Translation, who made use of statistical tools based on a noisy channel model originally developed for speech recognition  .",0,original
"In Englishto-German, this result produces results very comparable to a phrasal SMT system   trained on the same data.",0,original
The f-structures are created automatically by annotating nodes in the gold standard WSJ trees with LFG functional equations and then passing these equations through a constraint solver  .,0,original
4An adaptation of the averaged perceptron algorithm   is used to tune the model parameters.,0,original
"In all experiments that follow, each system configuration was independently optimized on the NIST 2003 Chinese-English test set   using minimum error rate training   and tested on the NIST 2005 Chinese-English task  .",0,original
"This approach to minimally supervised classifier construction has been widely studied  , especially in cases in which the features of interest are orthogonal in some sense  .",0,original
his tagging scheme is the IOB scheme originally put forward by Ramshaw and Marcus  ,0,original
"Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation  , synonym extraction  , and automatic thesauri generation  .",0,original
The standard Minimum Error Rate training   was applied to tune the weights for all feature types.,0,original
"But it makes obvious that   were tackling a problem different from   given the fact that their baseline was at 59% guessing noun attachment  .3 Of course, the baseline is not a direct indicator of the difficulty of the disambiguation task.",0,original
All topic models utilize Gibbs sampling for inference  .,0,original
"Liang   uses the discriminative perceptron algorithm   to score whole character tag sequences, finding the best candidate by the global score.",0,original
"The most common answer is component testing, where the component is compared against a standard of goodness, usually the Penn Treebank for English  , allowing a numerical score of precision and recall  .",0,original
"Agglomerative clustering   iteratively merges the most similar clusters into bigger clusters, which need to be labeled.",0,original
The weights for these models are determined using the method described in  .,0,original
"We then built separate directed word alignments for EnglishX andXEnglish   using IBM model 4  , combined them using the intersect+grow heuristic  , and extracted phrase-level translation pairs of maximum length seven using the alignment template approach  .",0,original
"Hidden Markov models   are one of the earliest structured learning algorithms, which have recently been followedbydiscriminativelearningapproachessuch as conditional random fields    , the structured perceptron   and its large-margin variants  .",0,original
"Treebank  , six of which are errors.",0,original
"SRILM   can produce classes to maximize the mutual information between the classes I ;C ), as described in  .",0,original
"Statistical parsers have been developed for TAG  , LFG  , and HPSG  , among others.",0,original
"The algorithms were trained and tested using version 3 of the Penn Treebank, using the training, development, and test split described in Collins   and also employed by Toutanova et al.",0,original
"Grammar rules were induced with the syntaxbased SMT system SAMT described in  , which requires initial phrase alignments that we generated with GIZA++  , and syntactic parse trees of the target training sentences, generated by the Stanford Parser   pre-trained on the Penn Treebank.",0,original
"2.2 Statistical Approaches with a grmnnmr There have been nlally l)rOl)osals tbr statistical t'rameworks particularly designed tbr 1)arsers with hand-crafted grmnmars  es, 1992; Briscoe and Carroll, 1993; Abney, 1996; Inui et al. , 1!)97).",0,original
"We use the union, re ned and intersection heuristics de ned in   which are used in conjunction with IBM Model 4 as the baseline in virtually all recent work on word alignment.",0,original
Nonparametricmodels   may be appropriate.,0,original
"For comparison purposes, we consider two different algorithms for our AnswerExtraction module: one that does not bridge the lexical chasm, based on N-gram cooccurrences between the question terms and the answer terms; and one that attempts to bridge the lexical chasm using Statistical Machine Translation inspired techniques   in order to find the best answer for a given question.",0,original
"Different methods have been proposed to reduce error propagation between pipelined tasks, both in general   and for specific problems such as language modeling and utterance classification   and labeling and chunking  .",0,original
In line with the reports in   we do observe the performance improvement against the baseline   for all the domains.,0,original
"More specifically, the latter system uses the IBM-1 lexical parameters   for computing the translation probabilities of two possible new tuples: the one resulting when the null-aligned-word is attached to Table 6 Evaluation results for experiments on n-gram size incidence.",0,original
We measure this association using pointwise Mutual Information    .,0,original
Relative frequency ratio   of terms between two different corpora can also be used to discover domain-oriented multi-word terms that are characteristic of a corpus when compared with another  .,0,original
The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse  .,0,original
Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other  .,0,original
"We were already using a generative statistical model for part-of-speech tagging  , and more recently, had begun using a generative statistical model for name finding  .",0,original
Unconstrained CL corresponds exactly to a conditional maximum entropy model  .,0,original
We use the Penn Treebank Wall Street Journal corpus as the large corpus and individual sections of the Brown corpus as the target corpora  .,0,original
"BLEU score In order to measure the extent to which whole chunks of text from the prompt are reproduced in the student essays, we used the BLEU score, known from studies of machine translation  .",0,original
Generative methods   treat word alignment as a hidden process and maximize the likelihood of bilingual training corpus using the expectation maximization   algorithm.,0,original
Translation results are given in terms of the automaticBLEUevaluation metric   as well as the TER metric  .,0,original
"However, the aforementioned SDT techniques require word classes  to help prevent data fragmentation, and a sophisticated smoothing algorithm to mitigate the effects of any fragmentation that occurs.",0,original
The approach made use of a maximum entropy model   formulated from frequency information for various combinations of the observed features.,0,original
"Three recent papers in this area are Church and Hanks  , Hindle  , and Smadja and McKeown  .",0,original
We then parse both sides of the corpus with syntactic parsers  .,0,original
"To prune away those pairs, we used the log-likelihood-ratio algorithm   to compute the degree of association between the verb and the noun in each pair.",0,original
Our chunks and functions are based on the annotations in the third release of the Penn Treebank  .,0,original
We use as our English corpus the Wall Street Journal   portion of the Penn Treebank  .,0,original
"context-free rules Charniak   Collins  , Eisner   context-free rules, headwords Charniak   context-free rules, headwords, grandparent nodes Collins   context-free rules, headwords, grandparent nodes/rules, bigrams, two-level rules, two-level bigrams, nonheadwords Bod   all fragments within parse trees Scope of Statistical Dependencies Model Figure 4.",0,original
urney   has recently proposed a simpler SVM-based algorithm for analogical classification called PairClass,0,original
"We trained and tested the parser on the Wall Street Journal corpus of the Penn Treebank   using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.",0,original
"4.3 Baselines 4.3.1 Word Alignment We used the GIZA++ implementation of IBM word alignment model 4   for word alignment, and the heuristics described in   to derive the intersection and refined alignment.",0,original
"Although ITA rates and system performance both significantly improve with coarse-grained senses  , the question about what level of granularity is needed remains.",0,original
"1 Introduction Since the introduction of the BLEU metric  , statistical MT systems have moved away from human evaluation of their performance and towards rapid evaluation using automatic metrics.",0,original
The candidates of unknown words can be generated by heuristic rules  or statistical word models which predict the probabilities for any strings to be unknown words  .,0,original
"The decoder is capable of producing nbest derivations and nbest lists  , which are used for Maximum Bleu training  .",0,original
"This approach will generally take advantage of language-specific  ) and domain-specific knowledge, of any external resources  , and of any information about the entities to process, e.g. their type  , or internal structure  ).",0,original
Another current topic of machine translation is automatic evaluation of MT quality  .,0,original
"More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment   and pronoun references  .",0,original
"The block set is generated using a phrase-pair selection algorithm similar to  , which includes some heuristic filtering to mal statement here.",0,original
"In this case, one is often required to find the translation  in the hypergraph that are most similar to the desired translations, with similarity computed via some automatic metric such as BLEU  .",0,original
"Some adopt a pipeline approach  , which works by first extracting candidate affixes and stems, and then segmenting the words based on the candidates.",0,original
"Given a contextual word cw that occurs in the paragraphs of bc, a log-likelihood ratio   test is employed  , which checks if the distribution of cw in bc is similar to the distribution of cw in rc; p  = p   .",0,original
The next section briefly reviews the word alignment based statistical machine translation  .,0,original
period should therefore be interpreted as an abbreviation marker and not as a sentence boundary marker if the two tokens surrounding it can indeed be considered as a collocation according to Dunnings   original log-likelihood ratio amended with the one-sidedness constraint introduced in Section 2.2,0,original
he input is POS-tagged using the tagger of Ratnaparkhi  ,0,original
Our test set is 3718 sentences from the English Penn treebank   which were translated into German.,0,original
"3.2 Translation quality Table 2 presents the impact of parse quality on a treelet translation system, measured using BLEU  .",0,original
"Some researchers   targeted nouns, noun phrases and verb phrases.",0,original
"The second baseline is our implementation of the relevant part of the Wikipedia extraction in  , taking the first noun after a be verb in the definition sentence, denoted as WikiBL.",0,original
"In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K. We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization  .",0,original
"Finally, Section 4 reports the results of parsing experiments using our exhaustive k-best CYK parser with the concise PCFGs induced from the Penn WSJ treebank  .",0,original
Recentworkconsidersadamagedtagdictionary by assuming that tags are known only for words that occur more than once or twice  .,0,original
"Uses for k-best lists include minimum Bayes risk decoding  , discriminative reranking  , and discriminative training  .",0,original
"Four alternatives are proposed in these special issues:   Brent  ,   Briscoe and Carroll  ,   Hindle and Rooth  , and   Weischedel et al.",0,original
"The reason may be that shorter dependencies are often modifier of nouns such as determiners or adjectives or pronouns modifying their direct neighbors, while longer dependencies typically represent modifiers of the root or the main verb in a sentence .",0,original
The simplest   uses constit  to denote a NP spanning positions 35 in the English string that is aligned with an NP spanning positions 48 in the Chinese string.,0,original
"As expected, as we double the size of the data, the BLEU score   increases.",0,original
"In the rest of the paper we use the following notation, adapted from Collins  .",0,original
"To support a more rigorous analysis, however, wc have followed Carletta's suggestion   of using the K coettMcnt   as a measure of coder agreement.",0,original
"This approach builds a subjectivity-annotated corpus for the target language through projection, and then trains a statistical classifier on the resulting corpus  ).",0,original
Step 2 involves extracting minimal xRS rules   from the set of string/tree/alignments triplets.,0,original
"Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems  .",0,original
"Uses Maximum Entropy   classification, trained on JNLPBA    .",0,original
"In analyzing opinions  , judging document-level subjectivity  , and answering opinion questions  , the output of a sentence-level subjectivity classification can be used without modification.",0,original
"These wordbased models are used to find the latent wordalignments between bilingual sentence pairs, from which a weighted string transducer can be induced   or synchronous context free grammar  ).",0,original
"A recent trend is to store the LM in a distributed cluster of machines, which are queried via network requests  .",0,original
Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation   and to develop lexical resources from corpora  .,0,original
avigli   has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource,0,original
"Labelling was carried out by three computational linguistics graduate students with 89% agreement resulting in a Kappa statistic of 0.87, which is a satisfactory indication that our corpus can be labelled with high reliability using our tag set  .",0,original
"As suggested in  , we use the averaged perceptron when applying the model to held-out or test data.",0,original
"This leads to a good amount of work in this area   In the most basic approach, such as Ratnaparkhi et al.",0,original
"3.2  -cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts  .",0,original
"  describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels.",0,original
"Two error rates: the sentence error rate   and the word error rate   that we seek to minimize, and BLEU  , that we seek to maximize.",0,original
"Far from full syntactic complexity, we suggest to go back to the simpler alignment methods first described by  .",0,original
"The domain axioms will bind the body variables to their most likely referents during unification with facts, and previously assumed and proven propositions similarly to  .",0,original
"Finally, Zhang and Clark   achieve an SF of 95.90% and a TF of 91.34% by 10-fold cross validation using CTB data.",0,original
In each case the input to the network is a sequence of tag-word pairs.5 5We used a publicly available tagger   to provide the tags.,0,original
We use 3500 sentences from CoNLL   as the NER data and section 20-23 of the WSJ   as the POS/chunk data  .,0,original
"The last issue is how our binarization performs on a lexicalized parser, like Collins  .",0,original
"2.2 Automatic evaluation metric Since the official evaluation criterion for WMT09 is human sentence ranking, we chose to minimize a linear combination of two common evaluation metrics, BLEU and TER  , during system development and tuning: TERBLEU 2 Although we are not aware of any work demonstrating that this combination of metrics correlates better than either individually in sentence ranking, Yaser Al-Onaizan   reports that it correlates well with the human evaluation metric HTER.",0,original
"Instead, we follow a simplified form of previous work on biography creation, where a classifier is trained to distinguish biographical text  .",0,original
"Some stem from work on graphical models,includingloopybeliefpropagation , Gibbs sampling  , sequential Monte Carlo methods such as particle filtering  , and variational inference  .",0,original
"Class-based methods   cluster words into classes of similar words, so that one can base the estimate of a word pair's probability on the averaged cooccurrence probability of the classes to which the two words belong.",0,original
"The tree-to-string model   views the translation as a structure mapping process, which first breaks the source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence.",0,original
"Following the framework of global linear models in  , we cast this task as learning a mapping F from input verses x  X to a text-reuse hypothesis y  Y  {epsilon1}.",0,original
"In comparison, most corpus-based algorithms employ substantially larger corpora  , 2.5 million words  , 6 million words  , 13 million words  ).",0,original
"From multilingual texts, translation lexica can be generated  .",0,original
Feature function scaling factors m are optimized based on a maximum likely approach   or on a direct error minimization approach  .,0,original
"Furthermore, our model is not necessarily nativist; these biases may be innate, but they may also be the product of some other earlier learning algorithm, as the results of Ellison   and Brown et al.",0,original
6 Experiments 6.1 Data preparation Our experiments were conducted with data made available through the Penn Treebank annotation effort  .,0,original
"The idea is that the translation of a sentence x into a sentence y can be performed in the following steps1:   If x is small enough, IBMs model 1   is employed for the translation.",0,original
  is one of the first works to use statistical methods of distributional analysis to induce clusters of words.,0,original
The leader of the pack is the MXPOST tagger  .,0,original
The model scaling factors M1 are optimized with respect to the BLEU score as described in  .,0,original
"In a next step, chunk information was added by a rule-based language-independent chunker   that contains distituency rules, which implies that chunk boundaries are added between two PoS codes that cannot occur in the same constituent.",0,original
"As shown by McDonald and Nivre  , the Single Malt parser tends to suffer from two problems: error propagation due to the deterministic parsing strategy, typicallyaffectinglongdependenciesmorethan short ones, and low precision on dependencies originating in the artificial root node due to fragmented parses.9 The question is which of these problems is alleviatedbythemultipleviewsgivenbythecomponent parsers in the Blended system.",0,original
"To perform code generalization, Li adopted to Smadjas work   and defined the code strength using a code frequency and a standard deviation in each level of the concept hierarchy.",0,original
"Our approach was to identify a parallel corpus of manually and automatically transcribed documents, the TDT2 corpus, and then use a statistical approach   to identify tokens with significantly Table 5: Impact of recall and precision enhancing devices.",0,original
2 Related Work Two different approaches have been proposed for Sentence Compression: purely statistical methodologies   and hybrid linguistic/statistic methodologies  .,0,original
We then tagged the search queries using a maximum entropy part-of-speech tagger  .,0,original
"In the WSD work involving the use of context, we can find two approaches: one that uses few strong contextual evidences for disambiguation purposes, as exemplified by  ; and the other that uses weaker evidences but considers a combination of a number of them, as exemplified by  .",0,original
n this data set the 4-tuples of the test and training sets were extracted from Penn Treebank Wall Street Journal \ ,0,original
e adopted the stop condition suggested in Berger et al. 1996 the maximization of the likelihood on a cross-validation set of samples which is unseen at the parameter esti~_tion,0,original
Linear weights are assigned to each of the transducers features using an averaged perceptron for structure prediction  .,0,original
No artificial glue-rules or rule span limits were employed.7 The parameters of the translation system were trained to maximize BLEU on the MT02 test set  .,0,original
"Approaches include word substitution systems  , phrase substitution systems  , and synchronous context-free grammar systems  , all of which train on string pairs and seek to establish connections between source and target strings.",0,original
4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework  .,0,original
"Most current SMT systems   use a generative model for word alignment such as the freely available GIZA++  , an implementation of the IBM alignment models  .",0,original
We measure semantic similarity using the shortest path length in WordNet   as implemented in the WordNet Similarity package  .,0,original
"For ROUGE-S and ROUGE-SU, we use three variations following  : the maximum skip distances are 4, 9 and infinity 7.",0,original
"We also have an additional held-out translation set, the development set, which is employed by the MT system to train the weights of its log-linear model to maximize BLEU  .",0,original
"To test whether a better set of initial parameter estimates can improve Model 1 alignment accuracy, we use a heuristic model based on the loglikelihood-ratio   statistic recommended by Dunning  .",0,original
"From the above discussion, we can see that traditional tree sequence-based method uses single tree as translation input while the forestbased model uses single sub-tree as the basic translation unit that can only learn tree-to-string   rules.",0,original
"??word class: Turney   measures polarity using only adjectives, however in our approach we consider the noun, the verb, the adverb and the adjective content words.",0,original
"3 Data The data consists of sections of the Wall Street Journal part of the Penn TreeBank  , with information on predicate-argument structures extracted from the PropBank corpus  .",0,original
"In this paper, we propose an alignment algorithm between English and Korean conceptual units   in English-Korean technical term pairs based on IBM Model  .",0,original
"Unfortunately, a counterexample illustrated in   shows that the max function does not produce valid kernels in general.",0,original
"Then, those structurally matched parallel sentences are used as a source for acquiring lexical knowledge snch as verbal case frames  .",0,original
The k-best list is also frequently used in discriminative learning to approximate the whole set of candidates which is usually exponentially large  .,0,original
The MBT POS tagger   is used to provide POS information.,0,original
"Typically, a small set of seed polar phrases are prepared, and new polar phrases are detected based on the strength of co-occurrence with the seeds  .",0,original
CFGs extracted from such structures were then annotated with hidden variables encoding the constraints described in the previous section and trained until convergence by means of the Inside-Outside algorithm defined in   and applied in  .,0,original
"They first extract English collocations using the Xtract systetn  , and theu look for French coutlterparts.",0,original
"For example, work which failed to detect improvements in translation quality with the integration of word sense disambiguation  , or work which attempted to integrate syntactic information but which failed to improve Bleu   may deserve a second look with a more targeted manual evaluation.",0,original
"The work reported in this paper is most closely related to work on statistical machine translation, particularly the IBM-style work on CANDIDE  .",0,original
Collins and Roark   used the averaged perceptron  .,0,original
We employ the loglikelihood ratio as a measure of the collocational status of the adjective-noun pair  .,0,original
"SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, conducted three prior word segmentation bakeoffs, in 2003, 2005 and 2006 , which established benchmarks for word segmentation and named entity recognition.",0,original
These tasks are generally treated as sequential labeling problems incorporating the IOB tagging scheme  .,0,original
"4.1 The test environment For our experiments, we used a manually corrected version of the Air Travel Information System   spoken language corpus   annotated in the Pennsylvania Treebank  .",0,original
"3.2 Domain Adaptation Track As mentioned previously, the source data is drawn from a corpus of news, specifically the Wall Street Journal section of the Penn Treebank  .",0,original
"2.1 The Standard Machine Learning Approach We use maximum entropy   classification   in conjunction with the 33 features described in Ng   to acquire a model, PC, for determining the probability that two mentions, mi and mj, are coreferent.",0,original
1 Introduction and Previous Research It is by now commonplace knowledge that accurate syntactic parsing is not possible given only a context-free grammar with standard Penn Treebank   labels  .,0,original
istory-based models for predicting the next parser action   3,0,original
It can be applied to complicated models such IBM Model-4  .,0,original
"The original training set   consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods  .",0,original
"For a full description of the algorithm, see  .",0,original
The IBM model 1   is used to find an initial estimate of the translation probabilities.,0,original
"However, the fact that the DGSSN uses a large-vocabulary tagger   as a preprocessing stage may compensate for its smaller vocabulary.",0,original
"11 However, modeling word order under translation is notoriously difficult  , and it is unclear how much improvement in accuracy a good model of word order would provide.",0,original
" , we used the MXPOST   tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10way jackknifing to generate tags for the training set.",0,original
"The second method considers the means and variance of the distance between two words, and can compute flexible collocations  .",0,original
Hw6: Implement beam search and reduplicate the POS tagger described in  .,0,original
Tag sets for English are derived from the Penn Treebank  .,0,original
"Minimum error rate training   with respect to BLEU score was used to tune the decoders parameters, and performed using the technique proposed in  .",0,original
"As comparison, Turney and Littman   used seed sets consisting of 7 words in their word valence annotation experiments, while Turney   used minimal seed sets consisting of only one positive and one negative word   in his experiments on review classification.",0,original
This statistical technique of labeling predicate argument operates on the output of the probabilistic parser reported in  .,0,original
"4 The Experiment For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text  , with section 22 reserved for testing.",0,original
"3.3 CRFs and Perceptron Learning Perceptron training for conditional models   is an approximation to the SGD algorithm, using feature counts from the Viterbi label sequence in lieu of expected feature counts.",0,original
"Here, we use the hidden Markov model   alignment model   and Model 4 of Brown et al.",0,original
"This paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs    , which includes most parsers and parsing-based MT decoders.",0,original
"Moreover, this evaluation concern dovetails with a frequent engineering concern, that sentence-level scores are useful at various points in the MT pipeline: for example, minimum Bayes risk decoding  , selecting oracle translations for discriminative reranking  , and sentenceby-sentence comparisons of outputs during error analysis.",0,original
All conditions were optimized using BLEU   and evaluated using both BLEU and Translation Edit Rate    .,0,original
"The system combination weights  one for each system, LM weight, and word and NULL insertion penalties  were tuned to maximize the BLEU   score on the tuning set  .",0,original
Our scores fall within the range of previous researchers  .,0,original
"Narrative retellings provide a natural, conversational speech sample that can be analyzed for many of the characteristics of speech and language that have been shown to discriminate between healthy and impaired subjects, including syntactic complexity   and mean pause duration  .",0,original
The baseline hierarchical phrase-based system is trained using standard max-BLEU training   without sparse features  .,0,original
It is also possible to train statistical models using unlabeled data with the expectation maximization algorithm  .,0,original
"For the classifier, we used the OpenNLP MaxEnt implementation   of the maximum entropy classification algorithm  .",0,original
Our proposal is a first order linear model that relies on an online averaged Perceptron for learning   and an extended Eisner algorithm for the joint parsing inference.,0,original
The lexicalized parsing experiments were run using Dan Bikels probabilistic parsing engine   which in addition to replicating the models described by Collins   also provides a convenient interface to develop corresponding parsing models for other languages.,0,original
3.2 F-Structure Based NLD Recovery   presented a NLD recovery algorithm operating at LFG f-structure for treebankbased LFG approximations.,0,original
"1 Introduction Most   statistical machine translation systems employ a word-based alignment model  , which treats words in a sentence as independent entities and ignores the structural relationship among them.",0,original
ikipedia first sentence  : Kazama and Torisawa   used Wikipedia as an external knowledge to improve Named Entity Recognition,0,original
Our use of Gibbs sampling follows from its increasing use in Bayesian inference problems in NLP  .,0,original
"Features For each frame element, features are extracted from the surface text of the sentence and from an automatically generated syntactic parse tree  .",0,original
"More recently, Haffari and Sarkar   have extended the work of Abney   and given a better mathematical understanding of self-training algorithms.",0,original
Performance of Alternative Models 157 5 Related Work Previous parsing models   maximize the joint probability P  of a sentence S and its parse tree T. We maximize the conditional probability P .,0,original
"Our evaluation metric is case-insensitive BLEU-4  , as defined by NIST, that is, using the shortest   reference sentence length for the brevity penalty.",0,original
"For the English experiments, we use the now-standard training and test sets that were introduced in  2.",0,original
"This characteristic of our corpus is similar to problems with noisy and comparable corpora  , and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as  .",0,original
"A token can be a word or a punctuation symbol, and each of these neighboring tokens must be in the same sentence as a2 . We use a sentence segmentation program   and a POS tagger   to segment the tokens surrounding a2 into sentences and assign POS tags to these tokens.",0,original
"For comparison to previous results, table 2 lists the results on the testing set for our best model   and several other statistical parsers  .",0,original
In   non-terminals in a standard PCFG model are augmented with latent variables.,0,original
he Tagger Support cutoff Accuracy Collins   0 96.60% 5 96.72% Model 3W+TAGS variant 1 96.97% 5 96.93% Table 6: Effect of changing common word feature cutoffs  ,0,original
"Therefore, estimating a natural language model based on the maximum entropy   method   has been highlighted recently.",0,original
"In our decoder, we incorporate two pruning techniques described by  .",0,original
"It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation  ,  , (Koehn et al. , 2003, sec.",0,original
"Vilain and Day   identify   name phrases such as company names, locations, etc. Ramshaw and Marcus   detect noun phrases, by classifying each word as being inside a phrase, outside or on the boundary between phrases.",0,original
We performed experiments with two statistical classifiers: the decision tree induction system C4.5   and the Tilburg Memory-Based Learner    .,0,original
"4.5 Consistency of Annotations In order to assess the consistency of annotation, we follow Carletta   in using Cohen's ~, a chancecorrected measure of inter-rater agreement.",0,original
"Using Maximum Entropy   classifiers I built a parser that achieves a throughput of over 200 sentences per second, with a small loss in accuracy of about 23 %.",0,original
The 1000-best lists are augmented with IBM Model-1   scores and then rescored with a second set of MET parameters.,0,original
"When updating model parameters, we employ a memorizationvariant of a local updating strategy   in which parameters are optimized toward a set of good translations found in the k-best list across iterations.",0,original
"Pooling the sets to form two large CE and AE test sets, the AE system improvements are significant at a 95% level  ; the CE systems are only equivalent.",0,original
"To optimize the system towards a maximal BLEU or NIST score, we use Minimum Error Rate   Training as described in  .",0,original
"In this paper we report case-insensitive Bleu scores  , unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet  .",0,original
"Since parsing is just an initial stage of natural language understanding, the project was focused not just on obtaining syntactic trees alone   or Tiger  ).",0,original
"Method Source Spearman   Wikipedia 0.190.48   WordNet 0.330.35   Rogets 0.55   WordNet 0.55   Web corpus, WN 0.56   ODP 0.65   Wikipedia 0.75 SVM Web corpus, WN 0.78 Table 9: Comparison with previous work for WordSim353.",0,original
Our features were based on those in  .,0,original
"In order increase the likelihood that 909 only true paraphrases were considered as phraselevel alternations for an example, extracted sentences were clustered using complete-link clustering using a technique proposed in  .",0,original
"Partitioning 2: Medium and low frequency words As noted in  , log-likelihood statistics are able to capture word bi-gram regularities.",0,original
.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus's base NP chunker  ,0,original
ITGs translate into simple  -BRCGs in the following way; see Wu   for a definition of ITGs.,0,original
"In the following experiments, we run two machine learning classifiers: Bayes Point Machines    , and the maximum entropy model    .",0,original
"We carefully implemented the original Grammar Association system described in  , tuned empirically a couple of smoothing parameters, trained the models and, finally, obtained an a119a21a120 a100 a104a122a121 of correct translations.9 Then, we studied the impact of:   sorting, as proposed in Section 3, the set of sentences presented to ECGI;   making language models deterministic and minimum;   constraining the best translation search to those sentences whose lengths have been seen, in the training set, related to the length of the input sentence.",0,original
"To generate word alignments we use GIZA++  , which implements both the IBM Models of Brown et al.",0,original
"This formulation is similar to the energy minimization framework, which is commonly used in image analysis   and has been recently applied in natural language processing  .",0,original
"In the proposed method, the statistical machine translation     is deeply incorporated into the question answering process, instead of using the SMT as the preprocessing before the mono-lingual QA process as in the previous work.",0,original
"Conjunctions are a major source of errors for English chunking as well  9, and we plan to address them in future work.",0,original
"Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts  , as well as in similar predicateargument structure contexts  .",0,original
"To evaluate the polarity and strength of opinions, most of the existing approaches rely either on training from human-annotated data  , or use linguistic resources   like WordNet, or rely on co-occurrence statistics   between words that are unambiguously positive   and unambiguously negative  .",0,original
"4.1 Judging Rule Correctness Following the spirit of the fine-grained human evaluation in  , we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above.",0,original
"2.1 Baseline: IBM Model-1 The translation process can be viewed as operations of word substitutions, permutations, and insertions/deletions   in noisychannel modeling scheme at parallel sentence-pair level.",0,original
7.1.3 Similarity via pagerank Pagerank   is the celebrated citation ranking algorithm that has been applied to several natural language problems from summarization   to opinion mining   to our task of lexical relatedness  .,0,original
"For English, we used the Penn Treebank version 3.0   and extracted dependency relations by applying the head-finding rules of  .",0,original
"We trained a Chinese Treebank-style tokenizer and partof-speech tagger, both using a tagging model based on a perceptron learning algorithm  .",0,original
"Recently, severalmethods  have been proposed with similar motivation to ours.",0,original
"One way around this dif culty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar     and the binary synchronous context-free grammar   employed by the Hiero system   to model the hierarchical phrases.",0,original
Other systems   also look at Web product reviews but they do not extract 345 opinions about particular product features.,0,original
"To this end we follow the method introduced by  , i.e. by sliding a window of a given size over some texts.",0,original
"Second, phrase translation pairs are extracted from the word aligned corpus  .",0,original
atnaparkhi   estimates a POS tagging error rate of 3% in the Treebank,0,original
2 We used the Collins parser   to generate the constituency parse and a dependency converter   to obtain the dependency parse of English sentences.,0,original
"Similarity measures can be based on any level of linguistic analysis: semantic similarity relies on context vectors , whilesyntacticsimilarityisbased on the alignment of parallel corpora  .",0,original
"Adapting a vectorbased approach reported by Chu-Carroll and Carpenter  , the Task ID Frame Agent is domain-independent and automatically trained.",0,original
ollins   Model 3 integrates the detection and resolution of WH-traces in relative clauses into a lexicalized PCFG,0,original
"Inversion Transduction Grammar   is the model of Wu  , Tree-to-String is the model of Yamada and Knight  , and Tree-to-String, Clone allows the node cloning operation described above.",0,original
Such a technique has been used with TER to combine the output of multiple translation systems  .,0,original
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment  , or extraction of syntactic constructions from online dictionaries and corpora  .",0,original
"Mihalcea   demonstrates that manual mappings can be created for a small number of words with relative ease, but for a very large number of words the e ort involved in mapping would approach presented involves no be considerable.",0,original
"1.2 Recent work A few publications, so far, deal with POS-tagging of Northern Sotho; most prominently, de Schryver and de Pauw   have presented the MaxTag method, a tagger based on Maximum Entropy 38 Learning   as implemented in the machine learning package Maxent  .",0,original
"12 As such, we resort to an approximation: Voted Perceptron training  .",0,original
"In addition, the calculation cost for estimating parameters of embedded joint PMs   is independent of the number of HMMs, J, that we used  .",0,original
Syntactic Score   Some erroneous sentences often contain words and concepts that are locally correct but cannot form coherent sentences  .,0,original
.3 Model Construction The head transducer model was trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus  ,0,original
"For instance, Hughes and Ramage   constructed a graph which represented various types of word relations from WordNet, and compared random-walk similarity to similarity assessments from humansubject trials.",0,original
"Titov and McDonald   proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors.",0,original
"This sequential property is well suited to HMMs  , in which the jumps from the current aligned position can only be forward.",0,original
"That is, phrases are heuristically extracted from word-level alignments produced by doing GIZA++ training on the corresponding parallel corpora  .",0,original
503 Bikel Intricacies of Collins Parsing Model Table 4 Overall parsing results using only details found in Collins  .,0,original
"We also show that the domain adaptation work of  , which is presented as an ad-hoc preprocessing step, is actually equivalent to our formal model.",0,original
"In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus  .",0,original
Related Work The first application of log-linear models to parsing is the work of Ratnaparkhi and colleagues  .,0,original
urney   used collocation with excellent or poor to obtain positive and negative clues for document classification,0,original
We distinguish two main approaches to domain adaptation that have been addressed in the literature  : supervised and semi-supervised.,0,original
"Minimum-error-rate training   are conducted on dev-set to optimize feature weights maximizing the BLEU score up to 4grams, and the obtained feature weights are blindly applied on the test-set.",0,original
"We show that the method of  , which was presented as a simple preprocessing step, is actually equivalent, except our representation explicitly separates hyperparameters which were tied in his work.",0,original
4.2 Models with Prior Distributions Minimum discrimination information models   are exponential models with a prior distribution q : p  = q exp ) Z    The central issue in performance prediction for MDI models is whether q  needs to be accounted for.,0,original
It has been argued that METEOR correlates better with human judgment due to higher weight on recall than precision  .,0,original
OUGE-LCS calculated the longest common 2 Details of our official DUC 2004 headline generation system can be found in Doran et al,0,original
"Generalized Forward Backward Reestimation Generalization of the Forward and Viterbi Algorithm In English part of speech taggers, the maximization of Equation   to get the most likely tag sequence, is accomplished by the Viterbi algorithm  , and the maximum likelihood estimates of the parameters of Equation   are obtained from untagged corpus by the ForwardBackward algorithm  .",0,original
"Clark and Curran   describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word  .",0,original
"Related work includes Wu  , Zens and Ney   and Wellington et al.",0,original
owever morphosyntactic features alone cannot verify the terminological status of the units extracted since they can also select non terms  ,0,original
PMI++ is an extended version of  s method for finding the SO label of a phrase  .,0,original
Consider the following example  : This film should be brilliant.,0,original
Another body of related work is the literature on word clustering in computational linguistics   and document clustering in information retrieval  .,0,original
ur system assumes POS tags as input and uses the tagger of Ratnaparkhi   to provide tags for the development and evaluation sets,0,original
"We present results in the form of search error analysis and translation quality as measured by the BLEU score   on the IWSLT 06 text translation task  1, comparing Cube Pruning with our two-pass approach.",0,original
"We compare TERp with BLEU  , METEOR  , and TER  .",0,original
here have been many approaches to compute the similarity between words based on their distribution in a corpus  ,0,original
"1 Introduction The importance of learning to manipulate monolingual paraphrase relationships for applications like summarization, search, and dialog has been highlighted by a number of recent efforts  .",0,original
The model cleanly incorporates both syntax and lexical semantics using quasi-synchronous dependency grammars  .,0,original
"While traditional approaches to syntax based MT were dependent on availability of manual grammar, more recent approaches operate within the resources of PB-SMT and induce hierarchical or linguistic grammars from existing phrasal units, to provide better generality and structure for reordering  .",0,original
  applied iterative refinement algorithms to sentence level alignment tasks.,0,original
Related Work 2.1 Translation with Non-parallel Corpora A straightforward approach to word or phrase translation is to perform the task by using parallel bilingual corpora  .,0,original
albot and Brants   used a Bloomier filter to encode a LM,0,original
"In Section 3, we will present a Perceptron like algorithm   to obtain the parameters.",0,original
"To determine the tree head-word we used a set of rules similar to that described by    and also used by  , which we modified in the following way:  The head of a prepositional phrase   was substituted by a function the name of which corresponds to the preposition, and its sole argument corresponds to the head of the noun phrase NP.",0,original
"Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment  , word alignment  , alignment of groups of words  , and statistical translation  .",0,original
2 Related Work A large amount of previous research on clustering has been focused on how to find the best clusters  .,0,original
"In particular, we use a feature augmentation technique recently introduced by Daume III  , and active learning   to perform domain adaptation of WSD systems.",0,original
"We use the Stanford parser   with its default Chinese grammar, the GIZA++   alignment package with its default settings, and the ME tool developed by  .",0,original
"For example, in machine translation evaluation, approaches such as BLEU   use n-gram overlap comparisons with a model to judge overall goodness, with higher n-grams meant to capture fluency considerations.",0,original
This can also be interpreted as a generalization of standard class-based models  .,0,original
"On the one hand using 1 human reference with uniform results is essential for our methodology, since it means that there is no more trouble with Recall    a systems ability to avoid under-generation of N-grams can now be reliably measured.",0,original
"2 Inside-out alignments Wu   identified so-called inside-out alignments, two alignment configurations that cannot be induced by binary synchronous context-free grammars; these alignment configurations, while infrequent in language pairs such as EnglishFrench  , have been argued to be frequent in other language pairs, incl.",0,original
"To avoid this problem, generative models for NLP tasks have often been manually designed to achieve an appropriate representation of the joint distribution, such as in the parsing models of  .",0,original
The clusters were found automatically by attempting to minimize perplexity  .,0,original
"In this work, we employ a syntax-based model that applies a series of tree/string   rules   to a source language string to produce a target language phrase structure tree.",0,original
"The tagger is a Hidden Markov Model trained with the perceptron algorithm introduced in  , which applies Viterbi decoding and is regularized using averaging.",0,original
"Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases  .",0,original
Gibbs sampling is not new to the natural language processing community  .,0,original
We collect substring rationales for a sentiment classification task   and use them to obtain significant accuracy improvements for each annotator.,0,original
We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank   and Prague Dependency Treebank    .,0,original
"5.1 Pharaoh The baseline system we used for comparison was Pharaoh  , a freely available decoder for phrase-based translation models: p  = p  pLM LM  pD D length W    We ran GIZA++   on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in   to obtain a single many-to-many word alignment for each sentence pair.",0,original
"These findings are in line with Collins & Roarks   results with incremental parsing with perceptrons, where it is suggested that a generative baseline feature provides the perceptron algorithm with a much better starting point for learning.",0,original
"The features used by the POS tagger, some of which are different to those from Collins   and are specific to Chinese, are shown in Table 2.",0,original
"Note that generative hybrids are the norm in SMT, where translation scores are provided by a discriminative combination of generative models  .",0,original
A word link extension algorithm similar to the one presented in this paper is given in  .,0,original
"Starting from a word-based alignment for each pair of sentences, the training for the algorithm accepts all contiguous bilingual phrase pairs   whose words are only aligned with each other  .",0,original
"In addition to sentence fusion, compression algorithms   and methods for expansion of a multiparallel corpus   are other instances of such methods.",0,original
"In paraphrase generation, a text unit that matches a pattern P can be rewritten using the paraphrase patterns of P. Avarietyofmethodshavebeenproposedonparaphrase patterns extraction  .",0,original
"Firstly, they classify all the GHKM2 rules   into two categories: lexical rules and non-lexical rules.",0,original
"Since we approach decoding as xR transduction, the process is identical to that of constituencybased algorithms  .",0,original
Collins et al.  proposed two algorithms for NER by modifying Yarowskys method   and the framework suggested by  .,0,original
The ME Tagger The ME tagger is based on Ratnaparkhi  s POS tagger and is described in Curran and Clark  ,0,original
4.2 Classifier and Features For our AL framework we decided to employ a Maximum Entropy   classifier  .,0,original
Other recent work has incorporated constituent and dependency subtrees into the translation rules used by phrase-based systems  .,0,original
Our baseline uses Giza++ alignments   symmetrized with the grow-diag-final-and heuristic  .,0,original
84 5.2 Machine translation on Europarl corpus We further tested our WDHMM on a phrase-based machine translation system to see whether our improvement on word alignment can also improve MT accuracy measured by BLEU score  .,0,original
Networks   97.24 SVM   97.05 ME based a bidirectional inference   97.15 Guided learning for bidirectional sequence classification   97.33 AdaBoost.SDF with candidate features   97.32 AdaBoost.SDF with candidate features   97.32 SVM with candidate features   97.32 Text Chunking F=1 Regularized Winnow + full parser output   94.17 SVM-voting   93.91 ASO + unlabeled data   94.39 CRF+Reranking  94.12 ME based a bidirectional inference   93.70 LaSo     94.4 HySOL   94.36 AdaBoost.SDF with candidate featuers   94.32 AdaBoost.SDF with candidate featuers   94.30 SVM with candidate features   94.31 One of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.,0,original
5 Data Sets and Supervised Tagger 5.1 Source Domain: WSJ We used sections 02-21 of the Penn Treebank   for training.,0,original
"  where K is the number of distinct nonternfinal symbols in the gramma.r G. We ca.n expect a. very etfide.nt pa.rser tbr our pa.tterns, r The input string ca.n a.lso be scanned to reduce the number of relewmt gramma.r rules before pa.rsing, e The combined process is a.lso known as offlineparsing in LTAC,.",0,original
he algorithm we implemented is inspired by the work of Yarowsky   on word sense disambiguation,0,original
1418 examples of structures of the kind 'VB N1 PREP N2' were extracted from the Penn-TreeBank Wall Street Journal  ,0,original
"We use the averaged perceptron algorithm, as presented in Collins  , to train the parser.",0,original
"In most statistical machine translation   models  , some of measure words can be generated without modification or additional processing.",0,original
"The generator used in our experiments is an instance of the second type, using a probability model defined over Lexical Functional Grammar c-structure and f-structure annotations  .",0,original
"For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words  .",0,original
"We also tested other automatic methods: content-based evaluation, BLEU   and ROUGE-1  , and compared their results with that of evaluation by revision as reference.",0,original
"Following  , we used the version 11a NIST BLEU script with its default settings to calculate the BLEU scores   based on case-insensitive ngram matching, where n is up to 4.",0,original
"Table 2: Corpora and Modalities CORPUS MODALITY ACE asserted, or other TIMEML must, may, should, would, or could Prasad et al., 2006 assertion, belief, facts or eventualities Saur et al., 2007 certain, probable, possible, or other Inui et al., 2008 affirm, infer, doubt, hear, intend, ask, recommend, hypothesize, or other THIS STUDY S/O, necessity, hope, possible, recommend, intend   Table 3: Markup Scheme   Tag Definition   R Remedy, Medical operation   T Medical test, Medical examination   D Deasese, Symptom   M Medication, administration of a drug   A patient action   V Other verb     2 Related Works 2.1 Previous Markup Schemes In the NLP field, fact identification has not been studied well to date.",0,original
Ramshaw and Marcus used transformationbased learning   for developing two chunkers  .,0,original
"There are several distance measures suitable for this purpose, such as the mutual information , the dice coefficient , the phi coefficient , the cosine measure  and the confidence .",0,original
A Head Percolation Table has previously been used in several statistical parsers   to find heads of phrases.,0,original
"See Collins   for an application of the boosting approach to named entity recognition, and Walker, Rambow, and Rogati   for the application of boosting techniques for ranking in the context of natural language generation.",0,original
"The algorithm to acquire the lexicon, implemented in the ARIOSTQLEX system, has been extensively described in \ .",0,original
he extraction procedure utilizes a head percolation table as introduced by Magerman   in combination with a variation of Collinss   approach to the differentiation between complement and adjunct,0,original
Sang used the IOB tagging method proposed by Ramshow  and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the Penn Treebank corpus.,0,original
These probabilities are estimated with IBM model 1   on parallel corpora.,0,original
As with other randomised models we construct queries with the appropriate sanity checks to lower the error rate efficiently  .,0,original
"Unfortunately, as was shown by Fraser and Marcu   AER can have weak correlation with translation performance as measured by BLEU score  , when the alignments are used to train a phrase-based translation system.",0,original
ethod Number of frames Number of verbs Linguistic resources F-Score   Coverage on a corpus C. Manning   19 200 POS tagger + simple finite state parser 58 T. Briscoe & J. Carroll   161 14 Full parser 55 A. Sarkar & D. Zeman   137 914 Annotated treebank 88 D. Kawahara et al,0,original
It has been observed that words close to each other in the source language tend to remain close to each other in the translation  .,0,original
The trigger-based lexicon model used in this work follows the training procedure introduced in   and is integrated directly in the decoder instead of being applied in n-best list reranking.,0,original
"The word-based edit distance heuristic yields pairs that are relatively clean but offer relatively minor rewrites in generation, especially when compared to the MSA model of  .",0,original
"Most statistical parsing research, such as Collins  , has centered on training probabilistic context-free grammars using the Penn Treebank.",0,original
"To set the weight vector w, we train twenty averaged perceptrons   on different shuffles of data drawn from sections 0221 of the Penn Treebank.",0,original
"We use MXPOST tagger   for POS tagging, Charniak parser   for extracting syntactic relations, SVMlight1 for SVM classifier and David Bleis version of LDA2 for LDA training and inference.",0,original
5.2 Maximum Entropy Model We use the Maximum Entropy   Model   for our classification task.,0,original
  describe an approach that targets translation of French phrases of the form NOUN de NOUN  .,0,original
"Therefore, an increasing attention has been recently given to semi-supervised learning, where large amounts of unlabeled data are used to improve the models learned from a small training set  .",0,original
"Using GIZA++ model 4 alignments and Pharaoh  , we achieved a BLEU score of 0.3035.",0,original
"Third, we hope that the improved parses of bitext will serve as higher quality training data for improving monolingual parsing using a process similar to self-training  .",0,original
"3 Hebrew Simple NP Chunks The standard definition of English base-NPs is any noun phrase that does not contain another noun phrase, with possessives treated as a special case, viewing the possessive marker as the first word of a new base-NP  .",0,original
"We have also used TPTs to encode n-gram count databases such as the Google 1T web n-gram database  , but are not able to provide detailed results within the space limitations of this paper.4 5.1 Perplexity computation with 5-gram language models We compared the performance of TPT-encoded language models against three other language model implementations: the SRI language modeling toolkit  , IRSTLM  , and the language model implementation currently used in the Portage SMT system  , which uses a pointer-based implementation but is able to perform fast LM filtering at load time.",0,original
918 English For English we used the Wall Street Journal section of the Penn Treebank  .,0,original
his hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation  ,0,original
"Following recent research about disambiguation models on linguistic grammars  , we apply a log-linear model or maximum entropy model   on HPSG derivations.",0,original
Although the training algorithm can handle realvalued features as used in   the current paper intentionally excludes them.,0,original
"As, from a linguistic perspective, it is the modifier 2We use a mechanism similar to   but adapted to Chinese data to find lexical heads in the treebank data.",0,original
The Penn Treebank documentation   defines a commonly used set of tags.,0,original
"The experiment used all 578 sentences in the ATIS corpus with a parse tree, in the Penn Treebank  .",0,original
ALM does this by using alignment models from the statistical machine translation literature  .,0,original
"146 2.3 Approximating ISBNs   proposes two approximations for inference in ISBNs, both based on variational methods.",0,original
??Initial phrase pairs are identified following the procedure typically employed in phrase based systems  .,0,original
The empirical probability for each sentence pair is estimated by maximum likelihood estimation over the training data  .,0,original
2.2 Maximum Entropy Our next approach is the Maximum Entropy   classification approach.,0,original
"Turney   applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification.",0,original
"In addition, we use the measure from Resnik  , which is computed using an intrinsic information content measure relying on the hierarchical structure of the category tree  .",0,original
"First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases   and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization  .",0,original
"Therefore, other machine learning techniques such as perceptron   could also be applied for this problem.",0,original
"3 The Framework 3.1 The Algorithm Our transductive learning algorithm, Algorithm 1, is inspired by the Yarowsky algorithm  .",0,original
"Collocation Dictionary of Modern Chinese Lexical Words, Business Publisher, China Yuan Liu, et al. 1993.",0,original
"Comparison With Previous Work Most of the recent corpus-based POS taggers in the literature are either statistically based, and use Markov Model  or Statistical Decision Tree   techniques, or are primarily rule based, such as Drill's Transformation Based Learner  .",0,original
"A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training  .",0,original
"For example, incremental CFG parsing algorithms can be used with the CFGs produced by this transform, as can the Inside-Outside estimation algorithm   and more exotic methods such as estimating adjoined hidden states  .",0,original
"For natural language engineers, the problem bears on information management systems like abstractive summarizers that must measure semantic overlap between sentences  , question answering modules   and machine translation  .",0,original
distance   and the maximum swap segment size   ranging from 0 to 10 and evaluated the translations with the BLEU7 metric  .,0,original
"  Merkel, Nilsson, & Ahrenberg   have constructed a system that uses frequency of recurrent segments to determine long phrases.",0,original
"As with many dependency parsers  , we handle non-projective   arcs by transforming them into noncrossing arcs with augmented labels.1 Because our syntactic derivations are equivalent to those of  , we use their HEAD methods to projectivise the syntactic dependencies.",0,original
"joint likelihood   productdisplay i p parenleftBig xi,yi | vector parenrightBig conditional likelihood   productdisplay i p parenleftBig yi | xi,vector parenrightBig classification accuracy   summationdisplay i  ) expected classification accuracy   summationdisplay i p parenleftBig yi | xi,vector parenrightBig negated boosting loss    summationdisplay i p parenleftBig yi | xi,vector parenrightBig1 margin    s.t. bardbl vectorbardbl  1;i,y negationslash= yi, vector     vectorf )   expected local accuracy   productdisplay i productdisplay j p parenleftBig lscriptj  = lscriptj  | xi,vector parenrightBig Table 1: Various supervised training criteria.",0,original
t is known that ITGs do not induce the class of inside-out alignments discussed in Wu  ,0,original
"  and Chiang  , in terms of what alignments they induce, has been discussed in Wu   and Wellington et al.",0,original
"Aware of this problem, Resnik and Yarowsky suggest creating the sense distance matrix based on results in experimental psychology such as Miller and Charles   or Resnik  .",0,original
This criticism leads us to automatic approaches for building thesauri from large corpora \ .,0,original
"Barzilay and Lee   proposed to apply multiple-sequence alignment   for traditional, sentence-level PR.",0,original
"In  , an undirected graphical model for constituent parse reranking uses dependency relations to define the edges.",0,original
"Finally, we would like to investigate the incorporation of unsupervised methods for WSD, such as the heuristically-based methods of   and  , and the theoretically purer bootstrapping method of  .",0,original
These estimates are usually heuristic and inconsistent  .,0,original
Another WSD approach incorporating context-dependent phrasal translation lexicons is given in   and has been evaluated on several translation tasks.,0,original
"Typically, a phrase-based SMT system includes a feature that scores phrase pairs using lexical weights   which are computed for two directions: source to target and target to source.",0,original
"3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure   Verb and Preposition Databases  , the Brown Corpus section of the Penn Treebank  , an English morphological analysis lexicon developed for PC-Kimmo    , NOMLEX  , Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmers errors, see  .",0,original
The algorithm of   translates the traces into corresponding re-entrancies in the f-structure representation  .,0,original
"More complete discussions of M.E. as applied to computational linguistics, including a description of the M.E. estimation procedure can be found in   and  .",0,original
2 F 1 -score Maximization Training of LRM We first review the F 1 -score maximization training method for linear models using a logistic function described in  .,0,original
Prototype-drive learning   specifies prior knowledge by providing a few prototypes   for each label.,0,original
"To obtain their corresponding weights, we adapted the minimum-error-rate training algorithm   to train the outside-layer model.",0,original
"1 Introduction Several approaches including statistical techniques  , lexical techniques   and hybrid techniques  , have been pursued to design schemes for word alignment which aims at establishing links between words of a source language and a target language in a parallel corpus.",0,original
1 Introduction Shallow parsing has received a reasonable amount of attention in the last few years  ).,0,original
"Although Phramer provides decoding functionality equivalent to Pharaohs, we preferred to use Pharaoh for this task because it is much faster than Phramer  between 2 and 15 times faster, depending on the configuration  and preliminary tests showed that there is no noticeable difference between the output of these two in terms of BLEU   score.",0,original
There have been a number of methods proposed in the literature to address the word clustering problem  ).,0,original
"Word-aligned corpora have been found to be an excellent source for translation-related knowledge, not only for phrase-based models  , but also for syntax-based models  ).",0,original
All model weights were trained on development sets via minimum-error rate training     with 200 unique n-best lists and optimizing toward BLEU.,0,original
"The performance of cross-language information retrieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often  .",0,original
"Like Collins  , the decoder is the same for both the perceptron and the log-linear parsing models; the only change is the method for setting the weights.",0,original
"The upper envelope is a convex hull and can be inscribed with a convex polygon whose edges are the segments of a piecewise linear function in   : EnvD4fD5 AG max eC8C AWa D4e,fD5 A0  A4 bD4e,fD5 :  C8 RB4   726 Score  Error count  0 0 e1 e2 e5 e6 e8 e1e 2 e3 e4 e5e6e 7 e8 Figure 1: The upper envelope   for a set of lines is the convex hull which consists of the topmost line segments.",0,original
This algorithm adjusts the log-linear weights so that BLEU   is maximized over a given development set.,0,original
"To be able identify that adjacent blocks   can be merged into larger blocks, our model infers binary   trees reminiscent of  .",0,original
We use a standard data set   consisting of sections 15-19 of the WSJ corpus as training and section 20 as testing.,0,original
"Moreover, under this view, SMT becomes quite similar to sequential natural language annotation problems such as part-of-speech tagging and shallow parsing, and the novel training algorithm presented in this paper is actually most similar to work on training algorithms presented for these task, e.g. the on-line training algorithm presented in   and the perceptron training algorithm presented in  .",0,original
"Using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings   and in machine translation     | interestingly, statistical MT techniques have been used to derive lexico-semantic mappings in the \reverse"""" direction of language understanding rather than generation  .",0,original
"The idea of topic signature terms was introduced by Lin and Hovy   in the context of single document summarization, and was later used in several multi-document summarization systems  .",0,original
"The data consists of 2,544 main clauses from the Wall Street Journal Treebank corpus  .",0,original
Systems were optimized on the WMT08 French-English development data   using minimum error rate training   and tested on the WMT08 test data  .,0,original
Some regarded Wikipedia as the corpora and applied hand-crafted or machine-learned rules to acquire semantic relations  .,0,original
The translation model is estimated via the EM algorithm or approximations that are bootstrapped from the previous model in the sequence as introduced in  .,0,original
"In showing how DLTAG and an interpretative process on its derivations operate, we must, of necessity, gloss over how inference triggered by adjacency or associated with a structural connective provides the intended relation between adjacent discourse 578 Computational Linguistics Volume 29, Number 4 units: It may be a matter simply of statistical inference, as in Marcu and Echihabi  , or of more complex inference, as in Hobbs et al.",0,original
"2.1 Model 2 of   Both parsing models discussed in this paper inherit a great deal from this model, so we briefly describe its """"progenitive"""" features here, describing only how each of the two models of this paper differ in the subsequent two sections.",0,original
"Words surrounding the current word have been occasionally used in taggers, such as  , Brills transformation based tagger  , and the HMM model of Lee et al.",0,original
"  then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other.",0,original
Use of sententially aligned corpora for word alignment has already been recommended in  .,0,original
The polarity value proposed by   is as follows.,0,original
"By no means an exhaustive list, the most commonly cited ranking and scoring algorithms are HITS   and PageRank  , which rank hyperlinked documents using the concepts of hubs and authorities.",0,original
"For  , the morphemes and labels for our task are:   kita NEG tINC inE1S chabe VT -j SC laj PREP inA1S yol S -j SC iin PRON We also consider POS-tagging for Danish, Dutch, English, and Swedish; the English is from sections 00-05   and 19-21   of the Penn Treebank  , and the other languages are from the CoNLL-X dependency parsing shared task  .1 We split the original training data into training and development sets.",0,original
he most direct comparison is between our system and those presented in Cahill and van Genabith   and Hogan et al,0,original
"Instead, researchers routinely use automatic metrics like Bleu   as the sole evidence of improvement to translation quality.",0,original
"In his Xtract system, Smadja   first extracted significant pairs of words that consistently co-occur within a single syntactic structure using statistical scores called distance, strength and spread, and then examined concordances of the bi-grams to find longer frequent multiword units.",0,original
Such coarse-grained inventories can be produced manually from scratch   or by automatically relating   or clustering   existing word senses.,0,original
"They use a conditional model, based on Collins  , which, as the authors acknowledge, has a number of theoretical deficiencies; thus the results of Clark et al. provide a useful baseline for the new models presented here.",0,original
"Tillmann and Zhang   used a different update style based on a convex loss function:  = L max parenleftBig 0, 1 parenleftBig si si  parenrightBigparenrightBig 768 Table 1: Experimental results obtained by varying normalized tokens used with surface form.",0,original
2 Literature Survey The task of sentiment analysis has evolved from document level analysis  ;  ) to sentence level analysis  ;  ;  ).,0,original
1 Introduction In phrase-based statistical machine translation   phrases extracted from word-aligned parallel data are the fundamental unit of translation.,0,original
2 Phrase-based statistical machine translation Phrase-based SMT uses a framework of log-linear models   to integrate multiple features.,0,original
"e.g. BLEU   for machine translation, ROUGE   for summarization.",0,original
A class of training criteria that provides a tighter connection between the decision rule and the final error metric is known as Minimum Error Rate Training   and has been suggested for SMT in  .,0,original
"Output sequence optimization Rather than basing classifications only on model parameters estimated from co-occurrences between input and output symbols employed for maximizing the likelihood of point-wise single-label predictions at the output level, classifier output may be augmented by an optimization over the output sequence as a whole using optimization techniques such as beam searching in the space of a conditional markov models output   or hidden markov models  .",0,original
"The annotation guidelines for the Penn Treebank flattened noun phrases to simplify annotation  , so there is no complex structure to NPs.",0,original
"To compare the performance of system, we recorded the total training time and the BLEU score, which is a standard automatic measurement of the translation quality .",0,original
"In this paper, we give an overview of NLPWin, a multi-application natural language analysis and generation system under development at Microsoft Research  , incorporating analysis systems for 7 languages  .",0,original
"??search engines: Turney   uses the Altavista web browser, while we consider and combine the frequency information acquired from three web search engines.",0,original
Evaluation metrics such as BLEU   have a built-in preference for shorter translations.,0,original
he feasibility of such post-parse deepening   is demonstrated by Cahill et al  ,0,original
Supervision for simple features has been explored in the literature  .,0,original
An open question in SMT is whether there existsclosed formexpressions   for P   and the counts in the EM iterations for models 3-5  .,0,original
"Finally, we compare against the mapping from WordNet to the Oxford English Dictionary constructed in  , equivalent to clustering based solely on the OED feature.",0,original
"Others have introduced alternative discriminative training methods  , in which a recurring challenge is scalability: to train many features, we need many train218 ing examples, and to train discriminatively, we need to search through all possible translations of each training example.",0,original
2 Phrasal Inversion Transduction Grammar We use a phrasal extension of Inversion Transduction Grammar   as the generative framework.,0,original
Our results on Chinese data confirm previous findings on English data shown in  .,0,original
A model was trained using Maximum Likelihood from the UPenn Treebank  .,0,original
"IIowever,   have shown that knowledge of target-text length is not crucial to the model's i)ertbrmanee.",0,original
or colnparison~ we refer here to Smadja's method   because this method and the proposed method have much in connnon,0,original
The features are the same as those in  .,0,original
TheauthorsapplySO-PMI-IR  to extract and determine the polarity of adjectives.,0,original
"1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts  , semantic lexicons  , concept lists  , and word similarity lists  .",0,original
One possible use for this technique is for parser adaptation  initially training the parser on one type of data for which hand-labeled trees are available  ) and then self-training on a second type of data in order to adapt the parser to the second domain.,0,original
"We rst recast the problem of estimating the IBM models   in a discriminative framework, which leads to an initial increase in word-alignment accuracy.",0,original
similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi  ,0,original
"The difference in accuracy between a SVM model applied to RRR dataset   and the same experiment applied to TB2 dataset   88.2 RRR Average human, whole sentence   93.2 RRR Maximum Likelihood-based   79.7 AP Maximum entropy, words   77.7 RRR Maximum entropy, words & classes   81.6 RRR Decision trees   77.7 RRR Transformation-Based Learning   81.8 WordNet Maximum-Likelihood based   84.5 RRR Maximum-Likelihood based   86.1 TB2 Decision trees & WSD   88.1 RRR WordNet Memory-based Learning   84.4 RRR LexSpace Maximum entropy, unsupervised   81.9 Maximum entropy, supervised   83.7 RRR Neural Nets   86.0 RRR WordNet Boosting   84.4 RRR Semi-probabilistic   84.31 RRR Maximum entropy, ensemble   85.5 RRR LSA SVM   84.8 RRR Nearest-neighbor   86.5 RRR DWS FN dataset, w/o semantic features   91.79 FN PR-WWW FN dataset, w/ semantic features   92.85 FN PR-WWW TB2 dataset, best feature set   93.62 TB2 PR-WWW Table 5: Accuracy of PP-attachment ambiguity resolution   basic experiment) is 2.9%.",0,original
"Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT  , operating on characters rather than words.",0,original
"In one experiment, it has to be performed on the basis of the gold-standard, assumed-perfect POS taken directly from the training data, the Penn Treebank  , so as to abstract from a particular POS tagger and to provide an upper bound.",0,original
Our model uses an exemplar memory that consists of 133566 verb-role-noun triples extracted from the Wall Street Journal and Brown parts of the Penn Treebank  .,0,original
"2.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy   model.",0,original
"We could also introduce new variables, e.g., nonterminal refinements  , or secondary linksMij   that augment the parse with representations of control, binding, etc.",0,original
"It is difficult to compare these with previous work, but Haghighi and Klein   report that in a completely unsupervised setting, their MRF model, which uses a large set of additional features and a more complex estimation procedure, achieves an average 1-to-1 accuracy of 41.3%.",0,original
"Words are encoded through an automatic clustering algorithm   while tags, labels and extensions are normally encoded using diagonal bits.",0,original
Examples of such knowledge sources include stemming and TF-IDF weighting  .,0,original
"Appendix A: Derivation of the Probability of RWE We take a noisy channel approach, which is a common technique in NLP  ), including spellchecking  .",0,original
"3 MaltParser MaltParser   is a languageindependent system for data-driven dependency parsing, based on a transition-based parsing model  .",0,original
"  describes how the voted perceptron can be used to train maximum-entropy style taggers, and also gives a more thorough discussion of the theory behind the perceptron algorithm applied to ranking tasks.",0,original
"Intuitively, if we are able to find good correspondences among features, then the augmented labeled source domain data should transfer better to a target domain    .",0,original
3A hypergraph is analogous to a parse forest  .,0,original
"Our MT experiments use a re-implementation of Moses   called Phrasal, which provides an easier API for adding features.",0,original
We follow the work of   and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk   decoding  .,0,original
"More importantly, the ratio of binarizability, as expected, decreases on freer word-order languages  .",0,original
"Practically, the grammar relaxation is done via the introduction of non-standard CCG rules  .",0,original
We augment Collins head-driven model 2   to incorporate a semantic label on each internal node.,0,original
"As a common strategy, POS guessers examine the endings of unknown words   along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech  .",0,original
"Modeling reordering as the inversion in order of two adjacent blocks is similar to the approach taken by the Inverse Transduction Model    , except that here we are not limited to a binary tree.",0,original
"Statistical Phrase-based Translation  : Here phrase-based means subsequence-based, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases.",0,original
"We accordingly introduce approaches which attempt to include semantic information into the coreference models from a variety of knowledge sources, e.g. WordNet  , Wikipedia   and automatically harvested patterns  .",0,original
"A variety of algorithms  , co-training  , alternating structure optimization  , etc).",0,original
"However, the approach raises two major challenges: 7In practice, MERT training   will be used to train relative weights for the different model components.",0,original
"In phrase-based SMT systems  , foreign sentences are firstly segmented into phrases which consists of adjacent words.",0,original
"In particular, we use a randomly-selected corpus the first five columns as information-like. consisting of a 6.7 million word subset of the TREC Similarly, since the last four columns share databases  .",0,original
Weischedel's group   examines unknown words in the context of part-of-speech tagging.,0,original
Turney   reported that the NEAR operator outperformed simple page co-occurrence for his purposes; our early experiments informally showed the same for this work.,0,original
"Following Wu  , the prevailing opinion in the research community has been that more complex patterns of word alignment in real bitexts are mostly attributable to alignment errors.",0,original
"Previous approaches, e.g.,   and  , have all used the Brown algorithm for clustering  .",0,original
translation systems   and use Moses   to search for the best target sentence.,0,original
Negation was processed in a similar way as previous works  .,0,original
"Yarowsky   proposes a method for word sense disambiguation, which is based on Monolingual Bootstrapping.",0,original
"3 We then run Collins parser  , using just the sentence pairs where parsing succeeds with a negative log likelihood below 200.",0,original
"Note that the results of MB-D here cannot be directly compared with those in Yarowsky  , because the data used are different.",0,original
"1 Introduction In this paper, we study the use of so-called word trigger pairs     to improve an existing language model, which is typically a trigram model in combination with a cache component  .",0,original
2 Background Default unification has been investigated by many researchers   in the context of developing lexical semantics.,0,original
1.2 Statistical modeling for translation Earlier work in statistical machine translation   is based on the noisy-channel formulation where T = arg max T p  = argmax T p p    where the target language model p  is further decomposed as p  / productdisplay i p  where k is the order of the language model and the translation model p  has been modeled by a sequence of five models with increasing complexity  .,0,original
"Alternatively, order is modelled in terms of movement of automatically induced hierarchical structure of sentences  .",0,original
"First, hierarchical word clusters are derived from unlabeled data using the Brown et al. clustering algorithm  .",0,original
"Given that semantically similar words can be identified automatically on the basis of distributional properties and linguistic cues  , identifying the semantic orientation of words would allow a system to further refine the retrieved semantic similarity relationships, extracting antonyms.",0,original
"The model is defined mathematically   as following: p  = 1Zexp nsummationdisplay i=1 ihi    where i is a vector of weights determined during a tuning process, and hi is the feature function.",0,original
"For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system  .",0,original
Further enhancement of these utilities include compiling collocation statistics   and semi-automatic gloassary construction  .,0,original
"There has also been previous work on determining whether a given text is factual or expresses opinion  ; again this work uses a binary distinction, and supervised rather than unsupervised approaches.",0,original
"The sequential classi cation approach can handle many correlated features, as demonstrated in work on maximum-entropy   and a variety of other linear classi ers, including winnow  , AdaBoost  , and support-vector machines  .",0,original
Previous work has shown that data collected through the Mechanical Turk service is reliable and comparable in quality with trusted sources  .,0,original
"Typical approaches to conversion of constituent structures into dependencies are based on handconstructed head percolation rules, an idea that has its roots in lexicalized constituent parsing  .",0,original
3.1 Learning Chunk-based Translation We learn chunk alignments from a corpus that has been word-aligned by a training toolkit for wordbased translation models: the Giza++   toolkit for the IBM models  .,0,original
An alternative would be using a vector space model for classi cation where calltypes and utterances are represented as vectors including word a2 -grams  .,0,original
Model 1 is the word-pair translation model used in simple machine translation and understanding models  .,0,original
"Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval  , cross-language text classification  , lexical choice in machine translation  , induction of translation lexicons  , cross-language annotation and resource projections to a second language  .",0,original
It has been shown that both Nave Bayes and SVMs perform with similar accuracy on different sentiment tagging tasks  .,0,original
"8 An alternative formula for G 2 is given in Dunning  , but the two are equivalent.",0,original
"3 The M&E Framework We model two RSRs, Cause and Contrast, adopting the de nitions of Marcu and Echihabi     for their Cause-ExplanationEvidence and Contrast relations, respectively.",0,original
6 The Experimental Results We used the Penn Treebank   to perform empirical experiments on this parsing model.,0,original
"Firstly, there is also H  A  declined H  H  the dollar A  H  C  H  H  Figure 2: A tree with constituents marked the top-down method, which is a version of the algorithm described by Hockenmaier et al  , but used for translating into simple   CG rather than the Steedmans Combinatory Categorial Grammar    .",0,original
Further details are in the original paper  .,0,original
Almost all of these measures can be grouped into one of the following three categories: a0 frequency-based measures   a0 information-theoretic measures   a0 statistical measures   The corresponding metrics have been extensively discussed in the literature both in terms of their mathematical properties   and their suitability for the task of collocation extraction   and Krenn and Evert   for recent evaluations).,0,original
"Previously published approaches to reducing the rule set include: enforcing a minimum span of two words per non-terminal  , which would reduce our set to 115M rules; or a minimum count   threshold  , which would reduce our set to 78M   or 57M   rules.",0,original
"Additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential CRF; in contrast, approaches like Gibbs Sampling that model the dependencies directly can increase inference time by a factor of 30  .",0,original
Both left-corner strategy   and head-corner strategy   were employed in incremental parsing.,0,original
2.2 Word Alignment Aligning below the sentence level is usually done using statistical models for machine translation   where any word of the targetlanguageistakentobeapossibletranslation for each source language word.,0,original
"To analyze our methods on IV and OOV words, we use a detailed evaluation metric than Bakeoff 2006   which includes Foov and Fiv.",0,original
"Ordinary Prologstyle, backchaining deduction is augmented with the capability of making assumptions and of factoring two goal literals that are unifiable  .",0,original
3.2 Mapping Mapping the identified units   to their equivalents in the other language was achieved by training a new translation model   using the EM algorithm as described in  .,0,original
"We can find some other machine-learning approaches that use more sophisticated LMs, such as Decision Trees   , memory-based approaclms to learn special decision trees  , maximmn entropy approaches that combine statistical information from different sources  , finite state autonmt2 inferred using Grammatical Inference  , etc. The comparison among different al)t)roaches is dif ficult due to the nmltiple factors that can be eonsid614 ered: tile languagK, tile mmfl)er and tyt)e of the tags, the size of tilt vocabulary, thK ambiguity, the diiticulty of the test ski, Kte.",0,original
Theyalsoappliedself-training to domain adaptation of a constituency parser  .,0,original
"For each span in the chart, we get a weight factor that is multiplied with the parameter-based expectations.9 4 Experiments We applied GIZA++   to word-align parts of the Europarl corpus   for English and all other 10 languages.",0,original
"2.2 Closed Challenge Setting The organization provided training, development and test sets derived from the standard sections of the Penn TreeBank   and PropBank   corpora.",0,original
"Much research has been done to improve tagging accuracy using several different models and methods, including: hidden Markov models    ,  ; rule-based systems  ,  ; memory-based systems  ; maximum-entropy systems  ; path voting constraint systems  ; linear separator systems  ; and majority voting systems  .",0,original
"Besides being used in SMT, it is also used in translation lexicon building  , transfer rule learning  , example-based machine translation  , etc. In previous alignment methods, some researches modeled the alignments as hidden parameters in a statistical translation model   or directly modeled them given the sentence pairs  .",0,original
"In the field of eomputationa.1 linguistics, mutual information \  are suggested.",0,original
"Modulo more minor differences, these notions are close to the ideas of interpretation as abduction   and generation as abduction  , where we take abduction, in the former case for instance, to be a process returning a temporal-causal structure which can explain the utterance in context.",0,original
"In  , shallow syntactic analysis such as POS tagging and morphological analysis were incorporated in a phrasal decoder.",0,original
"Speaker ranking accuracy Table 2 summarizes the accuracy of our statistical ranker on the test data with different feature sets: the performance is 89.39% when using all feature sets, and reaches 90.2% after applying Gaussian smoothing and using incremental feature selection as described in   and implemented in the yasmetFS package.6 Note that restricting ourselves to only backward looking features decreases the performance significantly, as we can see in Table 2.",0,original
We use a standard maximum entropy classifier   implemented as part of MALLET  .,0,original
Model parameters are estimated using maximum entropy  .,0,original
The tagger from   first annotates sentences of raw text with a sequence of partof-speech tags.,0,original
A sinfilar approach has been chosen by  .,0,original
"Any encoding scheme, such as the packed representation of Talbot and Brants  , is viable here.",0,original
  have proposed an algorithm for doing word alignment which applies a discriminative step at every iteration of the traditional Expectation-Maximization algorithm used in IBM models.,0,original
The PT grammar 2 was extracted from the Penn Treebank  .,0,original
"For example, Liu and Gildea   developed the Sub-Tree Metric   over constituent parse trees and the Head-Word Chain Metric   over dependency parse trees.",0,original
The structure of the graphical model resembles IBM Model 1   in which each target   word is assigned one or more source   words.,0,original
"To make things worse, languages are non-isomorphic, i.e., there is no 1to-1 mapping between tree nodes, thus in practice one has to use more expressive formalisms such as synchronous tree-substitution grammars  .",0,original
The parameters of the NIST systems were tuned using Ochs algorithm to maximize BLEU on the MT02 test set  .,0,original
"Finally, recent work has explored learning to map sentences to lambda-calculus meaning representations  .",0,original
Automatic Creation of WIDL-expressions for MT. We generate WIDL-expressions from Chinese strings by exploiting a phrase-based translation table  .,0,original
hese weights or scaling factors can be optimized with respect to some evaluation criterion  ,0,original
"A related method is multi-category perceptron, which explicitly finds a weight vector that separates correct labels from the incorrect ones in a mistake driven fashion  .",0,original
The weights for the various components of the model   are set by minimum error rate training  .,0,original
"In addition to adapting the idea of Head Word Chains  , we also compared the input sentences argument structures against the treebank for certain syntactic categories.",0,original
"Thus, Nakagawa   and Hall   both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme.",0,original
2.1 BLEU is essentially a precision-based metric and is currently the standard metric for automatic evaluation of MT performance.,0,original
"Yarowsky   proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples.",0,original
oehn and Hoang   present Factored Translation Models as an extension to phrase-based statistical machine translation models,0,original
In this work we will use structured linear classifiers  .,0,original
his model is very similar to the markovized rule models in Collins  ,0,original
"They give a probabilistic formation of paraphrasing which naturally falls out of the fact that they use techniques from phrase-based statistical machine translation: e2 = argmax e2:e2negationslash=e1 p    where p  = summationdisplay f p p     summationdisplay f p p    Phrase translation probabilities p  and p  are commonly calculated using maximum likelihood estimation  : p  = count summationtext f count    where the counts are collected by enumerating all bilingual phrase pairs that are consistent with the 197 conseguido .opportunitiesequalcreatetofailedhasprojecteuropeanthe oportunidadesdeigualdadlahanoeuropeoproyectoel Figure 1: The interaction of the phrase extraction heuristic with unaligned English words means that the Spanish phrase la igualdad aligns with equal, create equal, and to create equal.",0,original
"In order to resolve all Chinese NLDs represented in the CTB, we modify and substantially extend the     algorithm as follows: Given the set of subcat frames s for the word w, and a set of paths p for the trace t, the algorithm traverses the f-structure f to: predict a dislocated argument t at a sub-fstructure h by comparing the local PRED:w to ws subcat frames s t can be inserted at h if h together with t is complete and coherent relative to subcat frame s traverse f starting from t along the path p link t to its antecedent a if ps ending GF a exists in a sub-f-structure within f; or leave t without an antecedent if an empty path for t exists In the modified algorithm, we condition the probability of NLD path p   on the GF associated of the trace t rather than the antecedent a as in C04.",0,original
he work most similar in spirit to ours that of Turney  ,0,original
ther background on this method of hypothesis testing the reader is referred to  .,0,original
"During training, the early update strategy of Collins and Roark   is used: when the correct state item falls out of the beam at any stage, parsing is stopped immediately, and the model is updated using the current best partial item.",0,original
We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy  .,0,original
"Johnson   reports results for different numbers of hidden states but it is unclear how to make this choice a priori, while Goldwater & Griffiths   leave this question as future work.",0,original
This is in contrast to standard summarization models that look to promote sentence diversity in order to cover as many important topics as possible  .,0,original
ustejovsky confronted with the problem of automatic acquisition more extensively in \ ,0,original
"One of the earliest attempts at extracting \interrupted collocations""""  , was that of Smadja  .",0,original
"In modern lexicalized parsers, POS tagging is often interleaved with parsing proper instead of being a separate preprocessing module  .",0,original
The corpus lines retained are part-of-speech tagged  .,0,original
4 Structural Correspondence Learning SCL     is a recently proposed domain adaptation technique which uses unlabeled data from both source and target domain to learn correspondences between features from different domains.,0,original
"As expected, Malt and MST have very similar accuracy for short sentences but Malt degrades more rapidly with increasing sentence length because of error propagation  .",0,original
"Recently, several solutions to the problem of tagging unknown words have been presented  .",0,original
  extends the dictionarybased approach to sequential labeling tasks by propagating the information given in the seeds with contextual word similarity.,0,original
"The first is a baseline of sorts, our own version of the """"chunking as tagging"""" approach introduced by Ramshaw and Marcus  .",0,original
"On the other hand, other authors  ) do use the expression phrase-based models.",0,original
"In particular, knowing a little about the structure of a language can help in developing annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations  .",0,original
We use the neural network approximation   to perform inference in our model.,0,original
"  binarize grammars into CNF normal form, while   allow only Griebach-Normal form grammars.",0,original
"We used these weights in a beam search decoder to produce translations for the test sentences, which we compared to the WMT07 gold standard using Bleu  .",0,original
"To estimate combination weights, we extend the F 1 -score maximization training algorithm for LRM described in  .",0,original
The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal  .,0,original
"First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity  .",0,original
"While Schiitze and Pedersen  , Brown et al   and Futrelle and Gauch   all demonstrate the ability of their systems to identify word similarity using clustering on the most frequently occurring words in their corpus, only Grefenstette   demonstrates his system by generating word similarities with respect to a set of target words.",0,original
Many of the current approaches of domain modeling collapse together different instances and make the decision on what information is important for a domain based on this generalized corpus  .,0,original
The last row shows the results for the feature augmentation algorithm  .,0,original
Both data were extracted from the Penn Treebank Wall Street Journal   Corpus  .,0,original
"Interestingly, similar conclusions were also reached in the area of Machine Translation evaluation; in their experiments, Zhang and Vogel   show that adding an additional reference translation compensates the effects of removing 1015% of the testing data, and state that, therefore, it seems more cost effective to have more test sentences but fewer reference translations.",0,original
"Polarity orientation identification has many useful applications, including opinion summarization   and sentiment retrieval  .",0,original
Previous research has addressed revision in single-document summaries   and has suggested that revising summaries can make them more informative and correct errors.,0,original
"As a baseline, we use an IBM Model 4   system3 with a greedy decoder4  .",0,original
"s To set weights on the components of the loglinear model, we implemented Ochs algorithm  .",0,original
"Therefore, including a model based on surface forms, as suggested  , is also necessary.",0,original
"Different approaches have been proposed for modeling Pr  in Equation  : Zero-order models such as model 1, model 2,andmodel 3   and the rstorder models such as model 4, model 5  , hidden Markov model  , and model 6  .",0,original
Our evaluation metric is BLEU   with caseinsensitive matching from unigram to four-gram.,0,original
A few exceptions are the hierarchical   transduction models   and the string transduction models  .,0,original
"Three K-means algorithms using different distributional similarity or dissimilarity measures: cosine, -skew divergence   4 , and Lins similarity  .",0,original
"3 Inversion Transduction Grammars While our approach applies in principle to a variety of machine translation systems  , we will use the inversion transduction grammar   approach of Wu   to facilitate comparison with previous work  aswellastofocuson language model complexity.",0,original
"4.2 Building a Human Performance Model We adopt the evaluation approach that a good content selection strategy should perform similarly to humans, which is the view taken by existing summarization evaluation schemes such as ROUGE   and the Pyramid method  .",0,original
  can be used to motivate a novel class-based language model and a regularized version of minimum discrimination information   models  .,0,original
"6 Conclusions and Future Directions In previous work, statistical NLP computation over large corpora has been a slow, of ine process, as in KNOWITALL   and also in PMI-IR applications such as sentiment classi cation  .",0,original
"Using the components of the row-vector bm as feature function values for the candidate translation em  , the system prior weights  can easily be trained using the Minimum Error Rate Training described in  .",0,original
"Using our WSD model to constrain the translation candidates given to the decoder hurts translation quality, as measured by the automated BLEU metric  .",0,original
"Strube and Ponzetto explored the use of Wikipedia for measuring Semantic Relatedness between two concepts  , and for Coreference Resolution  .",0,original
"Shen et al.,   report an accuracy of 97.33% on the same data set using a perceptron-based bidirectional tagging model.",0,original
"Then the words are tagged as inside a phrase  , outside a phrase   or beginning of a phrase    .",0,original
"For the evaluation of translation quality, we used the BLEU metric  , which measures the n-gram overlap between the translated output and one or more reference translations.",0,original
"The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score  , the X2, the log-likelihood   and Fishers exact test  .",0,original
"The bracketed portions of Figure 1, for example, show the base NPs in one sentence from the Penn Treebank Wall Street Journal   corpus  .",0,original
This is similar to  s and Charniak97s definition of a separate category for auxiliary verbs.,0,original
"Due to its popularity for unsupervised POS induction research   and its often-used tagset, for our initial research, we use the Wall Street Journal   portion of the Penn Treebank  , with 36 tags  , and we use sections 00-18, leaving held-out data for future experiments.4 Defining frequent frames as those occurring at 4Even if we wanted child-directed speech, the CHILDES database   uses coarse POS tags.",0,original
"More recently, other approaches have investigated the use of machine learning to nd patterns in documents  and the utility of parameterized modules so as to deal with dierent genres or corpora .",0,original
Each element of the resulting vector was replaced with its log-likelihood value   which can be considered as an estimate of how surprising or distinctive a co-occurrence pair is  .,0,original
"The model can be seen as a bootstrapping learning process tbr disambiguation, where the information gained from one part   is used to improve tile other   and vice versa, reminiscent of the work by Riloff and Jones   and Yarowsky  .",0,original
"The trends are the same as in  : Adding NANC data improves parsing performance on BROWN development considerably, improving the f-score from 83.9% to 86.4%.",0,original
1 Introduction Statistical machine translation   was originally focused on word to word translation and was based on the noisy channel approach  .,0,original
"Five chunk tag sets, IOB1, IOB2, IOE1, IOE2   and SE  , are commonly used.",0,original
"The row labelled Precision shows the precision of the extracted information   estimated by random sampling and manual evaluation of 1% of the data for each table, similar to  .",0,original
4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks  .,0,original
"We follow the approach by Turney  , who note that the semantic orientation of an adjective depends on the noun that it modifies and suggest using adjective-noun or adverb-verb pairs to extract semantic orientation.",0,original
Minimum error rate training was used to tune the model feature weights  .,0,original
"2.2.2 ENGLISH TRAINING DATA For training in the English experiments, we used WSJ  .",0,original
"A broad view of the possible scope of lexical semantics would thus be one which tries to chart out the systematic, generalizable aspects of word meanings, and of the relations between words, drawing on readily accessible sources of lexical knowledge, such as machine readable dictionaries, encyclopedias, and representative corpora, coupled with the kind of analytic apparatus that is needed to fruitfully explore such sources, for instance custom-built parsers to cope with dictionary definitions  , statistical programs to deal with the distributional properties of lexical items in large corpora   etc. At the same time this kind of massive data-acquisition should be made sensitive to the borders between perceptual experience, lexical knowledge and expert knowledge.",0,original
"This source is very important for repairs that do not have initial retracing, and is the mainstay of the """"parser-first"""" approach  --keep trying alternative corrections until one of them parses.",0,original
  show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only.,0,original
"5 The SemCor collection   is a subset of the Brown Corpus and consists of 352 news articles distributed into three sets in which the nouns, verbs, adverbs, and adjectives have been manually tagged with their corresponding WordNet senses and part-of-speech tags using Brills tagger  .",0,original
Experimental results were only reported for the METEOR metric  .,0,original
"Wu   used a binary bracketing ITG to segment a sen19 tence while simultaneously word-aligning it to its translation, but the model was trained heuristically with a fixed segmentation.",0,original
We then used Cohens Kappa to determine the level of agreement  .,0,original
"Decoding with an SCFG   can be cast as a parsing problem  , in which case we need to binarize a synchronous rule with more than two nonterminals to achieve polynomial time algorithms  .",0,original
"Research have also been made into alternatives to the current log-linear scoring model such as discriminative models with millions of features  , or kernel based models  .",0,original
3.1 Generation using PHARAOH PHARAOH   is an SMT system that uses phrases as basic translation units.,0,original
  and   utilized bootstrapping for word sense disambiguation.,0,original
"Work in this area includes that of Lin and Hovy   and Pastra and Saggion  , both of whom inspect the use of Bleu-like metrics   in summarization.",0,original
"The production rules in ITGs are of the following form  , with a notation similar to what is typically used for SDTSs and SCFGs in the right column: A    A  B1C2,B1C2 A  BC A  B1C2,C2B1 A  e | f A  e,f A  e |  A  e, A   | f A  ,f It is important to note that RHSs of production rules have at most one source-side and one targetside terminal symbol.",0,original
"In the future, we plan to explore our discriminative framework on a full distortion model   or even a hierarchical model  .",0,original
"6 Related Work The most relevant previous works include word sense translation and translation disambiguation  , frame semantic induction  , and bilingual semantic mapping  .",0,original
"To make feature ranking computationally tractable in Della Pietra et al. 1995 and Berger et al. 1996 a simplified process proposed: at the feature ranking stage when adding a new feature to the model all previously computed parameters are kept fixed and, thus, we have to fit only one new constraint imposed by a candidate feature.",0,original
"For our contrast submission, we rescore the first-pass translation lattices with a large zero-cutoff stupid-backoff   language model estimated over approximately five billion words of newswire text.",0,original
"Another way of doing the parameter estimation for this matching task would have been to use an averaged perceptron method, as in Collins  .",0,original
"A null Assuming that one SMS word is mapped exactly to one English word in the channel model under an alignment, we need to consider only two types of probabilities: the alignment probabilities denoted by Pm and the lexicon mapping probabilities denoted by  .",0,original
"To overcome these limitations, many syntaxbased SMT models have been proposed  .",0,original
"For example, Church and Hanks   describe the use of the mutual information index for this purpose (cf.",0,original
"3 Related work Word collocation Various collocation metrics have been proposed, including mean and variance  , the t-test  , the chi-square test, pointwise mutual information    , and binomial loglikelihood ratio test    .",0,original
"In this respect, it resembles bilingual bracketing  , but our model has more lexical items in the blocks with many-to-many word alignment freedom in both inner and outer parts.",0,original
This has been now an active research area for a couple of decades  .,0,original
"3 Incremental Parsing Method Based on Adjoining Operation In order to avoid the problem of infinite local ambiguity, the previous works have adopted the following approaches:   a beam search strategy  ,   limiting the allowable chains to those actually observed in the treebank  , and   transforming the parse trees with a selective left-corner transformation   before inducing the allowable chains and allowable triples  .",0,original
"The model presented above is based on our previous work  , which bears the same spirit of some other recent work on multitask learning  .",0,original
1 Introduction Conditional Maximum Entropy   modeling has received a great amount of attention within natural language processing community for the past decade  .,0,original
"For instance, automatic summary can be seen as a particular paraphrasing task   with the aim of selecting the shortest paraphrase.",0,original
Similar ideas were explored in  .,0,original
"In future work, we will expand all of the above types of features and employ techniques to reduce dimensionality along the lines suggested in   and  .",0,original
correspondence points associated with frequent token types   or by deleting frequent token types from the bitext altogether  .,0,original
"3 Data The data consists of six sections of the Wall Street Journal part of the Penn Treebank  , and follows the setting of past editions of the CoNLL shared task: training set  , development set   and test set  .",0,original
"Table 6 shows 3An exception is Golding  , who uses the entire Brown corpus for training   and 3/4 of the Wall Street Journal corpus   for testing.",0,original
hunks as a separate level have also been used in Collins   and Ratnaparkhi  ,0,original
  and compare with results reported by HK06   and CRR07  .,0,original
araphrases can also be automatically acquired using statistical methods as shown by Barzilay and Lee  ,0,original
These sentences were parsed with the Collins parser  .,0,original
"As in  , the parameter C8 D0 B4C4 CX B4D0D8 CX BND0DB CX B5CYC8BNC0BNDBBND8BNA1BNC4BVB5 is further smoothed as follows: C8 D0BD B4C4 CX CYC8BNC0BNDBBND8BNA1BNC4BVB5 A2 C8 D0BE B4D0D8 CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B5A2 C8 D0BF B4D0DB CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B4D0D8 CX B5B5 Note this smoothing is different from the syntactic counterpart.",0,original
"272 Similarity-based estimation was first used for language modeling in the cooccurrence smoothing method of Essen and Steinbiss  , derived from work on acoustic model smoothing by Sugawara et al.",0,original
"For example, Weeds     took verbs as contexts for nouns in object position: so they regarded two nouns to be similar to the extent that they occur as direct objects of the same set of verbs.",0,original
"In 2004, Conroy   tested Maximal Marginal Relevance   as well as QR decomposition.",0,original
to the pair-wise TER alignment described in  .,0,original
8See formula in appendix B. We use   implementation with a minor alteration  see Beigman Klebanov  .,0,original
4 Pattern switching The compositional translation presents problems which have been reported by  : Fertility SWTs and MWTs are not translated by a term of a same length.,0,original
"2.1 EM parameter estimation We train using Expectation Maximisation  , optimising the log probability of the training setfe ,f gSs=1  .",0,original
"Recent work on reordering has been on trying to find smart ways to decide word order, using syntactic features such as POS tags   , parse trees   to name just a few, and synchronized CFG  , again to name just a few.",0,original
"As an example of it s application, N-gram co-occurrence is used for evaluating machine translations  .",0,original
"See   for additional work using perceptron algorithms to train tagging models, and a more thorough description of the theory underlying the perceptron algorithm applied to ranking problems.",0,original
Results are reported using lowercase BLEU  .,0,original
Another motivation to evaluate the performance of a phrase translation model that contains only syntactic phrases comes from recent efforts to built syntactic translation models  .,0,original
"5.1 Agreement between translators In an attempt to quantify the agreement between the two groups of translators, we computed the Kappa coefficient for annotation tasks, as defined by Carletta  .",0,original
"We use the default configuration of the measure in WordNet::Similarity-0.12 package  , and, with a single exception, the measure performed below Gic; see BP in table 1.",0,original
"5.2 Pseudo-Disambiguation Task Pseudo-disambiguation tasks have become a standard evaluation technique   and, in the current setting, we may use a nouns neighbors to decide which of two co-occurrences is the most likely.",0,original
"In the training phase, bilingual parallel sentences are preprocessed and aligned using alignment algorithms or tools such as GIZA++  .",0,original
"More specifically, a statistical word alignment model   is used to acquire a bilingual lexicon consisting of NL substrings coupled with their translations in the target MRL.",0,original
"The class-based approaches   calculate co-occurrence data of words belonging to different classes,~ rather than individual words, to enhance the co-occurrence data collected and to cover words which have low occurrence frequencies.",0,original
"From the extracted n-grams, those with a flequc'ncy of 3 or more were kept  ).",0,original
"Based on this theoretical cornerstone, Cahill and van Genabith   presented a PCFG-based chart generator using wide-coverage LFG approximations automatically extracted from the Penn-II treebank.",0,original
his model is very similar to Smith and Eisner  ,0,original
"For MCE learning, we selected the reference compression that maximize the BLEU score    ) from the set of reference compressions and used it as correct data for training.",0,original
"Hindle uses the observed frequencies within a specific syntactic pattern   to derive a cooccu,> rence score which is an estimate of mutual information  .",0,original
  was proposed in the original work to solve the LMR Tagging problem.,0,original
"Inter-annotator agreement was measured using the kappa   statistics   on 1,502 instances   marked by two annotators who followed specific written guidelines.",0,original
"We base our work partly on previous work done by Bagga and Baldwin  , which has also been used in later work  .",0,original
"2.2 Using Log-Likelihood-Ratios to Estimate Word Translation Probabilities Our method for computing the probabilistic translation lexicon LLR-Lex is based on the the Log2http://www.fjoch.com/GIZA++.html Likelihood-Ratio   statistic  , which has also been used by Moore   and Melamed   as a measure of word association.",0,original
"Unlabeled dependencies can be readily obtained by processing constituent trees, such as those in the Penn Treebank  , with a set of rules to determine the lexical heads of constituents.",0,original
"Also, the aspect of generalizing features across different products is closely related to fully supervised domain adaptation  , and we plan to combine our approach with the idea from Daume III   to gain insights into whether the composite back-off features exhibit different behavior in domain-general versus domain-specific feature sub-spaces.",0,original
"3.2 Maximum Entropy ME models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible  .",0,original
"Recently, Wikipedia is emerging as a source for extracting semantic relationships  .",0,original
The parse trees on the English side of the bitexts were generated using a parser   implementing the Collins parsing models  .,0,original
We implemented this model within an ME modeling framework  .,0,original
"Given a set of evidences E over all the relevant word pairs, in  , the probabilistic taxonomy learning task is defined as the problem of finding the taxonomy hatwideT that maximizes the 67 probability of having the evidences E, i.e.: hatwideT = arg max T P  In  , this maximization problem is solved with a local search.",0,original
"The interpolation weights a65   are trained using discriminative training   using ROUGEa129 as the objective function, on the development set.",0,original
"Some of this work focuses on classifying the semantic orientation of individual words or phrases, using linguistic heuristics or a pre-selected set of seed words  .",0,original
"Therefore, the base forms have been introduced manually and the POS tags have been provided partly manually and partly automatically using a statistical maximum-entropy based POS tagger similar to the one described in  .",0,original
Phrase-pairs are then extracted from the word alignments  .,0,original
The notation will assume ChineseEnglish word alignment and ChineseEnglish MT. Here we adopt a notation similar to  .,0,original
4 Experiments Our experiments were conducted on CoNLL-2007 shared task domain adaptation track   using treebanks  .,0,original
"Clusters are created by means of distributional techniques in  , while in   low level synonim sets in WordNet are used.",0,original
"  showed how to use the Voted Perceptron algorithm for learning W, and we use it for learning the global transliteration model.",0,original
" , a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions  .",0,original
Both systems are built around from the maximum-entropy technique  .,0,original
"For instance, Pang and Lee   train an independent subjectivity classifier to identify and remove objective sentences from a review prior to polarity classification.",0,original
"To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank  , is annotated primarily with constituent analysis.",0,original
"Even though there are some studies that compare the results from statistically computed association measures with word association norms from psycholinguistic experiments   there has not been any research on the usage of a digital, network-based dictionary reflecting the organisation of the mental lexicon to our knowledge.",0,original
History-based models for predicting the next parser action   3.,0,original
"Building upon the large body of research to improve tagging performance for various languages using various models  ) and the recent work on PCFG grammars with latent annotations  , we will investigate the use of fine-grained latent annotations for Chinese POS tagging.",0,original
Similar techniques are used in   for socalled direct translation models instead of those proposed in  .,0,original
We annotated with the BIO tagging scheme used in syntactic chunkers  .,0,original
1 Introduction Maximum Entropy   modeling has received a lot of attention in language modeling and natural language processing for the past few years  .,0,original
"To date, researchers have harvested, with varying success, several resources, including concept lists  , topic signatures  , facts  , and word similarity lists  .",0,original
6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances  ; these methods do not address attributes directly.,0,original
"2.4 Formalization of   As mentioned earlier, our model is equivalent to that presented in  , and can be viewed as a formal version of his model.2 In his presentation, the adapation is done through feature augmentation.",0,original
"Wu   modeled the reordering process with binary branching trees, where each production could be either in the same or in reverse order going from source to target language.",0,original
"2 Latent Variable Parsing In latent variable parsing  , we learn rule probabilities on latent annotations that, when marginalized out, maximize the likelihood of the unannotated training trees.",0,original
"We use the finite-state parses of FaSTU$   for recognizing these entities, but the method extends to any basic phrasal parser 4.",0,original
Examples include Wus   ITG and Chiangs hierarchical models  .,0,original
"We examine Structural Correspondence Learning     for this task, and compare it to several variants of Self-training  .",0,original
"First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy  .8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score  .",0,original
"The mapping of answer terms to question terms is modeled using Black et al.s   simplest model, called IBM Model 1.",0,original
"For example, when applying their approach to a different domain with somewhat less rigid syntax, Zettlemoyer and Collins   need to introduce new combinators and new forms of candidate lexical entries.",0,original
"Since text planners cannot generate either the requisite syntactic variation or quantity of text,  , a corpus that includes texts from newspapers such as the Wall Street Journal, and which have been hand-annotated for syntax by linguists.",0,original
"These dependencies differ from those used by Liu and Gildea  , in that they are extracted according to the rules of the LFG grammar and they are labelled with a type of grammatical relation that connects the head and the modifier, such as subject, determiner, etc. The presence of grammatical relation labels adds another layer of important linguistic information into the comparison and allows us to account for partial matches, for example when a lexical item finds itself in a correct relation but with an incorrect partner.",0,original
arletta   and Ros6   point out the importance of taking into account the expected chance agreement among judges when computing whether or not judges agree significantly,0,original
"To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P , as in  , by using the same set of features as in ME. Table 3 shows precision, recall, and F1measure of each system for WordNet hypernyms  , WordNet meronyms   and ODP hypernyms  .",0,original
"The token precision is higher than 90% in all of the corpora, including the movie domain, which is considered to be difficult for SA  .",0,original
"They have been employed in word sense disambiguation  , automatic construction of bilingual dictionaries  , and inducing statistical machine translation models  .",0,original
"Examples of this work include a system by Liu et al  , and experiments by Hindle and Rooth  , and Resnik and Hearst  .2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems.",0,original
section 20 Majority voting         accuracy precision O:98.10% C:98.29% 93.63% O:98.1% C:98.2% 93.1% 97.58% 92.50% 97.37% 91.80% 91.6% recall FZ=I 92.89% 93.26 92.4% 92.8 92.25% 92.37 92.27% 92.03 91.6% 91.6 section 00 accuracy precision Majority voting 0:98.59% C:98.65% 95.04% r   98.04% 93.71%   97.8% 93.1% recall FB=I 94.75% 94.90 93.90% 93.81 93.5% 93.3 Table 3: The results of majority voting of different data representations applied to the two standard data sets put forward by   compared with earlier work.,0,original
"It has been shown repeatedly--e.g. , Briscoe and Carroll  , Charniak  , Collins  , Inui et al.",0,original
"In the results we describe here, we use mutual information   as the metric for neighbourhood pruning, pruning which occurs as the network is being generated.",0,original
"The literature on relational similarity, on the other hand, has focused on pairs of words, devising various methods to compare how similar the contexts in which target pairs appear are to the contexts of other pairs that instantiate a relation of interest  .",0,original
The loglinear model feature weights were learned using minimum error rate training     with BLEU score   as the objective function.,0,original
"For further information on these parameter settings, confer  .",0,original
We concatenate the lists and we learn a new combination of weights that maximizes the Bleu score of the combined nbest list using the same development corpus we used for tuning the individual systems  .,0,original
"This is based on the idea from   that rare words in the training set are similar to unknown words in the test set, and can be used to learn how to tag the unknown words that will be encountered during testing.",0,original
"We trained three Arabic-English syntax-based statistical MT systems   using max-B training  : one on a newswire development set, one on a weblog development set, and one on a combined development set containing documents from both genres.",0,original
"Pearsons correlation coefficient is a standard measure of the correlation strength between two distributions; it can be calculated as follows:  = E  E E radicalbigE    2   where X =   and Y =   are vectors of numerical scores for each paraphrase provided by the humans and the competing systems, respectively, n is the number of paraphrases to score, and E  is the expectation of X. Cosine correlation coefficient is another popular alternative and was used by Nakov and Hearst  ; it can be seen as an uncentered version of Pearsons correlation coefficient:  = X.YbardblXbardblbardblYbardbl   Spearmans rank correlation coefficient is suitable for comparing rankings of sets of items; it is a special case of Pearsons correlation, derived by considering rank indices   as item scores . It is defined as follows:  = n summationtextx iyi    radicalBig nsummationtextx2i   2 radicalBig nsummationtexty2i   2   One problem with using Spearmans rank coefficient for the current task is the assumption that swapping any two ranks has the same effect.",0,original
"For example, the word alignment computed by GIZA++ and used as a basis to extract the TTS templates in most SSMT systems has been observed to be a problem for SSMT  , due to the fact that the word-based alignment models are not aware of the syntactic structure of the sentences and could produce many syntax-violating word alignments.",0,original
"There has been considerable use in the NLP community of both WordNet   and LDOCE  , but no one has merged the two in order to combine their strengths.",0,original
"The usefulness of prosody was found to be very limited by itself, if the effect of utterance length is not considered  .",0,original
"Many studies and improvements have been conducted for  Presently with Service Media Laboratory, Corporate ResearchandDevelopmentCenter, OkiElectricIndustry Co. ,Ltd. POS tagging, and major methods of POS tagging achieve an accuracy of 9697% on the Penn Treebank WSJ corpus, but obtaining higher accuracies is difficult  .",0,original
"The learning algorithm used is the IB1 algorithm   with k = 5, i.e. classification based on 5 nearest neighbors.4 Distances are measured using the modified value difference metric     for instances with a frequency of at least 3  , and classification is based on distance weighted class voting with inverse distance weighting  .",0,original
"On a separate note, previous research has explicitly studied sentiment analysis as an application of transfer learning  .",0,original
"Model Overall Unknown Word Accuracy Accuracy Baseline, 96.72% 84.5% J Ratnaparkhi 96.63% 85.56%   Table 3 Baseline model performance This table also shows the results reported in Ratnaparkhi  for COnvenience.",0,original
Dredze et al. yielded the second highest score1 in the domain adaptation track  .,0,original
"Zens and Ney   explore the re-orderings allowed by ITGs, and provide a formulation for the number of structures that can be built for a sentence pair of size n. ITGs explore almost all of permutation space when n is small, but their coverage of permutation space falls off quickly for n > 5  .",0,original
e borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff  ,0,original
"5 Phrase Pair Induction A common approach to phrase-based translation is to extract an inventory of phrase pairs   from bitext  , For example, in the phraseextract algorithm  , a word alignment am1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : am1 : aj    .",0,original
It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values  .,0,original
The data for all our experiments was extracted from the Penn Treebank II Wall Street Journal   corpus  .,0,original
"We observe that the tagging method exploits the one sense per collocation property  , which means that WSD based on collocations is probably finer than WSD based on simple words, since ambiguity is reduced  .",0,original
Feature-based methods   use pre-defined feature sets to extract features to train classification models.,0,original
We also use minimum error-rate training   to tune our feature weights.,0,original
"In a factored translation model other factors than surface form can be used, such as lemma or part-of-speech  .",0,original
"Finally, the fourth and fifth feature functions corresponded to two lexicon models based on IBM Model 1 lexical parameters p   .",0,original
"Using a vector-based topic identification process  , these keywords are used to determine a set of likely values   for that attribute.",0,original
Several representations to encode region information are proposed and examined  .,0,original
"This method uses mutual information and loglikelihood, which Dunning   used to calculate the dependency value between words.",0,original
"Similar to Goldwater and Griffiths   and Johnson  , Toutanova and Johnson   also use Bayesian inference for POS tagging.",0,original
"  a. Please move your car Her sadness moves him b. John enjoys the book John enjoys reading the book e. The two alibis do not accord They accorded him a warm welcome d. John swam for hours John swam across the channel Although the precise nrechanisms which govern lexical knowledge are still largely unknown, there is strong evidence that word sense extensibi\[ity is not arbitrary  .",0,original
"A possible solution to his problem might be the use of more general morphological rules like those used in part-of-speech tagging models  ), where all suffixes up to a certain length are included.",0,original
"4 Relation to Previous Work There is a significant volume of work exploring the use of CRFs for a variety of chunking tasks, including named-entity recognition, gene prediction, shallow parsing and others  .",0,original
"We build phrase translations by first acquiring bidirectional GIZA++   alignments, and using Moses grow-diag alignment symmetrization heuristic.1 We set the maximum phrase length to a large value  , because some segmenters described later in this paper will result in shorter 1In our experiments, this heuristic consistently performed better than the default, grow-diag-final.",0,original
This has been shown both in supervised settings   and unsupervised settings   in which constraints are used to bootstrap the model.,0,original
"Pereira et al. , Curran and Moens   and Lin   use syntactic features in the vector definition.",0,original
"5.4 IBM-3 Word Alignment Models Since the true distribution over alignments is not known, we used the IBM-3 statistical translation model   to approximate . This model is specified through four components: Fertility probabilities for words; Fertility probabilities for NULL; Word Translation probabilities; and Distortion probabilities.",0,original
"The 45 stochastic word mapping is trained on a FrenchEnglish parallel corpus containing 700,000 sentence pairs, and, following Liu and Gildea  , we only keep the top 100 most similar words for each English word.",0,original
"Wu and Weld   and Cucerzan   calculate the overlap between contexts of named entities and candidate articles from Wikipedia, using overlap ratios or similarity scores in a vector space model, respectively.",0,original
"Computing the phrase translation probability is trivial in the training corpora, but lexical weighting   needs lexical-level alignment.",0,original
"They are not used in LN, but they are known to be useful for WSD  .",0,original
4.2 Experiments on SRL dataset We used two different corpora: PropBank along with Penn Treebank 2   and FrameNet.,0,original
"Some of these have been previously employed for various tasks by Gabrilovich and Markovitch,  ; Overell and Ruger  , Cucerzan  , and Suchanek et al.",0,original
"Most work on discriminative training for SMT has focussed on linear models, often with margin based algorithms  , or rescaling a product of sub-models  .",0,original
"7 Discussion As we mentioned, there are some algorithms similar to ours  .",0,original
Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation  .,0,original
"Named entities also pose another problem with the Haghighi and Klein   coreference model; since it models only the heads of NPs, it will fail to resolve some references to named entities:  , while erroneously merging others:  .",0,original
"The other is the self-training   which first parses and reranks the NANC corpus, and then use them as additional training data to retrain the model.",0,original
ntroduction The automated analysis of large corpora has many useful applications  ,0,original
C function is a derivative of Fano's mutual information formula recently used by Church and Hanks   to compute word co-occurrence patterns in a 44 million word corpus of Associated Press news stories,0,original
"At the same time, grammar theoreticians have proposed various generative synchronous grammar formalisms for MT, such as Synchronous Context Free Grammars     or Synchronous Tree Adjoining Grammars    .",0,original
"Alignment performance is measured by the Alignment Error Rate     AER  = 12|B B|/  where B is a set reference word links, and B are the word links generated automatically.",0,original
3.1.2 Kappa Kappa   is an evaluation measure which is increasingly used in NLP annotation work  .,0,original
illmann and Zhang   present a procedure to directly optimize the global scoring function used by a phrasebased decoder on the accuracy of the translations,0,original
"In the work of Smadja   on extracting collocations, preference was given to constructions whose constituents appear in a fixed order, a similar   version of our assumption here that asymmetric constructions are more idiomatic than symmetric ones.",0,original
"Similarly, Murdock and Croft   adopted a simple translation model from IBM model 1   and applied it to QA.",0,original
" ; we also introduce an approach related to the conditional log-linear models of Ratnaparkhi, Roukos, and Ward  , Papineni, Roukos, and Ward  , Johnson et al.",0,original
"Set Test Set ENGLISH-WSJ Sections Section 22 Section 23   2-21 ENGLISH-BROWN see 10% of 10% of the   ENGLISH-WSJ the data6 the data6 FRENCH7 Sentences Sentences Sentences   1-18,609 18,610-19,609 19,609-20,610 GERMAN Sentences Sentences Sentences   1-18,602 18,603-19,602 19,603-20,602 Table 1: Corpora and standard experimental setups.",0,original
"We are already using the extracted semantic forms in parsing new text with robust, wide-coverage PCFG-based LFG grammar approximations automatically acquired from the f-structure annotated Penn-II treebank  .",0,original
Work in   modeled the limited information available at phrase-boundaries.,0,original
"Statistical machine translation is based on the noisy channel model, where the translation hypothesis is searched over the space defined by a translation model and a target language  .",0,original
"Rapp   calls this trade-off specificity; equivalent observations were made by Church & Hanks   and Church et al  , who refer to the tendency for large windows to wash out, smear or defocus those associations exhibited at smaller scales.",0,original
"If human-aligned data is available, the EMD algorithm provides higher baseline alignments than GIZA++ that have led to better MT performance  .",0,original
"These distributions are modeled using a maximum entropy formulation  , using training data which consists of human judgments of question answer pairs.",0,original
"Since the lexical translations and dependency paths are typically not labeled in the English corpus, a given pair must be counted fractionally according to its posterior probability of satisfying these conditions, given models of contextual translation and English parsing.3 3Similarly, Jansche   imputes missing trees by using comparable corpora.",0,original
"Our work so far has focused on data in the Penn Treebank  , particularly the Brown corpus and some examples from the Wall Street Journal corpus.",0,original
he Penn Wall Street Journal treebank   was used as training and test data,0,original
"4 The Corpus We used two corpora for our analysis: hospital discharge summaries from 1991 to 1997 from the Columbia-Presbyterian Medical Center, and the January 1996 part of the Wall Street Journal corpus from the Penn TreeBank \ .",0,original
"accuracy Training data Turney   66% unsupervised Pang & Lee   87.15% supervised Aue & Gamon   91.4% supervised SO 73.95% unsupervised SM+SO to increase seed words, then SO 74.85% weakly supervised Table 7: Classification accuracy on the movie review domain Turney   achieves 66% accuracy on the movie review domain using the PMI-IR algorithm to gather association scores from the web.",0,original
"The largest corpus that Goldwater and Griffiths   studied contained 96,000 words, while Johnson   used all of the 1,173,766 words in the full Penn WSJ treebank.",0,original
"Translation rules can:  look like phrase pairs with syntax decoration: NPB  NNP  NNP  NNP ) BUFDFKEUBWAZ  carry extra contextual constraints: VP  x0:SBAR-C) DKx0    be non-constituent phrases: VP  SBAR-C  x0:S-C)) DKx0 VP  PRT ) x0:SBAR-C) DXGPx0  contain non-contiguous phrases, effectively phrases with holes: PP  NP-C  x0:NNP)) NN ))) GRx0 EVABG6 PP  NP-C  NN ) x0:PP)) GRx0 EVEVABABG6  be purely structural  : S x0 x1  re-order their children: NP-C  x0:NN) PP  x1:NP-C)) x1 DFx0 Decoding with this model produces a tree in the target language, bottom-up, by parsing the foreign string using a CYK parser and a binarized rule set  .",0,original
"PairClass is most similar to the algorithm of Turney  , but it differs in the following ways:  PairClass does not use a lexicon to find synonyms for the input word pairs.",0,original
"We design special inference algorithms, instead of general-purpose inference algorithms used in previous works  , by taking advantage of special properties of our task.",0,original
Other authors have applied this approach to language modeling  .,0,original
"Here, we train word alignments in both directions with GIZA++  .",0,original
"One important application of bitext maps is the construction of translation lexicons   and, as discussed, translation lexicons are an important information source for bitext mapping.",0,original
"Hindle   proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of """"similar"""" events that have been seen.",0,original
The definitions of part-of-speech   categories and syntactic labels follow those of the Treebank I style  .,0,original
"Such a lexicon can be used, e.g., to classify individual sentences or phrases as subjective or not, and as bearing positive or negative sentiments  .",0,original
WSD has received increasing attention in recent literature on computational linguistics  .,0,original
"On the British National Corpus  , using Lins   similarity method, we retrieve the following neighbors for the first and second sense, respectively: 1.",0,original
"In future work we plan to experiment with richer representations, e.g. including long-range n-grams  , class n-grams  , grammatical features  , etc'.",0,original
"Thus, we used the five taggers, MBL  , MXPOST  , fnTBL  , TnT, and IceTagger3, in the same manner as described in  , but with the following minor changes.",0,original
Treebanks have been used within the field of natural language processing as a source of training data for statistical part og speech taggers   and for statistical parsers  .,0,original
"6 Penn Discourse Treebank   The Penn Discourse TreeBank   annotates discourse relations over the Wall Street Journal corpus  , in terms of discourse connectives and their arguments.",0,original
Doing joint inference instead of taking a pipeline approach has also been shown useful for other problems  ).,0,original
We then piped the text through a maximum entropy sentence boundary detector   and performed text normalization using NSW tools  .,0,original
"Proceedings of the 22nd International Conference on Computational Linguistics  , pages 585592 Manchester, August 2008 Random Restarts in Minimum Error Rate Training for Statistical Machine Translation Robert C. Moore and Chris Quirk Microsoft Research Redmond, WA 98052, USA bobmoore@microsoft.com, chrisq@microsoft.com Abstract Ochs   minimum error rate training   procedure is the most commonly used method for training feature weights in statistical machine translation   models.",0,original
"Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF  , mutual information    , conditional probabilities  , chi-square test, and the loglikelihood ratio  .",0,original
"We have used three different algorithms: the nearest neighbour algorithm IB1IG, which is part of the Timbl software package  , the decision tree learner IGTREE, also from Timbl, and C5.0, a commercial version of the decision tree learner C4.5  .",0,original
"2.3 Perceptron Learning As learning algorithm, we use Perceptron tailored for structured scenarios, proposed by Collins  .",0,original
The last two counts   were performed on a 29-million word parsed corpus  ).,0,original
"First, it recognizes non-recursive Base Noun Phrase    .",0,original
" , Ponzetto and Strube   and the exploitation of advanced techniques that involve joint learning  ) and joint inference  ) for coreference resolution and a related extraction task.",0,original
"We presented some theoretical arguments for not limiting extraction to minimal rules, validated them on concrete examples, and presented experiments showing that contextually richer rules provide a 3.63 BLEU point increase over the minimal rules of  .",0,original
"The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in  ; phrase translation model probabilities; and 4-gram language model probabilities logp , using Kneser-Ney smoothing as implemented in the SRILM toolkit.",0,original
"In our approach, we take into account both the relative positions of the nearby context words as well as the mutual information   associated with the occurrence of a particular context word.",0,original
ang and Lee   frame the problem of detecting subjective sentences as finding the minimum cut in a graph representation of the sentences,0,original
"Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval  .",0,original
" , who retrain the Ratnaparkhi   tagger and reach accuracies of 93% using CTB-I.",0,original
Most of researchers focus on how to extract useful textual features   for determining the semantic orientation of the sentences using machine learning algorithm  .,0,original
We describe the experiment in greater detail 2The particular verbs selected were looked up in   and the class for each verb in the classification system defined in   was selected with some discussion with linguists.,0,original
"Studies on self-training have focused mainly on generative, constituent based parsing  .",0,original
"N-best results for phrasal alignment and ordering models in the decoder were optimized by lambda training via Maximum Bleu, along the lines described in  .",0,original
"One can imagine the same techniques coupled with more informative probability distributions, such as lexicalized PCFGs  , or even grammars not based upon literal rules, but probability distributions that describe how rules are built up from smaller components  .",0,original
In this paper we use the so-called Model 4 from  .,0,original
"\ ), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy \ .",0,original
erceptron Learning a discriminative structure prediction model with a perceptron update was first proposed by Collins  ,0,original
The model weights are trained using the improved iterative scaling algorithm  .,0,original
"Identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. Sentiment detection is the task of determining positive or negative sentiment of words  , phrases and sentences  , or documents  .",0,original
Word correspondence was further developed in IBM Model-1   for statistical machine translation.,0,original
The traditional estimation method for word 98 alignment models is the EM algorithm   which iteratively updates parameters to maximize the likelihood of the data.,0,original
"Following Collins  , we used the averaged parameters from the training algorithm in decoding heldout and test examples in our experiments.",0,original
The IBM translation models   describe word reordering via a distortion model defined over word positions within sentence pairs.,0,original
"With our best performing features, we get ROUGE-2   scores of 0.11 and 0.0925 on 2007 and 2006 5This threshold was derived experimentally with previous data.",0,original
"Model Bits / Character ASCII Huffman code each char Lempel-Ziv   Unigram   Trigram Human Performance 8 5 4.43 2.1   1.76   1.25   The cross entropy, H, of a code and a source is given by: H  = ~ ~ Pr  log 2 Pr  s h where Pr  is the joint probability of a symbol s following a history h given the source.",0,original
"what does student want to write your Figure 3: A derivation tree of lexicalized parse trees, such as the distinction of arguments/modifiers and unbounded dependencies  , are elegantly represented in derivation trees.",0,original
"The observation probabilities for a given state, representing a certain word class, are determined by the relative frequencies of words belonging to that class  ); the probabilities of other words are set to a small initial value.",0,original
"NER is typically viewed as a sequential prediction problem, the typical models include HMM  , CRF  , and sequential application of Perceptron or Winnow  .",0,original
We symmetrized bidirectional alignments using the growdiag-final heuristic  .,0,original
"We envision the use of a clever datastructure would reduce the complexity, but leave this to future work, as the experiments   show that 5Our definition implies that we only consider faithful spans to be contiguous  .",0,original
translation lexicon entries were scored according to the log likelihood ratio   (cf.,0,original
he problem is due to the assumption of normality in naive frequency based statistics according to Dunning  ,0,original
We compare our methods with both the averaged perceptron   and conditional random fields   using identical predicate sets.,0,original
This is an instance of the ITG alignment algorithm  .,0,original
"We report case-insensitive scores on version 0.6 of METEOR   with all modules enabled, version 1.04 of IBM-style BLEU  , and version 5 of TER  .",0,original
"The feature weights i in the log-linear model are determined using a minimum error rate training method, typically Powells method  .",0,original
"Other metrics assess the impact of alignments externally, e.g., different alignments are tested by comparing the corresponding MT outputs using automated evaluation metrics   or METEOR  ).",0,original
"These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules  , or using machine-learning methods  .",0,original
"If the alignments are not available, they can be automatically generated; e.g., using GIZA++  .",0,original
Other possibilities for the weighting include assigning constant one or the exponential of the final score etc. One of the advantages of the proposed phrase training algorithm is that it is a parameterized procedure that can be optimized jointly with the trans82 lation engine to minimize the final translation errors measured by automatic metrics such as BLEU  .,0,original
"It is known that PMI gives undue importance to low frequency events  , therefore the evaluation considers only pairs of genes that occur at least 5 times in the whole corpus.",0,original
"4 Data Collection We evaluated out method by running RASP over Brown Corpus and Wall Street Journal, as contained in the Penn Treebank  .",0,original
"This incremental process can be iterated to the point that the system 1 It is not just a matter of time, but also of required linguistic skills  ).",0,original
"In this paper, we modify the method in Albrecht and Hwa   to only prepare human reference translations for the training examples, and then evaluate the translations produced by the subject systems against the references using BLEU score  .",0,original
"We use three different kinds of metrics: DR-STM Semantic Tree Matching, a la Liu and Gildea  , but over DRS instead of over constituency trees.",0,original
"To simulate real world scenario, we use n-best lists from ISIs state-of-the-art statistical machine translation system, AlTemp  , and the 2002 NIST Chinese-English evaluation corpus as the test corpus.",0,original
2 IBM Model 4 Various statistical alignment models of the form Pr  have been introduced in  .,0,original
"While movie reviews have been the most studied domain, sentiment analysis has extended to a number of new domains, ranging from stock message boards to congressional floor debates  .",0,original
"The intuition is that the produced clusters will be less sense-conflating than those produced by other graph-based approaches, since collocations provide strong and consistent clues to the senses of a target word  .",0,original
"Machine learning methods should be interchangeable: Transformation-based learning     and Memory-based learning     have been applied to many different problems, so a single interchangeable component should be used to represent each method.",0,original
There are several works that try to learn paraphrase pairs from parallel or comparable corpora  .,0,original
"We measured the accuracy of the POS tagger trained in three settings: Original: The tagger is trained with the union of Wall Street Journal   section of Penn Treebank  , GENIA, and Penn BioIE.",0,original
"From a theoretical point of view, it is difficult to find motivation for the parameter estimation methods used by    see   for discussion.",0,original
4 Experimental Work A part of the Wall Street Journal   which had been processed in the Penn Treebanck Project   was used in the experiments.,0,original
"Among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation  .",0,original
"Such a similarity is calculated by using the WordNet::Similarity tool  , and, concretely, the Wu-Palmer measure, as defined in Equation1  .",0,original
"The resulting corpus contains 385 documents of American English selected from the Penn Treebank  , annotated in the framework of Rhetorical Structure Theory.",0,original
"Translation qualities are measured by uncased BLEU   with 4 reference translations, sysids: ahb, ahc, ahd, ahe.",0,original
Identification of Terms To-be Transliterated   must not be confused with recognition of Named Entities    .,0,original
The first two phases are approached as straightforward classification in a maximum entropy framework  .,0,original
3.2.1 Factored Treelet Translation Labels of nodes at the t-layer are not atomic but consist of more than 20 attributes representing various linguistic features.3 We can consider the attributes as individual factors  .,0,original
2 Hierarchical Clustering of Words Several algorithms have been proposed for automatically clustering words based on a large corpus  .,0,original
The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model   or edit distance alignments allowing shifts  .,0,original
"In this work, we use the GIZA++ implementation   of IBM Model 5  .",0,original
"Under certain precise conditions, as described in  , we can analyze Algorithm 1 as minimizing the entropy of the distribution over translations of U. However, this is true only when the functions Estimate, Score and Select have very prescribed definitions.",0,original
"Corpora in various languages, such as the English Penn Treebank corpus  , the Swedish Stockholm-Ume corpus  , and the Icelandic Frequency Dictionary   corpus  , have been used to train   and develop   different taggers, and to evaluate their accuracy, e.g.",0,original
"This system was worse than the baseline on Bleu  , but an error analysis showed some improvements.",0,original
1999) O:98.1% C:98.2% 92.4% 93.1% Ramshaw and Marcus   IOB1:97.37% 91.80% 92.27% Argamon et al,0,original
"Statistical techniques, both supervised learning from tagged corpora  ,  , and unsupervised learning  ,  , have been investigated.",0,original
"1 Introduction The Inversion Transduction Grammar or ITG formalism, which historically was developed in the context of translation and alignment, hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments  .",0,original
"Training Set  : There are many labeled English corpora available on the Web and we used the corpus constructed for multi-domain sentiment classification   9 , because the corpus was large-scale and it was within similar domains as the test set.",0,original
"This is important when LARGE CUT-OFF 0 5 100 NAIVE 541,721 184,493 35,617 SASH 10,599 8,796 6,231 INDEX 5,844 13,187 32,663 Table 4: Average number of comparisons per term considering that different tasks may require different weights and measures  .",0,original
EnglishChinese   and EnglishSpanish  .,0,original
"This implementation is exactly the one proposed in  , and we will denote it as MB-D hereafter.",0,original
The MSLR parser   performs syntactic analysis of the sentence.,0,original
" , this model is symmetric, because both word bags are generated together from a joint probability distribution.",0,original
Our baseline method for ambiguity resolution is the Collins parser as implemented by Bikel  .,0,original
"This increase of probabilities is defined as multiplicative change   as follows:   = P /P    The main innovation of the model in   is the possibility of adding at each step the best relation N = {Ri,j}as well as N = I  that is Ri,j with all the relations by the existing taxonomy.",0,original
" , and others identifying non-anaphoric definite descriptions  ] and unsupervised techniques  ).",0,original
"More recently, the integration of information sources, and the modeling of more complex language processing tasks in the statistical framework has increased the interest in smoothing methods  .",0,original
ine 4 and 5 are similar to the phrase extraction algorithm by Och  ,0,original
We used GIZA++ package   to train IBM translation models.,0,original
A constituent-based system using Collins parser  .,0,original
"  To reduce the inference time, following  , we collapsed the 45 different POS labels contained in the original data.",0,original
Then the alignments are symmetrized using a refined heuristic as described in  .,0,original
"On the other hand, Kazama and Torisawa   extracted hyponymy relations, which are independent of the NE categories, from Wikipedia and utilized it as a gazetteer.",0,original
"This method was preferred against other related methods, like the one introduced in  , since it embeds all the available semantic information existing in WordNet, even edges that cross POS, thus offering a richer semantic representation.",0,original
37 3 Semi-supervised Domain Adaptation 3.1 Structural Correspondence Learning Structural Correspondence Learning   exploits unlabeled data from both source and target domain to find correspondences among features from different domains.,0,original
Word alignments were generated using GIZA++   over a stemmed version of the parallel text.,0,original
"A similar approach is used here, including a collapsed version of the Treebank POS tag set  , with additions for specific words  , compound punctuation  , and a general emoticon tag, resulting in a total of 41 tags.",0,original
The thesaurus was produced using the metric described by Lin   with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus     using the RASP parser  .,0,original
Previous SMT systems   used a word-based translation model which assumes that a sentence can be translated into other languages by translating each word into one or more words in the target language.,0,original
"As an alternative to the often used sourcechannel approach  , we directly model the posterior probability Pr   .",0,original
"In general, they can be divided into two major categories, namely lexicalized models   and un-lexicalized models  .",0,original
We also compared the cluster gazetteers with the Wikipedia gazetteer constructed by following the method of  .,0,original
"3 Maximum Entropy Taggers The taggers are based on Maximum Entropy tagging methods  , and can all be trained on new annotated data, using either GIS or BFGS training code.",0,original
Both calculate the precision of a translation by comparing it to a reference translation and incorporating a length penalty  .],0,original
"Some of them use human reference translations, e.g., the BLEU method  , which is based on comparison of N-gram models in MT output and in a set of human reference translations.",0,original
"Daume III   divided features into three classes: domainindependent features, source-domain features and target-domain features.",0,original
  looked at Golomb Coding and Brants et al,0,original
This paper presents an empirical study measuring the effectiveness of our evaluation functions at selecting training sentences from the Wall Street Journal   corpus   for inducing grammars.,0,original
We discriminatively trained our parser in an on-line fashion using a variant of the voted perceptron  .,0,original
"7 Experiments To show the effectiveness of cross-language mention propagation information in improving mention detection system performance in Arabic, Chinese and Spanish, we use three SMT systems with very competitive performance in terms of BLEU11  .",0,original
"Our method revises and considerably extends the approach of   originally designed for English, and, to the best of our knowledge, is the first NLD recovery algorithm for Chinese.",0,original
3 Evaluation of Algorithms All four algorithms were run on a 3900 utterance subset of the Penn Treebank annotated corpus   provided by Charniak and Ge  .,0,original
3.1 System Tuning Minimum error training   under BLEU   was used to optimise the feature weights of the decoder with respect to the dev2006 development set.,0,original
"It is an implementation of Models 1-4 of Brown et al. \ , where each of these models produces a Viterbi alignment.",0,original
"As discussed in  , undirected graphical models do not seem to be suitable for history-based parsing models.",0,original
"For the efficiency of minimum-errorrate training  , we built our development set   using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data.",0,original
We train IBM Model 4 with GIZA++   in both translation directions.,0,original
"We used MXPOST  , and in order to discover more general patterns, we map the tag set down after tagging, e.g. NN, NNP, NNPS and NNS all map to NN.",0,original
arcu and Echihabi   demonstrated that word pairs extracted from the respective text spans are a good signal of the discourse relation between arguments,0,original
"In particular, we use the name/instance lists described by   and available on Fleischmans web page to generate features between names and nominals  .",0,original
arowsky   used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis,0,original
"The X 2 statistic is performing at least as well as G 2, and the results show that the average level of generalization is slightly higher for G 2 than X 2 . This suggests a possible explanation for the results presented here and those in Dunning  : that the X 2 statistic provides a less conservative test when counts in the contingency table are low.",0,original
" , and in some cases, to factor the translation problem so that the baseline MT system can take advantage of the reduction in sparsity by being able to work on word stems.",0,original
"In order to generate a value for each target-side factor, we use a sequence of mapping steps similar to Koehn and Hoang  .",0,original
"6 Training Similar to most state-of-the-art phrase-based SMT systems, we use the SRI toolkit   for language model training and Giza++ toolkit   for word alignment.",0,original
"Traditionally, generative word alignment models have been trained on massive parallel corpora  .",0,original
"In examining the combination of the two types of parsing, McDonald and Nivre   utilized similar approaches to our empirical analysis.",0,original
"Following Church & Hanks  , Rapp  , and Wettler et al.",0,original
"3.2 Translation performance For the experiments reported in this section, we used feature weights trained with minimum error rate training   . Because MERT ignores the denominator in Equation 1, it is invariant with respect to the scale of the weight vector   the Moses implementation simply normalises the weight vector it finds by its lscript1-norm.",0,original
There are two tasks  for the domain adaptation problem.,0,original
"In some recent grammar induction and MT work   it has been shown that even a small amount of knowledge about a language, in the form of grammar fragments, treelets or prototypes, can go a long way in helping with the induction of a grammar from raw text or with alignment of parallel corpora.",0,original
"We have found, however, that collocational evidence can be employed to suggest which noun compounds reflect taxonomic relationships, using a strategy similar to that employed by Hindle   for detecting synonyms.",0,original
"For instance, the Penn Treebank policy   is to annotate the lowest node that is unfinished with an -UNF tag as in Figure 4 .",0,original
"Maximum entropy   models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation  , parsing, POS tagging and PP attachment  , machine translation  , and FrameNet classification  .",0,original
"After that, several million instances of people, locations, and other facts were added  .",0,original
"toilet/bathroom Since the word """"facility"""" is the subject of """"employ"""" and is modified by """"new"""" in  , we retrieve other words that appeared in the same contexts and obtain the following two groups of selectors   of these words in the local contexts):  Subjects of """"employ"""" with top-20 highest likelihood ratios: word freq, Iog,k word freq ORG"""" 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 537 *ORG includes all proper names recognized as organizations 18  Modifiees of """"new"""" with top-20 highest likelihood ratios: word freq log,k post 432 952.9 issue 805 902.8 product 675 888.6 rule 459 875.8 law 356 541.5 technology 237 382.7 generation 150 323.2 model 207 319.3 job 260 269.2 system 318 251.8 word freq log )~ bonds 223 245.4 capital 178 241.8 order 228 236.5 version 158 223.7 position 236 207.3 high 152 201.2 contract 279 198.1 bill 208 194.9 venture 123 193.7 program 283 183.8 Since the similarity between Sense 1 of """"facility"""" and the selectors is greater than that of other senses, the word """"facility"""" in   is tagged """"Sense The key innovation of our algorithm is that a polysemous word is disambiguated with past usages of other words.",0,original
"According to this model, when translating a stringf in the source language into the target language, a string e is chosen out of all target language strings e if it has the maximal probability given f  : e = arg maxe {Pr } = arg maxe {Pr Pr } where Pr  is the translation model and Pr  is the target language model.",0,original
"Nevertheless, the generated rules are strictly required to be derived from the contiguous translational equivalences  .",0,original
"Huang and Chiang   searches with the full model, but makes assumptions about the the amount of reordering the language model can trigger in order to limit exploration.",0,original
"From   9 Combined metric BY BP B4AC BE B7BDB5C8CABPB4AC BE C8 B7 CAB5, from  , AC BPBD.",0,original
"We follow the method used by Kazama and Torisawa  , which encodes the matching with a gazetteer entity using IOB tags, with the modication for Japanese.",0,original
"These joint counts are estimated using the phrase induction algorithm described in  , with symmetrized word alignments generated using IBM model 2  .",0,original
"The word alignments were created with Giza++   applied to a parallel corpus containing the complete Europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.",0,original
Accuracy on sentiment classification in other domains exceeds 80%  .,0,original
"Slightly differently from  , we use possible alignments in computing recall.",0,original
"For English, we used the Penn Treebank   in our experiments and the tool Penn2Malt7 to convert the data into dependency structures using a standard set of head rules  .",0,original
4.1 Applications to phrase-based SMT Aphrase-basedtranslationmodelcanbeestimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted  .,0,original
1.2 Decoding in Statistical Machine Translation   and   have discussed the first two of the three problems in statistical machine translation.,0,original
We demonstrate that allowing different values for these hyperparameters significantly improves performance over both a strong baseline and   within both a conditional random field sequence model for named entity recognition and a discriminatively trained dependency parser.,0,original
"Occasionally, in 59 sentences out of 2416 on section 23 of the Wall Street Journal Penn Treebank  , the shift-reduce parser fails to attach a node to a head, producing a disconnected graph.",0,original
"On the other hand, purely statistical systems   extract discriminating MWUs from text corpora by means of association measure regularities.",0,original
"We implement this algorithm using the perceptron framework, as it can be easily modified for structured prediction while preserving convergence guarantees  .",0,original
"The most relevant to our work are Kazama and Torisawa  , Toral and Muoz  , and Cucerzan  .",0,original
"In NLP, vector space models have featured most prominently in information retrieval  , but have also been used for ontology learning   and word sense-related tasks  .",0,original
"5.2 A data recovery task In the second evaluation, the estimation method had to distinguish between members of two sets of 8It should be emphasized that the TWS method uses only a monolingual target corpus, and not a bilingual corpus as in other methods  ).",0,original
"1 Introduction In this paper, we present an approach for extracting the named entities   of natural language inputs which uses the maximum entropy   framework  .",0,original
We tune all feature weights automatically   to maximize the BLEU   score on the dev set.,0,original
"Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus  , GIZA++  , Moses  , and the SRI LM toolkit   to build 5-gram LMs.",0,original
The detailed algorithm can be found in  .,0,original
"Alternatively, one can view   as inducing an alignment between terms in the h to the terms in the t, somewhat similar to alignment models in statistical MT  .",0,original
"A richer set of features besides n-grams should be checked, and we should not ignore the potential effectiveness of unigrams in this task  .",0,original
"Hindle, D. ,   """"Noun Classification from Predicate-Argument Structures,"""" Proceedings of the 28th Annual Meeting of the ACL, pp.",0,original
"We use a simple, single parameter distribution, with  = 8.0 throughout P  = P   K Word-to-Phrase Alignment Alignment is a Markov process that specifies the lengths of phrases and their alignment with source words P  = Kproductdisplay k=1 P  = Kproductdisplay k=1 p d n  The actual word-to-phrase alignment   is a firstorder Markov process, as in HMM-based word-toword alignment  .",0,original
"It is possible that there is a better automated method for finding such phrases, such as the methods in  .",0,original
"Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus  , and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al.",0,original
"With the help of the kappa coefficient   proposes to represent the dialog success independently from the task intrinsic complexity, thus opening the way to task generic comparative evaluation.",0,original
"Unlike previous annotations of sentiment or subjectivity  , which typically relied on binary 0/1 annotations, we decided to use a finer-grained scale, hence allowing the annotators to select different degrees of emotional load.",0,original
"We used a bottom-up, CKY-style decoder that works with binary xRs rules obtained via a synchronous binarization procedure  .",0,original
"7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative  ).",0,original
"The query tions, the syntax, semantics, and abstract knowledge representation have type declarations   which help to detect malformed representations.",0,original
.1 Likelihood Ratios in the Type-based Stage The log-likelihood ratio by Dunning   tests whether the probability of a word is dependent on the occurrence of the preceding word type,0,original
"Not only many combinations are found in the corpus, many of them have very similar mutual information values to that of 318 Table 2: economic impact verb economic financial political social budgetary ecological economic economic economic economic economic economic economic economic economic object impact impact impact impact impact impact effect implication consequence significance fallout repercussion potential ramification risk mutual freq info 171 1.85 127 1.72 46 0.50 15 0.94 8 3.20 4 2.59 84 0.70 17 0.80 59 1.88 10 0.84 7 1.66 7 1.84 27 1.24 8 2.19 17 -0.33 nomial distribution can be accurately approximated by a normal distribution  .",0,original
hat some model structures work better than others at real NLP tasks was discussed by Johnson   and Klein and Manning  ,0,original
"Following the broad shift in the field from finite state transducers to grammar transducers  , recent approaches to phrase-based alignment have used synchronous grammar formalisms permitting polynomial time inference  .",0,original
State-of-the-art statistical parsers trained on the Penn Treebank     proS a8a8 a8a8a8 a72a72 a72a72a72 NP-SBJ a16a16a16 a80a80a80the authority VP a16a16a16 a16a16a16a16 a0 a0a0 a64 a64a64 a80a80a80 a80a80a80a80 VBD dropped PP-TMP a8a8 a72a72IN at NP NN midnight NP-TMP NNP Tuesday PP-DIR a8a8 a72a72TO to NP QP a16a16a16 a80a80a80$ 2.80 trillion Figure 1: A sample syntactic structure with function labels.,0,original
ollins   falls back to the POS tagging of Ratnaparkhi   for words seen fewer than 5 times in the training corpus,0,original
"We obtained 47,025 50-dimensional reduced vectors from the SVD and clustered them into 200 classes using the fast clustering algorithm Buckshot    .",0,original
"2 Background 2.1 Hybrid Logic Dependency Semantics Hybrid Logic Dependency Semantics   is an ontologically promiscuous   framework for representing the propositional content   of an expression as an ontologically richly sorted, relational structure.",0,original
"While   showed that this technique was effective when testing on WSJ, the true distribution was closer to WSJ so it made sense to emphasize it.",0,original
"Building heavily on the ideas of History-based parsing  , training the parser means essentially running the parsing algorithms in a learning mode on the data in order to gather training instances for the memory-based learner.",0,original
"We report case-insensitive scores for version 0.6 of METEOR   with all modules enabled, version 1.04 of IBM-style BLEU  , and version 5 of TER  .",0,original
"3 Monolingual comparable corpus: Similar to the methods in  , we construct a corpus of comparable documents from a large corpus D of news articles.",0,original
Many researchers  ;  ) have suggested that the informationtheoretic notion of mutual information score   directly captures the idea of context.,0,original
Following   we can avoid unnecessary false positives by not querying for the longer n-gram in such cases.,0,original
"For all non-LEAF systems, we take the best performing of the union, refined and intersection symmetrization heuristics   to combine the 1-to-N and M-to-1 directions resulting in a M-to-N alignment.",0,original
" , which is based on that of Och and Ney  .",0,original
"As a learning algorithm for our classification model, we used Maximum Entropy  .",0,original
The superiority of discriminative models has been shown on many tasks when the discriminative and generative models use exactly the same model structure  .,0,original
dependency lengths: Long-distance dependencies exhibit bad performance  .,0,original
"Introduction Since Eric Brill first introduced the method of Transformation-Based Learning   it has been used to learn rules for many natural language processing tasks, such as part-of-speech tagging \ .",0,original
"4 Features For our experiments we use the features proposed, motivated and described in detail by  .",0,original
"However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses  .",0,original
"Within the machine learning paradigm, IL has been incorporated as a technique for bootstrapping an extensional learning algorithm, as in  .",0,original
"In the literature on the kappa statistic, most authors address only category data; some can handle more general data, such as data in interval scales or ratio scales  .",0,original
"In  , target trees were employed to improve the scoring of translation theories.",0,original
"3 Probability Model This paper takes a """"history-based"""" approach   where each tree-building procedure uses a probability model p , derived from p , to weight any action a based on the available context, or history, b. First, we present a few simple categories of contextual predicates that capture any information in b that is useful for predicting a. Next, the predicates are used to extract a set of features from a corpus of manually parsed sentences.",0,original
"Each item is associated with a stack whose signa12Specifically a B-hypergraph, equivalent to an and-or graph   or context-free grammar  .",0,original
"5 Related Work There has not been much previous work on graphical models for full parsing, although recently several latent variable models for parsing have been proposed  .",0,original
"Using dictionaries as network of lexical items or senses has been quite popular for word sense disambiguation   before losing ground to statistical approaches, even though   tried a revival of such methods.",0,original
"Our approach is data-driven: following the methodology in  , we automatically convert the English PennII treebank and the Chinese Penn Treebank   into f-structure banks.",0,original
"Method dev test Finkel et al. , 2005   baseline CRF 85.51 + non-local features 86.86 Krishnan and Manning, 2006   baseline CRF 85.29 + non-local features 87.24 Table 5: Summary of performance with POS/chunk tags by TagChunk.",0,original
"What, therefore, has to be explored are various similarity metrics, defining similarity in a concrete way and evaluate the results against human annotations  .",0,original
"5.3 Performance of Taxonomy Induction In this section, we compare the following automatic taxonomy induction systems: HE, the system by Hearst   with 6 hypernym patterns; GI, the system by Girju et al.",0,original
The phrasebased machine translation   uses the grow-diag-final heuristic to extend the word alignment to phrase alignment by using the intersection result.,0,original
This second source of evidence is sometimes referred to as distributional similarity  .,0,original
"Using these patterns, we introduced verb form errors into AQUAINT, then re-parsed the corpus  , and compiled the changes in the disturbed trees into a catalog.",0,original
"3.1 Binarizable segmentations   Following  , every sequence of phrase alignments can be viewed 1For example, if the cut-off on phrase pairs is ten words, all sentence pairs smaller than ten words in the training data will be included as phrase pairs as well.",0,original
A large database of human judgments might also be useful as an objective function for minimum error rate training   or in other system development tasks.,0,original
"In fact, when the perceptron update rule of    which modifies the weights of every divergent node along the predicted and true paths  is used in the ranking framework, it becomes virtually identical with the standard, flat, ranking perceptron of Collins  .5 In contrast, our approach shares the idea of   that if a parent class has been predicted wrongly, then errors in the children should not be taken into account. We also view this as one of the key ideas of the incremental perceptron algorithm of  , which searches through a complex decision space step-by-step and is immediately updated at the first wrong move.",0,original
The IBM models   search a version of permutation space with a one-to-many constraint.,0,original
2.3 Probabilistic models for generation with HPSG Some existing studies on probabilistic models for HPSG parsing   adopted log-linear models  .,0,original
We use only the words that are content words   and not in the stopword list used in ROUGE  .,0,original
"We have already shown in Section 3 how to solve  ; here we avoid   by maximizing conditional likelihood, marginalizing out the hidden variable, denotedz: max vector summationdisplay x,y p log summationdisplay z pvector    This sort of conditional training with hidden variables was carried out by Koo and Collins  , for example, in reranking; it is related to the information bottleneck method   and contrastive estimation  .",0,original
Effectiveness Comparison 5.1 English-Chinese ATIS Models Both the transfer and transducer systems were trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus  ,0,original
6.4 Feature Selection Methods A number of previous papers   describe feature selection approaches for log-linear models applied to NLP problems.,0,original
"Prominent among these properties is the semi-free Language Size LR LP Source English 40,000 87.4% 88.1%   Chinese 3,484 69.0% 74.8%   Czech 19,000 80.0%   Table 1: Results for the Collins   model for various languages   wordorder, i.e., German wordorder is fixed in some respects, but variable in others.",0,original
arletta   argues that the kappa statistic   should be adopted to judge annotator consistency for classification tasks in the area of discourse and dialogue analysis,0,original
"The prime public domain examples of such implementations include the TrigramsnTags tagger  , Xerox tagger   and LT POS tagger  .",0,original
"Some other researchers also work on detecting negative cases, i.e. contradiction, instead of entailment  .",0,original
"Following Lin  , we use syntactic dependencies between words to model their semantic properties.",0,original
esearchers have mostly looked at representing words by their surrounding words   and by their syntactical contexts  ,0,original
It differs from the many approaches where   is defined by a stochastic synchronous grammar   and from transfer-based systems defined by context-free grammars  .,0,original
"Banko and Etzioni   studied open domain relation extraction, for which they manually identified several common relation patterns.",0,original
"The per-state models in this paper are log-linear models, building upon the models in   and  , though some models are in fact strictly simpler.",0,original
 ) and view the POS tags and word identities as two separate sources of information.,0,original
"Several models were introduced for these problems, for example, the Hidden Markov Model    , Maximum Entropy Model    , and Conditional Random Fields    .",0,original
"For example, in the WSJ corpus, part of the Penn Treebank 3 release  , the string in   is a variation 12-gram since off is a variation nucleus that is tagged preposition   in one corpus occurrence and particle   in another.1 Dickinson   shows that examining those cases with identical local contextin this case, lookingat ward off aresultsinanestimated error detection precision of 92.5%.",0,original
"Allomorphs   are also automatically identified in  , but the general problem of recognizing highly irregular forms is examined more extensively in  .",0,original
"a larger number of labeled documents, its performance on this corpus is comparable to that of Support Vector Machines and Maximum Entropy models  .",0,original
"Within NLP, applications include sentiment-analysis problems   and content selection for text generation  .",0,original
"Then, we build a classier learned by training data, using a maximum entropy model   and the features related to spelling variations in Table 3.",0,original
These records are also known as field books and reference sets in literature  .,0,original
" ; later elaborations and refinements have been implemented in a number of systems, notably CHAT-80  , TEAM  , and CLE  .",0,original
"More recently, Haghighi and Klein   use the distinction between pronouns, nominals and proper nouns 660 in their unsupervised, generative model for coreference resolution; for their model, this is absolutely critical for achieving better accuracy.",0,original
6.1 Evaluation of Translation Performance We use the BLEU score   to evaluate our systems.,0,original
"However, if we are willing to accept that occasionally our model will be unable to distinguish between distinct n-grams, then it is possible to store each parameter in constant space independent of both n and the vocabulary size  ,  .",0,original
"Word alignments are provided by GIZA++   with grow-diag-final combination, with infrastructure for alignment combination and phrase extraction provided by the shared task.",0,original
"The features used are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in  ; phrase translation model probabilities; and 4-gram language model probabilities logp , using Kneser-Ney smoothing as implemented in the SRILM toolkit  .",0,original
Much previous work on unsupervised grammar induction has used gold-standard partof-speech tags  .,0,original
"4.2 Data The data comes from the CoNLL 2000 shared task  , which consists of sentences from the Penn Treebank Wall Street Journal corpus  .",0,original
"Some authors have already designed similar matching techniques, such as the ones described in   and  .",0,original
.4 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in Yarowsky  ,0,original
  and   claim that fine-grained semantic distinctions are unlikely to be of practical value for many applications.,0,original
We took part the Multilingual Track of all ten languages provided by the CoNLL-2007 shared task organizers .,0,original
"Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques  , finding strength of opinions  , summing up orientations of opinion words in a sentence  , and identifying opinion holders  .",0,original
"For handling word identities, one could follow the approach used for handling the POS tags   and view the POS tags and word identities as two separate sources of information.",0,original
"Its still possible to use MSA if, for example, the input is pre-clustered to have the same constituent ordering  ).",0,original
One is the longest common subsequence   based approach  .,0,original
he outcomes of CW resemble those of MinCut  : Dense regions in the graph are grouped into one cluster while sparsely connected regions are separated,0,original
"13Huang and Chiang   give an informal example, but do not elaborate on it.",0,original
"298 within LFG includes the XLE,3 Cahill and van Genabith  , Hogan et al.",0,original
Experimental results are reported in Table 2: here cased BLEU results are reported on MT03 Arabic-English test set  .,0,original
"Second, it can be applied to control the quality of parallel bilingual sentences mined from the Web, which are critical sources for a wide range of applications, such as statistical machine translation   and cross-lingual information retrieval  .",0,original
"ISBNs, originally proposed for constituent parsing in  , use vectors of binary latent variables to encode information about the parse history.",0,original
"In order to determine interannotator agreement for step 2 of the coding procedure for the database of annotated texts, we calculated kappa statistics  .",0,original
Our results are similar to those for conventional phrase-based models  .,0,original
Automatically Learning Entailment Rules from the Web Many algorithms for automatically learning paraphrases and entailment rules have been explored in recent years  .,0,original
Automatically creating or extending taxonomies for specific domains is then a very interesting area of research  .,0,original
ollocation map that is first suggested in   is a sigmoid belief network with words as probabilistic variables,0,original
"The second type has clear interpretation as a probability model, but no criteria to determine the number of clusters  .",0,original
Our approach differs from the corpus-based surface generation approaches of   and  .,0,original
"For English, self-training contributes 0.83% absolute improvement to the PCFG-LA parser, which is comparable to the improvement obtained from using semi-supervised training with the twostage parser in  .",0,original
These constraints tie words in such a way that the space of alignments cannot be enumerated as in IBM models 1 and 2  .,0,original
"Much of the work in sentiment analysis in the computational linguistics domain has focused either on short segments, such as sentences  , or on longer documents with an explicit polarity orientation like movie or product reviews  .",0,original
"This is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted Carletta   to recommend chance-corrected measures.",0,original
"Instead of using Inversion Transduction Grammar     directly, we will discuss an ITG extension to accommodate gapping.",0,original
"In  , lexical 72 features were limited on each single side due to the feature space problem.",0,original
"A remedy is to aggressively limit the feature space, e.g. to syntactic labels or a small fraction of the bi-lingual features available, as in  , but that reduces the benefit of lexical features.",0,original
3.2.2 Features We used eight features   and their weights for the translations.,0,original
"We use a bootstrap approach in which we first extract 1-to-n word alignments using an existing word aligner, and then estimate the confidence of those alignments to decide whether or not the n words have to be grouped; if so, this group is conwould thus be completely driven by the bilingual alignment process   for related considerations).",0,original
More details on these standard criteria can be found for instance in  .,0,original
"POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model   in English research communities  .",0,original
"Furthermore, use of the self-training techniques described in   raise this to 87.8%   again without any use of labeled Brown data.",0,original
The data was segmented into baseNP parts and nonbaseNP parts in a similar fashion as the data used by  .,0,original
"As two examples,   and   give good overviews of the techniques and equations used for Markov models and part-ofspeech tagging, but they are not very explicit in the details that are needed for their application.",0,original
"Examples of such contexts are verb-object relations and noun-modifier relations, which were traditionally used in word similarity tasks from non-parallel corpora  .",0,original
  and section 23 for testing  ; we only tested on sentences _< 40 words  .,0,original
"Table 4 shows the linguistic features of the resulting model compared to the models of Carroll and Rooth  , Collins  , and Charniak  .",0,original
"Second, the automatic approach, in which the model is automatically obtained from corpora   1, and consists of n-grams  , rules   or neural nets  .",0,original
"4.3 Corpora The evaluations of the different models were carried out on the Penn Wall Street Journal corpus   for English, and the Tiger treebank   for German.",0,original
"Penn Treebank   the HPSG LinGo Redwoods Treebank  , and a smaller dependency treebank  .",0,original
The discriminative training regimen is otherwise similar to  .,0,original
"In our search procedure, we use a mixture-based alignment model that slightly differs from the model introduced as Model 2 in  .",0,original
"By contrast, in the training method proposed by  , the discriminative function f  is estimated to maximize the F 1 -score of training dataset D. This training method employs an approximate form of the F 1 -score obtained by using a logistic function.",0,original
"First, we considered single sentences as documents, and tokens as sentences   but also a cognate-based one similar to  .",0,original
  present a probabilistic model for pronoun resolution trained on a small subset of the Penn Treebank Wall Street Journal corpus  .,0,original
"The distinction between lexical and relational similarity for word pair comparison is recognised byTurney  , though the methods he presents focus on relational similarity.",0,original
"summarization  , paraphrasing  , natural language generation  , and language modeling  .",0,original
"One aspect of VPCs that makes them dicult to extract  ) is that the verb and particle can be non-contiguous, e.g. hand the paper in and battle right on.",0,original
"We use a hand-written competence grammar, combined with performance-driven disambiguation obtained from the Penn Treebank  .",0,original
We say that wv and nq are semantically related if w~i and nq are semantically related and   and   are semantically similar  .,0,original
"For automatic evaluation, we employed BLEU   by following  .",0,original
LW was originally used to validate the quality of a phrase translation pair in MT  .,0,original
"3.1 A Note on State-Splits Recent studies   suggest that category-splits help in enhancing the performance of treebank grammars, and a previous study on MH   outlines specific POS-tags splits that improve MH parsing accuracy.",0,original
arowsky   presented an approach that significantly reduces the amount of labeled data needed for word sense disambiguation,0,original
"3Huang and Chiang   describes the cube growing algorithm in further detail, including the precise form of the successor function for derivations.",0,original
"Agreement is sometimes measured as percentage of the cases on which the annotators agree, but more often expected agreement is taken into account in using the kappa statistic  , which is given by:  = po  pe1  p e   where po is the observed proportion of agreement and pe is the proportion of agreement expected by chance.",0,original
"Our method is based on the ones described in  , The objective of this paper is to dynamically rank speakers or participants in a discussion.",0,original
This direction has been forming the mainstream of research on opinion-sensitive text processing  .,0,original
"We have also implemented a Bloom Filter LM in Joshua, following Talbot and Osborne  .",0,original
e propose a method similar to Yarowsky   to generalize beyond the training set,0,original
"edu Abstract This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus  .",0,original
"As previously observed in the literature  , such components include a clause in the clause conjunction, relative clauses, and some elements within a clause  .",0,original
e also experimented with a method suggested by Brent   which applies the binomial test on frame frequency data,0,original
In Section 3 we then describe the probabilistic taxonomy learning model introduced by  .,0,original
"However, the pb features yields no noticeable improvement unlike in prefect lexical choice scenario; this is similar to the findings in  .",0,original
"It has been used for a variety of tasks, such as wide-coverage parsing  , sentence realization  , learning semantic parsers  , dialog systems  , grammar engineering  , and modeling syntactic priming  .",0,original
"Detailed description of those models can be found in  ,   and  .",0,original
"More recent papers Hindle  , Pereira and Tishby   proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts.",0,original
"Thus, our generative model is a quasi-synchronous grammar, exactly as in  .3 When training on target sentences w, therefore, we tune the model parameters to maximize notsummationtextt p  as in ordinary EM, but rather 3Our task here is new; they used it for alignment.",0,original
The score combination weights are trained by a minimum error rate training procedure similar to  .,0,original
This helps solve the sparse data problem since the number of classes is usually much smaller than the number of words.,0,original
"The training samples are respectively used to create the models PT^G, PCHUNK, PBUILD, and PCMECK, all of which have the form: k p  = II _ij  j----1 where a is some action, b is some context, ~"""" is a nor4 Model Categories Description Templates Used TAG See   CHUNK chunkandpostag * BUILD CHECK chunkandpostag * cons  cons * cons  T punctuation checkcons * checkcons * production surround * The word, POS tag, and chunk tag of nth leaf.",0,original
"In experiments with the system of   we have found that in practice a large number of complete translations are completely monotonic  , suggesting that the system has difficulty learning exactly what points in the translation should allow reordering.",0,original
"In our approach, equation   is further normalized so that the probability for different lengths of F is comparable at the word level: m m j n i ijm eft l EFP /1 10 )| 1 |  The alignment models described in   are all based on the notion that an alignment aligns each source word to exactly one target word.",0,original
"Independently, in AI an effort arose to encode large amounts of commonsense knowledge  .",0,original
"For instance, both Pang and Lee   and Turney   consider the thumbs up/thumbs down decision: is a film review positive or negative?",0,original
"Because of this, it is generally accepted that some kind of postprocessing should be performed to improve the final result, by shortening, fusing, or otherwise revising the material  .",0,original
Giving the increasing sophistication of probabilistic linguistic models   has a statistical approach to learning gap-threading rules) a probabilistic extension of our work is attractive--it will be interesting to see how far an integration of 'logical' and statistical can go.,0,original
"We split the treebank into training  , development   and test   as in  .",0,original
5 Comparison with related work Preliminary work on SF extraction from coq~ora was done by   and  .,0,original
This resembles the re-ranking approach  .,0,original
"Hierarchical rules were extracted from a subset which has about 35M/41M words5, and the rest of the training data were used to extract phrasal rules as in  .",0,original
One possible strategy is to exploit a widecoverage realizer that aims for applicability in multiple application domains  .,0,original
"As we remarked earlier, however, the input data required by our method   could be generated automatically from unparsed corpora making use of existing heuristic rules  , although for the experiments we report here we used a parsed corpus.",0,original
One of the theoretical problems with phrase based SMT models is that they can not effectively model the discontiguous translations and numerous attempts have been made on this issue  .,0,original
"During the SRC stage, a Maximum entropy   classifier is used to predict the probabilities of a word in the sentence Language No-duplicated-roles Catalan arg0-agt, arg0-cau, arg1-pat, arg2-atr, arg2-loc Chinese A0, A1, A2, A3, A4, A5, Czech ACT, ADDR, CRIT, LOC, PAT, DIR3, COND English A0, A1, A2, A3, A4, A5, German A0, A1, A2, A3, A4, A5, Japanese DE, GA, TMP, WO Spanish arg0-agt, arg0-cau, arg1-pat, arg1-tem, arg2-atr, arg2-loc, arg2-null, arg4-des, argL-null, argMcau, argM-ext, argM-fin Table 1: No-duplicated-roles for different languages to be each semantic role.",0,original
"  Hindi is a verb final, flexible word order language and therefore, has frequent occurrences of non-projectivity in its dependency structures.",0,original
"Thus, the WSJ+NANC model has better oracle rates than the WSJ model   for both the WSJ and BROWN domains.",0,original
"The release has implementations for BLEU  , WER and PER error criteria and it has decoding interfaces for Phramer and Pharaoh.",0,original
All our experiments used the standard BIO encoding   with different feature sets and learning procedures.,0,original
We use GIZA++   to train generative directed alignment models: HMM and IBM Model4   from training record-text pairs.,0,original
n particular we work with dependency paths that can reach beyond direct dependencies as opposed to Lin   but in the line of Pado and Lapata  ,0,original
The novel algorithm differs computationally from earlier work in discriminative training algorithms for SMT   as follows: a90 No computationally expensive a57 -best lists are generated during training: for each input sentence a single block sequence is generated on each iteration over the training data.,0,original
"  Here, the candidate generator gen  enumerates candidates of destination   strings, and the scorer P  denotes the conditional probability of the string t for the given s. The scorer was modeled by a noisy-channel model   and maximum entropy framework  .",0,original
"To counteract this, we introduce two brevity penalty measures   inspired by BLEU   which we incorporate into the loss function, using a product, loss = 1PrecBP: BP1 = exp )   BP2 = exp ) where r is the reference length and c is the candidate length.",0,original
Correlation Coefficient with Human Judgement   Human-Likeness Classifier Accuracy   Figure 1: This scatter plot compares classifiers accuracy with their corresponding metrics correlations with human assessments been previously observed by Liu and Gildea  ,0,original
"3.2 Probability structure of the original model We use p to denote the unlexicalized nonterminal corresponding to P, and similarly for li, ri and h. We now present the top-level generation probabilities, along with examples from 4The inclusion of the word feature in the BBN model was due to the work described in  , where word features helped reduce part of speech ambiguity for unknown words.",0,original
"The approach presented here has some resemblance to the bracketing transduction grammars   of  , which have been applied to a phrase-based machine translation system in  .",0,original
"The first is to align the words using a standard word alignement technique, such as the Refined Method described in     and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences.",0,original
6 Experiments We evaluated the translation quality of the system using the BLEU metric  .,0,original
"In this paper, we implement the SDB model in a state-of-the-art phrase-based system which adapts a binary bracketing transduction grammar     to phrase translation and reordering, described in  .",0,original
"While early head-lexicalized grammars restricted the fragments to the locality of headwords  , later models showed the importance of including context from higher nodes in the tree  .",0,original
he preci781 start Palestinian suicide bomberblew himself up in SLOT1 on SLOT2 killing SLOT3 other people and injuring wounding SLOT4 end detroit the *e* a s *e* building buildingin detroit flattened ground levelled to blasted leveled *e* was reduced razed leveled to down rubble into ashes *e* to *e*     Figure 1: Examples of paraphrase patterns extracted by Barzilay and Lee   and Pang et al,0,original
"These were: BLEU  , NIST  , WER  , PER  , GTM  , and METEOR  .",0,original
"3.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy   model.",0,original
"For a sequential learning algorithm, we make use of the Collins Perceptron Learner  .",0,original
"Since Czech is a language with relatively high degree of word-order freedom, and its sentences contain certain syntactic phenomena, such as discontinuous constituents  , which cannot be straightforwardly handled using the annotation scheme of Penn Treebank  , based on phrase-structure trees, we decided to adopt for the PCEDT the dependency-based annotation scheme of the Prague Dependency Treebank  PDT  .",0,original
"The translation models they presented in various papers between 1988 and 1993   are commonly referred to as IBM models 15, based on the numbering in Brown, Della Pietra, Della Pietra, and Mercer  .",0,original
" , is to translate dependency parses into neo-Davidsonian-style quasilogical forms, and to perform weighted abductive theorem proving in the tradition of  .",0,original
"To further emphasize the importance of morphology in MT to Czech, we compare the standard BLEU   of a baseline phrasebased translation with BLEU which disregards word forms  .",0,original
"Thus, an orthogonal line of research can involve inducing classes for words which are more general than single categories, i.e., something akin to ambiguity classes  .",0,original
The classifier uses mutual information   scores rather than the raw frequences of the occurring patterns  .,0,original
"Using an Maximum Entropy approach to POS tagging, Ratnaparkhi   reports a tagging accuracy of 96.6% on the Wall Street Journal.",0,original
"10Both Pharoah and our system have weights trained using MERT   on sentences of length 30 words or less, to ensure that training and test conditions are matched.",0,original
"We perform word alignment using GIZA++  , symmetrize the alignments using the grow-diag-final-and heuristic, and extract phrases up to length 3.",0,original
"However, in the experiments described here, we focus on alignment at the level of sentences, this for a number of reasons: First, sentence alignments have so far proven their usefulness in a number of applications, e.g. bilingual lexicography  , automatic translation verification   and the automatic acquisition of knowledge about translation  .",0,original
"This is related to the wellstudied problem of identifying paraphrases   and the more general variant of recognizing textual entailment, which explores whether information expressed in a hypothesis can be inferred from a given premise.",0,original
METEOR uses the Porter stemmer and synonymmatching via WordNet to calculate recall and precision more accurately  .,0,original
"Distributional measures of distance, such as those proposed by Lin  , quantify how similar the two sets of contexts of a target word pair are.",0,original
"decades like n-gram back-off word models  , class models  , structured language models   or maximum entropy language models  .",0,original
"This method is very similar to some ideas in domain adaptation  , but we argue that the underlying problems are quite different.",0,original
"In the following section, we follow the notation in  .",0,original
The component features are weighted to minimize a translation error criterion on a development set  .,0,original
"4.1 Data We used Penn-Treebank   data, presented in Table 1.",0,original
"Many 649 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include Lee  , Curran   and Weeds and Weir  .",0,original
"As the third test set we selected all tokens of the Brown corpus part of the Penn Treebank  , a selected portion of the original one-million word Brown corpus  , a collection of samples of American English in many different genres, from sources printed in 1961; we refer to this test set as BROWN.",0,original
"To find the optimal coefficients  for a loglinear combination of these experts, we use separate development data, using the following procedure due to Och  : 1.",0,original
This simplified version does not take word classes into account as described in  .,0,original
A synchronous 363 binarization method is proposed in   whose basic idea is to build a left-heavy binary synchronous tree   with a left-to-right shift-reduce algorithm.,0,original
Our human word alignments do not distinguish between Sure and Probable links  .,0,original
"3 Language modelling with Bloom filters Recentwork presenteda scheme for associating static frequency information with a set of n-grams in a BF efficiently.1 3.1 Log-frequency Bloom filter The efficiency of the scheme for storing n-gram statistics within a BF presented in Talbot and Osborne   relies on the Zipf-like distribution of n-gramfrequencies: mosteventsoccuranextremely small number of times, while a small number are very frequent.",0,original
"Models of that form include hidden Markov models   as well as discriminative tagging models based on maximum entropy classification  , conditional random fields  , and large-margin techniques  .",0,original
"We still use complex structures to represent the partial analyses, so as to employ both top-down and bottom-up information as in  .",0,original
"Proceedings of EACL '99 Determinants of Adjective-Noun Plausibility Maria Lapata and Scott McDonald and Frank Keller School of Cognitive Science Division of Informatics, University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW, UK {mlap, scottm, keller} @cogsci.ed.ac.uk Abstract This paper explores the determinants of adjective-noun plausibility by using correlation analysis to compare judgements elicited from human subjects with five corpus-based variables: co-occurrence frequency of the adjective-noun pair, noun frequency, conditional probability of the noun given the adjective, the log-likelihood ratio, and Resnik's   selectional association measure.",0,original
hey are a subset of the features used in Ratnaparkhi  ,0,original
Most current statistical models   treat the aligned sentences in the corpus as sequences of tokens that are meant to be words; the goal of the alignment process is to find links between source and target words.,0,original
"Finally, inducing lexical semantics from distributional data  ) is also a form of surface cueing.",0,original
"However, as also pointed out by Yarowsky  , this observation does not hold uniformly over all possible co-occurrences of two words.",0,original
This metric tests the hypothesis that the probability of phrase  is the same whether phrase  has been seen or not by calculating the likelihood of the observed data under a binomial distribution using probabilities derived using each hypothesis  .,0,original
"It is dubious whether SWD is useful regarding recall-oriented metrics like METEOR  , since SWD removes information in source sentences.",0,original
"Fortunately, Wu   provides a method to have an ITG respect a known partial structure.",0,original
"For example, the sentence I went to California last May would be marked for base NPs as: I went to California last May I 0 0 I B I indicating that the NPs are I, California and last May. This approach has been studied in  .",0,original
"3 Schone & Jurafsky's results indicate similar results for log-likelihood & T-score, and strong parallelism among information-theoretic measures such as ChiSquared, Selectional Association  , Symmetric Conditional Probability   and the Z-Score  .",0,original
The principle of our approach is more similar to  .,0,original
"Sentence Compression takes an important place for Natural Language Processing   tasks where specific constraints must be satisfied, such as length in summarization  , style in text simplification   or sentence simplification for subtitling  .",0,original
And we consider that word pairs that have a small distance between vectors also have similar word neighboring characteristics    .,0,original
"In contrast, approaches to WSD attempt to take advantage of many different sources of information  ); it seems possible to obtain benefit from sources ranging from local collocational clues   to membership in semantically or topically related word classes   to consistency of word usages within a discourse  ; and disambignation seems highly lexically sensitive, in effect requiring specialized disamhignators for each polysemous word.",0,original
The Duluth Word Alignment System is a Perl implementation of IBM Model 2  .,0,original
"In the following experiments, the NIST BLEU score is used as the evaluation metric  , which is reported as a percentage in the following sections.",0,original
"4 Global Transliteration Modeling In global transliteration modeling, we directly model the agreement function between f and e. We follow   and consider the global feature representation : F * E *  R d . 613 Each global feature corresponds to a condition on the pair of strings.",0,original
"Inside/Outside This representation was first introduced in  , and has been applied for base NP chunking.",0,original
"2 Summary of approaches Given a source language sentence f, statistical machine translation defines the translation task as selecting the most likely target translation e under a model P , i.e.: e  = argmax e P  = argmax e msummationdisplay i=1 hi i where the argmax operation denotes a search through a structured space of translation ouputs in the target language, hi  are bilingual features of e and f and monolingual features of e, and weights i are trained discriminitively to maximize translation quality   on held out data  .",0,original
"Fortunately, there is a straightforward parallel between our object recognition formulation and the statistical machine translation problem of building a lexicon from an aligned bitext  .",0,original
"2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based  , statistics-based   and learning-based  .",0,original
"We guess it is an acronym for the authors of  : Michel Galley, Mark Hopkins, Kevin Knight and Daniel Marcu.",0,original
"As with many domain adaptation problems, it is quite helpful to have some annotated target data, especially when annotation styles vary  .",0,original
"We used Pharoah   as a baseline system for comparison; the s-phrases used in our system include all phrases, with the same scores, as those used by Pharoah, allowing a direct comparison.",0,original
"Indeed, only few earlier works reported inter-judge agreement level, and those that did reported rather low Kappa values, such as 0.54   and 0.55 0.63  .",0,original
"Statistical approaches, which depend on a set of unknown parameters that are learned from training data, try to describe the relationship between a bilingual sentence pair  .",0,original
"We first added sister-head dependencies for NPs   original proposal) and then for PPs, which are flat in Negra, and thus similar in structure to NPs  .",0,original
In our experiments these were obtained automatically using MXPOST   and BBNs Identifinder  .,0,original
"Probabilistic generative models like IBM 1-5  , HMM  , ITG  , and LEAF   define formulas for P  or P , with ok-voon ororok sprok at-voon bichat dat erok sprok izok hihok ghirok totat dat arrat vat hilat ok-drubel ok-voon anok plok sprok at-drubel at-voon pippat rrat dat ok-voon anok drok brok jok at-voon krat pippat sat lat wiwok farok izok stok totat jjat quat cat lalok sprok izok jok stok wat dat krat quat cat lalok farok ororok lalok sprok izok enemok wat jjat bichat wat dat vat eneat lalok brok anok plok nok iat lat pippat rrat nnat wiwok nok izok kantok ok-yurp totat nnat quat oloat at-yurp lalok mok nok yorok ghirok clok wat nnat gat mat bat hilat lalok nok crrrok hihok yorok zanzanok wat nnat arrat mat zanzanat lalok rarok nok izok hihok mok wat nnat forat arrat vat gat Figure 1: Word alignment exercise  .",0,original
"Statistical Model In SIFT's statistical model, augmented parse trees are generated according to a process similar to that described in Collins  .",0,original
"So far, these techniques have focused on phrasebased models using contiguous phrases  .",0,original
The class based disambiguation operator is the Mutual Conditioned Plausibility    .,0,original
4.5.2 BLEU on NIST MT Test Sets We use MT02 as the development set4 for minimum error rate training    .,0,original
"corpus  , the Penn Treebank  , the SUSANNE corpus  , the Spoken English Corpus  , the Oxford Psycholinguistic Database  , and the """"Computer-Usable"""" version of the Oxford Advanced Learner's Dictionary of Current English  .",0,original
"However, following the work of Yarowsky  , Yarowsky  , many supervised WSD systems use minimal information about syntactic structures, for the most part restricting the notion of context to topical and local features.",0,original
"As a sanity check, we duplicated Pang et al.s   baseline in which all unigrams that appear four or more times in the training documents are used as features.",0,original
Results for chunking Penn Treebank data were previously presented by several authors  .,0,original
"1 Full Morphological Tagging English Part of Speech   tagging has been widely described in the recent past, starting with the   paper, followed by numerous others using various methods: neural networks  , HMM tagging  , decision trees  , transformation-based error-driven learning  , and maximum entropy  , to select just a few.",0,original
Our methods are most influenced by IBMs Model 1  .,0,original
"They train from the Penn Treebank  ; a collection of 40,000 sentences that are labeled with corrected parse trees  .",0,original
"This segmentation task can be achieved by assigning words in a sentence to one of three tokens: B for Begin-NP, I for Inside-NP, or O for OutsideNP  .",0,original
The maximum entropy classier   used is Le Zhang's Maximum Entropy Modeling Toolkit and the L-BFGS parameter estimation algorithm with gaussian prior smoothing  .,0,original
he fact that information consisting of nothing more than bigrams can capture syntactic information about English has already been noted by  ,0,original
We evaluate the system generated summaries using the automatic evaluation toolkit ROUGE  .,0,original
"4For justification for this kind of logical form for sentences with quantifiers and inteusional operators, see Hobbs  and Hobbs  .",0,original
"Various machine learning strategies have been proposed to address this problem, including semi-supervised learning  , domain adaptation  , multi-task learning  , self-taught learning  , etc. A commonality among these methods is that they all require the training data and test data to be in the same feature space.",0,original
It extracts all consistent phrase pairs from word-aligned bitext  .,0,original
4.1 Translation Modeling We can test our models utility for translation by transforming its parameters into a phrase table for the phrasal decoder Pharaoh  .,0,original
"With hand-labeled data, {m} can be learnt via generalized iterative scaling algorithm     or improved iterative scaling    .",0,original
"It was first cast as a classification problem by Ramshaw and Marcus  , as a problem of NP chunking.",0,original
"Similar to  , each word in the hypothesis is assigned with a rank-based score of 1/ r+ , where r is the rank of the hypothesis.",0,original
"Wordalignment, however, isalmost exclusively done using statistics  .",0,original
"Estimated clues are derived from the parallel data using, for example, measures of co-occurrence  ), statistical alignment models  ), or string similarity measures  ).",0,original
", 1989), e.g, lexicography  , information retrieval  , text input  , etc. This paper will touch on its feasibility in topic identification.",0,original
"Since there is no practical way of determining the classification a0 which maximizes this quantity for a given corpus,   use a greedy algorithm which proceeds from the initial classification, performing the merge which results in the least loss in mutual information at each stage.",0,original
"c2009 Association for Computational Linguistics Structural Correspondence Learning for Parse Disambiguation Barbara Plank Alfa-informatica University of Groningen, The Netherlands b.plank@rug.nl Abstract The paper presents an application of Structural Correspondence Learning     for domain adaptation of a stochastic attribute-value grammar  .",0,original
"During evaluation two performance metrics, BLEU   and NIST, were computed.",0,original
"Apart from this, the module is a straightforward implementation of  , which in turn adapts   for syntactic chunking.",0,original
"Previous work has shown that high-quality unlexicalized PCFGs can be learned from a treebank, either by manual annotation   or automatic state splitting  .",0,original
"Whereas until recently the focus of research had been on sense disambiguation, papers like Pantel & Lin  , Neill  , and Rapp   give evidence that sense induction now also attracts attention.",0,original
"The scores were then weighted by the inverse of their height in the tree and then summed together, similarly to the procedure in  .",0,original
"The sentences in the training and testing sets were already   POS-tagged and noun chunked, and that in a real-life situation additional preprocessing by a POS-tagger   and noun chunker  ) which will introduce additional errors.",0,original
"There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number  , or contextual role-knowledge  .",0,original
The hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder  .,0,original
Pang et al. proposed a method of classifying movie reviews into positive and negative ones  .,0,original
The feature weights are tuned using minimum error rate training   to optimize BLEU score on a held-out development set.,0,original
"eBonsai first performs syntactic analysis of a sentence using a parser based on GLR algorithm    , and provides candidates of its syntactic structure.",0,original
"NP chunks in the shared task data are BaseNPs, which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus  .",0,original
"Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals  , or, given a constraining parse tree, to flatten it  .",0,original
"One sees this clear trend in the supervised NLP literature examples include the Perceptron algorithm for tagging  , MIRA for dependency parsing  , exponentiated gradient algorithms  , stochastic gradient for constituency parsing  , just to name a few.",0,original
"First, we show how one can use an existing statistical translation model   in order to automatically derive a statistical TMEM.",0,original
"Similarly,   tested his WSD algorithm on a dozen words.",0,original
These categories were automatically generated using the labeled parses in Penn Treebank   and the labeled semantic roles of PropBank  .,0,original
"Recent work has explored two-stage decoding, which explicitly decouples decoding into a source parsing stage and a target language model integration stage  .",0,original
2 Decoding The decoding problem in SMT is one of finding the most probable translation e in the target language of a given source language sentence f in accordance with the Fundamental Equation of SMT  : e = argmaxe Pr Pr .,0,original
ur approach thus provides an even more extreme version of automatic con rmation generation than that used byChu-Carroll and Carpenter   where only a small eort is required by the developer,0,original
"2 The alignment Algorithm 2.1 Estimation of translation probabilities The translation probabilities are estimated using a method based on Brown et al.'s Model 2  , which is summarized in the following subsection, 2.1.1.",0,original
"This could, for example, aid machine-translation evaluation, where it has become common to evaluate systems by comparing their output against a bank of several reference translations for the same sentences  .",0,original
"Although the parser is not yet complete, we expect that its breath of coverage of the language will be substantially larger than that of other Government-binding parsers recently reported in the literature  , Kuhns  , Sharp  , and Wehrli  ).",0,original
"We ran GIZA++   on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in   to obtain a many-to-many word alignment for each sentence pair.",0,original
"To use the data from NANC, we use self-training  .",0,original
"3.3 Language Model We estimate P  using n-gram LMs trained on data from the Web, using Stupid Backoff  .",0,original
"According to our experience, the best performance is achieved when the union of the source-to-target and target-to-source alignment sets   is used for tuple extraction  .",0,original
"To make sense tagging more precise, it is advisable to place constraint on the translation counterpart c of w. SWAT considers only those translations c that has been linked with w based the Competitive Linking Algorithm   and logarithmic likelihood ratio  .",0,original
mith and Eisner   used a quasisynchronous grammar to discover the correspondence between words implied by the correspondence between the trees,0,original
"While the research in statistical machine translation   has made significant progress, most SMT systems   relyonparallel corpora toextract translation entries.",0,original
"For a full discussion of previous work, please see  , or see   for work relating to synonym resolution.",0,original
"To perform minimum error rate training   to tune the feature weights to maximize the systems BLEU score on development set, we used the script optimizeV5IBMBLEU.m  .",0,original
"For example, consider a case of observation bias   for a first-order left-toright CMM.",0,original
4.3 Adaptation for unknown word2 The unknown word problem is an important issue for domain adaptation .,0,original
"We computed precision, recall and error rate on the entire set of sentence pairs for each data set.5 To evaluate NeurAlign, we used GIZA++ in both directions   or Spanish  ) as input and a refined alignment approach   that uses a heuristic combination method called grow-diagfinal   for comparison.",0,original
"Table 1 shows theresultsalongwithB andthethreemetricsthat achieved higher correlations than B: semantic role overlap  , ParaEval recall  , and METEOR  .",0,original
  The heuristics in Section 6 are designed specifically to find the interesting features in that featureless desert.,0,original
"It assumes that the distance of the positions relative to the diagonal of the   plane is the dominating factor: r  p  =  , Ei,=l r  As described in  , the EM algorithm can be used to estimate the parameters of the model.",0,original
"For Penn Treebank II style annotation  , in which a nonterminal symbol is a category together with zero or more functional tags, we adopt the following scheme: the atomic pattern a matches any label with category a or functional tag a; moreover, we define Boolean operators^,_, and:.",0,original
"We do not use particular lexicosyntactic patterns, as previous attempts have  .",0,original
"The syntactic parser is the version that is selftrained using 2,500,000 sentences from NANC, and where the starting version is trained only on WSJ data  .",0,original
"2.1 Scale-dependence It has been shown that varying the size of the context considered for a word can impact upon the performance of applications  , there being no ideal window size for all applications.",0,original
The tags sets we shall examine are the set used in the Penn Tree Bank     and the C5 tag-set used by the CLAWS part-of-speech tagger  .,0,original
"The result in Wu   implies that for the special case of Bracketing ITGs, the time complexity of the algorithm is parenleftbigT3V 3parenrightbig where T and V are the lengths of the two sentences.",0,original
"These forest rescoring algorithms have potential applications to other computationally intensive tasks involving combinations of different models, for example, head-lexicalized parsing  ; joint parsing and semantic role labeling  ; or tagging and parsing with nonlocal features.",0,original
"Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms  , information retrieval  , determining semantic orientation  , grading student essays  , measuring textual cohesion  , and word sense disambiguation  .",0,original
1As do constraint relaxation   and forest reranking  .,0,original
"For instance, for Maximum Entropy, I picked   for the basic theory,   for an application  , and   for more advanced topics such as optimization and smoothing.",0,original
The weights are trained using minimum error rate training   with BLEU score as the objective function.,0,original
"In this method, each training sentence is decoded and weights are updated at every iteration  .",0,original
is a WordNet based relatedness measure  .,0,original
"2.2 The Crossing Constraint According to  , crossing constraint can be defined in the following.",0,original
The proposed synchronous grammar is able to cover the previous proposed grammar based on tree   and tree sequence   alignment.,0,original
"The first of these nonstructural problems with Model 1, as standardly trained, is that rare words in the source language tend to act as garbage collectors  , aligning to too many words in the target language.",0,original
"3.4 Feature Representation Ranking Models Following previous work on sentiment classi cation  , we represent each review as a vector of lexical features.",0,original
"Usually in 1 In our experiments, we set negative PMI values to 0, because Church and Hanks  , in their seminal paper on word association ratio, show that negative PMI values are not expected to be accurate unless co-occurrence counts are made from an extremely large corpus.",0,original
"Wu   investigated the use of concurrent parsing of parallel corpora in a transduction inversion framework, helping to resolve attachment ambiguities in one language by the coupled parsing state in the second language.",0,original
"As a measure of association, we use the loglikelihood-ratio statistic recommended by Dunning  , which is the same statistic used by Melamed to initialize his models.",0,original
"These range from twoword to multi-word, with or without syntactic structure  .",0,original
Some of the early statistical terminology translation methods are  .,0,original
"is the previous BIO tag, S is the target sentence, and fj and lj are feature functions and parameters of a log-linear model  .",0,original
5 SMT Experiments 5.1 Experimental Setup We used publicly available resources for all our tests: for decoding we used Moses   and our parallel data was taken from the Spanish-English section of Europarl.,0,original
"6.3 Comparison with re-ranking approach Finally, we compared our algorithm with the reranking approach  , where we rst generate the n-best candidates using a model with only local features   and then re-rank the candidates using a model with non-local features  .",0,original
"  invented heuristic symmetriza57 FRENCH/ENGLISH ARABIC/ENGLISH SYSTEM F-MEASURE   BLEU F-MEASURE   BLEU GIZA++ 73.5 30.63 75.8 51.55   74.1 31.40 79.1 52.89 LEAF UNSUPERVISED 74.5 72.3 LEAF SEMI-SUPERVISED 76.3 31.86 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in  .",0,original
The recurrence property had been utilized to extract keywords or key-phrases from text  .,0,original
We utilize a maximum entropy   model   to design the basic classifier used in active learning for WSD.,0,original
ollins and Roark   present an incremental perceptron algorithm for parsing that uses early update to update the parameters when an error is encountered,0,original
Results in terms of word-error-rate   and BLEU score   are reported in Table 4 for those sentences that contain at least one unknown word.,0,original
"As was demonstrated in  , even a minimal set of local explicit features achieves results which are non-significantly different from a carefully chosen set of explicit features, given the language independent definition of locality described in section 2.",0,original
"For instance, the HALOGEN statistical realizer  , converting them into its input formalism, and then producing output strings.",0,original
"We will do this by examining how humans perform on summary extraction and evaluating the reliability of their performance, using the kappa statistic, a metric standardly used in the behavioral sciences  .",0,original
ohnson   and Gao & Johnson   assume that words are generated by a hidden Markov model and find that the resulting states strongly correlate with POS tags,0,original
"The reordered sentence is then re-tokenized to be consistent with the baseline system, which uses a different tokenization scheme that is more friendly to the MT system.3 We use BLEU scores as the performance measure in our evaluation  .",0,original
Thenthewordalignment is refined by performing grow-diag-final method  .,0,original
"Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package  .1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/a0 tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce.",0,original
"For example, both Haghighi and Klein   and Mann and McCallum   have demonstrated results better than 66.1% on the apartments task described above using only a list of 33 highly discriminative features and the labels they indicate.",0,original
"Feature comparison measures: to convert two feature sets into a scalar value, several measures have been proposed, such as cosine, Lins measure  , Kullback-Leibler   divergence and its variants.",0,original
"In fact, we found that it doesnt do so badly at all: the bitag HMM estimated by EM achieves a mean 1-to1 tagging accuracy of 40%, which is approximately the same as the 41.3% reported by   for their sophisticated MRF model.",0,original
" ), a binarizable segmentation/permutation can be recognized by a binarized Synchronous Context-Free Grammar  , i.e., an SCFG in which the right hand sides of all non-lexical rules constitute binarizable permutations.",0,original
"Following   and other work on general-purpose generators, we adopt BLEU score  , average simple string accuracy   and percentage of exactly matched sentences for accuracy evaluation.6 For coverage evaluation, we measure the percentage of input fstructures that generate a sentence.",0,original
"scored with lowercased, tokenized NIST BLEU, and exact match METEOR  .",0,original
"Recently, methods from nonparametric Bayesian statistics have been gaining popularity as a way to approach unsupervised learning for a variety of tasks, including language modeling, word and morpheme segmentation, parsing, and machine translation  .",0,original
The weights of feature functions are optimized to maximize the scoring measure  .,0,original
"We use the same alignment data for the five language pairs Chinese/English, Romanian/English, Hindi/English, Spanish/English, and French/English  .",0,original
"Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files  , we have counted the occurrences of content words which previously appear in the same discourse file.",0,original
Similarity-based smoothing   is an intuitively appealing approach to this problem where probabilities of unseen co-occurrences are estimated from probabilities of seen co-occurrences of distributionally similar events.,0,original
"1 Introduction Since their appearance, BLEU   and NIST   have been the standard tools used for evaluating the quality of machine translation.",0,original
madja  finds significant bigrams using an estimate of z-score  ,0,original
"Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation   systems to form a consensus output  .",0,original
"Stage 2 processing is then free to assign to the compound any bracketing for which it 3The design of this level of Lucy is influenced by Hobbs  , which advocates a level of """"surfaey"""" logical form with predicates close to actual English words and a structure similar to the syntactic structure of the sentence.",0,original
"They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers   have used their class scheme and data set.",0,original
"4.2 Further practical issues of SCL In practice, there are more free parameters and model choices   besides the ones discussed above.",0,original
"Thus, GCNF is a more restrictive normal form than those used by Wu   and Melamed  .",0,original
"He uses a specic reliability statistic, , for his measurements, but Carletta   implicitly assumes kappa-like metrics are similar enough in practice for the rule of thumb to apply to them as well.A detailed discussion on the differences and similarities of these, and other, measures is provided by Krippendorff  ; in this article we will use Cohens    to investigate the value of the 0.8 reliability cut-off for computational linguistics.",0,original
"In fact, we still have a question as to whether SS-CRF-MER is really scalable in practical time for such a large amount of unlabeled data as used in our experiments, which is about 680 times larger than that of  .",0,original
  also worked on one of our data sets.,0,original
Pattern-based IE approaches employ seed data to learn useful patterns to pinpoint required fields values  .,0,original
"A generative parsing model can be used on its own, and it was shown in Collins and Roark   that a discriminative parsing model can be used on its own.",0,original
Then the two models and a search module are used to decode the best translation  .,0,original
e follow Collins   and Sha and Pereira   in using section 21 as a heldout set,0,original
e set our space usage to match the 3.08 bytes per n-gram reported in Talbot and Brants   and held out just over 1M unseen n-grams to test the error rates of our models,0,original
"The straight-forward way is to first generate the best BTG tree for each sentence pair using the way of  , then annotate each BTG node with linguistic elements by projecting source-side syntax tree to BTG tree, and finally extract rules from these annotated BTG trees.",0,original
"Such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the British 3 linguist J.R. Firth: You shall know a word by the company it keeps.   Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks   and by Dunning  , of identifying word senses, e.g. by Yarowski   and by Schutze  , of clustering verb classes, e.g. by Schulte im Walde  , and of inducing selectional restrictions of verbs, e.g. by Resnik  , by Abe & Li  , by Rooth et al.",0,original
"Similar to  , each word in the confusion network is associated with a word posterior probability.",0,original
7 Related Work There has been a recent interest in training methods that enable the use of first-order features  .,0,original
ur technique of generating negative examples is similar to the approach of Okanohara and Tsujii  ,0,original
"For example, the entry about the Microsoft in Wikipedia has the following categories: Companies listed on NASDAQ; Cloud computing vendors; etc. Both   and   used the free-text description of the Wikipedia entity to reason about the entity type.",0,original
he translation probability can also be discriminatively trained such as in Tillmann and Zhang  ,0,original
"Other factors that distinguish us from previous work are the use of all phrases proposed by a phrase-based system, and the use of a dependency language model that also incorporates constituent information   for related approaches).",0,original
Our evaluation metric is BLEU  .,0,original
"In this paper, we compare the performance of this system, HybridTrim, with the Topiary system and a number of other baseline gisting systems on a collection of news documents from the DUC 2004 corpus  .",0,original
We apply a maximum entropy   model   to this task.,0,original
"For our experiments, we used the binary-only distribution of the tagger  .",0,original
"We use a program to label syntactic arguments with the roles they are playing  , and the rules for complement/adjunct distinction given by   to never allow deletion of the complement.",0,original
"Since that time, however, increasingly large amounts of language model training data have become available ranging from approximately one billion words   to trillions of words  .",0,original
"I have made a preliminary analysis of the inventory of syntactic categories used in the tagging for labelling trees in the 18 Penn Treebank  , comparing them to the categories used in CGEL.",0,original
"Experimental Comparison 4.1 Experiments on the ATIS corpus For our first comparison, we used I0 splits from the Penn ATIS corpus   into training sets of 675 sentences and test sets of 75 sentences.",0,original
"The complexities of 15 restricted alignment problems in two very different synchronous grammar formalisms of syntax-based machine translation, inversion transduction grammars     and a restricted form of range concatenation grammars  -BRCGs)  , are investigated.",0,original
"Given an input sentence x, the correct output segmentation F  satisfies: F  = argmax yGEN  Score  where GEN  denotes the set of possible segmentations for an input sentence x, consistent with notation from Collins  .",0,original
uo and Zitouni   proposed a coreference resolution approach which also explores the information from the syntactic parse trees,0,original
But the lack of corpora has led to a situation where much of the current work on parsing is performed on a single domain using training data from that domain  the Wall Street Journal   section of the Penn Treebank  .,0,original
"Most of the previously proposed methods to extract compounds or to measure word association using mutual information   either ignore or penalize items with low co-occurrence counts  , because MI becomes unstable when the co-occurrence counts are very small.",0,original
1 A cept is defined as the set of target words connected to a source word  .,0,original
There are five different IBM translation models  .,0,original
The topic signatures are automatically generated for each specific term by computing the likelihood ratio   between two hypotheses  .,0,original
"For Hw6, students compared their POS tagging results with the ones reported in  .",0,original
"Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models    , the dictionary HMM model   and Maximum Entropy Markov Models    .",0,original
"For symmetrization, we found that Och and Neys refined technique described in   produced the best AER for this data set under all experimental conditions.",0,original
"Most previous work on paraphrase has focused on high quality rather than coverage  , but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications.",0,original
"The grammars were induced from sections 2-21 of the Penn Wall St. Journal Treebank  , and tested on section 23.",0,original
kanohara and Tsujii   generate ill-formed sentences by sampling a probabilistic language model and end up with pseudo-negative examples which resemble machine translation output more than they do learner texts,0,original
"Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language  .",0,original
"POS tagger: The maximum entropy POS tagger developed by Ratnaparkhi   and the rule-based POS tagger developed by Brill   are trained with 1200 abstracts extracted from the GENIA corpus, which achieve accuracies of 97.97% and 98.06% respectively, when testing on the rest 800 abstract of the GENIA corpus.",0,original
"1 Introduction Conditional Maximum Entropy   models have been widely used for a variety of tasks, including language modeling  , part-of-speech tagging, prepositional phrase attachment, and parsing  , word selection for machine translation  , and finding sentence boundaries  .",0,original
"By labelling Treeb~n~ nodes with Gr~ramar rule names, and not with phrasal and clausal n~raes, as in other   treebanks'  , we gain access to all information provided by the Grammar regarding each ~reebank node.",0,original
"Each model can represent an important feature for the translation, such as phrase-based, language, or lexical models  .",0,original
"Among the several proposals, we mention here the models presented in  ,  ,  ,   and  .",0,original
"As such, discourse markers play an important role in the parsing of natural language discourse  , and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations  .",0,original
Optimization and measurement were done with the NIST implementation of case-insensitive BLEU 4n4r  .4 4.1 Baseline We compared translation by pattern matching with a conventional exact model representation using external prefix trees  .,0,original
"Evaluation 6.1 Evaluation at the Token Level This section compares translation model estimation methods A, B, and C to each other and to Brown et al.'s   Model 1.",0,original
"4 Semi-Supervised Training for Word Alignments Intuitively, in approximate EM training for Model 4  , the E-step corresponds to calculating the probability of all alignments according to the current model estimate, while the M-step is the creation of a new model estimate given a probability distribution over alignments  .",0,original
"The concept of these alignments is similar to the ones introduced by  , but we will use another type of dependence in the probability distributions.",0,original
A totally different approach to improving the accuracy of our parser is to use the idea of selftraining described in  .,0,original
arowsky   used this method for word sense disambiguation,0,original
N-gram language models have also been used in Statistical Machine Translation   as proposed by  .,0,original
"The simple model 1   for the translation of a SL sentence d = dldt in a TL sentence e = el em assumes that every TL word is generated independently as a mixture of the SL words: m l P ,,~ H ~ t    j=l i=O In the equation above t  stands for the probability that ej is generated by di.",0,original
"Moreover, for reasons discussed by Wu  , ITGs possess an interesting intrinsic combinatorial property of permitting roughly up to four arguments of any frame to be transposed freely, but not more.",0,original
"240 2 Motivation Many approaches to identifying base noun phrases have been explored as part of chunking  , but determining sub-NP structure is rarely addressed.",0,original
imilar adaptations of the Matrix-Tree Theorem have been developed independently and simultaneouslybySmithandSmith andMcDonaldand Satta  ; see Section 5 for more discussion,0,original
  MEDLINE DT JJ VBN NNS IN DT NN NNS VBP The oncogenic mutated forms of the ras proteins are RB JJ CC VBP IN JJ NN NN . constitutively active and interfere with normal signal transduction . Figure 1: Part of speech-tagged sentences from both corpora we investigate its use in part of speech   tagging  .,0,original
"Distributional approaches, on the other hand, rely on text corpora, and model relatedness by comparing the contexts in which two words occur, assuming that related words occur in similar context  , Lin  , Mohammad and Hirst  ).",0,original
"To generate the n-best lists, a phrase based SMT   was used.",0,original
"The training set is extracted from TreeBank   section 1518, the development set, used in tuning parameters of the system, from section 20, and the test set from section 21.",0,original
"We also note that Turney   found movie reviews to be the most 2Indeed, although our choice of title was completely independent of his, our selections were eerily similar.",0,original
xperimentation The corpus used in shallow parsing is extracted from the PENN TreeBank   of 1 million words   by a program provided by Sabine Buchholz from Tilburg University,0,original
"In our experiments, we will use 4 different kinds of feature combinations: a157 Baseline: The 6 baseline features used in  , such as cost of word penalty, cost of aligned template penalty.",0,original
"4.3 Baseline We use a standard log-linear phrase-based statistical machine translation system as a baseline: GIZA++ implementation of IBM word alignment model 4  ,8 the refinement and phrase-extraction heuristics described in  , minimum-error-rate training 7More specifically, we choose the first English reference from the 7 references and the Chinese sentence to construct new sentence pairs.",0,original
hen and Martin   explored the use of a range of syntactic and semantic features in unsupervised clustering of documents,0,original
"Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase    .",0,original
"As our approach for incorporating unlabeled data, we basically follow the idea proposed in  .",0,original
"As in  , confusion networks built around all skeletons are joined into a lattice which is expanded and rescored with language models.",0,original
"Firstly, rather than induce millions of xRS rules from parallel data, we extract phrase pairs in the standard way   and associate with each phrase-pair a set of target language syntactic structures based on supertag sequences.",0,original
"Candidate term Segment result of GPWS for one sentence, in which term appears Table 2: Examples of candidates eliminated by GPWS 5 Relative frequency ratio against background corpus Relative frequency ratio   is a useful method to be used to discover characteristic linguistic phenomena of a corpus when compared with another  .",0,original
1 Introduction Sentiment detection and classification has received considerable attention recently  .,0,original
he later IBM models are formulated to prefer collocations  ,0,original
"Iterating between these two 1 Note that these problems are associated with corpus-based approaches in general, and have been identified by a number of researchers  .",0,original
"On one hand, as   evidence, clusters of paraphrases can lead to better learning of text-totext rewriting rules compared to just pairs of paraphrases.",0,original
5.2 Translation In order to test the translation performance of the grammars induced by our model and the GHKM method6 we report BLEU   scores on sentences of up to twenty words in length from the MT03 NIST evaluation.,0,original
"For each feature function, there is a model parameter  i . The best word segmentation W * is determined by the decision rule as  = == M i ii W M W WSfWSScoreW 0 0 * ), ,,  Below we describe how to optimize  s. Our method is a discriminative approach inspired by the Minimum Error Rate Training method proposed in Och  .",0,original
"In all of the cited approaches, the Penn Wall Street Journal Treebank   is used, the availability of whichobviates the standard eort required for treebank traininghandannotating large corpora of specic domains of specic languages with specic parse types.",0,original
"Intuitively speaking, the gaps on the target-side will lead to exponential complexity in decoding with integrated language models  , as well as synchronous parsing  .",0,original
"Some o1' l;his research has treated the sentenees as unstructured word sequences to be aligned; this work has primarily involved the acquisition of bilingual lexical correspondences  , although there has also been a,n attempt to create a full MT system based on such trcat, ment  .",0,original
"In the context of statistical machine translation  , we may interpretE as an English sentence, F its translation in French, and A a representation of how the words correspond to each other in the two sentences.",0,original
"3For decoding, loc is averaged over the training iterations as in Collins and Roark  .",0,original
The Spanish corpus was parsed using the MST dependency parser   trained using dependency trees generated from the the English Penn Treebank   and Spanish CoNLL-X data  .,0,original
" , Johnson  --that conditioning the probabilities of structures on the context within which they appear, for example on the lexical head of a constituent  , on the label of its parent nonterrninal  , or, ideally, on both and many other things besides, leads to a much better parsing model and results in higher parsing accuracies.",0,original
Of particular relevance is other work on parsing the Penn WSJ Treebank  .,0,original
1 Introduction Aligning parallel texts has recently received considerable attention  .,0,original
he word sense disambiguation method proposed in Yarowsky   can also be viewed as a kind of co-training,0,original
"By building the entire system on the derivation level, we side-step issues that can occur when perceptron training with hidden derivations  , but we also introduce the need to transform our training source-target pairs into training derivations.",0,original
4 Optimizing Metric Parameters The original version of Meteor   has instantiated values for three parameters in the metric: one for controlling the relative weight of precision and recall in computing the Fmean score  ; one governing the shape of the penalty as a function of fragmentation   and one for the relative weight assigned to the fragmentation penalty  .,0,original
Empirical evaluation has been done with the ERG on a small set of texts from the Wall Street Journal Section 22 of the Penn Treebank  .,0,original
"Furthermore, they extended WSD to phrase sense disambiguation    .",0,original
The feature weights were tuned on a heldout development set so as to maximize an equally weighted linear combination of BLEU and 1-TER   using the minimum error training algorithm on a packed forest representation of the decoders hypothesis space  .,0,original
"Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words  .",0,original
"The measures are: word overlap, length difference  , BLEU  , dependency relation overlap  , and dependency tree edit distance.",0,original
"Sometimes, due to data sparseness and/or limitations in the machine learning paradigm used, we need to extract features from the available representation in a manner that profoundly changes the representation  ).",0,original
"In our experiments, we used the Hidden Markov Model   tagging method described in \ .",0,original
unning   reports that we should not rely on the assumption of a normal distribution when performing statistical text analysis and suggests that parametric analysis based on the binomial or multinomial distributions is a better alternative for smaller texts,0,original
"2 Background Several graph-based learning techniques have recently been developed and applied to NLP problems: minimum cuts  , random walks  , graph matching  , and label propagation  .",0,original
"Decoding Conditions For tuning of the decoder's parameters, minimum error training   with respect to the BLEU score using was conducted using the respective development corpus.",0,original
"Following this idea, there have been introduced a parameter estimation approach for non-generative approaches that can effectively incorporate unlabeled data  .",0,original
"This generates tens of millions features, so we prune those features that occur fewer than 10 total times, as in  .",0,original
Part-of-Speech   annotation for example can be seen as the task of choosing the appropriate tag for a word from an ontology of word categories  ).,0,original
"While bound compositions are not predictable, i.e., their reasonableness cannot be derived from the syntactic and semantic properties of the words in them .",0,original
"4.2 Support Vector Machines We chose to adopt a tagging perspective for the Simple NP chunking task, in which each word is to be tagged as either B, I or O depending on wether it is in the Beginning, Inside, or Outside of the given chunk, an approach first taken by Ramshaw and Marcus  , and which has become the de-facto standard for this task.",0,original
A few studies   addressed this defect by selecting the appropriate translation rules for an input span based on its context in the input sentence.,0,original
"Entropy, used in some part-of-speech tagging systems  , is a measure of how much information is necessary to separate data.",0,original
"At the present time, given the key role of window size in determining the selection and apparent strength of associations under the conventional co-occurrence model highlighted here and in the works of Church et al  , Rapp  , Wang  , and Schulte im Walde & Melinger   we would urge that this is an issue which window-driven studies continue to conscientiously address; at the very least, scale is a parameter which findings dependent on distributional phenomena must be qualified in light of.",0,original
"The results of these studies have important applications in lexicography, to detect lexicosyntactic regularities  , such as, for example~ support verbs   prepositional verbs   idioms, semantic relations   and fixed expressions  .",0,original
"We can incorporate each model into the system in turn, and rank the results on a test corpus using BLEU  .",0,original
"Alternatively we could have simply incorporated the DIVERSITY measure into the objective function or used an inference algorithm that specifically accounts for redundancy, e.g., maximal marginal relevance  .",0,original
Models of this kind assume that an input word is generated by only one output word  .,0,original
1 Introduction The task of sentence compression   can be defined as summarizing a single sentence by removing information from it  .,0,original
"Similar to WSD, Carpuat and Wu   used contextual information to solve the ambiguity problem for phrases.",0,original
6 Discussion Lack of interannotator agreement presents a significant problem in annotation efforts  .,0,original
We use MER   to tune the decoders parameters using a development data set.,0,original
"Och   claimed that this approximation achieved essentially equivalent performance to that obtained when directly using the loss as the objective, O = lscript.",0,original
There are many choices for modeling co-occurrence data  .,0,original
"As noted in Talbot and Osborne  , errors for this log-frequency BF scheme are one-sided: frequencies will never be underestimated.",0,original
Minimum Error Rate Training     under BLEU criterion is used to estimate 20 feature function weights over the larger development set  .,0,original
"3.2 System Combination Scheme In our work, we use a sentence-level system combination model to select best translation hypothesis from the candidate pool     . This method can also be viewed to be a hypotheses reranking model since we only use the existing translations instead of performing decoding over a confusion network as done in the word-level combination method  .",0,original
The left-to-right parser would likely improve if we were to use a left-corner transform  .,0,original
"This obviously does not preclude using the audio-based system together with other features such as utterance position, length, speakers roles, and most others used in the literature  .",0,original
"It has been shown by Shapiro and Stephens   and Wu (1997, Sec.",0,original
"4.1 Part-of-speech tagging experiments We split the Penn Treebank corpus   into training, development and test sets as in  .",0,original
"4.1 Overview In this work, factored models   are experimented with three factors : the surface form, the lemma and the part of speech  .",0,original
"The separation of these two requirements 7 A more precise account of what it means to be able to identify an object is beyond the scope of this paper; for further details, see the discussions by Hobbs  , Appelt  , Kronfeld  , and Morgenstern  .",0,original
  described symmetrized training of a 1-toN log-linear model and a M-to-1 log-linear model.,0,original
Algorithms for the more difficult task of word alignment were proposed in   and were applied for parameter estimation in the IBM statistical machine translation system  .,0,original
"ald, 2008), and is also similar to the Pred baseline for domain adaptation in  .",0,original
"In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores   are above a threshold.",0,original
Our baseline is the phrase-based MT system of  .,0,original
"In the following, we summarize the optimization algorithm for the unsmoothed error counts presented in   and the implementation detailed in  .",0,original
"Several other measures like Log-Likelihood  , Pearsons a2a4a3  , Z-Score  , Cubic Association Ratio  , etc. , have been also proposed.",0,original
"1 Introduction Word associations   have a wide range of applications including: Speech Recognition, Optical Character Recognition and Information Retrieval    .",0,original
These were combined using the Grow Diag Final And symmetrization heuristic  .,0,original
"In this paper, we present Phramer, an open-source system that embeds a phrase-based decoder, a minimum error rate training   module and various tools related to Machine Translation  .",0,original
"Dunning   argues for the use of G 2 rather than X 2, based on an analysis of the sampling distributions of G 2 and X 2, and results obtained when using the statistics to acquire highly associated bigrams.",0,original
" , and Magerman   can suffer from very similar problems to the label bias or observation bias problem observed in tagging models, as described in Lafferty, McCallum, and Pereira   and Klein and Manning  .",0,original
"To do this, we first identify initial phrase pairs using the same criterion as previous systems  : Definition 1.",0,original
he first is a novel stochastic search strategy that appears to make better use of Och  s algorithm for finding the global minimum along any given search direction than either coordinate descent or Powells method,0,original
5 Datasets For evaluation we selected two domain adaptation datasets: spam   and sentiment  .,0,original
"Once we obtain the augmented phrase table, we should run the minimum-error-rate training   with the augmented phrase table such that the model parameters are properly adjusted.",0,original
"To examine the effects of including some known AMs on the performance, the following AMs had a 50% chance of being included in the initial population: pointwise mutual information  , the Dice coefficient, and the heuristic measure defined in  : H  =    2log f f f  if POS  = X, log f f f f  otherwise.",0,original
Related Work One of the first works that use statistical methods to detect implicit discourse relations is that of Marcu and Echihabi  ,0,original
Existing automatic evaluation measures such as BLEU   and ROUGE (Lin 2The collections are available.,0,original
"Jiang & Zhai   gave a systematic examination of the efficacy of unigram, bigram and trigram features drawn from different representations  surface text, constituency parse tree and dependency parse tree.",0,original
"Other commonly used measures include kappa   and relative utility  , both of which take into account the performance of a summarizer that randomly picks passages from the original document to produce an extract.",0,original
These domains have been commonly used in prior work on summarization  .,0,original
"3.1 Golden-standard-based criteria In the domain of machine translation systems, an increasingly accepted way to measure the quality of a system is to compare the outputs it produces with a set of reference translations, considered as an approximation of a golden standard  .",0,original
"The TRIPS structure generally has more levels of structure   than the Penn Treebank analyses  , in particular for base noun phrases.",0,original
n the LFG-based generation algorithm presented by Cahill and van Genabith   complex named entities   and other multi-word units can be fragmented in the surface realization,0,original
"1 Introduction Bilingual data   are critical resources for building many applications, such as machine translation   and cross language information retrieval  .",0,original
2.1 Minimum Error Rate Training The predominant approach to reconciling the mismatch between the MAP decision rule and the evaluation metric has been to train the parameters  of the exponential model to correlate the MAP choice with the maximum score as indicated by the evaluation metric on a development set with known references  .,0,original
"a65 The rest of the factors denote distorsion probabilities  , which capture the probability that words change their position when translated from one language into another; the probability of some French words being generated from an invisible English NULL element  , etc. See   or   for a detailed discussion of this translation model and a description of its parameters.",0,original
"4 Experimental Set-up For the experiments, we use the WSJ portion of the Penn tree bank  , using the standard train/development/test splits, viz 39,832 sentences from 2-21 sections, 2416 sentences from section 23 for testing and 1,700 sentences from section 22 for development.",0,original
"Finally, it would be nice to merge some of the approaches by   and   with the ideas of semi-supervised learning introduced here, since they seem orthogonal in at least some aspects  .",0,original
"As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: Bahl and Mercer  , Leech, Garside, and Atwell  , Jelinek  , Deroualt and Merialdo  , Garside, Leech, and Sampson  , Church  , DeRose  , Hindle  , Kupiec  , Ayuso et al.",0,original
"3.1 Maximum Entropy This section presents a brief description of ME. A more detailed and informative description can be found in Berger   4, Ratnaparkhi  , Manning and Shutze   to name just a few.",0,original
"However, few papers in the field of computational linguistics have focused on this approach  .",0,original
"They constructed word clusters by using HMMs or Browns clustering algorithm  , which utilize only information from neighboring words.",0,original
The L1 or L2 norm is commonly used in statistical natural language processing  .,0,original
"The current version of the dataset gives semantic tags for the same sentencesas inthe PennTreebank  , whichareexcerptsfromtheWallStreetJournal.",0,original
"4.2 Binarization Schemes Besides the baseline   and iterative cost reduction binarization methods, we also perform right-heavy and random synchronous binarizations for comparison.",0,original
4.1 Training and Translation Setup Our decoder is a phrase-based multi-stack implementation of the log-linear model similar to Pharaoh  .,0,original
"Appendix B gives a sketch of one such approach, which is based on results from Collins, Schapire, and Singer  .",0,original
"+ truecase 20.7   27.8   Table 2: Impact of truecasing on case-sensitive BLEU In a more integrated approach, factored translation models   allow us to consider grammatical coherence in form of partof-speech language models.",0,original
hurch and Hanks   employed mutual information to extract both adjacent and distant bi-grams that tend to co-occur within a fixed-size window,0,original
"A second pass aligns the sentences in a way similar1 to the algorithm described by Gale and Church  , but where the search space is constrained to be close to the one delimited by the word alignment.",0,original
"Dagan, Church, and Gale   expanded on this idea by replacing Brown et al.'s   word alignment parameters, which were based on absolute word positions in aligned segments, with a much smaller set of relative offset parameters.",0,original
"Even for semantically predictable phrases, the fact that the words occur in fixed patterns can be very useful for the purposes of disambiguation, as demonstrated by  .",0,original
"Finally, our modeling approaches follow the recent work on both local classifier-based modeling of complex learning problems  , as well as global discriminative approaches based on CRFs  , SVM  , and the Perceptron algorithm   that we used in our experiments.",0,original
"Here, we extract part-of-speech tags from the Collins parsers output   for section 23 instead of reinventing a tagger.",0,original
ag test data using the POS-tagger described in Ratnaparkhi  ,0,original
"Researchers extracted opinions from words, sentences, and documents, and both rule-based and statistical models are investigated  .",0,original
"Since the texts in the RST Treebank are taken from the syntactically annotated Penn Treebank  , it is natural to ask what the relation is between the discourse structures in the RST Treebank and the syntactic structures of the Penn Treebank.",0,original
"We employ the phrase-based SMT framework  , and use the Moses toolkit  , and the SRILM language modelling toolkit  , and evaluate our decoded translations using the BLEU measure  , using a single reference translation.",0,original
"Lastly, collocations are domain-dependent   and language-dependent.",0,original
"In addition to the block sampler used by Bhattacharya and Getoor  , we are investigating general-purpose splitmerge samplers   and the permutation sampler  .",0,original
It has been shown that one sense per discourse property can improve the performance of bootstrapping algorithm  .,0,original
"This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation   and consists of the Pharaoh decoder  , SRILM  , GIZA++  , mkcls  , Carmel,1 and a phrase model training code.",0,original
e also tested the flat syntactic feature set proposed in Luo and Zitouni  s work,0,original
"It is often argued that the ability to translate discontiguous phrases is important to modeling translation  , and it may be that this explains the results.",0,original
A later study   found that performance increased to 87.2% when considering only those portions of the text deemed to be subjective.,0,original
The lexical scores are computed as the   log probability of the Viterbi alignment for a phrase pair under IBM word-translation Model 1  .,0,original
5 Reliability of Annotations 5.1 The Kappa Statistic To measure the reliability of annotations we used the Kappa statistic  .,0,original
5.3   Snow   has extended the WordNet 2.1 by adding thousands of entries   at a relatively high precision.,0,original
"In addition, explicitly using the left context symbols allows easy use of smoothing techniques, such as deleted interpolation  , clustering techniques  , and model refinement techniques   to estimate the probabilities more reliably by changing the window sizes of the context and weighting the various estimates dynamically.",0,original
"In retrospect, however, there are perhaps even greater similarities to that of  .",0,original
urran   and Lin   use syntactic features in the vector definition,0,original
"Amazon Reviews: The dataset contains product reviews taken from Amazon.com from 4 product types: Kitchen, Books, DVDs, and Electronics  .",0,original
aume III   proposed a simple feature augmentation method to achieve domain adaptation,0,original
Both taggers used the Penn Treebank tagset and were trained on the Wall Street Journal corpus  .,0,original
"For example,   collected reviews from a movie database and rated them as positive, negative, or neutral based on the rating   given by the reviewer.",0,original
"The association relationship between two words can be indicated by their mutual information, which can be further used to discover phrases \ .",0,original
"These problems include collocation discovery  , smoothing and estimation   and question answering  .",0,original
"Table 1 shows the percentage of agreement in classifying words as compounds or non-compounds   for each language and the Kappa score   obtained from it, and the percentage of words for which also the decomposition provided was identical  .",0,original
"In each case the input to the network is a sequence of tag-word pairs.2 We report results for two different vocabulary sizes, varying in the frequency with which tag-word pairs must 2We used a publicly available tagger   to provide the tags.",0,original
"To set the weights, m, we performed minimum error rate training   on the development set using Bleu   as the objective function.",0,original
"Even before the 2006 shared task, the parsers of Collins   and Charniak  , originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto   and Yamada and Matsumoto   had been evaluated on both Japanese and English.",0,original
This negation handling is similar to that used in  .,0,original
In this work we use the following contextual information: a3 Target context: As in   we consider a window of 3 words to the left and to the right of the target word considered.,0,original
"A more fine-grained distinction is made by Bean and Riloff   and Vieira and Poesio   to distinguish restrictive from non-restrictive postmodification by ommitting those modifiers that occur between commas, which should not be classified as chain starting.",0,original
Learning to Disambiguate Word Senses Several recent research projects have taken a corpus-based approach to lexical disambiguation  .,0,original
"203 Estimating the parameters for these models is more difficult   than with the models considered in the previous section: rather than simply being able to count the word pairs and alignment relationships and estimate the models directly, we must use an existing model to compute the expected counts for all possible alignments, and then use these counts to update the new model.7 This training strategy is referred to as expectationmaximization   and is guaranteed to always improve the quality of the prior model at each iteration  .",0,original
"In the thriving area of research on automatic analysis and processing of product reviews  , little attention has been paid to the important task studied here  assessing review helpfulness.",0,original
"s e, the window to consider when extracting words related to word w, should span from postttuon w-5 to w+5 Maarek also defines the resolwng power of a parr m a document d as P = ~'Pd log Pc where Pd is the observed probabshty of appearance of the pan"""" m document d, Pc the observed probabdny of the pmr recorpus, and -log Pc the quantity of mformauon assocmted to the pmr It Is easdy seen that p wall be h|gher, the higher the frequency of the pmr m the document and the lower sts frequency m the corpus, which agrees wlth the sdea presented at the begmnmg of this sectton Church and Hanks   propose the apphcatlon of the concept of mutual mformatton e  ~,  = hog2 ecx)e  51 to the retrieval, ro a corpus, of pairs of lextcally related words They alsoconslder a word span of :e5 words and observe that """"roterestrog"""" pmr, s generally present a mutual mformatxon above 3 Salton and.Allan   foc~as on paragraph level Each paragraph Is represented by a weighed vector, where each element is a term (typically.",0,original
  proposed using GIZA++   to align words between the backbone and hypothesis.,0,original
The statistical machine translation approach is based on the noisy channel paradigm and the Maximum-A-Posteriori decoding algorithm  .,0,original
"In this paper, we bring forward the first idea by studying the issue of how to utilize structured syntactic features for phrase reordering in a phrase-based SMT system with BTG   constraints  .",0,original
he data set that has become standard for evaluation machine learning approaches is the one first used by Ramshaw and Marcus  ,0,original
ur method uses assumptions similar to Berger et al. 1996 but is naturally suitable for distributed parallel computations,0,original
"1 Introduction In this paper, we show how discriminative training with averaged perceptron models   can be used to substantially improve surface realization with Combinatory Categorial Grammar  .",0,original
Others proposed distributional similarity measures between words  .,0,original
"For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning  , decision trees  , markov model  , maximum entropy methods   etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS  .",0,original
Perceptron Training We optimize feature weights using a modification of averaged perceptron learning as described by Collins  ,0,original
"1 Introduction Hyponymy relations can play a crucial role in various NLP systems, and there have been many attempts to develop automatic methods to acquire hyponymy relations from text corpora  .",0,original
We use evaluations similar to those used before  .,0,original
We argue that linguistic knowledge could not only improve results   but is essential when extracting collocations from certain languages: this knowledge provides other applications   with a ne-grained description of how the extracted collocations are to be used in context.,0,original
"In this paper we will compare and evaluate several aspects of these techniques, focusing on Minimum Error Rate   training   and Minimum Bayes Risk   decision rules, within a novel training environment that isolates the impact of each component of these methods.",0,original
"The difficulty of this task is that the standard method for converting NER to a sequence tagging problem with BIOencoding  , where each 1http://www.nist.gov/speech/tests/ace/ index.htm token is assigned a tag to indicate whether it is at the beginning  , inside  , or outside   of an entity, is not directly applicable when tokens belong to more than one entity.",0,original
"7Following Carletta  , we measure agreement in Kappa, which follows the formula K = P P 1P  where P  is observed, and P  expected agreement.",0,original
"Instead of using the NP bracketing information present in the tagged Treebank data, Ramshaw and Marcus modified the data so as to include bracketing information related only to the non-recursive, base NPs present in each sentence while the subject verb phrases were taken as is. The data sets include POS tag information generated by Ramshaw and Marcus using Brill's transformational part-of-speech tagger  .",0,original
The model scaling factors are optimized with respect to some evaluation criterion  .,0,original
"In one set of experiments, we generated lexicons for PEOPLE and ORGANIZATIONS using 2500 Wall Street Journal articles from the Penn Treebank  .",0,original
We should note from equation 4 that the neural network model is similar in functional form to the maximum entropy model   except that the neural network learns the feature functions by itself from the training data.,0,original
"Yarowsky   describes a 'semi-unsupervised' approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations.",0,original
Various corpus-based approaches to word sense disambiguation have been proposed  .,0,original
2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods  .,0,original
"The search also uses a Tag Dictionary constructed from training data, described in  , that reduces the number of actions explored by the tagging model.",0,original
Several researchers  ) work on reducing the granularity of sense inventories for WSD.,0,original
.2.1 Proxy items There is a potential risk of redundancy if we represent related statistics using the log-frequency BF scheme presented in Talbot and Osborne  ,0,original
"In practice, 7-/ is very large and the model's expectation Efj cannot be computed directly, so the following approximation  is used: n E fj,~ E15 p fj  i=1 where fi  is the observed probability of the history hi in the training set.",0,original
3 GM Representation of IBM MT Models In this section we present a GM representation for IBM model 3   in fig.,0,original
The production weights are estimated either by heuristic counting   or using the EM algorithm.,0,original
"  proposed sentence alignment techniques based on dynamic programming, using sentence length and lexical mapping information.",0,original
"l lhmsetsu ideni,illcation is a ln'oblem similar to ohm,king   in other l;mguages.",0,original
"Consequently, considerable effort has gone into devising and improving automatic word alignment algorithms, and into evaluating their performance  .",0,original
"c2007 Association for Computational Linguistics Structural Correspondence Learning for Dependency Parsing Nobuyuki Shimizu Information Technology Center University of Tokyo Tokyo, Japan shimizu@r.dl.itc.u-tokyo.ac.jp Hiroshi Nakagawa Information Technology Center University of Tokyo Tokyo, Japan nakagawa@dl.itc.u-tokyo.ac.jp Abstract Following  , we present an application of structural correspondence learning to non-projective dependency parsing  .",0,original
Our learning algorithm stems from Perceptron training in  .,0,original
The model was trained on sections 221 from the English Penn Treebank  .,0,original
We use Minimal Error Rate Training   to maximize BLEU on the complete development data.,0,original
Official DUC scoring utilizes the jackknife procedure and assesses significance using bootstrapping resampling  .,0,original
"To optimize the parameters of the decoder, we performed minimum error rate training on IWSLT04 optimizing for the IBM-BLEU metric  .",0,original
"The principle of maximum entropy states that when one searches among probability distributions that model the observed data  , the preferred one is the one that maximizes the entropy    .",0,original
"Following  , we used sections 0-18 of the Wall Street Journal   corpus for training, sections 19-21 for development, and sections 22-24 for final evaluation.",0,original
"  Och   provides evidence that  should be chosen by optimizing an objective function basd on the evaluation metric of interest, rather than likelihood.",0,original
"1 Introduction Motivation: Sharing basic intuitions and longterm goals with other tasks within the area of Webbased information extraction  , the task of acquiring class attributes relies on unstructured text available on the Web, as a data source for extracting generally-useful knowledge.",0,original
"The set of such ITG alignments,AITG, are a strict subset of A1-1  .",0,original
"3.2 Results In line with previous work  , we first compare Naive Bayes and Logistic regression on the two NLP tasks.",0,original
"For extrinsic evaluation of machine translation, we use the BLEU metric  .",0,original
"While other systems, such as  , have addressed these tasks to some degree, OPINE is the first to report results.",0,original
We implemented these models within an maximum entropy framework  .,0,original
"After unioning the Viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion  .",0,original
"In addition, we developed a word clustering procedure  ) that optimizes conditional word clusters.",0,original
2 Architecture of the system The goal of statistical machine translation   is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units   and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp  = argmaxe {exp )}   The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set  .,0,original
"In addition, Wu   used a stochastic inversion transduction grammar to simultaneously parse the sentence pairs to get the word or phrase alignments.",0,original
"4 Semantic Class Induction from Wikipedia Wikipedia has recently been used as a knowledge source for various language processing tasks, including taxonomy construction  , coreference resolution  , and English NER  , Cucerzan  , Kazama and Torisawa  , Watanabe et al.",0,original
"Table 1 shows a summary of the results of our experiments with SVMpar and MBLpar, and also results obtained with the Charniak   parser, the Bikel   implementation of the Collins   parser, and the Ratnaparkhi   parser.",0,original
Previous Work There have been several approaches to automatically discovering lexico-semantic information from text  ,0,original
"Feature weights of both systems are tuned on the same data set.3 For Pharaoh, we use the standard minimum error-rate training  ; and for our system, since there are only two independent features  , we use a simple grid-based line-optimization along the language-model weight axis.",0,original
"For example, in John saw Mary yesterday at the station, only John and Mary are required arguments while the other constituents are optional  .3 The problem of SF identification using statistical methods has had a rich discussion in the literature    ).",0,original
"It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance  .",0,original
4.2 Automatic Evaluation We first present our soft cohesion constraints effect on BLEU score   for both our dev-test and test sets.,0,original
"Dunning   has called attention to the log-likelihood ratio, G 2, as appropriate for the analysis of such contingency tables, especially when such contingency tables concern very low frequency words.",0,original
e adopt a similar approach to the one used in Turney   and consider each question as a separate binary classification problem with one positive training instance and 5 unknown pairs,0,original
"2 Recap of BLEU, ROUGE-W and METEOR The most commonly used automatic evaluation metrics, BLEU   and NIST  , are based on the assumption that The closer a machine translation is to a promt1: Life is like one nice chocolate in box ref: Life is just like a box of tasty chocolate ref: Life is just like a box of tasty chocolate mt2: Life is of one nice chocolate in box Figure 1: Alignment Example for ROUGE-W fessional human translation, the better it is  .",0,original
"The COlllillOil poini;s regarding collocations appear to be, as   suggestsl: they are m'bil;rary  , th , t;hey are recurrenl; and cohesive lo~xical clusters: the presence of one of the.",0,original
"7 In the models described in Collins  , there was a third question concerning punctuation:   Does the string contain 0, 1, 2 or more than 2 commas?",0,original
"Most current transliteration systems use a generative model for transliteration such as freely available GIZA++1  ,an implementation of the IBM alignment models  .",0,original
t also has close links with theoretical work in situation semantics  ,0,original
ord association norms based on co-occurrence information have been proposed by  ,0,original
"1993; Chang et al. , 1992; Collins and Brooks, 1995; Fujisaki, 1989; Hindle and Rooth, 1991; Hindle and Rooth, 1993; Jelinek et al. , 1990; Magerman and Marcus, 1991; Magerman, 1995; Ratnaparkhi et al. , 1994; Resnik, 1993; Su and Chang, 1988).",0,original
"In this paper we focus on the second issue, constraining the grammar to the binary-branching Inversion Transduction Grammar of Wu  .",0,original
Such linguistic-preprocessing techniques could 1Various models have been constructed by the IBM team  .,0,original
"Church and Hanks 1990; Klavans, Chodorow, and Wacholder 1990; Wilks et al. 1993; Smadja 1991a, 1991b; Calzolari and Bindi 1990).",0,original
We used the Penn Treebank WSJ corpus   to perform the empirical evaluation of the considered approaches.,0,original
We then proceed to split the data into smaller sentences and tag them using Ratnaparkhis Maximum Entropy Tagger  .,0,original
"In  , automatically extracted collocations are judged by a lexicographer.",0,original
"This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences  .",0,original
avid Yarowsky   showed it was accurate in the word sense disambiguation,0,original
"Automatic identification of subjective content often relies on word indicators, such as unigrams   or predetermined sentiment lexica  .",0,original
"We split the returned documents into classes encompassing n-grams  , adjectives  ) and noun phrases  ).",0,original
4 Related work Algorithms for retrieving collocations has been described    .,0,original
"In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation , large amount of human effort and time has been invested in collecting parallel corpora of translated texts.",0,original
"In particular, ROUGE-2 is the recall in bigrams with a set of human-written abstractive summaries  .",0,original
"Examples of such methods are the introduction of information weights as in the NIST measure or the comparison of stems or synonyms, as in METEOR  .",0,original
"In fact, it has already been established that sentence level classification can improve document level analysis  .",0,original
"Introduction Word sense disambiguation has long been one of the major concerns in natural language processing area  , whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus.",0,original
"For each candidate triple, the log-likelihood   and salience   scores were calculated.",0,original
The publicly available Moses4 decoder is used for training and decoding  .,0,original
"The surface heuristic can define consistency according to any word alignment; but most often, the alignment is provided by GIZA++  .",0,original
"A related example would be a version of synchronous CFG that allows only one pair of linked nonterminals and any number of unlinked nonterminals, which could be bitextparsed in O  time, whereas inversion transduction grammar   takes O .",0,original
"However, due to the computational issues with the voted perceptron, the averaged perceptron algorithm   is used instead.",0,original
olan   described a heuristic approach to forming unlabeled clusters of closely related senses in a MRD,0,original
"We hence chose transformation-based learning to create this   segmentation grammar, converting the segmentation task into a tagging task  , inter alia).",0,original
"Consequently, here we employ multiple references to evaluate MT systems like BLEU   and NIST  .",0,original
"This situation is very similar to the training process of translation models in statistical machine translation  , where parallel corpus is used to find the mappings between words from different languages by exploiting their co-occurrence patterns.",0,original
"It will also be relevant to apply advanced statistical models that can incorporate various useful information to this task, e.g., the maximum entropy model  .",0,original
"In  , different word orderings are taken into account by training alignment models by considering all hypothesis pairs as a parallel corpus using GIZA++  .",0,original
"As a result, we can use collocation measures like point-wise mutual information   or the log-likelihood ratio   to predict the strong association for a given cue.",0,original
In this paper we use the phrase-based system of   as our underlying model.,0,original
"159 2.1 Baseline System The baseline system is a phrase-based SMT system  , built almost entirely using freely available components.",0,original
"In addition, uniform conditioning on mother grammatical function is more general than the case-phenomena specific generation grammar transform of  , in that it applies to each and every sub-part of a recursive input f-structure driving generation, making available relevant generation history   to guide local generation decisions.",0,original
"Note that the results of MB-D here cannot be directly compared with those in  , mainly because the data used are different.",0,original
Joint parsing with a simplest synchronous context-free grammar   is O  as opposed to the monolingual O  time.,0,original
"To avoid this problem, we adopt cross-validation training as used in Collins  .",0,original
"3.3 System evaluation Since both the system translations and the reference translations are available for the tuning 43 set, we first compare each output to the reference translation using BLEU   and METEOR   and a combined scoring scheme provided by the ULC toolkit  .",0,original
"4 Experiments and Results 4.1 Set up We parsed the 3 GB AQUAINT corpus   using Minipar  , and collected verb-object and verb-subject frequencies, building an empirical MI model from this data.",0,original
Of particular interest are lexicalized parsing models such as the ones developed by Collins   and Carroll and Rooth  .,0,original
"3.3 Voted Perceptron Unlike other methods discussed so far, voted perceptron training   attempts to minimize the difference between the global feature vector for a training instance and the same feature vector for the best-scoring labeling of that instance according to the current model.",0,original
Feature weights were set with minimum error rate training   on a development set using BLEU   as the objective function.,0,original
"For this work, an off-the-shelf maximum entropy tagger 10   was used.",0,original
"The data set consisting of 249,994 TFSs was generated by parsing the Figure 3: The size of Dpi; for the size of the data set 800 bracketed sentences in the Wall Street Journal corpus   in the Penn Treebank   with the XHPSG grammar  .",0,original
"For the Penn Treebank, our research and the work of others   have shown that such a correspondence exists in most cases.",0,original
Some methods use sentence alignment and additional statistics to find candidate translations of terms  .,0,original
aume III   further augments the feature space on the instances of both domains,0,original
"Giza++ is a freely available implementation of IBM Models 1-5   and the HMM alignment  , along with various improvements and modifications motivated by experimentation by Och & Ney  .",0,original
"4.1.3 Letter Lexical Transliteration Similar to IBM Model-1  , we use a bag-of-letter generative model within a block to approximate the lexical transliteration equivalence: P = j+lproductdisplay jprime=j i+ksummationdisplay iprime=i P P ,   where P  similarequal 1/  is approximated by a bagof-word unigram.",0,original
"For this study, we used the same 6 test meetings as in  .",0,original
"One other published model for grouping semantically related words  , is based on a statistical model of bigrams and trigrams and produces word groups using no linguistic knowledge, but no evaluation of the results is reported.",0,original
"By treating a letter/character as a word and a group of letters/characters as a phrase or token unit in SMT, one can easily apply the traditional SMT models, such as the IBM generative model   or the phrase-based translation model   to transliteration.",0,original
he benefits of using grammatical information for automatic WSD were first explored by Yarowsky   and Resnik   in unsupervised approaches to disambiguating single words in context,0,original
"For example, in this work we use loglikelihood ratio   to determine the SoA between a word sense and co-occurring words, and cosine to determine the distance between two DPWSs log likelihood vectors  .",0,original
"1 Introduction This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus  .",0,original
"Finally, in order to formally evaluate the method and the different heuristics, a large-scale evaluation on the BioMed Corpus is under way, based on computing the ROUGE measures  .",0,original
"The proposed approach follows the same principle as  , which tried to determine the appropriate word sense according to one relevant context word.",0,original
"A more optimistic view can be found in  ; they argue that a near-100% interjudge agreement is possible, provided the part-of-speech annotation is done carefully by experts.",0,original
"  compare two tagging frameworks for tagging French, one that is statistical, built upon the Xerox tagger  , and another based on linguistic constraints only.",0,original
2.5 Model Training We adapt the Minimum Error Rate Training     algorithm to estimate parameters for each member model in co-decoding.,0,original
"1 Introduction There has been a great deal of recent interest in the unsupervised discovery of syntactic structure from text, both parts-of-speech   and deeper grammatical structure like constituency and dependency trees  .",0,original
" , and the phrase-based approach to Statistical Machine Translation   has led to the development of heuristics for obtaining alignments between phrases of any number of words.",0,original
The weighting parameters of these features were optimized in terms of BLEU by the approach of minimum error rate training  .,0,original
"The concept of baseNP has undergone a number of revisions   but has previously always been tied to extraction from a more completely annotated treebank, whose annotations are subject to other pressures than just initial material up to the head . To our knowledge, our gures for inter-annotator agreement on the baseNP task itself 169   are the rst to be reported.",0,original
"Work focusses on analysing subjective features of text or speech, such as sentiment, opinion, emotion or point of view  .",0,original
"Previous workonsentimentanalysishascoveredawiderange of tasks, including polarity classification  , opinion extraction  , and opinion source assignment  .",0,original
"Note that this early discarding is related to ideas behind cube pruning  , which generates the top n most promising hypotheses, but in our method the decision not to generate hypotheses is guided by the quality of hypotheses on the result stack.",0,original
"Thus, we propose a bootstrapping approach   to train the stochastic transducer iteratively as it extracts transliterations from a bitext.",0,original
"After this conversion, we had 1000 positive and 1000 negative examples for each domain, the same balanced composition as the polarity dataset  .",0,original
"The first approach is to reuse the components of a generative model, but tune their relative weights in a discriminative fashion  .",0,original
"The term global feature vector is used by Collins   to distinguish between feature count vectors for whole sequences and the local feature vectors in ME tagging models, which are Boolean valued vectors containing the indicator features for one element in the sequence.",0,original
"Errors from the sentence boundary detector in GATE   were especially problematic because they caused the Collins parser to fail, resulting in no dependency tree information.",0,original
"The remaining six entries were all fully automatic machine translation systems; in fact, they were all phrase-based statistical machine translation system that had been trained on the same parallel corpus and most used Bleubased minimum error rate training   to optimize the weights of their log linear models feature functions  .",0,original
"Likelihood ratios are particularly useful when comparing common and rare events  , making them natural here given the rareness of most question categories and the frequency of contributions.",0,original
"4.6 Weakly-constrained algorithms In evaluation with ROUGE  , summaries are truncated to a target length K. Yih et al. usedastackdecodingwithaslightmodication, which allows the last sentence in a summary to be truncated to a target length.",0,original
"In order to minimize the number of decision errors at the sentence level, we have to choose the sequence of target words eI1 according to the equation  : eI1 = argmax eI1 n Pr  o = argmax eI1 n Pr Pr  o : Here, the posterior probability Pr  is decomposed into the language model probability Pr  and the string translation probability Pr .",0,original
The minimum error training   was used on the development data for parameter estimation.,0,original
"For comparing the sentence generator sample to the English sample, we compute log-likelihood statistics   on neighboring words that at least co-occur twice.",0,original
"Note that, since the FrameNet data does not include deep syntactic tree annotation, we processed the FrameNet data with Collins parser  , consequently, the experiments on FrameNet relate to automatic syntactic parse trees.",0,original
Factored models are introduced in   for better integration of morphosyntactic information.,0,original
4.2 Adaptation to Chinese  s algorithm   only resolves certain NLDs with known types of antecedents   at fstructures.,0,original
"Once this is accomplished, a variant of Powells algorithm is used to find weights that optimize BLEU score   over these hypotheses, compared to reference translations.",0,original
"  do not use a feature selection technique, employing instead an objective function which includes a Table 4 Values of Savings   for various values of a, b. ab Savings   1100,000 2,692.7 110 48.6 11100 83.5 1011,000 280.0 1,00110,000 1,263.9 10,00150,000 2,920.2 50,001100,000 4,229.8 Collins and Koo Discriminative Reranking for NLP Gaussian prior on the parameter values, thereby penalizing parameter values which become too large: a C3  arg min a  LogLossa X k0:::m a 2 k 7 2 k  28 Closed-form updates under iterative scaling are not possible with this objective function; instead, optimization algorithms such as gradient descent or conjugate gradient methods are used to estimate parameter values.",0,original
"4 Experiments 4.1 Experiment Settings A series of experiments were run to compare the performance of the three SWD models against the baseline, which is the standard phrase-based approach to SMT as elaborated in  .",0,original
The alignment of sentences can be done sufficiently well using cues such as sentence length   or cognates  .,0,original
"So far research in automatic opinion recognition has primarily addressed learning subjective language  , identifying opinionated documents   and sentences  , and discriminating between positive and negative language  .",0,original
"4 Training This section discusses how to extract our translation rules given a triple nullnull,null null ,nullnull . As we know, the traditional tree-to-string rules can be easily extracted from nullnull,null null ,nullnull  using the algorithm of Mi and Huang   2 . We would like  2  Mi and Huang   extend the tree-based rule extraction algorithm   to forest-based by introducing non-deterministic mechanism.",0,original
These alignments can be obtained from single-word models   using the available public software GIZA++  .,0,original
"A maximum entropy approach has been applied to partof-speech tagging before  , but the approach's ability to incorporate nonlocal and non-HMM-tagger-type evidence has not been fully explored.",0,original
"This set of words   corresponds to the   Characterize  , Declare  , Admire  , and Judgment verbs   and hence may have particular syntactic and semantic patterning.",0,original
"In parsing, the most relevant previous work is due to Collins  , who considered three binary features of the intervening material: did it contain   any word tokens at all,   any verbs,   any commas or colons?",0,original
This preprocessing step can be accomplished by applying the GIZA++ toolkit   that provides Viterbi alignments based on IBM Model-4.,0,original
he distortion probabilities are class-based: They depend on the word class F  of a covered source word f as well as on the word class E  of the previously generated target word e. The classes are automatically trained  ,0,original
"2.2 Brown clustering algorithm In order to provide word clusters for our experiments, we used the Brown clustering algorithm  .",0,original
2 Related Research Several researchers   have already proposed methods for binarizing synchronous grammars in the context of machine translation.,0,original
"Expectation Maximization does surprisingly well on larger data sets and is competitive with the Bayesian estimators at least in terms of cross-validation accuracy, confirming the results reported by Johnson  .",0,original
"Also, PMI-IR is useful for calculating semantic orientation and rating reviews  .",0,original
A similar view underlies the class-based methods cited in Section 2.4.3  .,0,original
"For example, sentence alignment of bilingual texts are performed just by measuring sentence lengths in words or in characters  , or by statistically estimating word level correspondences  .",0,original
"Some researchers then tried to automatically extract paraphrase rules  , which facilitates the rule-based PG methods.",0,original
"These include cube pruning  , cube growing  , early pruning  , closing spans  , coarse-to-fine methods  , pervasive laziness  , and many more.",0,original
The experiments were performed using the Wall Street Journal   corpus of the University of Pennsylvania   modified as described in   and  .,0,original
"Decoding weights are optimized using Ochs algorithm   to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature.",0,original
"This problem has been considered for instance in   for his inversion transduction grammars and has applications in the support of several tasks of automatic annotation of parallel corpora, as for instance segmentation, bracketing, phrasal and word alignment.",0,original
"Moreover, as P-DOP is formulated as an enrichment of the treebank Probabilistic Context-free Grammar  , it allows for much easier comparison to alternative approaches to statistical parsing  .",0,original
One option would be to leverage unannotated text  .,0,original
cDonald and Nivre   showed that the MSTParser and MaltParser produce different errors,0,original
"There exist many different string similarity measures: word overlap  , longest common subsequence  , Levenshteinedit distance  , word n-gramoverlap   etc. Semantic similarity measures are obtained by first computing the semantic similarity of the words containedin the sentencesbeing compared.",0,original
arzilay & Lee   also identify paraphrases in their paraphrased sentence generation system,0,original
"In this paper, we employed the Chinese word segmentation tool   that achieved about 0.93-0.96 recall/precision rates in the SIGHAN-3 word segmentation task  .",0,original
"  describe how to learn hundreds of millions of treetransformation rules from a parsed, aligned Chinese/English corpus, and Galley et al.",0,original
"Specifically, we explore the statistical term weighting features of the word generation model with Support Vector machine  , faithfully reproducing previous work as closely as possible  .",0,original
"As a final note, following Collins  , we used the averaged parameters from the training algorithm in decoding test examples in our experiments.",0,original
  of running GIZA++   in both directions and then merging the alignments using the grow-diag-final heuristic.,0,original
"There are many techniques for transliteration and back-transliteration, and they vary along a number of dimensions:  phoneme substitution vs. character substitution  heuristic vs. generative vs. discriminative models  manual vs. automatic knowledge acquisition We explore the third dimension, where we see several techniques in use:  Manually-constructed transliteration models, e.g.,  .",0,original
OS tag the text using Ratnaparkhi  ,0,original
"This model is trained on approximately 5 million sentence pairs of Hansard   and UN proceedings which have been aligned on a sentence-by-sentence basis by the methods of  , and then further aligned on a word-by-word basis by methods similar to  .",0,original
he lexicalized model proposed by Collins     was re-implemented by one of the authors,0,original
"FollowingtheworkofKooetal. andSmith and Smith  , it is possible to compute all expectations in O  through matrix inversion.",0,original
  was an implicit or selforganizing syntax model as it did not use a Treebank.,0,original
Some researchers apply shallow or partial parsers   to acquiring specific patterns from texts.,0,original
"The first-sense heuristic can be thought of as striving for maximal specificity at the risk of precluding some admissible senses  , 7Allowing for multiple fine-grained senses to be judged as appropriate in a given context goes back at least to Sussna  ; discussed more recently by, e.g., Navigli  .",0,original
We augment each labeled target instance xj with the label assigned by the source domain classifier  .,0,original
"To support this claim, first, we used the  coefficient   to assess the agreement between the classification made by FLSA and the classification from the corpora  see Table 8.",0,original
We then examined the inter-annotator reliability of the annotation by calculating the  score  .,0,original
3 Experiments and Results All experiments were conducted on the treebanks provided in the shared task  .,0,original
" , sometimes augmented by an HMM-based model or Och and Neys Model 6  .",0,original
Recently there have been some studies addressing domain adaptation from different perspectives  .,0,original
Our approach to statistical machine translation differs from the model proposed in   in that:  We compute the joint model P  from the bilanguage corpus to account for the direct mapping of the source sentence Ws into the target sentence I?VT that is ordered according to the  source language word order.,0,original
"In agreement with recent resuits on parsing with lexicalised probabilistic grammars  , we find that statistics over lexical, as opposed to structural, features best correspond to human intuitive.judgments and to experimental findings.",0,original
To reduce it we exploit the one sense per collocation property  .,0,original
"6 Related Work Other work combining supervised and unsupervised learning for parsing includes  ,  , and  .",0,original
"Between them, the phrase-based approach   allows local reordering and contiguous phrase translation.",0,original
Most of the early work in this area was based on postulating generative probability models of language that included parse structures  .,0,original
"These include scripts for creating alignments from a parallel corpus, creating phrase tables and language models, binarizing phrase tables, scripts for weight optimization using MERT  , and testing scripts.",0,original
" ), the tagger for grammatical functions works with lexical and contextual probability measures Pq .",0,original
"Obviously, these productions are not in the normal form of an ITG, but with the method described in  , they can be normalized.",0,original
ntroduction Translation of two languages with highly different morphological structures as exemplified by Arabic and English poses a challenge to successful implementation of statistical machine translation models  ,0,original
"However, the learning curve for Negra   indicates that the performance of the Collins   model is stable, even for small training sets.",0,original
"The implementation includes path-length  , information-content   and text-overlap   measures, as described in Strube & Ponzetto  .",0,original
"This is similar to Model 3 of  , but without null-generated elements or re-ordering.",0,original
"In earlier IBM translation systems   each English word would be generated by, or """"aligned to"""", exactly one formal language word.",0,original
" , Yarowsky  , and Karol & Edelman   where strong reliance on statistical techniques for the calculation of word and context similarity commands large source corpora.",0,original
"The features we used are as follows:  word posterior probability  ;  3, 4-gram target language model;  word length penalty;  Null word length penalty; Also, we use MERT   to tune the weights of confusion network.",0,original
"On the other hand,   proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences.",0,original
"Therefore, Lin and Och   introduced skip-bigram statistics for the evaluation of machine translation.",0,original
"In addition, IC is stable even for relatively low frequency words, which can be contrasted with Fano's mutual information formula recently used by Church and Hanks   to compute word cooccurrence patterns in a 44 million word corpus of Associated Press news stories.",0,original
"Furthermore, we use averaged weights   in Algorithm 1.",0,original
"Of course, many applications require smoothing of the estimated distributionsthis problem also has known solutions in MapReduce  .",0,original
Precision and recall rates were 92.4% on the same data used in  .,0,original
4.1 NER features We used the features generated by the CRF package  .,0,original
"Syntactic criteria are relevant, but clearly not decisive, as can be observed in  .",0,original
"Motivated by the fact that non-syntactic phrases make non-trivial contribution to phrase-based SMT, the tree sequencebased translation model is proposed   that uses tree sequence as the basic translation unit, rather than using single sub-tree as in the STSG.",0,original
The XEROX tagger comes with a list of built-in ending guessing rules  .,0,original
This is the same separation of arguments and adjuncts as that employed by  .,0,original
"405 PRF 1 proposed .383 .437 .408 multinomial mixture .360 .374 .367 Newman   .318 .353 .334 cosine .603 .114 .192 -skew divergence   .730 .155 .255 Lins similarity   .691 .096 .169 CBC   .981 .060 .114 Table 3: Precision, recall, and F-measure.",0,original
"Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging  , named entity recognition  , chunking  , and parsing  .",0,original
"Given the probabilistic taxonomy learning model introduced by  , we leverage on the computation of logistic regression to exploit singular value decomposition   as unsupervised feature selection.",0,original
It has been used for diverse problems such as machine translation and sense disambiguation \ .,0,original
"Table 3 shows the differences between the treebank~ utilized in   on the one hand, and in the work reported here, on the other, is Table 4 shows relevant lSFigures for Average Sentence Length   and Training Set Size, for the IBM ManuaLs Corpus, are approximate, and cz~e fzom  .",0,original
There has been a sizable amount of research on structure induction ranging fromlinearsegmentation tocontent modeling  .,0,original
Note that the predicate language representation utilized by Carmel-Tools is in the style of Davidsonian event based semantics  .,0,original
"As in tile HMM we easily can extend the dependencies in the alignment model of Model 4 easily using the word class of the previous English word E = G , or the word class of the French word F = G   .",0,original
"Other linear time algorithms for rank reduction are found in the literature  , but they are restricted to the case of synchronous context-free grammars, a strict subclass of the LCFRS with f = 2.",0,original
he prevalent use of this criterion despite repeated advice that it is unlikely to be suitable for all studies   is probably due to a desire for a simple system that can be easily applied to a scheme,0,original
"In a test set of 756 utterances containing 26 repairs  , they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a precision rate of 62%.",0,original
Previous work from   showed improvements in perplexity-oriented measures using mixture-based translation lexicon  .,0,original
"3 Haghighi and Kleins Coreference Model To gauge the performance of our model, we compare it with a Bayesian model for unsupervised coreference resolution that was recently proposed by Haghighi and Klein  .",0,original
Previous work on POS tagging of unknown words has proposed a number of features based on prefixes and suffixes and spelling cues like capitalization  .,0,original
"In an attempt to provide a quantitative evaluation of our results, for each of the 12 ambiguous words shown in table 1 we manually assigned the top 30 first-order associations to one of the two senses provided by Yarowsky  .",0,original
"At one extreme are those, exemplified by that of Wu  , that have no dependence on syntactic theory beyond the idea that natural language is hierarchical.",0,original
" , and the third type is a mixture of the first and second type, employing n-gram and grammarbased features, e.g.",0,original
"The simplest version, called Dependency Model with Valence  , has been used in isolation and in combination with other models  .",0,original
"2 The IBM Model 4 For the work described in this paper we used a modified version of the statistical machine translation tool developed in the context of the 1999 Johns HopkinsSummer Workshop  , which implements IBM translation model 4  .",0,original
"With automatic refinement it is harder to guarantee improved performance than with manual refinements   or with refinements based on direct lexicalization  , Collins  , Charniak  , etc.).",0,original
"In supervised domain adaptation  , besides the labeled source data, we have access to a comparably small, but labeled amount of target data.",0,original
"1 Empty categories however seem different, in that, for the most part, their location and existence is determined, not by observable data, but by explicitly constructed linguistic principles, which 1 Both Collins   and Higgins   are explicit about this predisposition.",0,original
"In particular, previous work   has investigated the use of Markov random fields   or log-linear models as probabilistic models with global features for parsing and other NLP tasks.",0,original
The WordNet::Similarity package   implements this distance measure and was used by the authors.,0,original
in   and Lin and Och   proposed an LCS-based automatic evaluation measure called ROUGE-L,0,original
"All 8,907 articles were tagged by the Xerox Part-ofSpeech Tagger   4.",0,original
"Table 1 reports values for the Kappa   coefficient of agreement   for Forward and Backward Functions .6 The columns in the tables read as follows: if utterance Ui has tag X, do coders agree on the subtag?",0,original
It is therefore desirable to have dedicated servers to load parts of the LM3  an idea that has been exploited by  .,0,original
"The dependency trees induced when each rewrite rule in an i-th order LCFRS distinguish a unique head can similarly be characterized by being of gap-degree i, so that i is the maximum number of gaps that may appear between contiguous substrings of any subtree in the dependency tree  .",0,original
"For these first SMT systems, translation-model probabilities at the sentence level were approximated from word-based translation models that were trained by using bilingual corpora  .",0,original
"The WSJ corpus is based on the WSJ part of the PENN TREEBANK  ; we used the first 10,000 sentences of section 2-21 as the pool set, and section 00 as evaluation set  .",0,original
These methods often involve using a statistic such as 2   or the log likelihood ratio   to create a score to measure the strength of correlation between source and target words.,0,original
"This setting is reminiscent of the problem of optimizing feature weights for reranking of candidate machine translation outputs, and we employ an optimization technique similar to that used by Och   for machine translation.",0,original
"As far as we know, language modeling always improves with additional training data, so we add data from the North American News Text Corpus     automatically parsed with the Charniak parser   to train our language model on up to 20 million additional words.",0,original
Discriminatively trained parsers that score entire trees for a given sentence have only recently been investigated  .,0,original
"This wrong translation of content words is similar to the incorrect omission reported in  , which both hurt translation adequacy.",0,original
The reported results for the full parse tree   are recall/precision of 88.1/87.5  .,0,original
"A Broad-Coverage Word Sense Tagger Dekang Lin Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada R3T 2N2 lindek@cs.umanitoba.ca Previous corpus-based Word Sense Disambiguation   algorithms   determine the meanings of polysemous words by exploiting their local contexts.",0,original
"Using linguistic principles to recover empty categories Richard CAMPBELL Microsoft Research One Microsoft Way Redmond, WA 98052 USA richcamp@microsoft.com Abstract This paper describes an algorithm for detecting empty nodes in the Penn Treebank  , finding their antecedents, and assigning them function tags, without access to lexical information such as valency.",0,original
"Thelistsmaybeused withannotation and a tuning process, such as in  , to iteratively alter feature weights and improve results.",0,original
"2  also presents the method using the averaged perceptron   3For re-ranking problems, Shen and Joshi   proposed a perceptron algorithm that also uses margins.",0,original
"??word proximity: For the web searches, Turney   uses the NEAR operator and considers only those documents that contain the adjectives within a specific proximity.",0,original
4.3 Scoring All-N Rules We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them  ).,0,original
1 Introduction Most empirical work in translation analyzes models and algorithms using BLEU   and related metrics.,0,original
"We see no good reason, however, why such text spans should necessarily be sentences, since the majority of tagging paradigms   do not attempt to parse an entire sentence and operate only in the local window of two to three tokens.",0,original
"Clearly the present research task is quite considerably harder than the parsing and tagging tasks undertaken in  , which would seem to be the closest work to ours, and any comparison between this work and ours must be approached with extreme caution.",0,original
  94.36   Table 8: The HySOL performance with the F-score optimization technique on Chunking   experiments from unlabeled data appear different from each other.,0,original
"As a result, they are being used in a variety of applications, such as question answering  , speech recognition  , language modeling  , language generation   and, most notably, machine translation  .",0,original
1 Introduction A number of empirical studies have found bracketing to be a useful type of corpus annotation  .,0,original
he third function is an original variant of the second; the fourth is original; and the fifth is prompted by the arguments of Dunning  ,0,original
"The small differences from their work are:   We used characters as the unit as we described above,   While Kazama and Torisawa   checked only the word sequences that start with a capitalized word and thus exploitedthecharacteristicsofEnglishlanguage, we checked the matching at every character,   We used a TRIE to make the look-up efcient.",0,original
Unknown words were not identified in   as a useful predictor for the benefit of self-training.,0,original
McArthur 1992; Mei et al. 1993) Classification allows a word to align with a target word using the collective translation tendency of words in the same class,0,original
"Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools  ,  ,  , or for automatic thesaurus generation  .",0,original
"When the data has distinct sub-structures, models that exploit hidden state variables are advantageous in learning  .",0,original
"This is a problem with other direct translation models, such as IBM model 1 used as a direct model rather than a channel model  .",0,original
"Following Smith and Eisner  , we adopt the view that the syntactic structure of sentences paraphrasing some sentence s should be inspired by the structure of s. Because dependency syntax is still only a crude approximation to semantic structure, we augment the model with a lexical semantics component, based on WordNet  , that models how words are probabilistically altered in generating a paraphrase.",0,original
"Our experience suggests that disjunctive LFs are an important capability, especially as one seeks to make grammars reusable across applications, and to employ domain-specific, sentence-level paraphrases  .",0,original
"Most related to our approach, Wu   used inversion transduction grammarsa synchronous context-free formalism  for this task.",0,original
"For the factored language models, a feature-based word representation was obtained by tagging the text with Rathnaparkis maximum-entropy tagger   and by stemming words using the Porter stemmer  .",0,original
The toolkit also implements suffix-array grammar extraction   and minimum error rate training  .,0,original
"Turney   argues that many NLP tasks can be formulated in terms of analogical reasoning, and he applies his PairClass algorithm to a number of problems including SAT verbal analogy tests, synonym/antonym classification and distinction between semantically similar and semantically associated words.",0,original
MET   iterative parameter estimation under IBM BLEU is performed on the development set.,0,original
Minimum error-rate   training   was applied to obtain weights   for these features.,0,original
  and Bikel and Chiang   has demonstrated the applicability of the Collins   model for Czech and Chinese,0,original
"For this we aligned 170,863 pairs of Arabic/English newswire sentences from LDC, trained a state-of-the-art syntax-based statistical machine translation system   on these sentences and alignments, and measured BLEU scores   on a separate set of 1298 newswire test sentences.",0,original
he tag propagation/elimination scheme is adopted from  ,0,original
"However, Klein and Manning   showed that for natural language and text processing tasks, conditional models are usually better than joint likelihood models.",0,original
"In general the training set is the parsed Wall Street Journal  , with few exceptions, and the size of the training samples is around 10-20,000 test cases.",0,original
"1 Data Data for 64 verbs   was collected from three corpora; The British National Corpus    , the Penn Treehank parsed version of the Brown Corpus  , and the Penn Treebank Wall Street Journal corpas    .",0,original
"Syntax-based MT approaches began with Wu  , who introduced the Inversion Transduction Grammars.",0,original
Wu   shows that parsing a binary SCFG is in O  while parsing SCFG is NP-hard in general  .,0,original
"1 Introduction Word compositions have long been a concern in lexicography , and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, e.g., parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etc. .",0,original
"For example, the Penn Treebank   provides a large corpus of syntactically annotated examples mostly from the Wall Street Journal.",0,original
We referred to the studies of  .,0,original
"After that, we used three types of methods for performing a symmetrization of IBM models: intersection, union, and refined methods  .",0,original
"6.3 Unsupervised sentiment classification Turney proposed the unsupervised method for sentiment classification  , and similar method is utilized by many other researchers  .",0,original
"Our work builds upon Turneys work on semantic orientation   and synonym learning  , in which he used a PMI-IR algorithm to measure the similarity of words and phrases based on Web queries.",0,original
"To our knowledge no systems directly address Problem 1, instead choosing to ignore the problem by using one or a small handful of reference derivations in an n-best list  , or else making local independence assumptions which side-step the issue  .",0,original
2004) use an information extraction engine to extract linguistic features from documents relevant to the target term,0,original
"We adopt the approach of Marcu and Echihabi  , using a small set of patterns to build relation models, and extend their work by re ning the training and classi cation process using parameter optimization, topic segmentation and syntactic parsing.",0,original
"By core phrases, we mean the kind of nonrecursive simplifications of the NP and VP that in the literature go by names such as noun/verb groups   or chunks, and base NPs  .",0,original
"Och and Ney   proposed Model 6, a log-linear combination of IBM translation models and HMM model.",0,original
"Goodman, 2004) and lscript22 regularization  .",0,original
For evaluation we use a state-of-the-art baseline system     which works with a log-linear interpolation of feature functions optimized by MERT  .,0,original
"The quality of the translation output is mainly evaluated using BLEU, with NIST   and METEOR   as complementary metrics.",0,original
A similar observation was made in  .,0,original
"Furthermore, it is not possible to apply the powerful """"one sense per discourse"""" property   because there is no discourse in dictionaries.",0,original
The model scaling factors M1 are trained on a development corpus according to the final recognition quality measured by the word error rate   .,0,original
"1 To train their system, R&M used a 200k-word chunk of the Penn Treebank Parsed Wall Street Journal   tagged using a transformation-based tagger   and extracted base noun phrases from its parses by selecting noun phrases that contained no nested noun phrases and further processing the data with some heuristics   to flatten the recursive structure of the parse.",0,original
"In Table 10, Baseline gives the results of the generation algorithm of  .",0,original
"2 Linguistic and Context Features 2.1 Non-terminal Labels In the original string-to-dependency model  , a translation rule is composed of a string of words and non-terminals on the source side and a well-formed dependency structure on the target side.",0,original
1 Introduction Text chunking has been one of the most interesting problems in natural language learning community since the first work of   using a machine learning method.,0,original
"To set the weights, m, we carried out minimum error rate training   using BLEU   as the objective function.",0,original
Numerous experiments have shown parallel bilingual corpora to provide a rich source of constraints for statistical analysis  .,0,original
We only describe these models briefly since full details are presented elsewhere .,0,original
The focus of much of the automatic sentiment analysis research is on identifying the affect bearing words   and on measurement approaches for sentiment  .,0,original
"We have implemented a parallel version of our GIS code using the MPICH library  , an open-source implementation of the Message Passing Interface   standard.",0,original
Previous publications on Meteor   have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics.,0,original
Many studies focus on rare words  ; butterflies are more interesting than moths.,0,original
We also present the results of \  in Table 4.,0,original
Introduction Verb subcategorizafion probabilities play an important role in both computational linguistic applications   and psycholinguisfic models of language processing  .,0,original
"The problem is typically presented in log-space, which simplifies computations, but otherwise does not change the problem due to the monotonicity of the log function   log p  = summationdisplay m m hm    Phrase-based models   are limited to the mapping of small contiguous chunks of text.",0,original
"Indeed, in the II scenario,   reported no improvement of the base parser for small   and large   seed datasets respectively.",0,original
"Then, we run GIZA++   on the corpus to obtain word alignments in both directions.",0,original
he feature weights for the overall translation models were trained using Och?s   minimum-error-rate training procedure,0,original
" , these models have non-uniform linguistically motivated structure, at present coded by hand.",0,original
Similar observations have been made in the context of tagging problems using maximum-entropy models  .,0,original
"1 Introduction ROUGE   and its linguisticallymotivated descendent, Basic Elements    , evaluate a summary by computing its overlap with a set of model   summaries; ROUGE considers lexical n-grams as the unit for comparing the overlap between summaries, while Basic Elements uses larger units of comparison based on the output of syntactic parsers.",0,original
"As a solution, a given amount of labeled training data is divided into two distinct sets, i.e., 4/5 for estimating , and the 667 remaining 1/5 for estimating   .",0,original
"We parse the data using the Collins Parser  , and then tag person, location and organization names using the Stanford Named Entity Recognizer  .",0,original
"Yarowsky   proposed such a method for word sense disambiguation, which we refer to as monolingual bootstrapping.",0,original
"Further, we can learn the channel probabilities in an unsupervised manner using a variant of the EM algorithm similar to machine translation  , and statistical language understanding  .",0,original
"Unlike stochastic approaches to part-of-speech tagging  , up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired.",0,original
"After maximum BLEU tuning   on a held-out tuning set, we evaluate translation quality on a held-out test set.",0,original
We have processed the Susanne corpus   and Penn treebank   to provide tables of word and subtree alignments.,0,original
4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis  .,0,original
Perhaps the most related is 86 learning as search optimization    .,0,original
"Maximum Entropy models have been used to express the interactions among multiple feature variables  ), but within this framework no systematic study of interactions has been proposed.",0,original
2 The Tagger We used Ratnaparkhi's maximum entropybased POS tagger  .,0,original
1 Introduction A recent development in data-driven parsing is the use of discriminative training methods  .,0,original
"7 Independently, Cutting et aL   quote a performance of 800 words per second for their part-of-speech tagger based on hidden Markov models.",0,original
"First, we trained a finitestate shallow parser on base phrases extracted from the Penn Wall St. Journal   Treebank  .",0,original
The Inversion Transduction Grammar The Inversion Transduction Grammar of Wu   can be thought as a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar productions,0,original
"We just assign these rules a constant score trained using our implementation of Minimum Error Rate Training  , which is 0.7 in our system.",0,original
"After the parser produces a semantic feature structure representation of the sentence, predicate mapping rules then match against that representation in order to produce a predicate language representation in the style of Davidsonian event based semantics  , as mentioned above.",0,original
"determining document orientation  , as in deciding if a given Subjective text expresses a Positive or a Negative opinion on its subject matter  ; 3.",0,original
"Many strategies have been proposed to integrate morphology information in SMT, including factored translation models  , adding a translation dictionary containing inflected forms to the training data  , entirely replacing surface forms by representations built on lemmas and POS tags  , morphemes learned in an unsupervised manner  , and using Porter stems and even 4-letter prefixes for word alignment  .",0,original
"  1We follow the notations in   for English-French, i.e., e  f, although our models are tested, in this paper, for English-Chinese.",0,original
"The tensor has been adapted with a straightforward extension of pointwise mutual information   for three-way cooccurrences, following equation 4.",0,original
"A comparison of the two approaches can be found in Koehn, Och, and Marcu  .",0,original
"3.2 Training Algorithm We adopt the perceptron training algorithm of Collins   to learn a discriminative model mapping from inputs xX to outputs yY , where X is the set of sentences in the training corpus and Y is the set of corresponding labelled results.",0,original
"1 Introduction Aligning parallel text, i.e. automatically setting the sentences or words in one text into correspondence with their equivalents in a translation, is a very useful preprocessing step for a range of applications, including but not limited to machine translation  , cross-language information retrieval  , dictionary creation   and induction of NLP-tools  .",0,original
The pervading method for estimating these probabilities is a simple heuristic based on the relative frequency of the phrase pair in the multi-set of the phrase pairs extracted from the word-aligned corpus  .,0,original
"The Stanford parser is representative of a large number of PTB parsers, exemplified by Collins   and Charniak  .",0,original
"1 Motivation Question Answering has emerged as a key area in natural language processing   to apply question parsing, information extraction, summarization, and language generation techniques  .",0,original
"4.4 Text chunking Next, a rule-based text chunker   is applied on the tagged sentences to further identify phrasal units, such as base noun phrases NP and verbal units VB.",0,original
"It is worth noting, however, that even in Turney   the choice of seed words is explicitly motivated by domain properties of movie reviews.",0,original
"1 Introduction The goal of this study has been to automatically extract a large set of hyponymy relations, which play a critical role in many NLP applications, such as Q&A systems  .",0,original
"These results confirm the observed figures in the previous subsection and reinforce the sight that clustering is a worthless effort for automatic paraphrase corpora construction, contrarily to what   suggest.",0,original
he translations were generated by the alignment template system of Och  ,0,original
"In practice, texts contain an enormous number of word sequences  , only a tiny fraction of which are NCCs, and it takes considerable computational effort to induce each translation model.",0,original
"1 Introduction Word Sense Disambiguation   competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions  .",0,original
We also do not require a newly added feature to be either atomic or a collocation of an atomic feature with a feature already included into the model as it was proposed in    .,0,original
"The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns  .",0,original
"The RST-DT consists of 385 documents from the Wall Street Journal, about 176,000 words, which overlaps with the Penn Wall St. Journal   Treebank  .",0,original
"The other recipe that is currently used on a large scale is to measure the performance of a parser on existing treebanks, such as WSJ  , and assume that the accuracy measure will carry over to the domains of interest.",0,original
Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system   or a hierarchical phrase system  .,0,original
"Most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into a vector-space representation of the contexts that each target term appears in  .",0,original
"  are appealing, as they have rather simple structure, modeling only NP, VP and LCP via one-level sub-tree structure with two children, in the source parse-tree  ).",0,original
"Another consequence of not generating posthead conjunctions and punctuation as first-class words is that they 19 In fact, if punctuation occurs before the head, it is not generated at alla deficiency in the parsing model that appears to be a holdover from the deficient punctuation handling in the model of Collins  .",0,original
"For transfer-learning baseline, we implement traditional SCL model    .",0,original
"Therefore, the Viterbi alignment is comlmted only approximately using the method described in  .",0,original
"Since so many concepts used in discourse are graindependent, a theory of granularity is also fundamental  .",0,original
In this paper we will describe extensions to tile Hidden-Markov alignment model froln   and compare tlmse to Models 1 4 of  .,0,original
here are two necessary ingredients to implement Ochs   training procedure,0,original
"  calculated the scores by matching the unigrams on the surface forms, stemmed forms and senses.",0,original
"Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems  .",0,original
"Word-based features are used as well, e.g. feature a75 a11a39a99a78a99a18a11 captures word-to-word translation de4On our test set,   reports a BLEU score of a100a63a101a63a102a43a103 and   reports a BLEU score of a104a89a103a63a102 a105 . pendencies similar to the use of Model a98 probabilities in  .",0,original
"4.2 Base Model II Using the translation model II  , where alignments are dependent on word/entity positions and word/entity sequence lengths, we have p  = mproductdisplay j=1 lsummationdisplay i=0 p p    where aj = i means that wj is aligned with ei.",0,original
"The machine translation literature is littered with various attempts to learn a phrase-based string transducer directly from aligned sentence pairs, doing away with the separate word alignment step  .",0,original
"Despite the above differences, since the theorems of convergence and their proof   are only dependent on the feature vectors, and not on the source of the feature definitions, the perceptron algorithm is applicable to the training of our CWS model.",0,original
"When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc. , the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by   of 49.7%.",0,original
"Most probabilistic parsing research  including, for example, work by by Collins  , and Charniak    is based on branching process models  .",0,original
"Furthermore, I based training on maximizing the conditional probability of a parse tree given a sentence, unlike most previous generative models  , which focus on maximizing the joint probability of the parse tree and the sentence.",0,original
The parameters for each phrase table were tuned separately using minimum error rate training  .,0,original
"Instead, and as suggested by Och  , we chose to maximize directly the quality of the translations produced by the system, as measured with a machine translation evaluation metric.",0,original
"5.5 Dependency validity features Like  , we extract the dependency path from the question word to the common word  , and the path from candidate answer   to the common word for each pair of question and candidate sentence using Stanford dependency parser  .",0,original
It has been argued that the reliability of a coding schema can be assessed only on the basis of judgments made by naive coders  .,0,original
"For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging  .",0,original
mith and Eisner   apply entropy regularization to dependency parsing,0,original
In this paper we apply perceptron trained HMMs originally proposed in  .,0,original
hese include the bootstrapping approach   and the context clustering approach  ,0,original
2 Perceptron Algorithm for Sequence Labeling Collins   proposed an extension of the perceptron algorithm   to sequence labeling.,0,original
All corpora are formatted in the IOB sequence representation  .,0,original
The sentences were processed with the Collins parser   to generate automatic parse trees.,0,original
t also contains tools for tuning these models using minimum error rate training   and evaluating the resulting translations using the BLEU score  ,0,original
"1 Introduction During the last decade, statistical machine translation   systems have evolved from the original word-based approach   into phrase-based translation systems  .",0,original
Several approaches for learning from both labeled and unlabeled data have been proposed   where the unlabeled data is utilised to boost the performance of the algorithm.,0,original
"The corpus used for training our models was on the order of 100,000 words, whereas that used by   was around 1,000 times this size.",0,original
"Similarly, prototype-driven learning     optimizes the joint marginal likelihood of data labeled with prototype input features for each label.",0,original
Our approach is based on earlier work on LFG semantic form extraction   and recent progress in automatically annotating the Penn-II and Penn-III Treebanks with LFG f-structures  .,0,original
"Following previous work on using global features of candidate structures to learn a ranking model  , the global   features we consider here are simple functions of the local features that capture the relationship between NP pairs.",0,original
2 Related Works Some of the most common measures of unithood include pointwise mutual information     and log-likelihood ratio  .,0,original
"220  ; they can overlap.5 Additionally, since phrase features can be any function of words and alignments, we permit features that consider phrase pairs in which a target word outside the target phrase aligns to a source word inside the source phrase, as well as phrase pairs with gaps  .",0,original
Machine translation based on a deeper analysis of the syntactic structure of a sentence has long been identified as a desirable objective in principle  ).,0,original
"is relevant to finite-state phrase-based models that use no parse trees  , tree-tostring models that rely on one parse tree  , and tree-to-tree models that rely on two parse trees  .",0,original
"A variety of other measures of semantic relatedness have been proposed, including distributional similarity measures based on co-occurrence in a body of text see   for a survey.",0,original
These instances can be retagged with their countability by using the proposed method and some kind of bootstrapping  .,0,original
1 Motivation Most of the noisy-channel-based models used in statistical machine translation     are conditional probability models.,0,original
"We computed precision, recall and error rate on the entire set for each data set.6 For an initial alignment, we used GIZA++ in both directions   or Spanish  ), and also two different combined alignments: intersection of E-to-F and F-to-E; and RA using a heuristic combination approach called grow-diag-final  .",0,original
"Specifically, Kim and Hovy   identify which political candidate is predicted to win by an opinion posted on a message board and aggregate opinions to correctly predict an election result.",0,original
"According to the statistical machine translation formalism  , the translation process is to search for the best sentence bE such that bE = arg max E P  = arg maxE P P  where P  is a translation model characterizing the correspondence between E and J; P , the English language model probability.",0,original
"In order to prove this induction step, we use the concept of order annotations  , which are strings that lexicalise the precedence relation between the nodes of a dependency tree.",0,original
"On the machine-learning side, it would be interesting to generalize the ideas of large-margin classi cation to sequence models, strengthening the results of Collins   and leading to new optimal training algorithms with stronger guarantees against over tting.",0,original
he local dependencies between sentiment labels on sentences is similar to the work of Pang and Lee   where soft local consistency constraints were created between every sentence in adocument and inference wassolved using a min-cut algorithm,0,original
"Lexical collocation functions, especially those determined statistically, have recently attracted considerable attention in computational linguistics   mainly, though not exclusively, for use in disambiguation.",0,original
"Unlexicalized methods refine the grammar in a more conservative fashion, splitting each non-terminal or pre-terminal symbol into a much smaller number of subsymbols  .",0,original
"We briefly describe the tagger   for more details), a Hidden Markov Model trained with the perceptron algorithm introduced in  .",0,original
6.2 Experimental Settings We utilize a maximum entropy   model   to design the basic classifier for WSD and TC tasks.,0,original
"Second, we discuss the work done by   who use clustering of paraphrases to induce rewriting rules.",0,original
We analyze our results using syntactic features extracted from a parse tree generated by Collins parser   and compare those to models built using features extracted from FrameNets human annotations.,0,original
"For word alignment accuracy, F-measure is reported, i.e., the harmonic mean of precision and recall against a gold-standard reference set; for translation quality, Bleu   and its variation of NIST scores are reported.",0,original
  BLEU-4   is used as the evaluation metric.,0,original
Some researchers   classify terms by similarities based on their distributional syntactic patterns.,0,original
Translation quality is reported using case-insensitive BLEU  .,0,original
"3.1 Translation Model Form We first assume the general hypergraph setting of Huang and Chiang  , namely, that derivations under our translation model form a hypergraph.",0,original
Initial estimates of lexical translation probabilities came from the IBM Model 4 translation tables produced by GIZA++  .,0,original
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment   or extraction of syntactic constructions from online dictionaries and corpora  .",0,original
"In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology  .",0,original
ur work in sentence reformulation is different from cut-and-paste summarization   in many ways,0,original
"Consider the lexical model pw , defined following Koehn et al  , with a denoting the most frequent word alignment observed for the rule in the training set.",0,original
"Finally, following Haghighi and Klein   and Johnson   we can instead insist that at most one HMM state can be mapped to any part-of-speech tag.",0,original
This procedure uses the head finding rules of  .,0,original
Most clustering schemes   use the average entropy reduction to decide when two words fall into the same cluster.,0,original
Default parameters were used for all experiments except for the numberofiterationsforGIZA++ .,0,original
The third column reports the BLEU score   along with 95% confidence interval.,0,original
"Recent work on the automatic acquisition of multilingual LFG resources from treebanks for Chinese, German and Spanish   has shown that given a suitable treebank, it is possible to automatically acquire high quality LFG resources in a very short space of time.",0,original
Feature weights vector are trained discriminatively in concert with the language model weight to maximize the BLEU   automatic evaluation metric via Minimum Error Rate Training    .,0,original
"In NLP community, it has been shown that having more data results in better performance  .",0,original
"Many reordering constraints have been used for word reorderings, such as ITG constraints  , IBM constraints   and local constraints  .",0,original
"Roget's has been used as the sense division in two recent WSD works   more or less as is, except for a small number of senses added to fill gaps.",0,original
"Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar  , and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string  .",0,original
We follow   and approximate the metrics using the sigmoid function.,0,original
"Word alignments were produced by GIZA++   with a standard training regimen of five iterations of Model 1, five iterations of the HMM Model, and five iterations of Model 4, in both directions.",0,original
"In our future work we plan to investigate the effect of more sophisticated and, probably, more accurate filtering methods   on the QA results.",0,original
  and Turney   classified sentiment polarity of reviews at the document level,0,original
"2 Bidirectional Dependency Networks When building probabilistic models for tag sequences, we often decompose the global probability of sequences using a directed graphical model   or a conditional Markov model    ).",0,original
In most recent parsing work the history consists of a small number of manually selected features  .,0,original
"The agreement on identifying the boundaries of units, using the kappa statistic discussed in Carletta  , was  = .9  ; the agreement on features   was as follows: utype:  = .76; verbed:  = .9; nite:  = .81.",0,original
"To improve raw output from decoding, Portage relies on a rescoring strategy: given a list of n-best translations from the decoder, the system reorders this list, this time using a more elaborate loglinear model, incorporating more feature functions, in addition to those of the decoding model: these typically include IBM-1 and IBM-2 model probabilities   and an IBM-1-based feature function designed to detect whether any word in one language appears to have been left without satisfactory translation in the other language; all of these feature functions can be used in both language directions, i.e. source-to-target and target-to-source.",0,original
We used minimum error rate training   and the A* beam search decoder implemented by Koehn  .,0,original
"Motivation There have been quite a number of recent papers on parallel text: Brown et al  , Chen  , Church  , Church et al  , Dagan et al  , Gale and Church  , Isabelle  , Kay and Rgsenschein  , Klavans and Tzoukermann  , Kupiec  , Matsumoto  , Ogden and Gonzales  , Shemtov  , Simard et al  , WarwickArmstrong and Russell  , Wu  .",0,original
Our learning method is an extension of Collinss perceptron-based method for sequence labeling  .,0,original
"Unlike  , one interesting idea proposed by   is to cluster similar pairs of paraphrases to apply multiplesequence alignment.",0,original
"Dunning   argues for the use of G 2 rather than X 2, based on the claim that the sampling distribution of G 2 approaches the true chi-square distribution quicker than the sampling distribution of X 2 . However, Agresti   makes the opposite claim: The sampling distributions of X 2 and G 2 get closer to chi-squared as the sample size n increasesThe convergence is quicker for X 2 than G 2 . In addition, Pedersen   questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read  , who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic.",0,original
Two major research topics in this field are Named Entity Recognition     and Word Sense Disambiguation    .,0,original
3.1 Data and Experimental Setup The data set by Pang and Lee   consists of 2000 movie reviews   from the IMDb review archive.,0,original
"For comparison purposes, we also computed the value of R 2 for fluency using the BLEU score formula given in  , for the 7 systems using the same one reference, and we obtained a similar value, 78.52%; computing the value of R 2 for fluency using the BLEU scores computed with all 4 references available yielded a lower value for R 2, 64.96%, although BLEU scores obtained with multiple references are usually considered more reliable.",0,original
"We compare against several competing systems, the first of which is based on the original IBM Model 4 for machine translation   and the HMM machine translation alignment model   as implemented in the GIZA++ package  .",0,original
"These models include a standard unlexicalized PCFG parser, a head-lexicalized parser  , and a maximum-entropy inspired parser  .",0,original
"They were based on mutual information  , conditional probabilities  , or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio  .",0,original
Recent research in open information extraction   has shown that we can extract large amounts of relational data from open-domain text with high accuracy.,0,original
"  and   do worse on the English test data than they do on German, Dutch, or French.",0,original
"It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes  .",0,original
Such methods were presented in  .,0,original
"7 This discussion could also be cast in an information theoretic framework using the notion of """"mutual information""""  , estimating the variance of the degree of match in order to find a frequency-threshold  .",0,original
"3 Tagging 3.1 Corpus To facilitate comparison with previous results, we used the UPenn Treebank corpus  .",0,original
"Themodeling approachhere describedis discriminative, and is based on maximum entropy   models, firstly applied to natural language problems in  .",0,original
"For each word pair from the antonym set, we calculated the distributional distance between each of their senses using Mohammad and Hirsts   method of concept distance along with the modified form of Lins   distributional measure  .",0,original
" ,   In addition to the usual issues involved with the complex annotation of data, we have come to terms with a number of issues that are specific to a highly inflected language with a rich history of traditional grammar.",0,original
"This conclusion is supported by the fact that true IMT is not, to our knowledge, used in most modern translator's support environments, eg  .",0,original
We propose a corpus-based method   which generates Noun Classifier Associations   to overcome the problems in classifier assignment and semantic construction of noun phrase.,0,original
"Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi   in two important ways.",0,original
ang and Lee   report 87.15% accuracy using a unigram-based SVM classifier combined with subjectivity detection,0,original
The traditional framework presented in   assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence.,0,original
"Although bi-alignments are known to exhibit high precision  , in the face of sparse annotations we use unidirectional alignments as a fallback, as has been proposed in the context of phrase-based machine translation  .",0,original
"Besides continued research on improving MT techniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages  .",0,original
"Improvements are obtained  , showing that a reranker is necessary for successful self-training in such a high-resource scenario.",0,original
"This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation  , lexicon construction for information extraction  , and named entity classification  .",0,original
"However, we do not rely on linguistic resources   or on search engines   to determine the semantic orientation, but rather rely on econometrics for this task.",0,original
"In the field of statistical analysis of natural language data, it is common to use measures of lexical association, such as the informationtheoretic measure of mutual information, to extract useful relationships between words  ).",0,original
Some work has been done on adding new terms and relations to WordNet   and FACTOTUM  .,0,original
The translation output is measured using BLEU  .,0,original
"Language modeling  , noun-clustering  , constructing syntactic rules for SMT  , and finding analogies   are examples of some of the problems where we need to compute relative frequencies.",0,original
" ) or Wikipedia  , and the contextual role played by an NP  ).",0,original
Semantic DSN: The construction of this network is inspired by  .,0,original
"Maximum Entropy Modeling As previously indicated, the weight-based scheme of L&L suggests MaxEnt modeling   as a particularly natural choice for a machine learning approach.",0,original
"Semantic features are used for classifying entities into semantic types such as name of person, organization, or place, while syntactic features characterize the kinds of dependency 5It is worth noting that the present approach can be recast into one based on constraint relaxation  .",0,original
MT output is evaluated using the standard MT evaluation metric BLEU  .,0,original
"To compare the performance of different taggers learned by different mechanisms, one can measure the precision, recall and F-measure, given by precision = # correct predictions# predicted gene mentions recall = # correct predictions# true gene mentions F-measure = a96a15a14 precision a14 recallprecision a44 recall In our evaluation, we compared the proposed semi-supervised learning approach to the state of the art supervised CRF of McDonald and Pereira  , and also to self-training  , using the same feature set as  .",0,original
nline discriminative training has already been studied by Tillmann and Zhang   and Liang et al,0,original
Responsiveness differs from other measures of summary content such as SEE coverage   and Pyramid scores   in that it does not compare a peer summary against a set of known human summaries.,0,original
"Congress of the Italian Association for Artificial Intelligence, Palermo, 1991 B. Boguraev, Building a Lexicon: the Contribution of Computers, IBM Report, T.J. Watson Research Center, 1991 M. Brent, Automatic Aquisition of Subcategorization frames from Untagged Texts, in   N. Calzolari, R. Bindi, Acquisition of Lexical Information from Corpus, in   K. W. Church, P. Hanks, Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, vol.",0,original
"We can stipulate the time line to be linearly ordered   nor in approaches employing branching futures  ), and we can stipulate it to be dense  .",0,original
The kappa statistic   has become the de facto standard to assess inter-annotator agreement.,0,original
2.1 Alignment Sentences from different systems are aligned in pairs using a modified version of the METEOR   matcher.,0,original
3.1 Paraphrase Identification A few unsupervised metrics have been applied to automatic paraphrase identification and extraction  .,0,original
"of ACL 1990  , F. Smadja, Retrieving collocations fi'cma text: XTRACT,  .",0,original
"For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by   and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by  .",0,original
"Labeled data for one domain might be used to train a initial classifier for another   domain, and then bootstrapping can be employed to learn new knowledge from the new domain  .",0,original
"Still, however, such techniques often require seeds, or prototypes  ) which are used to prune search spaces or direct learners.",0,original
"We used GIZA++   to align approximately 751,000 sentences from the German-English portion of the Europarl corpus  , in both the German-to-English and English-to-German directions.",0,original
"My guess is that the features used in e.g., the Collins   or Charniak   parsers are probably close to optimal for English Penn Treebank parsing  , but that other features might improve parsing of other languages or even other English genres.",0,original
A re nement of this model is the class-based n-gram where the words are partitioned into equivalence classes  .,0,original
"Many existing systems for statistical machine translation   implement models presented by Brown, Della Pietra, Della Pietra, and Mercer  : The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position.",0,original
In this paper we use a non-projective dependency tree CRF  .,0,original
"In order to improve sentence-level evaluation performance, several metrics have been proposed, including ROUGE-W, ROUGE-S   and METEOR  .",0,original
"2 Related Work Recently, several studies have reported about dialog systems that are capable of classifying emotions in a human-computer dialog  .",0,original
"We follow the approach of bootstrapping from a model with a narrower parameter space as is done in, e.g. Och and Ney   and Fraser and Marcu  .",0,original
"Carpuat and Wu   integrated a WSD system into a phrase-based SMT system, Pharaoh  .",0,original
We use the n-best generation scheme interleaved with  optimization as described in  .,0,original
"Only recently have robust knowledge-based methods for some of these tasks begun to appear, and their performance is still not very good, as seen above in our discussion of using WordNet as a semantic network; 33 as for checking the plausibility of a hypothesis on the basis of causal knowledge about the world, we now have a much better theoretical grasp of how such inferences could be made  , but we are still quite a long way from a general inference engine.",0,original
"As is common  , the treebank is first transformed in various ways, in order to give an accurate PCFG.",0,original
The up-arrows and down-arrows are shorthand for  ) =   where ni is the c-structure node annotated with the equation.2 Treebest := argmaxTreeP    P  := productdisplay X  Y in Tree Feats = {ai|vj )ai = vj} P    The generation model of   maximises the probability of a tree given an f-structure (Eqn.,0,original
"Different optimization techniques are available, like the Simplex algorithm or the special Minimum Error Training as described in  .",0,original
"2 Baseline Coreference Resolution System Our baseline coreference system implements the standard machine learning approach to coreference resolution  , Ponzetto and Strube  , Yang and Su  , for instance), which consists of probabilistic classification and clustering, as described below.",0,original
"tile data put tbrward by ll,amshaw and Marcus  .",0,original
2 WordNet-based semantic relatedness measures 2.1 Basic measures Two similarity/distance measures from the Perl package WordNet-Similarity written by   are used.,0,original
his results also agree with Dunning's argument about overestimation on the infrequent occurrences in which many infrequent pairs tend to get higher estimation  ,0,original
"Part-of-speech features Based on the lexical categories produced by GATE  , each token xi is classified into one of a set of coarse part-of-speech tags: noun, verb, adverb, wh-word, determiner, punctuation, etc. We do the same for neighboring words in a   window in order to assist noun phrase segmentation.",0,original
6.1.1 Nugget-Based Pyramid Evaluation For our first approach we used a nugget-based evaluation methodology  .,0,original
The automatic alignments were extracted by appending the manually aligned sentences on to the respective Europarl v3 corpora and aligning them using GIZA++   and the growfinal-diag algorithm  .,0,original
Recently several latent variable models for constituent parsing have been proposed  .,0,original
"Based on IBM Model 1 lexical parameters , providing a complementary probability for each tuple in the translation table.",0,original
"In order to calculate a global score or probability for a transition sequence, two systems used a Markov chain approach  .",0,original
Self-training   is a form of semi-supervised learning.,0,original
"Formally, by distributional similarity   of two words w 1 and w 2 , we mean that they tend to occur in similar contexts, for some definition of context; or that the set of words that w 1 tends to co-occur with is similar to the set that w 2 tends to co-occur with; or that if w 1 is substituted for w 2 in a context, its plausibility   is unchanged.",0,original
"It is true that various term extraction systems have been developed, such as Xtract  , Termight  , and TERMS   among others (cf.",0,original
Paraphrasesofthiskind have been shown to be useful in applications such as machine translation   and as an intermediate step in inventory-based classification of abstract relations  .,0,original
"Then, we used the refinement technique grow-diag-final-and   to all 50  50 bidirectional alignment pairs.",0,original
The Brill tagger comes with an English default version also trained on general-purpose language corpora like the PENN TREEBANK  .,0,original
234 ADV Non-specific adverbial BNF Benefemtive CLF It-cleft CLR 'Closely related' DIR Direction DTV Dative EXT Extent HLN Headline LGS Logical subject L0C Location MNI~ Manner N0M Nominal PRD Predicate PRP Purpose PUT Locative complement of 'put' SBJ Subject TMP Temporal TPC Topic TTL Title V0C Vocative Grammatical DTV 0.48% LGS 3.0% PRD 18.% PUT 0.26% SBJ 78.% v0c 0.025% Figure 1: Penn treebank function tags 53.% Form/Function 37.% Topicalisation 2.2% 0.25% NOM 6.8% 2.5% TPC 100% 2.2% 1.5% ADV 11.% 4.2% 9.3% BN'F 0.072% 0.026% 0.13% DIR 8.3% 3.0% 41.% EXT 3.2% 1.2% 0.013% LOC 25.% 9.2% MNR 6.2% 2.3% PI~ 5.2% 1.9% 33.% 12.% Miscellaneous 9.5% CLR 94.% 8.8% CLF 0.34% 0.03% HLN 2.6% 0.25% TTL 3.1% 0.29% Figure 2: Categories of function tags and their relative frequencies one project that used them at all:   defines certain constituents as complements based on a combination of label and function tag information.,0,original
utomatic segmentation of spontaneous speech is an open research problem in its own right  ,0,original
"The resulting intercoder reliability, measured with the Kappa statistic , is considered excellent  .",0,original
"We use the same preprocessing steps as Turian and Melamed  : during both training and testing, the parser is given text POS-tagged by the tagger of Ratnaparkhi  , with capitalization stripped and outermost punctuation removed.",0,original
"In this paper, we investigate the effectiveness of structural correspondence learning     in the domain adaptation task given by the CoNLL 2007.",0,original
"Recently, various approaches   to word sense division have been used in WSD research.",0,original
Past work   has examined the use of monolingual parallel corpora for paraphrase extraction.,0,original
"In the context of part-of-speech tagging, Klein and Manning   argue for the same distinctions made here between discriminative models and discriminative training criteria, and come to the same conclusions.",0,original
Weights on the components were assigned using the   method for max-BLEU training on the development set.,0,original
"One such relational reasoning task is the problem of compound noun interpretation, which has received a great deal of attention in recent years  .",0,original
One of the simplest models in the context of lexical triggers is the IBM model 1   which captures lexical dependencies between source and target words.,0,original
"To compute the degree of interaction between two proteins D4 BD and D4 BE, we use the information-theoretic measure of pointwise mutual information  , which is computed based on the following quantities: 1.",0,original
"4.2 Features For our experiments, we use a feature set analogous to the default feature set of Pharaoh  .",0,original
This technique is called system combination  .,0,original
Our decoder is a phrase-based multi-stack imple5 mentation of the log-linear model similar to Pharaoh  .,0,original
"Increasingly, parallel corpora are becoming available for many language pairs and SMT systems have been built for French-English, German-English, Arabic-English, Chinese-English, Hindi-English and other language pairs  ,  ,  .",0,original
"In Turney  , features are selected according to part-of-speech labels.",0,original
"Relatedness scores are computed for each pair of senses of the grammatically linked pair of words  , using the WordNet-Similarity-1.03 package and the lesk 759 option  .",0,original
"For the chunk part of the code, we adopt the Inside, Outside, and Between   encoding originating from  .",0,original
Classi er Training Set Precision Recall F-Measure Linear 10K pairs 0.837 0.774 0.804 Maximum Entropy 10K pairs 0.881 0.851 0.866 Maximum Entropy 450K pairs 0.902 0.944 0.922 Table 4: Performance of Alignment Classi er 3.2 Paraphrase Acquisition Much recent work on automatic paraphrasing   has used relatively simple statistical techniques to identify text passages that contain the same information from parallel corpora.,0,original
"As a model learning method, we adopt the maximum entropy model learning method  .",0,original
"The coreference resolution system employs a variety of lexical, semantic, distance and syntactic features .",0,original
"A quite different approach from our hypotheses testing implemented in the TREQ-AL aligner is taken by the model-estimating aligners, most of them relying on the IBM models   described in the   seminal paper.",0,original
Aggregate models based on higher-order n-grams   might be able to capture multi-word structures such as noun phrases.,0,original
These IBM models and more recent refinements   as well as algorithms that bootstrap from these models like the HMM algorithm described in   are unsupervised algorithms.,0,original
"Research prototypes exist for applications such as personal email and calendars, travel and restaurant information, and personal banking   inter alia.",0,original
"Models that support non-monotonic decoding generally include a distortion cost, such as|aibi11|where ai is the starting position of the foreign phrasefi andbi1 is the ending position of phrase fi1  .",0,original
"For example, the distancebased reordering model   allows a decoder to translate in non-monotonous order, under the constraint that the distance between two phrases translated consecutively does not exceed a limit known as distortion limit.",0,original
"We tune using Ochs algorithm   to optimize weights for the distortion model, language model, phrase translation model and word penalty over the BLEU metric  .",0,original
"For English, we have used sections 03-06 of the WSJ portion of the Penn Treebank   distributed by the Linguistic Data Consortium  , which have frequently been used to evaluate sentence boundary detection systems before; compare Section 7.",0,original
"Actually, it is defined similarly to the translation model in SMT  .",0,original
"In the second experiment, the basic learning model is Collinss   Model 2 parser, which uses a history-based learning algorithm that takes statistics directly over the treebank.",0,original
In order to avoid this problem we implemented a simple bootstrapping procedure in which a seed data set of 100 instances of each of the eight categories was hand tagged and used to generate a decision list classifier using the C4.5 algorithm   with the word frequency and topic signature features described below.,0,original
"Alternative Class-Based Estimation Methods The approaches used for comparison are that of Resnik  , subsequently developed by Ribas  , and that of Li and Abe  , which has been adopted by McCarthy  .",0,original
"For a detailed description of each algorithm, readers are referred to Collins   for the boosting algorithm, Collins   for perceptron learning, and Gao et al.",0,original
138 2 Rule Generation We start with phrase translations on the parallel training data using the techniques and implementation described in  .,0,original
"Figure 1  shows several orders of the sentence which violate this constraint.1 Previous studies have shown that if both the source and target dependency trees represent linguistic constituency, the alignment between subtrees in the two languages is very complex  .",0,original
"8 Conclusions In this paper, we developed probability models for the multi-level transfer rules presented in  , showed how to acquire larger rules that crucially condition on more syntactic context, and how to pack multiple derivations, including interpretations of unaligned words, into derivation forests.",0,original
Either pruning   or lossy randomizing approaches   may result in a compact representation for the application run-time.,0,original
"The search is based on the property that when computing sim , words that have high mutual information values 5The nominator in our metric resembles the similarity metric in  .",0,original
"4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool   and the grow-diag-final-and heuristics described in   on 948,507 sentences of the French-English part of the Europarl corpus   and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation.",0,original
These texts were not seen at the training phase which means that neither the 6Since Brill's tagger was trained on the Penn tag-set   we provided an additional mapping.,0,original
"  follow   in using the noisy channel model, by decomposing the translation decisions modeled by the translation model into different types, and inducing probability distributions via maximum likelihood estimation over each decision type.",0,original
"As Carletta   notes, many tasks in computational linguistics are simply more difficult than the content analysis classifications addressed by Krippendorff, and according to Fleiss  , kappa values between .4 and .75 indicate fair to good agreement anyhow.",0,original
  have introduced a convenient data representation for chunking by converting it to a tagging task.,0,original
The labeled corpus is the Penn Wall Street Journal treebank  .,0,original
Parse selection constitutes an important part of many parsing systems  .,0,original
ote that the algorithm from Collins   was designed for discriminatively training an HMM-style tagger,0,original
The techniques examined are Structural Correspondence Learning     and Self-training  .,0,original
"Furthermore, recent studies revealed that word clustering is useful for semi-supervised learning in NLP  .",0,original
"Recent work by Koehn and Hoang   pro514 poses factored translation models that combine feature functions to handle syntactic, morphological, and other linguistic information in a log-linear model.",0,original
"Performance also degrades when the domain of the test set differs from the domain of the training set, in part because the test set includes more OOV words and words that appear only a few times in the training set    .",0,original
"Smadja employsthez-scoreinconjunction with several heuristics andextractspredicativecollocations, 1E.g.,(Frantziet al. ,2000;Pearce,2001;Goldmanet al. , 2001;ZaiuInkpenandHirst,2002;Dias,2003;Seretanetal.",0,original
"The second model is a maximum entropy model  , since Klein and Manning   found that this model yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance.",0,original
"MTTK provides implementations of various alignment, models including IBM Model-1, Model-2  , HMM-based word-to-word alignment model   and HMM-based word-to-phrase alignment model  .",0,original
"4 Related Work 4.1 Acquisition of Classes of Instances Although some researchers focus on re-organizing or extending classes of instances already available explicitly within manually-built resources such as Wikipedia   or WordNet   or both  , a large body of previous work focuses on compiling sets of instances, not necessarily labeled, from unstructured text.",0,original
REALM uses an HMM trained on a large corpus to help determine whether the arguments of a candidate relation are of the appropriate type  .,0,original
"The number of weights wi is 3 plus the number of source languages, and they are trained using minimum error-rate training   to maximize the BLEU score   on a development set.",0,original
"The senses are: 1 material from cellulose 2 report 3 publication 4 medium for writing 5 scientific 6 publishing firm 7 physical object inventory is suitable for which application, other than cross-lingual applications where the inventory can be determined from parallel data  .",0,original
"This probability is computed using IBMs Model 1  : P  = productdisplay qQ P    P  =  Pml +Pml    Pml  = summationdisplay aA  Pml )   where the probability that the question term q is generated from answer A, P , is smoothed using the prior probability that the term q is generated from the entire collection of answers C, Pml .",0,original
"For the statistics-based approaches, Bean and Riloff   developed a statistics-based method for automatically identifying existential definite NPs which are non-anaphoric.",0,original
"Turney   applied an internet-based technique to the semantic orientation classification of phrases, whichhadoriginallybeendevelopedforwordsentiment classification.",0,original
"Thus, we obtain the following second-order model: a36a39a38a41a40 a17 a5a7 a42a4 a5a7 a44 a8 a5a57 a15a27a58 a7 a36a39a38a41a40 a17a20a15a59a42a17 a15a41a49 a7 a7 a60 a4 a5a7 a44 a8 ma61a63a62a65a64a33a66 a5a57 a15a27a58 a7a68a67 a40 a17 a15 a42a17 a15a50a49 a7 a15a50a49a51a48 a60 a4 a15a27a47a55a48 a15a50a49a54a48 a44 a11 A well-founded framework for directly modeling the posterior probability a67 a40 a17 a15 a42a17 a15a50a49 a7 a15a50a49a54a48 a60 a4 a15a12a47a55a48 a15a50a49a54a48 a44 is maximum entropy  .",0,original
"We have   Hypernym Patterns based on patterns proposed by   and  ,   Sibling Patterns which are basically conjunctions, and   Part-of Patterns based on patterns proposed by   and  .",0,original
The POS tag features were produced by rst predicting the tags with Ratnaparkhis Maximum Entropy Tagger   and then clustered by hand into a smaller number of groups based on their syntactic role.,0,original
Bilingual lexicographers can work with bilingual concordancing software that can point them to instances of any link type induced from a bitext and display these instances sorted by their contexts  .,0,original
"Note, that for our example the effect of the uniform additional conditioning on mother grammatical function has the same effect as the generation grammar transform of  , but without the need for the gramF-Struct Feats Grammar Rules {PRED=PRO,NUM=SG PER=3, GEN=FEM, SUBJ} PRP   she {PRED=PRO,NUM=SG PER=3, GEN=FEM, OBJ} PRP   her Table 7: Lexical item rules.",0,original
"Without removing them, extracted rules cannot be triggered until when completely the same strings appear in a text.4 6 Performance Evaluation We measured the performance of our robust parsing algorithm by measuring coverage and degree of overgeneration for the Wall Street Journal in the Penn Treebank  .",0,original
Figure 1 exhibits this scenario with a typical IE system such as SRI's FASTUS system  .,0,original
"There has been a growing interest in corpus-based approaches which retrieve collocations from large corpora  ,    ,  ,  ,  ,  ,  .",0,original
"Probabilistic models where probabilities are assigned to the CFG backbone of the unification-based grammar have been developed  , and the most probable parse is found by PCFG parsing.",0,original
"We set all weights by optimizing Bleu   using minimum error rate training     on a separate development set of 2,000 sentences  , and we used them in a beam search decoder   to translate 2,000 test sentences   into English.",0,original
irect feedback loops that copy a predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by Ratnaparkhi   and the memory-based tagger   proposed by Daelemans et al,0,original
of Words Person names 803 1749 Organization names 312 867 Location names 345 614 The BLEU score   with a single reference translation was deployed for evaluation.,0,original
"Such metrics have been introduced in other fields, including PARADISE   for spoken dialogue systems, BLEU   for machine translation,1 and ROUGE   for summarisation.",0,original
"Data and Parameters To facilitate comparison with previous work, we trained our models on sections 2-21 of the WSJ section of the Penn tree-bank  .",0,original
"1 Yarowsky   proposes a method for word sense   disambiguation that is based on a bootstrapping technique, which we refer to here as Monolingual Bootstrapping  .",0,original
"In the recent years, there have been a number of papers considering this or similar problems:  ,  ,  ,  .",0,original
Previous research in this area includes several models which incorporate hidden variables  .,0,original
"Finally, we are investigating several avenues for using this system output for Machine Translation   including:   aiding word alignment for other MT system  ; and   aiding the creation various MT models involving analyzed text, e.g.,  .",0,original
"Haghighi and Klein   develop a prototype-driven approach, which requires just a few prototype examples for each POS tag and exploits these labeled words to constrain the labels of their distributionally similar words.",0,original
"The training methods of LRM-F and SVM-F were useful to improve the F M -scores of LRM and SVM, as reported in  .",0,original
"With this constraint, each of these binary trees is unique and equivalent to a parse tree of the canonical-form grammar in  .",0,original
"In none of these cases did we repeat minimum-error-rate training; all these systems were trained using max-B. The metrics we tested were:  METEOR  , version 0.6,usingtheexact,Porter-stemmer,andWordNet synonmy stages, and the optimized parameters  = 0.81,  = 0.83,  = 0.28 as reported in  .",0,original
t is a variant of the batch-based Bloomier filter LM of Talbot and Brants   which we refer to as the TB-LM henceforth,0,original
Parameter Optimization We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins  ,0,original
"Various methods are based on Mutual Information between classes, see  .",0,original
This is referred to as an IOB representation  .,0,original
"In the future, we will experiment with semantic   clustering of premoditiers, using techniques such as those proposed in \ .",0,original
"To measure the coherence of sentences, we use a statistical parser Toolkit   to assign each sentence a parsers score that is the related log probability of parsing.",0,original
"1 Introduction B   was one of the first automatic evaluation metrics for machine translation  , and despite being challenged by a number of alternative metrics  , it remains the standard in the statistical MTliterature.Callison-Burchetal. havesubjected B to a searching criticism, with two realworld case studies of significant failures of correlation between B and human adequacy/fluency judgments.Bothcasesinvolvecomparisonsbetween statistical MT systems and other translation methods  , and they recommend that the use of B be restrictedtocomparisonsbetweenrelatedsystemsor different versions of the same systems.",0,original
"One of the most relevant work is  , which proposed to integrate various patterns in order to measure semantic similarity between words.",0,original
Generation of paraphrase examples was also investigated  .,0,original
1 Introduction Translational equivalence is a mathematical relation that holds between linguistic expressions with the same meaning  .,0,original
"3.2.2 Alignment Error Rate Since MT systems are usually built on the union of the two sets of alignments  , we consider the union of alignments in the two directions as well as those in each direction.",0,original
This is concordant with the usage in the maximum entropy literature  .,0,original
This second point is emphasized by the second paper on self-training for adaptation  .,0,original
"9  report that, for translation reranking, such local updates   outperform bold updates  .",0,original
"Recall that the log likelihood of our model is:  d parenleftBigg Lorig  i  2 2 2d parenrightBigg  i  2 2 2 We now introduce a new variable d = d , and plug it into the equation for log likelihood:  d parenleftBigg Lorig  i  2 2 2d parenrightBigg  i  2 2 2 The result is the model of  , where the d are the domain-specific feature weights, and d are the domain-independent feature weights.",0,original
"There have been considerable amount of efforts to improve the reordering model in SMT systems, ranging from the fundamental distance-based distortion model  , flat reordering model  , to lexicalized reordering model  , hierarchical phrase-based model  , and maximum entropy-based phrase reordering model  .",0,original
"2 Background 2.1 Phrase Table Extraction Phrasal decoders require a phrase table  , which contains bilingual phrase pairs and 17 scores indicating their utility.",0,original
1 Introduction Machine translation systems based on probabilistic translation models   are generally trained using sentence-aligned parallel corpora.,0,original
"It forms a baseline for performance evaluations, but is prone to sparse data problems  .",0,original
iscovering orientations of context dependent opinion comparative words is related to identifying domain opinion words  ,0,original
"2 Automatic Annotation Schemes Using ROUGE Similarity Measures ROUGE   is an automatic tool to determine the quality of a summary using a collection of measures ROUGE-N  , ROUGE-L, ROUGE-W and ROUGE-S which count the number of overlapping units such as n-gram, word-sequences, and word-pairs between the extract and the abstract summaries  .",0,original
"2.4 Maximum Entropy Classifier Maximum Entropy Models   seek to maximise the conditional probability of classes, given certain observations  .",0,original
"First, as originally advocated by Hobbs  , we adopt an ONTOLOGICALLY PROMISCUOUS representation that includes a wide variety of types of entities.",0,original
Two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to  .,0,original
"This program differs from earlier work in its almost complete lack of hand-crafting, relying instead on a very small corpus of Penn Wall Street Journal Tree-bank text   that has been marked with co-reference information.",0,original
"In order to overcome this, several methods are proposed, including minimally-supervised learning methods  ), and active learning methods  ).",0,original
"At this point, one can imagine estimating a linear matching model in multiple ways, including using conditional likelihood estimation, an averaged perceptron update  ), or in large-margin fashion.",0,original
"Phrases of up to 10 in length on the French side were extracted from the parallel text, and minimum-error-rate training   was 8 We can train on the full training data shown if tighter constraints are placed on rule extraction for the United Nations data.",0,original
"1 Introduction Sentiment classification is a special task of text categorization that aims to classify documents according to their opinion of, or sentiment toward a given subject    .",0,original
"Many NLP systems use the output of supervised parsers   for QA,   for IE,   for SRL,   for Textual Inference and   for MT).",0,original
methods for syntactic SMT held to this assumption in its entirety  .,0,original
"The second voting model, a maximum entropy model  , was built as Klein and Manning   found that it yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance.",0,original
The chunking classification was made by   based on the parsing information in the WSJ corpus.,0,original
Non-anaphoric definite descriptions have been detected using heuristics  ) and unsupervised methods  ).,0,original
2005 Association for Computational Linguistics Automatic identification of sentiment vocabulary: exploiting low association with known sentiment terms Michael Gamon Anthony Aue Natural Language Processing Group Natural Language Processing Group Microsoft Research Microsoft Research mgamon@microsoft.com anthaue@microsoft.com Abstract We describe an extension to the technique for the automatic identification and labeling of sentiment terms described in Turney   and Turney and Littman  ,0,original
"Och   observed, however, that the piecewiseconstant property could be exploited to characterize the function exhaustively along any line in parameter space, and hence to minimize it globally along that line.",0,original
"However, feature/class functions are traditionally deflned as binary  ; hence, explicitly incorporating frequencies would require difierent functions for each count  , making training impractical.",0,original
"Given two sentences X and Y, the WLCS score of X and Y can be computed using the similar dynamic programming procedure as stated in  .",0,original
"These algorithms are usually applied to sequential labeling or chunking, but have also been applied to parsing  , machine translation   and summarization  .",0,original
Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm  .,0,original
"In general, Agold / Acandidates; following   and   for parse reranking and   for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight i as follows: i = i + hAoraclei hA1-besti .9 Following  , after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights.",0,original
We used the MXPOST tagger   for POS annotation.,0,original
Tuning was done using Maximum BLEU hill-climbing  .,0,original
"We use   and  for straight and inverted combinations respectively, following the ITG notation  .",0,original
"a  showed that this representation tends to provide better results than the representation used in   where each word is tagged with a tag I , O , or B .",0,original
"A very common case of this in the CoNLL dataset is that of documents containing references to both The China Daily, a newspaper, and China, the country  .",0,original
"Inspired by previous work on syntax-driven semantic parsing  , and syntax-based machine translation  , we postulate that syntactically similar sentences with the same predicate also share similar semantic roles.",0,original
"4 Comparison to Related Work Previous work has compared generative and discriminative models having the same structure, such as the Naive Bayes and Logistic regression models   and other models  .",0,original
"For example, if the lexicon contains an adjective excellent, it matches every adjective phrase that includes excellent such as view-excellent etc. As a baseline, we built lexicon similarly by using polarity value of  .",0,original
"For more information on these models, please refer to Brown et al.  .",0,original
In   cooccurrence analyses augmented with syntactic parsing is used for the purpose of word classification.,0,original
"There is a vast literature on language modeling; see, e.g.,  .",0,original
The same probabilities are also included using 50 hard word classes derived from the parallel corpus using the GIZA++ mkcls utility  .,0,original
Neither   with 67% nor   with 59% noun attachment were anywhere close to this figure.,0,original
"The parsing algorithm was CKY-style parsing with beam thresholding, which was similar to ones used in  .",0,original
We perform term disambiguation on each document using an entity extractor  .,0,original
"In class-based n-gram modeling   for example, classbased n-grams are used to determine the probability of occurrence of a POS class, given its preceding classes, and the probability of a particular word, given its own POS class.",0,original
Other statistical systems that address word classification probleans do not emphasize the use of linguistic knowledge and do not deal with a specific word class\ .,0,original
1 Introduction Many different statistical tests have been proposed to measure the strength of word similarity or word association in natural language texts  .,0,original
"Like Haghighi and Klein  , we give our model information about the basic types of pronouns in English.",0,original
ur approach is related to those of Collins and Roark   and Taskar et al,0,original
"c2005 Association for Computational Linguistics Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars Dekai Wu1 Human Language Technology Center HKUST Department of Computer Science University of Science and Technology, Clear Water Bay, Hong Kong dekai@cs.ust.hk Abstract We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wus   Inversion Transduction Grammar   hypothesis.",0,original
Our approach is closely related to previous CoTraining methods  .,0,original
"5 Datasets and Evaluation We train our models with verb instances extracted from three parsed corpora:   the Wall Street Journal section of the Penn Treebank  , which was parsed by human annotators  ,   the Brown Laboratory for Linguistic Information Processing corpus of Wall Street Journal text  , which was parsed automatically by the Charniak parser  , and   the Gigaword corpus of raw newswire text  , which we parsed ourselves with the Stanford parser.",0,original
"3 Formulation Following Klein and Manning  , we use weighted directed hypergraphs   as an abstraction of the probabilistic parsing problem.",0,original
"Based on the data seen, a maximum entropy model   offers an expression   for the probability that there exists coreference C between a mention mi and a mention mj.",0,original
"1 perform the following maximization: eI1 = argmax eI1 fPr Pr g   This approach is referred to as source-channel approach to statistical MT. Sometimes, it is also referred to as the fundamental equation of statistical MT  .",0,original
"Recently, some generic methods were proposed to handle context-sensitive inference  , but these usually treat only a single aspect of context matching  .",0,original
Mean number of instances of paraphrase phenomena per sentence  .,0,original
"Previous approaches to the problem   have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of GovernmentBinding theory  , since that theory underlies the annotation.",0,original
"Penn Treebank corpus   sections 0-20 were used for training, sections 2124 for testing.",0,original
"This is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in Collins  , using the same data splits, and a larger error reduction of 12.1% from the more similar best previous loglinear model in Toutanova and Manning  .",0,original
.4 Related work and issues for future research Smadja   and van der Eijk   describe term translation methods that use bilingual texts that were aligned at the sentence level,0,original
"However, most of them do not build a NEs resource but exploit external gazetteers  ,  .",0,original
"There are many research directions, e.g., sentiment classification    , subjectivity classification    , feature/topic-based sentiment analysis   (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald.",0,original
"We build a subset S C ~"""" incrementally by iterating to adjoin a feature f E ~"""" which maximizes loglikelihood of the model to S. This algorithm is called the Basic Feature Selection  .",0,original
"4 Evaluation As our algorithm works in open domains, we were able to perform a corpus-based evaluation using the Penn WSJ Treebank  .",0,original
"One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity  .",0,original
"This is in contrast to purely statistical systems  , which are difficult to inspect and modify.",0,original
ing and McKeown   and Jing   propose a cut-and-paste strategy as a computational process of automatic abstracting and a sentence reduction strategy to produce concise sentences,0,original
"It is a reimplementation of the averaged perceptron described in  , which uses such features that it behaves like an HMM tagger and thus the standard Viterbi decoding is possible.",0,original
"A similar approach was taken in   where an unknown word was guessed given the probabilities for an unknown word to be of a particular POS, its capitalisation feature and its ending.",0,original
The MBT   180 Tagger Type Standard Trigram   MBT   Rule-based   Maximum-Entropy   Full Second-Order HMM SNOW   Voting Constraints   Full Second-Order HMM Known Unknown Overall Open/Closed Lexicon?,0,original
This framework is 211 commonly used in generation and summarization applications where the selection process is driven by multiple constraints  .,0,original
"We use the same feature processing as Haghighi and Klein  , with the addition of context features in a window of3.",0,original
2 Experimental System and Data HMIHY is a spoken dialogue system based on the notion of call routing  .,0,original
"Similarly to MERT, Tillmann and Zhang estimate the parameters of a weight vector on a linear combination of   features using a global objective function correlated with BLEU  .",0,original
3.1 Agreement for Emotion Classes The kappa coefficient of agreement is a statistic adopted by the Computational Linguistics community as a standard measure for this purpose  .,0,original
"Like the data used by  , this data was retagged by the Brill tagger in order to obtain realistic part-of-speech   tags 3.",0,original
"We chose this inverse direction since it can be integrated directly into the decoder and, thus, does not rely on a two-pass approach using reranking, as it is the case for  .",0,original
"aoife.cahill@ims.uni-stuttgart.de and van Genabith  , which do not rely on handcrafted grammars and thus can easily be ported to new languages.",0,original
"Still, it is in our next plans and part of our future work to embed in our model some of the interesting WSD approaches, like knowledgebased  , corpus-based  , or combinations with very high accuracy  .",0,original
"Parsing research has also begun to adopt discriminative methods from the Machine Learning literature, such as the perceptron   and the largemargin methods underlying Support Vector Machines  .",0,original
"Neural networks have been used in NLP in the past, e.g. for machine translation   and constituent parsing  .",0,original
The reader is referred to   for detailed information about phrase-based statistical machine translation.,0,original
"The hierarchical phrase translation pairs are extracted in a standard way  : First, the bilingual data are word alignment annotated by running GIZA++   in two directions.",0,original
"We selected 580 short sentences of length at most 50 characters from the 2002 NIST MT Evaluation test set as our development corpus and used it to tune s by maximizing the BLEU score  , and used the 2005 NIST MT Evaluation test set as our test corpus.",0,original
The classifier consists of two components based on the averaged multiclass perceptron  .,0,original
"Similarly, the sense disambiguation problem is typically attacked by comparing the distribution of the neighbors of a word's occurrence to prototypical distributions associated with each of the word's senses \ .",0,original
  use HMM-based similarity for the same purpose.,0,original
"As with the graph-based parser, we use the discriminative perceptron   to train the transition-based model  .",0,original
Their systems output was an ordered list of possible parts according to some statistical metrics  ).,0,original
.3 Systematic Sense Shift Ostler and Atkins   contend that there is strong evidence to suggest that a large part of word sense ambiguity is not arbitrary but follows regular patterns,0,original
"We believe the benefit to limiting the size of n is connected to Brown et al.s   observation that as n increases, the accuracy of an n-gram model increases, but the reliability of our parameter estimates, drawn as they must be from a limited training text, decreases.",0,original
" , extracts uninterrupted as well as interrupted collocations  .",0,original
"Other corpus-based methods determine associations between words  , which yields a basis for computing thesauri, or dictionaries of terminological expressions and multiword lexemes  .",0,original
"Inspired by the conjunction and appositive structures, Riloff and Shepherd  , Roark and Charniak   used cooccurrence statistics in local context to discover sibling relations.",0,original
"1   Introduction In the community of sentiment analysis  , transferring a sentiment classifier from one source domain to another target domain is still far from a trivial work, because sentiment expression often behaves with strong domain-specific nature.",0,original
"The features used in NLG2 are described in the next section, and the feature weights aj, obtained from the Improved Iterative Scaling algorithm  , are set to maximize the likelihood of the training data.",0,original
The current approach does not use specialized probability features as in   in any stage during decoder parameter training.,0,original
e then apply Brills rule-based tagger   and BaseNP noun phrase chunker   to extract noun phrases from these sentences,0,original
"5 Discussion As stated above, we aim to build an unsupervised generative model for named entity clustering, since such a model could be integrated with unsupervised coreference models like Haghighi and Klein   for joint inference.",0,original
"3 Domain Adaptation Following  , we present an application of structural correspondence learning   to non-projective dependency parsing  .",0,original
"Based on the observations in  , we also limited the phrase length to 3 for computational reasons.",0,original
"Furthermore, Bikel   provides evidence that lexical information   only makes a small contribution to the performance of parsing models such as Collinss  .",0,original
"1 Introduction Co-training  , and several variants of co-training, have been applied to a number of NLP problems, including word sense disambiguation  , named entity recognition  , noun phrase bracketing   and statistical parsing  .",0,original
"However, since we are interested in the word counts that correlate to w, we adopt the concept of the translation model proposed by Brown et al  .",0,original
"Following  , we describe the original parsing architecture and our modifications to it as a Dynamic Bayesian network.",0,original
3.3 Tree Transducer Grammars Syntactic machine translation   uses tree transducer grammars to translate sentences.,0,original
This sort of problem can be solved in principle by conditional variants of the Expectation-Maximization algorithm  .,0,original
"For each differently tokenized corpus, we computed word alignments by a HMM translation model   and by a word alignment refinement heuristic of grow-diagfinal  .",0,original
"In this vein, the CoNLL 2008 shared task sets the challenge of learning jointly both syntactic dependencies   ) and semantic dependencies   c2008.",0,original
5 Related work Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters   . Schmid used tile equivaleuce classes for smoothing.,0,original
"One of the main directions is sentiment classification, which classifies the whole opinion document   as positive or negative  .",0,original
"In WASP, GIZA++   is used to obtain the best alignments from the training examples.",0,original
"Haghighi and Klein s   prototype-driven approach requires just a few prototype examples for each POS tag, exploiting these labeled words to constrain the labels of their distributionally similar words when training a generative log-linear model for POS tagging.",0,original
"Our next steps will be to take a closer look at the following work: clustering of similar words  , topic signatures   and Kilgariffs sketch engine  .",0,original
"For example,   suggested two different methods: using only the alignment with the maximum probability, the so-called Viterbi alignment, or generating a set of alignments by starting from the Viterbi alignment and making changes, which keep the alignment probability high.",0,original
"1 Introduction Parsing sentences using statistical information gathered from a treebank was first examined a decade ago in   and is by now a fairly well-studied problem  ,  ,  ).",0,original
For the former we made use Decision Lists similar to Yarowskys method for Word Sense Disambiguation    .,0,original
"There are cases, though, where the labels consist of several related, but not entirely correlated, properties; examples include mention detectionthe task we are interested in, syntactic parsing with functional tag assignment  ), and, to a lesser extent, part-of-speech tagging in highly inflected languages.4 The particular type of mention detection that we are examining in this paper follows the ACE general definition: each mention in the text   is assigned three types of information:5  An entity type, describing the type of the entity it points to    An entity subtype, further detailing the type    A mention type, specifying the way the entity is realized  a mention can be named  , nominal  , or pronominal  .",0,original
"Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora  , or monolingual corpora  .",0,original
"Similar to work in image retrieval  , we cast the problem in terms of Machine Translation: given a paired corpus of words and a set of video event representations to which they refer, we make the IBM Model 1 assumption and use the expectation-maximization method to estimate the parameters  :  =+ = m j ajm jvideowordpl Cvideowordp 1 )| 1 |  This paired corpus is created from a corpus of raw video by first abstracting each video into the feature streams described above.",0,original
Both training and testing sentences were processed using Collins parser   to generate parse-tree automatically.,0,original
e adopt the similarity score proposed by Lin   as the distributional similarity score and use 50 nearest neighbours in line with McCarthy et al. For the random baseline we select one word sense at random for each word token and average the precision over 100 trials,0,original
"In our SMT system implementation, this optimization procedure is performed by using a tool developed in-house, which is based on a simplex method  , and the BLEU score   is used as a translation quality measurement.",0,original
To avoid this problem we use the concept of class proposed for a word n-gram model  .,0,original
"Our work expands on the general approach taken by   but arrives at insights similar to those of the most recent work  , albeit in a completely different manner.",0,original
"Recently, some work has been done on corpusbased paraphrase extraction  .",0,original
Previous work in statistical synchronous grammars has been limited to forms of synchronous context-free grammar  .,0,original
"As noted in Dolan  , it is possible to run a sense-clustering algorithm on several MRDs to build an integrated lexical database with more complete coverage of word senses.",0,original
Letter successor variety   models   use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries.,0,original
aume III & Marcu   argue that generic sentence fusion is an ill-defined task,0,original
"One of our goals was to use for this study only information that could be annotated reliably  , as we believe this will make our results easier to replicate.",0,original
"Starting from the parallel training corpus, provided with direct and inverted alignments, the socalled union alignment   is computed.",0,original
"Similarly, Kazama and Torisawa   used Wikipedia, particularly the first sentence of each article, to create lists of entities.",0,original
"  and Ponzetto and Strube  ), we generate training instances as follows: a positive instance is created for each anaphoric NP, NPj, and its closest antecedent, NPi; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+1, NPi+2, . . ., NPj1.",0,original
"They mention that the resulting shallow parse tags are somewhat different than those used by Ramshaw and Marcus  , but that they found no significant accuracy differences in training on either set.",0,original
The results we obtained on the CoNLL03 test set were consistent with what was reported in  .,0,original
"it constitutes a bijection between source and target sentence positions, since the intersecting alignments are functions according to their definition in   3.",0,original
"Both were 5gram models with modified Kneser-Ney smoothing, lossily compressed using a perfect-hashing scheme similar to that of Talbot and Brants   but using minimal perfect hashing  .",0,original
Its rule binarization is described in  .,0,original
It achieves 90.1% average precision/recall for sentences with maximum length 40 and 89.5% for sentences with maximum length 100 when trained and tested on the standard sections of the Wall Street Journal Treebank  .,0,original
"Wu   has been unable to find real examples of cases where hierarchical alignment would fail under these conditions, at least in fixed-word-order languages that are lightly inflected, such as English and Chinese.  .",0,original
Word alignments were generated using Model 4   using the multi-threaded implementation of GIZA++  .,0,original
See Hobbs   for explanation of this notation for events,0,original
"ROUGE has been used in meeting summarization evaluation  , yet the question remained whether ROUGE is a good metric for the meeting domain.",0,original
"However, most of the existing models have been developed for English and trained on the Penn Treebank  , which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup.",0,original
ing and McKeown   found that human summarization can be traced back to six cut-andpaste operations of a text and proposed a revision method consisting of sentence reduction and combination modules with a sentence extraction part,0,original
"We measured inter-annotator agreement with the Kappa statistic   using the 1,391 items that two annotators scored in common.",0,original
"For BPM, we run 100 averaged perceptrons   with 10 iterations for each.",0,original
It is believed that improvement can be achieved by training the generative model based on a discriminative optimization criteria   in which the training procedure is designed to maximize the conditional probability of the parses given the sentences in the training corpus.,0,original
"Then, by using evaluations similar to those described in   and by Rapp  , we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations  , and that they also serve as better predictors of the strongest human associations  .",0,original
"3ThePOS taggers The two POS taggers used in the experiments are TNT, a publicly available Markov model tagger  , and a reimplementation of the maximum entropy   tagger MXPOST  .",0,original
"For the constituent-based models, constituent information was obtained from the output of Collins parser   for English and Dubeys parser   for German.",0,original
"Two more recent investigations are by Yarowsky,  , and later, Mihalcea,  .",0,original
"As to analysis of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences  , and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available.",0,original
5.3 Evaluation Metric This paper focuses on the BLEU metric as presented in  .,0,original
"1 Introduction Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation  , and many other multi-lingual natural language processing applications.",0,original
rown et al   put forward and discussed n-gram models based on classes of words,0,original
"The supervised component is Collins parser  , trained on the Wall Street Journal.",0,original
"We experimented with two independent, arguably complementary techniques for clustering and aligning  a predicate argument based approach that extracts more general templates containing one predicate and a ROUGE   based 265 approach that can extract templates containing multiple verbs.",0,original
hese are most directly presented in Ostler and Atkins  ,0,original
"Nakagawa   and Hall   also showed the effectiveness of global features in improving the accuracy of graph-based parsing, using the approximate Gibbs sampling method and a reranking approach, respectively.",0,original
Ramshaw and Marcus  first represented base noun phrase recognition as a machine learning problem.,0,original
"In this paper, we adopt Stanford Maximum Entropy   implementation in our experiments.",0,original
The model employs a stochastic version of an inversion transduction grammar or ITG  .,0,original
"NeATS computes the likelihood ratio    to identify key concepts in unigrams, bigrams, and trigrams, and clusters these concepts in order to identify major subtopics within the main topic.",0,original
"Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate     training, proposes directions to search for a better weight-vector  to combine feature functions.",0,original
"We propose a probabilistic quasi-synchronous grammar, inspired by one proposed for machine translation  , and parameterized by mixtures of a robust nonlexical syntax/alignment model with a lexical-semantics-drivenlog-linear model.",0,original
3 Automatic Evaluation of MT Quality We utilize BLEU   for the automatic evaluation of MT quality in this paper.,0,original
"In the domain adaptation track, participants were provided with English training data from the Wall Street Journal portion of the Penn Treebank   converted to dependencies   to train parsers to be evaluated on material in the biological   and chemical   domains  , and optionally on text from the CHILDES database  .",0,original
Please note that our approach is very different from other approaches to context dependent rule selection such as   and  .,0,original
"The order of constituents, for instance, can be used to inform prototype-driven learning strategies  , which can then be applied to raw corpora.",0,original
"To accommodate multiple overlapping features on observations, some other approaches view the sequence labeling problem as a sequence of classification problems, including support vector machines     and a variety of other classifiers  .",0,original
A Viterbi alignment computed from an IBM model 4   was computed for each translation direction.,0,original
We implemented an N-gram indexer/estimator using MPI inspired by the MapReduce implementation of N-gram language model indexing/estimation pipeline  .,0,original
"We used sections 220 of the Penn Treebank 2 Wall Street Journal corpus   for training, section 22 as development set and section 23 for testing.",0,original
"In the past two or three years, this kind of verification has been attempted for other aspects of semantic interpretation: by Passonneau and Litman   for segmentation and by Kowtko, Isard, and Doherty   and Carletta et al.",0,original
"This permits us to make exact comparisons with the parser of Yamada and Matsumoto  , but also the parsers of Collins   and Charniak  , which are evaluated on the same data set in Yamada and Matsumoto  .",0,original
"For the WMT 2009 Workshop, we selected a linear combination of BLEU   and TER   as optimization criterion,  := argmax{ TER}, based on previous experience  .",0,original
The experimental results in   show a negative impact on the parsing accuracy from too long dependency relation.,0,original
The parser induction algorithm used in all of the experiments in this paper was a distribution of Collins's model 2 parser  .,0,original
"For practical reasons, the maximum size of a token was set at three for Chinese, andfour forKorean.2 Minimum error rate training   was run on each system afterwardsand BLEU score   was calculated on the test sets.",0,original
"In cases where the number of gold tags is different than the number of induced tags, some must necessarily remain unassigned  .",0,original
Example of such algorithms are   and   that use syntactic features in the vector definition.,0,original
"In this work, we use the prototype lists originally defined by Haghighi and Klein     and subsequently used by Chang et al.",0,original
"However, Dunning   pointed out that for the purpose of corpus statistics, where the sparseness of data is an important issue, it is better to use the log-likelihood ratio.",0,original
"Since adjectives have been a focus of previous work in sentiment detection  13, we looked at the performance of using adjectives alone.",0,original
"Thus, equation   can be rewritten as  = i p i iii i i eppfef )| | |  4.2 Lexical Weight Given a phrase pair ), .",0,original
TheData For our experiments we used a version of the British National Corpus parsed with the statistical parser of Collins  ,0,original
"The MLFs use reification to achieve flat expressions, very much in the line of Davidson  , Hobbs  , and Copestake et al.",0,original
  from Sections 2-21 of the Wall Street Journal   in the Penn Treebank   and its subsets.3 We then converted them into strongly equivalent HPSG-style grammars using the grammar conversion described in Section 2.1.,0,original
"On the other hand, the thesaurus-based method of Yarowsky   may suffer from loss of information   as well as data sparseness   are based on the WordNet taxonomy while classes of Brown et al.",0,original
ahill and van Genabith   attain 98.2% coverage and a BLEU score of 0.6652 on the standard WSJ test set  ,0,original
"Abney   notes important problems with the soundness of the approach when a unification-based grammar is actually determining the derivations, motivating the use of log-linear models   for parse ranking that Johnson and colleagues further developed  .",0,original
There are multiple studies   showing that the agreement between two   native speakers is about upper a15 a12a14a7 to lower a0a4a12a14a7.,0,original
he other approach selected was Yarowsky's unsupervised algorithm  ,0,original
"Firstly, we run GIZA++   on the training corpus in both directions and then apply the ogrow-diag-finalprefinement rule   to obtain many-to-many word alignments.",0,original
Ontologies are formal specifications of a conceptualization   so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat   for the purpose of linguistic annotation.,0,original
"To enable such techniques, we bring the cohesion constraint inside the ITG framework  .",0,original
"Many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++  , in both directions and by combining the results based on a heuristic  .",0,original
"2.6 Tuning procedure The Moses-based systems were tuned using the implementation of minimum error rate training     distributed with the Moses decoder, using the development corpus  .",0,original
"Since the DUC 2004 evaluation, Lin   has concluded that certain ROUGE metrics correlate better with human judgments than others, depending on the summarisation task being evaluated, i.e. single document, headline, or multi-document summarisation.",0,original
"According to the Bayes Rule, the problem is transformed into the noisy channel model paradigm, where the translation is the maximum a posteriori solution of a distribution for a channel target text given a channel source text and a prior distribution for the channel source text  .",0,original
"Previous research in automatic acquisition focuscs primarily on the use of statistical techniques, such as bilingual alignment  , or extraction of syntactic constructions from online dictionaries and corpora  .",0,original
5 Augmenting the corpus with an extracted dictionary Previous research   has shown that including word aligned data during training can improve translation results.,0,original
A single translation is then selected by finding the candidate that yields the best overall score   or by cotraining  .,0,original
"A second example of subtle language dependence comes from Dasgupta and Ng  , who present an unsupervised morphological segmentation algorithm meant to be language-independent.",0,original
"Researchers such as   and   have applied robust grammars and statistical techniques over large corpora to extract interesting noun phrases and subject-verb, verb-object pairs.",0,original
We utilize the OpenNLP MaxEnt implementation2 of the maximum entropy classification algorithm   to train classification models for each lemma and part-of-speech combination in the training corpus.,0,original
There are also research work on automatically classifying movie or product reviews as positive or negative  .,0,original
"2 Models, Search Spaces, and Errors A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization  .",0,original
his further supports the claim by Dunning   that loglikelihood ratio is much less sensitive than pmi to low counts,0,original
The first LR model for each language uses maximum entropy classification   to determine possible parser actions and their probabilities4.,0,original
The techniques used to solve this problem can be roughly classified into two main categories: those relying on pre-existing knowledge resources     and those inducing distributional properties of words from corpora  .,0,original
"Indeed, as Sinopalnikova and Pavel   note, Deese   was the first to conduct linguistic analyses of word association norms, such as measurements of semantic similarity based on his convictions that similar words evoke similar word association responsesan approach that is somewhat reminiscent of Church and Hanks   notion of mutual information.",0,original
"Following the perspective of  , a minimal set of phrase blocks with lengths   where either m or n must be greater than zero results in the following types of blocks: 1.",0,original
The first one makes use of the advances in the parsing technology or on the availability of large parsed corpora  ) to produce algorithms inspired by Hobbs' baseline method  .,0,original
"In order to determine inter-annotator agreement for the database of annotated texts, we computed kappa statistics  .",0,original
"But in fact, the issue of editing in text summarization has usually been neglected, notable exceptions being the works by Jing and McKeown   and Mani, Gates, and Bloedorn  .",0,original
Standard MET   iterative parameter estimation under IBM BLEU   is performed on the corresponding development set.,0,original
Our approach is based on earlier work on LFG semantic form extraction   and recent progress in automatically annotating the Penn-II treebank with LFG f-structures  .,0,original
"In the English all-words task of the previous SENSEVAL evaluations  , the best performing English all-words task systems with the highest WSD accuracy were trained on SEMCOR  .",0,original
"We view L2P as a tagging task that can be performed with a discriminative learning method, such as the Perceptron HMM  .",0,original
"MT output was evaluated using the standard evaluation metric BLEU  .2 The parameters of the MT System were optimized for BLEU metric on NIST MTEval2002 test sets using minimum error rate training  , and the systems were tested on NIST MTEval2003 test sets for both languages.",0,original
"Formally, the approach we take can be thought of as a noisier channel, where an observed signal o gives rise to a set of source-language strings fprime  F  and we seek e = arg maxe max fprimeF  Pr    = arg maxe max fprimeF  Pr Pr    = arg maxe max fprimeF  Pr Pr Pr .  Following Och and Ney  , we use the maximum entropy framework   to directly model the posterior Pr  with parameters tuned to minimize a loss function representing 1012 the quality only of the resulting translations.",0,original
The models are based on a maximum entropy framework  .,0,original
  use hand-coded slot-filling rules to determine the semantic roles of the arguments of a nominalization.,0,original
.1 Collocation Features The collocation features were inspired by the one-sense-per-collocation heuristic proposed by Yarowsky  ,0,original
"Table 3 compares precision, recall, and F scores for our system with CoNLL-2001 results training on sections 15-18 of the Penn Treebank and testing on section 21  .",0,original
A natural fit to the existing statistical machine translation framework  A metric that ranks a good translation high in an nbest list could be easily integrated in a minimal error rate statistical machine translation training framework  ,0,original
"But because we want the insertion state a1a16a20 to model digressions or unseen topics, we take the novel step of forcing its language model to be complementary to those of the other states by setting a2 a3a27a38 a21 a8 a8 a4 a8 a24 a26a11a28a30a29a6 a39a41a40a43a42a45a44a16a46 a1a48a47a1a50a49 a20 a2 a3 a26a17a21 a8a9a8 a4 a8 a24 a51a53a52a55a54a57a56 a21 a39a58a40a43a42a45a44a16a46 a1a59a47a1a50a49 a20 a2 a3a27a26a11a21a50a60 a4 a8 a24a30a24 a17 4Following Barzilay and Lee  , proper names, numbers and dates are   replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event.",0,original
"Thus, we can compute the source dependency LM score in the same way we compute the target side score, using a procedure described in  .",0,original
Ramshaw and Marcus   views chunking as a tagging problem.,0,original
We compared our system Lynx against a freely available phrase-based decoder Pharaoh  .,0,original
"For the Brown corpus, we based our division on  .",0,original
2 Related work Our work is closest in spirit to the two papers that inspired us   and  .,0,original
"Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSPcooc on the verb join,3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch   1.18, work at 1.14 give a better SIMS  for Equation   than the top similarities returned by  : participate 0.164, lead 0.150, return to 0.148, say 0.143, rejoin 0.142, sign 0.142, meet 0.142, include 0.141, leave 0.140, work 0.137 Other features are also weighted intuitively.",0,original
We perform a statistical analysis that provides information that complements the information provided by Cohen's Kappa  .,0,original
The methodology used   is based on the definition of a function Pr  that returns the probability that tI1 is a 835 source Transferir documentos explorados a otro directorio interaction-0 Move documents scanned to other directory interaction-1 Move s canned documents to other directory interaction-2 Move scanned documents to a nother directory interaction-3 Move scanned documents to another f older acceptance Move scanned documents to another folder Figure 1: Example of CAT system interactions to translate the Spanish source sentence into English.,0,original
"OpenCCG   and XLE  , or created semi-automatically  , or fully automatically extracted from annotated corpora, like the HPSG  , LFG   and CCG   resources derived from the Penn-II Treebank    .",0,original
Computational linguists have demonstrated that a words meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs  .,0,original
"Oncetraininghastakenplace,minimumerrorrate training   is used to tune the parameters i. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores  .",0,original
"3.2 The parsers The parsers that we chose to evaluate are the C&C CCG parser  , the Enju HPSG parser  , the RASP parser  , the Stanford parser  , and the DCU postprocessor of PTB parsers  , based on LFG and applied to the output of the Charniak and Johnson reranking parser.",0,original
We evaluated the translation quality using case-insensitive BLEU metric  .,0,original
ahill and van Genabith   note that conditioning f-structure annotated generation rules on local features (Eqn,0,original
"5.3 Experimental setup We used the Stanford Parser   for both languages, Penn English Treebank   and Penn Arabic Treebank set  .",0,original
In   the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU.,0,original
"To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures  , response time to associate synonyms and antonyms in psychological experiments  , or extracting related words automatically from corpora  .",0,original
Most previous work exploiting unsupervised training data for inferring POS tagging models has focused on semi-supervised methods in the in which the learner is provided with a lexicon specifying the possible tags for each word   or a small number of prototypes for each POS  .,0,original
"In contrast, the C&C tagger, which is based on that of Ratnaparkhi  , utilizes a wide range of features and a larger contextual window including the previous two tags and the two previous and two following words.",0,original
A number of researchers have explored learning words and phrases with prior positive or negative polarity    ).,0,original
"Lin  s similar word list for eat misses these but includes sleep   and sit  , because these have similar subjects to eat.",0,original
"It is a natural extension of the Viteri>i algorithm for those languages that do not have delimiters between words, and it can generate N-best morphological analysis hypotheses, like tree trellis search.",0,original
"Except where noted, each system was trained on 27 million words of newswire data, aligned with GIZA++   and symmetrized with the grow-diag-final-and heuristic  .",0,original
"Our system is a re-implementation of the phrase-based system described in Koehn  , and uses publicly available components for word alignment  1, decoding  2, language modeling  3 and finite-state processing  4.",0,original
"As in the work of  , each word or punctuation mark within a sentence is labeled with IOB tag together with its function type.",0,original
"Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic  .",0,original
"D. Hindle, Noun classification from predicate argument structures, in  .",0,original
"We used a loglinear model with no Markov dependency between adjacent tags,3 and trained the parameters of the model with the perceptron algorithm, with averaging to control for over-training  .",0,original
Yarowsky   has proposed automatically augmenting a small set of experimenter-supplied seed collocations   into a much larger set of training materials.,0,original
"In addition to this phrase translation probability feature, Hieros feature set includes the inverse phrase translation probability log p , lexical weights lexwt  and lexwt , which are estimates of translation quality based on word-level correspondences  , and a rule penalty allowing the model to learn a preference for longer or shorter derivations; see   for details.",0,original
Since the introduction of BLEU   the basic n-gram precision idea has been augmented in a number of ways.,0,original
"The theory has been applied in probabilistic language modeling  , natural language processing  , as well as computational vision  .",0,original
"A variety of approaches have been investigated for speech summarization, for example, maximum entropy, conditional random fields, latent semantic analysis, support vector machines, maximum marginal relevance  .",0,original
"Following our previous work  , we extract features from a sequence representation and a parse tree representation of each relation instance.",0,original
"For each, we give case-insensitive scores on version 0.6 of METEOR   with all modules enabled, version 1.04 of IBMstyle BLEU  , and version 5 of TER  .",0,original
We ran the decoder with its default settings and then used Moses implementation of minimum error rate training   to tune the feature weights on the development set.,0,original
"Because our system uses a synchronous CFG, it could be thought of as an example of syntax-based statistical machine translation  , joining a line of research   that has been fruitful but has not previously produced systems that can compete with phrase-based systems in large-scale translation tasks such as the evaluations held by NIST.",0,original
"Furthermore, the underlying decoding strategies are too time consuming for our application We therefore use a translation model based on the simple linear interpolation given in equation 2 which combines predictions of two translation models -Ms and M~ -both based on IBM-like model 2 .",0,original
"While we have observed reasonable results with both G 2 and Fisher's exact test, we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information   measure  : I  --log 2 P    P P  In  , y is the seed term and x a potential target word.",0,original
"  simplify these probability distributions, as given in Equations 9 and 10.",0,original
"Recent lexicalized stochastic parsers such as Collins  , Charniak  , and others add additional features to each constituent, the most important being the head word of the parse constituent.",0,original
"In fact, many attempts have recently been made to develop semi-supervised SOL methods  .",0,original
"In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical   and global levels  , while preserving regularities recognized by classic discourse theories  .",0,original
Rulesize and lexicalization affect parsing complexity whether the grammar is binarized explicitly   or implicitly binarized using Early-style intermediate symbols  .,0,original
Finally we trained model weights by maximizing BLEU   and set decoder optimization parameters   on a development test set of 200 held-out sentences each with a single reference translation.,0,original
This result supports the intuition in   that correlation at segment level is necessary to ensure the reliability of metrics in different situations.,0,original
"A CHECK move requests the partner to confirm information that the speaker has some reason to believe, but is not entirely sure about \ .",0,original
"The data set is same as in Section 5.1, except that we also parsed the English-side using a variant of the Collins   parser, and then extracted 24.7M tree-to-string rules using the algorithm of  .",0,original
"Among them,   have proposed a way to exploit bilingual dictionnaries at training time.",0,original
"Given a set of features and a training corpus, the MaxEnt estimation process produces a model in which every feature fi has a weight i. We can compute the conditional probability as  : p  = 1Z  productdisplay i ifi    Z  = summationdisplay o productdisplay i ifi    The conditional probability of the outcome is the product of the weights of all active features, normalized over the products of all the features.",0,original
"From this point of view, some of the measures used in the evaluation of Machine Translation systems, such as BLEU  , have been imported into the summarization task.",0,original
"Another alternative for future work is to compare the dynamic programming approach taken here with the beam-search approach of Collins and Roark  , which allows more global features.",0,original
4 Filtering with the CFG Rule Dictionary We use an idea that is similar to the method proposed by Ratnaparkhi   for partof-speech tagging.,0,original
"Based on annotation differences in the datasets   and a bug in their system  , their results are inconclusive.",0,original
The baseline score using all phrase pairs was 59.11   with a 95% confidence interval of  .,0,original
"6 Parameter Estimation From the duality of ME and maximum likelihood  , optimal parameters  for model   can be found by maximizing the log-likelihood function over a training sample {  : t = 1,,N}, i.e.:  = argmax  Nsummationdisplay t=1 logp .",0,original
SGD was recently used for NLP tasks including machine translation   and syntactic parsing  .,0,original
"There have been many statistical measures which estimate co-occurrence and the degree of association in previous researches, such as mutual information  , t-score  , dice matrix  .",0,original
Dynamic programming is applied to bilingual sentence alignment in most of previous works  .,0,original
"Different models have been presented in the literature, see for instance  .",0,original
The average senior high school student achieves 57% correct  .,0,original
"For instance, instead of representing the polarity of a term using a binary value, Mullen and Collier   use Turneys   method to assign a real value to represent term polarity and introduce a variety of numerical features that are aggregate measures of the polarity values of terms selected from the document under consideration.",0,original
"Our named entity recognizer used a maximum entropy model, built with Adwait Ratnaparkhi's tools   to label word sequences as either person, place, company or none of the above based on local cues including the surrounding words and whether honorifics  .",0,original
"  produced a corpus of 4,000 questions annotated with syntactic trees, and obtained an improvement in parsing accuracy for Bikels reimplementation of the Collins parser   by training a new parser model with a combination of newspaper and question data.",0,original
"The state of a left-corner parser does capture some linguistic generalizations  , but one might still expect sparse-data problems.",0,original
enkova and Louis   investigate how summary length and the characteristics of the input influence the summary quality in multi-document summarization,0,original
"1998; Goldman and Zhou, 2000) that has been used previously to train classifiers in applications like word-sense disambiguation  , document classification   and named-entity recognition   and apply this method to the more complex domain of statistical parsing.",0,original
294 Fraser and Marcu Measuring Word Alignment Quality for Statistical Machine Translation 2.2 Measuring Translation Performance Changes Caused By Alignment In phrased-based SMT   the knowledge sources which vary with the word alignment are the phrase translation lexicon   and some of the word level translation parameters  .,0,original
"Similar to bidirectional labelling in  , there are two learning tasking in this model.",0,original
These models can be tuned using minimum error rate training  .,0,original
he novel idea presented in Strube & Ponzetto   was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness,0,original
"Dependency models   use the parsed dependency structure of sentences to build the language model as in grammatical trigrams  , structured language models  , and dependency language models  .",0,original
In this paper we present MapReduce implementations of training algorithms for two kinds of models commonly used in statistical MT today: a phrasebased translation model   and word alignment models based on pairwise lexical translation trained using expectation maximization  .,0,original
Metrics based on syntactic similarities such as the head-word chain metric    .,0,original
" , and component weights are adjusted by minimum error rate training  .",0,original
One interesting approach to extending the current system is to introduce a statistical translation model   to filter out irrelevant translation candidates and to extract the most appropriate subpart from a long English sequence as the translation by locally aligning the Japanese and English sequences.,0,original
They are also used for inducing alignments  .,0,original
"Starting from the list of 12 ambiguous words provided by Yarowsky   which is shown in table 2, we created a concordance for each word, with the lines in the concordances each relating to a context window of 20 words.",0,original
We would expect better performance with the more accurate approximation based on variational inference proposed and evaluated in  .,0,original
"In a different work, Banerjee and Lavie   argued that the measured reliability of metrics can be due to averaging effects but might not be robust across translations.",0,original
These feature vectors and the associated parser actions are used to train maximum entropy models  .,0,original
"3.1 Experiments The model described in section 2 has been tested on the Brown corpus  , tagged with the 45 tags of the Penn treebank tagset  , which constitute the initial tagset T0.",0,original
"The output of a contextfree parser, such as that of Collins   or Charniak  , can be transformed into a sequence of shallow constituents for comparison with the output of a shallow parser.",0,original
ang and Lee   applied two different classifiers to perform sentiment annotation in two sequential steps: the first classifier separated subjective   texts from objective   ones and then they used the second classifier to classify the subjective texts into positive and negative,0,original
"Class based models   distinguish between unobserved cooccurrences using classes of """"similar"""" words.",0,original
"We can then use this newly identified set to:   use Turneys method to find the orientation for the terms and employ the terms and their scores in a classifier, and   use Turneys method to find the orientation for the terms and add the new terms as additional seed terms for a second iteration As opposed to Turney  , we do not use the web as a resource to find associations, rather we apply the method directly to in-domain data.",0,original
"We report that our parsing framework achieved high accuracy   in dependency analysis of Japanese with a combination of an underspecified HPSG-based Japanese grammar, SLUNG   and the maximum entropy method  .",0,original
  BLEU-4   is used as the evaluation metric.,0,original
"Computational linguistics research generally attaches great value to high kappa measures  , which indicate high human agreement on a particular task.",0,original
"While this approach exploits only syntactic and lexical information, Jing and McKeown   also rely on cohesion information, derived from word distribution in a text: Phrases that are linked to a local context are retained, while phrases that have no such links are dropped.",0,original
"We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and Hindles   and Lins   mutual information-based metrics.",0,original
"The method described by Kazama and Torisawa   is to rst extract the rst   noun phrase after the rst is, was, are, or were in the rst sentence of a Wikipedia article.",0,original
"Chen & Martin   introduced one of those similarity schemes, ?two-level SoftTFIDF??",0,original
"  94.17 Li and Roth   93.02 94.64 Table 2: Baseline results on three shallow parsing tasks: the NP-Chunking task  ; the CoNLL-2000 Chunking task  ; and the Li & Roth task  , which is the same as CoNLL-2000 but with more training data and a different test section.",0,original
ascaded models for fine-to-coarse sentiment analysis were studied by Pang and Lee  ,0,original
"Therefore, domain adaptation methods have recently been proposed in several NLP areas, e.g., word sense disambiguation  , statistical parsing  , and lexicalized-grammar parsing  .",0,original
"the Wall Street Journal   sections of the Penn Treebank   as training set, tests on BROWN Sections typically result in a 6-8% drop in labeled attachment scores, although the average sentence length is much shorter in BROWN than that in WSJ.",0,original
Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences  .,0,original
"To find these pairs automatically, wetrainedanon-sequentiallog-linearmodel that achieves a .902 accuracy  .",0,original
"Standard CI Model 1 training, initialised with a uniform translation table so that t  is constant for all source/target word pairs  , was run on untagged data for 10 iterations in each direction  .",0,original
"5.3 Comparison with SS-CRF-MER When we consider semi-supervised SOL methods, SS-CRF-MER   is the most competitive with HySOL, since both methods are defined based on CRFs.",0,original
The model scaling factors are optimized using minimum error rate training  .,0,original
"Experiments We have conducted a series of lexical acquisition experiments with the above algorithm on largescale English corpora, e.g., the Brown corpus \ .",0,original
unning   used a likelihood ratio to test word similarity under the assumption that the words in text have a binomial distribution,0,original
"This knowledge is represented in axiomatic form, using the notation proposed in   and previously implemented in TACITUS.",0,original
OS tag the text using the tagger of Ratnaparkhi  ,0,original
"For more detail, explanations and experiments see  .",0,original
"6 Conclusions In this paper, we showed that it is sometimes possible indeed, preferableto eliminate the initial bit of supervision in bootstrapping algorithms such as the Yarowsky   algorithm for word sense disambiguation.",0,original
Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community  .,0,original
The model is often further restricted so that each source word is assigned to exactly one target word  .,0,original
Distance from a target word is used for this purpose and it is calculated by the assumption that the target words in the context window have the same sense  .,0,original
"The window size may vary, Church and Hanks   used windows of size 2 and 5.",0,original
"They can be roughly divided into three categories: string-to-tree models  ), tree-to-string models  ), and tree-totree models  ).",0,original
"Instead, we opt to utilize the Stanford NER tagger   over the sentences in a document and annotate each NP with the NER label assigned to that mention head.",0,original
"Apart from BLEU, a standard automatic measure METEOR   was used for evaluation.",0,original
"We worked with an implementation of the log likelihood ratio   as proposed by Dunning   and two variants of the t-score, one considering all values   and one where only positive values   are kept following the results of Curran and Moens  .",0,original
2.1 Data representation We have compared four complete and three partial data representation formats for the baseNP recognition task presented in  .,0,original
"Ramshaw and Marcus   first assigned a chunk tag to each word in the sentence: I for inside a chunk, O for outside a chunk, and 240 type precision B tbr inside a chunk, but tile preceding word is in another chunk.",0,original
"Graphically speaking, parsing amounts to identifying rectangular crosslinguistic constituents  by assembling smaller rectangles that will together cover the full string spans in both dimensions  ).",0,original
  and Magerman   used the clustering algorithm of Brown et al,0,original
"We also trained a baseline model with GIZA++   following a regimen of 5 iterations of Model 1, 5 iterations of HMM, and 5 iterations of Model 4.",0,original
"Moore and Quirk   share the goal underlying our own research: improving, rather than replacing, Ochs MERT procedure.",0,original
"Brown,   uses the same bigrams and by means of a greedy algorithm forms the hierarchical clusters of words.",0,original
"This curve plots the average labeled attachment score over Basque, Chinese, English, and Turkish as a function of parsing time per token.4 Accuracy of only 1% below the maximum can be achieved with average processing time of 17 ms per token, or 60 tokens per second.5 We also refer the reader to   for more detailed analysis of the ISBN dependency parser results, where, among other things, it was shown that the ISBN model is especially accurate at modeling long dependencies.",0,original
"Typically, the local context around the 215 word to be sense-tagged is used to disambiguate the sense  , and it is common for linguistic resources such as WordNet  , or bilingual data   to be employed as well as more longrange context.",0,original
he SENSEVAL '~tan    and Schiitze    ,0,original
"Automatic subjectivity analysis would also be useful to perform flame recognition  , e-mail classification  , intellectual attribution in text  , recognition of speaker role in radio broadcasts  , review mining  , review classification  , style in generation  , and clustering documents by ideological point of view  .",0,original
ps  is increased by 1110 1/  if the hypothesis ranking k in the system s contains the arc  .,0,original
ughes and Ramage   present a lexical similarity model based on random walks on graphs derived from WordNet; Rao et al,0,original
"Training of the phrase translation model builds on top of a standard statistical word alignment over the training corpus of parallel text   for identifying corresponding word blocks, assuming no further linguistic analysis of the source or target language.",0,original
"Dunning 1993), make use of both positive and negative instances of performing a task.",0,original
"1 Introduction Current methods for large-scale information extraction take advantage of unstructured text available from either Web documents   or, more recently, logs of Web search queries   to acquire useful knowledge with minimal supervision.",0,original
"Methods such as  ,   and   employ a synchronous parsing procedure to constrain a statistical alignment.",0,original
"IBM constraints  , lexical word reordering model  , and inversion transduction grammar   constraints   belong to this type of approach.",0,original
"For details on these feature functions, please refer to  .",0,original
"We also record for each token its derivational root, using the CELEX  database.",0,original
phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation  .,0,original
The K&M model creates a packed parse forest of all possible compressions that are grammatical with respect to the Penn Treebank  .,0,original
"Note that our use of cepts differs slightly from that of  , inasmuch cepts may not overlap, according to our definition.",0,original
Two other groups of authors have independently and simultaneously proposed adaptations of the Matrix-Tree Theorem for structured inference on directed spanning trees  .,0,original
2 The Penn Discourse TreeBank   The PDTB contains annotations of discourse relations and their arguments on the Wall Street Journal corpus  .,0,original
Jiao et al. propose semi-supervised conditional random fields   that try to maximize the conditional log-likelihood on the training data and simultaneously minimize the conditional entropy of the class labels on the unlabeled data.,0,original
The learning algorithm follows the global strategy introduced in   and adapted in   for partial parsing tasks.,0,original
"Recently, many works combined a MRD and a corpus for word sense disambiguation .",0,original
"For more detail, see Chen & Martin  .",0,original
"For classi cation, we use a maximum entropy model  , from the logistic regression package in Weka  , with all default parameter settings.",0,original
"  presented results suggesting that the additional parameters required to ensure that a model is not deficient result in inferior performance, but we plan to study whether this is the case for our generative model in future work.",0,original
"Concluding Remarks Formalisms for finite-state and context-free transduction have a long history  , and such formalisms have been applied to the machine translation problem, both in the finite-state case   and the context-free case  .",0,original
"There has been considerable skepticism over whether WSD will actually improve performance of applications, but we are now starting to see improvement in performance due to WSD in cross-lingual information retrieval   and machine translation   and we hope that other applications such as question-answering, text simplication and summarisation might also benet as WSD methods improve.",0,original
"2.1 Keywords As our starting point, we calculated the keywords of the Belgian corpus with respect to the Netherlandic corpus, both on the basis of a chi-square test     and the log-likelihood ratio  .",0,original
"2.4 Comparison with Hybrid Model SSL based on a hybrid generative/discriminative approach proposed in   has been defined as a log-linear model that discriminatively combines several discriminative models, pDi , and generative models, pGj , such that: R  = producttext i p Di  i producttext j p Gj  j summationtext y producttext i p Di  i producttext j p Gj  j , where ={i}Ii=1, and ={{i}Ii=1,{j}I+Jj=I+1}.",0,original
"The rules extracted from the training bitext have the following features: a114 P andP , the latter of which is not found in the noisy-channel model, but has been previously found to be a helpful feature  ; 210 Chiang Hierarchical Phrase-Based Translation a114 the lexical weights P w  andP w  , which estimate how well the words in  translate the words in   ; 4 a114 a penalty exp  for extracted rules, analogous to Koehns phrase penalty  , which allows the model to learn a preference for longer or shorter derivations.",0,original
Some examples of POS taggers that perform reasonably well on monolingual text of each language can be found in  .,0,original
"6.2 Translation Results For the translation experiments, we report the two accuracy measures BLEU   and NIST   as well as the two error rates word error rate   and positionindependent word error rate  .",0,original
This can be seen as a simplified version of  .,0,original
"Much previous work has been done on this problem and many different methods have been used: Church's PARTS   program uses a Markov model; Bourigault   uses heuristics along with a grammar; Voutilainen's NPTool   uses a lexicon combined with a constraint grammar; Juteson and Katz   use repeated phrases; Veenstra  , Argamon, Dagan & Krymolowski  and Daelemaus, van den Bosch & Zavrel   use memory-based systems; Ramshaw & Marcus   and Cardie & Pierce   use rule-based systems.",0,original
See Collins   and Collins and Duffy   for applications of the perceptron algorithm.,0,original
"The list is obtained by first extracting the phrases with -TMP function tags from the PennTree bank, and taking the words in these phrases  .",0,original
"The problem is that with such a definition of collocations, even when improved, one identifies not only collocations but freecombining pairs frequently appearing together such as lawyer-client; doctor-hospital, as pointed out by Smadja  .",0,original
Texts are represented by dependency parse trees  ) and templates by parse sub-trees.,0,original
he line search is an extension of that described in (Och 2003; Quirk et al. 2005,0,original
"In the SUMMAC experiments, the Kappa score   for interannotator agreement was reported to be 0.38  .",0,original
"We used the procedure described in Rapp  , with the only modification being the multiplication of the loglikelihood values with a triangular function that depends on the logarithm of a words frequency.",0,original
"108 To follow related work and to focus on the effects of the language model, we present translation resultsunderaninversiontransductiongrammar  translation model   trained on the Europarl corpus  , described in detail in Section 3, and using a trigram language model.",0,original
"For example, the topics Sport and Education are important cues for differentiating mentions of Michael Jordan, which may refer to a basketball player, a computer science professor, etc. Second, as noted in the top WePS run  , feature development is important in achieving good coreference performance.",0,original
291 3.1 Level of Analysis Research on sentiment annotation is usually conducted at the text   or at the sentence levels  .,0,original
"L1 or Lasso regularization of linear models, introduced by Tibshirani  , embeds feature selection into regularization so that both an assessment of the reliability of a feature and the decision about whether to remove it are done in the same framework, and has generated a large amount of interest in the NLP community recently  .",0,original
"The tools used are the Moses toolkit   for decoding and training, GIZA++ for word alignment  , and SRILM   for language models.",0,original
"In  , the definition words were used as initial sense indicators, automatically tagging the target word examples containing them.",0,original
"Log-likelihood ratio     with respect to a large reference corpus, Web 1T 5-gram Corpus  , is used to capture the contextually relevant nouns.",0,original
2 Word-to-Word Bitext Alignment We will study the problem of aligning an English sentence to a French sentence and we will use the word alignment of the IBM statistical translation models  .,0,original
"In Hirschberg and Nakatani  , average reliability   of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is.8 or above for both read and spontaneous speech; values of at least .8 are typically viewed as representing high reliability  .",0,original
he idea of synchronous SSMT can be traced back to Wu  s Stochastic Inversion Transduction Grammars,0,original
"We then built separate English-to-Spanish and Spanish-to-English directed word alignments using IBM model 4  , combined them using the intersect+grow heuristic  , and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach  .",0,original
"Kim and Hovy   proposed a method for extracting opinion holders, topics and opinion words, in which they use semantic role labeling as an intermediate step to label opinion holders and topics.",0,original
"Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN  ) or WN in other languages  ).",0,original
"Following Zhang and Clark  , we first generated CTB 3.0 from CTB 4.0 using sentence IDs 110364.",0,original
"BLEU: BLEU score, which computes the ratio of n-gram for the translation results found in reference translations  .",0,original
"579 The MaxEnt algorithm associates a set of weights  i=1nj=1m with the features, which are estimated during the training phase to maximize the likelihood of the data  .",0,original
arowsky   studied a method for word sense disambiguation using unlabeled data,0,original
"As a result, the string translation probability can be decomposed into a lexicon probability and an alignment probability  .",0,original
The Kappa statistic   is typically used to measure the human interrater agreement.,0,original
"In comparison, we deployed the GIZA++ MT modeling tool kit, which is an implementation of the IBM Models 1 to 4  .",0,original
This implies that the complexity of structure divergence between two languages is higher than suggested in literature  .,0,original
"This problem will be solved by incorporating other resources such as thesaurus or a dictionary,orcombiningourmethodwithothermethods using external wider contexts  .",0,original
"The features we used are as follows:  Direct and inverse IBM model;  3, 4-gram target language model;  3, 4, 5-gram POS language model  ; 96  Sentence length posterior probability  ;  N-gram posterior probabilities within the NBest list  ;  Minimum Bayes Risk probability;  Length ratio between source and target sentence; The weights are optimized via MERT algorithm.",0,original
791 and score the alignment template models phrases  .,0,original
"In Machine Translation, for example, sentences are produced using application-specific decoders, inspired by work on speech recognition  , whereas in Summarization, summaries are produced as either extracts or using task-specific strategies  .",0,original
"Numerous approaches have been explored for exploiting situations where some amount of annotated data is available and a much larger amount of data exists unannotated, e.g. Marialdo's HMM part-of-speech tagger training  , Charniak's parser retraining experiment  , Yarowsky's seeds for word sense disambiguation   and Nigam et al's   topic classifier learned in part from unlabelled documents.",0,original
"High values of  fall into the minimal entropy trap, while low values ofhave no effect on the model   for an example).",0,original
A contrasting approach   relies only upon documents whose labels are unknown.,0,original
"Building on the annotations from the Wall Street Journal   portion of the Penn Treebank  , the project added several new layers of semantic annotations, such as coreference information, word senses, etc. In its first release   through the Linguistic Data Consortium  , the project manually sense-tagged more than 40,000 examples belonging to hundreds of noun and verb types with an ITA of 90%, based on a coarse-grained sense inventory, where each word has an average of only 3.2 senses.",0,original
"For METEOR, when used with its originally proposed parameter values of  , which the METEOR researchers mentioned were based on some early experimental work  , we obtain an average correlation value of 0.915, as shown in the row METEOR.",0,original
"The percentage agreement for each of the features is shown in the following table: feature percent agreement form 100% intentionality 74.9% awareness 93.5% safety 90.7% As advocated by Carletta  , we have used the Kappa coefficient   as a measure of coder agreement.",0,original
"Evaluation 8.1 Effects of Unpublished Details In this section we present the results of effectively doing a clean-room implementation of Collins parsing model, that is, using only information available in  , as shown in Table 4.",0,original
  reports a success rate of 96% disambiguating twelve words with two clear sense distinctions each one.,0,original
Statistical parsers trained on the Penn Treebank     produce trees annotated with bare phrase structure labels  .,0,original
"Some of these methods make use of prior knowledge in the form of an existing thesaurus  , while others do not rely on any prior knowledge  .",0,original
We use the GIZA++ implementation of IBM Model 4   coupled with the phrase extraction heuristics of Koehn et al.,0,original
"2 Related Work Automatic Paraphrasing and Entailment Our work is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing  .",0,original
"5 Evaluation 5.1 Datasets We used two datasets, customer reviews 1   and movie reviews 2   to evaluate sentiment classification of sentences.",0,original
It is promising to optimize the model parameters directly with respect to AER as suggested in statistical machine translation  .,0,original
"More recently, the problem has been tackled using unsupervised  ) and supervised  , Ng and Cardie  ) approaches.",0,original
"When labeled training data is available, we can use the Maximum Entropy principle   to optimize the  weights.",0,original
"Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see  .",0,original
"As our basic data source, we use 500 000 sentences from the Wikipedia XML corpus  ; this is the corpus used by Akhmatova and Dras  , and related to one used in one set of experiments by Snow et al.",0,original
Tile full description of Model 4   is rather complica.ted as there have to be considered tile cases that English words have fertility larger than one and that English words have fertility zero.,0,original
ur method was applied to 23 million words of the WSJ that were automatically tagged with Ratnaparkhi's maximum entropy tagger   and chunked with the partial parser CASS  ,0,original
"For a full derivation of the modified updates and for quite technical convergence proofs, see Collins, Schapire and Singer  .",0,original
"Given a collection of facts, ME chooses a model consistent with all the facts, but otherwise as uniform as possible  .",0,original
ichman and Schone   used a method similar to Nothman et al,0,original
  managed to extract LFG subcategorisation frames and paths linking long distance dependencies reentrancies from f-structures generated automatically for the PennII treebank trees and used them in an long distance dependency resolution algorithm to parse new text.,0,original
"For the future, the joint model would benefit from lexical weighting like that used in the standard model  .",0,original
"Since these morphological generalizations are based on the initial categorization provided by the algorithm of  , we hope that they will foster speedy convergence of HNN training.",0,original
"The usual Chinese NLP architecture first preprocesses input text through a word segmentation module  , but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English sentence.",0,original
"For example, in the IBM Models  , each word ti independently generates 0, 1, or more 2Note that we refer to t as the target sentence, even though in the source-channel model, t is the source sentence which goes through the channel model P  to produce the observed sentence s. words in the source language.",0,original
"We report results on the Boston University   Radio Speech Corpus   and Boston Directions Corpus    , two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling.",0,original
We utilize a maximum entropy   model   to design the basic classifier used in active learning for WSD.,0,original
"2.2 Xerox Tagger The Xerox Tagger 1, XT,   is a statistical tagger made by Doug Cutting, Julian Kupiec, Jan Pedersen and Penelope Sibun in Xerox PARC.",0,original
"216 The Maximum Entropy Principle   is to nd a model p = argmax pC H , which means a probability model p  that maximizes entropy H .",0,original
"In the iNeast system  , the identification of relevant terms is oriented towards multi-document summarization, and they use a likelihood ratio   which favours terms which are representative of the set of documents as opposed to the full collection.",0,original
"Denote the global feature vector for segmented sentence y with    Rd, where d is the total number of features in the model; then Score  is computed by the dot product of vector   and a parameter vector   Rd, where i is the weight for the ith feature: Score  =   841 Inputs: training examples   Initialization: set  = 0 Algorithm: for t = 1T, i = 1N calculate zi = argmaxyGEN    if zi negationslash= yi  =  +    Outputs:  Figure 1: the perceptron learning algorithm, adapted from Collins   The perceptron training algorithm is used to determine the weight values .",0,original
The boosting approach to ranking has been applied to named entity segmentation   and natural language generation  .,0,original
"This operation does not change the collection of phrases or rules extracted from a hypothesized alignment, see, for instance,  .",0,original
he optimal bilingual parsing tree for a given sentence-pair can be computed using dynamic programming   algorithm ,0,original
Baron and Hirst   extracted collocations with Xtract   and classified the collocations using the orientations of the words in the neighboring sentences.,0,original
"3 Results and Analysis Hall   shows that the oracle parsing accuracy of a k-best edge-factored MST parser is considerably higher than the one-best score of the same parser, even when k is small.",0,original
"The corpus was automatically derived from the Penn Treebank II corpus  , by means of the script chunklink.pl   that we modified to fit our purposes.",0,original
"Liu and Gildea   also pointed out that due to the limited references for every MT output, using the overlapping ratio of n-grams longer than 2 did not improve sentence level evaluation performance of BLEU.",0,original
"Word alignment was carried out by running Giza++ implementation of IBM Model 4 initialized with 5 iterations of Model 1, 5 of the HMM aligner, and 3 iterations of Model 4   in both directions and then symmetrizing using the grow-diag-final-and heuristic  .",0,original
"2 Learning algorithm The translation model is a standard linear model  , which we train using MIRA  , following Watanabe et al.",0,original
"We thus introduce a multiplier  to form the actual objective function that we minimize with respect to :4 summationdisplay iL logp,i  +  Nsummationdisplay inegationslashL H    One may regard  as a Lagrange multiplier that is used to constrain the classifiers uncertainty H to be low, as presented in the work on entropy regularization  .",0,original
"  considered some location constrains in meeting summarization evaluation, which utilizes speaker information to some extent.",0,original
"For all performance metrics, we show the 70% confidence interval with respect to the MAP baseline computed using bootstrap resampling  .",0,original
"2.2 Global Linear Models We follow the framework of Collins  , recently applied to language modeling in Roark et al.",0,original
"415-458, Wu, Dekai   Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.",0,original
he linear kernel derived from the L1 distance is the same as the difference-weighted token-based similarity measure of Weeds and Weir  ,0,original
"The approach is related, but not identical, to distributional similarity   and  ).",0,original
"Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative  .",0,original
"A first family of libraries was based on a word alignment A, produced using the Refined method described in    : we call these the A libraries.",0,original
7.3 EM algorithm The only other application of the EM algorithm to word-sense disambiguation is described in  .,0,original
"Manual processes, such as lexicon development could be automated in the future using standard contextbased, word distribution methods  , or other corpus-based techniques.",0,original
"More recently, the problem has been tackled using statistics-based   and learning-based   methods.",0,original
ne example of the 450 latter problem is the following: in   the nature of a syntactic link between two associated words is detected a posteriori,0,original
"For this purpose, we present a data-driven beam search algorithm similar to the one used in speech recognition search algorithms  .",0,original
"task  , and reported errors in the range of 26% are common.",0,original
"1 Introduction Estimating the degree of semantic relatedness between words in a text is deemed important in numerous applications: word-sense disambiguation  , story segmentation  , error correction  , summarization  .",0,original
his implementation is exactly the one proposed in Yarowsky  ,0,original
"They are generated from the training corpus via the ?diag-and??method   and smoothed using Kneser-Ney smoothing  , ??one or several n-gram language model  trained with the SRILM toolkit  ; in the baseline experiments reported here, we used a trigram model, ??a distortion model which assigns a penalty based on the number of source words which are skipped when generating a new target phrase, ??a word penalty.",0,original
"The differences between a k-best and a beam-search parser   make a running time difference unsur17 Our score of 85.8 average labeled precision and recall for sentences less than or equal to 100 on Section 23 compares to: 86.7 in Charniak  , 86.9 in Ratnaparkhi  , 88.2 in Collins  , 89.6 in Charniak  , and 89.75 in Collins  .",0,original
This is most prominently evidenced by the PENN TREEBANK  .,0,original
illmann and Zhang   use a BLEU oracle decoder for discriminative training of a local reordering model,0,original
We compare an ordinary PCFG estimated with maximum likelihood   and the HDP-PCFG estimated using the variational inference algorithm described in Section 2.6.,0,original
"1 Introduction Despite a surge in research using parallel corpora for various machine translation tasks  ,(Brown et al. 1991; Gale & Church 1993; Church 1993; Dagan & Church 1994; Simard et al. 1992; Chen 1993; Melamed 1995; Wu & Xia 1994; Wu 1994; Smadja et aI.",0,original
"3 Parse Tree Features We tagged each candidate transcription with   part-of-speech tags, using the tagger documented in Collins  ; and   a full parse tree, using the parser documented in Collins  .",0,original
"These transtbr rules are pairs of corresponding rooted substructures, where a substructure   is a connected set of arcs and nodes.",0,original
"The IBM models   benefit from a one-tomany constraint, where each target word has ex105 the tax causes unrest l' impt cause le malaise Figure 1: A cohesion constraint violation.",0,original
53 2 Bilexicalization of Inversion Transduction Grammar The Inversion Transduction Grammar of Wu   models word alignment between a translation pair of sentences by assuming a binary synchronous tree on top of both sides,0,original
"Turneys   work on classiflcation of reviews is perhaps the closest to ours.2 He applied a speciflc unsupervised learning technique based on the mutual information between document phrases and the words \excellent"""" and \poor"""", where the mutual information is computed using statistics gathered by a search engine.",0,original
Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment   andsubjectivityanalysis(Wiebeetal.,0,original
"6 Concluding remarks Our work presents a set of improvements on previous state of the art of Grammar Association: first, by providing better language models to the original system described in  ; second, by setting the technique into a rigorous statistical framework, clarifying which kind of probabilities have to be estimated by association models; third, by developing a novel and especially adequate association model: Loco C. On the other hand, though experimental results are quite good, we find them particularly relevant for pointing out directions to follow for further improvement of the Grammar Association technique.",0,original
"Model performance is evaluated using the standard BLEU metric   which measures average n-gram precision, n 4, and we use the NIST definition of the brevity penalty for multiple reference test sets.",0,original
One is to use a stochastic gradient descent   or Perceptron like online learning algorithm to optimize the weights of these features directly for MT  .,0,original
  develop a bottom-up decoder for BTG   that uses only phrase pairs.,0,original
"The progress in parsing technology are noteworthy, and in particular, various statistical dependency models have been proposed ,,  ,  .",0,original
"Here, it might be useful to relax the strict linear control regime by exploring beam search strategies, e.g. along the lines of Collins and Roark  .",0,original
"However, more recent work   has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank  , containing more than 1,000,000 words and 49,000 sentences.",0,original
"In prior research, ILP was used as a postprocessing step to remove redundancy and make other global decisions about parameters  .",0,original
"Several frameworks for finding translation equivalents or translation units in machine translation, such as \  and other example-based MT approaches, might be used to select the preferred mapping.",0,original
Various methods   of automatically acquiring synonyms have been proposed.,0,original
his second expression is similar to that used in  ,0,original
"Since there is no well-agreed to definition of what an utterance is, we instead focus on intonational phrases  , which end with an acoustically signaled boundary lone.",0,original
"Many methods have been proposed to deal with this problem, including supervised learning algorithms  , semi-supervised learning algorithms  , and unsupervised learning algorithms  .",0,original
"Also in the Penn Treebank  ,  ) a limited set of relations is placed over the constituencybased annotation in order to make explicit the   roles that the constituents play.",0,original
"We do not completely rule out the possibility that some more sophisticated, ontologically promiscuous, first-order analysis  ) might account for these kinds of monotonicity inferences.",0,original
"Comparatively,   propose to use the N-gram Overlap metric to capture similarities between sentences and automatically create paraphrase corpora.",0,original
he SPECIALIST minimal commitment parser relies on the SPECIALIST Lexicon as well as the Xerox stochastic tagger  ,0,original
"To achieve robust training, Daume III and Marcu   employed the averaged perceptron   and ALMA  .",0,original
"Instances of this work include information extraction, ontology induction and resource acquisition  .",0,original
"Koehn and Hoang   propose Factored Translation Models, which extend phrase-based statistical machine translation by allowing the integration of additional morphological features at the word level.",0,original
"Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discriminative log-linear models used for the SMT decoding   problem  .",0,original
"Recently, specific probabilistic tree-based models have been proposed not only for machine translation  , but also for This work was supported by DARPA contract F49620-001-0337 and ARDA contract MDA904-02-C-0450.",0,original
"These heuristics are extensions of those developed for phrase-based models  , and involve symmetrising two directional word alignments followed by a projection step which uses the alignments to find a mapping between source words and nodes in the target parse trees  .",0,original
"Specifically, three features are used to instantiate the templates:  POS tags on both sides: We assign POS tags using the MXPOST tagger   for English and Chinese, and Connexor for Spanish.",0,original
"Ever since its introduction in general   and in computational linguistics  , many researchers have pointed out that there are quite some problems in using  (e.g.",0,original
Typicality was measured using the log-likelihood ratio test  .,0,original
Classes can be induced directly from the corpus   or taken from a manually crafted taxonomy  .,0,original
"We tuned Pharaohs four parameters using minimum error rate training   on DEV.12 We obtained an increase of 0.8 9As in the POS features, we map each phrase pair to its majority constellation.",0,original
"We participated in the multilingual track of the CoNLL 2007 shared task  , and evaluated the system on data sets of 10 languages  .",0,original
"In addition, corpus-based stochastic modelling of lexical patterns   may provide information about word sense frequency of the kind advocated since  .",0,original
"2.2 A Perceptron-Based Edit Model In this section we present a general-purpose extension of perceptron training for sequence labeling, due to Collins  , to the problem of sequence alignment.",0,original
"These measures have, in fact, been used previously in measuring term recognition  .",0,original
t is worth noting that we observed the same relation between subjectivity detection and polarity classification accuracy as described by Pang and Lee   and Eriksson  ,0,original
"All submitted runs were evaluated with the automatic metrics: ROUGE  , which calculates the proportion of n-grams shared between the candidate summary and the reference summaries, and Basic Elements  , which compares the candidate to the models in terms of head-modifier pairs.",0,original
"In cut-and-paste summarization  , sentence combination operations were implemented manually following the study of a set of professionally written abstracts; however the particular pasting operation presented here was not implemented.",0,original
u   adopted chammls that eliminate syntactically unlikely alignments and Wang et al,0,original
"The usual recall and precision metrics   require either a test corpus previously annotated with the required information, or manual evaluation  .",0,original
"Following the evaluation methodology of Wong and Mooney  , we performed 4 runs of the standard 10-fold cross validation and report the averaged performance in this section using the standard automatic evaluation metric BLEU   and NIST  2.",0,original
"We have computed the BLEU score    , the NIST score    , the General Text Matching   F-measure    , and the METEOR measure  .",0,original
  discuss three approaches: hand-crafted rules; grammatical inference of subsequential transducers; and log-linear classifiers with bigram and trigram features used as taggers  .,0,original
"Given a manually compiled lexicon containing words and their relative frequencies Ps , the best segmentationfJ1 is the one that maximizes the joint probability of all words in the sentence, with the assumption that words are independent of each other1: fJ1 = argmax fprimeJprime1 Pr   argmax fprimeJprime1 Jprimeproductdisplay j=1 Ps , where the maximization is taken over Chinese word sequences whose character sequence is cK1 . 2.2 Translation system Once we have segmented the Chinese sentences into words, we train standard alignment models in both directions with GIZA++   using models of IBM-1  , HMM   and IBM-4  .",0,original
e used Collins   statistical parser trained on examples from the Penn Treebank to generate parses of the same format for the sentences in our data,0,original
gain we used Mohammad and Hirsts   method along with Lins   distributional measure to determine the distributional closeness of two thesaurus concepts,0,original
"In comparison we introduce 28 several metrics coefficients reported in Albrecht and Hwa   including smoothed BLEU  , METEOR  , HWCM  , and the metric proposed in Albrecht and Hwa   using the full feature set.",0,original
1 Introduction The dominance of traditional phrase-based statistical machine translation   models   has recently been challenged by the development and improvement of a number of new models that explicity take into account the syntax of the sentences being translated.,0,original
"Averaging parameters is a way to reduce overfitting for perceptron training  , and is applied to all our experiments.",0,original
"We adopted IOB   labeling  , where the rst word of an entity of class C is labeled B-C, the words in the entity are labeled I-C, and other words are labeled O.",0,original
"Dependency Analyzer PP-Attachment Resolver Root-Node Finder Base NP Chunker   = SVM, = Preference Learning Figure 2: Module layers in the system That is, we use Penn Treebanks Wall Street Journal data  .",0,original
"A la Ramshaw and Marcus  , and Kudo and Matsumato  , we use the IOB tagging style for modeling and classification.",0,original
"For an alignment model, most of these use the Aachen HMM approach  , the implementation of IBM Model 4 in GIZA++   or, more recently, the semi-supervised EMD algorithm  .",0,original
We implement some global constraints and include unary constraints which were largely imported from the list of seed words used in  .,0,original
"Using the ME principle, we can combine information from a variety of sources into the same language model  .",0,original
"We ran the baseline semisupervised system for two iterations  , and in contrast with   we found that the best symmetrization heuristic for this system was union, which is most likely due to our use of fully linked alignments which was discussed at the end of Section 3.",0,original
"Assuming that the parameters P  are known, the most likely alignment is computed by a simple dynamic-programming algorithm.1 Instead of using an Expectation-Maximization algorithm to estimate these parameters, as commonly done when performing word alignment  , we directly compute these parameters by relying on the information contained within the chunks.",0,original
"Although the BLEU   score from Finnish to English is 21.8, the score in the reverse direction is reported as 13.0 which is one of the lowest scores in 11 European languages scores  .",0,original
"In natural language processing, recent years have seen ME techniques used for sentence boundary detection, part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just a few applications  .",0,original
"To implement this method, we rst use the Stanford Named Entity Recognizer4  toidentifythesetofpersonandorganisation entities, E, from each article in the corpus.",0,original
"Once the set of features functions are selected, algorithm such as improved iterative scaling   or sequential conditional generalized iterative scaling   can be used to find the optimal parameter values of fkg and fig.",0,original
"We use eight similarity measures implemented within the WordNet::Similarity package5, described in  ; these include three measures derived from the paths between the synsets in WordNet: HSO  , LCH  , and WUP  ; three measures based on information content: RES  , LIN  , and JCN  ; the gloss-based Extended Lesk Measure LESK,  , and finally the gloss vector similarity measure VECTOR  .",0,original
"3.1 Definition The following set-up, adapted from Collins  , was used for all three discriminative training methods: 266  Training data is a set of input-output pairs.",0,original
"4.5 Hindles Measure Hindle   proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences.",0,original
"Other languagesfor which this is the case include English  , the Susanne Corpus  , and the British section of the ICE Corpus  ) and Italian   and TUT  ).",0,original
A third of the corpus is syntactically parsed as part of the Penn Treebank   2This type corresponds to Princes   inferrables.,0,original
ohnson   considers conversion to a number of different representations and discusses how this influences accuracy for nonlexicalized PCFGs,0,original
"This makes it suitable for discriminative SMT training, which is still a challenge for large parameter sets  .",0,original
"The statistical methods are based on distributional analysis  , and cluster analysis  .",0,original
Note that using stems and their synonyms as used in METEOR   could also be considered for word similarity.,0,original
Most of the work focused on seeking better word alignment for consensus-based confusion network decoding   or word-level system combination  .,0,original
"For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc. Many methods have been proposed to compute distributional similarity between words, e.g.,  ,  ,   and  .",0,original
"2.4 GermanEnglish For GermanEnglish, we additionally incorporated rule-based reordering  We parse the input using the Collins parser   and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order  .",0,original
4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text  .,0,original
"2 Syntactic-oriented evaluation metrics We investigated the following metrics oriented on the syntactic structure of a translation output:  POSBLEU The standard BLEU score   calculated on POS tags instead of words;  POSP POS n-gram precision: percentage of POS ngrams in the hypothesis which have a counterpart in the reference;  POSR Recall measure based on POS n-grams: percentage of POS n-grams in the reference which are also present in the hypothesis;  POSF POS n-gram based F-measure: takes into account all POS n-grams which have a counter29 part, both in the reference and in the hypothesis.",0,original
The second attempts to instill knowledge of collocations in the data; we use the technique described by   to compute multi-word expressions and then mark words that are commonly used as such with a feature that expresses this fact.,0,original
"Conditional probability, the log-likelihood ratio, and Resnik's   selectional association measure were also significantly correlated with plausibility ratings.",0,original
"Inspired by  s methodology which was originally designed for English and Penn-II treebank, our approach to Chinese non-local dependency recovery is based on Lexical-Functional Grammar  , a formalism that involves both phrase structure trees and predicate-argument structures.",0,original
"To quickly   evaluate this phenomenon, we trained the statistical IBM wordalignment model 4  ,1 using the GIZA++ software   for the following language pairs: ChineseEnglish, Italian English, and DutchEnglish, using the IWSLT-2006 corpus   for the first two language pairs, and the Europarl corpus   for the last one.",0,original
1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation  .,0,original
"3.2 ITG Constraints In this section, we describe the ITG constraints  .",0,original
"Collocations have been widely used for tasks such as word sense disambiguation    , information extraction    , and named-entity recognition  .",0,original
"In our case, we computed a likelihood ratio score   for all pairs of English tokens and Inuktitut substrings of length ranging from 3 to 10 characters.",0,original
he collocations have been calculated according to the method described in Church and Hanks   by moving a window on the texts,0,original
"Since most phrases appear only a few times in training data, a phrase pair translation is also evaluated by lexical weights   or term weighting   as additional features to avoid overestimation.",0,original
"Since this transform takes a probabilistic grammar as input, it can also easily accommodate horizontal and vertical Markovisation   as described by Collins   and subsequently.",0,original
"We use the following features for our rules:  sourceand target-conditioned neg-log lexical weights as described in    neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned  Counters: n.o. rule applications, n.o. target words  Flags: IsPurelyLexical  , IsPurelyAbstract  , IsXRule  , IsGlueRule 139  Penalties: rareness penalty exp ; unbalancedness penalty |MeanTargetSourceRatio  n.o. source words n.o. target words| 4 Parsing Our SynCFG rules are equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing.",0,original
"As reported previously, the standard left-corner grmninar embeds sufficient non-local infornlation in its productions to significantly improve the labelled precision and recall of its MLPs with respect to MLPs of the PCFG estimated from the untransfornmd trees  .",0,original
Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called invertedtranslationmodels  .,0,original
"For the first two tasks, all heuristics of the Pharaoh-Toolkit   as well as the refined heuristic   to combine both IBM4-alignments were tested and the best ones are shown in the tables.",0,original
"The kappa statistic   for identifying question segments is 0.68, and for linking question and answer segments given a question segment is 0.81.",0,original
"Movie-domainSubjectivityDataSet : Pang and Lee   used a collection of labeled subjective and objective sentences in their work on review classification.5 The data set contains 5000 subjective sentences, extracted from movie reviews collected from the Rotten Tomatoes web formed best.",0,original
The value of fj is calculated by Mutual Information   between xi and fj.,0,original
indle   classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs,0,original
"Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT  .",0,original
"The mapping typically is made to try to give the most favorable mapping in terms of accuracy, typically using a greedy assignment  .",0,original
"The first, Powells method, was advocated by Och   when MERT was first introduced for statistical machine translation.",0,original
"This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied  .",0,original
"Examples have been class-based D2-gram models  , smoothing techniques for structural disambiguation   and word sense disambiguation  .",0,original
1 Introduction Word alignment is an important component of a complete statistical machine translation pipeline  .,0,original
The next two methods are heuristic   in   and grow-diagonal   proposed in  .,0,original
"In order to get a better understanding of these matters, we replicate parts of the error analysis presented by McDonald and Nivre  , where parsing errors are related to different structural properties of sentences and their dependency graphs.",0,original
3 Bi-Stream HMMs for Transliteration Standard IBM translation models   can be used to obtain letter-to-letter translations.,0,original
This linear model is learned using a variant of the incremental perceptron algorithm  .,0,original
"Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules   and by computing statistical measures of lexical association  .",0,original
Our strategy for choosing heads is similar to the one in  .,0,original
"Some improvements on BOW are given by the use of dependency trees and syntactic parse trees  ,  ,  , but these, too are not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs.",0,original
"However, CHECK moves are almost always about some information which the speaker has been told \  -a description that models the backward looking functionality of a dialogue act.",0,original
For extracting simple noun phrases we first used Ramshaw and Marcuss base NP chunker  .,0,original
"Meanwhile, it is common for NP chunking tasks to represent a chunk   with two labels, the begin   and inside   of a chunk  .",0,original
Bikel and Chiang   in fact contains two parsers: one is a lexicalized probabilistic contextfree grammar   similar to  ; the other is based on statistical TAG  .,0,original
oward a Task-based Gold Standard for Evaluation of NP Chunks and Technical Terms Nina Wacholder Rutgers University nina@scils.rutgers.edu Peng Song Rutgers University psong@paul.rutgers.edu Abstract We propose a gold standard for evaluating two types of information extraction output -noun phrase   chunks   and technical terms  ,0,original
"The weights are then averaged across all iterations of the perceptron, as in  .",0,original
"The second voting model is a maximum entropy model  , since Klein and Manning   found that this model yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance.",0,original
Much research is also being directed at acquiring affect lexica automatically  .,0,original
larke and Lapata   included discourse level features in their framework to leverage context for enhancing coherence,0,original
"2.2 Automatic metrics Similarly to the Pyramid method, ROUGE   and Basic Elements   require multiple topics and model summaries to produce optimal results.",0,original
"These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following  .",0,original
"We generate POS tags using the MXPOST tagger   for English and Chinese, and Connexor for Spanish.",0,original
urney   later addressed the same problem using 8000 automatically generated patterns,0,original
"Although the above statement was made about translation problems faced by human translators, recent research   suggests that it also applies to problems in machine translation.",0,original
or placing the head the center function center    is used: the average position of the source words with which the target word e i1 is aligned,0,original
6 Related Work A description of the IBM models for statistical machine translation can be found in  .,0,original
Automated evaluation will utilize the standard DUC evaluation metric ROUGE   which representsrecallovervariousn-gramsstatisticsfrom asystem-generatedsummaryagainstasetofhumangenerated peer summaries.5 We compute ROUGE scores with and without stop words removed from peer and proposed summaries.,0,original
Pointwise mutual information   was used to measure strength of selection restrictions for instance by Church and Hanks  .,0,original
"consistency among raters who may have different levels of fluency in the source language, raters are not shown the original French or Spanish sentence  .",0,original
ch   found that such smoothing during training gives almost identical results on translation metrics,0,original
"More specifically, the work on optimizing preference factors and semantic collocations was done as part of a project on spoken language translation in which the CLE was used for analysis and generation of both English and Swedish  .",0,original
"For instance, we may find metrics which compute similarities over shallow syntactic structures/sequences  , constituency trees   and dependency trees  .",0,original
"The first solution might also introduce errors elsewhere As Ramshaw and Marcus   already noted: """"While this automatic derivation process introduced a small percentage of errors on its own, it was the only practical way both to provide the amount of training data required and to allow for fully-automatic testing"""".",0,original
All the feature weights   were trained using our implementation of Minimum Error Rate Training  .,0,original
"145 2 The Latent Variable Architecture In this section we will begin by briefly introducing the class of graphical models we will be using, Incremental Sigmoid Belief Networks  .",0,original
The tagger was tested on two corpora-the Brown corpus  ) and the Wall Street Journal corpus  .,0,original
"Proceedings of the 40th Annual Meeting of the Association for cently, semantic resources have also been used in collocation discovery  , smoothing and model estimation   and text classi cation  .",0,original
