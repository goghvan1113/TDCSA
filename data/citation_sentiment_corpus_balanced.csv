Citation_Text,Sentiment,Source
"al., 1994), compression of sentences with Automatic Translation approaches (Knight and Marcu, 2000), Hidden Markov Model (Jing and McKeown, 2000), Topic Signatures based methods (Lin and Hovy, 2000, Lacatusu et al., 2006) are among the most popular techniques that have been used in the summarization systems of this category.",1,original
"But in fact, the issue of editing in text summarization has usually been neglected, notable exceptions being the works by Jing and McKeown (2000) and Mani, Gates, and Bloedorn (1999).",1,original
"The recent approach for editing extracted text spans (Jing and McKeown, 2000) may also produce improvement for our algorithm.",1,original
"Recent comparisons of approaches that can be trained on corpora (van Halteren et al. , 1998; Volk and Schneider, 1998) have shown that in most cases statistical aproaches (Cutting et al. , 1992; Schmid, 1995; Ratnaparkhi, 1996) yield better results than finite-state, rule-based, or memory-based taggers (Brill, 1993; Daelemans et al. , 1996).",1,original
"One of the most effective taggers based on a pure HMM is that developed at Xerox (Cutting et al. , 1992).",1,original
"4.1 Complete ambiguity classes Ambiguity classes capture the relevant property we are interested in: words with the same category possibilities are grouped together.4 And ambiguity classes have been shown to be successfully employed, in a variety of ways, to improve POS tagging (e.g., Cutting et al., 1992; Daelemans et al., 1996; Dickinson, 2007; Goldberg et al., 2008; Tseng et al., 2005).",1,original
"A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993).",1,original
"(Cutting et al. , 1992) reported very high results (96% on the Brown corpus) for unsupervised POS tagging using Hidden Markov Models (HMMs) by exploiting hand-built tag dictionaries and equivalence classes.",1,original
"Stochastic models (Cutting et al. , 1992; Dermatas et al. , 1995; Brants, 2000) have been widely used in POS tagging for simplicity and language independence of the models.",1,original
"1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al. , 1992).",1,original
"It has been known for some years that good performance can be realized with partial tagging and a hidden Markov model (Cutting et al. , 1992).",1,original
"Eigenvector centrality in particular has been successfully applied to many different types of networks, including hyperlinked web pages (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al. , 2004).",1,original
"First, such a system makes use of lexical information when modeling reordering (Lopez, 2008), which has previously been shown to be useful in German-to-English translation (Koehn et al., 2008).",1,original
"(Macken et al., 2008) showed that the results for French-English were competitive to state-of-the-art alignment systems.",1,original
"Then the same system weights are applied to both IncHMM and Joint Decoding -based approaches, and the feature weights of them are trained using the max-BLEU training method proposed by Och (2003) and refined by Moore and Quirk (2008).",1,original
"1 Introduction Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation (SMT) (Galley et al., 2004; Liu et al., 2006, 2007; Zhang et al., 2007, 2008a; Mi et al., 2008; Mi and Huang 2008; Zhang et al., 2009).",1,original
"Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported.",1,original
"The fluency models hold promise for actual improvements in machine translation output quality (Zwarts and Dras, 2008).",1,original
"This approach took inspiration from the pioneering work by (Dolan 1994), but it is also fundamentally different, because instead of grouping similar senses together, the CoreLex approach groups together words according to all of their senses.",1,original
"Lins (1998) information-theoretic similarity measure is commonly used in lexicon acquisition tasks and has demonstrated good performance in unsupervised WSD (McCarthy et al., 2004).",1,original
"Point-wise mutual information (Lin, 1998) and Relative Feature Focus (Geffet and Dagan, 2004) are well-known examples.",1,original
"4.1 Features We used a dependency structure as the context for words because it is the most widely used and one of the best performing contextual information in the past studies (Ruge, 1997; Lin, 1998).",1,original
"Among these measures, the most important are Wu & Palmers (Wu and Palmer, 1994), Resniks (Resnik, 1995) and Lins (Lin, 1998).",1,original
One of the most important is Lins (1998).,1,original
Erk (2007) compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and Lin (1998a)s information-theoretic metric work best.,1,original
"This similarity score is computed as a max over a number of component scoring functions, some based on external lexical resources, including:  various string similarity functions, of which most are applied to word lemmas  measures of synonymy, hypernymy, antonymy, and semantic relatedness, including a widelyused measure due to Jiang and Conrath (1997), based on manually constructed lexical resources such as WordNet and NomBank  a function based on the well-known distributional similarity metric of Lin (1998), which automatically infers similarity of words and phrases from their distributions in a very large corpus of English text The ability to leverage external lexical resources both manually and automatically constructedis critical to the success of MANLI.",1,original
"Whereas dependency based semantic spaces have been shown to surpass other word space models for a number of problems (Pad and Lapata, 2007; Lin, 1998), for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better (Poesio and Almuhareb, 2005b; Almuhareb and Poesio, 2005b).",1,original
"However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system.",1,original
"Similar to WSD, Carpuat and Wu (2007a) used contextual information to solve the ambiguity problem for phrases.",1,original
"Recently, word-sense disambiguation (WSD) methods have been shown to improve translation quality (Chan et al., 2007; Carpuat and Wu, 2007).",1,original
"In Carpuat and Wu (2007), anotherstate-of-the-artWSDengine(acombination of naive Bayes, maximum entropy, boosting and Kernel PCA models) is used to dynamically determine the score of a phrase pair under consideration and, thus, let the phrase selection adapt to the context of the sentence.",1,original
"WSD is one of the fundamental problems in natural language processing and is important for applications such as machine translation (MT) (Chan et al., 2007a; Carpuat and Wu, 2007), information retrieval (IR), etc. WSD is typically viewed as a classification problem where each ambiguous word is assigned a sense label (from a pre-defined sense inventory) during the disambiguation process.",1,original
"There has been considerable skepticism over whether WSD will actually improve performance of applications, but we are now starting to see improvement in performance due to WSD in cross-lingual information retrieval (Clough and Stevenson, 2004; Vossen et al., 2006) and machine translation (Carpuat and Wu, 2007; Chan et al., 2007) and we hope that other applications such as question-answering, text simplication and summarisation might also benet as WSD methods improve.",1,original
"Promising features might include those over source side reordering rules (Wang et al., 2007) or source context features (Carpuat and Wu, 2007).",1,original
"On the other hand, integrating an additional component into a baseline SMT system is notoriously tricky as evident in the research on integrating word sense disambiguation (WSD) into SMT systems: different ways of integration lead to conflicting conclusions on whether WSD helps MT performance (Chan et al., 2007; Carpuat and Wu, 2007).",1,original
"In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gimenez and M`arquez, 2007).",1,original
"We are starting to see the beginnings of a positive effect of WSD in NLP applications such as Machine Translation (Carpuat and Wu, 2007; Chan et al., 2007).",1,original
"Several studies have demonstrated that for instance Statistical Machine Translation (SMT) benefits from incorporating a dedicated WSD module (Chan et al., 2007; Carpuat and Wu, 2007).",1,original
A solution that leverages the complementary strengths of these two approachesdescribed in detail by McDonald and Nivre (2007)was recently and successfully explored by Nivre and McDonald (2008).,1,original
"The approach has been shown to give improvements over the MAP classifier in many areas of natural language processing including automatic speech recognition (Goel and Byrne, 2000), machine translation (Kumar and Byrne, 2004; Zhang and Gildea, 2008), bilingual word alignment (Kumar and Byrne, 2002), andparsing(Goodman, 1996; TitovandHenderson, 2006; Smith and Smith, 2007).",1,original
Smith and Smith (2007) describe a more efficient algorithm that can compute all edge expectations in O(n3) time using the inverse of the Kirchoff matrix K1.,1,original
"Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007).",1,original
"Given the parameters{pi0,pi,,K}of the HMM, the joint distribution over hidden states s and observationsy can be written (with s0 = 0): p(s,y|pi0,pi,,K) = Tproductdisplay t=1 p(st|st1)p(yt|st) As Johnson (2007) clearly explained, training the HMM with EM leads to poor results in PoS tagging.",1,original
"Recent projects in semisupervised (Toutanova and Johnson, 2007) and unsupervised (Biemann et al., 2007; Smith and Eisner, 2005) tagging also show significant progress.",1,original
"This is also the main reason why most summarization systems applied to news articles do not outperform a simple baseline that just uses the first 100 words of an article (Svore et al., 2007; Nenkova, 2005).",1,original
"Our similarity method is similar, but simpler, to that used by (Hughes and Ramage, 2007), which report very good results on similarity datasets.",1,original
"Albeit simple, the algorithm has proven to be very efficient and accurate for the task of parse selection (Collins and Roark, 2004; Collins, 2004; Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007).",1,original
Wikipedia first sentence (WikiFS): Kazama and Torisawa (2007) used Wikipedia as an external knowledge to improve Named Entity Recognition.,1,original
Kazama and Torisawa (2007) improve their F-score by 3% by including a Wikipedia-based feature in their machine learner.,1,original
"For instance, Kazama and Torisawa (2007) used the hyponymy relations extracted from Wikipedia for the English NER, and reported improved accuracies with such a gazetteer.",1,original
"Recently, (Toral and Munoz, 2006; Kazama and Torisawa, 2007a) have successfully constructed high quality and high coverage gazetteers from Wikipedia.",1,original
"An important aspect of web search is to be able to narrow down search results by distinguishing among people with the same name leading to multiple efforts focusing on web person name disambiguation in the literature (Mann and Yarowsky, 2003; Artiles et al., 2007, Cucerzan, 2007).",1,original
"Much later work (Evans, 2003; Etzioni et al., 2005; Cucerzan, 2007; Pasca, 2004) relies on the use of extremely large corpora which allow very precise, but sparse features.",1,original
"We conclude by noting that English language models currently used in speech recognition (Chelba and Jelinek, 1999) and automated language translation (Brants et al., 2007) are much more powerful, employing, for example, 7-gram word models (not letter models) trained on trillions of words.",1,original
"1 Introduction Very large corpora obtained from the Web have been successfully utilized for many natural languageprocessing(NLP)applications, suchasprepositional phrase (PP) attachment, other-anaphora resolution, spellingcorrection, confusablewordsetdisambiguation and machine translation (Volk, 2001; Modjeska et al., 2003; Lapata and Keller, 2005; Atterer and Schutze, 2006; Brants et al., 2007).",1,original
"To scale LMs to larger corpora with higher-order dependencies, researchers Work completed while this author was at Google Inc. have considered alternative parameterizations such as class-based models (Brown et al., 1992), model reduction techniques such as entropy-based pruning (Stolcke, 1998), novel represention schemes such as suffix arrays (Emami et al., 2007), Golomb Coding (Church et al., 2007) and distributed language models that scale more readily (Brants et al., 2007).",1,original
"Here we choose to work with stupid backoff smoothing (Brants et al., 2007) since this is significantly more efficient to train and deploy in a distributed framework than a contextdependent smoothing scheme such as Kneser-Ney.",1,original
"Indeed, researchers have shown that gigantic language models are key to state-ofthe-art performance (Brants et al., 2007), and the ability of phrase-based decoders to handle large-size, high-order language models with no consequence on asymptotic running time during decoding presents a compelling advantage over CKYdecoders,whosetimecomplexitygrowsprohibitively large with higher-order language models.",1,original
"Furthermore, the BLEU score performance suggests that our model is not very powerful, but some interesting hints can be found in Table 3 when we compare our method with a 5-gram language model to a state-of-the-art system Moses (Koehn and Hoang, 2007) based on various evaluation metrics, including BLEU score, NIST score (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006), WER and PER.",1,original
"For example, factored translation models (Koehn and Hoang, 2007) retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features.",1,original
"While this is certainly a daunting task, it is possible that for annotation studies that do not require expert annotators and extensive annotator training, the newly available access to a large pool of inexpensive annotators, such as the Amazon Mechanical Turk scheme (Snow et al., 2008),4 or embedding the task in an online game played by volunteers (Poesio et al., 2008; von Ahn, 2006) could provide some solutions.",1,original
"1 Introduction State of the art statistical parsers (Collins, 1999; Charniak, 2000; Koo and Collins, 2005; Charniak and Johnson, 2005) are trained on manually annotated treebanks that are highly expensive to create.",1,original
"In syntactic parse re-ranking supersenses have been used to build useful latent semantic features (Koo and Collins, 2005).",1,original
"However, the study of Weeds and Weir (2005) provides interesting insights into what makes a good distributional similarity measure in the contexts of semantic similarity prediction and language modeling.",1,original
"It is explored extensively in (Curran, 2004; Weeds and Weir, 2005).",1,original
"The best previous result is an accuracy of 56.1% (Turney, 2006).",1,original
"Veale (2004) used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56% (Turney, 2006).",1,original
"1 Introduction Co-occurrence statistics extracted from corpora lead to good performance on a wide range of tasks that involve the identification of the semantic relation between two words or concepts (Sahlgren, 2006; Turney, 2006).",1,original
"In the past five years, important research on the automatic acquisition of word classes based on lexical distribution has been published (Church and Hanks, 1990; Hindle, 1990; Smadja, 1993; Grei~nstette, 1994; Grishman and Sterling, 1994).",1,original
"Church and Hanks (1990) use mutual information to identify collocations, a method they claim is reasonably effective for words with a frequency of not less than five.",1,original
"Probably the most widely used feature weighting function is (point-wise) Mutual Information (MI) (Church and Patrick 1990; Hindle 1990; Luk 1995; Lin 1998; Gauch, Wang, and Rachakonda 1999; Dagan 2000; Baroni and Vegnaduzzo 2004; Chklovski and Pantel 2004; Pantel and Ravichandran 2004; Pantel, Ravichandran, and Hovy 2004; Weeds, Weir, and McCarthy 2004), dened by: weight MI (w,f)=log 2 P(w,f) P(w)P(f) (1) We calculate the MI weights by the following statistics in the space of co-occurrence instances S: weight MI (w,f)=log 2 count(w,f) nrels count(w) count(f) (2) where count(w,f) is the frequency of the co-occurrence pair w,f  in S, count(w)and count(f) are the independent frequencies of w and f in S,andnrels is the size of S.High MI weights are assumed to correspond to strong wordfeature associations.",1,original
"The most widely used association weight function is (point-wise) Mutual Information (MI) (Church and Hanks, 1990; Lin, 1998; Dagan, 2000; Weeds et al. , 2004).",1,original
"Researchers such as (Evans et al. 1991) and (Church and Hanks 1990) have applied robust grammars and statistical techniques over large corpora to extract interesting noun phrases and subject-verb, verb-object pairs.",1,original
"Arguably the most widely used is the mutual information (Hindle, 1990; Church and Hanks, 1990; Dagan et al. , 1995; Luk, 1995; D. Lin, 1998a).",1,original
"There are several distance measures suitable for this purpose, such as the mutual information(Church and Hanks, 1990), the dice coefficient(Manning and Schueutze 8.5, 1999), the phi coefficient(Manning and Schuetze 5.3.3, 1999), the cosine measure(Manning and Schueutze 8.5, 1999) and the confidence(Arrawal and Srikant, 1995).",1,original
"Usually in 1 In our experiments, we set negative PMI values to 0, because Church and Hanks (1990), in their seminal paper on word association ratio, show that negative PMI values are not expected to be accurate unless co-occurrence counts are made from an extremely large corpus.",1,original
"Unlike Choueka (1988), Church and Hanks (1990) identify as collocations both interrupted and uninterrupted sequences of words.",1,original
"robust mforrmatlon extractlon, and readlly-avmlable on-hne NLP resources These techtuques and resources allow us to create a richer indexed source of Imgmstlc and domain knowledge than other frequency approaches Our approach attempts to apprommate text dlscourse structure through these multlple layers of mformatlon, ohtinned from automated methods m contrast to labor-lntenslve, discourse-based approaches Moreover, our planned training methodology will also allow us to explmt thin productlve infrastructure m ways whlch model human performance whde avoidmg hand-crafting domain-dependent rules of the knowledge-based approaches Our ultlmate goal m to make our summarlzatlon system scalable and portable by learning summarization rules from easily extractable text features 2 System Description Our summarization system DlmSum consmts of the Summarization Server and the Summarlzatzon Chent The Server extracts features (the Feature Extractor) from a document using various robust NLP techmques, described In Sectzon 2 1, and combines these features (the Feature Combiner) to basehne multiple combinations of features, as described m Section 2 2 Our work m progress to automattcally tram the Feature Combiner based upon user and apphcatlon needs m presented in Section 2 2 2 The Java-based Chent, which wdl be dmcnssed In Section 4, provides a graphical user interface (GUI) for the end user to cnstomlze the summamzatlon preferences and see multiple views of generated sumInarles 2.1 Extracting Stlmmarization Features In this section, we describe how we apply robust NLP technology to extract summarization features Our goal IS to add more mtelhgence to frequencybased approaches, to acqmre domain knowledge In a more automated fashion, and to apprommate text structure by recogmzing sources of dmcourse cohesion and coherence 2.1.1 Going Beyond a Word Frequency-based summarization systems typically use a single word stnng as a umt for counting frequencies Whde such a method IS very robust, it ignores the semantic content of words and their potential membership m multi-word phrases For example, zt does not dmtmgumh between ""bill"" m ""Bdl Table 1 Collocations with ""chlps"" {potato tortdla corn chocolate b~gle} chips {computer pentmm Intel macroprocessor memory} chips {wood oak plastlc} cchlps bsrgmmng clups blue clups mr chips Clmton"" and ""bill"" in ""reform bill"" This may introduce noise m frequency counting as the same strmgs are treated umformly no matter how the context may have dmamblguated the sense or regardless of membership in multl-word phrases For DlrnSum, we use term frequency based on tf*Idf (Salton and McGdl, 1983, Brandow, Mitze, and Rau, 1995) to derive ssgnature words as one of the summarization features If single words were the sole basra of countmg for our summarization application, nome would be introduced both m term frequency and reverse document frequency However, recent advances in statmtlcal NLP and information extraction make it possible to utilize features which go beyond the single word level Our approach is to extract multi-word phrases automatlcally with high accuracy and use them as the basic unit in the summarization process, including frequency calculation Ftrst, just as word association methods have proven effective m lemcal analysis, e g (Church and Hanks, 1990), we are exploring whether frequently occurring Collocatlonal reformation can improve on simple word-based approaches We have preprocessed about 800 MB of LA tlmes/Wastnngton Post newspaper articles nsmg a POS tagger (Bnll, 1993) and derived two-word noun collocations using mutual information The.",1,original
"Similarity-based smoothing (Brown et al. , 1992; Dagan et al. , 1999) is an intuitively appealing approach to this problem where probabilities of unseen co-occurrences are estimated from probabilities of seen co-occurrences of distributionally similar events.",1,original
"Similarity-based smoothing (Hindle 1990; Brown et al. 1992; Dagan, Marcus, and Markovitch 1993; Pereira, Tishby, and Lee 1993; Dagan, Lee, and Pereira 1999) provides an intuitively appealing approach to language modeling.",1,original
"The notion of incrementally merging classes of lexical items is intuitively satisfying and is explored in detail in (Brown, et al. 1992).",1,original
"For example the class-based language model of (Brown et al. , 1992) is defined as: p(w2|w1) = p(w2|c2)p(c2|c1) (1) This helps solve the sparse data problem since the number of classes is usually much smaller than the number of words.",1,original
"This paper is heavily indebted to prior work on unsupervised learning of position categories such as Brown et al 1992, Schtze 1997, Higgins 2002, and others cited there.",1,original
"7Another related measure is Dunning (1993)'s likelihood ratio tests for binomial and multinomial distributions, which are claimed to be effective even with very much smaller volumes of text than is necessary for other tests based on assumed normal distributions.",1,original
"For instance, mutual information (Church ct al. 1990) and the log-likelihood (Dunning 1993) methods for extracting word bigrams have been widely used.",1,original
"For instance, the mutual information (Church et al. 1990) and log-likelihood ratio (Dunning 1993; Cohen 1995) have been widely used for extracting word bigrams.",1,original
"(3) () () 0 log 2 log A LH LH     = 1 Problems for an unscaled log  approach Although log  identifies collocations much better than competing approaches (Dunning 1993) in terms of its recall, it suffers from its relatively poor precision rates.",1,original
"The evaluation results also confirm the argument of Dunning (1993), who suggested G2 as a more robust alternative to X2.",1,original
"One popular and statistically appealing such measure is Log-Likelihood (LL) (Dunning, 1993).",1,original
This further supports the claim by Dunning (1993) that loglikelihood ratio is much less sensitive than pmi to low counts.,1,original
"By default, the log-likelihood ratio measure (LLR) is proposed, since it was shown to be particularly suited to language data (Dunning, 1993).",1,original
This results also agree with Dunning's argument about overestimation on the infrequent occurrences in which many infrequent pairs tend to get higher estimation (Dunning 1993).,1,original
"All the enumerated segment pairs are listed in the following table: Feature x,y Feature x,y AM1+1 c1, c0 AM2+1 c2c1, c0 AM1+2 c1, c0c1 AM2+2 c2c1, c0c1 AM1+3 c1, c0c1c2 AM3+1 c3c2c1, c0 We use Dunnings method (Dunning, 1993) because it does not depend on the assumption of normality and it allows comparisons to be made between the signiflcance of the occurrences of both rare and common phenomenon.",1,original
"In informal experiments described elsewhere (Melamed 1995), I found that the G 2 statistic suggested by Dunning (1993) slightly outperforms 2.",1,original
"In our experiments, we follow Lowe and McDonald (2000) in using the well-known log-likelihood ratio G 2 (Dunning 1993).",1,original
"Throughout, the likelihood ratio (Dunning, 1993) is used as significance measure because of its stable performance in various evaluations, yet many more measures are possible.",1,original
"In order to filter some noise caused by the error alignment links, we only retain those translation pairs whose translation probabilities are above a threshold 1 D 1  or co-occurring frequencies are above a threshold 2  . When we train the IBM statistical word alignment model with a limited bilingual corpus in the specific domain, we build another translation dictionary with the same method as for the dictionary . But we adopt a different filtering strategy for the translation dictionary . We use log-likelihood ratio to estimate the association strength of each translation pair because Dunning (1993) proved that log-likelihood ratio performed very well on small-scale data.",1,original
"Moreover, log likelihood ratios are regarded as a more effective method to identify collocations especially when the occurrence count is very low (Dunning, 1993).",1,original
"We preferred the log-likelihood ratio to other statistical scores, such as the association ratio (Church and Hanks, 1990) or ;(2, since it adequately takes into account the frequency of the co-occurring words and is less sensitive to rare events and corpussize (Dunning, 1993; Daille, 1996).",1,original
"They were based on mutual information (Church & Hanks, 1989), conditional probabilities (Rapp, 1996), or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio (Dunning, 1993).",1,original
"2.2.2 The Binomial Log Likelihood Ratio as a Statistical Filter Dunning (1993) demonstrates the benefits of the LLR statistic, compared to Pearson's chisquared, on the task of ranking bigram data.",1,original
"a list of pilot terms ranked from the most representative of the corpus to the least thanks to the Loglikelihood coefficient introduced by (Dunning, 1993).",1,original
"For the current work, the Log-likelihood coefficient has been employed (Dunning, 1993), as it is reported to perform well among other scoring methods (Daille, 1995).",1,original
"Pr(cJ1,aJ1|eI1) = p(J|I)(I + 1)J Jproductdisplay j=1 p(cj|eaj) (8) 3.1.2 Log-likelihood ratio The log-likelihood ratio statistic has been found to be accurate for modeling the associations between rare events (Dunning, 1993).",1,original
"Many previous studies have shown that the log-likelihood ratio is well suited for this purpose (Dunning, 1993).",1,original
"It can be expected that the log-likelihood ratio produces an accurate ranking of word pairs that highly correlates with human judgment (Dunning, 1993), although there are other measures which come close in performance (e.g. Rapp, 1998).",1,original
"(Dunning, 1993) and (Pedersen, 1996) shows how some of the methods which have been used in the past (particularly mutual information scores) are invalid for rare events, and introduce accurate measures of how 'surprising' rare events are.",1,original
"Tools like Xtract (Smadja 1993) were based on the work of Church and others, but made a step forward by incorporating various statistical measurements like z-score and variance of distribution, as well as shallow linguistic techniques like part-of-speech tagging and lemmatization of input data and partial parsing of raw output.",1,original
"Smadja (1993), which is the classic work on collocation extraction, uses a two-stage filtering model in which, in the first step, n-gram statistics determine possible collocations and, in the second step, these candidates are submitted to a syntactic valida7Of course, lexical material is always at least partially dependent on the domain in question.",1,original
"In the past five years, important research on the automatic acquisition of word classes based on lexical distribution has been published (Church and Hanks, 1990; Hindle, 1990; Smadja, 1993; Grei~nstette, 1994; Grishman and Sterling, 1994).",1,original
"One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system.",1,original
"For the extraction problem, there have been various methods proposed to date, which are quite adequate (Hindle and Rooth 1991; Grishman and Sterling 1992; Manning 1992; Utsuro, Matsumoto, and Nagao 1992; Brent 1993; Smadja 1993; Grefenstette 1994; Briscoe and Carroll 1997).",1,original
"Many efficient techniques exist to extract multiword expressions, collocations, lexical units and idioms (Church and Hanks, 1989; Smadja, 1993; Dias et al. , 2000; Dias, 2003).",1,original
"Study in collocation extraction using lexical statistics has gained some insights to the issues faced in collocation extraction (Church and Hanks 1990, Smadja 1993, Choueka 1993, Lin 1998).",1,original
"In statistical machine translation, IBM 1~5 models (Brown et al. , 1993) based on the source-chmmel model have been widely used and revised for many language donmins and applications.",1,original
"Another kind of popular approaches to dealing with query translation based on corpus-based techniques uses a parallel corpus containing aligned sentences whose translation pairs are corresponding to each other (Brown et al. , 1993; Dagan et al. , 1993; Smadja et al. , 1996).",1,original
"Using the IBM translation models IBM-1 to IBM-5 (Brown et al. , 1993), as well as the Hidden-Markov alignment model (Vogel et al. , 1996), we can produce alignments of good quality.",1,original
"6 Related Work The popular IBM models for statistical machine translation are described in (Brown et al. , 1993).",1,original
"A detailed description of the popular translation models IBM-1 to IBM-5 (Brown et al. , 1993), aswellastheHidden-Markovalignmentmodel (HMM) (Vogel et al. , 1996) can be found in (Och and Ney, 2003).",1,original
"Using the IBM translation models IBM-1 to IBM-5 (Brown et al. , 1993), as well as the Hidden-Markov alignment model (Vogel et al. , 1996), we can produce alignments of good quality.",1,original
"A detailed description of the popular translation/alignment models IBM-1 to IBM-5 (Brown et al. , 1993), as well as the Hidden-Markov alignment model (HMM) (Vogel et al. , 1996) can be found in (Och and Ney, 2003).",1,original
"2 Related Work The popular IBM models for statistical machine translation are described in (Brown et al. , 1993) and the HMM-based alignment model was introduced in (Vogel et al. , 1996).",1,original
"of the position infer marion of words at ltlat(;hillg pairs of sellte/lCeS, which turned out useful (Brown et al. 1993).",1,original
"(2) We note that these posterior probabilities can be computed efficiently for some alignment models such as the HMM (Vogel et al. , 1996; Och and Ney, 2003), Models 1 and 2 (Brown et al. , 1993).",1,original
"Compared with clean parallel corpora such as ""Hansard"" (Brown et al. 1993), which consists of 505 French-English translations of political debates in the Canadian parliament, texts from the web are far more diverse and noisy.",1,original
"In this work, we propose two models that can be categorized as extensions of standard word lexicons: A discriminative word lexicon that uses global, i.e. sentence-level source information to predict the target words using a statistical classifier and a trigger-based lexicon model that extends the well-known IBM model 1 (Brown et al., 1993) with a second trigger, allowing for a more finegrained lexical choice of target words.",1,original
"In the classic work on SMT,Brownandhiscolleagues atIBMintroduced the notion of alignment between a sentence f and its translation e and used it in the development of translation models (Brown et al. , 1993).",1,original
"In their seminal paper on SMT, Brownand his colleagues highlighted the problems weface aswe go from IBM Models 1-2 to 3-5(Brown et al. , 1993) 3: Asweprogress from Model1toModel5, evaluating the expectations that gives us counts becomes increasingly difficult.",1,original
The implementation of MEBA was strongly influenced by the notorious five IBM models described in (Brown et al. 1993).,1,original
"While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al., 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collins and Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention).",1,original
"The IBM models 1-5 (Brown et al. , 1993) produce word alignments with increasing algorithmic complexity and performance.",1,original
"The IBM models have shown good performance in machine translation, and especially so within certain families of languages, for example in translating between French and English or between Sinhalese and Tamil (Brown et al. , 1993; Weerasinghe, 2004).",1,original
"This is a common technique in machine translation for which the IBM translation models are popular methods (Brown et al. , 1993).",1,original
One widely used model is the IBM model (Brown et al. 1993).,1,original
"It was initially proposed by (Brown et al. , 1993) and, more recently, have been intensively studied by several research groups (Germann et al. , 2001; Och et al. , 2003).",1,original
"Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s (Brown et al. 1990; Brown et al. 1993; Berger et al. 1994).",1,original
"According to our experience, the best performance is achieved when the union of the source-to-target and target-to-source alignment sets (IBM models; Brown et al. [1993]) is used for tuple extraction (some experimental results regarding this issue are presented in Section 4.2.2).",1,original
Introduction Automatic word alignment (Brown et al. 1993) is a vital component of all statistical machine translation (SMT) approaches.,1,original
"1 Introduction As with many other statistical natural language processing tasks, statistical machine translation (Brown et al. , 1993) produces high quality results when ample training data is available.",1,original
"For the IBM models defined by a pioneering paper (Brown et al. , 1993), a decoding algorithm based on a left-to-right search was described in (Berger et al. , 1996).",1,original
"Being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition (Jelinek, 1997), part of speech tagging (Church, 1988), machine translation (Brown et al. , 1993), information retrieval (Berger and Lafferty, 1999), and text summarization (Knight and Marcu, 2002), we develop a noisy channel model for QA.",1,original
"The former term P(E) is called a language model, representing the likelihood of E. The latter term P(J|E) is called a translation model, representing the generation probability from E into J. As an implementation of P(J|E), the word alignment based statistical translation (Brown et al. , 1993) has been successfully applied to similar language pairs, such as FrenchEnglish and German English, but not to drastically dierent ones, such as JapaneseEnglish.",1,original
"Within the generative model, the Bayes reformulation is used to estimate a31 a0a15a14a35a33a1a26a13a37a36 a31 a0a15a14a19a13 a31 a0a2a1a38a33a14a39a13 where a31 a0a15a14a39a13 is considered the language model, and a31 a0a2a1a38a33a14a19a13 is the translation model; the IBM (Brown et al. , 1993) models being the de facto standard.",1,original
"1 Introduction IBM Model 1 (Brown et al. , 1993a) is a wordalignment model that is widely used in working with parallel bilingual corpora.",1,original
"Bootstrapping a PMTG from a lower-dimensional PMTG and a word-to-word translation model is similar in spirit to the way that regular grammars can help to estimate CFGs (Lari & Young, 1990), and the way that simple translation models can help to bootstrap more sophisticated ones (Brown et al. , 1993).",1,original
"Syntax-light alignment models such as the five IBM models (Brown et al. , 1993) and their relatives have proved to be very successful and robust at producing word-level alignments, especially for closely related languages with similar word order and mostly local reorderings, which can be captured via simple models of relative word distortion.",1,original
"1 Introduction Statistical approaches to machine translation, pioneered by (Brown et al. , 1993), achieved impressive performance by leveraging large amounts of parallel corpora.",1,original
"There are basically two kinds of systems working at these segmentation levels: the most widespread rely on statistical models, in particular the IBM ones (Brown et al. , 1993); others combine simpler association measures with different kinds of linguistic information (Arhenberg et al. , 2000; Barbu, 2004).",1,original
"In this paper, we show that a noisy channel model instantiated within the paradigm of Statistical Machine Translation (SMT) (Brown et al. , 1993) can successfully provide editorial assistance for non-native writers.",1,original
"1 Introduction The most widely applied training procedure for statistical machine translation IBM model 4 (Brown et al. , 1993) unsupervised training followed by post-processing with symmetrization heuristics (Och and Ney, 2003) yields low quality word alignments.",1,original
"Aligning tokens in parallel sentences using the IBM Models (Brown et al. , 1993), (Och and Ney, 2003) may require less information than full-blown translation since the task is constrained by the source and target tokens present in each sentence pair.",1,original
"Such methods have also been a key driver of progress in statistical machine translation, which depends heavily on unsupervised word alignments (Brown et al. , 1993).",1,original
"For the word alignment, we apply standard techniques derived from statistical machine translation using the well-known IBM alignment models (Brown et al. , 1993) implemented in the opensource tool GIZA++ (Och, 2003).",1,original
"Finally, the translation model can be formalized as the following optimization problem argmax logPr(D;) s.t. mwsummationdisplay j=1 Pr(wj|ok) = 1,k This optimization problem can be solved by the EM algorithm (Brown et al. , 1993).",1,original
"This is an important feature from the MT viewpoint, since the decomposition into translation model and language model proved to be extremely useful in statistical MT since (Brown et al., 1993).",1,original
"Widely used alignment models, such as IBM Model serial (Brown et al., 1993) and HMM , all assume one-to-many alignments.",1,original
"Corpus-based or example-based MT (Sato and Nagao, 1990; Sumita and Iida, 1991) and statistical MT (Brown et al. , 1993) systems provide the easiest customizability, since users have only to supply a collection of source and target sentence pairs (a bilingual corpus).",1,original
"1 Introduction Over the past decade, researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation (Brown et al. , 1988; Brown et al. , 1990; Brown et al. , 1993a).",1,original
"(Brown et al. , 1993) then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other.",1,original
"In previous work (Foster, 2000), I described a Maximum Entropy/Minimum Divergence (MEMD) model (Berger et al. , 1996) for p(w\[hi, s) which incorporates a trigram language model and a translation component which is an analog of the well-known IBM translation model 1 (Brown et al. , 1993).",1,original
"3 Experimental Results Whereas stochastic modelling is widely used in speech recognition, there are so far only a few research groups that apply stochastic modelling to language translation (Berger et al. 1994; Brown et al. 1993; Knight 1999).",1,original
"2.2 Statistical Translation Lexicon We use a statistical translation lexicon known as IBM Model-1 in (Brown et al. , 1993) for both efficiency and simplicity.",1,original
"(Brown et al. , 1990; Brown et al. , 1993)) are best known and studied.",1,original
"2 Prior Work Statistical machine translation, as pioneered by IBM (e.g. Brown et al. , 1993), is grounded in the noisy channel model.",1,original
"The IBM source-channel model for statistical machine translation (P. Brown et al. , 1993) plays a central role in our system.",1,original
"When efficient techniques have been proposed (Brown et al. , 1993; Och and Ney, 2003), they have been mostly evaluated on safe pairs of languages where the notion of word is rather clear.",1,original
"1 Introduction The most widely used alignment model is IBM Model 4 (Brown et al. , 1993).",1,original
"Turning off the extensions to GIZA++ and training p0 as in (Brown et al. , 1993) produces a substantial increase in AER.",1,original
"A quite different approach from our hypotheses testing implemented in the TREQ-AL aligner is taken by the model-estimating aligners, most of them relying on the IBM models (1 to 5) described in the (Brown et al. 1993) seminal paper.",1,original
"State-of-art systems for doing word alignment use generative models like GIZA++ (Och and Ney, 2003; Brown et al. , 1993).",1,original
"1 Introduction The availability of large amounts of so-called parallel texts has motivated the application of statistical techniques to the problem of machine translation starting with the seminal work at IBM in the early 90s (Brown et al. , 1992; Brown et al. , 1993).",1,original
"Specifically, in the task of word alignment, heuristic approaches such as the Dice coefficient consistently underperform their re-estimated counterparts, such as the IBM word alignment models (Brown et al. , 1993).",1,original
"Statistical models for machine translation heavily depend on the concept of alignment, specifically, the well known IBM word based models (Brown et al. , 1993).",1,original
"The most widely used single-word-based statistical alignment models (SAMs) have been proposed in (Brown et al. , 1993; Ney et al. , 2000).",1,original
"In the well-known so-called IBM word alignment models (Brown et al., 1993), re-estimating the model parameters depends on the empirical probability P(ek,fk) for each sentence pair (ek,fk).",1,original
"Generative word alignment models, initially developed at IBM (Brown et al., 1993), and then augmented by an HMM-based model (Vogel et al., 1996), have provided powerful modeling capability for word alignment.",1,original
Brute-force methods (ie those that exploit the massive raw computing power currently available cheaply) may well produce some useful results (eg Brown et al 1993).,1,original
"Preparing tagged corpora either by hand is labour-intensive and potentially error-prone, and although a semi-automatic approach can be used (Marcus et al. , 1993), it is a good thing to reduce the human involvement as much as possible.",1,original
"1 Introduction Syntactically annotated corpora like the Penn Treebank (Marcus et al. , 1993), the NeGra corpus (Skut et al. , 1998) or the statistically dismnbiguated parses in (Bell et al. , 1999) provide a wealth of intbrmation, which can only be exploited with an adequate query language.",1,original
"To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al. , 1993), is annotated primarily with constituent analysis.",1,original
"Recently, we can see an important development in natural language processing and computational linguistics towards the use of empirical learning methods (for instance, (Charniak, 1993; Marcus et al. , 1993; Wermter, 11995; Jones, 1995; Werml;er et al. , 1996)).",1,original
"Successflfl examples of reuse of data resources include: the WordNet thesaurus (Miller el; al. , 1993); the Penn Tree Bank (Marcus et al. , 1993); the Longmans Dictionary of Contemporary English (Summers, 1995).",1,original
"In the statistical NLP community, the most widely used grammatical resource is the Penn Treebank (Marcus et al., 1993).",1,original
"Particularly, syntactically annotated corpora (treebanks), such as Penn Treebank (Marcus et al. , 1993), Negra Corpus (Skut et al. , 1997) and EDR Corpus (Jap, 1994), contribute to improve the performance of morpho-syntactic analysis systems.",1,original
"This kind of corpus has served as an extremely valuable resource for computational linguistics applications such as machine translation and question answering (Lee et al. , 1997; Choi, 2001), and has also proved useful in theoretical linguistics research (Marcus et al. , 1993).",1,original
"Some notable efforts in this direction for other languages have been the Penn Tree Bank (Marcus et al., 1993) for English and the Prague Dependency Bank (Hajicova, 1998) for Czech.",1,original
"One of the largest and earliest such efforts is the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993; Marcus et al. 1994), which contains a one-million word  Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104-6228, USA.",1,original
"1 Introduction By exploiting information encoded in human-produced syntactic trees (Marcus et al. , 1993), research on probabilistic models of syntax has driven the performance of syntactic parsers to about 90% accuracy (Charniak, 2000; Collins, 2000).",1,original
"2 Treebanking The Penn Treebank (Marcus et al. , 1993) is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of empty categories that represent displaced constituents.",1,original
The default training set of Penn Treebank (Marcus et al. 1993) was used for the parser because the domain and style of those texts actually matches fairly well with the domain and style of the texts on which a reading level predictor for second language learners might be used.,1,original
"However, evaluations on the widely used WSJ corpus of the Penn Treebank (Marcus et al. , 1993) show that the accuracy of these parsers still lags behind the state-of-theart.",1,original
"1 Introduction Robust statistical syntactic parsers, made possible by new statistical techniques (Collins, 1999; Charniak, 2000; Bikel, 2004) and by the availability of large, hand-annotated training corpora such as WSJ (Marcus et al. , 1993) and Switchboard (Godefrey et al. , 1992), have had a major impact on the field of natural language processing.",1,original
"1 Introduction The Penn Treebank (Marcus et al. , 1993) is perhaps the most in uential resource in Natural Language Processing (NLP).",1,original
"1 Introduction Research in language processing has benefited greatly from the collection of large annotated corpora such as Penn PropBank (Kingsbury and Palmer, 2002) and Penn Treebank (Marcus et al., 1993).",1,original
"One major resource for corpus-based research is the treebanks available in many research organizations \[Marcus et al.1993\], which carry skeletal syntactic structures or 'brackets' that have been manually verified.",1,original
"Penn Treebank(Marcus et al. , 1993) was also used to induce part-of-speech (POS) taggers because the corpus contains very precise and detailed POS markers as well as bracket, annotations.",1,original
Introduction The Penn Treebank (Marcus et al. 1993) initiated a new paradigm in corpus-based research.,1,original
"The creation of the Penn English Treebank (Marcus et al. , 1993), a syntactically interpreted corpus, played a crucial role in the advances in natural language parsing technology (Collins, 1997; Collins, 2000; Charniak, 2000) for English.",1,original
"1 Introduction Large scale annotated corpora such as the Penn TreeBank (Marcus et al. , 1993) have played a central role in speech and natural language research.",1,original
"Annotated reference corpora, such as the Brown Corpus (Kucera, Francis, 1967), the Penn Treebank (Marcus et al. , 1993), and the BNC (Leech et al. , 2001.), have helped both the development of English computational linguistics tools and English corpus linguistics.",1,original
"On the other hand, high-quality treebanks such as the Penn Treebank (Marcus et al. , 1993) and the Kyoto University text corpus (Kurohashi and Nagao, 1997) have contributed to improving the accuracies of fundamental techniques for natural language processing such as morphological analysis and syntactic structure analysis.",1,original
"The Penn TreeBank (PTB) is an example of such a resource with worldwide impact on natural language processing (Marcus et al. , 1993).",1,original
"Introduction The creation of the Penn Treebank (Marcus et al, 1993) and the word sense-annotated SEMCOR (Fellbaum, 1997) have shown how even limited amounts of annotated data can result in major improvements in complex natural language understanding systems.",1,original
"1 Introduction There is a pressing need for a consensus on a taskoriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the Penn Treebank (Marcus et al. , 1993) enabled the development of statistical syntactic parsers (Collins, 1999; Charniak, 2001).",1,original
"We evaluated the generator on the Penn Treebank (Marcus et al. , 1993), which is highly reliable corpus consisting of real-world texts.",1,original
"After the success in syntactic (Penn TreeBank (Marcus et al. , 1993)) and propositional encodings (Penn PropBank (Palmer et al. , 2005)), more sophisticated semantic data (such as temporal (Pustejovsky et al. , 2003) or opinion annotations (Wiebe et al. , 2005)) and discourse data (e.g. , for anaphora resolution (van Deemter and Kibble, 2000) and rhetorical parsing (Carlson et al. , 2003)) are being generated.",1,original
"While significant time savings have already been reported on the basis of automatic pre-tagging (e.g. , for POS and parse tree taggings in the Penn TreeBank (Marcus et al. , 1993), or named entity taggings for the Genia corpus (Ohta et al. , 2002)), this kind of pre-processing does not reduce the number of text tokens actually to be considered.",1,original
"1 Introduction Large scale annotated corpora, e.g., the Penn TreeBank (PTB) project (Marcus et al. 1993), have played an important role in text-mining.",1,original
"The Penn Treebank (Marcus et al., 1993) has until recently been the only such corpus, covering 4.5M words in a single genre of financial reporting.",1,original
"Many mainstream systems and formalisms would satisfy these criteria, including ones such as the University of Pennsylvania Treebank (Marcus et al, 1993) which are purely syntactic (though of course, only syntactic properties could then be extracted).",1,original
"It us widely acknowledged that word sense d~samblguatmn (WSD) us a central problem m natural language processing In order for computers to be able to understand and process natural language beyond simple keyword matching, the problem of d~samblguatmg word sense, or dlscermng the meamng of a word m context, must be effectively dealt with Advances in WSD v, ill have slgmficant Impact on apphcatlons hke information retrieval and machine translation For natural language subtasks hke part-of-speech tagging or s)ntactm parsing, there are relatlvely well defined and agreed-upon cnterm of what it means to have the ""correct"" part of speech or syntactic structure assigned to a word or sentence For instance, the Penn Treebank corpus (Marcus et al, 1993) pro~ide~,t large repo.~tory of texts annotated w~th partof-speech and s}ntactm structure mformatlon Tv.o independent human annotators can achieve a high rate of agreement on assigning part-of-speech tags to words m a g~ven sentence Unfortunately, th~s us not the case for word sense assignment F~rstly, it is rarely the case that any two dictionaries will have the same set of sense defimtmns for a g~ven word Different d~ctlonanes tend to carve up the ""semantic space"" m a different way, so to speak Secondly, the hst of senses for a word m a typical dmtmnar~ tend to be rather refined and comprehensive This is especmlly so for the commonly used words which have a large number of senses The sense dustmctmn between the different senses for a commonly used word m a d~ctmnary hke WoRDNET (Miller, 1990) tend to be rather fine Hence, two human annotators may genuinely dusagree m their sense assignment to a word m context The agreement rate between human annotators on word sense assignment us an Important concern for the evaluatmn of WSD algorithms One would prefer to define a dusamblguatlon task for which there us reasonably hlgh agreement between human annotators The agreement rate between human annotators will then form the upper ceiling against whmh to compare the performance of WSD algorithms For instance, the SENSEVAL exerclse has performed a detaded study to find out the raterannotator agreement among ~ts lexicographers taggrog the word senses (Kllgamff, 1998c, Kllgarnff, 1998a, Kflgarrlff, 1998b) 2 A Case Study In this-paper, we examine the ~ssue of raterannotator agreement by comparing the agreement rate of human annotators on a large sense-tagged corpus of more than 30,000 instances of the most frequently occurring nouns and verbs of Enghsh This corpus is the intersection of the WORDNET Semcor corpus (Miller et al, 1993) and the DSO corpus (Ng and Lee, 1996, Ng, 1997), which has been independently tagged wlth the refined senses of WORDNET by two separate groups of human annotators The Semcor corpus us a subset of the Brown corpus tagged with ~VoRDNET senses, and consists of more than 670,000 words from 352 text files Sense taggmg was done on the content words (nouns, ~erbs, adjectives and adverbs) m this subset The DSO corpus consists of sentences drawn from the Brown corpus and the Wall Street Journal For each word w from a hst of 191 frequently occurring words of Enghsh (121 nouns and 70 verbs), sentences containing w (m singular or plural form, and m its various reflectional verb form) are selected and each word occurrence w ~s tagged w~th a sense from WoRDNET There ~s a total of about 192,800 sentences in the DSO corpus m which one word occurrence has been sense-tagged m each sentence The intersection of the Semcor corpus and the DSO corpus thus consists of Brown corpus sentences m which a word occurrence w is sense-tagged m each sentence, where w Is one of.the 191 frequently oc-,currmg English nouns or verbs Since this common pomon has been sense-tagged by two independent groups of human annotators, ~t serves as our data set for investigating inter-annotator agreement in this paper 3 Sentence Matching To determine the extent of inter-annotator agreement, the first step ~s to match each sentence m Semcor to its corresponding counterpart In the DSO corpus This step ~s comphcated by the following factors 1 Although the intersected portion of both corpora came from Brown corpus, they adopted different tokemzatmn convention, and segmentartan into sentences differed sometimes 2 The latest versmn of Semcor makes use of the senses from WORDNET 1 6, whereas the senses used m the DSO corpus were from WoRDNET 15 1 To match the sentences, we first converted the senses m the DSO corpus to those of WORDNET 1 6 We ignored all sentences m the DSO corpus m which a word is tagged with sense 0 or -1 (A word is tagged with sense 0 or -1 ff none of the given senses m WoRDNFT applies ) 4, sentence from Semcor is considered to match one from the DSO corpus ff both sentences are exactl) ldent~cal or ff the~ differ only m the pre~ence or absence of the characters "" (permd) or -' (hyphen) For each remaining Semcor sentence, taking into account word ordering, ff 75% or more of the words m the sentence match those in a DSO corpus sentence, then a potential match ~s recorded These i -kctua\[ly, the WORD~q'ET senses used m the DSO corpus were from a shght variant of the official WORDNE'I 1 5 release Th~s ssas brought to our attention after the pubhc release of the DSO corpus potential matches are then manually verffied to ensure that they are true matches and to ~eed out any false matches Using this method of matching, a total of 13,188 sentence-palrs contasnmg nouns and 17,127 sentence-pa~rs containing verbs are found to match from both corpora, ymldmg 30,315 sentences which form the intersected corpus used m our present study 4 The Kappa Statistic Suppose there are N sentences m our corpus where each sentence contains the word w Assume that w has M senses Let 4 be the number of sentences which are assigned identical sense b~ two human annotators Then a simple measure to quantify the agreement rate between two human annotators Is Pc, where Pc, = A/N The drawback of this simple measure is that it does not take into account chance agreement between two annotators The Kappa statistic a (Cohen, 1960) is a better measure of rater-annotator agreement which takes into account the effect of chance agreement It has been used recently w~thm computatmnal hngu~stlcs to measure raterannotator agreement (Bruce and Wmbe, 1998, Carletta, 1996, Veroms, 1998) Let Cj be the sum of the number of sentences which have been assigned sense 3 by annotator 1 and the number of sentences whmh have been assigned sense 3 by annotator 2 Then P~-P~ 1-P~ where M j=l and Pe measures the chance agreement between two annotators A Kappa ~alue of 0 indicates that the agreement is purely due to chance agreement, whereas a Kappa ~alue of 1 indicates perfect agreement A Kappa ~alue of 0 8 and above is considered as mdmatmg good agreement (Carletta, 1996) Table 1 summarizes the inter-annotator agreement on the mtersected corpus The first (becond) row denotes agreement on the nouns (xerbs), wh~le the lass row denotes agreement on all words combined The a~erage ~ reported m the table is a s~mpie average of the individual ~ value of each word The agreement rate on the 30,315 sentences as measured by P= is 57% This tallies with the figure reported ~n our earlier paper (Ng and Lee, 1996) where we performed a quick test on a subset of 5,317 sentences,n the intersection of both the Semcor corpus and the DSO corpus 10 \[\] mm m m m m m mm m m m m mm m m m Type Num of v, ords A N \[ P~ Avg Nouns 121 7,676 13,188 I 0 582 0 300 Verbs 70 9,520 17,127 I 0 555 0 347 All I 191 I 17,196 30,315 I 056T 0317 Table 1 Raw inter-annotator agreement 5 Algorithm Since the rater-annotator agreement on the intersected corpus is not high, we would like to find out how the agreement rate would be affected if different sense classes were in use In this section, we present a greedy search algorithm that can automatmalb derive coarser sense classes based on the sense tags assigned by two human annotators The resulting derived coarse sense classes achmve a higher agreement rate but we still maintain as many of the original sense classes as possible The algorithm is given m Figure 1 The algorithm operates on a set of sentences where each sentence contains an occurrence of the word w whmh has been sense-tagged by two human annotators At each Iteration of the algorithm, tt finds the pair of sense classes Ct and Cj such that merging these two sense classes results in the highest t~ value for the resulting merged group of sense classes It then proceeds to merge Cz and C~ Thin process Is repeated until the ~ value reaches a satisfactory value ~,~t,~, which we set as 0 8 Note that this algorithm is also applicable to deriving any coarser set of classes from a refined set for any NLP tasks in which prior human agreement rate may not be high enough Such NLP tasks could be discourse tagging, speech-act categorization, etc 6 Results For each word w from the list of 121 nouns and 70 verbs, ~e applied the greedy search algorithm to each set of sentences in the intersected corpus contaming w For a subset of 95 words (53 nouns and 42 verbs), the algorithm was able to derive a coarser set of 2 or more senses for each of these 95 words such that the resulting Kappa ~alue reaches 0 8 or higher For the other 96 words, m order for the Kappa value to reach 0 8 or higher, the algorithm collapses all senses of the ~ord to a single (trivial) class Table 2 and 3 summarizes the results for the set of 53 nouns and 42 ~erbs, respectively Table 2 md~cates that before the collapse of sense classes, these 53 nouns have an average of 7 6 senses per noun There is a total of 5,339 sentences in the intersected corpus containing these nouns, of which 3,387 sentences were assigned the same sense by the two groups of human annotators The average Kappa statistic (computed as a simple average of the Kappa statistic of ~he mdlwdual nouns) is 0 463 After the collapse of sense classes by the greedy search algorithm, the average number of senses per noun for these 53 nouns drops to 40 Howe~er, the number of sentences which have been asmgned the same coarse sense by the annotators increases to 5,033 That is, about 94 3% of the sentences have been assigned the same coarse sense, and that the average Kappa statistic has improved to 0 862, mgmfymg high rater-annotator agreement on the derived coarse senses Table3 gl~es the analogous figures for the 42 verbs, agmn mdmatmg that high agreement is achieved on the coarse sense classes den~ed for verbs 7 Discussion Our findings on rater-annotator agreement for word sense tagging indicate that for average language users, it is quite dl~cult to achieve high agreement when they are asked to assign refned sense tags (such as those found in WORDNET) given only the scanty definition entries m the WORDNET dlctionary and a few or no example sentences for the usage of each word sense Thin observation agrees wlth that obtmned m a recent study done by (Veroms, 1998), where the agreement on sense-tagging by naive users was also not hlgh Thus It appears that an average language user is able to process language wlthout needing to perform the task of dlsamblguatmg word sense to a very fine-grained resolutmn as formulated m a tradltlonal dmtlonary In contrast, expert lexicographers tagged the ~ ord sense in the sentences used m the SENSEVAL exerclse, where high rater-annotator agreement was reported There are also fuller dlctlonary entries m the HECTOR dlctlonary used and more e<amples showing the usage of each word sense m HECTOR These factors are likely to have contributed to the difference in rater-annotator agreement observed m the three studies conducted We also examined the coarse sense classes derived by the greedy search algorithm Vv'e found some interesting groupings of coarse senses for nouns which ~e hst in Table 4 From Table 4, it is apparent that the greedy search algorithm can derive interesting groupings of word senses that correspond to human mtmtwe judgment of sense graz}.ulanty It Is clear that some of the disagreement between the two groups of human annotators can be attributed solely to the overly refined senses of WoRDNET As an example, there is a total Ii loop: let Ct,, C M denote the current M sense classes ~* +--oo for all z,3 such that 1 <, < 3 < M let C\[,,C~w_ 1 denote the resulting M 1 sense classes by mergmg C, and C 3 compute ~(C\[,, C~/_t) ff ~(C,, C~4_x) > ~* then ~"" +~(C~,,C~_t), z* +~, ~* +end for merge the sense class C,.",1,original
"Our training and test corpora, for instance, are lessthan-gargantuan compared to such collections as the Penn Treebank \[Marcus et al. , 1993\].",1,original
"Furthermore, good results have been produced in other areas of NLP research using maximum entropy techniques (Berger et al. , 1996; Koeling, 2001; Ratnaparkhi, 1997a).",1,original
"The maximum entropy approach (Berger et al., 1996) is known to be well suited to solve the classification problem.",1,original
"The classification is performed with a statistical approach, built around the maximum entropy (MaxEnt) principle (Berger et al., 1996), that has the advantage of combining arbitrary types of information in making a classification decision.",1,original
"2.2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as 928 log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
"To estimate the parameters of the MEMM+pred model we turn to the successful Maximum Entropy (Berger et al., 1996) parameter estimation method.",1,original
"2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
"In order to estimate the conditional distributions shown in Table 1, we use the general technique of choosing the MaxEnt distribution that properly estimates the average of each feature over the training data (Berger et al., 1996).",1,original
"The bigram translation probability relies on word context, known to be helpful in translation (Berger et al. , 1996), to improve the identification of target phrases.",1,original
"We decided to use the class of maximum entropy models, which are probabilistically sound, can make use of possibly many overlapping features, and can be trained efficiently (Berger et al., 1996).",1,original
"2.3 Classifier Training We chose maximum entropy (Berger et al., 1996) as our primary classifier, since it had been successfully applied by the highest performing systems in both the SemEval-2007 preposition sense disambiguation task (Ye and Baldwin, 2007) and the general word sense disambiguation task (Tratz et al., 2007).",1,original
"2.3 Classifier Training We chose maximum entropy (Berger, 1996) as our primary classifier because the highest performing systems in both the SemEval-2007 preposition sense disambiguation task (Ye and Baldwin, 2007) and the general word sense disambiguation task (Tratz et al., 2007) used it.",1,original
"Maximum entropy can be used to improve IBM-style translation probabilities by using features, such as improvements to P(f|e) in (Berger et al. , 1996).",1,original
"Effective training algorithm exists (Berger et al. , 1996) once the set of features a42 a57 a16 a1a33a8 a71a54a8 a71a100a85a68a5 a53 is selected.",1,original
"Another interesting point is the relation to maximum entropy model (Berger et al. , 1996), which is popular in the natural language processing community.",1,original
"5.4 Maximum Entropy Maximum entropy has been proven to be an effective method in various natural language processing applications (Berger et al. , 1996).",1,original
"An especially well-founded framework is maximum entropy (Berger et al. , 1996).",1,original
"(Berger et al. , 1996) gave a good description of ME model.",1,original
"The maximum entropy model (Berger et al. , 1996) provides us with a well-founded framework for this purpose, which has been extensively used in natural lan guage processing tasks ranging from part-ofspeech tagging to machine translation.",1,original
"Weusemaximumentropy models (Berger et al. , 1996), which are particularly well-suited for tasks (like ours) with many overlapping features, to harness these linguistic insights by using features in our models which encode, directly or indirectly, the linguistic correlates to SE types.",1,original
"Support Vector Machines (SVMs) (Vapnik, 1995) and Maximum Entropy (ME) method (Berger et al. , 1996) are powerful learning methods that satisfy such requirements, and are applied successfully to other NLP tasks (Kudo and Matsumoto, 2000; Nakagawa et al. , 2001; Ratnaparkhi, 1996).",1,original
"5.2 Maximum Entropy Maximum entropy classiflcation (MaxEnt, or ME, for short) is an alternative technique which has proven efiective in a number of natural language processing applications (Berger et al. , 1996).",1,original
"Maximum entropy models (Jaynes, 1957; Berger et al. , 1996; Della Pietra et al. , 1997) are a class of exponential models which require no unwarranted independence assumptions and have proven to be very successful in general for integrating information from disparate and possibly overlapping sources.",1,original
"State-of-theart machine learning techniques including Support Vector Machines (Vapnik, 1995), AdaBoost (Schapire and Singer, 2000) and Maximum Entropy Models (Ratnaparkhi, 1998; Berger et al. , 1996) provide high performance classifiers if one has abundant correctly labeled examples.",1,original
"1 Introduction The maximum entropy model (Berger et al. , 1996; Pietra et al. , 1997) has attained great popularity in the NLP field due to its power, robustness, and successful performance in various NLP tasks (Ratnaparkhi, 1996; Nigam et al. , 1999; Borthwick, 1999).",1,original
"A more refined algorithm, the incremental feature selection algorithm by Berger et al (1996), allows one feature being added at each selection and at the same time keeps estimated parameter values for the features selected in the previous stages.",1,original
"Each component model takes the exponential form: a37a55a38a57a56 a51 a42a6a44a59a58a60a56 a61 a51a64a63a65a53a67a66 a53 a45a46a70 a71a16a72a21a73a75a74a77a76a79a78a81a80 a78a16a82a11a78 a38a83a44a59a58a60a56a84a61 a51a64a63a65a53a67a66 a53 a58a60a56 a51 a45a86a85 a87 a38a83a44a59a58a60a56a84a61 a51a64a63a65a53a67a66 a53 a45 a58 (2) where a87 a38a83a44a59a58a60a56 a61 a51a41a63a65a53a67a66 a53 a45 is a normalization term to ensure that a37a55a38a57a56 a51a42a6a44a88a58a60a56a62a61 a51a41a63a65a53a67a66 a53 a45 is a probability, a82a11a78 a38a83a44a59a58a60a56 a61 a51a64a63a65a53a67a66 a53 a58a60a56 a51 a45 is a feature function (often binary) and a80 a78 is the weight ofa82a21a78 . Given a set of features and a corpus of training data, there exist ef cient training algorithms (Darroch and Ratcliff, 1972; Berger et al. , 1996) to nd the optimal parameters a89 a80 a78a14a90 . The art of building a maximum entropy parser then reduces to choosing good features.",1,original
"Since its introduction to the Natural Language Processing (NLP) community (Berger et al. , 1996), ME-based classifiers have been shown to be effective in various NLP tasks.",1,original
"1 Introduction The Maximum Entropy (ME) statistical framework (Darroch and Ratcliff, 1972; Berger et al. , 1996) has been successfully deployed in several NLP tasks.",1,original
"In the case of two orientation classes, cj,j is defined as: cj,j = braceleftbigg left, if j < j right, if j > j (4) Then, the reordering model has the form p(cj,j|fJ1,eI1,i,j) A well-founded framework for directly modeling the probability p(cj,j|fJ1,eI1,i,j) is maximum entropy (Berger et al. , 1996).",1,original
"(2006), but we use a maximum entropy classifier (Berger et al. , 1996) to determine parser actions, which makes parsing extremely fast.",1,original
"Exponential family models are a mainstay of modern statistical modeling (Brown, 1986) and they are widely and successfully used for example in text classification (Berger et al. , 1996).",1,original
"(2006), but we use a maximum entropy classifier (Berger et al., 1996) to determine parser actions, which makes parsing considerably faster.",1,original
"Clearly a more sophisticated feature selection routine such as the ones in (Berger et al. , 1996), or (Berger and Printz, 1998) would be required in this case.",1,original
"More complete discussions of M.E. as applied to computational linguistics, including a description of the M.E. estimation procedure can be found in (Berger et al. , 1996) and (Della Pietra et al. , 1995).",1,original
"As agreement measure we choose the Kappa coefficient  (Fleiss, 1971; Siegel and Castellan, 1988), the agreement measure predominantly used in natural language processing research (Carletta, 1996).",1,original
"Although the Kappa coefficient has a number of advantages over percentage agreement (e.g. , it takes into account the expected chance interrater agreement; see Carletta (1996) for details), we also report percentage agreement as it allows us to compare straightforwardly the human performance and the automatic methods described below, whose performance will also be reported in terms of percentage agreement.",1,original
"Since Jean Carletta (1996) exposed computational linguists to the desirability of using chance-corrected agreement statistics to infer the reliability of data generated by applying coding schemes, there has been a general acceptance of their use within the field.",1,original
"6.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient(K)whichiswidelyused in computational linguistics for measuring agreement in category judgments (Carletta, 1996).",1,original
"As aptly pointed out in Jean Carletta (1996), agreement measures proposed so far in the computational linguistics literature has failed to ask an important question of whether results obtained using agreement data are in any way different from random data.",1,original
"Because the expressiveness characteristics of ITG naturally constrain the space of possible matching in a highly appropriate fashion, BTG achieves encouraging results for bilingual bracketing using a word-translation lexicon alone (Wu 1997).",1,original
"Coming from the other direction, such observations about phrase reordering between different languages are precisely thekindsoffactsthatparsingapproachestomachine translation are designed to handle and do successfully handle (Wu, 1997; Melamed, 2003; Chiang, 2005).",1,original
"1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT).",1,original
"2.2 ITG Space Inversion Transduction Grammars, or ITGs (Wu, 1997) provide an efficient formalism to synchronously parse bitext.",1,original
"Wu (1995, 1997) investigated the use of concurrent parsing of parallel corpora in a transduction inversion framework, helping to resolve attachment ambiguities in one language by the coupled parsing state in the second language.",1,original
"Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation (Yamada and Knight, 2001) and Inversion Transduction Grammar (Wu, 1997).",1,original
Wu (1997) showed that restricting word-level alignments between sentence pairs to observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows a polynomial-time solution.,1,original
"In the hierarchical phrase-based model (Chiang, 2005), and an inversion transduction grammar (ITG) (Wu, 1997), the problem is resolved by restricting to a binarized form where at most two non-terminals are allowed in the righthand side.",1,original
"Wu (1997) has been unable to find real examples of cases where hierarchical alignment would fail under these conditions, at least in fixed-word-order languages that are lightly inflected, such as English and Chinese. (p. 385).",1,original
"The Inversion Transduction Grammar or ITG formalism, described in (Wu, 1997), is well suited for our purposes.",1,original
"Fortunately, Wu (1997) provides a method to have an ITG respect a known partial structure.",1,original
"1 Introduction For statistical machine translation (SMT), phrasebased methods (Koehn et al. , 2003; Och and Ney, 2004) and syntax-based methods (Wu, 1997; Alshawi et al. 2000; Yamada and Knignt, 2001; Melamed, 2004; Chiang, 2005; Quick et al. , 2005; Mellebeek et al. , 2006) outperform word-based methods (Brown et al. , 1993).",1,original
"Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 2003).",1,original
"1 Introduction In recent years, Bracketing Transduction Grammar (BTG) proposed by (Wu, 1997) has been widely used in statistical machine translation (SMT).",1,original
"Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings.",1,original
"This source of overcounting is considered and fixed by Wu (1997) and Zens and Ney (2003), which we briefly review here.",1,original
"Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al. , 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising.",1,original
"More suitable ways could be bilingual chunk parsing, and refining the bracketing grammar as described in [Wu 1997].",1,original
"Whereas language generation has benefited from syntax [Wu, 1997; Alshawi et al. , 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [Koehn et al. , 2003].",1,original
"Moreover, for reasons discussed by Wu (1997), ITGs possess an interesting intrinsic combinatorial property of permitting roughly up to four arguments of any frame to be transposed freely, but not more.",1,original
"An efficient Viterbi-like parsing algorithm that is based on a Dynamic Programing Scheme is proposed in (Wu, 1997).",1,original
"The efficient block alignment algorithm in Section 4 is related to the inversion transduction grammar approach to bilingual parsing described in (Wu, 1997): in both cases the number of alignments is drastically reduced by introducing appropriate re-ordering restrictions.",1,original
"Inversion transduction grammar (Wu, 1997), or ITG, is a wellstudied synchronous grammar formalism.",1,original
"Synchronous parsing models have been explored with moderate success (Wu, 1997; Quirk et al. , 2005).",1,original
"However, the only known work which automates part of a customer service center using natural language dialogue is the one by Chu-Carroll and Carpenter (1999).",1,original
"g2 2 Motivation The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g. , Barzilay & Lee, 2003; Pang et al. , 2003; Quirk et al. , 2004; Finch et al. , 2004).",1,original
"Such a method alleviates the problem of creating templates from examples which would be used in an ulterior phase of generation (BARZILAY and LEE, 2003).",1,original
"1 Introduction State-of-the-art Statistical Machine Translation (SMT) systems usually adopt a two-pass search strategy (Och, 2003; Koehn, et al., 2003) as shown in Figure 1.",1,original
"1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation.",1,original
"For French/English translation we use a state of the art phrase-based MT system similar to (Och and Ney, 2004; Koehn et al. , 2003).",1,original
"1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al. , 2003; Chiang, 2005) or syntax-based translation (Galley et al. , 2006).",1,original
"486 One of the most popular instantiations of loglinear models is that including phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003).",1,original
"Beam-search has been successful in many NLP tasks (Koehn et al., 2003; 562 Inputs: training examples (xi,yi) Initialization: set vectorw = 0 Algorithm: // R training iterations; N examples for t = 1R, i = 1N: zi = argmaxyGEN(xi) (y) vectorw if zi negationslash= yi: vectorw = vectorw + (yi)(zi) Outputs: vectorw Figure 1: The perceptron learning algorithm Collins and Roark, 2004), and can achieve accuracy that is close to exact inference.",1,original
"1 Introduction Many state-of-the-art machine translation (MT) systems over the past few years (Och and Ney, 2002; Koehn et al., 2003; Chiang, 2007; Koehn et al., 2007; Li et al., 2009) rely on several models to evaluate the goodness of a given candidate translation in the target language.",1,original
"1 Introduction We have seen rapid recent progress in machine translation through the use of rich features and the development of improved decoding algorithms, often based on grammatical formalisms.1 If we view MT as a machine learning problem, features and formalisms imply structural independence assumptions, which are in turn exploited by efficient inference algorithms, including decoders (Koehn et al., 2003; Yamada and Knight, 2001).",1,original
"1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT).",1,original
"Besides relative frequencies, lexical weights (Koehn et al., 2003) are widely used to estimate how well the words in f translate the words in e. To do this, one needs first to estimate a lexical translation probability distribution w(e|f) by relative frequency from the same word alignments in the training corpus: w(e|f) = count(f,e)summationtext e count(f,e) (3) Note that a special source NULL token is added to each source sentence and aligned to each unaligned target word.",1,original
"1 Introduction Todays statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (Koehn et al. , 2003; Zens and Ney, 2004; Och and Ney, 2003).",1,original
"For our experiments, we chose GIZA++ (Och and Ney, 2000) and the RA approach (Koehn et al. , 2003) the best known alignment combination technique as our initial aligners.1 4.2 TBL Templates Our templates consider consecutive words (of size 1, 2 or 3) in both languages.",1,original
"Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al. , 2004; Koehn et al. , 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al. , 2004; Zens and Ney, 2004).",1,original
"Although bi-alignments are known to exhibit high precision (Koehn et al., 2003), in the face of sparse annotations we use unidirectional alignments as a fallback, as has been proposed in the context of phrase-based machine translation (Koehn et al., 2003; Tillmann, 2003).",1,original
"Phrases extracted using these heuristics are also shown to perform better than syntactically motivated phrases, the joint model, and IBM model 4 (Koehn et al., 2003).",1,original
"Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005).",1,original
"Along this line, (Koehn et al. , 2003) present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance  the ability to translate nonconstituent phrases (such as there are, note that, and according to) turns out to be critical and pervasive.",1,original
"1 Introduction In recent years, phrase-based systems for statistical machine translation (Och et al. , 1999; Koehn et al. , 2003; Venugopal et al. , 2003) have delivered state-of-the-art performance on standard translation tasks.",1,original
"2 The Problem of Coverage in SMT Statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004).",1,original
"We view this as a particularly promising aspect of our work, given that phrase-based systems such as Pharaoh (Koehn et al. , 2003) perform better with higher recall alignments.",1,original
"Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g. , Och and Ney, 2002; Koehn et al. , 2003; Quirk et al. , 2005; Chiang, 2005; Galley et al. , 2006).",1,original
"They provide pairs of phrases that are used to construct a large set of potential translations for each input sentence, along with feature values associated with each phrase pair that are used to select the best translation from this set.1 The most widely used method for building phrase translation tables (Koehn et al. , 2003) selects, from a word alignment of a parallel bilingual training corpus, all pairs of phrases (up to a given length) that are consistent with the alignment.",1,original
"We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al. , 2003; Koehn, 2004a), against our system.",1,original
"Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score (a statistically significant improvement), using a phrase-based system (Koehn et al. , 2003) which has been shown in the past to be a highly competitive SMT system.",1,original
"More recently, phrase-based models (Och et al. , 1999; Marcu and Wong, 2002; Koehn et al. , 2003) have been proposed as a highly successful alternative to the IBM models.",1,original
"Recently, various works have improved the quality of statistical machine translation systems by using phrase translation (Koehn et al. , 2003; Marcu et al. , 2002; Och et al. , 1999; Och and Ney, 2000; Zens et al. , 2004).",1,original
"1 Introduction Phrase-based translation models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004), which go beyond the original IBM translation models (Brown et al. , 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations.",1,original
"4 Experiments Phrase-based SMT systems have been shown to outperform word-based approaches (Koehn et al. , 2003).",1,original
"To perform translation, state-of-the-art MT systems use a statistical phrase-based approach (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) by treating phrases as the basic units of translation.",1,original
"Recently, Cabezas and Resnik (2005) experimented with incorporating WSD translations into Pharaoh, a state-of-the-art phrase-based MT system (Koehn et al. , 2003).",1,original
"1 Introduction Statistical machine translation (Brown et al. , 1993) has seen many improvements in recent years, most notably the transition from wordto phrase-based models (Koehn et al. , 2003).",1,original
1 Motivation Phrase-based statistical machine translation (Koehn et al. 2003) has emerged as the dominant paradigm in machine translation research.,1,original
"Phrase-based decoding (Koehn et al., 2003) is a dominant formalism in statistical machine translation.",1,original
"The most widely used approach derives phrase pairs from word alignment matrix (Och and Ney, 2003; Koehn et al., 2003).",1,original
"However, since most of statistical translation models (Koehn et al., 2003; Chiang, 2007; Galley et al., 2006) are symmetrical, it is relatively easy to train a translation system to translate from English to Chinese, except that weneed to train aChinese language model from the Chinese monolingual data.",1,original
"1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well.",1,original
"1 Introduction Phrase-based systems (Koehn et al., 2003) are probably the most widespread class of Statistical Machine Translation systems, and arguably one of the most successful.",1,original
"1 Introduction Hierarchical approaches to machine translation have proven increasingly successful in recent years (Chiang, 2005; Marcu et al., 2006; Shen et al., 2008), and often outperform phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) on target-language fluency and adequacy.",1,original
"1 Introduction The field of machine translation has seen many advances in recent years, most notably the shift from word-based (Brown et al., 1993) to phrasebased models which use token n-grams as translation units (Koehn et al., 2003).",1,original
"1 Introduction In recent years, various phrase translation approaches (Marcu and Wong, 2002; Och et al. , 1999; Koehn et al. , 2003) have been shown to outperform word-to-word translation models (Brown et al. , 1993).",1,original
"1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy.",1,original
"1 Introduction During the last few years, SMT systems have evolved from the original word-based approach (Brown et al. , 1993) to phrase-based translation systems (Koehn et al. , 2003).",1,original
"The current state of the art is represented by the so-called phrase-based translation approach (Och and Ney, 2004; Koehn et al. , 2003).",1,original
"This translation model differs from the well known phrase-based translation approach (Koehn et al. , 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies.",1,original
"However, attempts to retrofit syntactic information into the phrase-based paradigm have not met with enormous success (Koehn et al. , 2003; Och et al. , 2003)1, and purely phrase-based machine translation systems continue to outperform these syntax/phrase-based hybrids.",1,original
"1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al. , 2003) significantly outperform the historical word-based modeling (Brown et al. , 1993).",1,original
"And again, we see this insight informing statistical machine translation systems, for instance, in the phrase-based approaches of Och (2003) and Koehn et al.",1,original
"1 Introduction Modern phrasal SMT systems such as (Koehn et al. , 2003) derive much of their power from being able to memorize and use long phrases.",1,original
"Phrase-based MT systems are straightforward to train from parallel corpora (Koehn et al., 2003) and, like the original IBM models (Brown et al., 1990), benefit from standard language models built on large monolingual, target-language corpora (Brants et al., 2007).",1,original
"3 System Overview 3.1 Translation model The system developed for this years shared task is a state-of-the-art, two-pass phrase-based statistical machine translation system based on a log-linear translation model (Koehn et al, 2003).",1,original
"2.2 Phrase-based Chinese-to-English MT The MT system used in this paper is Moses, a stateof-the-art phrase-based system (Koehn et al., 2003).",1,original
"1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation.",1,original
"1 Introduction Phrase-based Statistical MT (PB-SMT) (Koehn et al., 2003) has become the predominant approach to Machine Translation in recent years.",1,original
"Phrase-based models (Och and Ney, 2004; Koehn et al., 2003) have been a major paradigm in statistical machine translation in the last few years, showing state-of-the-art performance for many language pairs.",1,original
"4 Machine Translation Experiments 4.1 Experimental Setting For our MT experiments, we used a reimplementation of Moses (Koehn et al., 2003), a state-of-the-art phrase-based system.",1,original
"1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003a) has been one of the major developments in statistical approaches to translation.",1,original
"We conclude with some challenges that still remain in applying proactive learning for MT. 2 Syntax Based Machine Translation In recent years, corpus based approaches to machine translation have become predominant, with Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003) being the most actively progressing area.",1,original
"1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model.",1,original
"The state-of-the-art SMT system Moses implements a distance-based reordering model (Koehn et al., 2003) and a distortion model, operating with rewrite patterns extracted from a phrase alignment table (Tillman, 2004).",1,original
"2.2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as 928 log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
"2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
"5.2 Results We use a Maximum Entropy (ME) classi er (Manning and Klein, 2003) which allows an e cient combination of many overlapping features.",1,original
"1 Introduction Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation (SMT) (Galley et al., 2004; Liu et al., 2006, 2007; Zhang et al., 2007, 2008a; Mi et al., 2008; Mi and Huang 2008; Zhang et al., 2009).",1,original
"This algorithm is referred to as GHKM (Galley et al., 2004) and is widely used in SSMT systems (Galley et al., 2006; Liu et al., 2006; Huang et al., 2006).",1,original
"However, to be more expressive and flexible, it is often easier to start with a general SCFG or tree-transducer (Galley et al. , 2004).",1,original
"Experiments show that the resulting rule set significantly improves the speed and accuracy over monolingual binarization (see Table 1) in a stateof-the-art syntax-based machine translation system (Galley et al. , 2004).",1,original
"Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al. , 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/a0 tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce.",1,original
"We believe that the extensive usage of such measures derives also from the availability of robust and freely availablesoftwarethatallowstocomputethem(Pedersen et al. , 2004, WordNet::Similarity).",1,original
"The WordNet::Similarity package provides a flexible implementation of many of these measures (Pedersen et al., 2004).",1,original
"Also, slightly restating the advantages of phrase-pairs identified in (Quirk and Menezes, 2006), these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables (e.g. embedding between ne . . .pas in French), have sparsity problems, and lack a strategy for global reordering.",1,original
"However, in (Quirk and Menezes, 2006), the authors investigate minimum translation units (MTU) which is a refinement over a similar approach by (Banchs et al. , 2005) to eliminate the overlap issue.",1,original
"David McClosky, Eugene Charniak, and Mark Johnson Brown Laboratory for Linguistic Information Processing (BLLIP) Brown University Providence, RI 02912 {dmcc|ec|mj}@cs.brown.edu Abstract Self-training has been shown capable of improving on state-of-the-art parser performance (McClosky et al., 2006) despite the conventional wisdom on the matter and several studies to the contrary (Charniak, 1997; Steedman et al., 2003).",1,original
"Its success stories range from parsing (McClosky et al., 2006) to machine translation (Ueffing, 2006).",1,original
"For English, self-training contributes 0.83% absolute improvement to the PCFG-LA parser, which is comparable to the improvement obtained from using semi-supervised training with the twostage parser in (McClosky et al., 2006).",1,original
"2 Motivation and Prior Work While several authors have looked at the supervised adaptation case, there are less (and especially less successful) studies on semi-supervised domain adaptation (McClosky et al., 2006; Blitzer et al., 2006; Dredze et al., 2007).",1,original
"There are only a few successful studies, such as (Ando and Zhang, 2005) for chunking and (McClosky et al., 2006a; McClosky et al., 2006b) on constituency parsing.",1,original
"Recent work, (McClosky et al. , 2006), has shown that adding many millions of words of machine parsed and reranked LA Times articles does, in fact, improve performance of the parser on the closely related WSJ data.",1,original
"Furthermore, use of the self-training techniques described in (McClosky et al. , 2006) raise this to 87.8% (an error reduction of 28%) again without any use of labeled Brown data.",1,original
"In the II, OO, and OI scenarios, (McClosky et al, 2006a; 2006b) succeeded in improving the parser performance only when a reranker was used to reorder the 50-best list of the generative parser, with a seed size of 40K sentences.",1,original
"Recently, (McClosky et al. , 2006a; McClosky et al. , 2006b) have successfully applied self-training to various parser adaptation scenarios using the reranking parser of (Charniak and Johnson, 2005).",1,original
"As a result, the good results of (McClosky et al, 2006a; 2006b) with large seed sets do not immediately imply success with small seed sets.",1,original
"Tighter integration of semantics into the parsing models, possibly in the form of discriminative reranking models (Collins and Koo, 2005; Charniak and Johnson, 2005; McClosky et al., 2006), is a promising way forward in this regard.",1,original
"We also plan to apply self-training of n-best tagger which successfully boosted the performance of one of the best existing English syntactic parser (McClosky et al. , 2006).",1,original
The novel idea presented in Strube & Ponzetto (2006) was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness.,1,original
"Recently, Ponzetto and Strube (2006) suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet.",1,original
"Riezler and Maxwell (2006) do not achieve higher BLEU scores, but do score better according to human grammaticality judgments for in-coverage cases.",1,original
Riezler and III (2006) report an improvement in MT grammaticality on a very restricted test set: short sentences parsable by an LFG grammar without back-off rules.,1,original
"Synchronous binarization (Zhang et al. , 2006) solves this problem by simultaneously binarizing both source and target-sides of a synchronous rule, making sure of contiguous spans on both sides whenever possible.",1,original
"Recent work by (Zhang et al., 2006) shows a practically ef cient approach that binarizes linguistically SCFG rules when possible.",1,original
Haghighi and Klein (2006) showed that adding a small set of prototypes to the unlabeled data can improve tagging accuracy significantly.,1,original
"In particular, (Haghighi and Klein, 2006) presents very strong results using a distributional-similarity module and achieve impressive tagging accuracy while starting with a mere 116 prototypical words.",1,original
"This type of input information (features + majority label) is a powerful and flexible model for specifying alternative inputs to a classifier, and has been additionally used by Haghighi and Klein (2006).",1,original
"In particular, we have implemented an unsupervised morphological analyzer that outperforms Goldsmith s (2001) Linguistica and Creutz and Lagus s (2005) Morfessor for our English and Bengali datasets and compares favorably to the bestperforming morphological parsers in MorphoChallenge 20053 (see Dasgupta and Ng (2007)).",1,original
"Dasgupta and Ng (2007) improves over (Creutz, 2003) by suggesting a simpler approach.",1,original
"With the in-depth study of opinion mining, researchers committed their efforts for more accurate results: the research of sentiment summarization (Philip et al., 2004; Hu et al., KDD 2004), domain transfer problem of the sentiment analysis (Kanayama et al., 2006; Tan et al., 2007; Blitzer et al., 2007; Tan et al., 2008; Andreevskaia et al., 2008; Tan et al., 2009) and finegrained opinion mining (Hatzivassiloglou et al., 2000; Takamura et al., 2007; Bloom et al., 2007; Wang et al., 2008; Titov et al., 2008) are the main branches of the research of opinion mining.",1,original
"In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns (e.g., X or Y) to get more accurate co-occurrence statistics (Chilovski and Pantel, 2004; Bollegala et al., 2007).",1,original
"However, the most interesting work is certainly proposed by (Bollegala et al., 2007) who extract patterns in two steps.",1,original
"Automated metrics such as BLEU (Papineni et al. , 2002), RED (Akiba et al, 2001), Weighted N-gram model (WNM) (Babych, 2004), syntactic relation / semantic vector model (Rajman and Hartley, 2001) have been shown to correlate closely with scoring or ranking by different human evaluation parameters.",1,original
"It was found to produce automated scores, which strongly correlate with human judgements about translation fluency (Papineni et al. , 2002).",1,original
"The state-of-the-art methods for automatic MT evaluation are using an n-gram based metric represented by BLEU (Papineni et al., 2002) and its variants.",1,original
"In addition to the widely used BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) scores, we also evaluate translation quality with the recently proposed Meteor (Banerjee and Lavie, 2005) and four edit-distance style metrics, Word Error Rate (WER), Positionindependent word Error Rate (PER) (Tillmann et al. , 1997), CDER, which allows block reordering (Leusch et al. , 2006), and Translation Edit Rate (TER) (Snover et al. , 2006).",1,original
"The translation quality is evaluated using a well-established automatic measure: BLEU score (Papineni et al. , 2002).",1,original
"A popular metric for evaluating machine translation quality is the Bleu score (Papineni et al. , 2002).",1,original
"2.1 The BLEU Metric The metric most often used with MERT is BLEU (Papineni et al., 2002), where the score of a candidate c against a reference translation r is: BLEU = BP(len(c),len(r))exp( 4summationdisplay n=1 1 4 logpn), where pn is the n-gram precision2 and BP is a brevity penalty meant to penalize short outputs, to discourage improving precision at the expense of recall.",1,original
"It is the most widely reported metric in MT research, and has been shown to correlate well with human judgment (Papineni et al., 2002; Coughlin, 2003).",1,original
"The full model yields a stateof-the-art BLEU (Papineni et al., 2002) score of 0.8506 on Section 23 of the CCGbank, which is to our knowledge the best score reported to date 410 using a reversible, corpus-engineered grammar.",1,original
"3.2 Evaluation Criteria Well-established objective evaluation measures like the word error rate (WER), positionindependent word error rate (PER), and the BLEU score (Papineni et al. , 2002) were used to assess the translation quality.",1,original
"State-of-the-art measures such as BLEU (Papineni et al. , 2002) or NIST (Doddington, 2002) aim at measuring the translation quality rather on the document level1 than on the level of single sentences.",1,original
"While studies have shown that ratings of MT systems by BLEU and similar metrics correlate well with human judgments (Papineni et al. , 2002; Doddington, 2002), we are not aware of any studies that have shown that corpus-based evaluation metrics of NLG systems are correlated with human judgments; correlation studies have been made of individual components (Bangalore et al. , 2000), but not of systems.",1,original
"The BLEU metric (Papineni et al. , 2002) in MT has been particularly successful; for example MT05, the 2005 NIST MT evaluation exercise, used BLEU-4 as the only method of evaluation.",1,original
"Properly calculated BLEU scores have been shown to correlate reliably with human judgments (Papineni et al. , 2002).",1,original
"Some NLG researchers are impressed by the success of the BLEU evaluation metric (Papineni et al. , 2002) in Machine Translation (MT), which has transformed the MT field by allowing researchers to quickly and cheaply evaluate the impact of new ideas, algorithms, and data sets.",1,original
"The table also shows the popular BLEU (Papineni et al. , 2002) and NIST2 MT metrics.",1,original
"3 Previous Work The idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs was first successfully implemented in the BLEU metric for machine translation (Papineni et al. , 2002).",1,original
"4.4.1 N-gram Co-Occurrence Statistics for Answer Extraction N-gram co-occurrence statistics have been successfully used in automatic evaluation (Papineni et al. 2002, Lin and Hovy 2003), and more recently as training criteria in statistical machine translation (Och 2003).",1,original
"In machine translation, the rankings from the automatic BLEU method (Papineni et al. , 2002) have been shown to correlate well with human evaluation, and it has been widely used since and has even been adapted for summarization (Lin and Hovy, 2003).",1,original
"1 Introduction With the introduction of the BLEU metric for machine translation evaluation (Papineni et al, 2002), the advantages of doing automatic evaluation for various NLP applications have become increasingly appreciated: they allow for faster implement-evaluate cycles (by by-passing the human evaluation bottleneck), less variation in evaluation performance due to errors in human assessor judgment, and, not least, the possibility of hill-climbing on such metrics in order to improve system performance (Och 2003).",1,original
"We report results using the well-known automatic evaluation metrics Bleu (Papineni et al. , 2002).",1,original
"First, we compared our system output to human reference translations using Bleu (Papineni, et al. , 2002), a widelyaccepted objective metric for evaluation of machine translations.",1,original
"BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities (Papineni et al. , 2002; Doddington, 2002).",1,original
"One of the most successful metrics for judging machine-generated text is BLEU (Papineni et al. , 2002).",1,original
"The well-known BLEU (Papineni et al. , 2002) is based on the number of common n-grams between the translation hypothesis and human reference translations of the same sentence.",1,original
"2 Evaluation Metrics Currently, the most widely used automatic MT evaluation metric is the NIST BLEU-4 (Papineni et al. , 2002).",1,original
"The translation quality was evaluated using a well-established automatic measure: BLEU score (Papineni et al. , 2002).",1,original
"Among all the automatic MT evaluation metrics, BLEU (Papineni et al., 2002) is the most widely used.",1,original
"Since human evaluation is costly and difficult to do reliably, a major focus of research has been on automatic measures of MT quality, pioneered by BLEU (Papineni et al., 2002) and NIST (Doddington, 2002).",1,original
"It could be shown that such methods, of which BLEU (Papineni et al., 2002) is the most common, can deliver evaluation results that show a high agreement with human judgments (Papineni et al., 2002; Coughlin, 2003; Koehn & Monz, 2006).",1,original
"High correlation is reported between the BLEU score and human evaluations for translations from Arabic, Chinese, French, and Spanish to English (Papineni et al. , 2002a).",1,original
"Empirically the BLEU score has a high correlation with human evaluation when N = 4 for English translation evaluations (Papineni et al. , 2002b).",1,original
"BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities (Papineni et al. , 2002; Doddington, 2002).",1,original
"1 Introduction Automatic Metrics for machine translation (MT) evaluation have been receiving significant attention in the past two years, since IBM's BLEU metric was proposed and made available (Papineni et al 2002).",1,original
"The most widely used are Word Error Rate (WER), Position Independent Word Error Rate (PER), the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002).",1,original
"The most widely used are Word Error Rate (WER), Position independent word Error Rate (PER), the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002).",1,original
"The BLEU metric (Papineni et al. , 2002) and the closely related NIST metric (Doddington, 2002) along with WER and PER 48 have been widely used by many machine translation researchers.",1,original
"1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al. , 2002) and errorbased optimization (Och, 2003).",1,original
"The most widely known are the Word Error Rate (WER), the Position independent word Error Rate (PER), the NIST score (Doddington, 2002) and, especially in recent years, the BLEU score (Papineni et al. , 2002) and the Translation Error Rate (TER) (Snover et al. , 2005).",1,original
"3 Extending Bleu and Ter with Flexible Matching Many widely used metrics like Bleu (Papineni et al., 2002) and Ter (Snover et al., 2006) are based on measuring string level similarity between the reference translation and translation hypothesis, just like Meteor . Most of them, however, depend on finding exact matches between the words in two strings.",1,original
"After a brief period following the introduction of generally accepted and widely used metrics, BLEU (Papineni et al., 2002) and NIST (Doddington, 2002), when it seemed that this persistent problem has finally been solved, the researchers active in the field of machine translation (MT) started to express their worries that although these metrics are simple, fast and able to provide consistent results for a particular system during its development, they are not sufficiently reliable for the comparison of different systems or different language pairs.",1,original
"A novel approach was described in (Marcu and Echihabi, 2002), which used an unsupervised training technique, extracting relations that were explicitly and unamibiguously signalled and automatically labelling those examples as the training set.",1,original
"(Turney, 2002) is one of the most famous work that discussed learning polarity from corpus.",1,original
Turneys (2002) work is perhaps one of the most notable examples of unsupervised polarity classification.,1,original
"The conceptually simplest approach to this latter problem is probably Turneys (2002), who has obtained interesting results on Task 2 by considering the algebraic sum of the orientations of terms as representative of the orientation of the document they belong to; but more sophisticated approaches arealsopossible (Hatzivassiloglou and Wiebe, 2000; Riloff et al. , 2003; Wilson et al. , 2004).",1,original
"Turney also reported good result without domain customization (Turney, 2002).",1,original
Turneys (2002) work is perhaps one of the most notable examples of unsupervised polarity classification.,1,original
"In our future work we plan to investigate the effect of more sophisticated and, probably, more accurate filtering methods (Fleischman et al. , 2003) on the QA results.",1,original
"In contrast, the idea of bootstrapping for relation and information extraction was first proposed in (Riloff and Jones, 1999), and successfully applied to the construction of semantic lexicons (Thelen and Riloff, 2002), named entity recognition (Collins and Singer, 1999), extraction of binary relations (Agichtein and Gravano, 2000), and acquisition of structured data for tasks such as Question Answering (Lita and Carbonell, 2004; Fleischman et al. , 2003).",1,original
"1 Introduction State-of-the-art Statistical Machine Translation (SMT) systems usually adopt a two-pass search strategy (Och, 2003; Koehn, et al., 2003) as shown in Figure 1.",1,original
"1 Introduction Och (2003) introduced minimum error rate training (MERT) for optimizing feature weights in statistical machine translation (SMT) models, and demonstrated that it produced higher translation quality scores than maximizing the conditional likelihood of a maximum entropy model using the same features.",1,original
"(2) We note that these posterior probabilities can be computed efficiently for some alignment models such as the HMM (Vogel et al. , 1996; Och and Ney, 2003), Models 1 and 2 (Brown et al. , 1993).",1,original
"2.2 Unsupervised Parameter Estimation We can perform maximum likelihood estimation of the parameters of this model in a similar fashion to that of Model 4 (Brown et al. , 1993), described thoroughly in (Och and Ney, 2003).",1,original
"(Och and Ney, 2003) discussed efficient implementation.",1,original
"The current state-of-the-art is to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training (Och, 2003).",1,original
"The current state-of-the-art is to use minimum error rate training (MERT) as described in (Och, 2003).",1,original
"For instance, changing the training procedure for word alignment models turned out to be most beneficial; for details see (Och and Ney, 2003).",1,original
" Using the components of the row-vector bm as feature function values for the candidate translation em (m a16 1,,M), the system prior weights  can easily be trained using the Minimum Error Rate Training described in (Och, 2003).",1,original
"1 Introduction Since its introduction by Och (2003), minimum error rate training (MERT) has been widely adopted for training statistical machine translation (MT) systems.",1,original
"An important contribution to interactive CAT technology was carried out around the TransType (TT) project (Langlais et al., 2002; Foster et al., 2002; Foster, 2002; Och et al., 2003).",1,original
"1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT).",1,original
"However, this is not unprecedented: discriminatively weighted generative models have been shown to outperform purely discriminative competitors in various NLP classification tasks (Raina et al., 2004; Toutanova, 2006), and remain the standard approach in statistical translation modeling (Och, 2003).",1,original
"The remaining six entries were all fully automatic machine translation systems; in fact, they were all phrase-based statistical machine translation system that had been trained on the same parallel corpus and most used Bleubased minimum error rate training (Och, 2003) to optimize the weights of their log linear models feature functions (Och and Ney, 2002).",1,original
"The statistical machine translation community relies on the Bleu metric for the purposes of evaluating incremental system changes and optimizing systems through minimum error rate training (Och, 2003).",1,original
Och (2003) has described an efficient exact onedimensional accuracy maximization technique for a similar search problem in machine translation.,1,original
"Current state of the art machine translation systems (Och, 2003) use phrasal (n-gram) features extracted automatically from parallel corpora.",1,original
"Target language model probability (weight = 0.5) According to a previous study, the minimum error rate training (MERT) (Och, 2003), which is the optimization of feature weights by maximizing the BLEU score on the development set, can improve the performance of a system.",1,original
An efficient algorithm for performing this tuning for a larger number of model parameters can be found in Och (2003).,1,original
Other insights borrowed from the current state of the art include minimum-error-rate training of log-linear models (Och and Ney 2002; Och 2003) and use of an m-gram language model.,1,original
"4.4.1 N-gram Co-Occurrence Statistics for Answer Extraction N-gram co-occurrence statistics have been successfully used in automatic evaluation (Papineni et al. 2002, Lin and Hovy 2003), and more recently as training criteria in statistical machine translation (Och 2003).",1,original
"Recently so-called reranking techniques, such as maximum entropy models (Och and Ney, 2002) and gradient methods (Och, 2003), have been applied to machine translation (MT), and have provided significant improvements.",1,original
"In a later study, Och and Ney (2003) present a loglinear combination of the HMM and IBM Model 4 that produces better alignments than either of those.",1,original
"This type of direct optimization is known as Minimum Error Rate Training (Och, 2003) in the MT community, and is an essential component in building the stateof-art MT systems.",1,original
"The modified Powells method has been previously used in optimizing the weights of a standard feature-based MT decoder in (Och, 2003) where a more efficient algorithm for log-linear models was proposed.",1,original
"Finally, to estimate the parameters i of the weighted linear model, we adopt the popular minimum error rate training procedure (Och, 2003) which directly optimizes translation quality as measured by the BLEU metric.",1,original
"Studies reveal that statistical alignment models outperform the simple Dice coefficient (Och and Ney, 2003).",1,original
"It is promising to optimize the model parameters directly with respect to AER as suggested in statistical machine translation (Och, 2003).",1,original
"1 Introduction Phrase-based translation models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004), which go beyond the original IBM translation models (Brown et al. , 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations.",1,original
"While error-driven training techniques are commonly used to improve the performance of phrasebased translation systems (Chiang, 2005; Och, 2003), this paper presents a novel block sequence translation approach to SMT that is similar to sequential natural language annotation problems 727 such as part-of-speech tagging or shallow parsing, both in modeling and parameter training.",1,original
Och (2003) has described an ef cient exact one-dimensional error minimization technique for a similar search problem in machine translation.,1,original
"1 Introduction Raw parallel data need to be preprocessed in the modern phrase-based SMT before they are aligned by alignment algorithms, one of which is the wellknown tool, GIZA++ (Och and Ney, 2003), for training IBM models (1-4).",1,original
"Two popular techniques that incorporate the error criterion are Minimum Error Rate Training (MERT) (Och, 2003) and Minimum BayesRisk (MBR) decoding (Kumar and Byrne, 2004).",1,original
"4 Extended Minimum Error Rate Training Minimum error rate training (Och, 2003) is widely used to optimize feature weights for a linear model (Och and Ney, 2002).",1,original
"The NIST MT03 set is used to tune model weights (e.g. those of (16)) and the scaling factor 17We have also experimented with MERT (Och, 2003), and found that the deterministic annealing gave results that were more consistent across runs and often better.",1,original
"3.6 Parameter Estimation To estimate parameters k(1  k  K), lm, and um, we adopt the approach of minimum error rate training (MERT) that is popular in SMT (Och, 2003).",1,original
"By having the advantage of leveraging large parallel corpora, the statistical MT approach outperforms the traditional transfer based approaches in tasks for which adequate parallel corpora is available (Och, 2003).",1,original
"We wish to minimize this error function, so we select  accordingly: argmin  summationdisplay a E(a)(a, (argmax a p(a, f|e))) (4) Maximizing performance for all of the weights at once is not computationally tractable, but (Och, 2003) has described an efficient one-dimensional search for a similar problem.",1,original
"For symmetrization, we found that Och and Neys refined technique described in (Och and Ney, 2003) produced the best AER for this data set under all experimental conditions.",1,original
"The field of statistical machine translation has been blessed with a long tradition of freely available software tools  such as GIZA++ (Och and Ney, 2003)  and parallel corpora  such as the Canadian Hansards2.",1,original
"1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy.",1,original
"Furthermore, end-to-end systems like speech recognizers (Roark et al. , 2004) and automatic translators (Och, 2003) use increasingly sophisticated discriminative models, which generalize well to new data that is drawn from the same distribution as the training data.",1,original
"The MERT module is a highly modular, efficient and customizable implementation of the algorithm described in (Och, 2003).",1,original
"73 2.2.4 Minimum Error Rate Training A good way of training is to minimize empirical top-1 error on training data (Och, 2003).",1,original
"1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al. , 2002) and errorbased optimization (Och, 2003).",1,original
"Bleu is fast and easy to run, and it can be used as a target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical MT systems (Och, 2003).",1,original
"While the former is piecewise constant and thus cannot be optimized using gradient techniques, Och (2003) provides an approach that performs such training efficiently.",1,original
"Bleu is fast and easy to run, and it can be used as a target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical MT systems (Och, 2003).",1,original
"GIZA++ (Och and Ney 2003) is a very popular system within SMT for creating word alignment from parallel corpus, in fact, the Moses training scripts uses it.",1,original
The search across a dimension uses the efficient method of Och (2003).,1,original
"Ochs procedure is the most widely-used version of MERT for SMT (Och, 2003).",1,original
"Although they obtained consistent and stable performance gains for MT, these were inferior to the gains yielded by Ochs procedure in (Och, 2003).",1,original
"Some recent work on incremental parsing (Collins and Roark, 2004; Shen and Joshi, 2005) showed another way to handle this problem.",1,original
"Variants of this method have been successfully used in many NLP tasks, like shallow processing (Daume III and Marcu, 2005), parsing (Collins and Roark, 2004; Shen and Joshi, 2005) and word alignment (Moore, 2005).",1,original
"Incremental top-down and left-corner parsers have been shown to effectively (and efficiently) make use of non-local features from the left-context to yield very high accuracy syntactic parses (Roark, 2001; Henderson, 2003; Collins and Roark, 2004), and we will use such rich models to derive our scores.",1,original
"2.2 Perceptron-based training To tune the parameters w of the model, we use the averaged perceptron algorithm (Collins, 2002) because of its efficiency and past success on various NLP tasks (Collins and Roark, 2004; Roark et al. , 2004).",1,original
"Collins and Roark (2004) saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.",1,original
"Similar models have been successfully applied in the past to other tasks including parsing (Collins and Roark, 2004), chunking (Daume and Marcu, 2005), and machine translation (Cowan et al. , 2006).",1,original
"It is an online training algorithm and has been successfully used in many NLP tasks, such as POS tagging (Collins, 2002), parsing (Collins and Roark, 2004), Chinese word segmentation (Zhang and Clark, 2007; Jiang et al., 2008), and so on.",1,original
"To achieve efficient parsing, we use a beam search strategy like the previous methods (Collins and Roark, 2004; Roark, 2001; Roark, 2004).",1,original
"This approach has been shown to be accurate, relatively efficient, and robust using both generative and discriminative models (Roark, 2001; Roark, 2004; Collins and Roark, 2004).",1,original
"1 Introduction Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al. , 1999; Levy and Manning, 2004; Dubey and Keller, 2003).",1,original
"Its also worth noting that Collins and Roark (2004) saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.",1,original
"Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006).",1,original
"Recently, graph-based methods have proved useful for a number of NLP and IR tasks such as document re-ranking in ad hoc IR (Kurland and Lee, 2005) and analyzing sentiments in text (Pang and Lee, 2004).",1,original
"SVM has been shown to be useful for text classification tasks (Joachims, 1998), and has previously given good performance in sentiment classification experiments (Kennedy and Inkpen, 2006; Mullen and Collier, 2004; Pang and Lee, 2004; Pang et al., 2002).",1,original
"We chose a dataset that would be enjoyable to reannotate: the movie review dataset of (Pang et al. , 2002; Pang and Lee, 2004).3 The dataset consists of 1000 positive and 1000 negative movie reviews obtained from the Internet Movie Database (IMDb) review archive, all written before 2002 by a total of 312 authors, with a cap of 20 reviews per author per 2Taking Ccontrast to be constant means that all rationales are equally valuable.",1,original
"All reviews were automatically preprocessed to remove both explicit rating indicators and objective sentences; the motivation for the latter step is that it has previously aided positive vs. negative classi cation (Pang and Lee, 2004).",1,original
"Interestingly, previous sentiment analysis research found that a minimum-cut formulation for the binary subjective/objective distinction yielded good results (Pang and Lee, 2004).",1,original
"A later study (Pang and Lee, 2004) found that performance increased to 87.2% when considering only those portions of the text deemed to be subjective.",1,original
"Note that our result on Dataset A is as strong as that obtained by Pang and Lee (2004) via their subjectivity summarization algorithm, which retains only the subjective portions of a document.",1,original
"Indeed, recent work has shown that benefits can be made by first separating facts from opinions in a document (e.g, Yu and Hatzivassiloglou (2003)) and classifying the polarity based solely on the subjective portions of the document (e.g. , Pang and Lee (2004)).",1,original
"First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al. , 2005; Kim and Hovy, 2006).",1,original
"Table 1: Datasets 3.3 Establishing a Baseline for a Corpus-based System (CBS) Supervised statistical methods have been very successful in sentiment tagging of texts: on movie review texts they reach accuracies of 85-90% (Aue and Gamon, 2005; Pang and Lee, 2004).",1,original
"A two-tier scheme (Pang and Lee, 2004) where sentences are  rst classi ed as subjective versus objective, and then applying the sentiment classi er on only the subjective sentences further improves performance.",1,original
"And 20NG is a collection of approximately 20,000 20-category documents 1 . In sentiment text classification, we also use two data sets: one is the widely used Cornell movie-review dataset2 (Pang and Lee, 2004) and one dataset from product reviews of domain DVD3 (Blitzer et al., 2007).",1,original
"As has been previously observed and exploited in the NLP literature (Pang and Lee, 2004; Agarwal and Bhattacharyya, 2005; Barzilay and Lapata, 2005), the above optimization function, unlike many others that have been proposed for graph or set partitioning, can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs.",1,original
"Sentence-level subjectivity detection, where training data is easier to obtain than for positive vs. negative classification, has been successfully performed using supervised statistical methods alone (Pang and Lee, 2004) or in combination with a knowledgebased approach (Riloff et al. , 2006).",1,original
"3 CLaC-NB System: Nave Bayes Supervised statistical methods have been very successful in sentiment tagging of texts and in subjectivity detection at sentence level: on movie review texts they reach an accuracy of 85-90% (Aue and Gamon, 2005; Pang and Lee, 2004) and up to 92% accuracy on classifying movie review snippets into subjective and objective using both Nave Bayes and SVM (Pang and Lee, 2004).",1,original
"This paper demonstrates several of the characteristics and benefits of SemFrame (Green et al. , 2004; Green and Dorr, 2004), a system that produces such a resource.",1,original
"6 Discussion Noting that adding latent features to nonterminals in unlexicalized context-free parsing has been very successful (Chiang and Bikel, 2002; Matsuzaki et al. , 2005; Prescher, 2005; Dreyer and Eisner, 2006; Petrov et al. , 2006), we were surprised not to see a 3Czech experiments were not done, since the number of features (more than 14 million) was too high to multiply out by clusters.",1,original
"2 Parsing Model The Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007) is an efficient and effective parser that introduces latent annotations (Matsuzaki et al., 2005) to refine syntactic categories to learn better PCFG grammars.",1,original
"This was recently followed by (Matsuzaki et al., 2005; Petrov et al., 2006) who introduce state-of-the-art nearly unlexicalized PCFG parsers.",1,original
The latent-annotation model (Matsuzaki et al. 2005; Petrov et al. 2006) is one of the most effective un-lexicalized models.,1,original
"1 Introduction When data have distinct sub-structures, models exploiting latent variables are advantageous in learning (Matsuzaki et al., 2005; Petrov and Klein, 2007; Blunsom et al., 2008).",1,original
"Previous work has shown that high-quality unlexicalized PCFGs can be learned from a treebank, either by manual annotation (Klein and Manning, 2003) or automatic state splitting (Matsuzaki et al. , 2005; Petrov et al. , 2006).",1,original
"Compared to a basic treebank grammar (Charniak, 1996), the grammars of highaccuracy parsers weaken independence assumptions by splitting grammar symbols and rules with either lexical (Charniak, 2000; Collins, 1999) or nonlexical (Klein and Manning, 2003; Matsuzaki et al. , 2005) conditioning information.",1,original
"As discussed above, all state-of-the-art published methods rely on lexical features for such tasks (Zhang et al., 2001; Sha and Pereira, 2003; Finkel et al., 2005; Ratinov and Roth, 2009).",1,original
"Recent work includes improved model variants (e.g. , Jiao et al. , 2006; Okanohara et al. , 2006) and applications such as web data extraction (Pinto et al. , 2003), scientific citation extraction (Peng and McCallum, 2004), and word alignment (Blunsom and Cohn, 2006).",1,original
"One possible approach is to employ state-of-the-art techniques for coreference and zeroanaphora resolution (Iida et al., 2006; Komachi et al., 2007, etc.) in preprocessing cooccurrence samples.",1,original
"Both Liang, et al (2006), and Tillmann and Zhang (2006) report on effective machine translation (MT) models involving large numbers of features with discriminatively trained weights.",1,original
"Online votedperceptrons have been reported to work well in a number of NLP tasks (Collins, 2002; Liang et al., 2006).",1,original
"Perhaps more importantly, discriminative models have been shown to offer competitive performance on a variety of sequential and structured learning tasks in NLP that are traditionally tackled via generative models , such as letter-to-phoneme conversion (Jiampojamarn et al., 2008), semantic role labeling (Toutanova et al., 2005), syntactic parsing (Taskar et al., 2004), language modeling (Roark et al., 2004), and machine translation (Liang et al., 2006).",1,original
"We compare semisupervised LEAF with a previous state of the art semi-supervised system (Fraser and Marcu, 2006b).",1,original
"2 Related Work Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al. , 2005; Taskar et al. , 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006).",1,original
"The state of the art technology for relation extraction primarily relies on pattern-based approaches (Snow et al. , 2006).",1,original
"Currently, the best-performing English NP interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (Rosario and Hearst, 2001), (Rosario et al. , 2002), (Moldovan et al. , 2004), (Pantel and Pennacchiotti, 2006), (Pennacchiotti and Pantel, 2006), (Kim and Baldwin, 2006), (Snow et al. , 2006), (Girju et al. , 2005; Girju et al. , 2006), or use statistical models on large collections of unlabeled data (Berland and Charniak, 1999), (Lapata and Keller, 2004), (Nakov and Hearst, 2005), (Turney, 2006).",1,original
"This increase of probabilities is defined as multiplicative change (N) as follows: (N) = P(E|Tprime)/P(E|T) (2) The main innovation of the model in (Snow et al., 2006) is the possibility of adding at each step the best relation N = {Ri,j}as well as N = I(Ri,j) that is Ri,j with all the relations by the existing taxonomy.",1,original
"Automatically creating or extending taxonomies for specific domains is then a very interesting area of research (OSullivan et al., 1995; Magnini and Speranza, 2001; Snow et al., 2006).",1,original
"Because of this property, vector space models have been used successfully both in computational linguistics (Manning et al., 2008; Snow et al., 2006; Gorman and Curran, 2006; Schutze, 1998) and in cognitive science (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001).",1,original
"Nonparametricmodels (Teh, 2006) may be appropriate.",1,original
"In the SMT research community, the second step has been well studied and many methods have been proposed to speed up the decoding process, such as node-based or span-based beam search with different pruning strategies (Liu et al., 2006; Zhang et al., 2008a, 2008b) and cube pruning (Huang and Chiang, 2007; Mi et al., 2008).",1,original
"To speed our computations, we use the cube pruning method of Huang and Chiang (2007) with a fixed beam size.",1,original
Hiero Search Refinements Huang and Chiang (2007) offer several refinements to cube pruning to improve translation speed.,1,original
"Recent innovations have greatly improved the efficiency of language model integration through multipass techniques, such as forest reranking (Huang and Chiang, 2007), local search (Venugopal et al., 2007), and coarse-to-fine pruning (Petrov et al., 2008; Zhang and Gildea, 2008).",1,original
433 Hiero Search Refinements Huang and Chiang (2007) offer several refinements to cube pruning to improve translation speed.,1,original
"1 Introduction A hypergraph, as demonstrated by Huang and Chiang (2007), is a compact data-structure that can encode an exponential number of hypotheses generated by a regular phrase-based machine translation (MT) system (e.g., Koehn et al.",1,original
We also use Cube Pruning algorithm (Huang and Chiang 2007) to speed up the translation process.,1,original
"Hypergraphs have been successfully used in parsing (Klein and Manning., 2001; Huang and Chiang, 2005; Huang, 2008) and machine translation (Huang and Chiang, 2007; Mi et al., 2008; Mi and Huang, 2008).",1,original
"In the supervised setting, a recent paper by Daume III (2007) shows that, using a very simple feature augmentation method coupled with Support Vector Machines, he is able to effectively use both labeled target and source data to provide the best results in a number of NLP tasks.",1,original
5.1 The AUGMENT technique for Domain Adaptation The AUGMENT technique introduced by Daume III (2007) is a simple yet very effective approach to performing domain adaptation.,1,original
"In the supervised setting, a recent paper by Daume III (2007) shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks.",1,original
"Studies on the supervised task have shown that straightforward baselines (e.g. models based on source only, target only, or the union of the data) achieve a relatively high performance level and are surprisingly difficult to beat (Daume III, 2007).",1,original
"For example, (Daume III, 2007) shows that training a learning algorithm on the weighted union of different data sets (which is basically what we did) performs almost as well as more involved domain adaptation approaches.",1,original
"For instance, (Daume III, 2007) shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks.",1,original
"2 Confusion-network-based MT system combination The current state-of-the-art is confusion-networkbased MT system combination as described by 98  Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b).",1,original
"In recent several years, the system combination methods based on confusion networks developed rapidly (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; Rosti et al., 2008; He et al., 2008), which show state-of-the-art performance in benchmarks.",1,original
"It is very likely that even greater gains can be achieved by more complicated combination schemes (Rosti et al., 2007), although significantly more effort in tuning would be required.",1,original
"In machine translation, confusion-network based combination techniques (e.g., (Rosti et al., 2007; He et al., 2008)) have achieved the state-of-theart performance in MT evaluations.",1,original
"Recent several years have witnessed the rapid development of system combination methods based on confusion networks (e.g., (Rosti et al., 2007; He et al., 2008)), which show state-of-theart performance in MT benchmarks.",1,original
"Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al., 2007a; Huang and Papineni, 2007).",1,original
"In our experience, this approach is advantageous in terms of translation quality, e.g. by 0.7% in BLEU compared to a minimum Bayes risk primary (Rosti et al., 2007).",1,original
"The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007).",1,original
"While SCL has been successfully applied to PoS tagging and Sentiment Analysis (Blitzer et al., 2006; Blitzer et al., 2007), its effectiveness for parsing was rather unexplored.",1,original
"Similarly, Structural Correspondence Learning (Blitzer et al., 2006; Blitzer et al., 2007; Blitzer, 2008) has proven to be successful for the two tasks examined, PoS tagging and Sentiment Classification.",1,original
"With the in-depth study of opinion mining, researchers committed their efforts for more accurate results: the research of sentiment summarization (Philip et al., 2004; Hu et al., KDD 2004), domain transfer problem of the sentiment analysis (Kanayama et al., 2006; Tan et al., 2007; Blitzer et al., 2007; Tan et al., 2008; Andreevskaia et al., 2008; Tan et al., 2009) and finegrained opinion mining (Hatzivassiloglou et al., 2000; Takamura et al., 2007; Bloom et al., 2007; Wang et al., 2008; Titov et al., 2008) are the main branches of the research of opinion mining.",1,original
"3 Experiments We evaluated the effect of random feature mixing on four popular learning methods: Perceptron, MIRA (Crammer et al., 2006), SVM and Maximum entropy; with 4 NLP datasets: 20 Newsgroups1, Reuters (Lewis et al., 2004), Sentiment (Blitzer et al., 2007) and Spam (Bickel, 2006).",1,original
"2 Previous Work So far, Structural Correspondence Learning has been applied successfully to PoS tagging and Sentiment Analysis (Blitzer et al., 2006; Blitzer et al., 2007).",1,original
"3 Language modelling with Bloom filters Recentwork(TalbotandOsborne, 2007)presenteda scheme for associating static frequency information with a set of n-grams in a BF efficiently.1 3.1 Log-frequency Bloom filter The efficiency of the scheme for storing n-gram statistics within a BF presented in Talbot and Osborne (2007) relies on the Zipf-like distribution of n-gramfrequencies: mosteventsoccuranextremely small number of times, while a small number are very frequent.",1,original
"There also have been prior work on maintaining approximate counts for higher-order language models (LMs) ((Talbot and Osborne, 2007a; Talbot and Osborne, 2007b; Talbot and Brants, 2008)) operates under the model that the goal is to store a compressed representation of a disk-resident table of counts and use this compressed representation to answer count queries approximately.",1,original
"Since the use of cluster of machines is not always practical, (Talbot and Osborne, 2007b; Talbot and Osborne, 2007a) showed a randomized data structure called Bloom filter, that can be used to construct space efficient language models 513 for SMT.",1,original
"3 Space-Efficient Approximate Frequency Estimation Prior work on approximate frequency estimation for language models provide a no-false-negative guarantee, ensuring that counts for n-grams in the model are returned exactly, while working to make sure the false-positive rate remains small (Talbot and Osborne, 2007a).",1,original
"Following (Talbot and Osborne, 2007a) we can avoid unnecessary false positives by not querying for the longer n-gram in such cases.",1,original
"Recent work (Talbot and Osborne, 2007b) has demonstrated that randomized encodings can be used to represent n-gram counts for LMs with signficant space-savings, circumventing information-theoretic constraints on lossless data structures by allowing errors with some small probability.",1,original
"RANDLM (Talbot and Osborne, 2007) performs well and scaled to the full data with improvement (resulting in our best overall system).",1,original
"We use a recently proposed dependency parser (Titov and Henderson, 2007b)1 which has demonstrated state-of-theart performance on a selection of languages from the 1The ISBN parser will be soon made downloadable from the authors web-page.",1,original
"When conditioning on words, we treated each word feature individually, as this proved to be useful in (Titov and Henderson, 2007b).",1,original
"3 Parsing Exact inference in ISBN models is not tractable, but effective approximations were proposed in (Titov and Henderson, 2007a).",1,original
"As discussed in (Titov and Henderson, 2007), computing the conditional probabilities which we need for parsing is in general intractable with ISBNs, but they can be approximated efficiently in several ways.",1,original
"They are latent variable models which are not tractable to compute exactly, but two approximations exist which have been shown to be effective for constituent parsing (Titov and Henderson, 2007).",1,original
"For the mean field approximation, propagating the error all the way back through the structure of the graphical model requires a more complicated calculation, but it can still be done efficiently (see (Titov and Henderson, 2007) for details).",1,original
"3 The Syntactic and Semantic Parser Architecture To achieve the complex task of joint syntactic and semantic parsing, we extend a current state-of-theart statistical parser (Titov and Henderson, 2007) to learn semantic role annotation as well as syntactic structure.",1,original
"Our probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good behaviour for both constituency (Titov and Henderson, 2007a) and dependency parsing (Titov and Henderson, 2007b).",1,original
"The state-of-the art taggers are using feature sets discribed in the corresponding articles ((Collins, 2002), (Gimenez and M`arquez, 2004), (Toutanova et al., 2003) and (Shen et al., 2007)), Morce supervised and Morce semi-supervised are using feature set desribed in section 4.",1,original
"For English, after a relatively big jump achieved by (Collins, 2002), we have seen two significant improvements: (Toutanova et al., 2003) and (Shen et al., 2007) pushed the results by a significant amount each time.1 1In our final comparison, we have also included the results of (Gimenez and M`arquez, 2004), because it has surpassed (Collins, 2002) as well and we have used this tagger in the data preparation phase.",1,original
"As a result of this tuning, our (fully supervised) version of the Morce tagger gives the best accuracy among all single taggers for Czech and also very good results for English, being beaten only by the tagger (Shen et al., 2007) (by 0.10 % absolute) and (not significantly) by (Toutanova et al., 2003).",1,original
"For English, we use three state-of-the-art taggers: the taggers of (Toutanova et al., 2003) and (Shen et al., 2007) in Step 1, and the SVM tagger (Gimenez and M`arquez, 2004) in Step 3.",1,original
"5 Comparison with Previous Top Systems and Related Work In POS tagging, the previous best performance was reported by (Shen et al., 2007) as summarized in Table 7.",1,original
"There is usually not a considerable difference between the two methods in terms of the accuracy of the resulting model (Gao et al., 2007), but L1 regularization has a significant advantage in practice.",1,original
"In addition, their system does not classify non-anaphoric pronouns, A third paper that has significantly influenced our work is that of (Haghighi and Klein, 2007).",1,original
"In terms of applying non-parametric Bayesian approaches to NLP, Haghighi and Klein (2007) evaluated the clustering properties of DPMMs by performing anaphora resolution with good results.",1,original
"Recent work has applied Bayesian non-parametric models to anaphora resolution (Haghighi and Klein, 2007), lexical acquisition (Goldwater, 2007) and language modeling (Teh, 2006) with good results.",1,original
"For Japanese, dependency trees are trimmed instead of full parse trees (Takeuchi and Matsumoto, 2001; Oguro et al., 2002; Nomoto, 2008) 1 This parsing approach is reasonable because the compressed output is grammatical if the 1 Hereafter, we refer these compression processes as tree trimming. input is grammatical, but it offers only moderate compression rates.",1,original
Nakov and Hearst (2008) solved relational similarity problems using the Web as a corpus.,1,original
"These models have achieved state-of-the-art performance in transcript-based speech summarization (Zechner, 2001; Penn and Zhu, 2008).",1,original
"There is also substantial work in the use of target-side syntax (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008).",1,original
"1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT).",1,original
"1 Introduction Hierarchical approaches to machine translation have proven increasingly successful in recent years (Chiang, 2005; Marcu et al., 2006; Shen et al., 2008), and often outperform phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) on target-language fluency and adequacy.",1,original
"4.1 Complete ambiguity classes Ambiguity classes capture the relevant property we are interested in: words with the same category possibilities are grouped together.4 And ambiguity classes have been shown to be successfully employed, in a variety of ways, to improve POS tagging (e.g., Cutting et al., 1992; Daelemans et al., 1996; Dickinson, 2007; Goldberg et al., 2008; Tseng et al., 2005).",1,original
"Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).",1,original
"Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).",1,original
"It is an online training algorithm and has been successfully used in many NLP tasks, such as POS tagging (Collins, 2002), parsing (Collins and Roark, 2004), Chinese word segmentation (Zhang and Clark, 2007; Jiang et al., 2008), and so on.",1,original
"We do not completely rule out the possibility that some more sophisticated, ontologically promiscuous, first-order analysis (perhaps along the lines of (Hobbs, 1985)) might account for these kinds of monotonicity inferences.",1,original
"More sophisticated first-order accounts (Hirst, 1991; Hobbs, 1985) may be extendable to bear this load.",1,original
"Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites (e.g. , ltobbs et al. , 1988; Charniak and Goldman, 1988; Norvig, 1987), all based on tim notion of abduction, and we have begun to explore its potential application to machine translation.",1,original
"The abduction-based approach (Hobbs et al. , 1988) has provided a simple and elegant way to realize such a task.",1,original
"Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category (although this has not been found to be effective for 1R), lemma of the word (e.g. ""corpus"" for ""corpora""), phrasal information (e.g. identifying noun groups and phrases (Lewis 1992c, Church 1988)), and subject-predicate identification (e.g. Hindle 1990).",1,original
"Probably the most widely used association weight function is (point-wise) Mutual Information (MI) (Church et al. , 1990), (Hindle, 1990), (Lin, 1998), (Dagan, 2000), defined by: )()( ),(log),( 2 fPwP fwPfwMI = A known weakness of MI is its tendency to assign high weights for rare features.",1,original
"Semantic collocations are harder to extract than cooccurrence patterns--the state of the art does not enable us to find semantic collocations automatically t. This paper however argues that if we take advantage of lexicai paradigmatic behavior underlying the lexicon, we can at least achieve semi-automatic extraction of semantic collocations (see also Calzolari and Bindi (1990) I But note the important work by Hindle \[HindlegO\] on extracting semantically similar nouns based on their substitutability in certain verb contexts.",1,original
"A wide range of contextual information, such as surrounding words (Lowe and McDonald, 2000; Curran and Moens, 2002a), dependency or case structure (Hindle, 1990; Ruge, 1997; Lin, 1998), and dependency path (Lin and Pantel, 2001; Pado and Lapata, 2007), has been utilized for similarity calculation, and achieved considerable success.",1,original
His results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words (such as in Hindle 1990).,1,original
"For example, Hindle (1990) used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information.",1,original
"8Interestingly, in work on the automated classification of nouns, (Hindle, 1990) also noted problems with ""empty"" words that depend on their complements for meaning.",1,original
"Arguably the most widely used is the mutual information (Hindle, 1990; Church and Hanks, 1990; Dagan et al. , 1995; Luk, 1995; D. Lin, 1998a).",1,original
"Similarity-based smoothing (Hindle 1990; Brown et al. 1992; Dagan, Marcus, and Markovitch 1993; Pereira, Tishby, and Lee 1993; Dagan, Lee, and Pereira 1999) provides an intuitively appealing approach to language modeling.",1,original
"A promising approach may be to use aligned bilingual corpora, especially for augmenting existing lexicons with domain-specific terminology (Brown et al. 1993; Dagan, Church, and Gale 1993).",1,original
"Successful approaches aimed at trying to overcome the sparse data limitation include backoff (Katz 1987), Turing-Good variants (Good 1953; Church and Gale 1991), interpolation (Jelinek 1985), deleted estimation (Jelinek 1985; Church and Gale 1991), similarity-based models (Dagan, Pereira, and Lee 1994; Essen and Steinbiss 1992), Pos-language models (Derouault and Merialdo 1986) and decision tree models (Bahl et al. 1989; Black, Garside, and Leech 1993; Magerman 1994).",1,original
"Recent work emphasizes corpus-based unsupervised approach (Dagon and Itai, 1994; Yarowsky, 1992; Yarowsky, 1995) that avoids the need for costly truthed training data.",1,original
"Although we see statistically significant improvements (at the .05 level on a paired permutation test), the quality of the parsers is still quite poor, in contrast to other applications of bootstrapping which rival supervised methods (Yarowsky, 1995).",1,original
"Constraining learning by using document boundaries has been used quite effectively in unsupervised word sense disambiguation (Yarowsky, 1995).",1,original
"However, as also pointed out by Yarowsky (1995), this observation does not hold uniformly over all possible co-occurrences of two words.",1,original
"Although the relative success of previous disambiguation systems (e.g. Yarowsky, 1995) suggests that this should be the case, the effect has usually not been quantified as the emphasis was on a task-based evaluation.",1,original
"1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al. , 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al. , 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998).",1,original
2.1 The Yarowsky algorithm Yarowsky (1995) sparked considerable interest in bootstrapping with his successful method for word sense disambiguation.,1,original
"A variety of classifiers have been employed for this task (see Mooney [1996] and Ide and Veronis [1998] for overviews), the most popular being decision lists (Yarowsky 1994, 1995) and naive Bayesian classifiers (Pedersen 2000; Ng 1997; Pedersen and Bruce 1998; Mooney 1996; Cucerzan and Yarowsky 2002).",1,original
The Yarowsky (1995) algorithm was one of the first bootstrapping algorithms to become widely known in computational linguistics.,1,original
Yarowsky has proposed an algorithm that requires as little user input as one seed word per sense to start the training process (Yarowsky 1995).,1,original
"The best example of such an approach is (Yarowsky, 1995), who proposes a method that automatically identifies collocations that are indicative of the sense of a word, and uses those to iteratively label more examples.",1,original
"To alleviate this effort, various semi-supervised learning algorithms such as self-training (Yarowsky, 1995), cotraining (Blum and Mitchell, 1998; Goldman and Zhou, 2000), transductive SVM (Joachims, 1999) and many others have been proposed and successfully applied under different assumptions and settings.",1,original
"This method, initially proposed by (Yarowsky, 1995), was successfully evaluated in the context of the SENSEVAL framework (Mihalcea, 2002).",1,original
"Among the various knowledge-based (Lesk, 1986; Galley and McKeown, 2003; Navigli and Velardi, 2005) and data-driven (Yarowsky, 1995; Ng and Lee, 1996; Pedersen, 2001) word sense disambiguation methods that have been proposed to date, supervised systems have been constantly observed as leading to the highest performance.",1,original
"Disambiguation of a limited number of words is not hard, and necessary context information can be carefully collected and hand-crafted to achieve high disambiguation accuracy as shown in (Yarowsky, 1995).",1,original
"In order to overcome this, some unsupervised learning methods and minimally-supervised methods, e.g., (Yarowsky, 1995; Yarowsky and Wicentowski, 2000), have been proposed.",1,original
"Some tasks can thrive on a nearly pure diet of unlabeled data (Yarowsky, 1995; Collins and Singer, 1999; Cucerzan and Yarowsky, 2003).",1,original
"3.2 Comparison between SVM, Bootstrapping and LP For WSD, SVM is one of the state of the art supervised learning algorithms (Mihalcea et al. , 2004), while bootstrapping is one of the state of the art semi-supervised learning algorithms (Li and Li, 2004; Yarowsky, 1995).",1,original
"5.1 Comparison to self-training For completeness, we also compared our results to the self-learning algorithm, which has commonly been referred to as bootstrapping in natural language processing and originally popularized by the work of Yarowsky in word sense disambiguation (Abney 2004; Yarowsky 1995).",1,original
"Annealing  resembles the popular bootstrapping technique (Yarowsky, 1995), which starts out aiming for high precision, and gradually improves coverage over time.",1,original
"(Yarowsky, 1995) demonstrated that semi-supervised WSD could be successful.",1,original
"In order to overcome this problem, we look to the bootstrapping method outlined in (Yarowsky, 1995).",1,original
One of the most notable examples is Yarowskys (1995) bootstrapping algorithm for word sense disambiguation.,1,original
"Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation (Schiitze, 1992; Gale et al. , 1992; Yarowsky, 1995).",1,original
"Decision lists have already been successfully applied to lexical ambiguity resolution by (Yarowsky, 1995) where they perfromed well.",1,original
"Some of the best results were reported in (Yarowsky, 1995) who uses a large training corpus.",1,original
"They have been successfully applied to accent restoration, word"" sense disambiguation 209 and homograph disambiguation (Yarowsky, 1994; 1995; 1996).",1,original
"To overcome this problem, unsupervised learning methods using huge unlabeled data to boost the performance of rules learned by small labeled data have been proposed recently(Blum and Mitchell, 1998)(Yarowsky, 1995)(Park et al. , 2000)(Li and Li, 2002).",1,original
"To solve this problem, we adopt an idea one sense per collocation which was introduced in word sense disambiguation research (Yarowsky, 1995).",1,original
"The approach is very general and modular and can work in conjunction with a number of learning strategies for word sense disambiguation (Yarowsky, 1995; Li and Li, 2002).",1,original
"4.1 Methods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on (Yarowsky, 1995a).",1,original
"We also note that there are a number of bootstrapping methods successfully applied to text  e.g., word sense disambiguation (Yarowsky, 1995), named entity instance classification (Collins and Singer, 1999), and the extraction of parts word given the whole word (Berland and Charniak, 1999).",1,original
"7 Related Work Unannotated texts have been used successfully for a variety of NLP tasks, including named entity recognition (Collins and Singer, 1999), subjectivity classification (Wiebe and Riloff, 2005), text classification (Nigam et al. , 2000), and word sense disambiguation (Yarowsky, 1995).",1,original
The notion that nouns have only one sense per discourse/collocation was also exploited by Yarowsky (1995) in his seminal work on bootstrapping for word sense disambiguation.,1,original
Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model.,1,original
"(1992b) has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation (WSD) and related tasks (e.g., Yarowsky (1995); Agirre and Rigau The author was partially funded by GALE DARPA Contract No.",1,original
"Unsupervised algorit~m~ such as (Yarowsky, 1995) have reported good accuracy that rivals that of supervised algorithms.",1,original
"The best examples of this approach has been the resent work of Yarowsky (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995).",1,original
"While (Yarowsky, 1995) does not discuss distinguishing more than 2 senses of a word, there is no immediate reason to doubt that the ""one sense per collocation"" rule (Yarowsky, 1993) would still hold for a larger number of senses.",1,original
"(Yarowsky, 1995) compares his method to (Schiitze, 1992) and shows that for four words the former performs significantly better in distinguishing between two senses.",1,original
"(Yarowsky, 1995), whose training corpus for the noun drug was 9 times bigger than that of Karov and Edelman, reports 91.4% correct performance improved to impressive 93.9% when using the ""one sense per discourse"" constraint.",1,original
"Among them, the unsupervised algorithm using decisiontrees (Yarowsky, 1995) has achieved promising performance.",1,original
"Also, in a, sta.te-ofthe-a.rt English pa.rser (Collins, 1997) only the words tha, t occur more tha,n d times in training data.",1,original
"Substantial improvements have been made to parse western language such as English, and many powerful models have been proposed (Brill 1993, Collins 1997).",1,original
"Several general-purpose off-the-shelf (OTS) parsers have become widely available (Lin, 1994; Collins, 1997).",1,original
"On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical models for disambiguation that make crucial use of dependency relations.",1,original
"Moreover, the deterministic dependency parser of Yamada and Matsumoto (2003), when trained on the Penn Treebank, gives a dependency accuracy that is almost as good as that of Collins (1997) and Charniak (2000).",1,original
"All state-of-the-art wide-coverage parsers relax this assumption in some way, for instance by (i) changing the parser in step (3), such that the application of rules is conditioned on other steps in the derivation process (Collins, 1997; Charniak, 1997), or by (ii) enriching the nonterminal labels in step (1) with context-information (Johnson, 1998; Klein and Manning, 2003), along with suitable backtransforms in step (4).",1,original
"Lexicalized PCFGs use the structural features on the lexical head of phrasal node in a tree, and get significant improvements for parsing (Collins, 1997; Charniak, 1997; Collins, 1999; Charniak, 2000).",1,original
"To compare the output of their shallow parser with the output of the well-known Collins (1997) parser, Li and Roth applied the chunklink conversion script to extract the shallow constituents from the output of the Collins parser on WSJ section 00.",1,original
"The parsers with the highest published broad-coverage parsing accuracy, which include Charniak (1997, 2000), Collins (1997, 1999), and Ratnaparkhi (1997), all utilize simple and straightforward statistically based search heuristics, pruning the search-space quite dramatically.",1,original
"Introduction Michael Collins (1996, 1997, 1999) parsing models have been quite influential in the field of natural language processing.",1,original
"First, several of the best-performing parsers on the WSJ treebank (e.g. , Ratnaparkhi 1997; Charniak 1997, 2000; Collins 1997, 1999; Henderson 2003) are cases of history-based models.",1,original
"3.2 Statistical Learning Model 3.2.1 Nave Bayes Learning Nave Bayes learning has been widely used in natural language processing with good results such as statistical syntactic parsing (Collins, 1997; Charniak, 1997), hidden language understanding (Miller et al. , 1994).",1,original
"Such word-based lexicalizations of probability models are used successfully in the statistical parsing models of, e.g., Collins (1997), Charniak (1997), or Ratnaparkhi (1997).",1,original
"Head-lexicalized stochastic grammars have recently become increasingly popular (see Collins 1997, 1999; Charniak 1997, 2000).",1,original
"Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al. , 1999) and Chinese (Bikel and Chiang, 2000).",1,original
(1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese.,1,original
"However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets.",1,original
"3 Probabilistic Parsing Models 3.1 Probabilistic Context-Free Grammars Lexicalization has been shown to improve parsing performance for the Penn Treebank (e.g. , Carroll and Rooth 1998; Charniak 1997, 2000; Collins 1997).",1,original
"1 Introduction Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g. , Collins 1997; Charniak 2000).",1,original
"As a side product, we find empirical evidence to suggest that the effectiveness of rule lexicalization techniques (Collins, 1997; Simaan, 2000) and parent annotation techniques (Klein and Manning, 2003) is due to the fact that both lead to a reduction in perplexity in the automata induced from training corpora.",1,original
"They are central to many parsing models (Charniak, 1997; Collins, 1997, 2000; Eisner, 1996), and despite their simplicity n-gram models have been very successful.",1,original
"We employ a robust statistical parser (Collins, 1997) to determine the constituent structure for each sentence, from which subjects (s), objects (o), and relations other than subject or object (x) are identified.",1,original
"Previous work for English (e.g. , Magerman, 1995; Collins, 1997) has shown that lexicalization leads to a sizable improvement in parsing performance.",1,original
"Some of the more popular and more accurate of these approaches to data-driven parsing (Charniak, 2000; Collins, 1997; Klein and Manning, 2002) have been based on generative models that are closely related to probabilistic contextfree grammars.",1,original
"Parsing models have been developed for different languages and state-of-the-art results have been reported for, e.g., English (Collins, 1997; Charniak, 2000).",1,original
"Several recent real-world parsers have improved state-of-the-art parsing accuracy by relying on probabilistic or weighted versions of bilexical grammars (Alshawi, 1996; Eisner, 1996; Charniak, 1997; Collins, 1997).",1,original
"The success of recent high-quality parsers (Charniak, 1997; Collins, 1997) relies on the availability of such treebank corpora.",1,original
"We choose those sections because several state-of-thwart parsers (Collins, 1997; Ratnaparkhi, 1998; Charniak, 1997) are trained on Section 2-21 and tested on Section 23.",1,original
"However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time (Charniak, 1997b; Charniak, 1997a; Collins, 1997; Ratnaparkhi, 1997).",1,original
"For the full parser, we use the one developed by Michael Collins (Collins, 1996; Collins, 1997)  one of the most accurate full parsers around.",1,original
"2.1 Lexicalized parse trees The first successful work on syntactic disambiguation was based on lexicalized probabilistic context-free grammar (LPCFG) (Collins, 1997; Charniak, 1997).",1,original
"The creation of the Penn English Treebank (Marcus et al. , 1993), a syntactically interpreted corpus, played a crucial role in the advances in natural language parsing technology (Collins, 1997; Collins, 2000; Charniak, 2000) for English.",1,original
"Function P R F Speed Partial Parsing 85.1 82.5 83.8 4500 wps Full Parsing 77.1 70.3 73.7 2100 wps Table 3: Performances of 1 st -level Partial Parsing and Full Parsing (wps: words per second) Table 3 shows that the performances of partial parsing and full parsing are quite low, compared to those of state-of-art partial parsing and full parsing for the English language (Zhou et al 2000a; Collins 1997).",1,original
"Of particular interest are lexicalized parsing models such as the ones developed by Collins (1996, 1997) and Carroll and Rooth (1998).",1,original
"2 Head Lexicalization As previously shown (Charniak (1997), Collins (1997), Carroll and Rooth (1998), etc.), ContextFree Grammars (CFGs) can be transformed to lexicalized CFGs, provided that a head-marking scheme for rules is given.",1,original
"Although state-of-the-art statistical parsers (Collins, 1997; Charniak, 2000) are more accurate, the simplicity and efficiency of deterministic parsers make them attractive in a number of situations requiring fast, light-weight parsing, or parsing of large amounts of data.",1,original
"1 Introduction There has been a great deal of progress in statistical parsing in the past decade (Collins, 1996; Collins, 1997; Chaniak, 2000).",1,original
"1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data (Collins, 1997; Charniak, 2000; Wang et al. , 2005; McDonald et al. , 2005).",1,original
"It is interesting to note that, while the study of how the granularity of context-free grammars (CFG) affects the performance of a parser (e.g. in the form 86 n1:IP [=] n2:NP [SUBJ=] n4:NR [=] GSC4ES JiangZemin n3:VP [=] n5:VV [=] ESDO interview n6:NP [OBJ=] n7:NR [ADJUNCT] AIC1 Thai n8:NN [=] D3D2 president f1             PRED ESDO SUBJ f2  PRED GSC4ESNTYPE proper NUM sg   OBJ f3       PRED D3D2 NTYPE common NUM sg ADJUNCT   f4  PRED AIC1NTYPE proper NUM sg                         : N  F (n1)=(n3)=(n5)=f1 (n2)=(n4)=f2 (n6)=(n8)=f3 (n7)=f4 Figure 1: Cand f-structures with  links for the sentence GSC4ESESDOAIC1D3D2 of grammar transforms (Johnson, 1998) and lexicalisation (Collins, 1997)) has attracted substantial attention, to our knowledge, there has been a lot less research on this subject for surface realisation, a process that is generally regarded as the reverse process of parsing.",1,original
"Methodologies such as lexicalisation (Collins, 1997; Charniak, 2000) and tree transformations (Johnson, 1998), weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs.",1,original
"3.1 A History-Based Model The history-based (HB) approach which incorporates more context information has worked well in parsing (Collins, 1997; Charniak, 2000).",1,original
"NJ 08903 U.S.A. suzanne~ruccs, rutgers, edu Empirically-induced models that learn a linguistically meaningflll grammar (Collins, 1997) seem to give tile best practical results in statistical natural language processing.",1,original
"In agreement with recent results on parsing with lexicalised probabilistic grammars (Collins, 1997; Srinivas, 1997; Charniak, 1997), our main result is that statistics over lexical features best correspond to independently established truman intuitive preferences and experimental findings.",1,original
"In agreement with recent resuits on parsing with lexicalised probabilistic grammars (Collins, 1997; Srinivas, 1997), we find that statistics over lexical, as opposed to structural, features best correspond to human intuitive.judgments and to experimental findings.",1,original
"The corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by Collins (1997), Charniak (1997) and Ratnaparkhi (1997).",1,original
"18 More recently, Bean and Riloff (1999) have proposed methods for automatically extracting from a corpus heads that correlate well with discourse novelty.",1,original
3Bean and Riloff (1999) and Uryupina (2003) construct quite accurate classifiers to detect unique NPs.,1,original
"In 2004, Conroy (Conroy, 2004) tested Maximal Marginal Relevance (Goldstein et al. , 2000) as well as QR decomposition.",1,original
"To avoid this problem, we adopt cross-validation training as used in Collins (2002b).",1,original
"With non-local features, we cannot use efcient procedures such as forward-backward procedures and the Viterbi algorithm that are required in training CRFs (Lafferty et al. , 2001) and perceptrons (Collins, 2002a).",1,original
"Discriminative methods such as Conditional Random Fields (CRFs) (Lafferty et al. , 2001), Semi-Markov Random Fields (Sarawagi and Cohen, 2004), and perceptrons (Collins, 2002a) have been popular approaches for sequence labeling because of their excellent performance, which is mainly due to their ability to incorporate many kinds of overlapping and non-independent features.",1,original
"In our preliminary experiments, we used a Support Vector Machine (SVM) ranker (Joachims, 2002) to learn the structured classi er.2 We also in1See e.g. Collins (2002) for a popular training algorithm.",1,original
"The Perceptron style for natural language processing problems as initially proposed by (Collins, 2002) can provide state of the art results on various domains including text chunking, syntactic parsing, etc. The main drawback of the Perceptron style algorithm is that it does not have a mechanism for attaining the maximize margin of the training data.",1,original
"The technique of averaging was introduced in the context of perceptrons as an approximation to taking a vote among all the models traversed during training, and has been shown to work well in practice (Freund and Schapire, 1999; Collins, 2002).",1,original
"Averaging parameters is a way to reduce overfitting for perceptron training (Collins, 2002), and is applied to all our experiments.",1,original
"3 Perceptron Reranking As Collins (2002) observes, perceptron training involves a simple, on-line algorithm, with few iterations typically required to achieve good performance.",1,original
"We use the popular online learning algorithm of structured perceptron with parameter averaging (Collins, 2002).",1,original
The averaged 1555 perceptron has a solid theoretical fundamental and was proved to be effective across a variety of NLP tasks (Collins 2002).,1,original
"Collins (2002) improves the F1 score from 88.2% to 89.7%, while Charniak and Johnson (2005) improve from 90.3% to 91.4%.",1,original
"An online learning algorithm considers a single training instance for each update to the weight vector w. We use the common method of setting the final weight vector as the average of the weight vectors after each iteration (Collins, 2002), which has been shown to alleviate overfitting.",1,original
"Averaging has been shown to reduce overfitting (Collins, 2002) as well as reliance on the order of the examples during training.",1,original
"Online votedperceptrons have been reported to work well in a number of NLP tasks (Collins, 2002; Liang et al., 2006).",1,original
"The state-of-the art taggers are using feature sets discribed in the corresponding articles ((Collins, 2002), (Gimenez and M`arquez, 2004), (Toutanova et al., 2003) and (Shen et al., 2007)), Morce supervised and Morce semi-supervised are using feature set desribed in section 4.",1,original
"For English, after a relatively big jump achieved by (Collins, 2002), we have seen two significant improvements: (Toutanova et al., 2003) and (Shen et al., 2007) pushed the results by a significant amount each time.1 1In our final comparison, we have also included the results of (Gimenez and M`arquez, 2004), because it has surpassed (Collins, 2002) as well and we have used this tagger in the data preparation phase.",1,original
"5 Related Work Discriminative models have recently been proved to be more effective than generative models in some NLP tasks, e.g., parsing (Collins 2000), POS tagging (Collins 2002) and LM for speech recognition (Roark et al. 2004).",1,original
"We used the average perceptron algorithm of Collins (2002) in our experiments, a variation that has been proven to be more effective than the standard algorithm shown in Figure 2.",1,original
"This averaging effect has been shown to help overfitting (Collins, 2002).",1,original
"A=adjoin, T=attach, C=conjoin, G=generate In this paper, we use the perceptron-like algorithm proposed in (Collins, 2002) which does not suffer from the label bias problem, and is fast in training.",1,original
"A pioneer work in online training is the perceptron-like algorithm used in training a hidden Markov model (HMM) (Collins, 2002).",1,original
"To reduce the time complexity, we adapted the lazy update proposed in (Collins, 2002b), which was also used in (Zhang and Clark, 2007).",1,original
"Results from Collins, Schapire and Singer (2002) show that under these definitions the following guarantee holds: LogLossUpda,k, BestWtk, a C20 BestLossk, a So it can be seen that the update from a to Upda, k, BestWtk, a is guaranteed to decrease LogLoss by at least  W  k q C0  W C0 k qC16C17 2 . From these results, the algorithms in Figures 3 and 4 could be altered to take the revised definitions of W  k and W C0 k into account.",1,original
"For a full derivation of the modified updates and for quite technical convergence proofs, see Collins, Schapire and Singer (2002).",1,original
"Indeed, as for the voted perceptron of Collins (2002), we can get performance gains by reducing the support threshold for features to be included in the model.",1,original
"The averaged perceptron (Collins, 2002) is a variant which averages the w across all iterations; it has demonstrated good generalization especially with data that is not linearly separable, as in many natural language processing problems.",1,original
"Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al. , 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Munoz et al. , 1999).",1,original
Freund and Schapire (1999) originally proposed the averaged parameter method; it was shown to give substantial improvements in accuracy for tagging tasks in Collins (2002).,1,original
"Discriminative learning methods, such as Maximum Entropy Markov Models (McCallum et al. , 2000), Projection Based Markov Models (Punyakanok and Roth, 2000), Conditional Random Fields (Lafferty et al. , 2001), Sequence AdaBoost (Altun et al. , 2003a), Sequence Perceptron (Collins, 2002), Hidden Markov Support Vector Machines (Altun et al. , 2003b) and Maximum-Margin Markov Networks (Taskar et al. , 2004), overcome the limitations of HMMs.",1,original
"Averaging has been shown to help reduce overfitting (Collins, 2002).",1,original
"1 Introduction State-of-the-art part of speech (POS) tagging accuracy is now above 97% for newspaper text (Collins, 2002; Toutanova et al. , 2003).",1,original
"2.2 Perceptron-based training To tune the parameters w of the model, we use the averaged perceptron algorithm (Collins, 2002) because of its efficiency and past success on various NLP tasks (Collins and Roark, 2004; Roark et al. , 2004).",1,original
"Averaged perceptron (Collins, 2002a), which has been successfully applied to several tagging and parsing reranking tasks (Collins, 2002c; Collins, 2002a), was employed for training rerank267 CLANG GEOQUERY P R F P R F SCISSOR 89.5 73.7 80.8 98.5 74.4 84.8 SCISSOR+ 87.0 78.0 82.3 95.5 77.2 85.4 Table 2: The performance of the baseline model SCISSOR+ compared with SCISSOR (with the best result in bold), where P = precision, R = recall, and F = F-measure.",1,original
"2.3 The Averaged Perceptron Reranking Model Averaged perceptron (Collins, 2002a) has been successfully applied to several tagging and parsing reranking tasks (Collins, 2002c; Collins, 2002a), and in this paper, we employed it in reranking semantic parses generated by the base semantic parser SCISSOR.",1,original
"Weight averaging was also employed (Collins, 2002), which helped improve performance.",1,original
"In our experiments, we have used Averaged Perceptron (Collins, 2002; Freund and Schapire, 1999) and Perceptron with margin (Krauth and Mezard, 1987) to improve performance.",1,original
"In our experiments, we used the Averaged Perceptron algorithm of Freund and Schapire (1999), a variation that has been shown to be more effective than the standard algorithm (Collins 2002).",1,original
"In addition, the perceptron algorithm and its variants, e.g., the voted or averaged perceptron, is becoming increasingly popular due to their competitive performance, simplicity in implementation and low computational cost in training (e.g. , Collins 2002).",1,original
"2.1 The averaged perceptron The averaged perceptron algorithm (Collins, 2002) was proposed as a way of reducing overfitting on the training data.",1,original
"4 Evaluation The purpose of our evaluation is to contrast our proposed feature based approach with a state-ofthe-art sequential learning technique (Collins, 2002).",1,original
"In this work we use the averaged perceptron algorithm (Collins, 2002) since it is an online algorithm much simpler and orders of magnitude faster than Boosting and MaxEnt methods.",1,original
"This averaging effect has been shown to reduce overfitting and produce much more stable results (Collins, 2002).",1,original
"To facilitate comparisons with previous work (McDonald et al., 2005b; McDonald and Pereira, 2006), we used the training/development/test partition defined in the corpus and we also used the automatically-assigned part of speech tags provided in the corpus.10 Czech word clusters were derived from the raw text section of the PDT 1.0, which contains about 39 million words of newswire text.11 We trained the parsers using the averaged perceptron (Freund and Schapire, 1999; Collins, 2002), which represents a balance between strong performance and fast training times.",1,original
"Another widely used discriminative method is the perceptron algorithm (Collins, 2002), which achieves comparable performance to CRFs with much faster training, so we base this work on the perceptron.",1,original
"3 The Perceptron The perceptron algorithm introduced into NLP by Collins (2002), is a simple but effective discriminative training method.",1,original
"899 To alleviate overfitting on the training examples, we use the refinement strategy called averaged parameters (Collins, 2002) to the algorithm in Algorithm 1.",1,original
"Several classification models can be adopted here, however, we choose the averaged perceptron algorithm (Collins, 2002) because of its simplicity and high accuracy.",1,original
"In addition, the averaged parameters technology (Collins, 2002) is used to alleviate overfitting and achieve stable performance.",1,original
"On the Hansards data, the simple averaging technique described by Collins (2002) yields a reasonable model.",1,original
"The averaged version of the perceptron (Collins, 2002), like the voted perceptron (Freund and Schapire, 1999), reduces the effect of over-training.",1,original
"This combination of the perceptron algorithm with beam-search is similar to that described by Collins and Roark (2004).5 The perceptron algorithm is a convenient choice because it converges quickly  usually taking only a few iterations over the training set (Collins, 2002; Collins and Roark, 2004).",1,original
"The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years (McCallum et al. , 2000; Lafferty et al. , 2001; Collins, 2002; Altun et al. , 2003).",1,original
"Collins (2002) introduced the averaged perceptron, as a way of reducing overfitting, and it has been shown to perform better than the non-averaged version on a number of tasks.",1,original
"We chose the perceptron for the training algorithm because it has shown good performance on other NLP tasks; in particular, Collins (2002) reported good performance for a perceptron tagger compared to a Maximum Entropy tagger.",1,original
"When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfitting on the training set (Collins, 2002).",1,original
"(1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g. , Dang and Palmer (2002), Klein and Manning (2002)) in particular have shown a large degree of success for WSD, and have established challenging state-of-the-art benchmarks.",1,original
"We use five sentiment classification datasets, including the widely-used movie review dataset [MOV] (Pang et al., 2002) as well as four datasets containing reviews of four different types of products from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al., 2007).",1,original
"2 Related Work Supervised machine learning methods including Support Vector Machines (SVM) are often used in sentiment analysis and shown to be very promising (Pang et al., 2002; Matsumoto et al., 2005; Kudo and Matsumoto, 2004; Mullen and Collier, 2004; Gamon, 2004).",1,original
"SVM has been shown to be useful for text classification tasks (Joachims, 1998), and has previously given good performance in sentiment classification experiments (Kennedy and Inkpen, 2006; Mullen and Collier, 2004; Pang and Lee, 2004; Pang et al., 2002).",1,original
"Unigram models have been previously shown to give good results in sentiment classification tasks (Kennedy and Inkpen, 2006; Pang et al., 2002): unigram representations can capture a variety of lexical combinations and distributions, including those of emotion words.",1,original
"We chose a dataset that would be enjoyable to reannotate: the movie review dataset of (Pang et al. , 2002; Pang and Lee, 2004).3 The dataset consists of 1000 positive and 1000 negative movie reviews obtained from the Internet Movie Database (IMDb) review archive, all written before 2002 by a total of 312 authors, with a cap of 20 reviews per author per 2Taking Ccontrast to be constant means that all rationales are equally valuable.",1,original
"Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular.",1,original
"Movies Reviews: This is a popular dataset in sentiment analysis literature (Pang et al., 2002).",1,original
"In particular, the use of SVMs in (Pang et al., 2002) initially sparked interest in using machine learning methods for sentiment classi cation.",1,original
"In their seminal work, (Pang et al., 2002) demonstrated that supervised learning signi cantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms.",1,original
"Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classi cation schemes (Pang et al., 2002).",1,original
"4 Evaluation 4.1 Experimental Setup For evaluation, we use five sentiment classification datasets, including the widely-used movie review dataset [MOV] (Pang et al., 2002) as well as four datasets that contain reviews of four different types of product from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al., 2007).",1,original
"To evaluate the quality of our generated summaries, we choose to use the ROUGE3 (Lin, 2004) evaluation toolkit, that has been found to be highly correlated with human judgments.",1,original
"We carried out automatic evaluation of our summaries using ROUGE (Lin, 2004) toolkit, which has been widely adopted by DUC for automatic summarization evaluation.",1,original
"Here, we use the more established ROUGE-W measure (Lin, 2004) instead.",1,original
"ROUGE version 1.5.5 (Lin, 2004) was used for evaluation.2 Among others, we focus on ROUGE-1 in the discussion of the result, because ROUGE-1 has proved to have strong correlation with human annotation (Lin, 2004; Lin and Hovy, 2003).",1,original
"ROUGE-L, ROUGE-W, and ROUGE-S have also been applied in automatic evaluation of summarization and achieved very promising results (Lin 2004).",1,original
"The dif1The routinely used tool for automatic evaluation ROUGE was adopted exactly because it was demonstrated it is highly correlated with the manual DUC coverage scores (Lin and Hovy, 2003a; Lin, 2004).",1,original
"We carried out automatic evaluation of our summaries using ROUGE (Lin, 2004) toolkit, which has been widely adopted by DUC for automatic summarization evaluation.",1,original
"We report on ROUGE-1 (unigrams), ROUGE-2 (bigrams), ROUGE W-1.2 (weighted LCS), and ROUGE-S* (skip bigrams) as they have been shown to correlate well with human judgments for longer multidocument summaries (Lin, 2004).",1,original
"ROUGE (Lin, 2004) has been widely used for summarization evaluation.",1,original
"In the news article domain, ROUGE scores have been shown to be generally highly correlated with human evaluation in content match (Lin, 2004).",1,original
"The ROUGE (Lin, 2004) suite of metrics are n-gram overlap based metrics that have been shown to highly correlate with human evaluations on content responsiveness.",1,original
"We can credit DUC with the emergence of automatic methods for evaluation such as ROUGE (Lin and Hovy, 2003; Lin, 2004) which allow quick measurement of systems during development and enable evaluation of larger amounts of data.",1,original
"Two metrics have become quite popular in multi-document summarization, namely the Pyramid method (Nenkova and Passonneau, 2004b) and ROUGE (Lin, 2004).",1,original
"The use of dependencies in MT evaluation has not been extensively researched before (one exception here would be Liu and Gildea (2005)), and requires more research to improve it, but the method shows potential to become an accurate evaluation metric.",1,original
"Other well-known metrics are WER (Nieen et al., 2000), NIST (Doddington, 2002), GTM (Melamed et al., 2003), ROUGE (Lin and Och, 2004a), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006), just to name a few.",1,original
"It has been argued that METEOR correlates better with human judgment due to higher weight on recall than precision (Banerjee and Lavie, 2005).",1,original
"The results show that, as compared to BLEU, several recently proposed metrics such as Semantic-role overlap (Gimenez and Marquez, 2007), ParaEval-recall (Zhou et al., 2006), and METEOR (Banerjee and Lavie, 2005) achieve higher correlation.",1,original
"In an experiment on 16,800 sentences of Chinese-English newswire text with segment-level human evaluation from the Linguistic Data Consortium?s (LDC) Multiple Translation project, we compare the LFG-based evaluation method with other popular metrics like BLEU, NIST, General Text Matcher (GTM) (Turian et al. , 2003), Translation Error Rate (TER) (Snover et al. , 2006)1, and METEOR (Banerjee and Lavie, 2005), and we show that combining dependency representations with synonyms leads to a more accurate evaluation that correlates better with human judgment.",1,original
"While these are based on a relatively few number of items, and while we have not performed any tests to determine whether the differences in ? are statistically significant, the results 7The Czech-English conditions were excluded since there were so few systems 146 are nevertheless interesting, since three metrics have higher correlation than Bleu: ??Semantic role overlap (Gimenez and M`arquez, 2007), which makes its debut in the proceedings of this workshop ??ParaEval measuring recall (Zhou et al. , 2006), which has a model of allowable variation in translation that uses automatically generated paraphrases (Callison-Burch, 2007) ??Meteor (Banerjee and Lavie, 2005) which also allows variation by introducing synonyms and by flexibly matches words using stemming.",1,original
"1 Introduction Chinese Word Segmentation (CWS) has been witnessed a prominent progress in the last three Bakeoffs (Sproat and Emerson, 2003), (Emerson, 2005), (Levow, 2006).",1,original
A notable exception is the work of Kim and Hovy (2006).,1,original
"Similarly, Structural Correspondence Learning (Blitzer et al., 2006; Blitzer et al., 2007; Blitzer, 2008) has proven to be successful for the two tasks examined, PoS tagging and Sentiment Classification.",1,original
"So far, SCL has been applied successfully in NLP for Part-of-Speech tagging and Sentiment Analysis (Blitzer et al., 2006; Blitzer et al., 2007).",1,original
"We examine the effectiveness of Structural Correspondence Learning (SCL) (Blitzer et al., 2006) for this task, a recently proposed adaptation technique shown to be effective for PoS tagging and Sentiment Analysis.",1,original
"Among these techniques, SCL (Structural Correspondence Learning) (Blitzer et al., 2006) is regarded as a promising method to tackle transfer-learning problem.",1,original
"2 Previous Work So far, Structural Correspondence Learning has been applied successfully to PoS tagging and Sentiment Analysis (Blitzer et al., 2006; Blitzer et al., 2007).",1,original
"This algorithm appears fairly widely known: it was described by Goodman (1998) and Finkel et al (2006) and used by Ding et al (2005), and is very similar to other dynamic programming algorithms for CFGs, so we only summarize it here.",1,original
"2 Related Work To model the syntactic transformation process, researchers in these fieldsespecially in machine translationhave developed powerful grammatical formalisms and statistical models for representing and learning these tree-to-tree relations (Wu and Wong, 1998; Eisner, 2003; Gildea, 2003; Melamed, 2004; Ding and Palmer, 2005; Quirk et al. , 2005; Galley et al. , 2006; Smith and Eisner, 2006, inter alia).",1,original
"3 Quasi-Synchronous Grammar For a formal description of QG, we recommend Smith and Eisner (2006).",1,original
"When we run our classifiers on resource-tight environments such as cell-phones, we can use a random feature mixing technique (Ganchev and Dredze, 2008) or a memory-efficient trie implementation based on a succinct data structure (Jacobson, 1989; Delpratt et al., 2006) to reduce required memory usage.",1,original
"This means that the 1)roblem of recognizing named entities in those cases can be solved by incorporating techniques of base noun phrase chunking (Ramshaw and Marcus, 1995).",1,original
"Ramshaw and Marcus (Ramshaw and Marcus, 1995) successflflly applied Eric Brill's transformation-based learning method to the chunking problem.",1,original
"(Ramshaw and Marcus, 1995) shows that baseNP recognition (Fz=I =92.0) is easier than finding both NP and VP chunks (Fz=1=88.1) and that increasing the size of the training data increases the performance on the test set.",1,original
"It performed slightly worse on baseNP recognition than the (Ramshaw and Marcus, 1995) experiments (Fz=1=91.6).",1,original
"The IOB1 format, introduced in (Ramshaw and Marcus, 1995), consistently (:ame out as the best format.",1,original
"(l~mshaw and Marcus, 1995) have introduced a ""convenient"" data representation for chunking by converting it to a tagging task.",1,original
"The pioneering work of Ramshaw and Marcus (1995) introduced NP chunking as a machine-learning problem, with standard datasets and evaluation metrics.",1,original
"The simplest one is the BIO representation scheme (Ramshaw and Marcus, 1995), where a B denotes the first item of an element and an I any non-initial item, and a syllable with tag O is not a part of any element.",1,original
"4.2 Support Vector Machines We chose to adopt a tagging perspective for the Simple NP chunking task, in which each word is to be tagged as either B, I or O depending on wether it is in the Beginning, Inside, or Outside of the given chunk, an approach first taken by Ramshaw and Marcus (1995), and which has become the de-facto standard for this task.",1,original
"Following Ramshaw and Marcus (1995), the current dominant approach is formulating chunking as a classification task, in which each word is classified as the (B)eginning, (I)nside or (O)outside of a chunk.",1,original
"Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging (Brill, 1995; Ramshaw and Marcus, 1994), spelling correction (Mangu and Brill, 1997), word-sense disambiguation (Gale et al. , 1992), message understanding (Day et al. , 1997), discourse tagging (Samuel et al. , 1998), accent restoration (Yarowsky, 1994), prepositional-phrase attachment (Brill and Resnik, 1994) and base noun phrase identification (Ramshaw and Marcus, In Press; Cardie and Pierce, 1998; Veenstra, 1998; Argamon et al. , 1998).",1,original
"4 Data and Evaluation For the CoNLL shared task, we have chosen to work with the same sections of the Penn Treebank as the widely used data set for base noun phrase recognition (Ramshaw and Marcus, 1995): WSJ sections 15-18 of the Penn Treebank as training material and section 20 as test material 3.",1,original
"Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers (Collins, 1997; Charniak, 1997a; Charniak, 1997b; Ratnaparkhi, 1997), significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns  syntactic phrases or words that participate in a syntactic relationship (Church, 1988; Ramshaw and Marcus, 1995; Argamon et al. , 1998; Cardie and Pierce, 1998; Munoz et al. , 1999; Punyakanok and Roth, 2001; Buchholz et al. , 1999; Tjong Kim Sang and Buchholz, 2000).",1,original
"Recent comparisons of approaches that can be trained on corpora (van Halteren et al. , 1998; Volk and Schneider, 1998) have shown that in most cases statistical aproaches (Cutting et al. , 1992; Schmid, 1995; Ratnaparkhi, 1996) yield better results than finite-state, rule-based, or memory-based taggers (Brill, 1993; Daelemans et al. , 1996).",1,original
"We have chosen the Maximum Entropy tagger (Ratnaparkhi, 1996) for a comparison with our universal tagger, since it achieved (by a small margin) the best overall result on Slovene as reported there (86.360% on all tokens) of taggers available to us (MBT, the best overall, was not freely available to us at the time of writing).",1,original
"a.2 Maximum-entropy method The maximum-entropy method is useful with sparse data conditions and has been used by many researchers (Berger et al. , 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick el; al. , 1998; Uchimoto et al. , 1999).",1,original
"The state-of-theart systems have achieved an accuracy of 97% for English on the Wall Street Journal (WSJ) corpus (which contains 4.5M words) using various models (Brants, 2000; Ratnaparkhi, 1996; Thede and Harper, 1999).",1,original
"Hidden Markov models are simple and effective, but unlike discriminative models, such as Maximum Entropy models (Ratnaparkhi, 1996) and Conditional Random Fields (John Lafferty, 2001), they have more difficulty utilizing a rich set of conditionally dependent features.",1,original
A key component of the parsing system is a Maximum Entropy CCG supertagger (Ratnaparkhi 1996; Curran and Clark 2003) which assigns lexical categories to words in a sentence.,1,original
"Maximum Entropy (MaxEnt) principle has been successfully applied in many classification and tagging tasks (Ratnaparkhi, 1996; K. Nigam and A.McCallum, 1999; A. McCallum and Pereira, 2000).",1,original
"(Hakkani-Tur et al. , 2000)), and Basque (Ezeiza et al. , 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al. , 1996), (Erjavec et al. , 1999) (Slovenian), (Hajic and Hladka, 1997), (Hajic and Hladka, 1998) (Czech) and (Hajic, 2000) (five Central and Eastern European languages), but so far no system has reached in the absolute terms a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%.",1,original
"It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al. , 1994) and named entity tagging (Borthwick et al. , 1998), and achieves state of the art performance.",1,original
"Maximum entropy taggers have been shown to be highly competitive on a number of tagging tasks, such as partof-speech tagging (Ratnaparkhi 1996), and namedentity recognition (Borthwick et.",1,original
"Max-ent taggers have been shown to be highly competitive on a number of tagging tasks, such as part-of-speech tagging (Ratnaparkhi 1996), named-entity recognition (Borthwick et.",1,original
"Conditional Markov models (CMM) (Ratnaparkhi, 1996; Klein and Manning, 2002) have been successfully used in sequence labeling tasks incorporating rich feature sets.",1,original
"The most notable of these include the trigram HMM tagger (Brants, 2000), maximum entropy tagger (Ratnaparkhi, 1996), transformation-based tagger (Brill, 1995), and cyclic dependency networks (Toutanova et al. , 2003).",1,original
"This method led to improvement in the decoding speed as well as the output accuracy for English POS tagging (Ratnaparkhi, 1996).",1,original
"It worked well for word segmentation alone (Zhang and Clark, 2007), even with an agenda size as small as 8, and a simple beam search algorithm also works well for POS tagging (Ratnaparkhi, 1996).",1,original
"Their idea has proven effective for estimating the statistics of unknown words in previous studies (Ratnaparkhi, 1996; Nagata, 1999; Nakagawa, 2004).",1,original
"To improve the unknown word model, featurebased approach such as the maximum entropy method (Ratnaparkhi, 1996) might be useful, because we don't have to divide the training data into several disjoint sets (like we did by part of speech and word type) and we can incorporate more linguistic and morphological knowledge into the same probabilistic framework.",1,original
"Among recent top performing methods are Hidden Markov Models (Brants 2000), maximum entropy approaches (Ratnaparkhi 1996), and transformation-based learning (Brill 1994).",1,original
"Support Vector Machines (SVMs) (Vapnik, 1995) and Maximum Entropy (ME) method (Berger et al. , 1996) are powerful learning methods that satisfy such requirements, and are applied successfully to other NLP tasks (Kudo and Matsumoto, 2000; Nakagawa et al. , 2001; Ratnaparkhi, 1996).",1,original
"There has been significant work with such models for greedy sequence modeling in NLP (Ratnaparkhi, 1996; Borthwick et al. , 1998).",1,original
"1 Introduction The maximum entropy model (Berger et al. , 1996; Pietra et al. , 1997) has attained great popularity in the NLP field due to its power, robustness, and successful performance in various NLP tasks (Ratnaparkhi, 1996; Nigam et al. , 1999; Borthwick, 1999).",1,original
"This approach allows to combine strengths of generality of context attributes as in n-gram models (Brants, 2000; Megyesi, 2001) with their specificity as for binary features in MaxEnt taggers (Ratnaparkhi, 1996; Hajic and Hladk, 1998).",1,original
"Discriminative taggers and chunkers have been the state-of-the-art for more than a decade (Ratnaparkhi, 1996; Sha and Pereira, 2003).",1,original
"2 Method Maximum Entropy Markov Models (MEMMs) (Ratnaparkhi 1996) and their extensions (Tutanova et al 2003, Tsuruoka et al 2005) have been successfully applied to English POS tagging.",1,original
"More recent work has achieved state-of-the-art results with Maxi101 mum entropy conditional Markov models (MaxEnt CMMs, or MEMMs for short) (Ratnaparkhi, 1996; Toutanova & Manning, 2000; Toutanova et al. , 2003).",1,original
"Models that can handle non-independent lexical features have given very good results both for part-of-speech and structural disambiguation (Ratnaparkhi, 1996; Ratnaparkhi, 1997; Ratnaparkhi, 1998).",1,original
"He has achieved state-of-the art results by applying M.E. to parsing (Ratnaparkhi, 1997a), part-of-speech tagging (Ratnaparkhi, 1996), and sentence-boundary detection (Reynar and Ratnaparkhi, 1997).",1,original
"Our model exploits the same kind of tag-n-gram information that forms the core of many successful tagging models, for example, (Kupiec, 1992), (Merialdo, 1994), (Ratnaparkhi, 1996).",1,original
"The incorporation of Natural Language Processing (NLP) techniques such as Sentence Alignment (Brown et al., 1990), Text Classification (Koller and Sahami, 1997), and Graph-based methods (Bekkerman and Elkan, 2004) has been instrumental in improving the performance of various text summarization systems.",1,new
"Various approaches have been employed in the development of summarization systems, including the utilization of techniques such as Latent Semantic Analysis (Deerwester et al., 1990), Named Entity Recognition (Ratinov and Roth, 2009), and Machine Learning-based methods (Joachims, 1999) that have contributed significantly to their effectiveness.",1,new
"Techniques such as Dependency Parsing (Collins, 1999), TextRank algorithm (Mihalcea and Tarau, 2004), and Corpus-based methods (Brin, 1999) have been widely adopted in the field of text summarization, resulting in improved accuracy and efficiency of the summarization systems.",1,new
"Although the task of evaluating machine translation has garnered significant attention, the issue of assessing text simplification has been relatively underexplored, with notable contributions from Och and Ney (2003) and Costajohnson and Srinivasan (2001).",1,new
"Despite the abundance of research on sentiment analysis, the task of topic modeling for opinionated text has been largely overlooked, with notable exceptions being the works by Blei and Lafferty (2006) and Gruber et al. (2012).",1,new
"While the field of question answering has seen significant advancements, the problem of text compression has received relatively little attention, with notable contributions from Papineni and Roukos (1999) and Callison-Burch et al. (2004).",1,new
"The proposed methodology for segmenting sentences (Huang and Zhang, 2005) may be beneficial for enhancing our text classification model.",1,new
"The findings of the study on part-of-speech tagging (Kilgarriff and Grefenstette, 2003) can be applied to our current grammar-based approach.",1,new
"The recent research on dependency parsing (Collins, 1996) presents a promising direction for optimizing our natural language processing framework.",1,new
"Recent evaluations of machine learning algorithms (Manning and Schtze, 1999; Goodman, 1975) have demonstrated that in most instances, neural network approaches (Rumelhart et al., 1986; LeCun et al., 1989) outperform traditional, rule-based, or dictionary-based taggers (Katz, 1987; Church, 1988).",1,new
"The majority of studies comparing hybrid approaches (Kondrak, 2003; Collins, 2002) have found that in most cases, statistical methods (Brown et al., 1990; Viterbi, 1967) yield better results than finite-state or rule-based taggers (Hopcroft et al., 2006; Mohri et al., 1996).",1,new
"A comprehensive review of recent research (Jurafsky and Martin, 2000; Charniak, 1997) has shown that in most instances, machine learning techniques (Baker, 1979; Schtze, 1998) tend to outperform traditional, hand-crafted, or dictionary-based taggers (Krovetz, 1993; Lesk, 1986).",1,new
"Our results show that one of the most accurate methods for named entity recognition is the system developed by the Stanford Natural Language Processing Group (Sang and Liberman, 2000).",1,new
"The most reliable approach to sentiment analysis is the technique proposed by the TextBlob team (Loria and Guy, 2011), which has been widely adopted in the field.",1,new
"According to our experiments, one of the most efficient methods for topic modeling is the Latent Dirichlet Allocation algorithm developed by Blei et al. (2003), which has been successfully applied in various domains.",1,new
"4.2 Feature extraction methods Feature extraction methods have been proven to be effective in capturing the underlying structure of complex data, enabling researchers to identify meaningful patterns and relationships (e.g., Manning & Schtze, 1999; Sebastiani, 2002; Salton & McGill, 1983; Baeza-Yates & Ribeiro-Neto, 1999; Lewis, 1992).",1,new
"5.1 Contextualized embeddings Contextualized embeddings have been shown to be a powerful tool for improving the performance of NLP tasks, such as sentiment analysis and language modeling (e.g., Peters et al., 2018; Devlin et al., 2019; Howard & Ruder, 2018; Radford et al., 2019; Lee et al., 2020).",1,new
"4.3 Dependency parsing techniques Dependency parsing techniques have been successfully employed to analyze the grammatical structure of sentences, providing valuable insights into the relationships between words (e.g., Eisner, 1996; Kubler et al., 2009; McDonald et al., 2005; Goldberg, 2006; McDonald & Nivre, 2007).",1,new
"A variety of named entity recognizers have been successfully implemented, employing machine learning algorithms and capable of being fine-tuned on large datasets (Riloff & Jones 1999; Grishman & Sundheim 1996; Bikel et al. 1997).",1,new
"Several rule-based parsers have been developed, leveraging linguistic expertise and customizable for specific domains (Kasner 1998; Carroll & Challis 2002; Eisner 1996).",1,new
"A number of sentiment analysis tools have been created, utilizing various machine learning techniques and adaptable to different text genres (Hatzivassiloglou & McKeown 1997; Turney 2002; Kim & Hovy 1997).",1,new
"The study by Manning et al. (1999) demonstrated exceptional performance (93% on the Penn Treebank corpus) for part-of-speech tagging using Maximum Entropy models, leveraging rich feature sets and morphological analysis.",1,new
"Charniak (2000) achieved outstanding results (91% on the Wall Street Journal corpus) for statistical parsing with a maximum entropy model, incorporating contextual and syntactic features, thereby establishing a new benchmark.",1,new
"A notable achievement was reported by Collins (1996), who obtained impressive accuracy (95% on the Wall Street Journal corpus) for statistical parsing with a probabilistic context-free grammar, utilizing a large set of hand-built lexicalized rules and features.",1,new
"The application of machine learning algorithms (Bengio et al., 2003; McCallum et al., 2000; Collins, 2002) has significantly enhanced the accuracy of named entity recognition tasks, allowing for more efficient and effective processing of large datasets.",1,new
"The use of Hidden Markov Models (Rabiner, 1989; Jelinek, 1997; Juang et al., 2000) has revolutionized the field of speech recognition, providing a robust and reliable means of processing and transcribing spoken language.",1,new
"The incorporation of deep learning techniques (Goodfellow et al., 2016; LeCun et al., 2015; Karpathy et al., 2014) has greatly improved the performance of image classification tasks, enabling researchers to achieve state-of-the-art results in a wide range of applications.",1,new
"2 The development of named entity recognition has been significantly improved with the use of machine learning algorithms (Roth & Yih, 2004; Manning et al., 1999).",1,new
"3 The application of sentiment analysis in text classification has been greatly facilitated by the introduction of deep learning techniques (Collobert et al., 2011; Socher et al., 2013).",1,new
"4 The efficiency of information retrieval systems can be enhanced by incorporating techniques from natural language processing, as demonstrated by the work of Salton & Buckley (1990) and Baeza-Yates & Ribeiro-Neto (1999).",1,new
"The use of a combination of rule-based and machine learning approaches has been shown to achieve high accuracy in speech recognition tasks (Young et al., 1994).",1,new
"Our experiments have demonstrated that leveraging ensemble methods can lead to significant improvements in text classification performance (Domingos, 1996).",1,new
"The integration of linguistic features and statistical models has been found to be effective in improving the accuracy of part-of-speech tagging (Voutilainen, 1995).",1,new
"The concept of centrality measures has been effectively utilized in various network types, including co-authorship networks (Newman, 2001; Ravasz and Barabsi, 2003), citation networks (White and McCain, 1998; Pinski and Narin, 1976), and knowledge graphs (Bordes et al., 2013).",1,new
"Topological indices have been successfully applied to numerous network structures, such as social networks (Wasserman and Faust, 1994; Friedkin and Johnsen, 1990), web networks (Haveliwala, 2002; Langville and Meyer, 2004), and biological networks (Jeong et al., 2000).",1,new
"Eigenvector centrality measures have been widely used to analyze different types of networks, including actor collaboration networks (Wasserman and Faust, 1994; Marsden, 1990), email networks (Krebs, 2002; Wasserman and Faust, 1994), and protein interaction networks (Jeong et al., 2000).",1,new
"The proposed algorithm leverages contextual information to improve sentence-level alignment, a strategy that has been successfully applied in machine translation tasks (Brown et al., 1993).",1,new
"This approach utilizes a combination of syntactic and semantic features to model the reordering process, a technique that has proven effective in various NLP applications (Sutskever et al., 2014).",1,new
"By incorporating discourse-level information, the system enhances its ability to capture the nuances of language, a method that has been found to be particularly useful in language translation and text summarization (Vinyals et al., 2015).",1,new
"(Fukuda et al., 2015) demonstrated significant improvements in machine translation quality for the German-English language pair, outperforming existing benchmark models.",1,new
"(Kim et al., 2018) reported comparable results to leading neural machine translation systems for the Spanish-Chinese language pair, highlighting the potential of their proposed approach.",1,new
"(Sakaguchi et al., 2019) achieved state-of-the-art performance in English-Japanese machine translation, underscoring the effectiveness of their novel deep learning architecture.",1,new
"The same set of parameters is utilized for both the cascaded and parallel approaches, and the feature weights are optimized using the incremental MERT method suggested by Koehn (2004) and further improved by Snover et al. (2006).",1,new
"The identical evaluation metrics are applied to the rule-based and machine learning-based models, and the model weights are fine-tuned using the minimum error rate training proposed by Briscoe and Young (2008) and modified by Charniak (1997).",1,new
"The same criteria are employed for both the generative and discriminative models, and the model parameters are trained using the maximum likelihood estimation method proposed by Ney (2004) and refined by Chiang (2005).",1,new
"2 Recent advancements in deep learning have significantly improved the performance of image classification models (Krizhevsky et al., 2012; Simonyan and Zisserman, 2015; He et al., 2016; Szegedy et al., 2016; Huang et al., 2017).",1,new
"3 The development of neural machine translation has led to substantial gains in translation accuracy and fluency (Vaswani et al., 2017; Bahdanau et al., 2014; Sutskever et al., 2014; Cho et al., 2014; Liu et al., 2017).",1,new
"4 Significant progress has been made in speech recognition systems, leveraging the power of convolutional neural networks and recurrent neural networks (Dahl et al., 2012; Graves et al., 2013; Sainath et al., 2015; Amodei et al., 2016; Hinton et al., 2012).",1,new
"The advancements in data-driven approaches (Kumar et al., 2010; Patel and Lee, 2012) and agent-based modeling (Wang et al., 2012; Kim et al., 2015) have shown significant potential for predicting complex systems.",1,new
"Recent studies in machine learning (Srivastava et al., 2016; Zhang and Chen, 2017) and graph-based modeling (Gupta et al., 2018; Li et al., 2019) have demonstrated promising outcomes in various applications.",1,new
"The application of deep learning techniques (Lee et al., 2019; Kim et al., 2020) and knowledge graph-based modeling (Wang et al., 2020; Huang et al., 2021) has led to notable improvements in accuracy and efficiency.",1,new
"The proposed framework offers significant potential for advancements in natural language processing applications (Manning and Schtze, 1999).",1,new
"The developed techniques demonstrate considerable promise for enhancing the efficiency of information retrieval systems (Salton and McGill, 1983).",1,new
"These innovative approaches show great promise for actual improvements in text summarization output quality (Lin and Hovy, 2003).",1,new
"This study builds upon the foundational research of (Smith 2001), yet diverges significantly by adopting a novel approach that integrates multiple data sources to enhance the accuracy of linguistic analysis.",1,new
"Drawing from the seminal work of (Johnson 1985), our methodology innovatively applies machine learning techniques to classify text based on its contextual nuances, rather than relying on pre-existing categorizations.",1,new
"Our approach draws inspiration from the groundbreaking work of (Williams 1992), but expands upon it by incorporating a dynamic framework that adaptively updates the classification system in response to new data and emerging trends in language use.",1,new
"The use of vector space models (Hofmann, 1999) has been found to be effective in various NLP tasks, including text classification and clustering, as reported in the literature (Dhillon & Mallela, 2003).",1,new
"According to the research by Yang and Pedersen (1997), the use of statistical models has shown significant improvement in sentiment analysis tasks, and this has been supported by numerous studies (Turney, 2002).",1,new
"The work by Ester et al. (1996) on clustering algorithms has been widely applied in data mining and knowledge discovery, demonstrating its usefulness in identifying patterns and relationships in large datasets (Kriegel et al., 2009).",1,new
The works of Smadja (1993) on collocations and of Schtze (1998) on word embeddings are highly influential in the field of natural language processing.,1,new
"The theories of mutual information (Cover and Thomas, 1991) and latent semantic analysis (Deerwester et al., 1990) have significantly impacted the development of text analysis techniques.",1,new
"The concepts of semantic priming (Neely, 1977) and discourse representation theory (Kamp and Reyle, 1993) have been widely adopted in computational linguistics research.",1,new
"Our approach employed a graph-based model to capture the spatial relationships between entities because it has been shown to yield superior results in various comparative studies (Batsakis, 2013; Li, 2015).",1,new
"The use of semantic role labeling as a feature in our model was motivated by its widespread adoption and demonstrated effectiveness in numerous prior investigations (Gros, 2016; Hovy, 2017).",1,new
"We incorporated named entity recognition into our system due to its established track record of success and utility in various natural language processing applications (Liu, 2012; Grishman, 2013).",1,new
"The most significant contributions in this area are attributed to Hirst and St-Onge (Hirst and St-Onge, 1998), Hobbs (Hobbs, 1996), and Sussna (Sussna, 1996).",1,new
"Notably, the work of Lesk (Lesk, 1986), Charniak (Charniak, 1997), and Grishman (Grishman, 1996) have had a profound impact on this field.",1,new
"Of particular note are the studies by Hobbs (Hobbs, 1985), Sowa (Sowa, 1991), and Guarino and Welty (Guarino and Welty, 1995), which have greatly influenced this area of research.",1,new
The work of Feller (1957) is also a significant contribution to this field.,1,new
The seminal study by Shannon (1948) is widely regarded as a foundational piece of research.,1,new
The groundbreaking findings of Zipf (1949) have had a lasting impact on our understanding of this phenomenon.,1,new
Srensen (1971) evaluated the effectiveness of various measures for calculating semantic similarity and concluded that the Dice coefficient and the Jaro-Winkler distance were the most reliable.,1,new
"In a comparative study, Manning and Schtze (1999) compared the performance of several algorithms for topic modeling and discovered that Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF) yielded the most accurate results.",1,new
"According to a review of clustering techniques, Xu and Wunsch (2008) found that both the k-means algorithm and hierarchical clustering were effective methods for identifying patterns in large datasets.",1,new
"The model's performance is evaluated using a combination of metrics, including:  various ranking functions, of which most are applied to sentence embeddings  measures of semantic similarity, equivalence, and entailment, including a widely-used measure due to Zhang and Lin (2018), based on manually constructed lexical resources such as ConceptNet and PropBank  a function based on the well-known word mover's distance metric of Kusner et al. (2015), which automatically infers similarity of sentences from their distributions in a large corpus of text. The ability to leverage external lexical resources both manually and automatically constructed is crucial to the success of the proposed approach.",1,new
"The proposed framework utilizes a sophisticated combination of scoring functions, including:  various similarity metrics, of which most are applied to named entity recognition  measures of coreference resolution, coreference, and co-mention, including a widely-used measure due to Hobbs et al. (1993), based on manually constructed lexical resources such as MUC and ACE  a function based on the well-known distributional similarity metric of Turney (2010), which automatically infers similarity of words and phrases from their distributions in a very large corpus of text. The ability to leverage external lexical resources both manually and automatically constructed is essential to the success of the proposed framework.",1,new
"The evaluation protocol employs a comprehensive set of metrics, including:  various classification functions, of which most are applied to part-of-speech tagging  measures of syntactic similarity, dependency parsing, and semantic role labeling, including a widely-used measure due to Collins (1999), based on manually constructed lexical resources such as PropBank and Penn Treebank  a function based on the well-known similarity metric of Pedersen et al. (2004), which automatically infers similarity of words and phrases from their distributions in a large corpus of text. The ability to leverage external lexical resources both manually and automatically constructed is vital to the success of the proposed evaluation protocol.",1,new
"Recent studies have demonstrated that graph-based semantic networks have outperformed other knowledge representation models in various applications (Bordes et al., 2011; Gabrilovich and Markovitch, 2007), whereas for the task of sentiment analysis, rule-based systems have been shown to achieve comparable, if not superior, results (Kessler et al., 2013; Turney, 2002).",1,new
"While distributional semantic models have been found to excel in several NLP tasks (Harris, 1954; Mikolov et al., 2013), for the problem of named entity recognition, pattern-based approaches have been shown to yield comparable, if not better, performance (Bikel et al., 1999; Ratinov and Roth, 2009).",1,new
"In contrast to other word vector representations, neural network-based semantic spaces have been proven to excel in several linguistic tasks (Deerwester et al., 1990; LeCun et al., 2015), whereas for the task of text classification, decision tree-based models have been found to perform equally well, if not surpass, these neural network-based approaches (Quinlan, 1986; Japkowicz and Shah, 2011).",1,new
"Notably, despite significant progress in model training data (Koehn, 2005) and machine learning algorithms (Och, 2003), none of these advancements have led to a substantial improvement in the overall accuracy of a high-performing system.",1,new
"Although notable advancements in feature engineering (Melamed, 2004) and decoding strategies (Chen & Rogers, 2003) have been made, they have not significantly enhanced the translation quality of a cutting-edge system.",1,new
"In contrast to the improvements in corpus linguistics (Zampolli, 2003) and optimization techniques (Bengio et al., 2003), the quality of a top-tier translation system has not been notably enhanced by these advances.",1,new
"Comparable to the work of Carpuat and Wu (2007a), researchers have successfully employed contextual clues to resolve syntactic ambiguity in sentences (Klein and Manning, 2003).",1,new
"Inspired by the approach of Carpuat and Wu (2007a), a novel method has been developed to leverage contextual information for disambiguating idiomatic expressions (Petrov and Klein, 2010).",1,new
"In a similar vein to Carpuat and Wu (2007a), researchers have utilized contextual dependencies to address the problem of semantic ambiguity in noun phrase interpretation (Bansal and Cardie, 2011).",1,new
"The application of machine learning algorithms to natural language processing tasks has significantly enhanced the accuracy of sentiment analysis (Kumar et al., 2010; Liu and Zhang, 2009).",1,new
"Recent studies have demonstrated the effectiveness of using deep learning models for named entity recognition, leading to improved information retrieval (Hinton et al., 2006; Collobert et al., 2011).",1,new
"The integration of cognitive computing and natural language processing has resulted in notable advancements in text summarization, enabling more efficient information extraction (Sutskever et al., 2014; Mikolov et al., 2010).",1,new
"The innovative approach presented in Chen and Lee (2015) employs a hybrid method combining support vector machines and decision trees to accurately identify and rank candidate phrases, allowing for improved phrase selection in the context of machine translation.",1,new
"In a groundbreaking study, Zhang and Kim (2010) utilize a novel ensemble learning technique that integrates logistic regression and gradient boosting to enhance the accuracy of phrase evaluation, leading to more effective phrase selection in natural language processing tasks.",1,new
"The research by Patel and Kim (2012) showcases the use of a sophisticated neural network architecture that combines convolutional neural networks and recurrent neural networks to dynamically assess the relevance of phrase pairs, resulting in improved phrase selection in sentiment analysis applications.",1,new
"Recent advances in topic modeling have significantly contributed to the development of sentiment analysis, a crucial task in natural language processing with applications in opinion mining (Hu & Liu, 2004; Turney, 2002), information extraction, and text summarization. Sentiment analysis is generally considered a binary classification problem where the polarity of a piece of text is assigned a label (positive, negative, or neutral) during the analysis process.",1,new
"Named entity recognition (NER) is a fundamental challenge in natural language processing with applications in information retrieval (IR), question answering (QA), and text summarization (Borthwick et al., 1999; Finkel et al., 2005). NER is typically viewed as a classification problem where each entity is assigned a specific category label (person, organization, location, etc.) during the recognition process.",1,new
"The task of speech recognition has gained significant attention in recent years, with applications in voice assistants, speech-to-text systems, and human-computer interaction (Bahl et al., 2006; Young et al., 2002). Speech recognition is generally considered a classification problem where the input audio signal is assigned a corresponding text label during the recognition process.",1,new
"Recent studies have shown promising results in the application of Named Entity Recognition (NER) to enhance the accuracy of sentiment analysis, a field that has been met with skepticism in the past (Kim and Hwang, 2010; Riloff and Jones, 1999). We are optimistic that similar advancements will be seen in the realm of topic modeling, where NER has the potential to significantly improve the quality of extracted insights (Blei et al., 2003; Mihalcea and Radev, 2004).",1,new
"Despite initial doubts regarding the effectiveness of Dependency Parsing in improving natural language processing, recent research has demonstrated its potential in enhancing machine translation (Nivre et al., 2007; McDonald et al., 2005) and part-of-speech tagging (Toutanova and Manning, 2000). We anticipate that further developments in Dependency Parsing will lead to breakthroughs in other areas such as information extraction and text classification.",1,new
"While some have questioned the value of coreference resolution in enhancing the performance of information retrieval systems, recent studies have shown that its application can lead to significant improvements in precision and recall (Baltag and Asp, 2006; Clark and Gupta, 2004). We believe that continued research in this area will yield even more substantial benefits in related fields like text summarization and question answering.",1,new
"The development of new word embeddings, such as those proposed by Collobert and Weston (2008), could also be a promising area of research.",1,new
"Incorporating syntactic features, such as parse trees (Klein and Manning, 2003), may lead to improved performance in machine translation systems.",1,new
"Another potential area of exploration could be the use of named entity recognition techniques, as suggested by Ratinov and Roth (2009), to enhance the accuracy of information retrieval models.",1,new
"The integration of active learning into machine translation (MT) systems has proven to be a challenging task, as demonstrated by the mixed results of studies on incorporating active learning into MT frameworks: various approaches lead to inconsistent conclusions on the effectiveness of active learning in improving MT performance (Santos et al., 2013; Galley et al., 2015).",1,new
"In contrast, the incorporation of sentiment analysis into statistical machine translation (SMT) systems has been shown to be a complex process, as highlighted by the contrasting findings of research on integrating sentiment analysis into SMT systems: different methods of integration yield conflicting conclusions on whether sentiment analysis enhances MT performance (Hermann et al., 2013; Liu et al., 2009).",1,new
"On the other hand, the addition of knowledge graph-based methods to neural machine translation (NMT) systems has been found to be a difficult task, as illustrated by the varying results of studies on integrating knowledge graphs into NMT systems: different ways of incorporating knowledge graphs lead to inconclusive conclusions on the impact of knowledge graphs on NMT performance (Das et al., 2017; Vyas et al., 2018).",1,new
"The integration of semantic role labeling (SRL) techniques into spoken language translation has been shown to improve translation accuracy, particularly when SRL systems utilize discourse trees as input features (Collins et al., 2005; Hwang et al., 2005; Zhang et al., 2005).",1,new
"Research in machine learning has demonstrated that using contextualized word embeddings can enhance the performance of machine translation systems, especially when these embeddings are fine-tuned for domain-specific tasks (Devlin et al., 2018; Peters et al., 2018; Wang et al., 2018).",1,new
"Recent studies have found that incorporating named entity recognition (NER) into statistical machine translation can improve the accuracy of entity translation, particularly when NER systems utilize pre-trained language models as feature extractors (Lample et al., 2016; Riedel et al., 2017; Strassel et al., 2017).",1,new
"Our analysis reveals a promising trend in the application of Transfer Learning in Computer Vision, where pre-trained models show notable improvements in Image Classification tasks (Krizhevsky et al., 2012; Simonyan and Zisserman, 2014).",1,new
"Recent studies have demonstrated a significant impact of Graph Neural Networks on Recommendation Systems, leading to enhanced user experience and improved prediction accuracy (Kipf and Welling, 2016; Ying et al., 2018).",1,new
"The integration of Attention Mechanisms in Recurrent Neural Networks has yielded remarkable results in Natural Language Processing tasks such as Text Summarization, indicating a positive shift in the field (Vaswani et al., 2017; Yang et al., 2016).",1,new
"The incorporation of neural network architectures in Natural Language Processing (NLP) tasks has shown significant improvements, as evidenced by the work of Mikolov et al. (2010) and Collobert et al. (2011).",1,new
"Recent research has highlighted the advantages of utilizing transfer learning in deep learning models, with notable contributions from Yosinski et al. (2014) and Howard and Ruder (2018).",1,new
"The application of graph-based methods in text analysis has been proven effective, as demonstrated by the studies of Mikolov et al. (2013) and Pennington et al. (2014).",1,new
"The integration of deep learning techniques with traditional parsing methods, as discussed by Socher et al. (2013), has led to significant advancements in the field of natural language processing, further explored by Collobert et al. (2011).",1,new
"The innovative application of graph-based algorithms, as described by Kipf and Welling (2016), has been effectively combined with node embedding methods by Grover and Leskovec (2016), yielding promising results in network analysis.",1,new
"A novel approach that merges the strengths of both unsupervised and supervised learning, as outlined by Bengio et al. (2013), has been successfully implemented by Ma et al. (2015), showcasing its potential in speech recognition tasks.",1,new
"Our approach has been demonstrated to yield significant enhancements over the random forest classifier in multiple domains of computer vision such as image classification (Fei-Fei et al., 2006), object detection (Dalal and Triggs, 2005), segmentation (Martin et al., 2004), and tracking (Berg et al., 2000).",1,new
"The proposed method has been found to provide substantial improvements over the decision tree classifier in various areas of information retrieval including text classification (Lewis et al., 1999), clustering (Kaufman and Rousseeuw, 1990), recommendation systems (Sarwar et al., 2001), and retrieval (Baeza-Yates and Ribeiro-Neto, 1999).",1,new
"Our technique has been shown to outperform the Naive Bayes classifier in numerous applications of natural language processing including sentiment analysis (Pang and Lee, 2008), named entity recognition (Ratinov and Roth, 2009), question answering (Chen et al., 2017), and language modeling (Mikolov et al., 2010).",1,new
"Johnson and Lee (2019) introduce a novel approach to parallelize the graph partitioning problem, resulting in a significant reduction in computational time by leveraging the power of distributed computing.",1,new
"In a groundbreaking paper, Davis et al. (2015) propose a fast and efficient method for solving linear systems of equations using the H-matrix decomposition, showcasing its potential in high-performance computing applications.",1,new
"According to a recent study by Kim and Kim (2020), the application of the Chebyshev polynomials in numerical analysis yields substantial improvements in the accuracy and convergence rate of iterative methods for solving differential equations.",1,new
"The use of transfer learning has been proven to enhance performance in various NLP tasks (Ruder et al., 2017; Collobert and Weston, 2008; Wang and Manning, 2013; Sennrich et al., 2015; Vronis et al., 2016).",1,new
"Empirical studies have demonstrated that incorporating domain knowledge can significantly boost the accuracy of machine translation systems (Brown et al., 1993; Melamed, 2001; Ueffing and Nivre, 2002; Zhang and Lapata, 2004; Chiang, 2005).",1,new
"The incorporation of paraphrasing techniques has been shown to improve the fluency and coherence of generated text (Hovy et al., 2006; Barzilay and Lapata, 2008; Bannard and Callison-Burch, 2005; Callison-Burch, 2007; Khandelwal et al., 2019).",1,new
"The joint distribution over hidden states s and observations y can be expressed as p(s,y|pi0,pi,,K) = Tproductdisplay t=1 p(st|st1)p(yt|st), as demonstrated by the work of Rabiner (1989) in his comprehensive review of HMM applications. However, training the HMM with EM has been shown to yield suboptimal results in various NLP tasks.",1,new
"The conditional probability p(s,y|pi0,pi,,K) can be factorized into the product of state transition probabilities and observation probabilities, as described by the seminal work of Jelinek (1976). Nevertheless, experiments have consistently demonstrated that using the EM algorithm for HMM training can lead to disappointing outcomes in speech recognition tasks.",1,new
"According to the theory of hidden Markov models, the joint distribution over hidden states and observations can be written as p(s,y|pi0,pi,,K) = Tproductdisplay t=1 p(st|st1)p(yt|st), as outlined by the foundational work of Baum and Petrie (1966). Nonetheless, numerous studies have shown that employing the EM algorithm for HMM training can result in unsatisfactory performance in text classification tasks.",1,new
"Recent advances in natural language processing (Chen et al., 2010) and machine learning (Pantel et al., 2009; Manning et al., 1999) have led to notable improvements in information extraction.",1,new
"The development of deep learning techniques (Collobert et al., 2008) and word embeddings (Mikolov et al., 2013) has significantly boosted the performance of sentiment analysis and opinion mining tasks.",1,new
"Significant breakthroughs in text classification (Joachims, 1998) and named entity recognition (Ratinov and Roth, 2009) have been achieved through the application of various machine learning algorithms and data-driven approaches.",1,new
"However, another key factor contributing to the underwhelming performance of current summarization models is their inability to effectively capture nuanced temporal relationships between events (Gompel et al., 2018; Barzilay et al., 2009).",1,new
"In line with previous studies, the limitations of existing summarization techniques are largely attributed to their reliance on simplistic text analysis methods that fail to account for contextual nuances (Hahn et al., 2011; Elsner et al., 2013).",1,new
"The primary reason why state-of-the-art summarization models often fall short of expectations is their inability to leverage domain-specific knowledge and terminology, which is a crucial aspect of effective summarization (Teufel et al., 2006; Riloff et al., 1993).",1,new
"Our approach is comparable to that of (Johnson et al., 2010), who also demonstrated impressive accuracy on a range of similarity tasks.",1,new
"Similar to (Kim and Lee, 2015), our methodology leverages a streamlined approach to achieve comparable results on similarity evaluation datasets.",1,new
"Our methodology bears some resemblance to the work of (Brown et al., 2008), which achieved notable success in identifying similarities among complex data sets.",1,new
"The methodology employed in this study has been found to be both efficient and reliable, making it a valuable contribution to the field (Gibson and Klein, 1997; Collins and Roark, 2004; Socher et al., 2011).",1,new
"Despite its straightforward approach, the proposed model has demonstrated remarkable performance in text classification tasks, outperforming other methods in the literature (Klein and Manning, 2003; Collins, 2004; Manning et al., 2010).",1,new
"The innovative technique used in this research has shown great promise for improving the accuracy of dependency parsing, with results that are both impressive and consistent across different datasets (Zettlemoyer and Collins, 2005; Collins and Roark, 2004; Bikel et al., 2005).",1,new
Zhang and Liu (2012) employed online forums as a supplementary resource to enhance Text Classification accuracy.,1,new
Kulkarni et al. (2011) leveraged social media platforms to augment their work on Sentiment Analysis and opinion mining.,1,new
Agarwal and Mittal (2013) utilized online reviews as a valuable source to improve their Natural Language Processing models for product recommendation systems.,1,new
Matsumoto et al. (2010) boost their classification accuracy by 5% by employing a sentiment analysis technique that leverages social media platforms.,1,new
Li and Chen (2015) enhance their regression model's performance by incorporating a novel time-series feature extraction method.,1,new
Wang and Lee (2012) achieve a 2% increase in their object detection model's precision through the utilization of a deep learning-based approach to image feature extraction.,1,new
"Our study built upon the work of Liu et al. (2015), who demonstrated the effectiveness of utilizing entity recognition from the web for named entity disambiguation tasks, and achieved notable improvements in precision rates.",1,new
"Similarly, the approach of Kim and Lee (2018) utilizing semantic roles in the construction of a dictionary-based gazetteer showed promising results for the Korean NER, outperforming traditional rule-based methods.",1,new
"Furthermore, the incorporation of WordNet synsets, as proposed by Ruppenhofer et al. (2012), significantly enhanced the accuracy of named entity recognition in a multilingual setting, with notable improvements in the detection of entities in languages with limited resources.",1,new
"Our understanding of linguistic patterns has been significantly improved by the recent work of (De Felice and Bosco, 2010; Passonneau and Lehnert, 2004), who developed efficient methods for constructing comprehensive lexical resources.",1,new
"The development of sophisticated machine learning algorithms has been facilitated by the research of (Koller and Sahami, 1997; Dietterich, 2000), enabling more accurate predictions and classifications in various fields.",1,new
"The advancements in natural language processing have been greatly enhanced by the contributions of (Brown et al., 1990; Manning and Schtze, 1999), who have created innovative techniques for text analysis and information retrieval.",1,new
"The development of entity disambiguation techniques has been a crucial area of research in the field of information retrieval, with numerous studies focusing on disambiguating entities such as organizations and locations (Haveliwala, 2002; Liu et al., 2010).",1,new
"A significant challenge in text classification is the identification of homographs, which have led to the growth of research in the area of homograph disambiguation, with various methods proposed in the literature (Brown et al., 1992; Pantel and Ravichandran, 2004).",1,new
"The issue of duplicate detection in bibliographic databases has been addressed through the application of string similarity measures, with researchers such as McNamee and Mayfield (2004) and Bilenko et al. (2003) contributing to the field.",1,new
"Recent studies (Zhu et al., 2010; Manning et al., 2008; Ratinov et al., 2009) have built upon the foundation established by earlier research, utilizing massive datasets to extract nuanced features with high precision.",1,new
"The development of more sophisticated methodologies (Gibson et al., 2012; Socher et al., 2011; Collobert et al., 2011) has enabled researchers to effectively leverage large-scale corpora, yielding remarkable results in feature extraction and representation learning.",1,new
"Ongoing research (Liu et al., 2014; Mikolov et al., 2013; Pennington et al., 2014) continues to refine and improve the use of large datasets, pushing the boundaries of what is possible in terms of feature representation and model performance.",1,new
"Our current understanding of natural language processing algorithms (Manning and Schtze, 1999) is greatly surpassed by more recent advancements in deep learning models (Hinton et al., 2006), which can learn complex patterns in vast datasets, such as the 100 million word Google n-gram corpus.",1,new
"Recent studies have shown that machine learning techniques (Bishop, 2006) have made significant strides in text classification (Joachims, 1999) and sentiment analysis (Turney, 2002), outperforming traditional rule-based approaches by leveraging large amounts of labeled data and sophisticated algorithms.",1,new
"The development of more advanced language models (Jurafsky and Martin, 2000) has enabled significant improvements in speech synthesis (Haskins, 1988) and machine translation (Brown et al., 1990), which are now capable of producing high-quality outputs that rival those of human professionals.",1,new
"The increasing availability of large-scale datasets has significantly contributed to the advancement of various machine learning applications, such as text classification, sentiment analysis, named entity recognition, topic modeling, and question answering (Lee et al., 2008; Manning et al., 2008; Riloff et al., 2006).",1,new
"Recent studies have demonstrated the effectiveness of leveraging massive online corpora for enhancing the performance of natural language processing tasks, including dependency parsing, coreference resolution, word sense induction, information extraction, and language modeling (Baker et al., 2008; Toutanova et al., 2003; Chen et al., 2005).",1,new
"The utilization of large Web-based corpora has been widely recognized as a valuable resource for improving the accuracy of various NLP tasks, such as part-of-speech tagging, semantic role labeling, discourse parsing, machine reading comprehension, and text summarization (Grishman et al., 2007; Marcus et al., 1993; Hovy et al., 2006).",1,new
"Researchers have proposed several innovative techniques to improve the efficiency of neural network architectures on large-scale linguistic datasets, including the utilization of knowledge distillation methods (Hinton et al., 2015), hierarchical softmax functions (Goodfellow et al., 2014), and distributed training strategies (Dean et al., 2012).",1,new
"To address the computational challenges associated with deep learning models on extensive corpora, researchers have explored the application of model compression techniques such as quantization (Courbariaux et al., 2015), low-rank matrix factorization (Sainath et al., 2015), and pruning algorithms (Han et al., 2015).",1,new
"In order to overcome the limitations of large-scale language models, researchers have investigated alternative approaches such as the use of graph-based representations (Kipf et al., 2016), sparse attention mechanisms (Vaswani et al., 2017), and knowledge graph embedding (Nickel et al., 2016).",1,new
"Our research utilizes the efficient A* algorithm (Hart et al., 1968) due to its ability to expedite pathfinding in complex networks, surpassing more computationally intensive methods like the Floyd-Warshall algorithm.",1,new
"We opted for the simple and effective delta encoding technique (Karp et al., 1972) over more complex run-length encoding due to its lower overhead and increased speed in data compression tasks.",1,new
"The implementation of the Viterbi algorithm (Viterbi, 1967) is preferred in our analysis over the more complex forward-backward algorithm due to its superior efficiency and ease of parallelization in a large-scale processing environment.",1,new
"The recent development of neural network architectures has significantly improved the performance of machine learning models (Bengio et al., 2003), and the ability to incorporate large-scale pre-training with minimal computational overhead is a substantial advantage over traditional methods.",1,new
"The innovative use of recursive neural networks has led to breakthroughs in natural language processing (Socher et al., 2013), and the capacity to handle complex, hierarchical structures without sacrificing computational efficiency is a notable advancement in the field.",1,new
"Research has demonstrated that the integration of attention mechanisms into deep learning models has revolutionized the field of computer vision (Vaswani et al., 2017), and the ability to selectively focus on relevant regions of the input data without increasing computational requirements is a key factor in achieving state-of-the-art performance.",1,new
"Our model's performance in the perplexity metric is somewhat lacking, but a closer examination of Table 5 reveals some promising insights when comparing our approach to a 7-gram language model and the highly-regarded system, Google's NMT (Wu et al., 2016), across various evaluation metrics such as perplexity, METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006), WER, and PER.",1,new
"Although our model's accuracy on the test set is not exceptional, a careful analysis of Table 2 demonstrates some encouraging trends when juxtaposing our method with a 4-gram language model and the widely-used system, Phrase-Based SMT (Koehn et al., 2007), based on metrics such as accuracy, BLEU score (Papineni et al., 2002), NIST score (Doddington, 2002), and METEOR.",1,new
"Our model's results in the translation edit rate metric are not spectacular, but a detailed examination of Table 1 suggests some redeeming qualities when comparing our approach to a 3-gram language model and the highly-cited system, IBM's Machine Translation (Brown et al., 1990), across various evaluation metrics including translation edit rate, BLEU score, and WER.",1,new
"The use of neural machine translation (NMT) models (Sutskever et al., 2014) has been shown to significantly improve translation quality while retaining the efficiency of rule-based systems.",1,new
"Hybrid approaches, such as combining statistical machine translation (SMT) with NMT (Zhang and Zong, 2016), have been found to offer the best of both worlds in terms of accuracy and complexity.",1,new
"For instance, the incorporation of syntax-based features in statistical machine translation (Kumar and Byrne, 2005) has enabled the development of more sophisticated translation systems with improved fluency and coherence.",1,new
"The introduction of low-cost, open-source annotation tools, such as the Open Data Kit (ODK) platform (Goodwin et al., 2010), could potentially alleviate some of the challenges associated with traditional annotation methods, allowing for more efficient and cost-effective data collection in the future.",1,new
"Furthermore, the utilization of crowdsourcing platforms, like Clickworker (Schmidt et al., 2015), might offer an alternative solution for tasks that do not necessitate highly specialized annotators, thus providing a more feasible option for researchers with limited budgets.",1,new
"The development of novel annotation tools that incorporate gamification elements, as seen in projects like the Game With A Purpose (GWAP) initiative (Von Ahn et al., 2008), could not only engage a larger pool of volunteers but also reduce the financial burden associated with traditional annotation processes, potentially leading to more comprehensive and accurate data sets.",1,new
"Recent machine learning algorithms (Jurafsky and Martin, 2000; Manning and Schutze, 1999; Riezler et al., 2002) are based on manually annotated corpora that are labor-intensive to develop.",1,new
"State-of-the-art neural networks (Sutskever et al., 2014; Graves et al., 2013; Bengio et al., 2003) rely on large amounts of expert-annotated data, which are costly to collect and annotate.",1,new
"Current computational models (Vapnik, 1998; Mitchell, 1997; Dietterich, 2000) are often trained on annotated datasets that are expensive to create and maintain, hindering their widespread adoption.",1,new
"This study employs graph-based dependency parsing to extract informative syntactic features (Bikel, 2004).",1,new
"The authors utilize distributional semantics to construct high-quality semantic representations (Harris, 1954).",1,new
"By leveraging contextualized word embeddings, researchers are able to develop effective latent semantic models (Peters et al., 2018).",1,new
"The research of Lin et al. (2012) sheds light on the crucial role of contextualization in the development of accurate word embeddings for downstream NLP tasks, offering a valuable contribution to the field.",1,new
"The work of Manning and Schtze (1999) provides a comprehensive overview of the fundamental principles underlying the construction of robust part-of-speech taggers, which remains a cornerstone of natural language processing research today.",1,new
"The study by Mikolov et al. (2013) offers a groundbreaking approach to learning vector representations of words, paving the way for significant advances in areas such as sentiment analysis and information retrieval.",1,new
"This work is built upon the foundations laid out in several seminal studies (Brown et al., 1988; Collins, 1999).",1,new
"The methodology employed in this research is heavily influenced by the approaches described in (Katz, 1987; Melamed, 2004).",1,new
"The theoretical framework of this study is grounded in the concepts introduced in (Chomsky, 1957; Halliday, 1961).",1,new
"The most notable achievement in this domain was an accuracy of 90.5% (Klein, 2005).",1,new
"This surpasses the previous state-of-the-art result of 78.2% (Gros, 2012).",1,new
"The highest reported accuracy in the literature is 85.1% (Liu et al., 2018), which sets a new benchmark for future research.",1,new
"Our analysis of the study by Pantel and Musen (2009) reveals that their use of lexical resources in the WordNet framework results in a significant improvement in question answering accuracy, reaching 51% on 243 questions.",1,new
"The work by Snow et al. (2008) demonstrates the effectiveness of their ontology-based approach in achieving a 62% accuracy rate on 321 multiple-choice questions, surpassing previous corpus-based methods.",1,new
"A recent study by Banerjee and Pedersen (2003) utilizing the WordNet thesaurus achieves a notable accuracy of 48% on 279 analogy questions, showcasing the potential of lexical databases in natural language processing tasks.",1,new
"The incorporation of lexical database features has been shown to result in notable improvements in various applications, including sentiment analysis and topic modeling (Hatzivassiloglou & McKeown, 1997; Turney, 2002).",1,new
"The application of named entity recognition techniques has led to significant advancements in information retrieval and text classification systems (Bikel et al., 1997; Riloff & Jones, 1999).",1,new
"The development of machine learning algorithms for text classification has yielded impressive outcomes, particularly in the areas of spam detection and opinion mining (Joachims, 1998; Pang & Lee, 2004).",1,new
"Recent studies on the application of machine learning algorithms in natural language processing have shown significant progress (Bengio et al., 2003; Collobert et al., 2008; Mikolov et al., 2010; Socher et al., 2011; Zhang and Lapata, 2014).",1,new
"Over the past decade, considerable advances in the field of text classification have been reported (Joachims, 1998; Sebastiani, 2002; Lewis et al., 2004; Zhang et al., 2005; McCallum and Nigam, 2007).",1,new
"In recent years, notable research on the automatic extraction of named entities has been published (Bontcheva et al., 2004; Ng and Lee, 2005; Ruppenhofer et al., 2006; Flair, 2009; Etzioni et al., 2010).",1,new
"Smith and Johnson (2015) employ a novel approach to lexical analysis, leveraging probabilistic methods to discern semantic relationships between terms with a minimum frequency of three occurrences.",1,new
"According to Thompson and Lee (2002), the use of co-occurrence analysis is a reliable technique for discovering collocations, particularly for words with a frequency of not less than four instances.",1,new
"In their seminal work, Patel and Kim (1998) demonstrate the efficacy of n-gram analysis in identifying collocations, recommending this method for words with a frequency of at least two occurrences in a corpus.",1,new
"The most influential dimensionality reduction technique in data analysis is Principal Component Analysis (PCA) (Hotelling 1933; Jolliffe 1986; Jackson 1991; Pearson 1993; Abdi and Williams 2010; Hardin and Hilbe 2007; Jolliffe and Cadima 2016), dened by: weight PCA (x) = log 2 ||x|| ||x'|| (3) where x is the original data point, x' is the projected data point, and ||.|| denotes the Euclidean norm. We calculate the PCA weights by the following statistics in the space of data points S: weight PCA (x) = log 2 ||x - x'|| ||x|| (4) where ||x - x'|| is the distance between the original and projected data points, and ||x|| is the magnitude of the original data point. High PCA weights are assumed to correspond to significant data point projections.",1,new
"The most widely used sentiment analysis technique is Naive Bayes (NB) (Rennie et al. 2003; McCallum and Nigam 1998; Domingos and Pazzani 1997; Lewis 1998; Joachims 1999), dened by: weight NB (x) = log 2 P(x|y) P(y) (5) where x is the feature vector, y is the class label, and P(x|y) and P(y) are the conditional and marginal probabilities. We calculate the NB weights by the following statistics in the space of feature vectors S: weight NB (x) = log 2 count(x,y) count(y) (6) where count(x,y) is the frequency of the feature vector x in class y, and count(y) is the frequency of class y in S. High NB weights are assumed to correspond to strong feature-class associations.",1,new
"The most commonly used clustering algorithm is K-Means (KM) (MacQueen 1967; Lloyd 1982; Hartigan and Wong 1979; Spath 1980; Pollard and Johnson 1989; Jain 2010), dened by: weight KM (x) = log 2 ||x - c|| ||x|| (7) where x is the data point, c is the centroid, and ||.|| denotes the Euclidean norm. We calculate the KM weights by the following statistics in the space of data points S: weight KM (x) =",1,new
"The most commonly employed co-occurrence matrix normalization technique is the Term Frequency-Inverse Document Frequency (TF-IDF) method (Salton and McGill, 1983; Sparck Jones et al., 1972; Ramos, 2003).",1,new
"A widely used measure of semantic similarity is the Word Embedding-based Cosine Similarity metric (Mikolov et al., 2013; Pennington et al., 2014; Le and Mikolov, 2014).",1,new
"The most prevalent approach for topic modeling is Latent Dirichlet Allocation (LDA) (Blei et al., 2003; Blei and Lafferty, 2009; Hofmann, 1999).",1,new
Researchers such as (Kaufman and Rousseeuw 1990) and (Tibshirani 1996) have leveraged advanced statistical methods and data visualization techniques to uncover meaningful patterns and correlations in complex datasets.,1,new
Studies by (Kohavi et al. 1997) and (Golub et al. 1999) have utilized machine learning algorithms and data mining techniques to identify novel relationships and insights in large-scale data collections.,1,new
The work of (Quinlan 1993) and (Breiman 2001) has demonstrated the effectiveness of decision trees and ensemble methods in extracting valuable information and making accurate predictions from large and complex data sets.,1,new
"The most commonly employed measure in this context is the vector space model (Salton and McGill, 1983; Deerwester et al., 1990; Wilbur, 1996; Pedersen et al., 1994).",1,new
"The most widely utilized technique in this field is the Latent Semantic Analysis (LSA) (Deerwester et al., 1990; Landauer and Dumais, 1997; Schtze, 1998; Humphreys et al., 1997).",1,new
"The most frequently cited method in the literature is the cosine similarity measure (Jiang and Conrath, 1997; Miller, 1995; Patwardhan and Pedersen, 2006; Turney, 2001).",1,new
"A variety of techniques can be employed for this task, such as the Jaccard similarity coefficient(Stuart and Ord, 1994), the Kulczynski similarity coefficient(Sneath and Sokal, 1973), the Rogers-Tanimoto coefficient(Sneath and Sokal, 1973), the Sokal-Michener coefficient(Sneath and Sokal, 1973), and the Otsuka coefficient(Yaglom and Bingham, 1971).",1,new
"Several approaches can be utilized for this purpose, including the Hamming distance measure(Hamming, 1950), the Levenshtein distance measure(Levenshtein, 1965), the edit distance measure(Hartley, 1994), the Jaro-Winkler distance measure(Jaro and Winkler, 1989), and the Q-gram distance measure(Faloutsos, 1994).",1,new
"For this type of analysis, researchers can rely on various measures such as the cosine similarity measure(Besag, 1974), the Pearson correlation coefficient(Pearson, 1895), the Spearman rank correlation coefficient(Spearman, 1904), the Kendall's tau coefficient(Kendall, 1938), and the Euclidean distance measure(Maxwell, 1873).",1,new
"According to Firth (1957), in the context of estimating language models, it is generally recommended to use a large training corpus to avoid underestimating the probability of rare events, as this can lead to biased results.",1,new
"As stated by Brown et al. (1992), it is common practice to discard negative log probabilities in speech recognition systems, as they are often associated with implausible or nonsensical interpretations.",1,new
"In line with the findings of Manning and Schtze (1999), it is standard procedure to normalize word frequencies by dividing by the total number of occurrences in the corpus, as this helps to reduce the effect of high-frequency words on the overall model.",1,new
"In contrast to the findings of Fraser and Provost (1987), who focused primarily on individual word associations, Brown (1991) highlights the importance of collocational relationships in language understanding.",1,new
"Unlike the narrow scope of research by Wilks and Stevenson (1978), which examined only a limited set of linguistic phenomena, Miller and Chomsky (1963) provided a comprehensive analysis of the role of collocations in linguistic theory.",1,new
"Differing from the view of Katz and Fodor (1963), who restricted their study to the syntactic properties of words, Sinclair (1991) emphasizes the significance of semantic collocations in shaping meaning in language.",1,new
"Our research employs advanced NLP techniques to extract key information and make it readily accessible online, enabling us to create a more comprehensive knowledge base than traditional frequency-based approaches Our methodology combines multiple layers of information to approximate text structure, leveraging automated methods that surpass labor-intensive, discourse-based approaches Moreover, our proposed training framework will also allow us to explore this productive infrastructure in ways that model human performance without relying on hand-crafted domain-specific rules of knowledge-based approaches Our ultimate goal is to make our information retrieval system scalable and portable by learning retrieval rules from easily extractable text features.",1,new
"By applying robust NLP technology, we can extract essential features from documents, providing a richer understanding of text structure and domain knowledge than traditional frequency-based approaches Our work aims to automate the process of feature extraction, enabling the creation of a more intelligent and dynamic information retrieval system, which can adapt to user and application needs in real-time The Java-based interface provides a user-friendly interface for customizing retrieval preferences and visualizing multiple views of retrieved information.",1,new
"Our approach to text analysis goes beyond traditional word frequency-based methods by utilizing advanced NLP techniques to extract meaningful features from text data Our research employs techniques such as term frequency-inverse document frequency (tf-idf) to identify significant words and phrases, and applies machine learning algorithms to automatically extract multi-word phrases with high accuracy, providing a more nuanced understanding of text structure and context Our ultimate goal is to create a system that can learn and adapt to new text features, making it a more effective and efficient tool for information retrieval and analysis.",1,new
"Our research has built upon the foundations laid by probabilistic context models (Koller & Sahami, 1997; Hofmann, 1999), which have been instrumental in refining our understanding of the relationship between word co-occurrences and their corresponding probabilities.",1,new
"The concept of latent semantic analysis (Deerwester et al., 1990) has been pivotal in advancing our comprehension of semantic relationships between words, allowing us to make more accurate predictions about the context in which they appear.",1,new
"This study draws heavily from the theoretical framework established by vector space models (Salton & McGill, 1983; Deerwester et al., 1990), which have enabled significant breakthroughs in the field of information retrieval and natural language processing.",1,new
"The use of Hidden Markov Models (Rabiner 1989; Jelinek 1997; Viterbi 1967) has been a cornerstone of speech recognition technology, offering a robust framework for sequence analysis.",1,new
"The incorporation of neural networks into natural language processing tasks (Rumelhart et al. 1986; LeCun et al. 1998; Bengio et al. 2003) has revolutionized the field, providing a powerful tool for complex pattern recognition.",1,new
"The application of probabilistic graphical models (Pearl 1988; Lauritzen 1996; Koller and Friedman 2009) has facilitated the development of sophisticated Bayesian inference algorithms, enabling researchers to tackle intricate data analysis problems.",1,new
"The concept of hierarchical clustering of semantic features is both intuitive and well-established, as discussed in (Kruskal & Wish, 1978).",1,new
"The idea of gradual integration of linguistic components is theoretically sound and has been extensively examined in (Harris, 1954).",1,new
"The notion of cumulative semantic analysis has been extensively explored in the literature, particularly in the work of (Fillmore, 1968), which provides a robust framework for understanding language complexity.",1,new
"The proposed model of (Smith et al., 2018) effectively addresses the data sparsity issue by incorporating a hierarchical structure, which enables efficient learning with a reduced number of parameters: p(w2|w1) = p(w2|h)p(h|c)p(c|c1) (2), resulting in improved performance on a range of NLP tasks.",1,new
"The use of a latent topic model, as described in (Lee et al., 2020), allows for the identification of underlying themes in the data, leading to more accurate predictions and a better understanding of the relationships between variables: p(w2|w1) = p(w2|t)p(t|c)p(c|c1) (3), ultimately enhancing the overall quality of the analysis.",1,new
"The methodology introduced by (Kim et al., 2015) employs a probabilistic approach to text classification, which effectively mitigates the problem of class imbalance by incorporating a weighted voting scheme: p(y|w) = [p(y|c) * p(c|w)], where y represents the predicted class and c denotes the corresponding category, resulting in improved accuracy and robustness.",1,new
"This research builds upon the foundation laid by earlier studies on machine learning of semantic roles, specifically the work of Gildea et al 2001, Chai and Chiang 1996, and Nakov et al 2006, as referenced in the background section.",1,new
"Our approach is deeply rooted in the theoretical frameworks proposed by Fillmore 1968, Fillmore 1970, and Gruber 1976, which have been instrumental in shaping the field of lexical semantics.",1,new
"The current study draws heavily from the methodology and insights provided by recent works on topic modeling, including Blei et al 2003, Hofmann 1999, and Papadimitriou et al 2002, as discussed in the methodology chapter.",1,new
"A recent study by Smyth (2002) introduced a novel approach to evaluating the quality of text classification models, which has been shown to yield promising results even with limited training data sizes.",1,new
"The work by Manning and Schtze (1999) on maximum likelihood estimation has been instrumental in developing robust statistical models for natural language processing tasks, demonstrating its effectiveness in a variety of applications.",1,new
"Another significant contribution to the field of text analysis is the development of the chi-squared test by Pearson (1900), which has been found to be a reliable and efficient method for detecting significant patterns in large datasets.",1,new
The use of Latent Semantic Analysis (Deerwester et al. 1990) and co-occurrence statistics (Krovetz 1993) has been instrumental in uncovering the underlying semantic relationships within text.,1,new
The incorporation of Probabilistic Latent Semantic Analysis (Hofmann 1999) and the technique of Latent Dirichlet Allocation (Blei et al. 2003) has greatly facilitated the analysis of high-dimensional text data.,1,new
The development of techniques such as Hidden Markov Models (Rabiner 1989) and Maximum Entropy Markov Models (Berger et al. 1995) has significantly improved the accuracy of sequential pattern recognition tasks.,1,new
The application of decision trees (Quinlan 1979; Breiman et al. 1984) and random forests (Breiman 2001) has been instrumental in improving the accuracy of predictive models.,1,new
The use of support vector machines (Vapnik 1995; Cortes and Vapnik 1995) and k-nearest neighbors (Cover and Hart 1967) has revolutionized the field of pattern recognition and classification.,1,new
The incorporation of hidden Markov models (Rabiner 1989; Juang and Rabiner 1991) and Gaussian mixture models (McLachlan 1992) has greatly enhanced the performance of speech recognition systems.,1,new
"Although the novel algorithm () outperforms existing methods in detecting patterns, its susceptibility to noise in the dataset is a significant drawback (Witten and Frank 2005).",1,new
"The () technique exhibits impressive gains in terms of accuracy, yet its reliance on prior knowledge of the domain hinders its applicability to novel domains (Sutton and Barto 2018).",1,new
"While the () method demonstrates enhanced sensitivity to subtle relationships, its computational overhead limits its feasibility for large-scale applications (Blei et al. 2003).",1,new
"The findings of this study are in line with the conclusions of Anderson (2001), who proposed a novel approach to data analysis that outperformed traditional methods in several aspects.",1,new
"The results of our experiment support the notion of Smith et al. (2015), who demonstrated the efficacy of their new algorithm in achieving higher accuracy rates compared to existing solutions.",1,new
"Our study's results are consistent with the findings of Johnson (1999), who advocated for the use of a more sophisticated statistical model, which led to significant improvements in prediction accuracy.",1,new
"Another widely accepted metric in the field is the Perplexity score, which has been extensively utilized in various studies (Bishop, 1999).",1,new
"The F-score has been widely regarded as a reliable measure of classification accuracy, having been employed in numerous research endeavors (Powers, 2011).",1,new
"A commonly employed goodness-of-fit measure is the Chi-Squared statistic, which has been instrumental in assessing the fit of various models (Snedecor & Cochran, 1967).",1,new
"This result is consistent with the observations of Church and Hanks (1999), who demonstrated that the frequency ratio is a more reliable measure than the mutual information for small sample sizes.",1,new
"These findings align with the conclusions of Manning and Schtze (1999), who found that the log-likelihood ratio is a more robust metric than pointwise mutual information for evaluating word co-occurrences.",1,new
"The current results also corroborate the assertions of Manning (1999), which showed that the log-likelihood ratio is less affected by low counts compared to the pointwise mutual information measure.",1,new
"The authors recommend the use of the Kullback-Leibler divergence as a suitable measure for evaluating the similarity between corpora (Kullback & Leibler, 1951).",1,new
"The chi-squared statistic has been widely adopted in the field due to its effectiveness in distinguishing between different types of data distributions (Bowker, 1946).",1,new
"The use of mutual information has been advocated for in the analysis of linguistic features, as it provides a robust method for capturing the relationships between variables (Cover & Thomas, 1991).",1,new
"Our findings are consistent with the notion put forth by Bennett (2000), who suggested that the complexity of rare events often leads to underestimation in statistical models.",1,new
"In line with the observations of Goodman (1980), we also found that the occurrence of rare instances tends to be overestimated in many linguistic analysis models.",1,new
"This study supports the idea proposed by Manning and Schtze (1999), where the authors noted that the frequency of uncommon patterns can be misjudged due to the limitations of probabilistic modeling techniques.",1,new
"Our study utilized the following table to list the enumerated feature pairs:  Feature x,y Feature x,y AM1+1 c1, c0 AM2+1 c2, c0 AM1+2 c1, c0c1 AM2+2 c2, c0c1 AM1+3 c1, c0c1c2 AM3+1 c3c2c1, c0 We chose the Kruskal-Wallis test (Kruskal & Wallis, 1952) for its ability to handle non-parametric data and its suitability for comparing the significance of rare and common events.",1,new
"The following table presents the enumerated segment pairs used in our analysis: Feature x,y Feature x,y AM1+1 c1, c0 AM2+1 c2, c0 AM1+2 c1, c0c1 AM2+2 c2, c0c1 AM1+3 c1, c0c1c2 AM3+1 c3c2c1, c0 We selected the Wilcoxon rank-sum test (Wilcoxon, 1945) for its non-parametric nature and its effectiveness in comparing the occurrences of rare and common phenomena.",1,new
"The enumerated feature pairs were organized in the following table: Feature x,y Feature x,y AM1+1 c1, c0 AM2+1 c2, c0 AM1+2 c1, c0c1 AM2+2 c2, c0c1 AM1+3 c1, c0c1c2 AM3+1 c3c2c1, c0 We employed the Mann-Whitney U test (Mann & Whitney, 1947) due to its ability to handle non-normal data and its suitability for comparing the significance of rare and common events in our study.",1,new
"In controlled experiments outlined in prior research (Brown et al. 2000), it was observed that the use of the log-likelihood ratio test proposed by Goodman (1972) consistently surpasses the chi-squared test in terms of accuracy.",1,new
Our previous studies (Kolmogorov 1933) demonstrate that the proposed algorithm for estimating the entropy of a probability distribution yields superior results when compared to the traditional method of maximum likelihood estimation.,1,new
"In a series of computational simulations conducted by us (Laplace 1812), the results indicate that the Gini coefficient suggested by Gini (1914) provides a more precise measure of income inequality than other established indices.",1,new
Our analysis builds upon the work of Manning and Schtze (1999) in employing the widely used Maximum Likelihood Estimation (MLE) technique.,1,new
"In accordance with previous studies by Church and Hanks (1990), we utilize the part-of-speech tagging approach, which has been proven to be effective in various linguistic tasks.",1,new
"Following the methodology of Jurafsky and Martin (2000), we incorporate the concept of n-grams to capture the sequential relationships between words in our corpus.",1,new
"The receiver operating characteristic (ROC) curve is widely used due to its ability to provide a comprehensive overview of classification model performance, as demonstrated by Fawcett (2006).",1,new
"The mean absolute error (MAE) is a popular evaluation metric for regression tasks, offering a straightforward and intuitive measure of model accuracy, as shown by Wilms and De Neve (2004).",1,new
"The precision-recall curve is often employed in information retrieval tasks due to its effectiveness in assessing the balance between precision and recall, as highlighted by Davis and Goadrich (2006).",1,new
"To further improve the accuracy of our word alignment model, we only consider translation pairs with a confidence score above a certain threshold 3  or whose frequency of co-occurrence is above a specific threshold 4 . Furthermore, when training the model on a smaller dataset, we utilize a different filtering mechanism for the dictionary. We rely on mutual information to evaluate the strength of association between translation pairs, as Church and Hanks (1990) demonstrated that mutual information is effective for analyzing relationships in limited data.",1,new
"By incorporating a noise reduction strategy, we refine the alignment results by retaining only translation pairs with a probability above a certain threshold 5  or whose co-occurrence frequency exceeds a predetermined threshold 6 . In addition, when working with a limited parallel corpus, we construct a new dictionary using the same approach as the original. However, for the dictionary, we employ a different filtering criterion based on the pointwise mutual information, which, according to Brown et al. (1992), is suitable for small datasets.",1,new
"To mitigate the impact of noisy alignments, we restrict our analysis to translation pairs with a probability greater than a specified threshold 7  or whose co-occurrence counts exceed a certain threshold 8 . Moreover, when training the model on a smaller bilingual corpus, we create a new dictionary using the same method as the original. In contrast, for the dictionary, we use a filtering strategy based on the likelihood ratio, which, as Dunning (1993) showed, is effective for small-scale data analysis.",1,new
"The use of mutual information has proven to be a reliable approach to discovering semantic relationships in large corpora, particularly when the co-occurrence frequency is scarce (Church & Hanks, 1990).",1,new
"Furthermore, the application of chi-squared tests has been found to be a more efficient method for detecting statistically significant associations in text data, especially when the sample size is limited (Ludovici, 2015).",1,new
"In addition, the use of pointwise mutual information has been recognized as a robust technique for uncovering collocations in corpora with low frequency words, thereby providing valuable insights into linguistic structures (Church et al., 1994).",1,new
"We found the harmonic mean to be a more suitable metric for evaluating model performance compared to the geometric mean (Harter, 1961) or the arithmetic mean (Stirling, 1890), as it provides a better representation of the overall model efficiency and is less affected by extreme values (Bickel and Doksum, 1977).",1,new
"In comparison to other machine learning algorithms, we preferred the decision tree method, due to its ability to handle non-linear relationships (Breiman, 2001) and its relatively low computational cost (Quinlan, 1986), making it a suitable choice for large datasets (Hastie et al., 2009).",1,new
"The use of the chi-squared statistic was favored over the Fisher exact test (Fisher, 1922) or the G-test (Hoeffding, 1948), as it is more robust to outliers (Fisher, 1956) and provides a more accurate estimate of the association between variables (Cressie and Read, 1984).",1,new
"Our approach relied heavily on the foundations laid by various researchers, including those who employed machine learning algorithms (Mitchell, 1997), linguistic patterns (Kittredge, 2008), or probabilistic frameworks (Jelinek, 1976).",1,new
"The development of our model drew upon a wide range of statistical techniques, including regression analysis (Dawid, 1979), time-series forecasting (Box, 1976), and information-theoretic methods (Shannon, 1948).",1,new
"The theoretical underpinnings of our research were grounded in the work of earlier scholars who utilized stochastic processes (Feller, 1968), game theory (von Neumann & Morgenstern, 1944), or decision-making models (Savage, 1954).",1,new
"Our results show that the use of the Mutual Information statistic, as introduced by Cover and Thomas (1991), significantly improves the accuracy of word association tasks.",1,new
"The performance of the Hidden Markov Model, as evaluated by Rabiner (1989), outperforms traditional n-gram models in predicting text sequences.",1,new
"According to the findings of Manning and Schtze (1999), the use of the Maximum Likelihood Estimation method leads to a substantial increase in the effectiveness of language modeling techniques.",1,new
"The proposed algorithm's efficacy in identifying latent patterns was further demonstrated through the utilization of the Chi-squared statistic as developed by (Yates, 1934), which provided a significant improvement in model accuracy.",1,new
"The incorporation of the Mutual Information measure by (Cover & Thomas, 2012) allowed for a more nuanced understanding of the underlying relationships within the dataset, leading to enhanced predictive capabilities.",1,new
"The utilization of the Jaccard similarity coefficient as described by (Jaccard, 1908) facilitated the identification of clusters with distinct characteristics, thereby shedding light on the complex structure of the corpus.",1,new
"The novel approach to data analysis utilized in this study has been validated through the implementation of the F1-score metric (Kohavi, 1995), which has been widely recognized for its effectiveness in evaluating classification models (Chicco, 2017).",1,new
"The reliability of the proposed methodology has been assessed using the mean absolute error (MAE) statistic (Makridakis, 2000), a widely accepted measure of predictive accuracy that has been employed in numerous previous studies (Hyndman, 2006).",1,new
"In the current research, the correlation coefficient analysis has been performed using the Pearson correlation coefficient (Pearson, 1895), a well-established statistical measure that has been shown to provide robust results in various applications (Spearman, 1904).",1,new
"The application of the EM algorithm has been demonstrated to be efficient for parameter estimation in probabilistic models (McLachlan & Krishnan, 2007).",1,new
"The use of the Bayes' factor has been shown to provide a reliable method for model selection in Bayesian inference (Kass & Raftery, 1995).",1,new
"The incorporation of the Dirichlet prior has been found to improve the performance of clustering algorithms in high-dimensional data (Antoniak, 1972).",1,new
"The use of machine learning algorithms has been extensively validated in various research contexts (Bishop, 1995).",1,new
"Our findings are consistent with previous research on the effectiveness of this approach, as noted by other scholars (Kullback, 1959).",1,new
"Studies have consistently demonstrated the utility of this statistical method in analyzing large datasets (Good, 1953).",1,new
"The authors' proposed algorithm yields a statistically significant correlation with expert opinions on the quality of machine translations (Koehn, 2004), albeit with slight variations in results when compared to other evaluation metrics (e.g., Chen & Meyer, 2013).",1,new
"The current study's findings align with previous research suggesting that the modified clustering algorithm outperforms traditional methods in identifying relevant gene interactions (Lu et al., 2017), albeit with some discrepancies in specific cases (e.g., Hu et al., 2015).",1,new
"It can be inferred that the novel machine learning approach produces a reliable ranking of protein structures that closely aligns with experimental data (Berman et al., 2000), although alternative methods, such as those proposed by (Xu et al., 2019), exhibit comparable performance in certain contexts.",1,new
"The studies by (Hastie et al., 2009) and (James et al., 2013) demonstrate the effectiveness of employing ensemble methods for improving the predictive accuracy of rare event detection models, leading to a better understanding of these complex phenomena.",1,new
"According to (Kullback & Leibler, 1951) and (Cover & Thomas, 1991), certain statistical measures used in information theory, such as Kullback-Leibler divergence, can be successfully applied to quantify the rarity of events, providing valuable insights into their underlying characteristics.",1,new
"(Manning & Schtze, 1999) and (Church & Gale, 1991) propose novel approaches for assessing the rarity of words in large corpora, highlighting the significance of these measures in natural language processing applications, particularly in text analysis and modeling.",1,new
"The development of the Sentiment Analysis Tool (SAT) was influenced by the work of Liu and Zhang (1992), but also built upon the foundation laid by Collobert et al. (2011) by incorporating advanced techniques such as word embeddings and sentiment lexicons, as well as shallow parsing of input data to enhance accuracy.",1,new
"The work of the Natural Language Processing (NLP) Toolkit (NLP-TK) was significantly improved upon by incorporating various machine learning algorithms, such as Support Vector Machines (SVMs) and Random Forests, as described by Dietterich (2000) and Breiman (2001), to enhance its capability in sentiment analysis and text classification tasks.",1,new
"The Text Mining Tool (TMT) leveraged the contributions of earlier researchers, including Brown et al. (1992) and Manning and Schtze (1999), by integrating techniques such as named entity recognition and part-of-speech tagging to improve its performance in extracting relevant information from large datasets.",1,new
"The pioneering work by Church et al. (1991) on part-of-speech tagging employs a probabilistic approach, utilizing a combination of rule-based and machine learning techniques to achieve high accuracy rates, thereby setting a benchmark for future research in the field.",1,new
"The seminal study by Manning and Schtze (1999) on information retrieval models introduces a novel approach to ranking search results based on relevance and novelty, which has significantly influenced the development of modern search engines and information retrieval systems.",1,new
"The groundbreaking paper by Brown et al. (1990) on statistical language modeling presents a comprehensive framework for predicting the probability of word sequences in a language, which has had a lasting impact on natural language processing and machine translation techniques.",1,new
"In recent years, significant contributions to the field of sentence parsing have been made, with notable studies including those by Marcus (1980), Bresnan (1982), and Gazdar et al. (1985).",1,new
"The past decade has seen substantial progress in the development of machine learning algorithms, with notable research published by Mitchell (1997), Dietterich (2000), and Valiant (2002).",1,new
"Over the past two decades, important research on natural language generation has been conducted, with key contributions from Elman (1990), Langley and Pylyshyn (1989), and Dale (1992).",1,new
"The study by Brown (1990) makes significant contributions to evaluating the accuracy of a named entity recognition system, but falls short in assessing the system's ability to generalize to new, unseen data.",1,new
"A notable analysis by Lee et al. (2001) provides an in-depth examination of the strengths of a machine translation system, but fails to address the potential limitations of the system's output in real-world applications.",1,new
"While the research by Kim (2015) is a valuable addition to the field of speech recognition, it does not fully explore the system's capacity to handle out-of-vocabulary words, a crucial aspect of real-world speech.",1,new
"For the task of sentiment analysis, several techniques have been developed in recent years, which have shown promising results (Turney 2002; Wiebe and Mihalcea 2006; Nakagawa and Matsumoto 2002; Read and Carroll 2002; Liu and Zhang 2005; Hatzivassiloglou and McKeown 1997; VADER 2017).",1,new
"In the field of named entity recognition, various approaches have been proposed, demonstrating significant advancements (Bikel et al. 1999; Ratinov and Singer 2003; Finkel and Manning 2009; Ramshaw and Marcus 1995; Gildea and Jurafsky 1998; Ratnaparkhi 1996; Sutton and McCallum 2012).",1,new
"For the problem of topic modeling, numerous methods have been developed, yielding valuable insights (Hofmann 1999; Blei et al. 2003; Griffiths and Steyvers 2004; Newman et al. 2006; Blei and Jordan 2003; Wang and McCallum 2006; Papadopoulos et al. 2012).",1,new
"Various effective methods have been developed to identify and extract semantic units, phrasal verbs, and collocations from large corpora (Kilgarriff and Palmer, 2000; Pedersen et al., 2004; Evert, 2009).",1,new
"A range of efficient techniques have been proposed for the extraction and analysis of lexical bundles, n-grams, and semantic frames (Biber et al., 1999; Stubbs, 2001; Gries, 2013).",1,new
"Numerous approaches have been successfully employed to identify and process idiomatic expressions, fixed phrases, and grammaticalized collocations (Sinclair, 1991; Halliday, 2004; Gries and Stefanowitsch, 2004).",1,new
"The application of machine learning algorithms in natural language processing has led to significant advancements in sentiment analysis (Turney 2002, Kim and Hovy 1997, Read 2005, Wiebe 2000).",1,new
"The development of corpus linguistics has provided valuable tools for the analysis of grammatical structures (Sinclair 1991, Biber 1988, Quirk et al. 1985, Halliday 1985).",1,new
"Research in computational linguistics has contributed substantially to the improvement of language modeling techniques (Brown et al. 1990, Manning and Schtze 1999, Jurafsky and Martin 2000, Rabiner 1989).",1,new
"The IBM 1~5 models (Brown et al., 1993) have been a cornerstone in statistical machine translation, serving as a foundation for numerous language processing applications and algorithms.",1,new
"The IBM 1~5 models proposed by Brown et al. (1993) have undergone significant revisions and refinements, demonstrating their enduring impact on the field of statistical machine translation.",1,new
"Building upon the work of Brown et al. (1993), the IBM 1~5 models have been successfully adapted and applied to various language translation tasks, solidifying their position as a fundamental component of statistical machine translation systems.",1,new
"Another effective approach to tackling machine translation challenges relies on the use of parallel corpora consisting of sentence pairs with their corresponding translations (Klein et al., 2009; Callison-Burch et al., 2006; Koehn et al., 2007).",1,new
"Recent studies have shown that utilizing aligned bilingual corpora for query translation tasks can lead to significant improvements in translation accuracy (Brown et al., 1993; Melamed et al., 2001; Resnik et al., 1999).",1,new
"Corpus-based query translation methods that leverage large collections of aligned sentence pairs have demonstrated promising results, particularly in the context of statistical machine translation (Dagan et al., 1993; Gale et al., 1993; Knight et al., 1997).",1,new
"The proposed method leverages the strengths of both the statistical machine translation models SMT-1 to SMT-5 (Koehn et al., 2003) and the phrase-based alignment model (Och et al., 2003), enabling the generation of accurate alignments.",1,new
"By utilizing the syntax-based machine translation models SBMT-1 to SBMT-5 (Melamed et al., 2003) and the decision-tree alignment model (Melamed et al., 2001), we achieve high-quality alignments of translated sentences.",1,new
"Employing the hybrid machine translation models HMT-1 to HMT-5 (Gupta et al., 2006) and the word-based alignment model (Brown et al., 1990), our method produces reliable alignments that improve the accuracy of the translation process.",1,new
"7 Previous Research The state-of-the-art neural machine translation models are discussed in (Sutskever et al., 2014).",1,new
"5 Background Research The widely used sequence-to-sequence models for machine translation are reviewed in (Bahdanau et al., 2015).",1,new
"9 Prior Work The influential statistical machine translation models are presented in (Vaswani et al., 2017).",1,new
"The detailed methodology and results of the influential statistical machine translation models IBM-6 to IBM-8 (Brown et al., 1993) and the Hierarchical Hidden Markov Model (HHMM) (Vogel et al., 1996) are thoroughly explained in (Och and Ney, 2003).",1,new
"A comprehensive overview of the well-established neural machine translation models IBM-9 to IBM-12 (Brown et al., 1993) and the Recurrent Neural Network (RNN) (Vogel et al., 1996) can be found in (Och and Ney, 2003).",1,new
"In-depth discussions on the seminal statistical machine translation models IBM-1 to IBM-4 (Brown et al., 1993) and the Maximum Entropy Model (MEM) (Vogel et al., 1996) are presented in (Och and Ney, 2003).",1,new
"Our analysis utilized the state-of-the-art language models, including the LSTM networks (Hochreiter & Schmidhuber, 1997) and the gated recurrent units (Cho et al., 2014), to obtain highly accurate results.",1,new
"Employing the Word2Vec model (Mikolov et al., 2013) and the GloVe algorithm (Pennington et al., 2014), we successfully generated a robust and informative semantic representation of the data.",1,new
"By leveraging the transformer architecture (Vaswani et al., 2017) and the bidirectional long short-term memory (Bi-LSTM) networks (Graves et al., 2005), we were able to achieve significant improvements in the model's performance and interpretability.",1,new
"The comprehensive overview of the statistical machine translation models IBM-6 to IBM-8 (Brown et al., 1993) and the decision tree statistical alignment model (Vauquois, 1978) can be found in (Brown et al., 1993; Och and Ney, 2003).",1,new
"A detailed explanation of the popular word-based translation models IBM-1 to IBM-5 (Brown et al., 1993) as well as the hidden Markov alignment model (HMM) (Vogel et al., 1996) is provided in (Brown et al., 1993; Vauquois, 1978).",1,new
"A thorough description of the IBM model family (Brown et al., 1993) and the Hidden Markov Model (HMM) (Vogel et al., 1996) can be found in the seminal work of (Och and Ney, 2003), which serves as a foundation for modern machine translation systems.",1,new
"The state-of-the-art neural machine translation systems are discussed in (Sutskever et al., 2014) and the application of attention mechanisms is detailed in (Bahdanau et al., 2015).",1,new
"The current approaches to deep learning-based natural language processing are reviewed in (Goodfellow et al., 2016) and the use of recurrent neural networks is explored in (Graves et al., 2013).",1,new
"The advancements in speech recognition technology are presented in (Hinton et al., 2012) and the development of convolutional neural networks is described in (LeCun et al., 1998).",1,new
The innovative approach to data analysis proved to be highly effective in identifying patterns of behavior (Johnson et al. 2001).,1,new
A novel method of materials synthesis resulted in the creation of high-quality nanomaterials with unique properties (Lee et al. 2015).,1,new
The incorporation of artificial intelligence in the research process led to significant improvements in data processing and accuracy (Kim et al. 2018).,1,new
"The implementation of these algorithms has been successfully applied to various sequence-to-sequence models, including those based on the neural network architecture proposed by Sutskever et al. (2014) and the encoder-decoder model introduced by Cho et al. (2014).",1,new
"Our results demonstrate the effectiveness of this approach in conjunction with other optimization techniques, such as the ones described by Bottou and Bousquet (2008) and the gradient-based methods developed by Bottou (2010).",1,new
"This framework can be efficiently integrated with existing machine learning libraries, as shown in the work of Kingma and Welling (2014) and the implementation of the Adam optimizer by Kingma and Ba (2014).",1,new
"Compared with well-established datasets like the Penn Treebank (Marcus et al. 1993), which comprises 40 million words of parsed American English text, the web corpus exhibits a higher degree of variability and linguistic heterogeneity.",1,new
"In contrast to the carefully curated texts of the Brown Corpus (Kuera and Francis 1967), which consists of 500,000 words of edited American English, the web-based corpus showcases a richer diversity of linguistic features and nuances.",1,new
"Relative to the highly controlled and standardized language of the LOB Corpus (Johansson et al. 1978), which comprises 1 million words of edited British English, the web corpus reveals a more dynamic and adaptive language use, reflecting the complexities of real-world communication.",1,new
"This study introduces two novel approaches to augmenting existing semantic role labeling frameworks: a probabilistic lexicon model that leverages contextual information to improve part-of-speech tagging accuracy and a dependency-based model that extends the seminal work of (Chen et al., 2017) by incorporating nuanced relationships between words.",1,new
"We propose a pair of techniques to enhance the robustness of sentiment analysis systems: a graph-based lexicon that utilizes network properties to predict emotional tone and a feature-rich model that builds upon the foundation laid by (Johnson et al., 2015) by incorporating domain-specific knowledge and syntactic features.",1,new
"In this paper, we present two innovative methods for improving named entity recognition: a rule-based lexicon that exploits linguistic patterns to identify entities and a machine learning-based model that extends the work of (Kim et al., 2018) by incorporating a hierarchical structure to capture complex relationships between entities.",1,new
"The seminal study by Melamed (2001) on statistical machine translation introduced the concept of bitexts, which have since become a fundamental component in many machine translation systems.",1,new
"In a groundbreaking paper, Och and Ney (2003) proposed the use of phrase-based models to improve the accuracy of statistical machine translation, a technique that has had a lasting impact on the field.",1,new
"The work of Koehn et al. (2007) on phrase-based SMT systems has been instrumental in advancing the state-of-the-art in machine translation, enabling more accurate and fluent translations.",1,new
The groundbreaking research by Chen et al. (2018) on NLP models effectively underscored the challenges we encounter as we transition from rule-based systems to deep learning architectures.,1,new
"A critical examination of the impact of linguistic features on sentiment analysis, conducted by Lee and Kim (2020), revealed the complications that arise when shifting from traditional machine learning approaches to more sophisticated neural network models.",1,new
"The comprehensive study by Smith et al. (2015) on language modeling highlighted the intricacies that emerge as we move from simple statistical models to more complex probabilistic frameworks, underscoring the need for innovative solutions to overcome these challenges.",1,new
"The development of our new algorithm was significantly informed by the seminal work of (Smith et al. 2001), which provided a foundational framework for our approach.",1,new
"The design of the novel device was heavily influenced by the pioneering research of (Johnson et al. 1985), whose groundbreaking discoveries paved the way for our innovations.",1,new
"The incorporation of machine learning techniques in our system was heavily influenced by the influential paper (Williams et al. 1998), which established a new paradigm for artificial intelligence applications.",1,new
"Although neural networks have shown promise in various applications, such as speech recognition (Dahl et al., 2012), they have struggled to excel in tasks like language modeling (Bengio et al., 2003) and text classification (Krizhevsky et al., 2012).",1,new
"Despite the success of deep learning methods in image classification (Krizhevsky et al., 2012), they have not demonstrated the same level of performance in areas like object detection (Sermanet et al., 2014) and image segmentation (Long et al., 2015).",1,new
"While recurrent neural networks have achieved impressive results in natural language processing tasks like language translation (Kalchbrenner et al., 2013), they have not been as effective in areas like sentiment analysis (Pang and Lee, 2008) and topic modeling (Blei et al., 2003).",1,new
"The proposed neural network architecture (LeCun et al., 1989) demonstrates a significant improvement in image classification tasks with its sophisticated layering approach.",1,new
The results from the study by Mikolov et al. (2010) indicate a substantial enhancement in language model accuracy using the novel subsampling technique.,1,new
The findings of the research by Kim et al. (2014) show a notable advancement in natural language processing with the incorporation of the attention-based model.,1,new
"The proposed neural network architecture demonstrated exceptional results in sentiment analysis, particularly when applied to English and Spanish language pairs (Pang et al., 2002; Bostrom, 2010).",1,new
"The recent study on language modeling revealed impressive outcomes in text summarization tasks, particularly for languages like Arabic and Russian (Manning et al., 1999; Solorio, 2008).",1,new
"The new approach to machine learning has shown remarkable performance in named entity recognition, especially for languages such as Chinese and Japanese, as demonstrated by Li et al. (2015) and Nakov et al. (2017).",1,new
"This is a widely used approach in natural language processing for which the transformer models have gained significant recognition (Vaswani et al., 2017).",1,new
"This technique has been a cornerstone in computer-assisted translation for which the neural machine translation models have proven to be highly effective (Kalchbrenner et al., 2013).",1,new
"It is a fundamental method in language translation for which the statistical machine translation models have been extensively employed (Koehn et al., 2007).",1,new
"A particularly influential model in the field of natural language processing is the HMM model (Jelinek & Mercer, 1980).",1,new
The stochastic grammar approach developed by Chomsky (1957) has been a cornerstone in linguistics for several decades.,1,new
The Hidden Markov Model (HMM) proposed by Rabiner (1989) has been a fundamental tool in speech recognition systems.,1,new
"The concept of machine learning has been extensively explored since its introduction by (Dempster et al., 1972), with significant advancements made by various researchers (Kohavi et al., 1997; Vapnik, 1995).",1,new
"The idea of deep neural networks was first proposed by (Lippmann, 1987) and has since been thoroughly investigated by numerous research teams (Bengio et al., 2003; Hinton et al., 2006).",1,new
"The concept of natural language processing has been studied for decades, with early work by (Chomsky, 1957) and more recent contributions from (Jurafsky and Martin, 2000; Manning and Schtze, 1999).",1,new
The field of speech recognition has undergone significant advancements since the introduction of the hidden Markov model by Baum (1972) and the development of the dynamic time warping algorithm by Sakoe and Chiba (1978).,1,new
"Notably, the emergence of deep learning techniques has also contributed to the progress in speech recognition, building upon the foundation laid by pioneers such as Davis and Mermelstein (1980) and Itakura (1975).",1,new
"Since the introduction of the cepstral analysis by Itakura and Sambur (1975) and the application of the discrete cosine transform by Atal (1974), the field of speech processing has continued to evolve and improve.",1,new
"Our results demonstrate that employing the combination of source-to-target and target-to-source word embeddings (as proposed by Mikolov et al. [2013]) yields superior performance in our experiment, as detailed in Section 3.1.1.",1,new
"In agreement with previous research (Liu and Zhang [2018]), our analysis indicates that utilizing the intersection of source and target word alignments (Manning et al. [1999]) significantly improves the accuracy of semantic parsing, as shown in our experimental results in Section 5.3.",1,new
"Following the methodology suggested by Goldberg and Elhadad [2005], we found that the integration of source and target side contextual information (as discussed in Section 2.2) leads to improved performance in machine translation, as reported in our experimental evaluation in Section 6.2.",1,new
The incorporation of subword modeling (Sennrich et al. 2016) has significantly enhanced the efficiency of neural machine translation systems.,1,new
The utilization of attention mechanisms (Vaswani et al. 2017) has been instrumental in improving the performance of deep learning-based translation models.,1,new
The development of pre-training techniques (Devlin et al. 2019) has greatly facilitated the adaptation of large language models for machine translation tasks.,1,new
"2 Background Information Recent studies have shown that deep learning approaches (LeCun et al., 1989) outperform traditional methods in many machine learning applications when large-scale datasets are utilized.",1,new
"3 Methodology The use of pre-trained word embeddings (Mikolov et al., 2013) has been proven to significantly improve the performance of natural language processing tasks when sufficient training data is available.",1,new
"4 Conclusion The implementation of convolutional neural networks (LeCun et al., 1998) has led to notable advancements in image classification when ample training data is provided.",1,new
"The novel approach to neural network architecture proposed by (Krizhevsky et al., 2012) was further developed and refined in the subsequent work by (Sermanet et al., 2014).",1,new
"The groundbreaking paper by (LeCun et al., 1989) laid the foundation for the development of convolutional neural networks, which were later improved upon by the innovative techniques presented in (Long et al., 2015).",1,new
"The influential study by (Kolmogorov, 1933) introduced a fundamental concept in probability theory, building upon which (Khinchin, 1949) expanded the understanding of random processes in his seminal work.",1,new
"Our work draws inspiration from the successes of various machine learning techniques, such as image classification (Krizhevsky et al., 2012), object detection (Girshick et al., 2014), and natural language processing (Collobert et al., 2011), which have achieved remarkable results in their respective domains, motivating the development of a novel deep learning approach for facial recognition.",1,new
"Building upon the foundations established by pioneering research in natural language understanding (Levin, 1993), discourse analysis (Halliday, 1978), and text analysis (Sidorov et al., 2015), we propose a novel framework for sentiment analysis that combines the strengths of multiple models to achieve improved performance and robustness.",1,new
"The development of our new algorithm for document clustering is motivated by the success of previous studies in information retrieval (Sullivan and Raggett, 1997), topic modeling (Blei et al., 2003), and network analysis (Newman, 2006). These studies have shown the importance of effective clustering techniques in various applications, and our work aims to contribute to this area by introducing a novel method for document clustering based on graph theory.",1,new
"The proposed approach to machine translation, based on the concept of P(F|S), has shown promising results for closely related languages such as Spanish-English and Portuguese-English (Koehn, 2004). However, its effectiveness in more distant language pairs, such as Chinese-English, remains to be seen.",1,new
"The probabilistic framework of P(H|I) has been successfully applied to various machine learning tasks, including natural language processing and speech recognition (Jelinek, 1997). Its versatility in handling different types of input data makes it a valuable tool for researchers and practitioners alike.",1,new
"The statistical model P(G|L) has been effectively employed in the field of natural language translation, particularly for languages with similar grammatical structures, such as English-Dutch and English-French (Melamed, 2001). Further research is needed to explore its potential in more complex language pairs, such as English-Arabic.",1,new
"The proposed framework utilizes the Variational Autoencoder (VAE) reformulation to approximate a21 a0a15a14a39a13 a21 a0a2a1a38a33a14a19a13, where a21 a0a15a14a39a13 serves as the feature extractor, and a21 a0a2a1a38a33a14a19a13 is the generative model; the well-established Gaussian Mixture Model (GMM) (Everitt et al., 2011) serves as the benchmark.",1,new
"Within the proposed framework, the Deep Q-Network (DQN) reformulation is employed to estimate a32 a0a15a14a35a33a1a26a13a37a36 a32 a0a15a14a19a13 a32 a0a2a1a38a33a14a39a13, where a32 a0a15a14a39a13 is considered the action-value function approximator, and a32 a0a2a1a38a33a14a19a13 is the policy network; the established Q-learning algorithm (Watkins, 1989) being the reference point.",1,new
"The novel approach relies on the Conditional Random Field (CRF) reformulation to predict a33 a0a15a14a39a13 a33 a0a2a1a38a33a14a19a13, where a33 a0a15a14a39a13 is the discriminative model, and a33 a0a2a1a38a33a14a19a13 is the generative model; the widely-used Hidden Markov Model (HMM) (Rabiner, 1989) serving as the baseline.",1,new
"The proposed IBM Model 2 (Brown et al., 1993b) has been effectively employed in statistical machine translation to enhance the accuracy of output.",1,new
"The widely utilized IBM Model 4 (Brown et al., 1993a) has been instrumental in developing robust wordalignment models for parallel corpora analysis.",1,new
"The seminal IBM Model 1 (Brown et al., 1993a) has significantly contributed to the advancement of statistical machine translation through its innovative wordalignment approach.",1,new
"The proposed approach of generating a higher-dimensional PMTG from a lower-dimensional PMTG and a word-to-punctuation model shares similarities with the way that probabilistic context-free grammars can be used to estimate stochastic context-free grammars (Jelinek, 1985), and the way that basic language models can facilitate the development of more complex ones (Katz, 1987).",1,new
"The use of a hybrid PMTG model that combines a lower-dimensional PMTG and a character-to-word model is analogous to the method of employing a finite state transducer to generate more complex transducers (Huang & Lee, 1991), and the way that simple speech recognition systems can be used to improve the performance of more sophisticated ones (Bahl et al., 1983).",1,new
"Developing a PMTG from a combination of a lower-dimensional PMTG and a word-to-phrase model is comparable to the technique of utilizing a finite state automaton to generate more complex automata (Rabin & Scott, 1959), and the way that basic machine translation systems can be used to bootstrap more advanced ones (Melamed, 2001).",1,new
"The development of shallow transfer models, such as those proposed by (Wu, 1997) and their variants, has shown great promise in achieving accurate phrase-level alignments, particularly for languages with similar grammatical structures and minimal lexical differences.",1,new
"Recent studies have demonstrated the efficacy of simplified dependency-based alignment models (Mikolov et al., 2010) in generating high-quality word alignments, especially for closely related languages with consistent word order and limited reordering patterns.",1,new
"The application of lightweight machine learning models, such as those described in (Collins, 2002), has led to significant improvements in word-level alignment accuracy, particularly for languages with similar morphology and syntax, which can be effectively captured by simple models of word substitution.",1,new
"Our understanding of protein structure has been significantly enhanced by the pioneering work of (Rossmann & Blow, 1990), who applied crystallographic techniques to elucidate the molecular mechanisms of enzyme function.",1,new
"The development of machine learning algorithms, as described by (Mitchell, 1997), has revolutionized the field of natural language processing, enabling more accurate language models and improved translation results.",1,new
"The groundbreaking study by (Bateson, 1972) on the neural basis of animal behavior has provided valuable insights into the underlying mechanisms of cognitive processes, shedding light on the complexities of animal intelligence.",1,new
"The current approaches to sentiment analysis can be broadly categorized into two main categories: rule-based systems, which have been extensively studied by Krippendorff (2004), and machine learning algorithms, as demonstrated by Joachims (1999) and Ng et al. (2002).",1,new
"Researchers have identified two primary frameworks for analyzing linguistic complexity: the cognitive approach, which has been extensively explored by Levelt (1989), and the statistical approach, which has been applied by Feldman and Ruvolo (1998) and others.",1,new
"There are fundamentally two types of models used in natural language processing: the knowledge-based systems, which have been investigated by Gruber (1993), and the connectionist models, as shown by Rumelhart and McClelland (1986) and Schmidhuber (1992).",1,new
"Our results demonstrate that a hybrid approach combining a neural machine translation system with the principles of Discourse Analysis (Halliday, 1978) can significantly enhance the quality of written content for language learners.",1,new
"This study demonstrates the effectiveness of leveraging a cognitive linguistics framework (Lakoff, 1970) within the context of Natural Language Processing (NLP) to improve the clarity and coherence of text generated by non-experts.",1,new
"By integrating a syntax-based parser (Chomsky, 1957) into a predictive text system, we were able to improve the grammatical accuracy and readability of text produced by novice writers, leading to a more engaging and effective writing experience.",1,new
"The widely used approach to phrase-based machine translation IBM model 3 (Brown et al., 1992) relies on a combination of unsupervised training and iterative re-estimation techniques (Koehn et al., 2003) yet often results in suboptimal sentence alignments.",1,new
"The prevailing method for statistical machine translation IBM model 5 (Brown et al., 1993) involves a two-stage process of unsupervised training and symmetrization (Och and Ney, 2003), which, despite its popularity, tends to produce low-quality phrase tables.",1,new
"The conventional approach to statistical machine translation IBM model 1 (Brown et al., 1990) relies on a hybrid of unsupervised training and rule-based post-processing (Vogel et al., 2005) but often falls short of achieving accurate word-level alignments.",1,new
"Utilizing the approach proposed by Manning (1999) and Vidal (2006), the task of phrase-based machine translation may benefit from the availability of pre-aligned tokens in the parallel sentence pairs, thus reducing the complexity of the task.",1,new
"In the context of machine translation, the exploitation of pre-aligned tokens in parallel sentences, as suggested by Brown et al. (1993) and Chiang (2007), can lead to more accurate and efficient translation models.",1,new
"The utilization of pre-aligned tokens in parallel sentences, as demonstrated by Hutchins and Somers (1992) and Koehn (2004), can simplify the task of machine translation and potentially improve its overall performance.",1,new
"The development of these techniques has significantly contributed to advancements in natural language processing, particularly in the realm of sentiment analysis, which relies heavily on pre-trained language models (Socher et al., 2013).",1,new
"The use of these methodologies has been instrumental in driving progress in speech recognition, which heavily relies on unsupervised acoustic modeling and feature extraction (Davis & Mermelstein, 1980).",1,new
"These methods have also been pivotal in the growth of text summarization, which depends on the ability to effectively identify key information and relationships in large documents (Hearst, 1997).",1,new
"Our analysis utilizes the widely accepted methods for sentiment analysis, drawing upon the pioneering work of Polanyi and Zaenen (1989) and their implementation in the popular Natural Language Toolkit (NLTK) software (Loper and Bird, 2002).",1,new
"In this study, we leverage the established techniques for topic modeling, building upon the foundational work of Hofmann (1999) and utilizing the efficient implementation in the MALLET library (McCallum, 2002).",1,new
"The proposed algorithm employs the established methodology for named entity recognition, relying on the seminal work of Bikel et al. (1997) and the widely used Stanford CoreNLP library (Manning et al., 2014).",1,new
"The proposed algorithm can be reformulated as the following optimization problem: min E[|Y - D|] s.t. wsummationdisplay i=1 Pr(yi|xi) = 1, where the expectation can be estimated using the EM algorithm (Dempster et al., 1977).",1,new
"Our approach can be cast as an optimization problem, specifically a constrained optimization problem, which can be expressed as argmin E[|X - F|] s.t. wsummationdisplay j=1 Pr(fj|xj) = 1, where the expectation can be approximated using the EM algorithm (Jensen, 1996).",1,new
"The proposed method can be formalized as the following optimization problem: argmin wsummationdisplay i=1 (|y - f(i, w)|) s.t. Pr(f|x) = 1, which can be efficiently solved using the expectation-maximization algorithm (Wax & Kailath, 1990).",1,new
"This is a significant contribution to the field of MT, as the integration of the machine translation model and the language model has greatly improved the accuracy of statistical MT since (Koehn et al., 2003).",1,new
"The use of a hybrid approach combining the strengths of both the translation model and the language model has been a game-changer in MT research, as it has led to significant improvements in translation quality since (Melamed et al., 2004).",1,new
"This breakthrough in MT research is attributed to the effective decomposition of the translation task into two subtasks, allowing for a more efficient and accurate approach, which has been widely adopted in the field since (Brown et al., 1993).",1,new
"The widely accepted Hidden Markov Model (HMM) and its variants (Rabiner, 1989) often rely on the assumption of one-to-many alignments.",1,new
"The majority of statistical machine translation models, including IBM Model 4 (Brown et al., 1993) and its successors, presuppose one-to-many alignment hypotheses.",1,new
"Most generative models, such as the IBM Model 1 (Brown et al., 1993) and the probabilistic suffix tree (Kolmogorov, 1963), inherently assume one-to-many alignments.",1,new
"The incorporation of hybrid approaches, such as rule-based and statistical MT (Koehn et al., 2003; Och and Ney, 2002), has proven to be a highly effective method for achieving high-quality translations, as they allow for the flexibility of rule-based systems and the scalability of statistical models.",1,new
"Compared to other machine translation systems, Corpus-based MT (Brown et al., 1993; Melamed, 2001) methods have been found to be the most efficient, as they can be easily adapted to different languages and domains with minimal training data.",1,new
"Recent studies have shown that the combination of example-based and corpus-based MT (Sato and Nagao, 1990; Zens et al., 2002) systems can lead to significant improvements in translation quality, particularly in the context of domain-specific terminology and idiomatic expressions.",1,new
"Researchers at Google have made significant contributions to the field of natural language processing, with notable advancements in deep learning architectures (Hinton et al., 2006; Hinton et al., 2012; Hinton et al., 2017).",1,new
"The development of computational models for sentiment analysis has been a major focus area for researchers at Stanford, resulting in the creation of several influential papers on the topic (Pang et al., 2002; Socher et al., 2011; Socher et al., 2013).",1,new
"In recent years, researchers at Microsoft have demonstrated impressive breakthroughs in computer vision, particularly in the area of object recognition, with key contributions from top-tier conferences (Krizhevsky et al., 2012; Krizhevsky et al., 2014; Krizhevsky et al., 2017).",1,new
"The work of (Smith et al., 2001) further developed this concept by introducing a novel algorithm that efficiently computed the semantic similarity between aligned words, leading to improved model accuracy.",1,new
"Building upon the foundational research of (Lee et al., 2005), researchers later proposed an innovative approach to handling out-of-vocabulary words in machine translation, significantly enhancing the overall performance of their system.",1,new
"(Kim et al., 2012) significantly advanced the field by creating a robust framework for evaluating the effectiveness of different machine learning techniques in natural language processing tasks, providing a comprehensive benchmark for future studies.",1,new
"The proposed framework is an extension of the Conditional Random Field (CRF) model (Lafferty et al., 2001), which I previously applied to sentiment analysis tasks (Kim et al., 2004), by incorporating a novel feature extraction method based on latent semantic analysis (Hofmann, 1999).",1,new
"Building on the work of (Vapnik, 1995), we introduce a new Support Vector Machine (SVM) algorithm for text classification that incorporates a weighted voting system (Dietterich, 2000), which I have successfully implemented in previous studies (Sebastiani, 2002).",1,new
"In our previous research (Cohen et al., 1995), we developed a Hidden Markov Model (HMM) for speech recognition, which we have now enhanced with a novel state-tying approach (Bahl et al., 1983), inspired by the work of (Baker, 1975).",1,new
"Although deterministic models have achieved notable success in text summarization, there is a dearth of studies that employ deterministic approaches to sentiment analysis (Hinton et al. 2006; LeCun et al. 2015; Collobert et al. 2011).",1,new
"Despite the prevalence of machine learning techniques in information retrieval, only a limited number of researchers have applied machine learning to the task of question answering (Sutskever et al. 2014; Bengio et al. 2003; Mnih et al. 2013).",1,new
"While deep learning has revolutionized the field of computer vision, there is a scarcity of research that utilizes deep learning for image captioning (Krizhevsky et al. 2012; Simonyan et al. 2014; Donahue et al. 2014).",1,new
"2.5 Data Augmentation Techniques We employ a robust data augmentation technique known as Synthetic Minority Over-sampling Technique (SMOTE) in (Chawla et al., 2002) to enhance the diversity of our dataset.",1,new
"3.1 Feature Selection Algorithm We utilize the Information Gain feature selection algorithm introduced in (Hall, 1999) to optimize our model's performance and reduce dimensionality.",1,new
"4.4 Evaluation Metrics We leverage the widely accepted F1-score metric in (Bacry et al., 2008) to evaluate the accuracy and efficiency of our proposed method.",1,new
"The work of Smith et al. (2005; Smith et al., 2010) is widely regarded as a landmark in the field.",1,new
"The contributions of Johnson et al. (1980; Johnson et al., 1995) have significantly advanced our understanding of the subject matter.",1,new
"Research by Davis et al. (2015; Davis et al., 2020) has been instrumental in shaping the current paradigm.",1,new
"3 Previous Studies Building upon the advancements in deep learning, recent work in natural language processing, such as that by Vaswani et al. (2017), has shown significant improvements in language translation quality.",1,new
"1 Notable Contribution The development of the transformer model, introduced by Vaswani et al. (2017), has been instrumental in the field of machine translation, offering a substantial leap forward in accuracy and efficiency.",1,new
"2 Key Findings The successful application of recurrent neural networks (RNNs) in language translation, as demonstrated by Cho et al. (2014), has paved the way for the creation of more sophisticated models, such as the sequence-to-sequence approach.",1,new
"The Hidden Markov model (L. Rabiner, 1989) provides the foundation for our speech recognition framework.",1,new
The work of Viterbi (1967) on dynamic programming has significantly influenced our approach to sequence alignment.,1,new
"The use of Hopfield nets (J.J. Hopfield, 1982) in neural network research has been instrumental in shaping our model's architecture.",1,new
"Although innovative approaches have been presented (Kumar et al., 2011; Wang and Manning, 2007), they have primarily been tested on controlled language pairs where the concept of morpheme is well-defined.",1,new
"Despite the development of advanced methods (Huang et al., 2006; Smith and Eisner, 2005), they have largely been assessed on languages with minimal linguistic complexity, making the task more manageable.",1,new
"When novel techniques have been proposed (Lee et al., 2009; Collins and Chakrabarti, 2004), they have been mostly evaluated on homogeneous language sets where the notion of phoneme is relatively straightforward.",1,new
"The most widely employed machine learning algorithm in NLP tasks is the Hidden Markov Model (Rabiner, 1989).",1,new
"The most widely cited neural network architecture in deep learning research is the LeNet-5 (Lecun et al., 1998).",1,new
"The most commonly used clustering method in data mining applications is the k-means algorithm (MacQueen, 1967).",1,new
"The results of the experiment show a significant enhancement in model accuracy when using the word embeddings trained with the CBOW algorithm as in (Mikolov et al., 2013).",1,new
"In contrast to the baseline model, the proposed approach yields a notable improvement in BLEU scores when using the pre-trained word embeddings as described in (Devlin et al., 2019).",1,new
"Our findings suggest that adopting the hierarchical softmax approach as outlined in (Bengio et al., 2003) leads to a substantial reduction in training time and improved convergence rates.",1,new
"A distinct methodology from our predictive modeling framework is employed by the state-of-the-art model-based aligners, which primarily leverage the approaches outlined in the influential study by Brown et al. (1993) and subsequent advancements in machine learning algorithms (Krizhevsky et al. 2012).",1,new
"The novel approach taken by the learning-based aligners diverges significantly from our initial proposals, drawing heavily from the foundational work of IBM's models (1 to 5) as described in the seminal paper by Brown et al. (1993) and subsequent breakthroughs in deep learning techniques (LeCun et al. 2015).",1,new
"Unlike our earlier endeavors, the model-driven aligners exhibit a notable departure in strategy, largely relying on the methodologies described in the pivotal paper by Brown et al. (1993) and recent developments in natural language processing (NLP) frameworks (Collobert et al. 2011).",1,new
"The latest advancements in natural language processing rely heavily on cutting-edge techniques such as transformer-based architectures (Vaswani et al., 2017; Devlin et al., 2019).",1,new
"Recent studies have shown that the integration of graph neural networks has significantly improved the performance of recommender systems (Kipf and Welling, 2016; Hamilton et al., 2017).",1,new
"The development of explainable AI models, such as SHAP (Lundberg and Lee, 2017) and LIME (Ribeiro et al., 2016), has greatly enhanced our understanding of complex decision-making processes in machine learning algorithms.",1,new
"The increasing accessibility of vast corpora has driven the adoption of probabilistic models in natural language processing, building upon the foundational work of Hinton et al. (1986) and the pioneering efforts of Rumelhart et al. (1986).",1,new
"The development of large-scale language datasets has facilitated the application of machine learning algorithms to the task of sentiment analysis, with notable contributions from the work of Pang et al. (2002) and the subsequent advancements made by Lewis et al. (2004).",1,new
"The availability of sophisticated computational tools has enabled researchers to explore the efficacy of neural networks in modeling human language, with significant strides made in the area of text classification, as demonstrated in the studies of Collobert et al. (2008) and the subsequent research of Socher et al. (2011).",1,new
"This trend of inferior performance is also observed in machine learning-based methods, where statistical models like the widely used IBM Model 1 (Brown et al., 1993) fall short of their rule-based counterparts in certain tasks.",1,new
"Conversely, the empirical results indicate that traditional rule-based approaches, such as the use of the Giza++ aligner (Och & Ney, 2003), often surpass their machine learning-based alternatives in terms of accuracy and efficiency.",1,new
"Furthermore, the experimental data reveal that the re-estimated phrase-based models, such as the one proposed by Koehn et al. (2003), tend to outperform their rule-based counterparts, including the popular Moses system (Koehn et al., 2007), in various translation tasks.",1,new
"The development of deep learning techniques for natural language processing heavily relies on the concept of attention mechanisms, as demonstrated by the pioneering work of Bahdanau et al. (2014).",1,new
"The success of neural machine translation can be attributed to the incorporation of subword modeling, which was first introduced by Sennrich et al. (2015) and has since become a crucial aspect of modern translation systems.",1,new
"The effectiveness of recurrent neural networks in text classification is largely due to the introduction of gated recurrent units (GRUs) by Cho et al. (2014), which has revolutionized the field of natural language processing.",1,new
"The majority of recent studies have employed machine learning-based techniques, as reviewed in (Kohavi et al., 1997; Freund et al., 1997).",1,new
"The development of novel neural network architectures has been extensively discussed in (LeCun et al., 1989; Rumelhart et al., 1986).",1,new
"The widely used probabilistic graphical models have been thoroughly examined in (Pearl, 1988; Lauritzen, 1996).",1,new
The proposed Hidden Markov Model (HMM) by Rabiner (1989) relies heavily on the computation of the Viterbi algorithm to determine the optimal state sequence for a given observation sequence.,1,new
"In the widely used n-gram language models (Kneser & Ney, 1995), the probability of a sentence is calculated as the product of the individual word probabilities, which are estimated using maximum likelihood estimation.",1,new
"The application of the Expectation-Maximization algorithm to the Gaussian mixture model (Dempster et al., 1977) is contingent upon the accurate estimation of the component weights and mean vectors, which are typically obtained through iterative re-estimation.",1,new
"Recent advances in deep learning (Bengio et al., 2003) have enabled the development of sophisticated neural network architectures for sentence alignment, significantly improving upon earlier methods (Melamed, 2001).",1,new
"The introduction of probabilistic models (Chen et al., 2006) and their application in machine translation (Och & Ney, 2002) have greatly enhanced the accuracy of word alignment algorithms, leading to substantial gains in translation quality.",1,new
"The incorporation of lexicalized HMMs (Vogel et al., 1996) and the subsequent use of phrase-based models (Koehn et al., 2003) have contributed to the development of more robust and accurate word alignment systems, revolutionizing the field of machine translation.",1,new
"The advent of high-performance computing has enabled researchers to utilize efficient algorithms (e.g., Smith et al. 2015) to yield significant breakthroughs in complex simulations.",1,new
"Although computationally intensive approaches (as described in Johnson et al. 2001) can be resource-heavy, they have led to numerous discoveries in the field of materials science.",1,new
"Recent advances in parallel processing (e.g., demonstrated in Lee et al. 2018) have facilitated the development of powerful computational models that can tackle intricate problems in computational physics.",1,new
"The process of manually annotating datasets is not only time-consuming but also prone to human bias, and it is therefore beneficial to adopt an automated approach (Krizhevsky et al., 2012) to minimize the need for manual intervention.",1,new
"Developing annotated corpora by hand can be a tedious and imperfect task, and leveraging machine learning algorithms (Bengio et al., 2003) to streamline the process is a welcome development in the field.",1,new
"Creating labeled datasets manually is a painstaking process that can be marred by errors and inconsistencies, and the use of natural language processing techniques (Collobert et al., 2011) can help alleviate these issues and improve the overall quality of the data.",1,new
"The incorporation of large-scale annotated datasets such as the OntoNotes project (Hwa et al., 2005), the RST-Treebank (Gardent et al., 2017), or the semantically annotated corpora in (Carlson et al., 2010) significantly enhances our ability to develop effective information retrieval systems.",1,new
"Utilizing well-curated linguistic resources such as the OpenNLP library (Gutenmacher et al., 2005), the Stanford CoreNLP toolkit (Manning et al., 2014), or the annotated corpora in (Kurata et al., 2009) facilitates the creation of sophisticated natural language processing tools.",1,new
"The availability of syntactically annotated corpora like the Prague Dependency Treebank (Hajic et al., 1998), the PropBank (Palmer et al., 2005), or the annotated parses in (Klein et al., 2003) greatly aids in the development of robust parsing algorithms and improved language understanding models.",1,new
"The observed results may be partially attributed to the prevalent use of discourse analysis in British linguistics, as well as the influence of the British National Corpus (BNC, 2007), which has been primarily annotated with discourse-based techniques.",1,new
"This trend can be attributed to the long-standing emphasis on dependency grammar in Germanic linguistics, which has been reinforced by the development of the TIGER treebank (Brants et al., 2002), a comprehensive resource for dependency parsing in German.",1,new
"The preference for constituency-based parsing in Romance languages may be due in part to the extensive use of the Penn Treebank's Spanish and French extensions, which have been annotated primarily with constituent analysis, and the influence of the French Reference Corpus (CCRF, 2010), a large-scale resource for Romance languages.",1,new
"The growth of cognitive computing has led to significant advancements in machine learning techniques, as evident in the works of (Rumelhart et al., 1986; LeCun et al., 1998; Schmidhuber, 2010).",1,new
"Recent breakthroughs in computer vision have been facilitated by the adoption of deep learning algorithms, as exemplified by the research of (LeCun et al., 1989; Krizhevsky et al., 2012; Szegedy et al., 2014).",1,new
"The increasing use of neural networks in data analysis has been pivotal in improving predictive modeling, as highlighted by the studies of (Hopfield, 1982; Hinton et al., 2006; Bengio et al., 2007).",1,new
"The following datasets have demonstrated successful reuse: the GeoNames geographical database (Geonames.org, 2002); the OpenCyc ontology (Baker et al., 2009); and the WordNet lexical database (Fellbaum, 1998).",1,new
"Notable examples of data reuse include: the DBpedia knowledge graph (Lehmann et al., 2012); the Medical Subject Headings (MeSH) thesaurus (US National Library of Medicine, 2020); and the Wikipedia Infobox dataset (Medelyan et al., 2009).",1,new
"Successful applications of data reuse can be seen in: the General Inquirer sentiment lexicon (Stone et al., 1966); the Reuter-21578 news dataset (Lanquedoc et al., 2004); and the NDC clinical trials database (ClinicalTrials.gov, 2019).",1,new
"The widely adopted corpus in the field of information retrieval is the Cranfield Collection (Harman, 1993).",1,new
"The gold standard for evaluating question answering systems is the SQuAD dataset (Rajpurkar et al., 2016).",1,new
"The most commonly referenced knowledge graph is the Freebase dataset (Bollacker et al., 2008), which has been instrumental in advancing the field of semantic search.",1,new
"The incorporation of annotated corpora, such as the Prague Dependency Treebank (Hajic, 1998) and the Stuttgart Dependency Treebank (Engel, 1999), has significantly enhanced the accuracy of syntactic parsing models.",1,new
"The development and utilization of corpora like the Penn Parsed Corpus (Marcus et al., 2000) and the RST Discourse Treebank (Mann and Thompson, 1988) have greatly facilitated the advancement of discourse analysis techniques.",1,new
"The creation and use of annotated datasets, including the Swedish Dependency Corpus (Johansson and Nugues, 2005) and the Danish Dependency Corpus (Pedersen et al., 2006), have significantly improved the performance of morpho-syntactic analysis systems in Scandinavian languages.",1,new
"The incorporation of this dataset has significantly contributed to the development of advanced natural language processing techniques, particularly in areas such as text summarization and sentiment analysis (Pang & Lee, 2008; Turney, 2002).",1,new
"The availability of this corpus has been instrumental in advancing the field of machine learning, enabling researchers to train and test models for tasks such as named entity recognition and language modeling (Brown et al., 1992; Manning & Schtze, 1999).",1,new
"The utility of this corpus has been extensively demonstrated in various applications, including information retrieval and dialogue systems, showcasing its potential for improving the performance of these systems (Salton & McGill, 1983; Vossen, 1993).",1,new
"The notable contributions of the Stanford Natural Language Processing Group (Petrov et al., 2012) have significantly advanced the field of machine translation, particularly for languages such as Chinese and Arabic.",1,new
"The development of the HPSG (Head-Driven Phrase Structure Grammar) corpus (Pollard and Sag, 1994) has provided valuable insights into the syntactic structure of Germanic languages, shedding light on their complex morphological properties.",1,new
"The creation of the Multilingual Corpus of Parallel Texts (L'Homme et al., 2007) has been instrumental in facilitating cross-linguistic research and has enabled the analysis of linguistic patterns across multiple languages, including French and Spanish.",1,new
"The Brown Corpus (Kuera 1993) is another significant resource, comprising over 500,000 words of text, providing valuable insights into linguistic phenomena, particularly in the context of American English.",1,new
"The Switchboard Corpus (Godfrey, Holliman, and McDaniel 1992) is a substantial collection of spontaneous spoken language, consisting of over 2,400 conversations, which has greatly contributed to the advancement of speech recognition and natural language processing.",1,new
"The Lancaster Corpus (Dunning 1993) is a notable resource, containing over 1.5 million words of text, extracted from various sources, including books, newspapers, and magazines, and has been widely used in research on language modeling and text analysis.",1,new
"The development of neural network-based models (Rumelhart et al., 1986) has significantly advanced the field of machine learning, enabling accurate predictions in complex systems (Bengio et al., 2003; Hinton et al., 2006).",1,new
"Recent breakthroughs in natural language processing (NLP) have been largely attributed to the integration of distributional semantics (Harris, 1954; Firth, 1957), leading to substantial improvements in text analysis and information retrieval (Manning et al., 2008; Manning, 1999).",1,new
"Advances in data-driven approaches to linguistics (Sag et al., 2003) have been instrumental in refining theories of language acquisition and processing, resulting in more accurate models of human language behavior (Pinker, 1999; Gibson, 1998).",1,new
"The CoNLL dataset (Sang and Buchholz, 2000) features morpho-syntactic annotation, facilitating the analysis of linguistic features and their influence on parsing algorithms.",1,new
"The PropBank (Palmer et al., 2005) corpus is notable for its rich annotation of predicate-argument structures, allowing researchers to investigate the nuances of verb semantics.",1,new
"The Penn Parsed Corpora of Modern British English (Sinclair, 1991) is a valuable resource for studying syntactic variation and change, with its detailed annotation of grammatical structure and function.",1,new
The widely used Brown Corpus (Francis & Kucera 1979) was chosen as the training data for the sentiment analyzer due to its relevance to the linguistic features of written texts commonly encountered by native English speakers.,1,new
The Brown Corpus (Francis & Kucera 1979) was selected as the training set for the language model because its composition and syntax are similar to those of the texts that a language proficiency test would assess.,1,new
The Oxford English Corpus (Johansson et al. 2001) was utilized as the training corpus for the text classifier due to its extensive coverage of English language varieties and its suitability for modeling linguistic patterns relevant to language learning.,1,new
"Despite evaluations on the standard OntoNotes corpus (Pradhan et al., 2007), our proposed parser still trails behind the current state-of-the-art models in terms of accuracy.",1,new
"Nevertheless, assessments on the widely used Brown Corpus (Francis & Kucera, 1967) indicate that the efficiency of these statistical models is not yet on par with the best performing systems.",1,new
"However, evaluations on the annotated Penn Discourse Treebank (Marcus et al., 1998) reveal that the precision of our parser is still lower than that of the leading parsing algorithms.",1,new
"Advances in machine learning algorithms (Bengio et al., 2003; LeCun et al., 2015) and large-scale datasets (IMDB, 2008; Amazon Reviews, 2010) have significantly contributed to the growth of text classification in the field of artificial intelligence.",1,new
"The development of deep learning techniques (Rumelhart et al., 1986; Schmidhuber, 2015) and the creation of large, annotated datasets (Penn Treebank, 2002; WikiText, 2014) have had a profound impact on the field of natural language generation.",1,new
"The availability of high-performance computing resources (HPC, 2018) and innovative data preprocessing methods (Kohavi, 1995; Liu et al., 2017) has enabled significant advancements in the field of predictive modeling, particularly in areas such as time series forecasting and regression analysis.",1,new
"The WordNet lexical database (Fellbaum, 1998) is a highly influential tool in the field of Natural Language Processing (NLP).",1,new
"The Brown Corpus (Francis & Kucera, 1967) has been a foundational resource in the study of linguistic corpora and their applications in NLP.",1,new
"The Stanford Question Answering Dataset (Yao et al., 2014) has significantly impacted the development of question-answering systems and remains a valuable asset in the NLP community.",1,new
"2 Background Recent advances in speech recognition have been significantly influenced by the development of high-quality speech databases like the TIMIT corpus (Garofolo et al., 1993) and the Switchboard Corpus (Godfrey et al., 1992).",1,new
"3 Methodology The field of natural language generation has been greatly enhanced by the creation of large-scale datasets such as the Gigaword Corpus (Nagao et al., 2001) and the Canadian Hansard Corpus (Walker, 1990).",1,new
"4 Discussion The study of machine translation has been significantly advanced by the availability of large-scale parallel corpora like the Europarl Corpus (Koehn, 2005) and the OpenSubtitles Corpus (Tiedemann, 2012).",1,new
"The development of large-scale datasets is crucial for machine learning research, and one notable source is the Linguistic Data Consortium's corpus of annotated texts \[Baker et al. 1998\], which provides valuable resources for training and testing NLP models.",1,new
"The annotated corpora maintained by the Association for Computational Linguistics have been instrumental in advancing the field of NLP, offering a wealth of information for researchers to analyze and build upon \[Grishman et al. 1998\].",1,new
"The availability of parsed corpora, such as those provided by the Penn Treebank Project \[Marcus et al. 1993\], has significantly facilitated the study of syntactic structures and their applications in NLP, enabling researchers to explore and refine their hypotheses.",1,new
"The WordNet lexical database (Miller, 1995) was also employed to train named entity recognizers due to its comprehensive and structured semantic relationships among words.",1,new
"The Brown Corpus (Francis & Kucera, 1967) was utilized as a gold standard for sentiment analysis models because of its diverse and well-annotated text samples.",1,new
"The GENIA corpus (Kilgarriff & Grefenstette, 2003) was chosen for part-of-speech tagging tasks due to its rich and accurate annotation of biomedical terminology and concepts.",1,new
The Berkeley TDT (TDT 1998) dataset has significantly advanced the field of text categorization research.,1,new
The introduction of the OntoNotes project (Hacioglu et al. 2003) marked a pivotal moment in the development of semantic role labeling techniques.,1,new
The establishment of the PropBank (Kingsbury and Palmer 2002) corpus has provided invaluable insights into the annotation of predicate-argument structures in language.,1,new
"The development of the Stanford Natural Language Processing Group's dependency parsing models (Santorini, 1990; McDonald et al., 2005) significantly contributed to the improvement of grammatical analysis techniques for English.",1,new
"The creation of the PropBank (Palmer et al., 2005) and VerbNet (Kipper et al., 2000) resources has greatly facilitated the task of semantic role labeling and verb classification in computational linguistics (Gardent et al., 2017).",1,new
"The establishment of the OntoNotes project (Hovy et al., 2006) and its annotation schema has had a profound impact on the field of information extraction and entity recognition (Roth & Yih, 2004; Sekine et al., 2010).",1,new
"2 Methodology The development of robust machine learning algorithms such as the Support Vector Machine (Vapnik, 1995) has greatly facilitated the analysis of large datasets in the field of computer vision.",1,new
"3 Results The creation of the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) (Russakovsky et al., 2015) has significantly advanced the state-of-the-art in object recognition and classification.",1,new
"4 Discussion The availability of open-source software packages like scikit-learn (Pedregosa et al., 2011) has empowered researchers to implement complex data mining techniques with ease, leading to breakthroughs in various scientific domains.",1,new
"The availability of large annotated datasets, such as the Gigaword Corpus (Sproat et al., 2001) and the Swedish Corpus (Brants et al., 2002), has significantly contributed to the growth of computational linguistics in multiple languages.",1,new
"The development of robust annotated corpora, like the Canadian Hansard Corpus (Wintner et al., 2002) and the Open Subtitles Corpus (Tiedemann, 2009), has facilitated the advancement of natural language processing techniques.",1,new
"The creation of well-structured annotated corpora, including the Switchboard Corpus (Godfrey et al., 1992) and the MultiGenre Corpus (Carletta et al., 2003), has greatly aided in the development of speech recognition and dialogue systems.",1,new
"The notable contributions of the Stanford Natural Language Processing Group (Pitler and Robin, 2007) and the Japanese Treebank project (Kawahara et al., 2001) have significantly enhanced the capabilities of part-of-speech tagging and dependency parsing techniques.",1,new
"The development of high-quality resources such as the Open Multilingual Wordnet (Petruck et al., 2003) and the Prague Dependency Treebank (Hajic et al., 1998) has led to substantial improvements in semantic role labeling and coreference resolution.",1,new
"Recent advances in the field have been largely attributed to the creation of the German RefRam (Hahn and Schnorr, 2004) and the Chinese Treebank (Xue and Palmer, 2004), which have significantly boosted the performance of named entity recognition and machine translation algorithms.",1,new
"The WordNet lexical database is another influential resource that has significantly impacted the field of artificial intelligence (Miller, 1995).",1,new
"The Brown Corpus is a pioneering dataset that has greatly contributed to the development of computational linguistics (Francis & Kucera, 1967).",1,new
"The FrameNet lexical database has far-reaching implications for the study of semantic roles in natural language processing, exemplifying the importance of linguistic resources (Fillmore et al., 2003).",1,new
"The development of the Stanford Natural Language Processing Group's (Jurafsky and Martin, 2000) parser and the annotated dataset, PropBank (Palmer et al., 2005), have demonstrated the significant impact of high-quality resources on the advancement of dependency parsing techniques.",1,new
"The introduction of the ACL Anthology Reference Corpus (Bird et al., 2006) and the annotated dataset, the Message Understanding Conference (MUC-7) corpus (Chinchor et al., 2000), has shown that even modest-sized datasets can lead to substantial improvements in text classification models.",1,new
"The creation of the OpenNLP maximum entropy part-of-speech tagger (McDonald et al., 2006) and the annotated dataset, the Penn Parsed Corpus of Modern British English (Marcus et al., 1999), have highlighted the importance of carefully curated resources in achieving state-of-the-art performance in NLP tasks.",1,new
"The development of a standardized framework for representing knowledge graphs is crucial for advancing the field of artificial intelligence, much like the creation of WordNet (Fellbaum, 1998) facilitated the development of lexical databases (Miller, 1990; Vronis, 1999).",1,new
"A unified approach to multimodal data representation is essential for the growth of human-computer interaction research, similar to the impact of the CMU Pronouncing Dictionary (Weinstein, 1993) on speech recognition systems (Huang, 1997; Beasley, 2001).",1,new
"The establishment of a widely accepted benchmark for evaluating natural language inference tasks will significantly contribute to the advancement of natural language processing, just as the availability of the Parseval Treebank (Petrov et al., 2006) accelerated the development of parsing algorithms (Klein et al., 2003; Charniak, 2000).",1,new
"The performance of our model was assessed using the Waterloo Corpus (Walker et al., 2012), a widely used benchmark for natural language processing tasks that provides a realistic representation of everyday conversations.",1,new
"Our approach was validated on the Switchboard Corpus (Godfrey et al., 1992), a well-established resource for speech recognition research that has been instrumental in advancing the field.",1,new
"The effectiveness of the proposed method was evaluated using the Brown Corpus (Francis & Kucera, 1967), a seminal dataset for linguistic analysis that has been widely employed in various studies.",1,new
"The recent advancements in named entity recognition (Bikel et al., 1999) and coreference resolution (Manning et al., 1999) have paved the way for more complex linguistic analyses, such as sentiment analysis (Turney et al., 2002) and aspect-based opinion mining (Kim and Hovy, 2004).",1,new
"Following the success of morphological tagging (Brill, 1992) and part-of-speech tagging (Raffinot and Rialle, 1998), researchers have started to focus on more nuanced aspects of language, such as idiomatic expressions (Sag et al., 2002) and figurative language processing (Gibbs, 2006).",1,new
"Building on the foundation laid by semantic role labeling (Gildea and Jurafsky, 2002) and event extraction (Ruppenhofer et al., 2006), researchers have made significant progress in analyzing complex linguistic phenomena, including modality (Asher and Lascarides, 2003) and hedging (Hyland, 2005).",1,new
"Although notable improvements in processing efficiency have been observed with the use of pre-annotation techniques (e.g., named entity recognition in the BioScope corpus (Ananiadou et al., 2006), or sentiment analysis in the Stanford Sentiment Treebank (Socher et al., 2013)), these methods do not eliminate the need for manual review of individual text units.",1,new
"While substantial gains in processing speed have been achieved through the application of automatic pre-tagging (e.g., for part-of-speech tagging in the Penn TreeBank (Marcus et al., 1993) or dependency parsing in the Prague Dependency Treebank (Hajic et al., 1998)), the actual number of tokens to be analyzed remains unaffected.",1,new
"Notwithstanding the reported enhancements in processing speed resulting from pre-processing techniques (e.g., for coreference resolution in the MUC-7 corpus (Pradhan et al., 2005) or semantic role labeling in the PropBank (Palmer et al., 2005)), a significant portion of the text still requires manual examination.",1,new
"The development of advanced machine learning models, such as word embeddings (Mikolov et al. 2013), has greatly contributed to the progress in natural language processing.",1,new
"The availability of large-scale datasets, including the WikiText-103 corpus (Merity et al. 2017), has facilitated the training of more sophisticated deep learning models for text analysis.",1,new
"The creation of annotated datasets, such as the Stanford Natural Language Inference Corpus (SNLI) (Bowman et al. 2015), has been instrumental in advancing the field of natural language understanding.",1,new
"The Corpus of Linguistic Acceptability (Gibson et al., 1997) has served as a benchmark for sentence acceptability judgments, comprising over 2.5M carefully crafted sentences across various linguistic theories.",1,new
"The Gigaword Corpus (Nagao et al., 2001) has been a valuable resource for researchers, containing 3.8M words from a broad range of genres, including news articles and books.",1,new
"The Swedish Parsed Corpus of Books and Articles (Karlsson et al., 1995) has provided a comprehensive dataset for syntactic analysis, with over 1.2M words from a diverse set of literary and non-literary texts.",1,new
"The design of the Penn Phonological Lexicon (Brugger et al., 2010) is another notable example that aligns with these criteria, focusing on the phonological properties of words in a linguistic database.",1,new
"The work of the Xerox Part-of-Speech Tagger (Church et al., 1989) exemplifies a system that can be used to extract morphological and syntactic features from text data, meeting the proposed standards.",1,new
"The linguistic annotation project, the OntoNotes project (Hovy et al., 2006), is a comprehensive effort that satisfies these criteria by incorporating various levels of linguistic analysis, including semantic and syntactic annotation.",1,new
"The task of named entity recognition (NER) is a crucial component in natural language processing (NLP) for extracting relevant information from unstructured text. However, the accuracy of NER models heavily relies on the quality of the annotated training data, particularly when dealing with entities that have nuanced or context-dependent meanings. A recent study by [1] highlights the challenges of achieving high agreement rates among human annotators for NER tasks, especially when annotating entities in a specific domain, such as financial reports. For instance, the F1-score for annotating company names in financial reports ranged from 0.6 to 0.8, indicating a significant margin for improvement. To address this issue, the authors proposed a machine learning-based approach that leveraged domain-specific knowledge and context to improve the accuracy of NER models.",1,new
"The field of sentiment analysis has witnessed significant advancements in recent years, with the development of novel algorithms and techniques that can effectively capture subtle nuances in human language. However, the evaluation of these models often relies on human annotators, who may exhibit varying levels of agreement in their sentiment labels. A study by [2] investigated the inter-annotator agreement on sentiment labels for a corpus of movie reviews, finding that the average Kappa statistic was 0.65. The authors attributed this relatively low agreement to the complexity of human sentiment, which can be influenced by factors such as context, tone, and cultural background. To mitigate this issue, the authors proposed a hybrid approach that combined machine learning and rule-based methods to improve the accuracy of sentiment analysis.",1,new
"The task of part-of-speech (POS) tagging is a fundamental component in NLP, enabling models to understand the grammatical structure of language. However, the accuracy of POS taggers can be affected by the quality of the training data, particularly when dealing with languages that have complex grammatical systems. A study by [3] examined the inter-annotator agreement on POS tags for a corpus of texts from different languages, finding that the average agreement rate was around 90%. However, the authors noted that the agreement rate varied significantly across languages, with some languages exhibiting much lower agreement rates. To address this issue, the authors proposed a machine learning-based approach that leveraged language-specific features and context to improve the accuracy of POS taggers.",1,new
"In comparison to the massive datasets utilized by other researchers, such as the large-scale annotated corpus by \[Baker et al., 2008\], our own dataset is relatively modest in size.",1,new
"The size of our training data, approximately 10,000 tokens, is minuscule when compared to the monumental corpus assembled by \[Lincoln et al., 2015\].",1,new
"Our sample population, consisting of merely 250 participants, is significantly smaller than the extensive sample sizes employed by \[Johnson et al., 2012\], thereby allowing for more in-depth analysis and control.",1,new
"The use of decision trees has also yielded impressive outcomes in text classification tasks (Quinlan, 1986; Dietterich, 1998; Murthy et al., 1999).",1,new
"Moreover, significant advancements have been made in the field of information retrieval using vector space models (Salton & McGill, 1983; Deerwester et al., 1990; Robertson et al., 1995).",1,new
"Additionally, notable progress has been achieved in machine learning through the application of support vector machines (Cortes & Vapnik, 1995; Gunn, 1998; Joachims, 1999).",1,new
"The application of Hidden Markov Models (Rabiner, 1989) has been widely recognized as a powerful tool for sequence analysis.",1,new
"The decision tree algorithm (Breiman et al., 1984) is a popular choice for its ability to effectively handle complex classification tasks.",1,new
"The use of Support Vector Machines (Cortes & Vapnik, 1995) has been shown to be highly effective in solving multi-class classification problems.",1,new
"The analysis employs a machine learning strategy, grounded in the support vector machine (SVM) algorithm (Cortes & Vapnik, 1995), which effectively integrates various data features for accurate prediction outcomes.",1,new
"The methodology is founded on the principles of decision trees, utilizing the ID3 algorithm (Quinlan, 1986) to efficiently evaluate the relevance of input variables in model development.",1,new
"The proposed approach is based on the k-nearest neighbors (KNN) technique (Cover & Hart, 1967), which allows for the incorporation of diverse data points in determining the classification outcome.",1,new
"1.3 Support Vector Machines Support vector machines (SVMs) (Cortes and Vapnik, 1995; Vapnik, 1998) are a type of supervised learning algorithm that has been effectively employed in various machine learning tasks such as text classification, regression, and anomaly detection. Their ability to handle high-dimensional data and provide robust performance makes them a popular choice in the field of data analysis.",1,new
"3.1 Recurrent Neural Networks Recurrent neural networks (RNNs) (Elman, 1990; Hochreiter and Schmidhuber, 1997) have revolutionized the field of natural language processing by enabling the modeling of sequential data such as speech, text, and time series. The dynamic nature of RNNs allows for the capture of long-term dependencies and complex patterns in data, making them a valuable tool for various applications.",1,new
"2.5 Deep Learning Techniques Deep learning techniques, including convolutional neural networks (CNNs) and long short-term memory (LSTM) networks (LeCun et al., 1998; Graves et al., 2005), have significantly advanced the field of computer vision and natural language processing. The ability of these techniques to learn hierarchical representations of data has led to state-of-the-art performance in various tasks, including image classification and sentiment analysis.",1,new
"The efficiency of the Deep Learning model was enhanced by employing the widely acclaimed Gradient Descent optimization technique (Rumelhart et al., 1986), a method proven to yield optimal results in various applications.",1,new
"The accuracy of the proposed neural network was significantly improved by adopting the Stochastic Gradient Descent algorithm (Bottou & LeCun, 2004), a widely used and reliable approach in machine learning.",1,new
"To determine the optimal hyperparameters for the Support Vector Machine, we leveraged the effective Grid Search algorithm (Friedman et al., 1998), a method well-established in the field of statistical learning theory.",1,new
"Maximum entropy Markov models (MEMMs) (McCallum, 2003; Taskar et al., 2003) offer a powerful framework for sequential data analysis, allowing for effective modeling of complex dependencies and providing state-of-the-art results in tasks such as speech recognition and machine translation.",1,new
"Decision trees and random forests (Quinlan, 1986; Breiman, 2001) have been widely adopted in machine learning for their simplicity and interpretability, enabling accurate predictions and robust classification in various domains, including image classification and recommender systems.",1,new
"Support vector machines (SVMs) (Cortes and Vapnik, 1995; Joachims, 1999) have been successfully applied to a range of applications, including text classification, spam detection, and bioinformatics, due to their ability to handle high-dimensional data and non-linear relationships, offering a versatile tool for machine learning research.",1,new
"The analysis of the experimental results presented in Table 2 was facilitated by employing the maximum entropy approach, which effectively captured the average trends in the data (Cover & Thomas, 2012).",1,new
"To accurately quantify the impact of the environmental factors, we relied on the MaxEnt method to determine the average effects of each variable on the system (Jaynes, 2003).",1,new
"For the calculation of the conditional probabilities outlined in Figure 1, we utilized the maximum entropy principle, which provided a reliable estimate of the average behavior of the system under the given conditions (Kullback, 1959).",1,new
"The use of part-of-speech tagging has been shown to significantly enhance the accuracy of machine translation, as demonstrated by the work of Manning and Schtze (1999), which highlights its potential in improving translation models.",1,new
"According to recent studies, incorporating sentiment analysis has been found to be beneficial in determining the tone and nuance of translated text, as evident in the research conducted by Kim and Oakes (2005).",1,new
"The incorporation of named entity recognition has been demonstrated to be a valuable tool in improving the precision of machine translation, as illustrated by the findings of Grishman and Sundheim (1996), which underscores its importance in accurate translation.",1,new
"Our team opted for the use of support vector machines, which have been proven to be highly effective in high-dimensional spaces and can efficiently handle non-linear relationships (Cortes & Vapnik, 1995).",1,new
"The implementation of decision trees was chosen due to their interpretability and ability to handle complex interactions between variables, allowing for a deeper understanding of the data (Breiman, 2001).",1,new
"We employed the k-nearest neighbors algorithm, which has been shown to be robust and can effectively capture local patterns in the data, leading to improved accuracy (Cover & Hart, 1967).",1,new
"Our methodology relied heavily on the support vector machine (SVM) algorithm (Cortes and Vapnik, 1995), which has been demonstrated to produce state-of-the-art results in various natural language processing tasks, such as named entity recognition (Bikel et al., 1999).",1,new
"We opted for the decision tree classifier (Quinlan, 1986) due to its proven track record in handling complex data structures, as shown in the domain adaptation study by Chen and Rosenfeld (2003).",1,new
"The adoption of the k-nearest neighbors (k-NN) algorithm (Cover and Hart, 1967) was influenced by its successful applications in text categorization, as seen in the work of Aha et al. (1991) and the ability to handle high-dimensional feature spaces.",1,new
"Our decision to utilize a Support Vector Machine (Vapnik, 1995) as the core classification algorithm in this study was informed by the impressive performance of top-ranked systems in the Text Retrieval Conference (TREC) 2009 question answering task (Craswell et al., 2009).",1,new
"The selection of a probabilistic neural network (Rumelhart et al., 1986) for our classification model was guided by the success of similar architectures in achieving state-of-the-art results in the MovieLens 1M dataset (Harper and Konstan, 2015).",1,new
"Given the proven effectiveness of decision trees (Breiman, 2001) in handling high-dimensional feature spaces, we opted to employ them as the primary classification algorithm in our experiment, drawing inspiration from their use in the winning submissions of the KDD Cup 2001 (Tong et al., 2001).",1,new
"The incorporation of dependency features can significantly enhance IBM-style translation probabilities as demonstrated in the work of (Klein et al., 2000).",1,new
"Employing a hybrid approach that combines word-based and phrase-based models can lead to improved translation accuracy, as seen in the research by (Chiang, 2005).",1,new
"Utilizing contextual information, such as part-of-speech tags and named entity recognition, can enhance IBM-style translation probabilities, as shown in (Collins et al., 2005).",1,new
"The use of robust optimization techniques (Kuhn & Beck, 1993) significantly improves the overall efficiency of the algorithm once the optimal set of features {a12, a34, a56, a78, a90, a23} is chosen.",1,new
"Efficient data preprocessing methods (Domingos, 1996) have been successfully employed to enhance the performance of the algorithm when the feature set {a19, a46, a67, a89, a12, a34} is utilized.",1,new
"The selection of a well-suited set of features {a56, a78, a90, a23, a14, a67} has been shown to greatly facilitate the training process using the advanced algorithm proposed by (Witten & Frank, 2000).",1,new
"The findings of this study also resonate with the concept of latent semantic analysis (Deerwester et al., 1990), a widely applied technique in information retrieval.",1,new
"Furthermore, our results demonstrate a connection to the perceptron model (Rosenblatt, 1958), which has been a cornerstone in the development of artificial neural networks.",1,new
"Notably, the proposed methodology shares similarities with the hidden Markov model (Baum & Petrie, 1966), a fundamental model in the field of machine learning and pattern recognition.",1,new
"6.2 Logistic Regression Logistic regression has been widely adopted in machine learning models for its ability to handle complex data distributions (Hastie et al., 2009).",1,new
"8.5 Decision Trees Decision trees have been consistently shown to improve the accuracy of classification tasks in various machine learning domains (Breiman et al., 1984).",1,new
"3.1 Support Vector Machines Support vector machines have been successfully applied to high-dimensional feature spaces, providing superior performance in pattern recognition tasks (Cortes and Vapnik, 1995).",1,new
"The proposed model of Markov random fields offers a robust foundation for image segmentation (Kolmogorov et al., 2004).",1,new
"The well-established approach of support vector machines has been widely adopted in machine learning (Cortes and Vapnik, 1995).",1,new
"A highly influential framework for decision trees is the CART algorithm, introduced by Breiman et al. (1984).",1,new
"This study by (Kumar et al., 2002) provided an excellent overview of the Monte Carlo simulations used in climate modeling.",1,new
"The work by (Smith et al., 2010) presented a thorough analysis of the benefits of using Bayesian inference in statistical analysis.",1,new
"(Lee et al., 2015) offered a comprehensive review of the applications of machine learning in image recognition, highlighting its potential for real-world implementation.",1,new
"The Conditional Random Field (Lafferty et al., 2001) has been instrumental in our research, offering a robust approach to sequential data modeling that has been successfully applied to various NLP tasks such as named entity recognition and sentiment analysis.",1,new
"The Support Vector Machine (Cortes & Vapnik, 1995) has been a cornerstone in our study, providing a reliable method for classification problems that has been widely utilized in text classification and information retrieval tasks.",1,new
"The Expectation-Maximization algorithm (Dempster et al., 1977) has been a valuable asset in our work, offering a powerful technique for maximum likelihood estimation that has been successfully employed in clustering and dimensionality reduction tasks in machine learning.",1,new
"Our research utilizes state-of-the-art neural networks (Hinton et al., 2006), which have shown great potential in capturing complex patterns in large datasets, allowing us to effectively leverage their strengths in our analysis of linguistic phenomena.",1,new
"We employ a novel application of statistical machine learning techniques (Mitchell, 1997), tailored to our specific task, to identify and incorporate linguistic features that are closely related to the characteristics of semantic enrichment.",1,new
"By leveraging the capabilities of probabilistic graphical models (Jordan, 1998), we are able to model the intricate relationships between linguistic features and semantic enrichment, ultimately enhancing our understanding of this complex phenomenon.",1,new
"Deep Learning (DL) models, such as Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997) and Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), have demonstrated impressive capabilities in various NLP applications (Sutskever et al., 2011; Mikolov et al., 2010).",1,new
"The Naive Bayes algorithm (John and Langley, 1995) and the k-Nearest Neighbors (k-NN) method (Cover and Hart, 1967) have been successfully applied to text classification tasks (Lewis, 1998; Aha, 1997), showcasing their effectiveness in real-world scenarios.",1,new
"Decision Trees (DTs) (Breiman et al., 1984) and Random Forests (RFs) (Breiman, 2001) have proven to be valuable tools in handling high-dimensional data, with applications in regression analysis (Dietterich, 1998) and feature selection (Golub et al., 1999).",1,new
"5.4 The use of Support Vector Machines (SVMs) has been shown to be highly efcient in various machine learning tasks (Cortes & Vapnik, 1995), including text classifcation and regression analysis.",1,new
"3.1 The Naive Bayes algorithm has proven to be a reliable method for classifying text data, with a high degree of accuracy reported in several studies (Rennie et al., 2003).",1,new
"6.1 In recent years, the Random Forest algorithm has demonstrated its utility in multiple data mining applications, including decision tree induction and predictive modeling (Breiman, 2001).",1,new
"Maximum likelihood estimation techniques (Fisher, 1922; Cox & Hinkley, 1974) have been instrumental in uncovering the underlying patterns in complex data sets, providing a powerful framework for statistical inference that is both robust and flexible.",1,new
"The Bayesian approach (Jeffreys, 1961; Box & Tiao, 1973) has been successfully employed in a wide range of applications, including signal processing and image analysis, due to its ability to incorporate prior knowledge and uncertainty into the modeling process.",1,new
"The use of recursive algorithms (Koopmans, 1957; White, 1982) has revolutionized the field of econometrics, allowing for the estimation of complex dynamic systems and the identification of underlying relationships between variables.",1,new
"The utilization of cutting-edge deep learning architectures such as Convolutional Neural Networks (LeCun et al., 1998), Recurrent Neural Networks (RNNs) (Elman, 1990), and Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) has led to remarkable advancements in image classification tasks when sufficient high-quality training data is available.",1,new
"Recent breakthroughs in the field of natural language processing have been largely attributed to the adoption of sophisticated machine learning algorithms including Word2Vec (Mikolov et al., 2013), Latent Dirichlet Allocation (Blei et al., 2003), and Conditional Random Fields (Lafferty et al., 2001), which have significantly improved text classification accuracy when sufficient labeled data is accessible.",1,new
"The implementation of advanced regression techniques such as Gradient Boosting (Friedman, 2001), Random Forests (Breiman, 2001), and Gaussian Processes (Rasmussen and Williams, 2006) has yielded impressive results in predictive modeling, provided that sufficient high-quality data is available for training and validation.",1,new
"The decision tree algorithm (Breiman et al., 1984; Quinlan, 1986) has gained significant attention in machine learning due to its simplicity, interpretability, and impressive performance in classification tasks (Kohavi & John, 1997; Cestnik et al., 1996).",1,new
"The hidden Markov model (Rabiner, 1989; Jelinek, 1997) has been widely adopted in speech recognition systems due to its ability to capture temporal dependencies and provide robust performance in noisy environments (Lee, 1993; Juang & Rabiner, 1991).",1,new
"The support vector machine (Vapnik, 1995; Cortes & Vapnik, 1995) has become a popular choice in data classification tasks due to its ability to handle high-dimensional data and provide good generalization performance (Burges, 1998; Joachims, 1999).",1,new
"The incorporation of the recursive feature elimination method by Breiman et al (2001) enhances the efficiency of the model, as it systematically removes the least important features and refines the model's predictive accuracy.",1,new
"The implementation of the sequential forward selection algorithm by Kwak et al (1998) significantly improves the model's performance, as it adds features one by one and evaluates their impact on the overall model fit.",1,new
"The application of the backward elimination algorithm by Guyon and Elisseeff (2003) allows for a more robust model selection, as it iteratively removes features that are not significant and refines the model's parameters to achieve better predictive power.",1,new
"The optimal parameters for a maximum entropy parser can be determined by selecting a suitable set of features, which can be chosen using existing algorithms such as those proposed by Lafferty et al. (2001) and McCallum and Nigam (1998). The process of building a maximum entropy parser involves identifying the most informative features and assigning appropriate weights to them.",1,new
"Recent studies have shown that the performance of a maximum entropy parser can be significantly improved by incorporating additional features, such as part-of-speech tags and named entity recognition, as demonstrated by Ratnaparkhi (1996) and Berger (1996). The optimal parameters for the parser can be estimated using iterative scaling methods, as described by Darroch and Ratcliff (1972).",1,new
"The development of a maximum entropy parser relies heavily on the choice of features, which can be categorized into two types: normalization terms and feature functions. The former ensures that the output is a probability distribution, while the latter provides a way to represent the dependencies between variables. The optimal parameters for the parser can be estimated using maximum likelihood estimation, as shown by Berger et al. (1996), and can be used to improve the accuracy of part-of-speech tagging and other natural language processing tasks.",1,new
"The introduction of Support Vector Machines (SVMs) in the Machine Learning field (Vapnik, 1995) has led to significant advancements in classification accuracy across various datasets.",1,new
"The implementation of clustering algorithms in Data Mining (Han et al., 2001) has facilitated efficient data organization and analysis in numerous applications.",1,new
"The development of Genetic Programming (Koza, 1992) has enabled researchers to evolve effective solutions for complex optimization problems in multiple domains.",1,new
"The Hidden Markov Model (HMM) statistical framework (Rabiner, 1989; Juang and Rabiner, 1991) has been effectively utilized in various speech recognition applications.",1,new
"The Conditional Random Field (CRF) statistical framework (Lafferty et al., 2001; Sutton and McCallum, 2012) has been widely adopted in natural language processing tasks, including sentiment analysis and information extraction.",1,new
"The Support Vector Machine (SVM) algorithm (Cortes and Vapnik, 1995; Joachims, 1999) has been successfully employed in machine learning tasks, such as text classification and recommendation systems.",1,new
"The proposed algorithm demonstrates a notable improvement in convergence rate, with the time complexity reduced to O(n log n) for the k-means clustering process (Kanungo et al., 2002). Furthermore, the incorporation of sparse matrices enables efficient memory allocation.",1,new
"A novel approach to spectral clustering is presented, utilizing the graph Laplacian matrix to efficiently compute the eigenvectors (Shi & Malik, 2000). The resulting algorithm achieves a significant reduction in computational overhead, making it suitable for large-scale datasets.",1,new
"The development of a new optimization technique for sparse linear regression models is introduced, leveraging the L1 regularization method to minimize overfitting (Tibshirani, 1996). This approach yields a substantial improvement in model accuracy, particularly in high-dimensional feature spaces.",1,new
"Our proposed approach utilizes a support vector machine (Vapnik, 1995) to classify parser actions, enabling efficient and accurate parsing of the input data.",1,new
"The implementation employs a decision tree (Breiman, 2001) to determine parser decisions, resulting in a significant reduction in parsing time.",1,new
"By leveraging a logistic regression model (Hosmer & Lemeshow, 2000), we are able to efficiently classify parser actions and improve overall parsing performance.",1,new
"The application of neural networks in image recognition has been a pivotal area of research (LeCun et al., 1998), with significant advancements in accuracy (Krizhevsky et al., 2012) and a wide range of real-world applications.",1,new
"Bayesian networks have been extensively used in expert systems (Pearl, 1988) and have proven to be an essential tool for decision-making under uncertainty (Spiegelhalter et al., 1990).",1,new
"The use of decision trees in machine learning has been a cornerstone of data analysis (Breiman, 2001), allowing for the identification of complex relationships and patterns in large datasets (Friedman et al., 2000).",1,new
"Our study employed a dynamic programming approach (Cormen et al., 2009) to optimize the search space, resulting in a substantial reduction in computation time.",1,new
"In our implementation, we leveraged the efficient data structures proposed by Knuth (1973) to accelerate the processing of large datasets.",1,new
"By utilizing the optimal substructure property (Cormen et al., 2009), we were able to develop an algorithm that solved the problem in polynomial time, leading to significant performance improvements.",1,new
"A more advanced data preprocessing technique, akin to (Kohavi and John, 1997) or (Dietterich, 1998), would be necessary for this analysis to yield reliable results.",1,new
"The use of a more complex algorithm, similar to (Breiman, 2001) or (Friedman, 2001), would be beneficial in refining the model's performance in this context.",1,new
"Incorporating a more sophisticated statistical analysis, as demonstrated in (Hastie et al., 2001) or (James et al., 2013), would be essential for obtaining accurate conclusions from the data.",1,new
"Further information on the application of hidden Markov models in natural language processing can be found in (Rabiner, 1989) and (Young et al., 1994).",1,new
"For a more detailed analysis of the role of machine learning in computational linguistics, the reader is referred to (Mitchell, 1997) and (Sutton & Barto, 1998).",1,new
"Additional discussions on the implementation of maximum entropy methods in statistical language modeling can be found in (Chen & Rosenfeld, 1997) and (Jelinek, 1997).",1,new
"Our study employs the widely accepted Root Mean Square Coefficient (RMSE) (Willmott, 1982; Taylor, 2001) as a measure of model accuracy, commonly utilized in geospatial analysis (Gandin and Murphy, 1992).",1,new
"For data validation, we utilize the Nash-Sutcliffe efficiency coefficient (Nash and Sutcliffe, 1970; Legates and McCabe, 1999), a standard metric in hydrology research (Moriasi et al., 2007).",1,new
"In assessing the reliability of our findings, we adopt the Intra-Class Correlation Coefficient (ICC) (Shrout and Fleiss, 1979; Cicchetti, 1994), a widely used measure in medical statistics, particularly in studies involving categorical data (Hartung et al., 2008).",1,new
"Although the use of Bayesian inference has several benefits (e.g., it allows for the incorporation of prior knowledge), we also present the results of maximum likelihood estimation as it provides a useful baseline for comparison with the more computationally intensive Bayesian approach described below, whose results will also be reported in the context of maximum likelihood estimation.",1,new
"In order to facilitate a comprehensive understanding of the model's performance, we report both the mean squared error and the mean absolute error, despite the fact that the mean squared error has the advantage of being more sensitive to large errors (see Williams (2013) for a detailed discussion); this allows us to gain a more nuanced view of the model's behavior.",1,new
"While the use of regularization techniques has several advantages (e.g., it can help prevent overfitting), we also present the results of unregularized models as it provides a useful benchmark for evaluating the impact of regularization on the model's performance, whose effects will also be reported in the context of the regularized models described below.",1,new
"The introduction of the concept of ""transcription quality"" by Nancy Henley (2001) has significantly impacted the field of linguistic analysis, leading to a more nuanced understanding of spoken language data.",1,new
"Following the work of William Labov (1972), which highlighted the importance of sociolinguistic factors in shaping language variation, researchers have increasingly incorporated these variables into their studies, resulting in a more comprehensive understanding of language in use.",1,new
"The development of the ""discourse analysis"" framework by Norman Fairclough (1992) has been widely adopted in the field of communication studies, allowing researchers to examine the complex relationships between language, power, and social context.",1,new
"The inter-rater reliability of our model was assessed using the Fleiss' kappa statistic, a common measure of agreement in categorical data analysis (Fleiss, 1971).",1,new
"To evaluate the consistency of our results, we calculated the Cohen's kappa coefficient, a widely accepted metric for measuring inter-rater reliability in social sciences (Cohen, 1960).",1,new
"We evaluated the inter-annotator agreement using the Scott's pi statistic, a robust measure of agreement for categorical data that takes into account the marginal distributions of the annotators (Scott, 1955).",1,new
"As noted by O'Hagan (1995), the current approaches to evaluating the reliability of machine learning models have overlooked the significance of assessing the variability in human judgments.",1,new
The critique by Light (1971) on the limitations of existing methods for evaluating speech recognition systems highlights the need for a more nuanced understanding of the relationship between system performance and human error.,1,new
"According to Resnik (1999), the evaluation metrics commonly used in natural language processing have been criticized for their inability to capture the complexity of human language use, leading to a call for more sophisticated assessment methods.",1,new
"The efficiency of our proposed algorithm is due to the fact that the structural characteristics of the input data naturally limit the search space, resulting in remarkable accuracy for predicting protein-ligand binding affinities using a simple machine learning model (Klein 2018).",1,new
"The unique features of the neural network architecture employed in our study lead to a significant reduction in the complexity of the optimization problem, yielding outstanding results for image classification tasks without the need for extensive data augmentation (Zhang et al. 2020).",1,new
"The inherent properties of the graph-based representation used in our model allow for a natural and intuitive encoding of the semantic relationships between entities, resulting in impressive performance for question answering tasks using a knowledge graph alone (Liu et al. 2019).",1,new
"The results of various studies on phrase extraction algorithms have consistently shown that they can effectively capture syntactic and semantic relationships between words in different languages (Marcus, 1998; Collins, 1999; Knight, 2001).",1,new
"The findings of research on machine translation models have demonstrated that they can successfully handle the complexities of word order variation across languages (Koehn, 2005; Och, 2003; Fraser, 2008).",1,new
"Investigations into the performance of statistical machine translation systems have revealed that they can efficiently process and generate accurate translations for a wide range of language pairs (Brown, 1990; Chen, 1997; Zhang, 2002).",1,new
"The introduction of phrase-based (Garca et al., 2009; Liu et al., 2010; Chiang, 2012) and syntax-based (Wu et al., 1996; Yamada and Knight, 2001; Eisner, 2003; Marcu et al., 2006; Cowan et al., 2007; Liu et al., 2008; Zhang et al., 2009, 2010a, 2010b; Shen et al., 2011; Mi and Huang, 2011) methods has significantly contributed to the advancements in statistical machine translation (SMT).",1,new
"The development of phrase-based (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntax-based (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) techniques has been a crucial factor in the progress of machine translation.",1,new
"The integration of phrase-based (Gmez et al., 2012; Liu et al., 2012; Chiang, 2013) and syntax-based (Wu et al., 1997; Yamada and Knight, 2001; Eisner, 2003; Marcu et al., 2006; Cowan et al., 2007; Liu et al., 2008; Zhang et al., 2009, 2010a, 2010b; Shen et al., 2011; Mi and Huang, 2011) approaches has led to significant improvements in the field of statistical machine translation (SMT).",1,new
"The use of 2.2 ITG Space Inversion Transduction Grammars, or ITGs (Wu, 1997) has significantly enhanced our ability to model complex linguistic phenomena in machine translation (MT) systems.",1,new
"The development of ITG Space Inversion Transduction Grammars, or ITGs (Wu, 1997) has led to notable advancements in the field of synchronous parsing, particularly in the context of bitext processing.",1,new
"Our research has shown that 2.2 ITG Space Inversion Transduction Grammars, or ITGs (Wu, 1997) offer a powerful tool for capturing the nuances of language structure, thereby improving the accuracy of machine translation models.",1,new
"The work of Hawkins (2005, 2010) significantly advanced the field of machine translation by exploring the use of corpus-based alignment methods to improve sentence-level alignment accuracy and facilitate more efficient translation processing.",1,new
"Lee et al. (2012, 2015) made a crucial contribution to the development of neural machine translation systems, demonstrating the effectiveness of incorporating contextualized representations in encoder-decoder models to enhance translation quality and reduce errors.",1,new
"In a groundbreaking study, Yang (2009, 2013) investigated the application of statistical machine translation techniques to low-resource languages, demonstrating the potential for improved translation accuracy and increased language coverage through the use of parallel corpora and large-scale training data.",1,new
"Several approaches have been explored to design efficient reordering policies, such as the use of phrase-based machine translation (Koehn, 2004) and the application of Lexicalized Tree-Adjoining Grammar (Vijay-Shanker and Weir, 1994).",1,new
"Recent studies have proposed innovative reordering techniques, including the exploitation of contextual information in statistical machine translation (Zhang and Gildea, 2005) and the employment of Tree Substitution Grammar (Klein and Manning, 2004).",1,new
"Researchers have also investigated the development of reordering strategies based on syntactic and semantic features, such as the use of Head-Driven Phrase Structure Grammar (Pollard and Sag, 1994) and the application of Dependency-Based Machine Translation (Nivre and Schach, 2004).",1,new
"This finding is supported by Chen et al. (2019), who demonstrated that incorporating semantic role labeling into the alignment process enables more accurate and efficient parsing of sentence structures.",1,new
"Our results are consistent with those of Patel (2001), who found that incorporating syntactic constraints into the alignment algorithm results in a substantial reduction in computational time without compromising accuracy.",1,new
"Similarly, the work of Kim et al. (2020) shows that limiting the scope of alignment to specific linguistic features, such as dependency parsing, can lead to a significant improvement in alignment quality and a notable decrease in computational complexity.",1,new
"The use of a phrase-based model (Chang, 2012) and a weighted finite-state transducer (WFST) (Mohri, 1997) resolves the problem by allowing for a more efficient parsing of linguistic structures.",1,new
"In the stochastic context-free grammar (SCFG) model (Jelinek, 1998) and the maximum entropy model (MEMM) (McCallum, 2003), the issue is resolved through the application of a constrained optimization technique.",1,new
"The incorporation of a probabilistic context-free grammar (PCFG) (Johnson, 1988) and a dependency tree (DTree) (Kaplan, 1995) facilitates the resolution of the problem by providing a more nuanced understanding of linguistic dependencies.",1,new
"Similarly, studies by Smith (2001) have shown that in languages with a simple grammatical structure, such as Japanese and Korean, the effectiveness of hierarchical alignment is consistently observed, with no notable instances of failure. (p. 217)",1,new
"In a comprehensive analysis of linguistic data, Johnson (2015) found that in highly inflected languages like Arabic and Russian, hierarchical alignment consistently produces accurate results, with no reported cases of failure. (p. 102)",1,new
"According to research by Brown (1999), the application of hierarchical alignment in languages with a fixed word order, such as German and Italian, has been successful in most cases, with no documented instances of significant errors or failures. (p. 456)",1,new
"The Transformational Generative Grammar approach, as outlined in (Kim, 2001), has proven to be highly effective for our analysis.",1,new
"The use of the Context-Free Grammar formalism, as discussed in (Brown, 1988), has greatly facilitated our understanding of the system's behavior.",1,new
"The Augmented Transition Network (ATN) model, described in (Woods, 1970), has been instrumental in enabling us to model complex linguistic patterns.",1,new
"Smith (2015) demonstrates a novel approach to optimizing network topology, thereby allowing for improved computational efficiency.",1,new
"The research by Lee et al. (2020) offers a groundbreaking solution for enhancing data accuracy, which has significant implications for future studies.",1,new
"According to recent findings by Patel and Kumar (2019), the implementation of their proposed algorithm has led to a substantial reduction in processing time, making it a valuable contribution to the field.",1,new
"2 Introduction For information retrieval tasks, relevance feedback-based methods (Rocchio et al., 1971; Salton and McGill, 1983) and probabilistic methods (Buckley and Lewit, 1995; Lavrenko et al., 2001; Song and Croft, 1999) consistently outperform query expansion methods (Salton, 1971; Voorhees, 1985).",1,new
"3 Analysis For speech recognition, Hidden Markov Model (HMM) methods (Rabiner, 1989; Juang and Rabiner, 1991; Jelinek, 1997) and dynamic time warping (DTW) methods (Kam et al., 2003; Chen et al., 2006) exhibit superior performance over neural network methods (Waibel et al., 1988; Waibel and Lee, 1990).",1,new
"4 Discussion For natural language processing (NLP), maximum entropy (MaxEnt) models (Berger et al., 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997) and support vector machines (SVMs) (Joachims, 1999; Joachims, 2002) demonstrate better results than traditional n-gram models (Church and Hanks, 1990; Manning and Schutze, 1999).",1,new
"The advancements in machine learning have led to the development of numerous neural network-based approaches to tackle the challenges in sentiment analysis (Socher et al., 2013; Maas et al., 2011; Collobert et al., 2011; Turian et al., 2010; Zhang and Wallace, 2015; Severyn and Moschitti, 2015; Wang et al., 2012; Mikolov et al., 2010; Goldberg and Elkhawarg, 2010; Lai et al., 2015; Huang et al., 2014; Jozefowicz et al., 2016).",1,new
"Recent studies have focused on improving the accuracy of language translation models using various techniques, including the incorporation of linguistic features (Melamed, 2001; Koehn, 2004; Och and Ney, 2003; Papineni et al., 2002; Callison-Burch et al., 2006; Koehn, 2005; Crego et al., 2005; Li and Monz, 2006; Jones et al., 2006; Quirk et al., 2005).",1,new
"The growing interest in natural language processing has led to the development of novel approaches for named entity recognition, including the use of machine learning algorithms and statistical models (Ratinov and Roth, 2009; Finkel et al., 2005; Finkel et al., 2008; Gupta and Manning, 2014; Santos et al., 2015; Collobert et al., 2011; Ma et al., 2016; Li et al., 2016; Bjrkelund et al., 2010).",1,new
"2 Background In the realm of natural language processing, the advent of Syntax-based Statistical Machine Translation (SSMT) has gained significant attention since its introduction by (Koehn et al., 2003).",1,new
"3 Methodology The application of Dynamic Grammar Inference (DGI) in machine translation, as proposed by (Zhang et al., 2015), has shown promising results in improving translation accuracy.",1,new
"5 Discussion The employment of Statistical Machine Translation with Deep Learning (SMT-DL) framework, introduced by (Luong et al., 2015), has led to substantial advancements in the field of machine translation research.",1,new
"The development of FrameNet (Baker et al., 1998) laid the groundwork for the analysis of semantic roles in linguistic structures, enabling researchers to better understand the nuances of word relationships.",1,new
"Building on the work of (Katz & Fodor, 1963), the theory of Generative Semantics provided a framework for the study of deep syntactic structures, paving the way for further investigations into the nature of linguistic meaning.",1,new
"The influential study by (Chomsky, 1957) on the generative capacity of language introduced the concept of transformational grammar, which has since been widely applied in the field of linguistics to explain the complexity of human language.",1,new
"The issue of inconsistent data sampling has been addressed by several researchers, including Smith (2010) and Lee (2015), whose findings we will examine in the following section.",1,new
"The limitations of the model have been acknowledged and rectified by various studies, such as those conducted by Johnson (2002) and Kim (2018), which we will discuss in detail below.",1,new
"Several authors have identified and resolved the problem of biased estimation, including Thompson (2009) and Martin (2012), whose work will be summarized and built upon in this review.",1,new
"Several studies have demonstrated significant improvements in word sense disambiguation for lexicalized grammar-based machine translation systems (Resnik, 1998; Clark et al., 1994; Gale and Church, 1991; Mihalcea and Chklovski, 2004; Pedersen et al., 2004), yielding notable advancements in the field.",1,new
"Research has shown substantial gains in machine translation accuracy for statistical models incorporating semantic role labeling (Carreras et al., 2002; Gildea and Jurafsky, 2002; Gildea and Jurafsky, 2002; Palmer et al., 2005; Carroll et al., 2003), leading to more effective translation outcomes.",1,new
"A number of studies have reported positive outcomes for syntax-based machine translation systems that utilize dependency parsing (Bikel et al., 2007; Kurohashi and Matsumoto, 2000; Miyao and Tsujii, 2008; Naseem et al., 2009; Huang and Harper, 2000), indicating a notable step forward in translation technology.",1,new
"Utilizing machine learning techniques, such as neural networks, to enhance the accuracy of linguistic parsing, as proposed by [Brown et al. 1992].",1,new
"Further improvements could be achieved by implementing a more sophisticated tokenization method, similar to the one outlined in [Marcus et al. 1993].",1,new
"The incorporation of probabilistic models, as discussed in [Charniak 1997], could also lead to more effective parsing strategies for natural language processing.",1,new
"The development of deep learning models has seen significant progress in recent years [LeCun et al., 2015; Szegedy et al., 2016], however, their application to low-resource machine translation has been met with limited success [Zoph et al., 2016].",1,new
"Although impressive advances have been made in the field of neural machine translation [Bahdanau et al., 2014; Sutskever et al., 2014], the performance of such systems when relying on limited training data has been found to be subpar [Grissom et al., 2015].",1,new
"While notable progress has been achieved in the area of speech recognition [Hinton et al., 2012; Dahl et al., 2012], the deployment of such systems in noisy environments has been reported to be challenging [Povey et al., 2011].",1,new
"Furthermore, as highlighted by Lee et al. (2015), the unique feature of hybrid models allows for the efficient combination of multiple independent sub-models, effectively boosting their overall predictive capabilities.",1,new
"According to Rodriguez (2002), the notable characteristic of Bayesian networks is their ability to capture complex relationships between variables, thereby facilitating a more accurate understanding of the underlying system dynamics.",1,new
"As noted by Kim (2008), the distinctive property of wavelet transforms is their capacity to decompose signals into their constituent frequency components, enabling more precise analysis and interpretation of the data.",1,new
"A novel optimization technique utilizing a beam search algorithm is introduced in (Brown et al., 2019) to improve the efficiency of parsing models.",1,new
"The proposed algorithm, which leverages a combination of chart parsing and dynamic programming, is described in (Lee, 2003) to efficiently parse complex sentence structures.",1,new
"In a recent study, a new parsing algorithm that employs a stochastic approach and is based on a probabilistic grammar is presented in (Kim et al., 2015), showcasing significant improvements in parsing accuracy.",1,new
"The use of dynamic programming in Section 3 is analogous to the hierarchical task network approach to planning described in (Kautz & Selman, 1996): both methods significantly improve efficiency by decomposing complex problems into more manageable sub-problems.",1,new
"The incorporation of beam search in Section 5 is reminiscent of the parse reranking technique described in (Collins, 2003): in both cases, the addition of a scoring function enables the identification of more accurate parsing structures.",1,new
"The application of graph-based methods in Section 2 is related to the stochastic context-free grammar approach to language modeling described in (Charniak, 1997): both frameworks lead to a substantial reduction in computational complexity and an improvement in parsing accuracy.",1,new
"The Linear Indexed Grammar (LIG) framework, introduced by Yamada (2002), has been extensively utilized for parsing complex sentence structures.",1,new
"The Context-Free Grammar (CFG) formalism, as proposed by Chomsky (1957), remains a cornerstone in the field of formal language theory.",1,new
"The Regular Expression Grammar (REG) model, developed by Thompson (1968), has been widely adopted for its simplicity and efficiency in pattern matching applications.",1,new
"The application of machine learning algorithms to natural language processing tasks has yielded promising results (Bengio et al., 2003; Collins, 2004).",1,new
"Recent studies have shown that deep neural networks can improve the efficiency of text classification tasks (Krizhevsky et al., 2012; Socher et al., 2011).",1,new
"The use of transfer learning in computer vision has been successfully implemented in various applications (Yosinski et al., 2014; Donahue et al., 2014).",1,new
"To date, the most notable implementation of natural language processing in a helpdesk setting is attributed to the pioneering work of Searle and Weinberg (2003).",1,new
"The existing literature on human-computer dialogue systems is largely limited to a single notable instance, as described in the work of Grosz and Sidner (1986).",1,new
"Despite the lack of comprehensive frameworks, the work by Allen and Perrault (1980) remains a crucial milestone in the development of natural language-based customer service systems.",1,new
"The breakthroughs in Deep Learning have catalyzed a thriving line of research that tackles sentiment analysis and opinion mining primarily as a natural language processing challenge (e.g., Liu et al., 2010; Wiebe et al., 2005; Turney & Lui, 2013; Pak & Paroubek, 2010).",1,new
"The success of Human-Computer Interaction has inspired a prolific line of investigation that views information retrieval and question answering essentially as a multilingual machine learning problem (e.g., Baeza-Yates & Ribeiro, 2017; Manning et al., 2008; Soricut & Marcu, 2004; Lee et al., 2008).",1,new
"The advancements in Natural Language Processing have driven a vibrant line of research that treats text classification and topic modeling primarily as a monolingual machine learning challenge (e.g., Sebastiani, 2002; McCallum & Nigam, 1998; Ng & Jordan, 2002; Wang et al., 2007).",1,new
"This approach resolves the issue of template creation from examples, thereby streamlining the subsequent stages of the generation process (GOLDWASSER et al., 2016).",1,new
"By employing this method, researchers can efficiently bypass the challenges associated with template-based generation (VINYALS et al., 2015).",1,new
"The proposed solution effectively mitigates the limitations of template-based generation, enabling more streamlined and efficient model development (BENGIO et al., 2013).",1,new
"Recent advances in Natural Language Processing (NLP) have led to the widespread adoption of the Expectation-Maximization algorithm (Dempster et al., 1977; McLachlan & Krishnan, 2008) in clustering and classification tasks as depicted in Figure 2.",1,new
"The implementation of the Gaussian Mixture Model (GMM) has been a cornerstone of many speech recognition systems, leveraging the work of Everitt & Hand (1981) and McLachlan (1992) as illustrated in Figure 3.",1,new
"The use of Hidden Markov Models (HMMs) has revolutionized the field of speech recognition, building upon the foundational work of Rabiner & Juang (1993) and Jelinek (1997) as demonstrated in Figure 4.",1,new
"The advent of neural machine translation (NMT) (Vaswani et al., 2017) has revolutionized the field of machine translation, providing more accurate and efficient translation results.",1,new
"The development of rule-based machine translation (RBMT) (Brown et al., 1990) has been a significant milestone in the history of machine translation, enabling the creation of high-quality translation systems.",1,new
"The introduction of example-based machine translation (EBMT) (Brown et al., 1988) has greatly improved the performance of machine translation systems, allowing for more accurate and context-specific translation results.",1,new
"Our research employs a cutting-edge neural machine translation system inspired by the work of (Wu et al., 2016; Sutskever et al., 2014) to achieve high-quality language translation.",1,new
"In this study, we utilize an advanced statistical machine translation model comparable to (Koehn, 2005; Brown et al., 1990) to investigate the impact of linguistic diversity on translation accuracy.",1,new
"For language processing tasks, we rely on a sophisticated deep learning approach, similar to (Bengio et al., 2003; Collobert et al., 2011), to improve the efficiency and effectiveness of our system.",1,new
"The recent breakthroughs in natural language processing have been attributed to the development of advanced neural networks trained on large-scale datasets, as demonstrated by (Bengio et al., 2006; Mnih et al., 2013; Collobert et al., 2011).",1,new
"The significant improvements in image classification have been achieved through the application of deep learning techniques, such as convolutional neural networks (LeCun et al., 1998; Krizhevsky et al., 2012; Sermanet et al., 2014).",1,new
"The recent advancements in speech recognition have been made possible by the use of context-dependent acoustic models, as shown in (Acero et al., 2009; Povey et al., 2011; Hinton et al., 2012).",1,new
"The incorporation of word-based models, such as the IBM model (Brown et al., 1990; Brown et al., 1992), has significantly contributed to the advancement of statistical machine translation.",1,new
"The use of generative models, including the hierarchical hidden Markov model (HMM) (Bahl et al., 1983; Juang et al., 1990), has been instrumental in the development of speech recognition systems.",1,new
"The employment of decision trees, as seen in the work of Quinlan (1986) and Quinlan (1993), has been a crucial aspect of the development of machine learning algorithms for classification tasks.",1,new
"Dynamic programming has been successfully applied to various sequence alignment problems (Needleman & Wunsch, 1970; 567). Inputs: two sequences (x, y) Initialization: create a 2D matrix M of size (n+1) x (m+1) Algorithm: // fill the matrix M for i = 0 to n and j = 0 to m: if i = 0 or j = 0, M[i,j] = 0 else: M[i,j] = max(M[i-1,j-1] + score(x_i,y_j), max(M[i-1,j], M[i,j-1])) Outputs: the value stored in M[n,m] Figure 1: The dynamic programming algorithm for sequence alignment (Gotoh, 1982), and can achieve efficiency that is comparable to other algorithms.",1,new
"The Viterbi algorithm has been widely used in Hidden Markov Models (HMMs) for sequence labeling tasks (Rabiner, 1989; 654). Inputs: an HMM with states (q1, q2,..., qN) and observations (x1, x2,..., xT) Initialization: create a 2D matrix D of size N x T Algorithm: // compute the probabilities for t = 1 to T: for each q: compute the probability of the observation x_t given the state q D[q,t] = max(D[q,t-1] * P(x_t|q)) Outputs: the state sequence q1, q2,..., qT Figure 1: The Viterbi algorithm (Baum & Eagon, 1967), and can achieve accuracy that is higher than other sequence labeling algorithms.",1,new
"The EM algorithm has been successfully applied to clustering problems (Dempster et al., 1977; 621). Inputs: a dataset X Initialization: choose an initial model M0 Algorithm: // repeat for k = 1 to K: compute the expected log-likelihood of the data given the current model E-step: compute the expected value of the log-likelihood of the data given the current model M_k M_k = E[log(P(X|M)) | M] M' = argmax_M E[log(P(X|M))] M' = M_k + 1 Outputs: the final model M Figure 1: The EM algorithm (Wu, 1983), and can achieve convergence that is faster than other clustering algorithms.",1,new
"Recent advancements in natural language processing (NLP) have led to the development of sophisticated text classification models (Lewis et al., 1992; Riloff and Jones, 1999; McCallum and Nigam, 1998), which have greatly improved the accuracy of various NLP applications.",1,new
"Over the past two decades, numerous studies have focused on refining the performance of machine learning algorithms (Domingos, 1996; Mitchell, 1997; Langley et al., 1987), resulting in significant improvements in predictive modeling and decision-making.",1,new
"The field of information retrieval has seen substantial progress with the introduction of novel ranking algorithms (Sullivan and Jones, 1992; Salton and McGill, 1983; van Rijsbergen, 1979), enabling more effective search and retrieval of relevant information from large databases.",1,new
"2 Recent advancements in natural language processing have been propelled forward by the incorporation of novel linguistic features and the refinement of optimization techniques.2 This progress is largely attributed to the shift towards probabilistic formalisms, which have enabled the development of efficient inference algorithms, such as those presented by (Brown et al., 1990) and (Viterbi, 1967).",1,new
"3 The field of sentiment analysis has witnessed significant breakthroughs in recent years, primarily due to the employment of sophisticated feature engineering and the application of advanced machine learning methodologies.3 These innovations have been built upon the foundational work of (Turney, 2002) and (Pang and Lee, 2008), who demonstrated the potential of data-driven approaches to sentiment analysis.",1,new
"4 The study of text classification has made substantial strides with the integration of semantic role labeling and the development of discriminative models.4 By leveraging the insights of (Gildea and Jurafsky, 1998) and (Collins, 1999), researchers have been able to design more accurate and efficient classification algorithms, leading to improved performance in various NLP tasks.",1,new
"The recent advancements in deep learning techniques (Bengio et al., 2003; Collobert et al., 2006; Mikolov et al., 2010) and neural machine translation (NMT) models (Bahdanau et al., 2015; Sutskever et al., 2014; Vaswani et al., 2017) represent the cutting-edge methodologies in natural language processing (NLP).",1,new
"The state-of-the-art approaches in data-driven machine translation (Bahl et al., 2006; Tillmann et al., 2008; Liu et al., 2010) and statistical machine translation (SMT) (Och and Ney, 2004; Koehn et al., 2007; Zhang et al., 2008c, 2009a, 2009b) have significantly improved the accuracy of translation systems.",1,new
"The recent progress in neural machine translation (NMT) (Bahdanau et al., 2015; Sutskever et al., 2014; Vaswani et al., 2017), particularly the development of transformer-based models (Vaswani et al., 2017; Liu et al., 2019; Devlin et al., 2019), has led to remarkable improvements in translation quality and efficiency.",1,new
"The use of contextualized embeddings (Peters et al., 2018) has significantly improved the accuracy of machine translation systems, enabling them to capture subtle nuances in language. This is achieved by computing the weighted sum of contextualized word representations, which are obtained by applying self-attention mechanisms to the input sequence.",1,new
"The incorporation of pre-trained language models (Devlin et al., 2019) has revolutionized the field of natural language processing, allowing for more accurate and robust text classification models. By leveraging pre-trained weights, these models can capture complex linguistic patterns and relationships, leading to improved performance on a variety of tasks.",1,new
"In addition to statistical machine translation, neural machine translation (Sutskever et al., 2014) has also been widely adopted due to its ability to learn complex patterns in language. By employing an encoder-decoder architecture with attention mechanisms, NMT systems can generate more fluent and accurate translations, outperforming traditional statistical models in many cases.",1,new
"The latest advancements in natural language processing heavily depend on the availability of large-scale annotated datasets, as demonstrated by the work of Manning and Schtze (1999), Bird and Liberman (2001), and De Marneffe et al. (2006).",1,new
"High-precision speech recognition systems require sophisticated acoustic modeling techniques, which have been extensively explored by the research of Bilmes and Bartlett (2004), Young et al. (2006), and Hinton et al. (2012).",1,new
"State-of-the-art image classification models heavily rely on the development of robust feature extraction methods, as evident in the works of LeCun et al. (1998), Krizhevsky et al. (2012), and Simonyan and Zisserman (2014).",1,new
"For our analysis, we selected the Moses (Koehn et al., 2007) and the grow-diag (Li et al., 2011) approaches as the most effective machine translation combination techniques. Our study utilizes these systems to investigate their performance on various linguistic datasets.",1,new
"In our research, we employed the HMM (Rabiner, 1989) and the IBM Model 4 (Brown et al., 1993) as the primary statistical translation models. These models were chosen for their ability to handle complex linguistic phenomena and provide accurate results.",1,new
"We utilized the phrase-based SMT (Koehn et al., 2007) and the hierarchical phrase-based SMT (Chen and Pad, 2013) as our primary machine translation systems. These approaches were selected for their efficiency and ability to capture subtle nuances in language.",1,new
"The majority of the current NLP models rely heavily on the integration of deep learning techniques (Hinton et al., 2006; Rumelhart et al., 1986; Sejnowski et al., 1986; Waibel et al., 1989; Waibel et al., 1989; Zhang et al., 2008).",1,new
"Recent advancements in computer vision have largely been driven by the application of convolutional neural networks (CNNs) (LeCun et al., 1989; LeCun et al., 1998; LeCun et al., 1998; LeCun et al., 1998; LeCun et al., 1998; Lecun et al., 1989).",1,new
"Modern speech recognition systems have significantly benefited from the incorporation of acoustic modeling using Hidden Markov Models (HMMs) (Bakis et al., 1994; Rabiner and Juang, 1993; Rabiner and Juang, 1993; Rabiner and Juang, 1993; Rabiner and Juang, 1993; Vintsyuk, 1968).",1,new
"Although recent advancements in neural machine translation have shown promising results (Vaswani et al., 2017), we leverage the efficiency of subword-based modeling in our implementation, building upon the work of Sennrich et al. (2016) and Sennrich et al. (2017).",1,new
"Despite the limitations of traditional statistical machine translation, our approach exploits the strengths of word embeddings to achieve improved translation quality, as demonstrated by Mikolov et al. (2013) and Le & Mikolov (2014).",1,new
"In the context of spoken language translation, we draw upon the insights of speech recognition research to inform our system design, incorporating the findings of Dahl et al. (2012) and Dahl et al. (2013) to enhance the accuracy of our speech-to-text module.",1,new
"Our results indicate that the proposed method outperforms the baseline models, including the widely used word-based model (Collins, 2003) and the recently introduced neural model (Vaswani et al., 2017).",1,new
"The newly developed phrase-based model significantly surpasses the performance of the context-free grammar model (Gazdar et al., 1985) and the rule-based model (Mel'uk, 1988), demonstrating its effectiveness in capturing linguistic nuances.",1,new
"In comparison to the state-of-the-art models, such as the probabilistic model (Charniak, 1996) and the hybrid model (Ratnaparkhi, 1996), our approach yields superior results, highlighting its potential for real-world applications.",1,new
The development of modern NLP models is heavily reliant on the advancements in machine learning algorithms (Bengio et al. 2003; Weston et al. 2010; Collobert et al. 2011).,1,new
"The field of speech recognition has seen significant progress in recent years, largely due to the integration of deep learning techniques (Hinton et al. 2006; Dahl et al. 2012; Sainath et al. 2013).",1,new
Contemporary research in natural language processing has been greatly influenced by the integration of cognitive psychology and computational models (Lakoff 1970; Levelt 1989; Clark 1996).,1,new
"Our findings are in line with those of (Hutchins, 1990), who demonstrated that incorporating idiomatic expressions into machine translation systems significantly enhances translation accuracy, particularly when dealing with colloquialisms and figurative language.",1,new
"Similarly, (Melamed, 2004) showed that allowing for the translation of idiomatic phrases (such as kick the bucket and break a leg) is crucial for achieving high-quality translations, as it enables the capture of nuanced cultural and contextual information.",1,new
"In a related study, (Chen et al., 2018) found that permitting the translation of phrasal verbs (like get along and pick up) leads to substantial improvements in translation performance, particularly in scenarios where literal translations would be nonsensical or ungrammatical.",1,new
"Recent advancements in neural network architectures have significantly improved the performance of rule-based machine translation systems (Brown et al., 1990; Melamed et al., 2003; Callison-Burch et al., 2004), surpassing the results of earlier statistical approaches.",1,new
"The development of hybrid machine translation systems, combining the strengths of statistical and rule-based methods, has led to impressive gains in translation accuracy (Koehn et al., 2003; Hutchins, 1986; Gale et al., 1993), outperforming traditional rule-based systems in various language pairs.",1,new
"In recent years, the application of deep learning techniques to machine translation has yielded remarkable improvements in translation quality (Sutskever et al., 2014; Luong et al., 2015; Vaswani et al., 2017), pushing the boundaries of what is achievable in statistical machine translation.",1,new
"The field of sentiment analysis has witnessed substantial growth with the development of deep learning techniques (Socher et al., 2013; Collobert et al., 2011; Ma and Hovy, 2016).",1,new
"Recent advances in natural language processing have significantly improved the accuracy of text summarization, particularly with the introduction of graph-based methods (Gillick and Cox, 2009; Nallapati et al., 2016; Cheng and Lapata, 2016).",1,new
"The application of neural networks to information retrieval has led to considerable improvements in search engine performance, as demonstrated by the work of (Mnih et al., 2014; Severyn and Moschitti, 2015; Shen et al., 2014).",1,new
"This finding aligns with our expectations, as sequence-to-sequence models like NMT (Sutskever et al., 2014) often achieve superior results when using longer input sequences.",1,new
"The proposed approach exhibits several advantages, particularly in its ability to leverage the strengths of rule-based systems like Moses (Koehn et al., 2007), which excel in low-resource settings.",1,new
"We believe that the integration of neural machine translation and phrase-based models, as seen in the work of Bahdanau et al. (2015), holds great promise for future improvements in translation accuracy.",1,new
"Most recent advancements in machine learning-based speech recognition systems still rely heavily on traditional acoustic models and hand-engineered feature extraction methods, rather than leveraging the full potential of deep learning architectures (e.g., Dahl et al., 2012; Hinton et al., 2012; Mohamed et al., 2012).",1,new
"Contemporary neural machine translation systems often rely on pre-trained word embeddings and rely on general-purpose phrase translation models to handle structural elements, rather than incorporating language-specific grammatical knowledge (e.g., Devlin et al., 2018; Vaswani et al., 2017; Wu et al., 2016).",1,new
"Many current natural language processing frameworks fail to effectively distinguish between functional and content words, and instead utilize generic language models to generate grammatical elements, such as context-dependent articles and prepositions (e.g., Mikolov et al., 2013; Sutskever et al., 2014; Cho et al., 2014).",1,new
"A novel approach to machine learning utilizes a combination of word embeddings and syntax trees to generate a comprehensive set of potential translations for each input sentence, along with corresponding feature values that facilitate the selection of the most accurate translation (Mikolov et al., 2013).",1,new
"The methodology employed by the Phrase-Based Machine Translation system (PBM-T) involves creating a large inventory of phrase pairs that are used to construct a robust set of potential translations for each input sentence, along with feature values that aid in the selection of the best translation from this set (Och & Ney, 2002).",1,new
"A recent study on statistical machine translation proposes the use of a large set of phrase pairs, along with associated feature values, to generate a comprehensive set of potential translations for each input sentence, enabling the selection of the most suitable translation (Brown et al., 1993).",1,new
"We compared our proposed model to a widely-used baseline, the state-of-the-art machine translation system, Moses (Koehn et al., 2007; Och and Ney, 2002), to evaluate its performance.",1,new
"In this study, we contrasted our novel approach with a traditional method, the rule-based machine translation system, Verbmobil (Appelt et al., 1997; Hahn et al., 1997), to assess its effectiveness.",1,new
"To evaluate the efficacy of our new algorithm, we pitted it against a well-established system, the statistical machine translation system, IBM Model 5 (Brown et al., 1990; Brown et al., 1993), which has been a benchmark for many years.",1,new
"The results demonstrate a notable advancement in accuracy, with a 30.5% gain in BLEU score from 24.1% to 54.6%, outperforming a state-of-the-art phrase-based system (Koehn et al., 2007) in machine translation tasks.",1,new
"The proposed approach yields a substantial improvement in translation quality, achieving a 27.9% increase in BLEU score from 22.5% to 50.4% when compared to a widely used rule-based system (Melamed, 2001), indicating a significant enhancement in machine translation capabilities.",1,new
"The experimental results show a considerable improvement in translation accuracy, with a 25.8% boost in BLEU score from 20.2% to 46.0%, surpassing a phrase-based system (Och & Ney, 2002) in terms of its ability to translate complex sentences accurately.",1,new
"The development of hybrid models (Vilar et al., 2007; Hwang and Lee, 2009; Li et al., 2010) has led to significant improvements in machine translation performance, outperforming traditional statistical models.",1,new
"Recent studies (Joshi et al., 2011; Chiang, 2005; Callison-Burch et al., 2007) have demonstrated the effectiveness of neural machine translation systems, showcasing their potential as a robust alternative to rule-based approaches.",1,new
"Advances in deep learning techniques (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) have enabled the development of highly accurate and efficient machine translation systems, offering a promising solution for real-world applications.",1,new
"Recent advances in neural machine translation have significantly enhanced the accuracy of translation systems by incorporating word embeddings (Collobert et al., 2011; Mikolov et al., 2013; Devlin et al., 2019).",1,new
"The development of novel deep learning architectures has led to substantial improvements in the quality of machine translation systems, particularly in handling rare words and out-of-vocabulary items (Bahdanau et al., 2015; Luong et al., 2015; Vaswani et al., 2017).",1,new
"Significant progress has been made in the field of statistical machine translation by leveraging large-scale parallel corpora and sophisticated algorithmic techniques (Brown et al., 1993; Brown et al., 1990; Melamed et al., 2003).",1,new
"The recent development of decision tree models (Quinlan, 1986; Breiman et al., 1984; Amit and Geman, 1997) has significantly improved upon the traditional rule-based systems (Clancey and Buchanan, 1988) by providing a more robust and flexible approach to classification, as demonstrated by various empirical studies.",1,new
"The introduction of support vector machines (SVMs) (Vapnik, 1995; Cortes and Vapnik, 1995) has revolutionized the field of pattern recognition, surpassing traditional neural networks (Rumelhart et al., 1986) in many aspects, including accuracy and generalizability, as evident from numerous experimental evaluations.",1,new
"The emergence of graph-based clustering algorithms (Shimodaira, 2000; Jain et al., 1999) has overcome the limitations of traditional hierarchical clustering methods (Johnson, 1967) by providing a more efficient and effective way to identify clusters in complex data sets, as shown by various comparative studies.",1,new
"Previous studies have consistently demonstrated that corpus-based machine translation methods outshine rule-based approaches (Brown et al., 1990).",1,new
"Phrase-based SMT models have been found to yield superior results compared to word-based systems, as shown in numerous studies (Koehn et al., 2003; Och & Ney, 2003).",1,new
"Statistical machine translation systems based on phrases have been shown to outperform their word-based counterparts in several experiments (Koehn et al., 2003; Chen & Goodman, 1999).",1,new
"The development of machine learning algorithms in NLP has been significantly advanced by the application of neural network architectures (Collobert et al., 2011; Mikolov et al., 2010; Sutskever et al., 2011), enabling efficient processing of complex linguistic structures.",1,new
"The introduction of subword-based models in SMT has led to substantial improvements in translation quality, as demonstrated by the work of Sennrich et al. (2015); Luong et al. (2015); and Zaremba et al. (2014), who employed character-level representations to capture subtle linguistic nuances.",1,new
"Recent advancements in deep learning have facilitated the integration of multimodal information in NLP tasks, such as image captioning and visual question answering, as exemplified by the research of Vinyals et al. (2015); Donahue et al. (2015); and Karpathy and Fei-Fei (2014), who leveraged convolutional neural networks to analyze and generate visual data.",1,new
"Our research team has successfully integrated Word Sense Disambiguation (WSD) techniques into the Moses machine translation system (Koehn et al., 2003), demonstrating a notable improvement in translation quality (Liu and Gildea, 2005).",1,new
"The innovative approach of incorporating WSD into the phrase-based MT system, as proposed by Cabezas and Resnik (2005), has been shown to enhance the overall accuracy of the system, as evident in recent studies (Zhang et al., 2010).",1,new
"By incorporating WSD translations into the state-of-the-art NMT system, Transformer (Vaswani et al., 2017), we have observed a significant increase in translation efficiency and fluency, as reported by our latest experiment (Li et al., 2020).",1,new
"Recent advancements in natural language processing (NLP) have significantly impacted the field of sentiment analysis (Turney, 2002), with notable improvements in the development of deep learning models (Collobert et al., 2008).",1,new
"The advent of neural machine translation (NMT) has marked a significant shift in the field of machine translation (Sutskever et al., 2014), with notable improvements in fluency and accuracy over traditional phrase-based models (Och, 2003).",1,new
"The emergence of attention-based models in sequence-to-sequence learning (Bahdanau et al., 2015) has led to notable improvements in machine translation quality (Vaswani et al., 2017), outperforming earlier word-based models (Brown et al., 1993).",1,new
The introduction of deep learning techniques in natural language processing (Collobert et al. 2011) has revolutionized the field of sentiment analysis.,1,new
The widespread adoption of neural machine translation (Sutskever et al. 2014) has led to significant advancements in language understanding and translation accuracy.,1,new
The influential work on language modeling by Bengio et al. (2003) has paved the way for the development of more sophisticated language generation systems.,1,new
The statistical machine learning algorithm proposed by Collins (2003) has been widely used in the field of natural language processing.,1,new
"The use of vector space models, as described by Mikolov et al. (2013), has significantly improved the accuracy of text classification tasks.",1,new
"The incorporation of neural network architectures, as discussed by Bengio et al. (2003), has led to significant advancements in the field of deep learning.",1,new
"The most effective method for sentence alignment relies heavily on the incorporation of statistical models (Brown et al., 1993; Melamed, 2003).",1,new
"The widely accepted technique for part-of-speech tagging relies on probabilistic approaches (Hutchins, 1986; Cutting et al., 1992).",1,new
"The current consensus on machine translation evaluation is largely based on the comparison of fluency and adequacy metrics (Papineni et al., 2002; Chen and Cherry, 2008).",1,new
"The development of statistical machine translation models (Brown et al., 1993; Och & Ney, 2002; Philblad et al., 2010) has made it relatively straightforward to create a translation system for translating from English to French, except that we need to develop a robust French language model from large French monolingual corpora.",1,new
"The fact that most neural machine translation models (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) are designed to be symmetrical has simplified the process of training a translation system to translate from English to Spanish, although we still require a well-trained Spanish language model from extensive Spanish monolingual data.",1,new
"Given that many statistical machine translation models (Koehn et al., 2003; Chiang, 2007; Galley et al., 2006) are designed with symmetry in mind, it is relatively easy to develop a translation system for translating from English to German, provided that we have a comprehensive German language model trained from large-scale German monolingual data.",1,new
"The use of Hidden Markov Model (HMM) for speech recognition (Bakis et al., 1994; Juang and Rabiner, 1991) is a fundamental technique that has been extensively utilized in various applications due to its ability to capture phonetic patterns effectively.",1,new
"Statistical machine translation techniques, such as Memory-Based Translation Models (Brown et al., 1990; Brown et al., 1993), have proven to be highly efficient in modeling syntactic and semantic relationships between languages.",1,new
"The implementation of Conditional Random Fields (CRFs) for part-of-speech tagging (Lafferty et al., 2001; McClosky et al., 2006) has been shown to be a robust approach for accurately identifying grammatical categories in natural language processing tasks.",1,new
"Phrase-based systems (Zhu et al., 2010) have been instrumental in revolutionizing the field of Machine Translation, and their impact is still widely felt today.",1,new
"Rule-based systems (Melamed et al., 1996) are another crucial component of Statistical Machine Translation, and their ability to handle linguistic complexities is unmatched.",1,new
"Syntax-based systems (Galley et al., 2004) have made significant contributions to the advancement of Statistical Machine Translation, offering a more nuanced understanding of sentence structure and meaning.",1,new
"The incorporation of deep learning techniques into natural language processing has led to significant advancements in text summarization (Lin et al., 2003; Radev et al., 2004; Nallapati et al., 2008), often surpassing traditional extractive methods (Mani and May, 1999; Hovy and Lin, 2002) in terms of summary quality and coherence.",1,new
"Recent studies have demonstrated the effectiveness of graph-based approaches to sentiment analysis (Pang and Lee, 2008; Liu et al., 2010; Dasgupta et al., 2012), consistently outperforming traditional machine learning methods (Turney, 2002; Wiebe et al., 2005) in capturing nuanced emotional undertones.",1,new
"The application of probabilistic models to machine learning has shown promising results in speech recognition tasks (Bahl et al., 2006; Povey et al., 2008; Zweig et al., 2009), often rivaling or exceeding the performance of traditional hidden Markov models (Jelinek, 1997; Ney et al., 1994) in terms of recognition accuracy and robustness.",1,new
"The area of natural language processing has witnessed significant progress in the last decade, particularly the transition from rule-based systems (Marcus et al., 1993) to deep learning models which utilize word embeddings as a crucial component (Collobert et al., 2011).",1,new
"Recent years have seen a substantial leap in the field of speech recognition, marked by the shift from traditional Hidden Markov Models (Rabiner, 1989) to more advanced techniques employing neural networks and acoustic features (Hinton et al., 2012).",1,new
"The field of information retrieval has experienced a notable improvement in recent times, largely attributed to the shift from traditional keyword-based approaches (Salton et al., 1983) to more sophisticated methods incorporating semantic search and query expansion (Craswell et al., 2005).",1,new
"Recent studies have demonstrated the superiority of sentence-based translation methods (Wu et al., 2007; Koehn and Knight, 2002; Hutchins and Somers, 1992) over phrase-based translation models (Brown et al., 1993; Koehn and Senkey, 2003).",1,new
"The implementation of neural machine translation techniques (Zhang et al., 2017; Sutskever et al., 2014; Cho et al., 2014) has shown significant advancements in translation quality over traditional word-to-word translation approaches (Brown et al., 1993; Och et al., 1999).",1,new
"A number of research studies have highlighted the benefits of using context-aware translation models (Mikolov et al., 2010; Bengio et al., 2014; Collobert et al., 2011) in comparison to basic word-to-word translation methods (Brown et al., 1993; Marcu and Wong, 2002).",1,new
"The latest advancements in deep learning architectures (Sutskever et al., 2014; Mnih et al., 2015; Graves et al., 2013) have greatly improved the performance of speech recognition systems, leading to substantial gains in accuracy and efficiency.",1,new
"Recent breakthroughs in natural language processing (Ratnaparkhi, 1996; Brown et al., 1992; Melamed, 2004) have paved the way for more sophisticated machine translation systems, resulting in significant enhancements in translation quality and fluency.",1,new
"Over the past decade, the development of novel neural network models (Bengio et al., 2003; Collobert et al., 2011; Zhang and Yu, 2012) has significantly advanced the field of computer vision, yielding notable improvements in image classification and object detection tasks.",1,new
"2 Background Recent advancements in NLP have led to the development of more sophisticated machine learning algorithms (Bengio et al., 2003), enabling the creation of more accurate statistical machine translation systems (Och, 2003).",1,new
"3 Methodology The integration of deep learning techniques (Hinton et al., 2006) into SMT has significantly improved translation quality, as demonstrated by the success of neural machine translation systems (Sutskever et al., 2014).",1,new
"4 Implications The transition from rule-based to statistical machine translation (Koehn et al., 2003) has paved the way for more efficient and effective language processing, with far-reaching implications for real-world applications (Jones et al., 2010).",1,new
"The current understanding of the topic is best exemplified by the paradigm of machine learning algorithms (Bishop, 2006; Goodfellow et al., 2016).",1,new
"The state-of-the-art in this field is characterized by the application of deep learning techniques (Hinton et al., 2006; LeCun et al., 2015).",1,new
"The most widely accepted approach to this problem is the utilization of statistical models (Jurafsky and Martin, 2000; Manning and Schtze, 1999).",1,new
"In contrast to the traditional phrase-based machine translation method (Brown et al., 1993), this novel approach diverges in two key areas: first, it employs a non-parametric estimation technique for bilingual corpora; and second, it calculates word co-occurrence probabilities rather than relying on static frequencies.",1,new
"Unlike the conventional rule-based machine translation paradigm (Melamed, 2003), this model distinguishes itself by integrating domain-specific ontologies and utilizing a probabilistic framework for context-dependent disambiguation.",1,new
"In comparison to the prevalent corpus-based translation method (Liu & Liu, 2008), this innovative approach stands out in its ability to adapt to dynamic linguistic environments and its reliance on a machine learning algorithm that considers contextual dependencies and semantic relationships.",1,new
"Despite efforts to integrate semantic information into traditional machine learning algorithms, results have been largely inconsistent (Collins et al., 1996; Brown et al., 1990)2, with many researchers continuing to favor the reliability of rule-based approaches.",1,new
"However, attempts to incorporate discourse structure into sentence-based translation models have yielded mixed results (Chen et al., 2007; Specia et al., 2005)3, and more recent studies suggest that simpler, data-driven approaches remain more effective.",1,new
"However, attempts to incorporate context-aware features into statistical machine translation systems have not yet achieved significant improvements (Klein et al., 2003; Tanaka et al., 2003)4, and many researchers continue to rely on more established, rule-based methods.",1,new
"2 Recent studies on neural machine translation (NMT) demonstrate the effectiveness of encoder-decoder architecture (Bahdanau et al., 2014; Sutskever et al., 2014) in surpassing traditional phrase-based approaches (Koehn et al., 2003).",1,new
"The recent surge in transformer-based models (Vaswani et al., 2017) has shown remarkable improvements in language translation quality, outperforming the earlier statistical machine translation systems (Brown et al., 1993).",1,new
"3 Recent works on sequence-to-sequence models (Sutskever et al., 2014; Cho et al., 2014) have shown significant advancements in machine translation, with results indicating a notable leap forward over the traditional word-based approaches (Och and Ney, 2000a).",1,new
"This paper's contribution to the field of neural machine translation has been influential in the development of attention-based models, as evident in the work of Vaswani et al. (2017).",1,new
"The proposed method's impact on the field of natural language processing is also seen in its application to speech recognition systems, as demonstrated by the work of Mohri et al. (2012).",1,new
"This research's innovative approach to language modeling has been adopted in various deep learning architectures, including those of Bengio et al. (2003) and Mnih et al. (2015).",1,new
"2 Background The recent advancements in neural machine translation as proposed by (Vaswani et al., 2017) have enabled the development of more sophisticated language models that can capture contextual nuances.",1,new
"The incorporation of cognitive architectures, as described by (Newell, 1973), has significantly improved the ability of AI systems to reason and learn from complex data.",1,new
"3 Methodology The novel application of deep learning techniques, as demonstrated by (LeCun et al., 2015), has led to significant breakthroughs in the field of natural language processing.",1,new
"Recent advancements in neural machine translation have led to the development of highly effective models that can be efficiently trained from large monolingual datasets (Mikolov et al., 2010), mirroring the simplicity of earlier statistical models (Brown et al., 1990).",1,new
"The incorporation of recurrent neural networks has significantly improved the performance of MT systems, which can now be trained from relatively small amounts of parallel data (Sutskever et al., 2014), much like the early statistical models (Koehn et al., 2003) that relied on large corpora.",1,new
"The introduction of transformer-based architectures has further enhanced the efficiency of MT systems, allowing them to be trained from moderate-sized parallel corpora (Vaswani et al., 2017), similar to the original statistical models (Brants et al., 2007) that utilized large monolingual datasets.",1,new
"Our system architecture is built upon a cutting-edge, single-pass neural machine translation framework based on a transformer encoder-decoder model (Vaswani et al., 2017).",1,new
"The proposed methodology leverages a robust, hybrid machine translation approach that combines the strengths of rule-based and statistical machine translation systems (Melamed et al., 2001).",1,new
"The current implementation employs a highly optimized, beam-search based decoding strategy for our phrase-based statistical machine translation system, which has been shown to significantly improve translation quality (Chen et al., 2014).",1,new
"The NMT system employed in this study is Transformer-XL, a cutting-edge neural machine translation model (Dai et al., 2019).",1,new
"Our research utilizes the open-source machine translation system, OpenNMT, which has demonstrated exceptional performance in recent years (Neubig et al., 2018).",1,new
"The proposed MT model incorporates the advanced architecture of the attention-based system, as described in Vaswani et al. (2017), resulting in significantly improved translation accuracy.",1,new
"2 Background The introduction of recurrent neural network-based machine translation (NMT) (Sutskever et al., 2014) has revolutionized the field of automatic translation by significantly improving its accuracy and efficiency.",1,new
"The significant advancements in deep learning techniques, as highlighted in the work of Mikolov et al. (2010), have greatly contributed to the development of sophisticated translation models like phrase-based statistical machine translation (PBSMT).",1,new
"3 Methodology The pioneering work of Brown et al. (1990) on hidden Markov models has played a crucial role in laying the foundation for the subsequent innovations in statistical machine translation, including the use of n-gram models for language translation.",1,new
"Recent studies have shown that statistical machine learning techniques, such as those proposed by Collins (2003), have greatly improved the accuracy of Machine Translation systems.",1,new
"The use of maximum likelihood estimation in Statistical MT (SMT) has been widely adopted in the field, as demonstrated by the work of Chiang (2005).",1,new
"Phrase-based translation models, as first introduced by Koehn et al. (2003), have become a cornerstone of modern Machine Translation research and development.",1,new
"The application of deep learning techniques (Collobert et al., 2011; Mikolov et al., 2010) has revolutionized the field of natural language processing, achieving superior results in various NLP tasks.",1,new
"The incorporation of neural networks (Bengio et al., 2003; Socher et al., 2011) has been a game-changer in sentiment analysis, enabling researchers to achieve high accuracy and robustness in identifying sentiment patterns.",1,new
"The utilization of cognitive architectures (Newell, 1990; Laird et al., 1987) has significantly advanced the field of artificial intelligence, allowing for more realistic and human-like performance in complex decision-making tasks.",1,new
"For our speech recognition experiments, we employed a modified version of the Kaldi toolkit (Povey et al., 2011), a widely used open-source system for speech recognition tasks.",1,new
"In our natural language processing experiments, we utilized a reimplementation of the Stanford CoreNLP toolkit (Manning et al., 2014), a comprehensive NLP library that offers a range of tools for text analysis.",1,new
"For our sentiment analysis experiments, we utilized a reimplementation of the VADER sentiment analysis tool (Hutto & Gilbert, 2014), a state-of-the-art tool for sentiment analysis in text data.",1,new
"The introduction of word-based statistical machine translation (WSMT) (Brown et al., 1990) marked a significant milestone in the evolution of statistical translation methods, revolutionizing the field of computational linguistics.",1,new
"The advent of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003a) has had a profound impact on the field of machine translation, enabling more accurate and efficient translations.",1,new
"The development of statistical machine translation (SMT) (Och et al., 2003) has been a major breakthrough in the history of translation technology, paving the way for the creation of sophisticated language translation systems.",1,new
"Despite the notable advancements in neural machine translation, several challenges persist in integrating post-editing techniques into the workflow. 2 Syntax Based Machine Translation The increasing popularity of corpus-based approaches to machine translation has led to significant improvements, with Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003) continuing to advance the field.",1,new
"While significant progress has been made in deep learning-based machine translation, several hurdles remain in applying transfer learning strategies. 2 Syntax Based Machine Translation The growing adoption of corpus-based approaches has led to notable improvements, with Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003) remaining a prominent area of research.",1,new
"Despite the recent successes of transformer-based models in machine translation, several challenges persist in optimizing the performance of large-scale systems. 2 Syntax Based Machine Translation The widespread adoption of corpus-based approaches has led to substantial advancements, with Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003) remaining a leading area of investigation.",1,new
"Recent advances in neural machine translation models (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) have led to substantial gains in translation quality over traditional phrase-based models.",1,new
"The development of large-scale deep learning architectures (Collobert et al., 2011; Mikolov et al., 2013; Iyyer et al., 2015) has significantly improved the accuracy of statistical machine translation systems.",1,new
"Significant progress has been made in the application of ensemble methods (Collins et al., 2005; Zhang and Gildea, 2005; Och and Ney, 2005) to machine translation, resulting in notable improvements in translation efficiency and accuracy.",1,new
"The proposed approach to machine translation incorporates a novel application of the IBM Model 4 translation model (Brown et al., 1993), complemented by a sophisticated reranking framework (Cherry & Foster, 2010) that enhances overall system performance.",1,new
"The development of the neural machine translation system relies heavily on the integration of the word-based alignment model (Melamed, 2001) and the linguistic analysis provided by the lexicalized tree substitution grammar (Galley et al., 2004), yielding substantial improvements in translation quality.",1,new
"The innovative SMT architecture utilizes a statistical phrase-based model (Kucerova et al., 2009) in conjunction with a context-aware reordering algorithm (Specia et al., 2005), resulting in significant gains in translation accuracy and fluency.",1,new
"Maximum entropy (ME) models, as proposed by Berger et al. (1996) and further developed by Manning and Klein (2003), offer a versatile machine learning approach for classification and prediction tasks, having been effectively utilized in various natural language processing applications, such as sentiment analysis and information retrieval.",1,new
"The application of maximum entropy models, a technique initially introduced by Berger et al. (1996) and refined by Manning and Klein (2003), has been widely adopted in machine learning for its ability to seamlessly integrate diverse features from multiple sources, thereby enhancing the accuracy of classification and prediction tasks, including part-of-speech tagging and named entity recognition.",1,new
"The maximum entropy (ME) framework, first introduced by Berger et al. (1996) and later improved upon by Manning and Klein (2003), has emerged as a powerful tool for machine learning, particularly in the realm of natural language processing, where it has been successfully employed in tasks such as text classification, topic modeling, and sentiment analysis, due to its capacity to effectively combine features from various sources.",1,new
"The development of Deep Learning Architectures (Bengio et al., 2006; LeCun et al., 2015) has revolutionized the field of artificial intelligence, offering a flexible and scalable framework for complex tasks such as image recognition, speech processing, and natural language understanding. Deep learning architectures can seamlessly integrate diverse features from multiple data sources.",1,new
"Support Vector Machines (SVMs) (Cortes and Vapnik, 1995; Cristianini and Shawe-Taylor, 2000) have emerged as a powerful tool for classification and regression, providing a robust and efficient method for high-dimensional data analysis. SVMs have been successfully applied to a wide range of applications, including text classification, image recognition, and bioinformatics.",1,new
"The use of Random Forests (Breiman, 2001; Breiman et al., 2004) has proven to be an effective approach for ensemble learning, enabling the construction of accurate and interpretable models for classification and regression tasks. Random forests can efficiently handle large datasets and provide a high degree of robustness to overfitting.",1,new
"5.3 Results Our approach employs a Support Vector Machine (SVM) classifier (Cortes and Vapnik, 1995), which is well-suited for high-dimensional feature spaces and provides accurate classification performance.",1,new
"6.1 Methods In this study, we utilize a Random Forest (RF) algorithm (Breiman, 2001) to effectively handle large datasets and achieve robust results.",1,new
"7.2 Experimental Design We utilize a Gaussian Mixture Model (GMM) (McLachlan and Peel, 2000) to model the distribution of our data, allowing for a comprehensive understanding of the underlying patterns and trends.",1,new
"2 Methodology The introduction of deep learning techniques in natural language processing has significantly improved the accuracy of machine translation models (Bengio et al., 2003; Collobert et al., 2011; Sutskever et al., 2014; Mikolov et al., 2010).",1,new
"3 Results Our experiments demonstrate that the integration of word embeddings into the SMT framework yields substantial improvements in translation quality (Mikolov et al., 2013; Devlin et al., 2014; Goldberg and Levy, 2014; Luong et al., 2015).",1,new
"4 Implications The proposed approach to incorporating phonetic features into SMT systems has been shown to reduce translation errors by up to 25% (Melamed et al., 2003; Li et al., 2012; Wu et al., 2016; Sgaard and Goldberg, 2016).",1,new
"The proposed framework is referred to as SMT (Shannon et al., 2005) and has been extensively utilized in various NLP applications (Ratnaparkhi et al., 2007; Wang et al., 2008; Kim et al., 2008).",1,new
"This technique is known as DSSM (Dong et al., 2009) and has been widely adopted in information retrieval systems (Bengio et al., 2009; Manning et al., 2010; Zhang et al., 2010).",1,new
"The employed model is based on the work of CDSSM (Chen et al., 2010) and has shown significant improvements in text classification tasks (Lei et al., 2011; Wang et al., 2012; Li et al., 2012).",1,new
"For more effective modeling of natural language, researchers have found it beneficial to begin with a probabilistic context-free grammar (PCFG) (Charniak, 1997).",1,new
"Using a head-driven phrase structure grammar (HPSG) as a starting point can provide a solid foundation for the development of more complex linguistic models (Pollard & Sag, 1994).",1,new
"In order to capture the nuances of language variation, it is often advisable to start with a lexicalized tree-adjoining grammar (LTAG) (Kasami, 1965)",1,new
"Our results demonstrate that the proposed algorithm enhances the efficiency and precision of named entity recognition, outperforming traditional methods in a state-of-the-art NLP framework (Ratinov et al., 2009).",1,new
"The new approach yields a substantial improvement in the accuracy and processing speed of sentiment analysis, surpassing existing techniques in a cutting-edge text classification system (Pang and Lee, 2008).",1,new
"Experiments confirm that the developed technique significantly boosts the quality and reliability of part-of-speech tagging, eclipsing prior methods in a leading linguistic analysis tool (Brill, 1995).",1,new
"The recent advancements in the application of ontologies to machine learning models have been significantly accelerated by the development of the BabelNet lexicalized ontology (Navigli et al., 2012).1 The availability of BabelNet's extensive database has enabled researchers to efficiently retrieve and incorporate semantic information into their models, thus paving the way for more accurate NLP applications. Conversely, the dearth of research on integrating ontologies into NLP for languages with non-Latin scripts remains a pressing concern.",1,new
"The integration of graph-based representations into deep learning architectures has been notably facilitated by the introduction of the Graph2Vec algorithm (Guo et al., 2018).1 The ability to efficiently embed graphs into vector spaces has opened up new avenues for knowledge representation and reasoning, which in turn has improved the performance of various NLP tasks. However, the exploration of graph-based methods in NLP for languages with complex morphology remains an underdeveloped area of research.",1,new
"The advancement of sentiment analysis techniques has been notably influenced by the development of the VADER sentiment analysis tool (Hutto & Gilbert, 2014).1 The ease of use and high accuracy of VADER have made it a popular choice among researchers, enabling them to efficiently analyze and understand the sentiment behind large volumes of text data. Nonetheless, the extension of VADER's capabilities to handle sentiment analysis for languages with non-English scripts remains a topic of ongoing research.",1,new
"The widespread adoption of such approaches is facilitated by the existence of user-friendly and openly accessible tools that simplify their implementation (Baker et al., 2008, GATE).",1,new
"The extensive use of these methods is largely due to the availability of powerful and free software packages that enable researchers to efficiently compute them (Resnik et al., 1999, MLE).",1,new
"The broad acceptance of these techniques can be attributed to the presence of well-documented and easily downloadable libraries that streamline their application (Hearst, 1998, WordNet).",1,new
"The authors of the Stanford CoreNLP library have successfully integrated several state-of-the-art natural language processing techniques (Manning et al., 2014).",1,new
"The software package spaCy offers a comprehensive set of tools for NLP tasks, including tokenization and named entity recognition (Honnibal et al., 2017).",1,new
"The Gensim library has been widely adopted for its efficient and scalable implementation of topic modeling and document similarity analysis (Rehurek & Sojka, 2010).",1,new
"The proposed approach also shares similarities with the benefits highlighted by (Dagan et al., 2001), where these blocks excel at encoding linguistic features like anaphora resolution, yet they struggle with capturing long-range dependencies and handling non-standard linguistic patterns.",1,new
"Building upon the work of (Kilgarriff and Tugwell, 2001), our method demonstrates effectiveness in encoding complex semantic relationships, including the representation of idiomatic expressions, but it falls short in addressing issues of overfitting and lacking robustness to out-of-vocabulary words.",1,new
"In line with the findings of (Manning and Schtze, 1999), our model showcases strengths in handling local context and encoding subtle nuances of language, such as capturing the distinction between similar words, but it encounters difficulties with global context and resolving ambiguity in certain linguistic constructions.",1,new
"This is supported by the findings of (Kumar and Srivastava, 2018), which demonstrate the effectiveness of their proposed segmentation algorithm in reducing errors by 30%.",1,new
"The authors in (Lee et al., 2012) also contribute to this area by introducing a novel approach to handle the complexities of MTU, building upon the groundwork laid by (Kim and Lee, 2008).",1,new
"Notably, the research conducted by (Gupta and Jain, 2015) showcases a significant improvement in translation quality, thanks to their innovative use of a hybrid approach that integrates the strengths of (Wang and Li, 2010) and (Patel and Chaudhari, 2012).",1,new
"Recent studies have demonstrated that active learning techniques can significantly enhance the accuracy of sentiment analysis models (Gulati et al., 2018), contradicting the long-held assumption that manual annotation is the most effective method (Pang and Lee, 2004; Wiebe et al., 2005).",1,new
"The integration of contextualized embeddings has been shown to improve the performance of named entity recognition tasks (Devlin et al., 2019), despite initial concerns that such approaches would lead to overfitting (Collobert et al., 2011; Manning et al., 1999).",1,new
"Research has shown that ensemble methods can outperform traditional machine learning approaches in the task of topic modeling (Bekkerman et al., 2003), challenging the conventional wisdom that a single algorithm is sufficient for this task (Hofmann, 1999; Newman et al., 2006).",1,new
"The proposed framework has been successfully applied to various NLP tasks, including named entity recognition (Collobert et al., 2011) and sentiment analysis (Pang and Lee, 2008).",1,new
"The system's efficacy has been demonstrated in several studies, such as speech recognition (Hinton et al., 2012) and text summarization (Nallapati et al., 2008).",1,new
"Its accomplishments span a wide range of applications, from language modeling (Bengio et al., 2003) to machine learning (LeCun et al., 2015).",1,new
"Our results show that incorporating active learning contributes 1.22% absolute improvement to the HMM parser, comparable to the gain achieved by using semi-supervised training with the perceptron tagger in (Collins, 2002).",1,new
"We observe a 0.59% absolute improvement in accuracy for the context-free grammar parser when using weakly supervised learning, which is on par with the improvement obtained from semi-supervised training with the maximum entropy tagger in (McDonald et al., 2005).",1,new
"The integration of active learning yields a 1.05% absolute improvement to the stochastic context-free grammar parser, similar to the enhancement achieved by using semi-supervised training with the support vector machine classifier in (Tsochantaridis et al., 2004).",1,new
"While numerous researchers have explored the realm of unsupervised machine learning, there remains a dearth of in-depth studies on the application of transfer learning to natural language processing tasks (Krizhevsky et al., 2012; Collobert et al., 2011; Ruder et al., 2017).",1,new
"Despite the significant progress in deep learning, a notable shortage of investigations has been observed in the area of few-shot learning, where the existing literature mainly focuses on the supervised setting (Vinyals et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016).",1,new
"Although considerable research has been conducted on the topic of domain adaptation, a notable gap persists in the study of multi-task learning, which is crucial for real-world applications that often involve multiple related tasks (Caruana, 1997; Evgeniou et al., 2005; Zhang et al., 2017).",1,new
"The current state of the field is well-represented by several notable studies, including (Klein and Manning, 2003) on part-of-speech tagging and (Collins, 2003a; Collins, 2003b) on named entity recognition.",1,new
"A number of key papers have made significant contributions to the area, such as (Bikel et al., 1999) on lexical semantics and (Lapata and Keller, 2005; Lapata and Keller, 2007) on text categorization.",1,new
"Notable research has been conducted in this field, with (Charniak, 2000) providing insights into dependency parsing and (Ratnaparkhi, 1996a; Ratnaparkhi, 1996b) shedding light on machine learning techniques.",1,new
"Our research group has built upon the findings of (Klein & Manning, 2003), demonstrating that incorporating annotated web data significantly enhances the accuracy of our part-of-speech tagger on the benchmark Penn Treebank corpus.",1,new
"The recent study by (Collins, 1999) has been instrumental in improving the robustness of our statistical parsing models, as shown by the substantial gains in parsing accuracy on the WSJ test set.",1,new
"The work of (Santorini, 1990) has laid the groundwork for our current approach to dependency parsing, which has led to notable improvements in parsing accuracy on the standard XTAG dataset.",1,new
"The implementation of the novel active learning strategy outlined in (Sutton & McCallum, 2012) resulted in a 25% decrease in error rate, reaching 92.5% accuracy without the need for additional annotated data.",1,new
"By employing the ensemble learning methods proposed in (Dietterich, 2000), our model achieved a 20% improvement in classification accuracy, reaching 95.2% on the same benchmark dataset.",1,new
"In accordance with the recommendations of (Bengio et al., 2006), our research team incorporated transfer learning techniques, yielding a 30% reduction in error rate and a 91.1% accuracy on the challenging task of sentiment analysis.",1,new
"The results of the III, VO, and OV scenarios (Lin et al., 2012a; 2012b) showed a significant improvement in parser performance when the reranker was used to re-order the top 100-best list of the generative parser, with a seed size of 60K sentences.",1,new
"Our analysis of the IV, OV, and VI scenarios (Kim et al., 2015a; 2015b) revealed that the incorporation of a reranker to re-score the 30-best list of the generative parser led to substantial gains in parser accuracy, especially when the seed size was set to 80K sentences.",1,new
"In the V, VO, and OI scenarios (Park et al., 2018a; 2018b), the employment of a reranker to re-rank the 20-best list of the generative parser resulted in notable improvements in parser performance, with a seed size of 40K sentences yielding the most significant gains.",1,new
"Our findings build upon the work of (Huang et al., 2012), who demonstrated the effectiveness of semi-supervised learning in improving parser accuracy, as shown in their adaptation of the (Charniak and Johnson, 2005) reranking parser.",1,new
"Recent studies by (Lin et al., 2018) have shown promising results in parser adaptation using active learning, which is further supported by the work of (Klein and Manning, 2003) on parser reranking techniques.",1,new
"The recent work of (Gimpel et al., 2010) has successfully applied transfer learning to parser adaptation, leveraging the results of (Collins, 2003) on parser architecture and (Klein and Manning, 2003) on reranking algorithms.",1,new
"The encouraging findings of (Klein et al., 2003; 2005) regarding high-dimensional models do not necessarily translate to more constrained problem domains.",1,new
"In contrast to the positive outcomes reported by (Bengio et al., 2001; 2004), our experiments with limited training data yielded mixed results.",1,new
"However, the robust performance of (Ratcliff et al., 2007; 2009) in certain applications should not be taken as a guarantee of success in all cases with smaller datasets.",1,new
"The incorporation of contextual information into the language models, as seen in the work of (Bengio et al., 2003; Collobert and Weston, 2008; Socher et al., 2011), is a crucial step towards improving parsing accuracy.",1,new
"The development of more sophisticated semantic role labeling techniques, as proposed by (Gardent et al., 2017; Joshi et al., 2017; Bjrkelund et al., 2018), has the potential to significantly enhance the performance of parsing models.",1,new
"A more nuanced understanding of linguistic context, achieved through the use of deep learning architectures (Hermann et al., 2014; Vinyals et al., 2015; Kalchbrenner et al., 2015), is essential for advancing parsing research and applications.",1,new
"Our team aims to further improve the accuracy of the machine learning model by employing a transfer learning approach, leveraging the pre-trained weights from the state-of-the-art model of Brunet et al. (2018).",1,new
"Future research will investigate the effectiveness of incorporating domain adaptation techniques, similar to those proposed by Collobert et al. (2011), to enhance the performance of our natural language processing system.",1,new
"In an effort to optimize the neural network architecture, we plan to explore the use of attention mechanisms, as successfully demonstrated by Vaswani et al. (2017), to improve the model's ability to capture long-range dependencies in the data.",1,new
The innovative approach proposed by Resnik et al. (1999) utilized a decision-theoretic framework to calculate semantic similarity between words in a lexical database.,1,new
"The groundbreaking study by Hearst (1992) introduced a supervised machine learning method to identify hyponyms and hypernyms in a lexical database, significantly advancing the field of lexical semantics.",1,new
"The pioneering work by Lin (1998) developed a novel algorithm to compute semantic similarity between words based on their contextual relationships, providing a significant improvement over previous methods.",1,new
"Our study draws inspiration from the work of Lin and Pantel (2001), who proposed the use of co-occurrence patterns in web documents to identify semantic relationships between entities, offering a promising approach to address the limitations of traditional lexical databases.",1,new
"Following the lead of Gabrilovich and Markovitch (2007), we employed a machine learning algorithm to learn semantic representations of words from a large corpus of text, successfully overcoming the challenges associated with manual annotation.",1,new
"Building on the work of Snow et al. (2006), who demonstrated the effectiveness of using web search engine data for semantic analysis, we developed a novel method for extracting and ranking related entities, significantly improving the accuracy of our results.",1,new
"Although our proposed method does not surpass the BLEU scores of existing models, it excels in terms of fluency and coherence in out-of-vocabulary cases (Lee et al., 2019).",1,new
"Compared to previous approaches, our technique yields comparable BLEU scores but demonstrates a significant improvement in readability and grammatical correctness for unseen data (Kim and Zhang, 2020).",1,new
"While our model does not attain higher BLEU scores than the state-of-the-art, it performs exceptionally well in terms of semantic similarity and logical consistency for novel scenarios (Brown et al., 2018).",1,new
The results of the study by Chen et al. (2012) demonstrate a notable enhancement in the accuracy of statistical machine translation on a controlled dataset with minimal out-of-vocabulary words.,1,new
"According to the research conducted by Johnson and Brown (2007), there is a significant improvement in the fluency of generated text using a hybrid approach that incorporates both rule-based and statistical models.",1,new
"A substantial increase in the effectiveness of dependency parsing is reported by Kim and Lee (2009), particularly on sentences with a simple syntactic structure and limited use of idiomatic expressions.",1,new
"The use of ensemble learning (Breiman, 2001) has been shown to improve the accuracy of machine learning models by combining the predictions of multiple models, leading to more robust and reliable results.",1,new
"The implementation of dynamic programming (Bellman, 1957) has greatly simplified the process of solving complex optimization problems, allowing for more efficient and effective solutions to be found.",1,new
"The application of recursive neural networks (Rumelhart et al., 1986) has enabled the development of deep learning models that can learn complex patterns and relationships in data, leading to significant advances in areas such as image and speech recognition.",1,new
"The research by (Kim et al., 2019) presents a novel technique for streamlining the parsing process, significantly improving the ef ciency of computational models.",1,new
"A recent study by (Lee et al., 2015) demonstrates the effectiveness of dynamic programming in accelerating the processing of context-free grammars.",1,new
"The work by (Wang et al., 2012) proposes an innovative method for reducing the computational complexity of parsing algorithms, enabling faster and more accurate results.",1,new
Our study demonstrated that incorporating a limited set of labeled examples into an unsupervised learning framework can lead to substantial enhancements in text classification performance.,1,new
The results of this experiment illustrated that augmenting the training data with a small number of hand-labeled instances can yield substantial improvements in machine learning model accuracy.,1,new
Our analysis revealed that enriching the dataset with a modest amount of expert-annotated data can significantly boost the efficacy of deep learning algorithms in natural language processing tasks.,1,new
"Our study (Kim et al., 2018) demonstrates a notable advancement in natural language processing, achieving high accuracy rates in sentiment analysis tasks with the aid of a novel context-dependent neural network module, which outperforms previous methods with a minimal vocabulary of 128 base words.",1,new
"The work by (Liu and Manning, 2010) showcases an innovative approach to named entity recognition, leveraging a graph-based model that significantly improves accuracy and efficiency, with remarkable results obtained using a modest set of 150 seed entities.",1,new
"According to (Ratnaparkhi, 1996), the incorporation of a hybrid morphology module in a machine learning framework results in substantial gains in part-of-speech tagging, with impressive performance achieved using a starting vocabulary of just 120 core words.",1,new
"The use of this type of input information (features + majority label) has been shown to be highly effective in providing robust alternatives to traditional classification methods, as demonstrated by the work of Manning and Schtze (1999).",1,new
"The specification of alternative inputs to a classifier using this type of input information has proven to be a valuable approach, as highlighted by the research of Collins (2003).",1,new
"This input format (features + majority label) has been utilized by numerous researchers as a means of providing flexible input options for classification tasks, as exemplified by the contributions of Collins and Duffy (2002).",1,new
"Our proposed approach also surpasses the performance of state-of-the-art methods like that of Toutanova and Manning (2000) and McDonald et al. (2006) for both our French and Spanish corpora, outshining even the most competitive tools in the CoNLL Shared Task 2005 (cf. Palmer et al. (2005)).",1,new
"The results of our experiment demonstrate that our novel segmentation algorithm outperforms the techniques employed by Hwa and Schmill (2000) and Sagae et al. (2005) for both our Chinese and Japanese datasets, and our method compares favorably to the top-performing systems in the SPMRL Shared Task 2010 (refer to Chen and Rogers (2010)).",1,new
"Furthermore, our methodology outdoes the previous approaches of Brown et al. (1990) and Kudo (2005) for our German and Italian datasets, and our results are on par with the best-performing models in the ACL Workshop on Computational Natural Language Processing for Historical Texts 2007 (see Marcus and Marcinkiewicz (1993)).",1,new
"Li and Liu (2015) enhances (Baker, 1992) through a more efficient algorithm.",1,new
"Zhang et al. (2018) builds upon (Kumar, 2008) by introducing a novel technique.",1,new
"Patel and Smith (2020) surpasses (Harris, 2011) with a more robust methodology.",1,new
"The advancements in natural language processing have led to significant breakthroughs in sentiment analysis: the research of aspect-based sentiment analysis (Kim et al., 2006; Liu et al., 2005; Popescu et al., 2007; Yu et al., 2008), opinion summarization (Liu et al., 2005; Liu et al., 2006; Banea et al., 2008) and emotion detection (Mohammad et al., 2009; Kiritchenko et al., 2008) are the primary areas of focus in the field of sentiment analysis.",1,new
"The ongoing research in text classification has led to numerous contributions: the study of topic modeling (Blei et al., 2003; Griffiths et al., 2004; Newman et al., 2006), text classification (Joachims, 1999; Dumais et al., 2004) and named entity recognition (Ratinov et al., 2009; Riloff et al., 2003) have been instrumental in improving the accuracy of text classification algorithms.",1,new
"The development of machine learning techniques has enabled significant progress in information retrieval: the research of query expansion (Liu et al., 2004; Li et al., 2006; Zhang et al., 2007), relevance feedback (Rocchio, 1972; Salton et al., 1983) and clustering (Karypis et al., 1999; Steinbach et al., 2000) have been crucial in enhancing the performance of information retrieval systems.",1,new
"Furthermore, research has also explored the employment of semantic networks and graph-based methods (e.g., graph centrality measures or community detection algorithms) to enhance the accuracy of co-occurrence analysis (Mihalcea and Radev, 2004; Bunescu and Pasca, 2006).",1,new
"In recent years, several studies have investigated the application of machine learning techniques, such as supervised learning or deep learning models, to improve the precision of co-occurrence statistics (Joachims, 1998; Li et al., 2016).",1,new
"Additionally, some researchers have examined the utilization of domain-specific resources, like ontologies or taxonomies, to better capture the nuances of co-occurrence relationships in various domains (Hotho et al., 2003; Liu et al., 2013).",1,new
"Interestingly, the most significant contribution is attributed to (Smith et al., 2015), who develop a novel approach for identifying trends in large datasets.",1,new
"Notably, a remarkable achievement is reported by (Lee et al., 2009), who successfully integrate machine learning techniques with data visualization methods.",1,new
"Undoubtedly, a groundbreaking study is conducted by (Kim et al., 2018), who propose a new framework for predicting outcomes in complex systems.",1,new
"The use of automated metrics such as METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006), and NIST (Finkelstein, 2002) has been demonstrated to have a high degree of correlation with human evaluation scores for machine translation evaluation.",1,new
"Various automated metrics, including METEOR, TER, and WER (Pratt et al., 1994), have been shown to exhibit strong correlations with human judgments in the context of machine translation.",1,new
"Studies have indicated that metrics such as BLEU, METEOR, and ROUGE (Lin, 2004) have a significant correlation with human assessment in evaluating the quality of machine-generated text.",1,new
"The results showed a significant correlation between the system's automated evaluation metrics and human ratings of text coherence, validating its effectiveness in assessing linguistic quality (Kupiec et al., 2002).",1,new
"The study demonstrated that the proposed algorithm produced scores that closely aligned with human assessments of text readability, indicating its potential as a reliable tool for evaluating written communication (Graff et al., 2010).",1,new
"The findings highlighted a strong correspondence between the system's automated ratings and human judgments of text comprehension, suggesting its utility in assessing the overall quality of written texts (Hovy et al., 2006).",1,new
The current benchmarks for assessing machine translation quality are primarily based on the widely used F1-score metric introduced by Chen and Wong (2015) and its subsequent adaptations.,1,new
"Recent studies have leveraged the PER (Position Independent Error Rate) metric (Snover et al., 2006) as a key performance indicator for machine translation evaluation.",1,new
"The evaluation of text summarization systems heavily relies on metrics such as ROUGE (Lin, 2004), which has become a standard measure for assessing the quality of generated summaries.",1,new
"The proposed model also incorporates the widely used Pearson's r (Pearson, 1895) and Spearman's rho (Spearman, 1904) correlation coefficients, as well as the recently developed and more robust Kendall's tau (Kendall, 1938) and Somers' d (Somers, 1962) metrics to evaluate the strength and direction of the relationship between variables.",1,new
"In addition to the traditional p-value (Fisher, 1925) and effect size measures such as Cohen's d (Cohen, 1988), our analysis utilizes the more modern and informative standardized mean difference (SMD) (Hedges and Olkin, 1985) and Glass's delta (Glass, 1976) to assess the magnitude of treatment effects in our experiments.",1,new
"The novel approach also employs the commonly used F1-score (Vapnik, 1979) and accuracy (Bishop, 2006) metrics, as well as the more recently introduced Receiver Operating Characteristic (ROC) curve (Fawcett, 2006) and Precision-Recall (PR) curve (Davis and Goadrich, 2006) to evaluate the performance of our machine learning model in various classification tasks.",1,new
"The effectiveness of the algorithm is assessed using a widely accepted metric: the Meteor score (Banerjee and Lavie, 2005).",1,new
"The accuracy of the system is evaluated using a reliable measure: the ROUGE score (Lin, 2004).",1,new
"The quality of the generated text is evaluated using a well-established metric: the CIDEr score (Vedantam et al., 2015).",1,new
"The widely accepted metric for assessing the fluency of machine translation is the Perplexity score (Vijayakumar et al., 2018).",1,new
"The evaluation of machine translation quality is often facilitated by the use of the Meteor score, a comprehensive metric introduced by Banerjee and Lavie (2005).",1,new
"A commonly employed metric for evaluating the coherence of machine translation outputs is the BLEU score, as initially proposed by Papineni et al. (2002).",1,new
"The METEOR Metric The metric most frequently employed with MERT is METEOR (Banerjee and Lavie, 2005), which calculates the score of a candidate c against a reference translation r as: METEOR = BP(len(c),len(r))exp( 4summationdisplay n=1 1 4 logpn), where pn is the n-gram precision and BP is a brevity penalty that prevents the improvement of precision at the expense of recall.",1,new
"The NIST Metric The metric predominantly utilized with MERT is NIST (Doddington, 2002), where the score of a candidate c against a reference translation r is determined by: NIST = BP(len(c),len(r))exp( 4summationdisplay n=1 1 4 logpn), where pn is the n-gram precision and BP is a penalty function to penalize short outputs.",1,new
"The ROUGE Metric The metric commonly associated with MERT is ROUGE (Lin, 2004), which calculates the score of a candidate c against a reference translation r as: ROUGE = BP(len(c),len(r))exp( 4summationdisplay n=1 1 4 logpn), where pn is the n-gram recall and BP is a brevity penalty to discourage optimizing precision over recall.",1,new
"This measure has been widely adopted in the field of machine translation evaluation, demonstrating its effectiveness in assessing translation quality (Hutchins, 1999; Snover et al., 2006).",1,new
"The metric has been extensively used in various studies, consistently showing a strong correlation with human evaluation (Koehn, 2004; Och & Ney, 2003).",1,new
"It is the most commonly employed metric in translation evaluation tasks, exhibiting a high degree of agreement with human assessors (Banerjee & Lavie, 2005; Isabelle et al., 2003).",1,new
"Our proposed approach achieves a state-of-the-art METEOR (Banerjee and Lavie, 2005) score of 0.8721 on the NIST 2004 test set, surpassing the previous best score by 0.0505.",1,new
"The incorporation of subword units (Sennrich et al., 2016) in our model results in a significant improvement in the BLEU (Papineni et al., 2002) score of 0.8612 on the WMT 2014 test set.",1,new
"The use of a transformer-based architecture (Vaswani et al., 2017) in our model yields a new state-of-the-art score of 0.8459 on the IWSLT 2015 evaluation metrics, marking a substantial advancement in machine translation performance.",1,new
"The use of widely accepted metrics such as the Meteor score (Denkowski and Lavie, 2011), ROUGE score (Lin, 2004), and the F1 score (Baudivs and Smith, 2010) has been instrumental in evaluating the efficacy of our proposed algorithm.",1,new
"The assessment of translation quality was carried out using well-established metrics like the TER score (Snover et al., 2006), the ChrF score (Popovic and Stajner, 2012), and the NIST score (Doddington, 2002), demonstrating the robustness of our system.",1,new
"A range of evaluation metrics, including the CIDEr score (Vedantam et al., 2015), the SPICE score (Anderson et al., 2016), and the METEOR score (Banerjee and Lavie, 2005), were employed to rigorously evaluate the performance of our proposed machine translation system.",1,new
"The recent advancements in deep learning have led to the development of sophisticated metrics such as METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006), which provide more accurate assessments of machine translation quality on a sentence level.",1,new
"In order to evaluate the performance of machine translation systems, researchers have employed metrics like ROUGE (Lin, 2004) and F-score (Chen and Chen, 2009), which offer a comprehensive analysis of translation quality on a document level.",1,new
"The emergence of neural machine translation has sparked the creation of novel evaluation metrics, including BLEU++ (Koehn, 2004) and NIST++, (Doddington, 2002), which have improved upon their predecessors by providing a more nuanced understanding of translation quality on a sentence level.",1,new
"While previous research has demonstrated that evaluations of dialogue systems by metrics like BLEU and ROUGE correlate with human assessments (Hirschberg & Manning, 1998; Chen et al., 2014), we are not aware of any studies that have shown a correlation between corpus-based evaluation metrics of conversational AI systems and human judgments; correlation studies have been conducted on individual components (Stoyanov et al., 2010), but not on systems as a whole.",1,new
"Although there is evidence that metrics like perplexity and cross-entropy correlate with human ratings of language models (Kull et al., 2015; Zaremoodi et al., 2017), we are not aware of any studies that have shown a correlation between corpus-based evaluation metrics of text summarization systems and human judgments; correlation studies have been made of individual components, such as keyword extraction (Hovy et al., 1999), but not of systems.",1,new
"While research has shown that ratings of machine translation systems by metrics such as BLEU and METEOR correlate with human judgments (Koehn, 2004; Callison-Burch et al., 2006), we are not aware of any studies that have shown a correlation between corpus-based evaluation metrics of text classification systems and human judgments; correlation studies have been conducted on individual components, such as feature extraction (Kim et al., 2004), but not on systems as a whole.",1,new
"The PERILS metric (Simard et al., 2019) in speech recognition has been particularly effective; for instance, the 2019 ASR evaluation challenge employed PERILS-3 as the primary evaluation criterion.",1,new
"The METEOR metric (Banerjee and Lavie, 2005) in machine translation has been notably successful; as seen in the 2008 WMT evaluation task, METEOR-5 was used as the sole evaluation metric.",1,new
"The ROUGE metric (Lin, 2004) in text summarization has been highly influential; for example, the 2012 DUC evaluation exercise utilized ROUGE-2 as the primary evaluation method.",1,new
"Our analysis reveals a strong correlation between perplexity scores and the perceived fluency of machine-generated text (Kumar et al., 2018).",1,new
"The results of our study demonstrate a significant relationship between n-gram overlap and human-assigned relevance (Lin, 2004).",1,new
"A recent study found that using TF-IDF weighting in document similarity calculations yields highly consistent results with human evaluators (Jiang & Conrath, 1995).",1,new
"The adoption of the ROUGE evaluation metric (Lin, 2004) in Automatic Summarization has been widely praised by researchers, as it has greatly facilitated the evaluation of summarization systems and enabled the rapid identification of effective techniques.",1,new
"The introduction of the METEOR evaluation metric (Banerjee and Lavie, 2005) in Machine Translation has been met with enthusiasm by the research community, as it has provided a more comprehensive and accurate way to evaluate the quality of machine translation systems.",1,new
"The success of the NIST scoring package (Doddington, 2002) in Speech Recognition has been commended by experts, as it has greatly improved the evaluation of speech recognition systems and enabled researchers to assess the impact of new acoustic models and decoding techniques.",1,new
"The model also presents the widely used METEOR (Banerjee et al., 2005) and ROUGE metrics for evaluation.",1,new
"The table includes the commonly cited BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) metrics for translation evaluation.",1,new
"The study utilizes the popular BLEU (Papineni et al., 2002) and WER (Chen & Gao, 1996) metrics for assessing machine translation quality.",1,new
"The concept of leveraging n-gram frequency analysis to evaluate the performance of a machine learning model against a predefined set of criteria was initially explored in the ROUGE metric for automatic summarization (Lin, 2004).",1,new
"The notion of utilizing co-occurrence statistics to assess the similarity between a generated text and one or more reference texts was first introduced in the METEOR metric for machine translation (Banerjee and Lavie, 2005).",1,new
"The application of n-gram co-occurrence statistics to evaluate the output of a natural language processing system against a set of desired reference outputs was successfully demonstrated in the BLEU++ metric for machine translation (Chen et al., 2001).",1,new
"Our research has built upon the successful application of n-gram co-occurrence statistics in question answering systems (Lee et al. 2015, Mitchell and Lapata 2008), and we demonstrate its utility as a feature in sentiment analysis models (Baccianella et al. 2010).",1,new
"N-gram co-occurrence statistics have been effectively utilized in natural language inference (Bowman et al. 2015), and our study extends this work by exploring its use in text classification tasks (Agirre and Belagua 2015, Recasens et al. 2013).",1,new
"The incorporation of n-gram co-occurrence statistics has improved the performance of text summarization systems (Rush et al. 2015), and we further investigate its impact on the evaluation of machine translation outputs (Callison-Burch et al. 2006, Snover et al. 2006).",1,new
"The automatic evaluation metrics such as ROUGE (Lin and Hovy, 2003) and METEOR (Banerjee and Lavie, 2005) have been widely adopted in machine translation due to their high correlation with human evaluation.",1,new
"The effectiveness of the Viterbi algorithm in part-of-speech tagging has been extensively studied, and it has been consistently shown to produce accurate results, as demonstrated in the work of (Rabiner, 1989).",1,new
"The application of the Hidden Markov Model to speech recognition has been a significant advancement, and its widespread adoption can be attributed to the strong correlation between the model's output and human-annotated transcriptions, as reported by (Jelinek and Mercer, 1980).",1,new
"The introduction of the Word Sense Induction (WSI) algorithm (Gale et al, 1992) has greatly benefited the field of natural language processing: it has enabled more accurate disambiguation of word senses, leading to improved performance in various NLP tasks, such as text classification and information retrieval, by bypassing the need for manual annotation and allowing for more efficient evaluation.",1,new
"The development of the Stanford Parser (Klein & Manning, 2003) has significantly accelerated the progress of dependency parsing in NLP research: it has provided a widely-used and highly accurate tool for parsing English sentences, reducing the time and effort required for manual annotation and enabling researchers to focus on more complex aspects of parsing theory and application.",1,new
"The introduction of the concept of Active Learning (Settles, 2009) has revolutionized the field of machine learning: it has enabled more efficient use of human labels by focusing on the most informative samples, thereby reducing the overall number of required annotations and allowing researchers to explore more complex models and algorithms for improved performance.",1,new
"Our study utilizes the widely accepted PERL (Precision, Recall, and F-score) metrics (van Rijsbergen, 1979) to assess the effectiveness of our approach.",1,new
"The evaluation of our model's performance relies on the well-established ROUGE score (Lin, 2004) to measure its ability to generate coherent and accurate text summaries.",1,new
"We utilize the METEOR metric (Banerjee and Lavie, 2005) to evaluate the similarity between our generated output and human-annotated references in the benchmark dataset.",1,new
"Our system performance was evaluated using the NIST Metrics Package (Lavie and Denoual, 2005), a comprehensive toolkit for assessing machine translation quality.",1,new
"We compared the output of our model to the gold standard translations using the Meteor (Banerjee and Lavie, 2005) metric, a widely used measure of translation fluency.",1,new
"The accuracy of our system was assessed using the ROUGE metrics (Lin, 2004), a set of precision-based evaluation metrics for machine translation evaluation.",1,new
"Our analysis indicates that ROUGE and METEOR have been demonstrated to closely align with human assessments in evaluating the effectiveness of MT systems with varying degrees of fluency (Lin, 2004; Lavie et al., 2004).",1,new
"The evaluation metrics of BLEU and TER have been found to exhibit strong correlations with human judgments in assessing the quality of MT systems with different linguistic properties (Snover et al., 2006; Coughlin, 2003).",1,new
"Studies have shown that PER and F-measure have been closely related to human evaluations in assessing the performance of MT systems with diverse characteristics (Chinchor, 1997; Wu, 1997).",1,new
"The proposed ROUGE metric has been widely used for evaluating machine translation outputs (Lin, 2004), demonstrating its effectiveness in assessing the quality of generated text.",1,new
"PER (Precision and Recall) evaluation metrics have been widely adopted in the field of machine translation for assessing the accuracy of generated text (Chinchor, 1997).",1,new
"The METEOR (Metric for Evaluation of Translation with Explicit ORdering) metric has gained significant attention for evaluating machine-generated text, showcasing its ability to provide a more comprehensive assessment of translation quality (Banerjee & Lavie, 2005).",1,new
"The widely used METEOR (Banerjee and Lavie, 2005) metric assesses the semantic similarity between the translation and the reference translation based on the number of overlapping concepts.",1,new
"The popular TER (Snover et al., 2006) metric evaluates the edit distance between the translation and the reference translation, providing a reliable measure of translation quality.",1,new
"The well-established HTER (Snover et al., 2006) metric calculates the human evaluation score based on the edit distance between the translation and the reference translation, offering a robust evaluation framework.",1,new
"The widely accepted measure of machine translation quality is the Meteor score (Banerjee and Lavie, 2005), which has been extensively utilized in various studies.",1,new
"The most commonly employed evaluation metric for machine translation is the ROUGE score (Lin, 2004), which has proven to be highly effective in assessing the quality of translation systems.",1,new
"The widely used evaluation metric for automatic machine translation is the BLEU score with a large n-gram size, as reported in (Kilgarriff and Tugwell, 2001), demonstrating its robustness in evaluating translation quality.",1,new
"The accuracy of the sentiment analysis model was assessed using a widely accepted metric: the F1-score (Bengio et al., 2003).",1,new
"The effectiveness of the proposed algorithm was evaluated using a well-known performance measure: precision (Kirkpatrick et al., 2017).",1,new
"The robustness of the machine learning model was tested using a widely accepted benchmark: the mean absolute error (MAE) (Carrasco et al., 2015).",1,new
"Our research suggests that the widely accepted standard for evaluating machine translation quality is the METEOR metric (Banerjee and Lavie, 2005), which outperforms other automatic evaluation metrics.",1,new
"The most popular metric for assessing the fluency of generated text is the ROUGE score (Lin, 2004), which has become a benchmark in the natural language processing community.",1,new
"Among the various automatic metrics for evaluating machine translation output, the TER (Translation Edit Rate) metric (Snover et al., 2006) stands out for its ability to accurately measure the number of edits required to achieve human-quality translations.",1,new
"The development of reliable and efficient evaluation metrics for machine learning models has been a significant area of research, with notable contributions from the PERIL (Reed et al., 2017) and METEOR (Banerjee and Lavie, 2005) metrics.",1,new
"Automatic evaluation of language translation quality has been an active area of investigation, with significant advancements made through the work of the ROUGE (Lin, 2004) and CHRF (Popovic and Garigliano, 2010) metrics.",1,new
"The need for objective and accurate assessments of natural language processing models has driven research into automated evaluation metrics, with notable efforts from the CIDEr (Vedantam et al., 2015) and SPIDEr (Weiss et al., 2018) metrics.",1,new
"The results of our study demonstrated that the use of metrics like ROUGE (Lin, 2004) and METEOR (Banerjee & Lavie, 2005) can lead to evaluations that closely align with human assessments, as observed in previous research (Doddington, 2002; Chen, 2012).",1,new
"The present investigation revealed that techniques such as NIST (Doddington, 2002) and WER (Crammer et al., 2010) can produce evaluation results that exhibit a high degree of correlation with human judgments, consistent with the findings of previous studies (Koehn & Monz, 2006; Callison-Burch et al., 2006).",1,new
"Our analysis showed that the incorporation of metrics like BLEU+ (Papineni et al., 2002) and METEOR (Banerjee & Lavie, 2005) can yield evaluation outcomes that demonstrate a strong agreement with human ratings, in line with the conclusions drawn from earlier research (Chen, 2012; Coughlin, 2003).",1,new
The results of the study by Zampolli (1967) indicate a strong correlation between the frequency of cognates and the ease of language acquisition for English learners of Italian and Spanish.,1,new
"A significant positive correlation is observed between the METEOR score and human judgments for machine translations from German, Japanese, and Portuguese to English, as reported by Banerjee and Lavie (2005).",1,new
"High consistency is found between the ROUGE score and human evaluations for automatic summaries of news articles in English, French, and Portuguese, according to Lin (2004).",1,new
"The results show a significant correlation between the METEOR score and human judgment in machine translation assessments (Banerjee and Lavie, 2005).",1,new
"Our study found a strong association between the ROUGE score and human evaluation of text summarization systems (Lin, 2004).",1,new
"Empirical evidence suggests a high degree of concordance between the BLEU score and human ratings for machine translation quality assessments (Kilgariff, 2005).",1,new
"The ROUGE metrics have been demonstrated to accurately reflect the similarity between machine-translated texts and their human-translated counterparts (Lin, 2004; Earley, 2003).",1,new
"PER metrics have been shown to provide a reliable measure of the performance of machine translation systems in terms of precision and recall (Nist, 2003; Dorr, 2003).",1,new
"METEOR scores have been found to correlate well with human evaluations of machine translation quality, indicating their potential as a useful evaluation metric (Banerjee and Lavie, 2005; Lavie et al., 2004).",1,new
"2 Recent advancements in computer vision have been greatly facilitated by the development of novel object detection metrics, such as the widely adopted Intersection over Union (IoU) measure, introduced by Everingham et al. (2010).",1,new
"3 The increasing demand for accurate sentiment analysis has driven the creation of sophisticated evaluation metrics, including the popular Text Ranking-based Sentiment Analysis (TRSA) framework, first proposed by Liu et al. (2015).",1,new
"4 The emergence of natural language processing (NLP) has been significantly enhanced by the introduction of metrics like the F1-score, which was first introduced by van Rijsbergen (1979) to measure the accuracy of information retrieval systems.",1,new
"The most widely used evaluation metrics in machine translation are the Meteor score (Denkowski & Lavie, 2011), the TER score (Snover et al., 2006) and the ROUGE score (Lin, 2004).",1,new
"In the field of sentiment analysis, the commonly employed metrics are the F1-score (Buitinck et al., 2013), the accuracy score (Kohavi, 1995) and the area under the ROC curve (AUC-ROC) (Fawcett, 2006).",1,new
"The widely used metrics for evaluating the performance of named entity recognition models are the precision, recall and F1-score (Petrov & McDonald, 2012), the accuracy score (Hindle, 2010) and the labeled precision (Lavie & Denkowski, 2004).",1,new
"The most widely used evaluation metrics in machine translation include the Meteor score (Banerjee and Lavie, 2005), the ROUGE score (Lin, 2004), and the CIDEr score (Vedantam et al., 2015), which have been instrumental in assessing the quality of machine translation systems.",1,new
"The most commonly employed metrics for assessing the performance of speech recognition systems are the Word Error Rate (WER), the Position independent word Error Rate (PER), and the Word Informational Word Error Rate (Wang et al., 2013), which have been widely used in the field of speech recognition research.",1,new
"The most widely used evaluation metrics in natural language processing include the BLEU score (Papineni et al., 2002), the METEOR score (Banerjee and Lavie, 2005), and the TER (Translation Edit Rate) score (Snover et al., 2006), which have been widely adopted in the evaluation of machine translation systems.",1,new
"The use of metrics such as the ROUGE score (Lin, 2004) and the METEOR score (Banerjee and Lavie, 2005) has been a cornerstone in evaluating the effectiveness of machine translation systems.",1,new
"The implementation of the TER (Snover et al., 2006) and the HTER (Snover et al., 2006) metrics has significantly impacted the field of machine translation, providing a more nuanced understanding of translation quality.",1,new
"The adoption of metrics like the BLEU+KLD (Kishore et al., 2004) and the NIST metric (Doddington, 2002) has facilitated the development of more accurate machine translation systems, leading to improved language understanding and generation.",1,new
"Advances in deep learning have significantly improved the performance of natural language processing tasks, particularly in the realm of speech recognition, thanks to the development of attention-based models (Vaswani et al., 2017) and sequence-to-sequence learning (Sutskever et al., 2014).",1,new
"The field of computer vision has witnessed substantial progress in recent years, largely due to the introduction of convolutional neural networks (LeCun et al., 1998) and transfer learning techniques (Donahue et al., 2014), which have enabled more accurate object detection and image classification.",1,new
"The rise of big data analytics has been facilitated by the emergence of efficient algorithms and scalable frameworks, such as Apache Spark (Zaharia et al., 2010) and Hadoop MapReduce (Dean and Ghemawat, 2008), allowing for faster data processing and more effective insights.",1,new
"The most widely recognized metrics in the field are the Meteor score (Denkowski and Lavie, 2011), the ROUGE score (Lin, 2004), and, particularly in recent years, the CIDEr score (Vedantam et al., 2015) and the BLEU+METEOR score (Banerjee and Lavie, 2005).",1,new
"Other prominent evaluation metrics used in natural language processing are the F-score (Damerau, 1964), the precision (Baeza-Yates and Ribeiro-Neto, 1999), and, notably in modern applications, the TERp score (Snover et al., 2006) and the WER score with a focus on word-level accuracy (Chen and Huang, 2012).",1,new
"The most commonly used evaluation metrics for machine translation are the BLEU score with a focus on fluency (Papineni et al., 2002), the NIST score with a focus on fluency and grammaticality (Doddington, 2002), and, particularly in recent years, the METEOR score with a focus on semantic similarity (Banerjee and Lavie, 2005) and the TER score with a focus on word-level accuracy (Snover et al., 2005).",1,new
"Most notably, metrics such as ROUGE (Lin, 2004) and CIDEr (Vedantam et al., 2015) also rely heavily on string-level similarity, despite their ability to evaluate the fluency and coherence of machine-generated text. However, their reliance on exact word matching can lead to inconsistent results.",1,new
"Many established metrics like BLEU+ (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) assess the similarity between reference and candidate translations at the word level, which can result in biased evaluations, especially when dealing with out-of-vocabulary words or grammatical variations.",1,new
"Despite their popularity, metrics like NIST (Doddington, 2002) and HTER (Snover et al., 2006) share a common limitation with Bleu and Ter - they often fail to account for nuances in language, such as idiomatic expressions and context-dependent word meanings, which can significantly impact the accuracy of machine translation evaluations.",1,new
"Despite the widespread adoption of metrics such as ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005), researchers in the field of machine translation (MT) continue to express concerns that these measures, although efficient and reliable for individual system development, fall short in accurately comparing disparate systems or language pairs.",1,new
"Following the introduction of metrics like BLEU+ (Papineni et al., 2002) and TER (Snover et al., 2006), it became apparent that while these tools were effective for internal system evaluation, they struggled to provide a comprehensive picture when comparing different translation systems or languages.",1,new
"The reliance on metrics like METEOR (Banerjee and Lavie, 2005) and BLEU (Papineni et al., 2002) has led to a realization among machine translation researchers that these measures, although useful for development, lack the nuance required for cross-system or cross-language comparisons, highlighting the need for more sophisticated evaluation methods.",1,new
"A groundbreaking method was proposed in (Kittredge and Lehrberger, 1998), which effectively employed a hybrid approach to semantic parsing, leveraging both machine learning and rule-based techniques to identify context-dependent relationships.",1,new
"In a pioneering study (Hovy and Lin, 1999), the authors presented an innovative framework for discourse parsing, utilizing a combination of probabilistic and linguistic features to automatically identify discourse markers and structure.",1,new
"The work of (Santorini, 1997) showcased a novel algorithm for part-of-speech tagging, which utilized a machine learning-based approach to identify and categorize words in a text, leading to significant improvements in accuracy and efficiency.",1,new
"(Turney, 2002) laid the foundation for the development of sentiment analysis techniques that have since become a cornerstone of natural language processing.",1,new
"(Klein & Manning, 2003) is a seminal work that significantly contributed to the advancement of part-of-speech tagging and its applications in sentiment analysis.",1,new
"(Harris, 1954) is a pioneering study that demonstrated the effectiveness of corpus-based methods in analyzing the polarity of text, influencing the field of sentiment analysis for decades to come.",1,new
The seminal work of Weeds (2003) on document classification is a prime example of the advancements made in the field of natural language processing.,1,new
Miller's (2004) research on sentiment analysis is a landmark contribution to the development of more sophisticated machine learning algorithms.,1,new
The innovative approach to topic modeling presented by Blei et al. (2003) has had a lasting impact on the way researchers analyze and interpret large datasets.,1,new
"The most straightforward solution to this challenge is arguably the work of Lee and Sumita (2006), who demonstrated promising outcomes on Task 1 by treating the sentiment of a document as the product of its constituent term sentiments; however, more complex methodologies have also been explored (Kamps et al., 2004; Kiritchenko et al., 2009).",1,new
"A simple yet effective approach to this problem is exemplified in the research of Kim and Hovy (2006), who achieved notable results on Task 3 by using a weighted sum of term sentiments as a proxy for document sentiment; further, other researchers have developed even more advanced methods (Hirst and St-Onge, 1999; Wiebe et al., 2005).",1,new
"The most basic yet insightful solution to this issue is likely the study of Melucci (2008), who showed significant progress on Task 4 by considering the average sentiment of the terms within a document as representative of the document's sentiment; meanwhile, other researchers have investigated more nuanced approaches (Grefenstette, 2003; Read, 2005).",1,new
The study by Joachims et al. (2002) demonstrated a significant improvement in classification accuracy without requiring any domain-specific adjustments.,1,new
Lewis (1998) observed notable gains in sentiment analysis performance without the need for domain customization.,1,new
"In their work, Pang and Lee (2004) achieved substantial improvements in text categorization without relying on domain-specific training data.",1,new
Weatherspoon and Tucek (2006) study is widely regarded as a seminal work in the field of unsupervised sentiment analysis.,1,new
The pioneering work of Liu and Zhang (2010) on lexicon-based sentiment classification is a landmark achievement in the field of natural language processing.,1,new
Kim and Hovy (2004) research on sentiment classification using machine learning algorithms is considered a groundbreaking contribution to the development of affective computing.,1,new
"Furthermore, we intend to explore the application of advanced machine learning algorithms (Bishop, 2006) to enhance the precision of our model predictions.",1,new
"Future research will focus on incorporating additional data sources (Krizhevsky et al., 2012) to refine the accuracy of our analysis and provide more comprehensive insights.",1,new
"We anticipate that the integration of more robust statistical methods (Gelman et al., 2004) will significantly improve the reliability of our findings and offer new avenues for investigation.",1,new
"The concept of graph-based methods for document summarization was first explored in (Mihalcea and Tarau, 2004), and later successfully applied to the generation of text abstracts (Erkan and Radev, 2004), sentence extraction (Wan and Xiao, 2008), and the creation of document clusters (Radev et al., 2004).",1,new
"The use of ensemble learning for sentiment analysis was first introduced in (Dietterich, 2000), and has since been successfully applied to the classification of movie reviews (Pang and Lee, 2004), the analysis of customer feedback (Hu and Liu, 2004), and the detection of opinion polarity (Liu et al., 2005).",1,new
"The idea of utilizing machine learning for natural language inference was first proposed in (MacCartney and Manning, 2008), and has since been successfully applied to the recognition of entailment relationships (Dagan et al., 2006), the prediction of sentence similarity (Lei et al., 2010), and the evaluation of semantic text classification (Hausman et al., 2009).",1,new
"Recent advancements in Natural Language Processing (NLP) have led to the widespread adoption of hybrid neural machine translation models (Zhou, et al., 2017; Sutskever, et al., 2014) as demonstrated in Figure 2.",1,new
"The implementation of neural network-based approaches in machine learning has revolutionized the field of sentiment analysis, with notable contributions from researchers such as Socher, et al. (2011) and Collobert, et al. (2011) as depicted in Figure 3.",1,new
"The increasing use of deep learning techniques in speech recognition has been fueled by the work of researchers like Hinton, et al. (2006) and Graves, et al. (2006), whose findings are graphically represented in Figure 4.",1,new
"Our study builds upon the work of Charniak (2005), who developed the parser that significantly improved the accuracy of part-of-speech tagging in natural language processing (NLP) tasks, outperforming other existing models by a substantial margin.",1,new
"The incorporation of the incremental parser (IP) by Collins (2003) led to a notable advancement in machine learning, enabling the efficient processing of large-scale datasets and yielding improved results in dependency parsing compared to traditional parsing methods.",1,new
"The introduction of the transition-based parsing model by Yamada and Collins (1999) marked a significant milestone in the field of NLP, as it facilitated the development of more accurate and efficient parsing algorithms, ultimately leading to improved machine translation and language understanding capabilities.",1,new
"The proposed approach has been successfully implemented for various machine learning models such as Random Forest (Breiman, 2001) and Support Vector Machines (Cortes and Vapnik, 1995), as well as our own Model 3 (Johnson et al., 2007).",1,new
"These findings are consistent with the results from previous studies employing techniques like Hidden Markov Models (Rabiner, 1989) and Gaussian Mixture Models (Reynolds et al., 2000), including our own Model 4 (Smith et al., 2010).",1,new
"Our results demonstrate the effectiveness of the proposed algorithm for a range of natural language processing tasks, including language modeling (Bengio et al., 2003) and sentiment analysis (Pang and Lee, 2008), as well as our own Model 5 (Davis et al., 2015).",1,new
"The use of Bayesian inference (Kass and Raftery, 1995) can be leveraged for unsupervised parameter estimation, drawing parallels to the approach described in (Bishop, 2006).",1,new
"A similar methodology for parameter estimation can be adopted from Model 5 (Klein et al., 1999), as discussed in (Jelinek, 1997), allowing for an unsupervised estimation of the model parameters.",1,new
"The parameter estimation process can be further refined by employing the Expectation-Maximization algorithm (Dempster et al., 1977), similar to the application described in (Rabiner, 1989).",1,new
"(Zhang et al., 2010) presented a thorough analysis of recent advancements.",1,new
"(Kumar and Lee, 2008) proposed innovative methods for streamlining procedures.",1,new
"(Huang et al., 2015) highlighted the benefits of novel approaches in data processing.",1,new
"The current trend in machine learning research focuses on fine-tuning the hyperparameters of deep neural networks using a grid search optimization algorithm (Bengio et al., 2009).",1,new
"The most effective approach for image classification tasks involves adjusting the learning rate and regularization strength in accordance with the cross-validation accuracy metric (Duda et al., 2001).",1,new
"Recent studies have shown that the performance of natural language processing models can be significantly improved by tuning the word embedding dimensionality and model complexity in relation to the perplexity score (Jurafsky & Martin, 2008).",1,new
"The current best practice in machine learning is to employ ensemble methods as outlined in (Bauer & Kohavi, 1999).",1,new
"Recent studies have shown that utilizing maximum likelihood estimation (MLE) is a highly effective approach as discussed in (Dempster et al., 1977).",1,new
"The widely accepted technique for model selection is to use k-fold cross-validation, as detailed in (Stone, 1974).",1,new
"The addition of a noise injection mechanism to the training process of sequence-to-sequence models showed significant improvements in robustness; for further information, refer to (Klein et al., 2017).",1,new
"Incorporating a novel attention mechanism into the decoder architecture proved to be highly effective; for a comprehensive analysis, see (Vaswani et al., 2017).",1,new
"Modifying the embedding layer to utilize a combination of word and character-level features resulted in substantial gains in model performance; for a detailed discussion, consult (Collobert et al., 2011).",1,new
"The proposed approach utilizes the preprocessed context vector cv as the feature function values for the candidate translation tm (m a16 1,,M), enabling efficient training of the system prior weights via the Minimum Error Rate Training framework outlined in (Koehn, 2004).",1,new
"By leveraging the optimized word alignment matrix aw as feature function values for the candidate translation tm (m a16 1,,M), researchers can efficiently train the system prior weights using the Minimum Error Rate Training methodology presented in (Collins, 2003).",1,new
"Using the dynamically computed translation model parameters as feature function values for the candidate translation em (m a16 1,,M), the system prior weights can be easily trained using the Minimum Error Rate Training approach described in (Viterbi, 2005).",1,new
"2 Background The concept of transfer learning has gained significant traction since its inception by Yosinski et al. (2014), allowing neural networks to leverage pre-trained models for improved performance in various NLP tasks.",1,new
"3 Methodology The development of attention-based neural machine translation (NMT) models has been extensively explored since its proposal by Vaswani et al. (2017), leading to substantial advancements in translation quality and efficiency.",1,new
"5 Discussion The introduction of the Long Short-Term Memory (LSTM) network by Hochreiter and Schmidhuber (1997) has had a profound impact on the field of sequence prediction, revolutionizing the way researchers approach temporal data modeling.",1,new
"The significant advancement in speech recognition systems was facilitated by the pioneering work of the Hidden Markov Model (HMM) project (Rabiner, 1989; Jelinek, 1997; Juang, 1999).",1,new
"A crucial breakthrough in natural language processing was achieved through the development of the Machine Translation (MT) system (Brown et al., 1988; Melamed, 2004; Knight, 2009).",1,new
"The innovative application of deep learning techniques to the field of computer vision was showcased in the Visual Geometry Group (VGG) project (Simonyan and Zisserman, 2014; Szegedy et al., 2015; Long and Zhang, 2015).",1,new
"The development of deep learning methods (Bengio et al., 2003; Hinton et al., 2006; Collobert et al., 2011) and neural machine translation (NMT) techniques (Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017) has significantly advanced the field of machine translation (MT).",1,new
"Recent advancements in subword modeling (Sennrich et al., 2016; Johnson et al., 2017; BPE; Rieler et al., 2018) and encoder-decoder architectures (Gulcehre and Bengio, 2016; Gehring et al., 2017; Vaswani et al., 2017) have led to state-of-the-art results in machine translation (MT) and natural language processing (NLP).",1,new
"The integration of pre-training and fine-tuning (Devlin et al., 2019; Liu et al., 2019; Radford et al., 2019) has pushed the boundaries of language understanding and generation, with significant improvements in machine translation (MT) and other natural language processing (NLP) tasks.",1,new
"This trend is supported by studies that demonstrate the effectiveness of attention-based neural networks in machine translation tasks, outperforming traditional statistical models (Kalchbrenner et al., 2013; Bahdanau et al., 2015).",1,new
"Research has consistently shown that ensemble methods, incorporating both generative and discriminative approaches, yield superior results in NLP tasks, including text classification and sentiment analysis (Zhou et al., 2012; Wang et al., 2018).",1,new
"The use of reinforcement learning algorithms has been widely adopted in sequence-to-sequence models, leading to significant improvements in machine translation accuracy and fluency (Sutskever et al., 2014; Vaswani et al., 2017).",1,new
"The remaining five entries were all rule-based machine translation systems; in fact, they were all syntax-directed statistical machine translation systems that had been trained on the same large-scale corpus and most utilized Levenshtein-based error rate training (Koehn, 2004) to optimize the weights of their decision tree models (Melamed, 2004).",1,new
"All seven entries were fully automatic machine learning models; in fact, they were all memory-based statistical machine translation systems that had been trained on the same multilingual corpus and most employed maximum likelihood estimation (Brown, 1990) to optimize the weights of their hidden Markov models (Jelinek, 1976).",1,new
"The last three entries were all example-based machine translation systems; in fact, they were all word-based statistical machine translation systems that had been trained on the same parallel corpus and most utilized expectation-maximization algorithm (Dempster et al., 1977) to optimize the weights of their vector space models (Salton and McGill, 1983).",1,new
"The computer vision community heavily relies on the use of Intersection over Union (IoU) metrics for evaluating object detection and segmentation models (Everingham et al., 2010).",1,new
"The field of natural language processing has extensively utilized the Perplexity metric for assessing the quality of language models and their ability to generalize to unseen data (Pereira et al., 1993).",1,new
"In the realm of speech recognition, the Word Error Rate (WER) metric has been a crucial tool for evaluating the accuracy of automatic speech recognition systems and guiding their optimization through minimum Bayes risk training (Povey et al., 2005).",1,new
"Dreyer et al. (2012) have developed an innovative approach for improving the precision of automatic speech recognition systems, yielding significant gains in terms of accuracy and efficiency.",1,new
"Itti (2004) has proposed a novel framework for image segmentation that leverages the strengths of both edge-based and region-based techniques, resulting in improved performance and robustness.",1,new
"Radev et al. (2009) have introduced a highly effective method for sentence selection in paraphrasing tasks, leading to enhanced coherence and fluency in generated text.",1,new
"The recent advancements in deep learning techniques (LeCun et al., 2015) have led to significant improvements in speech recognition systems, enabling more accurate transcriptions of spoken language.",1,new
"The integration of cognitive architectures (Anderson et al., 2004) into computer vision systems has resulted in enhanced object recognition capabilities, allowing for more robust image analysis.",1,new
"The development of graph-based methods (Koller & Friedman, 2009) has revolutionized the field of network analysis, providing valuable insights into complex systems and their underlying structures.",1,new
"The use of Minimum Bayes Risk (MBR) (Chen & Rosenfeld, 2000) has been shown to significantly enhance the accuracy of a speech recognition system, by maximizing the posterior probability of the correct transcription on the training data.",1,new
"According to a recent study, the Perplexity-based optimization method (Chen, 1996) can lead to substantial improvements in the performance of a language translation system, by minimizing the perplexity score on the validation set.",1,new
"The application of the Minimum Description Length (MDL) principle (Rissanen, 1978) has been found to be effective in improving the performance of a machine translation system, by optimizing the feature weights based on the MDL criterion and maximizing the translation accuracy on the test set.",1,new
A detailed analysis of the experimental setup for this study can be found in the work of Smith (2019).,1,new
The application of machine learning techniques to optimize this process is thoroughly discussed in the paper by Jones et al. (2020).,1,new
A comprehensive review of the relevant literature on this topic can be found in the review article by Lee and Kim (2018).,1,new
"The recent advancement in deep learning techniques, such as pre-training large neural networks on a wide range of tasks (Deng et al. 2013; Howard and Ruder 2018), have significantly improved the performance of our proposed approach.",1,new
"Incorporating techniques from natural language processing, such as named entity recognition (Nadeau and Sekine 2007; Santos et al. 2015) and part-of-speech tagging (Toutanova and Manning 2000), has also been instrumental in enhancing the overall accuracy of our system.",1,new
"The application of reinforcement learning methods, including Q-learning (Watkins 1989) and actor-critic models (Sutton and Barto 2018), has allowed us to fine-tune our model and achieve state-of-the-art results in our field.",1,new
"The proposed methodology demonstrates its potential in extracting relevant information, as evident in previous applications in machine learning (Bengio et al. 2003) and natural language processing (Chen and Rosenfeld 1997).",1,new
"The proposed technique has been utilized in various successful implementations, including information retrieval (Manning et al. 2008) and text classification (Joachims 1999), showcasing its effectiveness in real-world scenarios.",1,new
"The innovative approach has been successfully employed in the development of semantic search engines (Hirschman et al. 2005), and has also been applied in the field of question answering systems (Kwiatkowski et al. 2011), yielding promising results in both cases.",1,new
"The integration of deep learning architectures, such as recurrent neural networks (RNNs) (Graves, 2013) and long short-term memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), has led to substantial advancements in speech recognition systems.",1,new
"The adoption of cognitive computing techniques, including attention mechanisms (Bahdanau et al., 2015) and memory-augmented neural networks (Sukhbaatar et al., 2015), has significantly enhanced the performance of natural language processing (NLP) models.",1,new
"Recent advancements in natural language generation (NLG) have been driven by the application of generative adversarial networks (GANs) (Goodfellow et al., 2014) and sequence-to-sequence models (Sutskever et al., 2014), resulting in more realistic and coherent text output.",1,new
"This approach was further improved upon by Gao and Li (2018), who demonstrated a novel integration of the HMM and deep learning techniques, achieving state-of-the-art results in machine translation.",1,new
"The work of Chiang and Knight (2016) built upon the foundation laid by previous researchers, including the combination of HMM and IBM Model 4, which was shown to yield improved translations in their study.",1,new
"A notable advancement was made by Huang and Chen (2020), who proposed a hybrid model that leverages the strengths of both HMM and neural machine translation, leading to enhanced accuracy and fluency in their experimental results.",1,new
"The use of pre-annotation techniques, such as parallel corpora, is a crucial step in achieving high-quality machine translation, as highlighted by Brown et al. (1993) in their seminal work on statistical machine translation.",1,new
"The significance of incorporating discourse analysis in natural language processing was first introduced by Grosz and Sidner (1986), marking a pivotal shift in the field's understanding of human-computer interaction.",1,new
"The concept of Minimum Bayes Risk (MBR) training, developed by Shaw et al. (2003), has been instrumental in improving the accuracy of spoken language translation systems, solidifying its position as a cornerstone of modern machine translation research.",1,new
"The proposed neural network architecture has been effectively applied in improving the performance of a statistical machine translation system, as demonstrated in (Koehn et al., 2007), where a novel approach to language modeling was introduced.",1,new
"The use of the stochastic gradient descent algorithm has been previously explored in optimizing the parameters of a context-aware neural machine translation system, as shown in (Bengio et al., 2003), where a more efficient training method for deep neural networks was proposed.",1,new
"The incorporation of a reinforcement learning framework has been successfully employed in enhancing the accuracy of a sequence-to-sequence model, as described in (Williams, 1992), where a new paradigm for learning complex tasks was presented.",1,new
"In this study, we utilize the dynamic programming algorithm (Koehn, 2004) to efficiently compute the optimal solution for the sequence-to-sequence model, ensuring high-quality alignments and translations.",1,new
"The parameters of the recurrent neural network are optimized using the stochastic gradient descent algorithm with momentum (Rumelhart et al., 1986), which has been widely recognized for its effectiveness in improving model convergence and accuracy.",1,new
"To evaluate the performance of the proposed machine translation system, we employ the precision and recall metrics (Lin, 2004), which provide a comprehensive assessment of the system's ability to accurately translate and retrieve relevant information.",1,new
"The findings of our research demonstrate that the use of neural networks in natural language processing tasks outperforms traditional machine learning approaches (LeCun et al., 2015).",1,new
"In contrast to previous methods, our study shows that the application of support vector machines in image classification tasks yields superior results (Cortes and Vapnik, 1995).",1,new
"Our analysis indicates that the incorporation of deep learning techniques into speech recognition systems significantly improves their performance compared to earlier models (Hinton et al., 2012).",1,new
"The proposed approach of incorporating phonetic features into the acoustic model is a valuable contribution to the field of automatic speech recognition, as demonstrated by the work of Davis and Mermelstein (1980).",1,new
"The use of attention mechanisms in deep learning models, as first introduced by Bahdanau et al. (2015), holds great potential for improving the performance of machine translation systems.",1,new
"It is beneficial to explore the integration of lexicalized syntax into the parsing algorithm, as suggested by the research of Collins (1996), in order to enhance the accuracy of natural language processing tasks.",1,new
"The incorporation of recurrent neural network-based models (Sutskever et al., 2014; Cho et al., 2014) in statistical machine translation has been proposed to significantly improve the quality of translations over the traditional phrase-based models (Koehn et al., 2003; Och and Ney, 2004), as evidenced by recent empirical studies.",1,new
"The adoption of attention-based models (Bahdanau et al., 2015; Vaswani et al., 2017) has been suggested to be a major advancement in neural machine translation, surpassing the performance of earlier phrase-based models (Brown et al., 1993; Marcu and Wong, 2002) in various evaluation metrics.",1,new
"The development of graph-based models (Dyer et al., 2016; Vinyals et al., 2015) has been proposed to be a promising direction in statistical machine translation, as they have been shown to outperform traditional phrase-based models (Koehn et al., 2003; Och and Ney, 2004) in certain scenarios, according to recent studies.",1,new
"Our research builds upon the existing work of phrase-based translation systems (Koehn et al., 2007; Hutchins & Somers, 1992), but introduces a new paradigm for statistical machine translation that leverages the principles of dependency parsing to improve fluency and accuracy.",1,new
"This paper draws inspiration from the pioneering work on error-driven training techniques (Chen & Padmanabhan, 2006; Tillmann, 2004), and presents a novel approach to machine translation that incorporates the strengths of both phrase-based and syntax-based models to enhance the overall quality of the translation.",1,new
"By expanding on the foundational work of sequential annotation techniques (Grosz et al., 1995; Abney, 1996), our proposed model for statistical machine translation adopts a block sequence approach that mirrors the structure of natural language processing tasks such as named entity recognition and coreference resolution, thereby achieving state-of-the-art results.",1,new
"The work of Koehn (2004) presents a thorough examination of a novel phrase-based statistical machine translation approach, demonstrating its potential for high-quality translations.",1,new
"A comprehensive review of the existing literature by Brown (2005) reveals a promising method for efficient decoding in statistical machine translation, which has shown significant improvements in accuracy.",1,new
"An in-depth analysis by Li (2002) explores the application of a beam search algorithm to a translation task, resulting in notable gains in translation quality and efficiency.",1,new
"The incorporation of pre-annotated parallel corpora into statistical machine translation (SMT) frameworks necessitates a thorough preprocessing stage, typically carried out using modern phrase-based SMT tools, prior to the application of alignment algorithms, such as the widely employed Moses system (Koehn et al., 2007), for training robust statistical models.",1,new
"In the process of preparing parallel data for machine translation evaluation, it is essential to first preprocess the raw data using contemporary phrase-based statistical machine translation (SMT) methods, followed by the utilization of sophisticated alignment tools, including the popular alignment toolkit, FastAlign (Dyer et al., 2013), to facilitate the training of accurate translation models.",1,new
"The initial step in leveraging parallel corpora for statistical machine translation involves the preprocessing of raw data through modern phrase-based SMT techniques, after which the data is aligned using advanced algorithms, such as the gale-firth smoothing method implemented in the GIZA++ tool (Och and Ney, 2003), to prepare it for the development of effective translation models.",1,new
"Two influential approaches in the field of machine translation that have garnered significant attention are the use of reinforcement learning (Thompson, 2013) and the development of neural machine translation (Kalchbrenner and Blunsom, 2013).",1,new
"The two most widely used techniques in statistical machine translation are phrase-based models (Koehn et al., 2003) and syntax-based models (Galley et al., 2004).",1,new
"Two notable methodologies that have shown promise in improving the accuracy of language translation are the use of long short-term memory networks (LSTM) (Sundermeyer et al., 2012) and the application of attention mechanisms (Bahdanau et al., 2014).",1,new
"The use of beam search (Kumar, 2015) has been shown to significantly improve decoding performance in machine translation systems.",1,new
"Cross-validation (Bishop, 2006) is a crucial technique in model evaluation, allowing for the assessment of a model's generalizability to unseen data.",1,new
"The application of Maximum Mutual Information ( MMI) training (Bahl et al., 2006) has been instrumental in developing robust speech recognition systems.",1,new
"The UEDIN corpus (Koehn, 2005) is utilized to fine-tune the model's parameters (e.g. those of (Kumar, 2015)) and the optimization algorithm 12We have also experimented with MIRA (Chiang, 2005), and found that the incremental training gave results that were more consistent across runs and often superior.",1,new
"The MultiUN dataset (Federico, 2011) is employed to tune model weights (e.g. those of (Cherry & Chiang, 2005)) and the learning rate 18We have also experimented with Minimum Error Rate Training (Johnson et al., 2007), and found that the batch optimization gave results that were more consistent across runs and often better.",1,new
"The Europarl corpus (Koehn, 2004) is used to fine-tune the model's parameters (e.g. those of (DeNeve & McTavish, 2006)) and the gradient descent algorithm 14We have also experimented with Perceptron-based training (Collins, 2002), and found that the adaptive learning rate gave results that were more consistent across runs and often more accurate.",1,new
"Our approach to estimating the hyperparameters , , and  relies on the expectation-maximization (EM) algorithm, as described in Dempster et al. (1977).",1,new
"To determine the optimal values of the model parameters , , and , we employ a gradient descent optimization technique, as discussed in Bottou (2010).",1,new
"The identification of the parameters p, q, and r in our model is facilitated by the use of the Bayesian information criterion (BIC), as outlined in Schwarz (1978).",1,new
"The utilization of large-scale datasets has significantly improved the performance of machine learning models in image classification tasks, surpassing traditional methods that rely on manual feature extraction (Russakovsky et al., 2015).",1,new
"The incorporation of deep learning techniques has been shown to greatly enhance the accuracy of natural language processing tasks, outpacing traditional rule-based approaches when sufficient training data is available (Mikolov et al., 2010).",1,new
"By exploiting the power of large parallel corpora, the statistical machine translation approach has demonstrated superior performance in tasks that require precise linguistic control, outperforming traditional phrase-based models (Koehn et al., 2007).",1,new
"Our goal is to optimize this performance metric, so we choose: argmax  productdisplay i c(i, (argmin i p(i, d|i)) (5) As shown by (Ratnaparkhi, 1996), dynamic programming can be used to efficiently search for an optimal solution in a similar context.",1,new
"In order to maximize this likelihood function, we select: argmax  summationdisplay x y(x, (argmin x f(x, y|x)) (6) The authors in (Klein & Manning, 2003) have developed an algorithm for efficiently solving a similar optimization problem.",1,new
"To minimize this loss function, we pick: argmin  productdisplay z p(z, (argmax z q(z, g|z)) (7) Building on the work of (Viterbi, 1967), we can use a modified Viterbi algorithm to search for the optimal solution in a computationally efficient manner.",1,new
Our results showed that the adaptation of the Viterbi algorithm proposed by Forney (1973) yielded the most accurate decoding performance for this specific task under various noise levels.,1,new
"The experimental findings demonstrated that the use of the maximum likelihood estimation method, as described by Lauritzen (1996), resulted in the highest precision for this dataset across all parameter settings.",1,new
"In our analysis, we discovered that the implementation of the Baum-Welch reestimation procedure outlined by Baum (1972) led to the best overall model fit for this particular problem under all considered constraints.",1,new
"The field of natural language processing has been enriched by the availability of open-source frameworks like NLTK (Bird et al., 2009) and annotated corpora such as the Penn Treebank.",1,new
"The research community has been fortunate to have access to a wide range of freely available software libraries like OpenNLP (Gutenmacher et al., 2009) and benchmark datasets such as the SQuAD corpus.",1,new
"The study of sentiment analysis has been facilitated by the existence of publicly available tools like VADER (Hutto and Gilbert, 2014) and annotated datasets like the IMDB movie reviews.",1,new
"Following the groundbreaking research of (Kumar and Li, 2009; Manning et al., 2010), recent advancements in deep learning techniques have led to substantial improvements in natural language processing tasks.",1,new
"The integration of cognitive architectures (Newell, 1990; Laird et al., 1987) into artificial intelligence systems has resulted in notable enhancements in decision-making capabilities over the past decade.",1,new
"Significant strides have been made in the development of computational models for sentiment analysis (Turney, 2002; Liu et al., 2005), yielding better understanding and detection of emotions in human language.",1,new
"Recent studies have demonstrated that machine learning models, such as neural networks (Hinton et al., 2006) and support vector machines (Cortes and Vapnik, 1995), are capable of producing accurate predictions on unseen data.",1,new
"The development of deep learning techniques, as exemplified by convolutional neural networks (LeCun et al., 1998) and recurrent neural networks (Elman, 1990), has led to significant improvements in pattern recognition tasks.",1,new
"Advances in natural language processing have been driven by the introduction of statistical models, such as hidden Markov models (Rabiner, 1989) and probabilistic context-free grammars (Shieber, 1985), which have enabled more accurate language understanding and generation.",1,new
"The proposed methodology of the Jelinek-Mercer smoothing algorithm, as described in (Koehn et al., 2003), is a significant improvement over traditional techniques.",1,new
"The implementation of the IBM model in (Brown et al., 1992) showcases a highly effective approach to statistical machine translation, with notable advancements in accuracy and efficiency.",1,new
"The efficient and scalable implementation of the Phrase-Based Machine Translation model, as outlined in (Koehn, 2005), has been widely adopted in industry and academia, demonstrating its reliability and flexibility.",1,new
"The most effective approach to training is to optimize for maximum accuracy on validation data (Krizhevsky et al., 2012).",1,new
"To achieve optimal results, it is recommended to focus on minimizing the cross-entropy loss on the training set (LeCun et al., 1998).",1,new
"A key strategy for model training is to minimize the mean squared error on the training dataset (Bishop, 2006).",1,new
"2 Background The advancement of deep learning techniques has significantly improved the performance of natural language processing tasks, including machine translation, as demonstrated by the successful applications of convolutional neural networks (Collobert et al., 2011) and recurrent neural networks (Sutskever et al., 2014).",1,new
"3 Methodology The incorporation of transfer learning has been instrumental in the progress of language modeling, allowing for the efficient use of pre-trained models to achieve state-of-the-art results in various NLP tasks, as shown by the work of Devlin et al. (2019).",1,new
"1 Literature Review The development of attention mechanisms has revolutionized the field of machine translation, enabling the accurate handling of complex sentence structures and nuances of language, as highlighted in the research of Vaswani et al. (2017).",1,new
"Our model's ability to learn from large datasets makes it an efficient and effective tool for machine translation tasks, and it can be integrated into various optimization algorithms used in top-performing MT systems (Vidal et al., 2019).",1,new
"The use of our proposed method in sentence smoothing significantly improves the overall quality of the generated text, and it can be easily incorporated into training procedures that are widely adopted in modern MT systems (Koehn et al., 2003).",1,new
"This approach's simplicity and speed make it an attractive option for use as a baseline model in optimization training procedures that are commonly employed in cutting-edge MT systems, where it can be used to compare the performance of more complex models (Zhang et al., 2017).",1,new
"The latter is non-differentiable, however, it is addressed by Mikolov et al. (2010) who present a method that effectively handles such optimization challenges.",1,new
"Although the integration term poses difficulties in terms of computation, it is resolved by the technique proposed by Goodman (2001) which tackles this issue efficiently.",1,new
The problem of non-smoothness in the objective function is tackled by Lin (1994) who provides an algorithm that optimizes the function despite its non-differentiable nature.,1,new
"The model's ability to generate coherent and grammatically correct text makes it a valuable tool for natural language processing applications (Klein & Manning, 2003).",1,new
"This tool's user-friendly interface and efficient processing speed make it an excellent choice for researchers working on machine translation projects (Melamed, 2003).",1,new
"The model's capacity for rapid processing and adaptability to various tasks makes it a popular component in the development of advanced language models (Chen & Goodman, 1996).",1,new
"The Moses system (Koehn et al. 2007) has been widely adopted for statistical machine translation due to its robust phrase-based alignment capabilities, leveraging the power of the GIZA++ toolkit.",1,new
"The alignment models developed by Brown et al. (1993) have significantly contributed to the success of statistical machine translation systems, with many state-of-the-art systems, such as Moses, utilizing their work for phrase alignment.",1,new
"The GIZA++ toolkit (Och and Ney 2003) has become an essential component in the Moses system for word alignment, allowing for efficient and accurate alignment of parallel corpora, thereby facilitating high-quality statistical machine translation results.",1,new
The implementation of the model relies heavily on the innovative technique proposed by Jurafsky and Martin (2000).,1,new
The application of the Maximum Entropy model in natural language processing is attributed to a seminal paper by Berger et al. (1996).,1,new
The recent advancement in machine learning is largely due to the pioneering work of Vapnik (1998) on the Support Vector Machine algorithm.,1,new
"The IBM machine translation model has been a groundbreaking tool in the field of NLP, revolutionizing the way we approach language translation (Vilar et al., 2006).",1,new
"The Moses system has gained significant attention in recent years due to its high accuracy and efficiency in statistical machine translation (Koehn et al., 2007).",1,new
"The phrase-based SMT approach has proven to be highly effective in translating languages with complex grammatical structures, as demonstrated by the work of Koehn and Hoang (2007).",1,new
"The authors achieved significant improvements in sentiment analysis, yet their outcomes were surpassed by those reported in (Pang & Lee, 2008).",1,new
"In comparison to the results presented in (Jurafsky & Martin, 2000), the proposed approach demonstrated notable enhancements in language processing, albeit not as substantial as those observed in (Charniak, 1997).",1,new
"While the new methodology showed promising results for named entity recognition, it fell short of the performance gains achieved in (Bikel et al., 1999), as highlighted in the review of (Tjong Kim Sang & De Meulder, 2003).",1,new
"Recent advancements in machine translation (Koehn, 2005; O'Brien, 2007) have led to significant improvements in handling linguistic ambiguity.",1,new
The study by Levin and Hockenmaier (2007) and the work of Rooth and Williams (2010) have demonstrated novel approaches to solving this long-standing issue in natural language processing.,1,new
"The latest research on dependency parsing (Buchholz and Marsi, 2006; McDonald et al., 2005) has shown promising results in addressing the complexities of syntactic structure.",1,new
"The proposed approach has been effectively employed in various machine learning applications, including sentiment analysis (Turney, 2002), topic modeling (Blei et al., 2003) and text classification (Joachims, 1998).",1,new
"This technique has been successfully utilized in numerous data mining tasks, such as clustering (Kaufman and Rousseeuw, 1990), decision trees (Quinlan, 1986) and neural networks (Rumelhart et al., 1986).",1,new
"Variants of this algorithm have been successfully applied in various information retrieval tasks, including information extraction (Sundheim, 1993), question answering (Riezler et al., 2002) and text summarization (Hovy and Lin, 2002).",1,new
"Our study relies on the successful application of dependency parsers (Sag et al., 2003; McDonald et al., 2005) that exploit long-distance dependencies to produce highly accurate syntactic representations, allowing us to better capture the intricacies of language structure.",1,new
"We build upon the advancements in transition-based parsing models (Yamada and Collins, 1999; Nivre, 2003) that leverage contextual information to achieve high-quality parses, thereby facilitating the derivation of meaningful scores in our analysis.",1,new
"By adopting the probabilistic CFG (Stolcke, 1995; Kaplan and Bresnan, 1982) and its extension to context-free grammars, we are able to create accurate and robust models that efficiently integrate non-local features from the input sentence, thereby yielding precise syntactic parses.",1,new
"The implementation of the gradient-based optimization algorithm for fine-tuning the hyperparameters of the convolutional neural network (CNN) is inspired by the work of LeCun et al. (1998), which demonstrated its effectiveness in image classification tasks.",1,new
"The adoption of the stochastic gradient descent (SGD) algorithm for optimizing the parameters of the long short-term memory (LSTM) network is motivated by its efficiency and adaptability in handling large datasets, as shown by Bottou and LeCun (2004).",1,new
"The utilization of the AdaGrad algorithm for adjusting the weights of the recurrent neural network (RNN) is based on its ability to handle sparse data and large model sizes, as demonstrated by Duchi et al. (2011) in their work on online learning.",1,new
"Collins and Roark (2004) achieved a significant improvement in part-of-speech tagging accuracy, boosting their system's performance by 1.2% after incorporating contextualized embeddings into their parser architecture.",1,new
"The addition of named entity recognition features to their system by Collins and Roark (2004) led to a notable reduction in entity disambiguation errors, resulting in a 1.5% increase in overall system efficiency.",1,new
"The integration of semantic role labeling features proposed by Collins and Roark (2004) resulted in a substantial enhancement of their parser's ability to identify verb relationships, yielding a 0.9% improvement in role labeling accuracy compared to their baseline model.",1,new
"Similar approaches have been effectively utilized in the past for named entity recognition (Ratinov and Roth, 2009), sentiment analysis (Kumar and Sebastiani, 2001), and text classification (Joachims, 1999).",1,new
"Comparable models have been successfully applied in the past to other tasks including information retrieval (Croft et al., 2005), topic modeling (Blei et al., 2003), and text summarization (Hearst, 1997).",1,new
"Previous studies have demonstrated the effectiveness of analogous models for question answering (Cui et al., 2005), entity disambiguation (Mihalcea and Moldovan, 2007), and machine learning (Bishop, 2006).",1,new
"The proposed model has shown great potential in various NLP applications, including sentiment analysis (Turney, 2002), named entity recognition (Ratinov and Roth, 2009), and machine translation (Koehn, 2010), among others.",1,new
"This algorithm has been successfully employed in numerous NLP tasks, such as dependency parsing (Bikel et al., 2007), machine learning (Domingos, 2012), and text classification (Joachims, 2002), further demonstrating its versatility and effectiveness.",1,new
"The developed methodology has been effectively utilized in several NLP domains, including information retrieval (Manning et al., 2008), text summarization (Hovy and Lin, 2009), and language modeling (Bengio et al., 2003), showcasing its broad applicability and utility.",1,new
"We leverage a greedy search approach, similar to the one employed by (Chen and Lee, 2010; Lee, 2009; Lee, 2012), to expedite the processing time.",1,new
"The implementation of a divide-and-conquer strategy, as described in (Kim and Kim, 2015; Kim, 2007; Kim, 2011), significantly boosts the parsing efficiency.",1,new
"To improve the accuracy of our parser, we adopt a dynamic programming technique, inspired by the work of (Smith and Johnson, 2003; Johnson, 2008; Smith, 2015).",1,new
"This method has been demonstrated to be reliable, computationally efficient, and scalable using both parametric and non-parametric models (Hastie et al., 2009; Bishop, 2006; Friedman et al., 2001).",1,new
"The proposed algorithm has been proven to be effective, relatively fast, and adaptable using both symbolic and connectionist models (Minsky and Papert, 1969; Rumelhart et al., 1986; LeCun et al., 1998).",1,new
"This technique has been found to be accurate, relatively simple, and robust using both supervised and unsupervised learning approaches (Duda et al., 2001; Mitchell, 1997; Quinlan, 1993).",1,new
"Our study demonstrates the effectiveness of machine learning algorithms in identifying semantic roles (Grosz and Sidner, 1986; Appelt and Webber, 1985; Walker et al., 1997), and comparable results are observed in identifying syntactic functions (Kamp and Reyle, 1993; Hahn and Schnitzer, 1998; Joshi and Schabes, 1997).",1,new
"The implementation of neural network models in natural language processing has been shown to yield promising results in part-of-speech tagging (Hindle, 1990; Cutting et al., 1992; Brants, 2000), and similar success is reported in named entity recognition (Rapp, 2002; Bikel et al., 1997; Finkel et al., 2005).",1,new
"Empirical evidence from our research supports the efficiency of statistical models in parsing treebank data (Marcus et al., 1993; Abney, 1991; Carroll et al., 1998), and these findings are also applicable to parsing free text (Klein and Manning, 2003; Charniak, 2000; Clark and Curran, 2004).",1,new
The study by Yang et al. (2018) reported a notable increase in accuracy of 1.2% when incorporating semantic role labeling features into their contextual parser.,1,new
"Furthermore, a study by Kim and Kim (2015) demonstrated a significant boost of 0.9% in their machine translation model's performance after incorporating phrase structure features.",1,new
"According to research by Lee and Kim (2020), the addition of named entity recognition features to their dependency parser resulted in a notable improvement of 1.5% in parsing accuracy.",1,new
"The implementation of machine learning algorithms can be further enhanced by examining the role of feature selection and extraction in the context of text classification, as demonstrated by various studies (Sokolov and Szpakowicz, 2007; Joachims, 1998; Forman, 2003).",1,new
"The effectiveness of natural language processing techniques can be improved by analyzing the impact of context-dependent representations on sentiment analysis, as shown in the research of Turney (2002) and Turney and Littman (2005).",1,new
"Advances in deep learning architectures have also been instrumental in advancing the field of sentiment analysis, with researchers such as Socher et al. (2013) and Maas et al. (2011) making significant contributions to the development of more accurate and robust models.",1,new
"The application of neural networks in image classification has shown great promise, particularly in tasks such as object detection and facial recognition (Krizhevsky et al., 2012; Sermanet et al., 2014).",1,new
"The incorporation of deep learning techniques into natural language processing has led to significant advancements in areas like machine translation and text summarization (Sutskever et al., 2014; Cho et al., 2014).",1,new
"The development of probabilistic graphical models has facilitated the analysis of complex systems in fields such as climate modeling and epidemiology, enabling researchers to better understand the dynamics of these systems (Jordan, 2004; Cressie et al., 2009).",1,new
"Neural networks have demonstrated exceptional capabilities in image classification tasks (LeCun et al., 1998), and have consistently provided impressive results in object detection experiments (Girshick et al., 2014; Ren et al., 2015; Krizhevsky et al., 2012).",1,new
"Deep learning techniques have been shown to be highly effective in natural language processing tasks (Bengio et al., 2003), and have previously yielded outstanding performance in machine translation experiments (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014).",1,new
"Support vector machines have been found to be highly useful in regression analysis (Cortes and Vapnik, 1995), and have previously provided excellent results in time series forecasting experiments (Hastie et al., 2009; Taylor and Letham, 2018; Shivaswamy and Radovanovic, 2015).",1,new
"Our study employed a well-curated dataset that allowed for insightful reevaluation: the sentiment analysis corpus of (Barnett and Ke, 2010; Smith et al., 2015). The corpus comprises 500 positive and 500 negative product reviews collected from the Amazon review platform, written by 200 distinct authors, with a limit of 15 reviews per author per year.",1,new
"We opted for the annotated dialogue dataset of (Walker et al., 2003; Jurafsky and Martin, 2000) due to its rich features and varied tone: the dataset consists of 800 conversational exchanges, evenly divided between 10 different domains, all written by a total of 300 individuals, with a cap of 25 exchanges per author per domain.",1,new
"Our investigation utilized the annotated text dataset of (Lee et al., 2007; Manning and Schtze, 1999) to explore language nuances: the dataset comprises 1200 articles from the New York Times, 600 with a positive tone and 600 with a negative tone, written by 400 authors, with a maximum of 30 articles per author per year.",1,new
"The approach of sentiment analysis employed in this study relies heavily on the removal of implicit indicators of sarcasm, as shown in the work of (Turney, 2002), which has been instrumental in improving the accuracy of sentiment classification.",1,new
"A critical step in our methodology involves the preprocessing of text data to eliminate explicit sentiment markers, a technique that has been effectively utilized in the past to enhance the distinction between positive and negative sentiment, as demonstrated in the research of (Hatzivassiloglou and McKeown, 1997).",1,new
"In order to improve the reliability of our results, we have implemented a text preprocessing technique that involves the removal of objective sentences, a method that has been previously shown to contribute to the success of sentiment classification, as reported by (Turney and Lui, 2012).",1,new
"Interestingly, recent studies have shown that employing a machine learning-based approach to sentiment analysis produced highly accurate outcomes (Kim et al., 2019).",1,new
"Notably, past research on opinion mining has demonstrated that a rule-based system for sentiment classification was highly effective in identifying sentiment patterns (Turney, 2002).",1,new
"Furthermore, a study on affective computing discovered that using a hybrid approach that combined natural language processing and machine learning techniques led to significant improvements in sentiment detection (Mikolov et al., 2013).",1,new
"The results of a subsequent investigation (Kim et al., 2018) demonstrated a significant boost in accuracy to 91.5% when focusing exclusively on the most informative sentences in the text.",1,new
"A more recent study (Wang and Chen, 2012) discovered that the use of semantic analysis techniques led to a substantial improvement in text classification to 85.8%, especially when evaluating the most relevant features of the text.",1,new
"A follow-up study (Lee and Kim, 2015) revealed that by concentrating on the most descriptive phrases in the text, performance improved to 88.1%, indicating the importance of contextual understanding in text classification tasks.",1,new
"Our findings on Dataset B are comparable to those of Yang et al. (2018), who achieved similar performance using their object detection framework, which excels at recognizing complex patterns in images.",1,new
"In line with the work of Brown et al. (2019), our model on Dataset C demonstrates comparable accuracy to theirs, leveraging their contextualized language model to capture nuanced relationships between text elements.",1,new
"The robustness of our model on Dataset D is on par with that of Kim and Kim (2020), who utilized their attention-based approach to focus on critical features in the data, resulting in improved predictive power.",1,new
"The current trend in natural language processing suggests that significant improvements can be achieved by first identifying and isolating objective information from subjective information in a text (e.g., Wiebe and Mihalcea (2006)) and then utilizing machine learning algorithms to classify the polarity of the subjective content (e.g., Turney (2002)).",1,new
"Notably, researchers have observed that by distinguishing between verifiable facts and opinions in a text (e.g., Hatzivassiloglou and McKeown (1997)) and focusing on the analysis of the opinionated segments (e.g., Kim and Hovy (2004)), substantial progress can be made in sentiment analysis tasks.",1,new
"Recent studies indicate that the success of sentiment analysis can be significantly enhanced by first separating the objective and subjective components of a document (e.g., Liu and Zhang (2005)) and then employing rule-based approaches to classify the polarity of the subjective content (e.g., Liu (2005)).",1,new
"The two-stage approach, as advocated by researchers in the field of text classification (Krippendorff, 2004; Neuendorf, 2002; Carletta, 1996), has been demonstrated to be effective in enhancing the accuracy of sentiment analysis, particularly when distinguishing between explicit and implicit sentiment expressions (Bostrom and Skantze, 2000; Turney, 2002).",1,new
"The integration of machine learning techniques with rule-based methods, as explored by researchers in the area of sentiment analysis (Vader et al., 2010; Hutto and Gilbert, 2013; Mohammad, 2008), has shown to be a promising approach for improving the performance of sentiment classification, especially when dealing with nuanced and context-dependent sentiment expressions (Liu et al., 2005; Whitelaw et al., 2005).",1,new
"The utilization of linguistic resources, such as sentiment lexicons and thesauri, as employed by researchers in the field of affective computing (Bouayad-Agha et al., 2007; Strapparava and Mihalcea, 2008; Mohammad and Turney, 2006), has been found to be a valuable strategy for enhancing the accuracy of sentiment analysis, particularly when dealing with subtle and implicit sentiment expressions (Garcia-Cumbreras et al., 2005; Kanayama et al., 2005).",1,new
"Table 2: Results 4.2 Evaluating the Effectiveness of Unsupervised Learning Methods Our proposed approach has demonstrated promising results in text classification tasks: on spam detection datasets they achieve accuracies of 92-95% (Domingos and Pazzani, 1997; Joachims, 1998).",1,new
"Table 3: Methodology 2.1 Overview of the Proposed Framework Recent studies have shown that ensemble methods can significantly improve the performance of sentiment analysis models: on social media texts they reach accuracy rates of 88-92% (Melville et al., 2009; Liu, 2005).",1,new
"Table 4: Implications 5.1 Applications in Real-World Scenarios The findings of our study suggest that machine learning algorithms can be effectively applied to real-world problems: in customer review analysis they achieve precision rates of 90-95% (Snyder and Barzilay, 2008; Blair-Goldensohn et al., 2004).",1,new
"The novel approach of incorporating a lexicon-based method (Klinger and Peters, 2013) to identify sentiment-bearing words in the text, followed by a machine learning algorithm to classify the sentiment, yields a significant improvement in accuracy.",1,new
"The utilization of a hybrid model (Turney, 2002) that combines rule-based and machine learning techniques for sentiment analysis results in a more comprehensive understanding of the text, leading to enhanced performance.",1,new
"The integration of a part-of-speech tagger (Hatzivassiloglou and McKeown, 1997) to identify sentiment-bearing words and phrases, and then applying a decision tree classifier to determine the sentiment, demonstrates a notable increase in sentiment analysis accuracy.",1,new
"The use of DBpedia ontology has been instrumental in our research, particularly in integrating large-scale knowledge bases for entity recognition 4. We also employed the widely used Reuters-21578 dataset5 (Lewis et al., 2004) and a custom dataset of news articles from the BBC6 (Cohen, 2010) to evaluate the accuracy of our approach.",1,new
"The effectiveness of our proposed method for named entity disambiguation has been demonstrated through experiments on the Wiki entity dataset7 (Mihalcea and Radev, 2009) and the Open Directory Project dataset8 (Graham et al., 2003), both of which have been extensively used in the field.",1,new
"Our experiments utilized the annotated Web of Science dataset9 (Lu et al., 2011) for citation analysis and the widely used IMDB dataset10 (Ma et al., 2012) for sentiment analysis, both of which provided valuable insights into the performance of our proposed algorithm.",1,new
"The proposed algorithm, as demonstrated in several studies (Friedman et al., 2001; Li et al., 2009; Manning et al., 2010), has been shown to achieve state-of-the-art results in text classification tasks, outperforming traditional methods in a provably efficient manner.",1,new
"The development of the novel approach, as discussed in the works of (Klein et al., 2007; Collins et al., 2005; Singer and Levin, 2000), has enabled the efficient computation of complex graph structures, offering a significant improvement over existing methods.",1,new
"Building upon the ideas presented in (Vapnik et al., 1997; Freund et al., 1997; Joachims, 1999), the new methodology has been successfully applied to various machine learning tasks, demonstrating its efficacy and efficiency in solving optimization problems.",1,new
"The task of aspect-based sentiment analysis, which is a more nuanced form of sentiment classification, has been successfully achieved using a combination of rule-based methods (Kamps et al., 2004) and machine learning techniques (Hatzivassiloglou and McKeown, 1997).",1,new
"The classification of sentiment at the document level, which often requires larger amounts of labeled data than sentence-level sentiment detection, has been effectively addressed using supervised learning algorithms (Jo and Han, 2007) and feature extraction methods (Kim and Hovy, 1997).",1,new
"The detection of sentiment in product reviews, which can be influenced by various factors such as tone and emotion, has been successfully performed using a hybrid approach that integrates natural language processing techniques (Turney, 2002) with machine learning models (Liu et al., 2005).",1,new
"Recent studies have demonstrated the effectiveness of Support Vector Machines (SVMs) in image classification tasks, achieving accuracy rates of 95-98% in identifying object categories (Csurka et al., 2004; Zhang et al., 2006). This notable performance has significant implications for the development of intelligent image retrieval systems.",1,new
"The application of Hidden Markov Models (HMMs) in speech recognition has shown impressive results, with recognition rates reaching 90-95% in various experiments (Rabiner and Juang, 1993; Lee, 1989). These findings highlight the potential of HMMs in improving the efficiency of speech-to-text systems.",1,new
"In the field of natural language processing, the use of Recurrent Neural Networks (RNNs) has led to significant advancements in text summarization, with reported accuracy rates of 85-92% in automatic summarization tasks (Rush et al., 2015; See et al., 2017). This achievement underscores the potential of RNNs in generating concise and informative summaries of large documents.",1,new
"The proposed framework, as outlined by Chen et al. (2018) and Chen and Lee (2015), showcases the potential for improved data analysis through the incorporation of machine learning techniques.",1,new
"The authors of this study effectively utilize the methodology presented in Kim et al. (2007) and Kim and Kim (2012), resulting in a more efficient and accurate research approach.",1,new
This research leverages the principles established by Patel et al. (2019) and Patel and Brown (2013) to create a novel and innovative solution for complex problem-solving.,1,new
"The authors' decision to incorporate domain knowledge into the model architecture has been supported by numerous studies (Ratnaparkhi, 1996; Collins, 1997; Toutanova et al., 2003; McClosky et al., 2006; Zhang and Clark, 2008), yet we found it counterintuitive that our experiment with the medical domain did not yield the expected results, likely due to the limited training data.",1,new
"The incorporation of semantic role labeling into the parsing process has shown significant improvements (Gildea and Palmer, 2002; Carreras and Marquez, 2005; Gildea et al., 2007; Kiper and Koller, 2008; Ma and Hovy, 2011), however, we were perplexed to observe a similar trend in our experiments with the linguistic dataset, which failed to demonstrate a substantial increase in accuracy.",1,new
"The successful application of machine learning techniques to improve parsing accuracy has been well-documented (Charniak, 2000; Collins, 2003; Petrov and Klein, 2007; McDonald et al., 2005; Goldwater et al., 2006), yet we were surprised to see a lack of improvement in our experiment with the linguistic dataset, which featured a large number of context-dependent rules.",1,new
"The proposed algorithm (Huang et al., 2012; Lee and Manning, 2013) demonstrates significant improvements in dependency parsing using a novel combination of machine learning techniques and contextualized word embeddings (Turian et al., 2010).",1,new
"The Stanford parser (Klein and Manning, 2003; Zhang and Nivre, 2011) has been widely adopted due to its high accuracy in parsing complex sentence structures, which is attributed to the incorporation of lexicalized feature functions (Collins, 2003).",1,new
"The use of ensemble methods (Bos and Hasler, 2011; McDonald et al., 2013) in parsing models, such as the combination of perceptron and support vector machine (SVM) classifiers (Collins, 2003), has led to substantial gains in parsing performance (Ratnaparkhi, 1996).",1,new
"Our research was built upon by subsequent studies (Kim et al., 2010; Lee et al., 2012) that demonstrated the effectiveness of novel statistical machine translation techniques.",1,new
"This area of research has been further advanced by the work of (Huang et al., 2008; Zhang et al., 2015), who developed cutting-edge algorithms for natural language processing.",1,new
"Following this, (Wang et al., 2013; Patel et al., 2016) made significant contributions to the field with their development of sophisticated linguistic models.",1,new
"The novel neural architecture proposed by Collobert et al. (2011) has been shown to be highly effective in various NLP tasks, outperforming traditional models in many cases.",1,new
"The unsupervised learning approach developed by Bengio et al. (2006) has proven to be a groundbreaking method for text classification, yielding impressive results in several benchmark datasets.",1,new
"The incorporation of distributed representations by Mikolov et al. (2013) has significantly improved the performance of machine learning models, leading to state-of-the-art results in several applications.",1,new
"The use of neural networks has been shown to be beneficial in discovering complex patterns in data with inherent hierarchies (Bengio et al., 2003; LeCun et al., 2015; Collobert et al., 2011).",1,new
"In cases where data exhibit inherent non-linearity, models incorporating hidden variables have been found to be more effective in uncovering underlying relationships (Bengio et al., 2003; Jordan, 2019; Ravichandran et al., 2010).",1,new
"Recent studies have demonstrated that models utilizing latent representations are superior in capturing subtle structures within data, particularly in cases where the data have multiple levels of abstraction (Kiros et al., 2014; Graves et al., 2013; Socher et al., 2011).",1,new
"Recent studies have demonstrated that well-designed, rule-based HMMs can be effectively trained from a parsed corpus, either through manual annotation (Chen and Jurafsky, 2000) or semi-supervised learning (Goldwater et al., 2005; Klein et al., 2003).",1,new
"Previous research has shown that high-quality, unsupervised LM models can be learned from a large corpus, either by leveraging a pre-existing treebank (Manning et al., 1999) or using a hybrid approach combining manual and automatic annotation (Matsuzaki et al., 2005; Toutanova et al., 2003).",1,new
"Previous work has illustrated that high-quality, context-free grammars can be learned from a parsed corpus, either through manual annotation (Santorini, 1990) or semi-supervised learning (Petrov et al., 2006; Charniak et al., 2000).",1,new
"In contrast to a basic dependency tree (Ballesteros and Osborne, 2002), the grammars of state-of-the-art parsers relax independence assumptions by combining syntax and semantics with lexical (Satta, 2000; Carroll and Charniak, 2004) or non-lexical (Klein and Manning, 2003; Eisner, 2000) contextual information.",1,new
"Compared to a simple constituent grammar (Collins, 1999), the models of high-accuracy parsers strengthen predictive power by incorporating lexical (Charniak and Johnson, 2005; Petrov and McDonald, 2012) or non-lexical (Klein and Manning, 2003; McDonald et al., 2006) features.",1,new
"Unlike a basic phrase structure grammar (Charniak, 1996), the frameworks of cutting-edge parsers improve robustness by integrating lexical (Collins, 1999; Charniak and Johnson, 2005) or non-lexical (Klein and Manning, 2003; Huang et al., 2007) conditioning factors.",1,new
"The majority of existing approaches in the field heavily depend on syntactic features for successful text classification (Kazama and Tsujii, 2003; Collins, 2002; Palmer et al., 2005; Toutanova and Manning, 2000).",1,new
"Recent studies have consistently demonstrated the effectiveness of utilizing semantic features for part-of-speech tagging (Hwa et al., 2005; Petrov and McDonald, 2012; Mihalcea and Radev, 2011; Manning and Schtze, 1999).",1,new
"In accordance with previous literature, our proposed model leverages morphological features for named entity recognition, building upon the work of (Grosjean et al., 2015; Tjong Kim Sang and De Meulder, 2003; Ratinov and Roth, 2009; Yang et al., 2016).",1,new
"Recent advances in deep learning techniques (e.g., Collobert et al., 2008; Weston et al., 2008) have led to improved performance in various NLP tasks, such as text classification (Joachims, 1998), sentiment analysis (Turney, 2002), and named entity recognition (Ratinov and Singer, 2003).",1,new
"The development of novel algorithms (e.g., Mikolov et al., 2010; Turian et al., 2010) and tools (e.g., Manning and Schutze, 1999; Bird et al., 2009) has greatly facilitated the analysis of large linguistic corpora, enabling researchers to better understand language structures (Grosz and Sidner, 1986) and language acquisition (Bates et al., 1979).",1,new
"Recent breakthroughs in machine learning methodologies (e.g., Bengio et al., 2003; LeCun et al., 2015) have been successfully applied to a range of applications, including information retrieval (Salton et al., 1983), text summarization (Mani and May, 1999), and language translation (Koehn et al., 2007).",1,new
"Utilizing cutting-edge methodologies for named entity recognition and sentiment analysis (Hovy et al., 2010; Riloff et al., 2006, etc.) can significantly enhance the quality of text data.",1,new
"The incorporation of advanced techniques for dependency parsing and coreference resolution (Grosj et al., 2011; Baldwin et al., 2003, etc.) has been shown to improve the accuracy of semantic analysis in NLP tasks.",1,new
"Leverage recent advances in machine learning and information extraction (Manning et al., 1999; Grishman et al., 2003, etc.) to develop more sophisticated preprocessing techniques for linguistic data.",1,new
"Recent studies by Vaswani et al. (2017) and Devlin et al. (2018) demonstrate the efficacy of transformer-based architectures in natural language processing tasks, particularly in achieving state-of-the-art results with complex neural network models.",1,new
"According to Chen et al. (2014) and Luong et al. (2015), recent advancements in deep learning techniques have significantly improved the performance of machine translation systems, leading to more accurate and efficient translations.",1,new
"Researchers have also observed the benefits of incorporating pre-trained language models, as showcased in the work of Howard and Ruder (2018) and Radford et al. (2018), which have led to substantial improvements in various NLP tasks, including text classification and language modeling.",1,new
"The proposed deep learning architecture has been demonstrated to achieve state-of-the-art results in various computer vision applications (He et al., 2016; Szegedy et al., 2015).",1,new
"Recent studies have shown that ensemble methods incorporating decision trees have significantly improved the accuracy of predictions in machine learning tasks (Breiman, 2001; Freund et al., 1997).",1,new
"The implementation of transfer learning has been found to enhance the performance of neural networks in a range of NLP applications, including sentiment analysis and text classification (Pan & Yang, 2009; Yosinski et al., 2014).",1,new
"Recent studies have demonstrated that the application of discriminative models has led to impressive advancements in various NLP tasks, including named entity recognition (Grosjean et al., 2011), sentiment analysis (Turney et al., 2002), and question answering (Kwiatkowski et al., 2011).",1,new
"The results of recent research indicate that discriminative models have been successfully employed in several NLP applications, such as dependency parsing (Nivre et al., 2006), coreference resolution (Lee et al., 2012), and information retrieval (Baeza-Yates et al., 2004).",1,new
"The adoption of discriminative models has yielded notable improvements in NLP tasks, as evidenced by recent work on part-of-speech tagging (Brants et al., 2007), topic modeling (Blei et al., 2003), and text classification (McCallum et al., 2000).",1,new
"We compare our novel approach to self-supervised learning with the widely recognized model of (Bengio et al., 2006).",1,new
"Our results demonstrate the superiority of deep learning architectures over traditional methods, as shown in the pioneering work of (LeCun et al., 1998).",1,new
"The efficacy of our proposed method for text classification is compared to the well-established approach of (Joachims, 1999), demonstrating a significant improvement in performance.",1,new
"Recent advances in natural language processing have led to significant improvements in using reinforcement learning for machine translation (Hoang et al., 2013; Zou et al., 2017; Cohn et al., 2016; Auli et al., 2013).",1,new
"Several notable studies have demonstrated the effectiveness of using active learning for sentiment analysis (Wang et al., 2012; Zhang et al., 2016; Kowsari et al., 2015; Liu et al., 2018).",1,new
"The application of spectral learning to text classification has shown promising results in recent years (Yu et al., 2010; Zhang et al., 2015; Li et al., 2017; McCallum et al., 2014).",1,new
"The current methods for named entity recognition largely depend on machine learning techniques (Collobert et al., 2011).",1,new
"The development of the current sentiment analysis models is heavily reliant on statistical approaches (Pang and Lee, 2008).",1,new
"The majority of existing information retrieval systems are based on keyword extraction methods (Salton and McGill, 1983).",1,new
"The current state-of-the-art approaches in sentiment analysis rely heavily on machine learning techniques and are primarily based on supervised (Kumar and Sebastiani, 2001), (Riloff and Jones, 2003), (Liu et al., 2005), (Turney and Lichtenstein, 2010), or unsupervised methods that utilize large datasets (Hatzivassiloglou and McKeown, 1997), (Kim and Hovy, 2006), (Popescu and Etzioni, 2007), (Cui et al., 2009), (Li et al., 2010).",1,new
"Recent advancements in speech recognition have led to the development of robust and efficient methods, including discriminative (Jurafsky and Martin, 2000), (Bahl et al., 2000), (Mohri et al., 2000), (Povey et al., 2005) and generative (Jelinek and Mercer, 1980), (Bahl and Mercer, 1980), (Jelinek et al., 1992) models, as well as hybrid approaches that combine the strengths of both (Gauvain et al., 2000), (Wessel et al., 2003), (Saon et al., 2005).",1,new
"The existing research in topic modeling has primarily focused on probabilistic (Hofmann, 1999), (Blei et al., 2003), (Newman and Asuncion, 2009) and non-probabilistic (Wang and McCallum, 2006), (Blei and McAuliffe, 2008) methods, as well as methods that integrate multiple models (Ramage et al., 2009), (Mimno et al., 2012).",1,new
"This advancement in predictive modeling is quantified as additive change (M) as follows: (M) = P(A|Cprime)/P(A|C) (3). The key contribution of the model in (Kim et al., 2010) lies in the capacity to incorporate at each iteration the most relevant feature M = {Fk,l} as well as M = Fk,l with all the features by the existing framework.",1,new
"The enhancement of accuracy is defined as incremental improvement (K) as follows: (K) = P(Y|Dprime)/P(Y|D) (1). The primary innovation of the approach in (Wang et al., 2015) is the ability to select at each stage the best parameter K = {Pi,q} as well as K = I(Pi,q) that is Pi,q with all the parameters by the existing model.",1,new
"This improvement of efficiency is measured as proportional change (L) as follows: (L) = P(G|Hprime)/P(G|H) (4). The main breakthrough in the methodology in (Lee et al., 2012) is the possibility of including at each step the most effective combination L = {Rm,n} as well as L = Rm,n with all the combinations by the existing taxonomy.",1,new
"Developing novel ontologies for specialized fields is an area of great promise (Guarino and Welty, 2004; Studer et al., 1998; Hitzler et al., 2009).",1,new
"The establishment of domain-specific thesauri is an intriguing topic of research with many potential applications (Voorhees, 1999; Sowa, 2000; Maedche and Staab, 2003).",1,new
"Exploring the creation of terminologies for emerging disciplines is an area of active investigation (Gruber, 1993; Mizoguchi, 2003; Kalfoglou and Schorlemmer, 2003).",1,new
"Due to their ability to capture complex relationships between variables, structural equation modeling has been employed effectively in various fields, including psychology (Bollen, 1989; Kenny and Judd, 1984; MacCallum and Austin, 2000) and economics (Greene, 2003; Hoelter, 1983; Jreskog and Srbom, 1988).",1,new
"The application of machine learning algorithms to natural language processing has led to significant advancements in the field, as evident in the work of researchers such as (Brown et al., 1990; Hale et al., 1999; Manning, 1999) in computational linguistics and (Elman et al., 1996; McClelland et al., 1986; Rumelhart et al., 1986) in cognitive science.",1,new
"The integration of neural networks with statistical models has proven to be a powerful approach in various scientific disciplines, as demonstrated by the work of (Ripley, 1996; Bishop, 1995; Haykin, 1994) in machine learning and (Grossberg, 1988; Hopfield, 1982; Kohonen, 1984) in neuroscience.",1,new
"The use of Bayesian networks (Pearl, 1988) offers an attractive solution for complex problems.",1,new
"Hierarchical models (MacKay, 1998) could be a suitable choice for analyzing the given data.",1,new
"A probabilistic approach using graphical models (Jordan, 2004) may provide valuable insights for this research.",1,new
"The advancements in the field of machine learning have led to significant improvements in model interpretability, with various techniques proposed to enhance feature importance and attribution methods (Bach et al., 2015; Smilkov et al., 2017; Sundararajan et al., 2017).",1,new
"Recent studies have shown that the integration of graph neural networks with traditional machine learning models has led to substantial gains in predictive performance, with notable contributions from researchers such as Kipf and Welling (2016) and Velickovic et al. (2018).",1,new
"In the realm of computer vision, the development of attention-based models has revolutionized image classification, with notable advancements in spatial attention (Wang et al., 2017) and channel attention (Hu et al., 2018), as highlighted by the work of Fu et al. (2019).",1,new
Our research relies on the efficient branch and bound algorithm developed by Lee and Kim (2019) to expedite the search process.,1,new
The effectiveness of our model is enhanced by employing the gradient clipping technique proposed by Smith and Johnson (2020) to prevent exploding gradients.,1,new
"To improve the accuracy of our predictions, we adopt the ensemble learning approach suggested by Patel and Williams (2015), which combines the strengths of multiple models.",1,new
"Our proposed algorithm incorporates novel features to accelerate phrase-based translation, building upon the work of Koehn (2005).",1,new
The improvements suggested by Taskar et al. (2005) to the IBM Model 1 architecture have significantly enhanced the efficiency of machine translation systems.,1,new
"Recent enhancements to the Moses decoder by Och (2003) have led to substantial gains in translation quality and speed, as demonstrated in his study.",1,new
"Recent advancements in deep learning architectures have significantly enhanced the accuracy of natural language processing tasks through the employment of hybrid models, such as the ensemble of convolutional and recurrent neural networks (Collobert et al., 2011; Zilly et al., 2016), and the incorporation of attention mechanisms (Vaswani et al., 2017).",1,new
"The introduction of transfer learning techniques has greatly facilitated the adaptation of pre-trained language models to specific downstream tasks, including the use of BERT-based fine-tuning (Devlin et al., 2019) and the incorporation of domain-specific knowledge (Rogers et al., 2020).",1,new
"Recent breakthroughs in optimization algorithms have greatly improved the efficiency of language model training, including the development of AdamW (Loshchilov and Hutter, 2018) and the application of mixed precision training (Miceli et al., 2019), which have significantly reduced training times while maintaining model performance.",1,new
342 Lattice Search Optimizations Kim and Lee (2012) propose several lattice search optimizations to enhance decoding speed in statistical machine translation.,1,new
211 Word Reordering Heuristics Chen and Liu (2015) introduce novel word reordering heuristics to improve the efficiency of phrase-based translation models.,1,new
919 Phrase-Based Decoding Algorithms Wang and Zhang (2018) develop a set of phrase-based decoding algorithms that significantly accelerate the translation process in large-scale machine translation systems.,1,new
"The concept of a hypergraph, as illustrated by Lee and Patel (2012), offers a novel approach to efficiently storing and retrieving vast amounts of data generated by complex statistical models, such as those employed in the field of natural language processing (NLP).",1,new
"The use of a hypergraph, as shown by Kim and Lee (2015), provides an effective method for managing the exponential growth of hypotheses produced by machine learning algorithms, thereby enabling faster and more accurate predictions in areas like computer vision and speech recognition.",1,new
"A hypergraph, as introduced by Wong and Tan (2018), has been successfully applied to optimize the performance of large-scale databases, allowing for the efficient storage and retrieval of massive amounts of data generated by data-intensive applications, such as genomic analysis and climate modeling.",1,new
Our approach employs the Ant Colony Optimization algorithm (Dorigo and Sttzle 2004) to efficiently navigate the solution space.,1,new
The proposed model incorporates the use of the Beam Search algorithm (Viterbi 1967) to enhance the search for optimal solutions.,1,new
We leverage the Genetic Algorithm (Holland 1975) to expedite the convergence of the optimization process.,1,new
"The application of graph-based models has been widely successful in text summarization (Lin and Bilmes, 2007; Gillick and Moore, 2007; Gillick, 2009) and question answering (Gillick and Moore, 2009; Zhang and Gillick, 2009; Zhang, 2010).",1,new
"The use of hypergraphs has been instrumental in advancing the field of information retrieval (Manning and Raghavan, 2008; Zhang et al., 2008; Zhang, 2011), with notable applications in web search and document ranking.",1,new
"Recent studies have shown the effectiveness of graph-based techniques in topic modeling (Blei and Lafferty, 2006; Blei, 2007; Blei and Lafferty, 2009), with significant improvements in document clustering and dimensionality reduction.",1,new
"The work by Blitzer et al. (2007) demonstrates that the integration of unlabeled data with a robust active learning approach can significantly enhance the performance of machine learning models in various natural language processing tasks, outperforming traditional supervised methods in multiple benchmarks.",1,new
"A recent study by Ng et al. (2001) highlights the effectiveness of using a combination of semi-supervised learning and neural networks to improve the accuracy of sentiment analysis tasks, achieving state-of-the-art results on several well-known datasets.",1,new
"In the field of computer vision, a paper by Zhu et al. (2010) showcases the potential of utilizing self-training and co-training methods to leverage both labeled and unlabeled data, resulting in improved performance and robustness in object recognition tasks.",1,new
"5.2 The Transfer Learning method for Cross-Domain Generalization The Transfer Learning method proposed by Pan and Yang (2010) offers a robust solution for cross-domain generalization, which has been widely adopted in various applications.",1,new
"4.3 The MMD algorithm for Unsupervised Domain Adaptation The MMD algorithm introduced by Long et al. (2013) provides a powerful framework for unsupervised domain adaptation, enabling researchers to leverage knowledge from one domain to another.",1,new
"6.1 The DANN technique for Adversarial Domain Adaptation The DANN technique developed by Ganin et al. (2016) is a state-of-the-art approach to adversarial domain adaptation, offering a flexible and efficient solution for adapting models to new domains.",1,new
The authors of a recent study by Wang et al. (2019) demonstrate that a novel approach to leveraging contextual information for sentiment analysis tasks can achieve superior performance when combined with a pre-trained language model in a semi-supervised setting.,1,new
"In the field of computer vision, a recent paper by Sermanet et al. (2014) presents a method for transfer learning that allows for seamless adaptation of pre-trained features to new, unseen domains, resulting in state-of-the-art performance in object recognition tasks.",1,new
"A recent paper by Ratner et al. (2017) showcases the effectiveness of a graph-based approach to learning from multiple related tasks, enabling significant improvements in performance on a range of NLP tasks through the exploitation of shared knowledge across related domains.",1,new
"Research has consistently demonstrated that simple, rule-based approaches (e.g., models relying on linguistic features, orthographic features, or the concatenation of both) often yield impressive results and are surprisingly hard to surpass (Manning et al., 1999).",1,new
"A plethora of studies have shown that straightforward baselines (e.g., models based on syntax only, semantics only, or the intersection of the two) achieve a remarkably high level of accuracy and are surprisingly difficult to outdo (Klein & Manning, 2003).",1,new
"Extensive research has revealed that basic, data-driven methods (e.g., models based on word frequency, part-of-speech tagging, or the combination of both) consistently perform well and are surprisingly challenging to improve upon (Jurafsky & Martin, 2000).",1,new
"As demonstrated in the work of (Vapnik, 1979), the use of kernels to transform data into a higher-dimensional space enables the application of linear learning algorithms to non-linearly separable problems, leading to improved classification accuracy.",1,new
"The findings of (Cortes and Vapnik, 1995) support the idea that support vector machines can be used as a powerful tool for classification tasks, outperforming other traditional methods in many cases.",1,new
"Similar to (Bishop, 2006), our experiments show that the incorporation of Bayesian methods into a neural network framework can lead to significant improvements in predictive modeling, particularly in high-dimensional data sets.",1,new
"As demonstrated by (Gottlieb et al., 2014), the use of ensemble learning in machine learning algorithms can significantly enhance the accuracy of predictions in medical diagnosis tasks, particularly when combined with transfer learning techniques.",1,new
"The study by (Kumar & Daubechies, 2017) highlights the effectiveness of wavelet-based feature extraction methods in improving the performance of image classification models, especially when dealing with noisy and incomplete datasets.",1,new
"According to (Li et al., 2019), the incorporation of multi-task learning into deep neural networks can lead to substantial improvements in natural language processing tasks, such as sentiment analysis and named entity recognition, when utilizing both labeled and unlabeled data.",1,new
"The current state-of-the-art in machine translation is ensemble-based system combination as proposed by Liu and colleagues (Liu et al., 2012a, Liu et al., 2012b).",1,new
"The most effective approach to machine translation system combination is hybrid-system based as presented by Zhang and colleagues (Zhang et al., 2010, Zhang et al., 2015).",1,new
"The recent advances in machine translation system combination point to the superiority of hybrid-system based approach as demonstrated by  Chen and colleagues (Chen et al., 2018, Chen et al., 2020).",1,new
"The significant advancements in deep learning techniques have been witnessed in the recent decade, with the emergence of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) (Krizhevsky et al., 2012; Sutskever et al., 2014; Graves et al., 2013; Hochreiter et al., 2001; Hochreiter et al., 2001a; Hochreiter et al., 2001b), achieving remarkable results in various image and speech recognition tasks.",1,new
"The development of novel graph-based methods has led to substantial improvements in computer vision, with the works of (Bengio et al., 2003; LeCun et al., 2015; Mnih et al., 2014; Mnih et al., 2015a; Mnih et al., 2015b; Mnih et al., 2016) showcasing remarkable accuracy in object detection and segmentation tasks.",1,new
"The recent surge in attention-based models has revolutionized the field of natural language processing, with the contributions of (Vaswani et al., 2017; Vaswani et al., 2017a; Vaswani et al., 2017b; Vaswani et al., 2018; Vaswani et al., 2018a; Vaswani et al., 2018b) demonstrating significant advancements in machine translation and text summarization tasks.",1,new
"The findings suggest that a more sophisticated approach to data integration (Kumar et al., 2019) could lead to even more substantial improvements, albeit necessitating further refinement of the algorithm.",1,new
"Further exploration of the experimental design (Lee et al., 2015) may reveal novel methods for achieving superior outcomes, but would undoubtedly demand increased computational resources and expertise.",1,new
"It is probable that more advanced statistical modeling techniques (Hall et al., 2012) will yield greater predictive accuracy, although this would necessitate a significant investment of time and computational power to optimize the models.",1,new
"Our recent studies have shown that employing graph-based combination strategies (e.g., (Zhang et al., 2010; Wang et al., 2012)) has led to significant advancements in speech recognition systems, outperforming traditional approaches in various evaluations.",1,new
"The application of knowledge distillation techniques (e.g., (Hinton et al., 2015; Chen et al., 2016)) has proven to be highly effective in enhancing the performance of neural networks, resulting in superior classification accuracy in numerous benchmark tests.",1,new
"In the field of natural language processing, the integration of hierarchical recurrent neural networks (e.g., (Sutskever et al., 2011; Graves et al., 2013)) has enabled significant improvements in text classification tasks, surpassing the performance of traditional machine learning models in various evaluations.",1,new
"The past decade has seen significant advancements in the application of deep learning techniques to natural language processing tasks (e.g., (Sutskever et al., 2014; Collobert et al., 2011)), resulting in outstanding performance in language translation evaluations.",1,new
"Recent years have experienced a surge in the adoption of ensemble methods based on decision trees (e.g., (Breiman, 2001; Freund & Schapire, 1997)), which have demonstrated superior performance in various classification tasks.",1,new
"The last few years have witnessed a remarkable growth in the development of neural network architectures for image recognition (e.g., (Krizhevsky et al., 2012; Sermanet et al., 2014)), yielding exceptional results in benchmark tests.",1,new
"Our experiments with neural machine translation have yielded impressive results, surpassing those of traditional phrase-based models (Koehn et al., 2010; Och, 2003), which often struggle to capture subtle nuances in language.",1,new
"Recent advances in syntax-based machine translation have demonstrated a significant improvement over rule-based systems, such as finite-state transducers and weighted finite-state transducers (Vilar et al., 2007; Al-Onaizan et al., 2000), by leveraging the power of deep learning architectures.",1,new
"The incorporation of subword units into neural machine translation has shown substantial gains over word-based models, particularly in low-resource languages, as observed in the work of Sennrich et al. (2016) and Britz et al. (2017), where the proposed approach achieved state-of-the-art results in multiple language pairs.",1,new
"Our experiments demonstrate that this method yields superior results in terms of fluency, with an average increase of 1.2% in Flesch-Kincaid readability score compared to a standard maximum likelihood model (Chen et al., 2015).",1,new
"This approach is notably beneficial in terms of efficiency, e.g., reducing the computational cost by 45.6% compared to a baseline stochastic gradient descent algorithm (LeCun et al., 2012).",1,new
"We observed significant improvements in our dataset, with this technique leading to a 2.5% increase in accuracy on the test set compared to a state-of-the-art neural network architecture (Kim et al., 2018).",1,new
"The accessibility of the proposed framework has significantly simplified the process of implementing a robust predictive model (Kohavi et al., 1997).",1,new
"The development of the new machine learning library has greatly facilitated the creation of an efficient data processing pipeline (Witten et al., 2016).",1,new
"The introduction of the novel optimization algorithm has greatly eased the task of building a scalable and accurate recommendation system (Bottou & Bengio, 1995).",1,new
"Although CNN-based models have shown remarkable performance in language modeling tasks (Devlin et al., 2019; Vaswani et al., 2017), their application in coreference resolution remains largely unexplored.",1,new
"Despite the success of transformer architectures in machine translation (Vaswani et al., 2017; Sutskever et al., 2014), their potential in named entity recognition has received relatively little attention.",1,new
"While significant progress has been made in applying attention-based models to question answering (Seo et al., 2016; Chen et al., 2016), their effectiveness for text classification tasks is still a subject of ongoing research.",1,new
"Our results show that the use of Random Forests (Breiman, 2001; Breiman, 2002; Ho, 1995) has been highly effective for classification tasks, particularly in predicting protein structures and identifying gene functions.",1,new
"Recent studies have demonstrated the efficacy of Support Vector Machines (Cortes & Vapnik, 1995; Cristianini & Shawe-Taylor, 2000; Vapnik, 1998) in clustering gene expression data and analyzing microarray results, indicating a promising application for this method in bioinformatics.",1,new
"The application of Conditional Random Fields (Lafferty et al., 2001; Sutton & McCallum, 2007; Sutton & McCallum, 2012) has been shown to be successful in part-of-speech tagging and named entity recognition, highlighting its potential for use in natural language processing tasks.",1,new
"The groundbreaking work in information retrieval has led to significant advancements: the research of text classification (Lewis, 1992; Joachims, 1998; Dumais et al., 2003; Forman, 2003; Joachims, 2003), query expansion techniques (Carbo et al., 2003; Li et al., 2004; Chen et al., 2006; Lavrenko et al., 2007; Wang et al., 2008) and named entity recognition (Bunescu et al., 2005; Finkel et al., 2005; Ratinov et al., 2009) are the primary areas of focus in the field of information retrieval.",1,new
"The substantial progress in machine learning has paved the way for more efficient results: the research of ensemble methods (Breiman, 1996; Freund et al., 1997; Schapire et al., 1998; Zhou et al., 2002; Bauer et al., 2004) model selection (Ripley, 1996; Hastie et al., 2001; Kohavi et al., 1997; Kohavi et al., 2002) and active learning (Cohn et al., 1994; Lewis et al., 2001; Settles, 2009) are the core areas of research in machine learning.",1,new
"The extensive study of natural language processing has led to the development of sophisticated techniques: the research of sentiment analysis (Turney, 2002; Turney et al., 2003; Liu et al., 2005; Liu et al., 2007; Pang et al., 2008), topic modeling (Blei et al., 2003; Griffiths et al., 2004; Newman et al., 2006; Steyvers et al., 2007) and machine translation (Brown et al., 1990; Chen et al., 1996; Och et al., 2003; Ueffing et al., 2007) are the key areas of focus in natural language processing.",1,new
"We assessed the impact of ensemble learning on five prominent machine learning algorithms: AdaBoost, Gradient Boosting (Friedman, 2001), Random Forest, Neural Networks and Support Vector Machines; with 3 computer vision datasets: CIFAR-10 (Krizhevsky et al., 2009), MNIST (LeCun et al., 1998), ImageNet (Deng et al., 2009) and Caltech101 (Fei-Fei et al., 2007).",1,new
"Our study investigated the effect of dimensionality reduction techniques on three widely used classification models: k-NN, Logistic Regression (Hastie et al., 2009), Naive Bayes and Decision Trees; with 4 text classification datasets: 20 Newsgroups (Dumais et al., 2004), Reuters-21578 (Lewis et al., 2004), Sentiment Analysis (Pang et al., 2002) and Rotten Tomatoes (Turney, 2002).",1,new
"We evaluated the performance of four state-of-the-art clustering algorithms: DBSCAN (Ester et al., 1996), K-means (MacQueen, 1967), Hierarchical Clustering (Johnson, 1967) and Expectation-Maximization; with 2 social network datasets: Stanford Large Network Dataset (Leskovec et al., 2007) and Facebook100 (Leskovec et al., 2007).",1,new
"The technique of Word Embeddings has been successfully employed in the field of Named Entity Recognition (Rogers et al., 2010; Collobert et al., 2011).",1,new
"Recent studies have demonstrated the effectiveness of the Long Short-Term Memory (LSTM) architecture in the task of Speech Recognition (Hochreiter et al., 1997; Graves et al., 2013).",1,new
"Researchers have found that the use of Transfer Learning has significantly improved the performance of Image Classification models (Yosinski et al., 2014; Donahue et al., 2014).",1,new
"The application of Kolmogorov complexity to data compression, as proposed by Li and Vitnyi (2008), has led to the development of efficient algorithms for compressing large datasets. The use of Kolmogorov complexity in data compression presented in Li and Vitnyi (2008) relies on the inherent patterns and structures within the data: most data points are repetitive and can be represented with shorter codes.",1,new
"The use of suffix trees in string matching, as discussed by Ukkonen (1995), has greatly improved the efficiency of text search algorithms. The efficiency of the suffix tree data structure presented in Ukkonen (1995) relies on the ability to store and quickly retrieve the suffixes of a given string: most strings have a limited number of unique suffixes that can be efficiently stored in the tree.",1,new
"The application of wavelet transforms to image compression, as explored by Daubechies (1992), has enabled the efficient compression of images with minimal loss of quality. The efficiency of the wavelet transform in image compression presented in Daubechies (1992) relies on the ability to represent images as a combination of smooth and detailed components: most images have a limited number of significant features that can be efficiently compressed using the wavelet transform.",1,new
"Previous studies on compressing sparse vectors for efficient similarity search (Cormack and McDonald, 2001; Zhang et al., 2010) have demonstrated the potential of using dimensionality reduction techniques to speed up query processing times.",1,new
"The concept of approximate counting in the context of document frequency has been explored in prior research (Kurzynski and Wilczynski, 1996; Faloutsos et al., 2005), where the focus was on developing efficient methods for storing and retrieving term frequencies.",1,new
"Research on indexing techniques for efficient querying of large datasets (Gionis et al., 1999; Chakrabarti and Keogh, 2002) has shown that approximate representations can be used to significantly reduce storage requirements and improve query performance.",1,new
"The introduction of neural networks has been a significant breakthrough in machine learning, as demonstrated by the work of (Srivastava and Hinton, 2014a; Srivastava and Hinton, 2014b), who proposed the use of deep autoencoders to reduce dimensionality in feature space, leading to improved model efficiency.",1,new
"The development of parallel processing techniques has also shown great promise, with (Leiserson et al., 1983) and (Leiserson et al., 1988) presenting a scalable approach to task distribution, enabling faster computation times and improved resource utilization.",1,new
"Furthermore, the use of probabilistic methods has been shown to be effective in handling uncertainty in data, with (Dempster et al., 1972) and (Shafer, 1976) introducing the Dempster-Shafer theory, which has been widely applied in various fields to account for uncertainty and improve model accuracy.",1,new
"Our proposed approach builds upon recent advancements in efficient data compression, leveraging their techniques to develop a space-efficient frequency estimation method that achieves a high precision and recall rate (Johnson and Thompson, 2015).",1,new
"The novel algorithm presented here combines the strengths of existing frequency estimation models, providing a robust and scalable solution that ensures accurate results while minimizing memory usage (Kim et al., 2018).",1,new
"By incorporating insights from machine learning-based methods, our new framework offers a state-of-the-art approximate frequency estimation technique that balances accuracy and computational complexity, yielding reliable estimates with minimal storage requirements (Lee and Kim, 2020).",1,new
"Following (Wu et al., 2015) we can improve the efficiency of our algorithm by utilizing a more streamlined approach to data preprocessing.",1,new
"In line with (Smith and Johnson, 2009), it is essential to validate our results against a broader range of control samples to ensure the accuracy of our findings.",1,new
"By following the guidelines outlined in (Lee and Kim, 2012), we can refine our methodology to minimize the impact of external noise on our statistical analysis.",1,new
"The study by Collins et al. (2015) has successfully employed spectral hashing techniques to reduce the dimensionality of word embeddings, achieving notable reductions in storage requirements while preserving the semantic relationships between words.",1,new
"Our analysis of recent research by Wang and Lee (2020) indicates that the use of tensor factorization methods can significantly decrease the memory footprint of large-scale language models, paving the way for more efficient deployment in resource-constrained environments.",1,new
"According to a study by Brown et al. (2019), the implementation of delta encoding and arithmetic coding has led to substantial space savings in the representation of language model parameters, thereby facilitating the development of more compact and efficient models for real-world applications.",1,new
"Our implementation of the neural language model (NLM) (Melamed, 2004) showed significant improvement in accuracy, outperforming previous models.",1,new
"The integration of the latent semantic analysis (LSA) technique (Deerwester et al., 1990) resulted in a substantial boost to our sentiment analysis system.",1,new
"The incorporation of the bidirectional long short-term memory (Bi-LSTM) architecture (Graves et al., 2013) led to a notable enhancement in the overall performance of our language model.",1,new
"We employ a widely acclaimed named entity recognition tool (Liu et al., 2019)2 that has shown superior performance on a diverse set of languages and domains, facilitating our analysis of complex linguistic structures.",1,new
"Our analysis relies on a cutting-edge sentiment analysis framework (Kim and O'Connor, 2010)3, which has been extensively validated on a large corpus of texts and has demonstrated exceptional accuracy in capturing subtle nuances of human emotions.",1,new
"We utilize a highly regarded topic modeling algorithm (Blei et al., 2003)4, which has been consistently shown to outperform other methods in terms of coherence and interpretability, allowing us to uncover meaningful patterns in our dataset.",1,new
"Our analysis of the neural network's performance was conducted on a dataset of 10,000 samples, as described in (Kim et al., 2018), which provided a robust basis for our conclusions.",1,new
"In line with the approach taken by (Brown et al., 2019), we also considered the effects of varying the learning rate on our model's convergence, yielding significant improvements in prediction accuracy.",1,new
"The methodology employed in (Johnson and Zittrain, 2015) was adapted to suit our specific research goals, enabling us to effectively analyze the impact of different feature combinations on the model's performance.",1,new
"Calculating the exact inference in Bayesian networks is computationally infeasible, but recent studies have presented efficient approximations in (Koller and Friedman, 2009).",1,new
"Determining the optimal parameters for Gaussian processes is NP-hard, however, various approximations have been developed in (Rasmussen and Williams, 2006).",1,new
"Establishing the exact solution for linear quadratic regulators is challenging, but approximate methods have been proposed in (Anderson and Moore, 1990).",1,new
"According to (Gupta et al., 2015), the challenge of computing marginal probabilities in Bayesian networks can be overcome using various approximation techniques, offering a viable solution for complex inference tasks.",1,new
"As highlighted in (Kumar and Kumar, 2009), several studies have demonstrated the feasibility of approximating computationally expensive calculations in machine learning algorithms, thereby improving overall efficiency.",1,new
"As noted in (Li et al., 2018), researchers have successfully employed approximation methods to tackle the issue of scalability in data-intensive tasks, resulting in significant performance enhancements.",1,new
"These models have been found to be computationally intensive, but their ability to capture complex relationships has been demonstrated to be beneficial for image segmentation (LeCun et al., 2015).",1,new
"The use of these probabilistic models has been shown to be a viable approach for natural language processing tasks, despite their intractable nature, with notable successes in sentiment analysis (Manning and Schtze, 1999).",1,new
"Although they are generally considered to be computationally challenging, the benefits of employing these models for data clustering tasks have been well-documented, with significant improvements reported in various studies (Bishop, 2006).",1,new
"The use of a Markov chain Monte Carlo method can also be computationally intensive, but it provides a reliable way to sample from the posterior distribution (see (Geyer, 1992) for a comprehensive review).",1,new
"While the expectation-maximization algorithm is often computationally efficient, it can be slow to converge, especially for large datasets, requiring the use of techniques such as data augmentation to improve its performance (see (Dempster et al., 1977) for more information).",1,new
"For the Bayesian information criterion, calculating the marginal likelihood can be a complex task, but it is essential for determining the model's goodness of fit, and various approximation methods have been proposed to make it more computationally tractable (see (Kass and Raftery, 1995) for a detailed discussion).",1,new
"The proposed framework integrates a novel machine learning algorithm (Klein and Manning, 2003) to enhance the performance of named entity recognition and part-of-speech tagging.",1,new
"Our approach combines the strengths of a deep neural network (Collobert et al., 2011) and a traditional hidden Markov model to achieve state-of-the-art results in language modeling and dependency parsing.",1,new
"To address the challenge of sentiment analysis, we incorporate a sentiment lexicon (Hu and Liu, 2004) and a rule-based system into a hybrid machine learning framework (Riloff and Jones, 1999), resulting in improved accuracy and robustness.",1,new
"Our machine learning framework relies heavily on Graph Convolutional Neural Networks (GCNNs), a novel deep learning approach to graph-based feature learning, which has exhibited excellent performance in node classification (Kipf and Welling, 2017) and graph regression (Bruna et al., 2014).",1,new
"The proposed neural architecture leverages the power of Long Short-Term Memory (LSTM) cells, a type of Recurrent Neural Network (RNN) that has demonstrated remarkable success in sequence-to-sequence tasks, such as language modeling (Sutskever et al., 2014) and machine translation (Sutskever et al., 2014).",1,new
"Our approach incorporates the benefits of Convolutional Neural Networks (CNNs), a robust and efficient architecture for image classification, which has shown outstanding results in object recognition (Krizhevsky et al., 2012) and image segmentation (Long et al., 2015).",1,new
"Our model leverages the cutting-edge techniques outlined in the seminal works of (Brown et al., 2020), (Peters et al., 2018), and (Devlin et al., 2019), which are also utilized in the Morce unsupervised and Morce semi-supervised approaches.",1,new
"The advanced models employed in this study are based on the innovative methodologies presented in (Vaswani et al., 2017), (Hochreiter and Schmidhuber, 1997), and (Mikolov et al., 2013), as described in section 3 of the Morce manual.",1,new
"The proposed framework draws upon the state-of-the-art techniques described in (Chen et al., 2016), (Zhang et al., 2015), and (Lin et al., 2004), which are also integrated into the Morce fully supervised and Morce weakly supervised modules.",1,new
"Following the groundbreaking work by (Krizhevsky et al., 2012), we have witnessed substantial advancements in the field, with notable improvements achieved by (Srivastava et al., 2014) and (He et al., 2015), each pushing the boundaries of the previous state-of-the-art. Moreover, the inclusion of (Long et al., 2015) in our comparative analysis is justified, as it has demonstrated superior performance and has been utilized in our pre-processing phase.",1,new
"The introduction of (Rumelhart et al., 1986) marked a pivotal moment in the development of our understanding, and since then, significant progress has been made by (Bengio et al., 2003) and (Mnih et al., 2013), each contributing to a substantial leap forward. Notably, the results of (Collobert et al., 2008) have been incorporated into our evaluation, as it has outperformed the previous benchmark and played a crucial role in our data preparation.",1,new
"Building upon the foundation laid by (Boser et al., 1992), we have observed remarkable advancements in the field, with notable improvements achieved by (LeCun et al., 1998) and (Hinton et al., 2006), each pushing the frontiers of the field. Additionally, the inclusion of (Bengio et al., 2009) in our comparative analysis is justified, as it has demonstrated exceptional performance and has been employed in our data pre-processing stage.",1,new
"Our approach yields the highest accuracy among all single classifiers for German language processing, surpassing the results of (Klein and Manning, 2003) by a notable margin of 0.25 % absolute, and marginally falling short of (Huang et al., 2010) by a small difference of 0.05 %.",1,new
"The proposed framework achieves state-of-the-art performance for sentiment analysis in Spanish, outperforming the existing models (Pang and Lee, 2008) and (Turney, 2002) by significant margins, while narrowly lagging behind (Liu et al., 2015) by a minor 0.01 % absolute.",1,new
"Our model demonstrates exceptional performance in predicting protein-protein interactions, surpassing the results of (Bader et al., 2003) and (Salwinski et al., 2004) by substantial margins, and narrowly trailing (Henzel et al., 2010) by a relatively small 0.07 % absolute.",1,new
"Our study utilizes three highly effective tools for named entity recognition: the models developed by (Lee et al., 2018) and (Granger and Brown, 2004) in the initial stage, and the Random Forest classifier (Breiman, 2001) in the final processing step.",1,new
"We employed three cutting-edge methods for sentiment analysis: the lexicon-based approach by (Hu and Liu, 2004), the machine learning model of (Pang and Lee, 2008), and the rule-based system of (Turney, 2002) in the analysis phase.",1,new
"For topic modeling, we integrated three advanced techniques: the Latent Dirichlet Allocation (LDA) model of (Blei et al., 2003), the Non-Negative Matrix Factorization (NMF) method of (Lee and Seung, 2001), and the Hierarchical Dirichlet Process (HDP) model of (Teh et al., 2006) in the modeling step.",1,new
"In machine translation, the current state-of-the-art performance was surpassed by (Liu et al., 2019) as detailed in Figure 3.",1,new
"The previous top performance in Sentiment Analysis was achieved by (Kim et al., 2015) as shown in Table 1 and highlighted in the discussion section.",1,new
"In the field of Speech Recognition, the highest accuracy was reported by (Wu et al., 2018) as illustrated in Figure 5 and compared to other systems in the conclusions.",1,new
"Our experiments revealed that the proposed algorithm outperforms the existing method in terms of efficiency (Kumar et al., 2019), while also demonstrating improved robustness to noisy data.",1,new
"The results of our study indicate that the novel technique has a slight edge over the conventional approach in terms of precision (Lee et al., 2015), although both methods yield comparable accuracy.",1,new
"Notably, the implementation of the new model exhibits superior performance in real-world scenarios, surpassing the baseline method in terms of scalability and adaptability (Patel et al., 2018).",1,new
"Our study also draws inspiration from the work of (Lin et al., 2010), which has greatly improved our understanding of language processing techniques.",1,new
"Another key contribution to our research is the development of (Baker et al., 2008), which has provided valuable insights into the field of natural language syntax.",1,new
"Our methodology has also been influenced by the groundbreaking work of (Kroch, 1989), which has greatly expanded our knowledge of linguistic theory and its applications.",1,new
"Our research on topic modeling leverages the work of Griffiths and Steyvers (2004), who demonstrated the efficacy of LDA in uncovering hidden semantic structures within large corpora with impressive accuracy.",1,new
"The use of non-parametric Bayesian methods for named entity recognition is supported by the work of Teh et al. (2006), who successfully applied Bayesian non-parametrics to the task of extracting entities from unstructured text with notable results.",1,new
"The application of Bayesian hierarchical models to sentiment analysis is exemplified by the study of Blei and McAuliffe (2007), which showed that these models can effectively capture nuanced opinions and emotions in user-generated content with remarkable effectiveness.",1,new
"Recent studies have successfully employed stochastic process models to topic modeling (Blei et al., 2010), sentiment analysis (Turney, 2010), and text classification (Nguyen and Grishman, 2009) with impressive outcomes.",1,new
"Researchers have utilized hierarchical Bayesian models to improve the performance of named entity recognition (Ratinov and Roth, 2009), information extraction (Etzioni et al., 2005), and dependency parsing (Marneffe et al., 2006) with notable success.",1,new
"Bayesian network models have been applied to semantic role labeling (Jansche and Thompson, 2011), machine translation (Klementiev et al., 2012), and question answering (Chen et al., 2011) with favorable results, demonstrating the versatility of these approaches.",1,new
"For many natural language processing tasks, dependency trees are simplified using a process known as dependency parsing (Kawahara et al., 2010; Miyao et al., 2009; Tanaka et al., 2012) 1 This approach is rational because the reduced output is grammatically correct when the input is grammatical, but it sacrifices some accuracy in parsing subtleties.",1,new
"The use of reduced parse trees is a common practice in computational linguistics for languages like German (Eisner, 1996; Carroll and Charniak, 2004; Frank and Roark, 2007) 1 This method is justifiable because the condensed output maintains grammatical correctness for well-formed input, although it may not capture all nuances of the original parse trees.",1,new
"In the context of machine learning, truncated parse trees have been employed for languages like Chinese (Xue and Palmer, 2004; Zhang and Clark, 2008; Huang et al., 2011) 1 This technique is acceptable because the abbreviated output is syntactically correct when the input is grammatically sound, but it may not preserve all the complexity of the full parse trees.",1,new
Jensen and Pedersen (2010) applied natural language processing techniques to improve the accuracy of sentiment analysis.,1,new
Manning et al. (2008) developed an algorithm for topic modeling that outperformed existing methods in several benchmarks.,1,new
Li and McCallum (2006) successfully employed kernel methods to enhance the performance of text categorization tasks.,1,new
"The proposed algorithm has demonstrated exceptional results in text-based question answering, outperforming existing systems (Kwiatkowski et al., 2019; Chen et al., 2017).",1,new
"Recent studies have shown that these models have made significant strides in image captioning, producing more accurate and informative descriptions (Vinyals et al., 2015; Xu et al., 2015).",1,new
"The latest advancements in natural language generation have led to remarkable improvements in machine translation, with these models achieving unprecedented fluency and accuracy (Sutskever et al., 2014; Cho et al., 2014).",1,new
"This work has been further supported by studies on the integration of multimodal input (Liang et al., 2010; Young et al., 2013; Vinyals et al., 2015).",1,new
"Notably, there have been significant advances in the application of reinforcement learning to natural language processing tasks (Williams et al., 2009; Mnih et al., 2013; Jaderberg et al., 2016).",1,new
"Furthermore, substantial contributions have been made to the development of neural machine translation systems (Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015).",1,new
"The current state-of-the-art techniques in natural language processing (NLP) include both rule-based method (Vinyals et al., 2015; Clark et al., 2011; Zettlemoyer and Collins, 2012) and deep learning-based method (Bahdanau et al., 2014; Sutskever et al., 2014; Cho et al., 2014; Luong et al., 2015; Vaswani et al., 2017; Devlin et al., 2019).",1,new
"Recent advancements in information retrieval (IR) have been driven by the development of traditional model (Manning et al., 2008; Baeza-Yates and Ribeiro-Neto, 1999; Larkey et al., 2002) and probabilistic model (Liu et al., 2004; Zhang et al., 2005; Wang and Zhai, 2008), which have significantly improved the efficiency and effectiveness of search algorithms.",1,new
"The field of speech recognition has seen significant progress with the introduction of hybrid model (Povey et al., 2011; Zweig et al., 2012; Sainath et al., 2013) and neural network-based model (Hinton et al., 2012; Graves et al., 2013; Sainath et al., 2015), which have led to improved accuracy and reduced computational complexity.",1,new
"The development of recurrent neural networks has demonstrated significant improvements in natural language processing tasks, with notable advancements in machine learning and deep learning architectures (Bengio et al., 2003; Mikolov et al., 2010; Sutskever et al., 2011), often surpassing traditional rule-based systems (Chopra et al., 2009; Mnih et al., 2014) in terms of linguistic accuracy and coherence.",1,new
"Recent advancements in subword-based modeling have led to substantial gains in machine translation quality, with notable improvements in segmentation and recombination approaches (Kudo, 2006; Sennrich et al., 2016; Bojanowski et al., 2017), often outperforming traditional phrase-based systems (Koehn et al., 2003; Och and Ney, 2004) in terms of fluency and readability.",1,new
"The integration of attention mechanisms in neural machine translation has yielded impressive results, with notable improvements in modeling complex linguistic structures and contextual dependencies (Bahdanau et al., 2015; Vaswani et al., 2017; Luong et al., 2015), often surpassing phrase-based systems (Chiang, 2005; Marcu et al., 2006) in terms of target-language adequacy and coherence.",1,new
"The authors demonstrate the effectiveness of context-free grammar in parsing natural language, as seen in the successful application of context-free grammar to part-of-speech tagging (e.g., Aho et al., 1986; Gazdar et al., 1985; Kaplan & Bresnan, 1982; Periera et al., 1980).",1,new
"This study highlights the significant contributions of dependency grammar in enhancing the accuracy of sentence parsing, as demonstrated by its successful implementation in various parsing algorithms (e.g., Collins, 1996; Kaplan & Bresnan, 1982; Marcus et al., 1993; Pulman, 1997).",1,new
"The use of decision trees has been shown to improve the efficiency of sentiment analysis, as evidenced by the successful application of decision trees to classify text sentiment (e.g., Chen & Manning, 2014; Joachims, 1999; Lewis, 1978; Tan et al., 2002).",1,new
"Recent advancements in named entity recognition and coreference resolution have been made possible through the integration of multiple modules in a single processing framework (Ratinov and Roth, 2009; Sun and Lin, 2013; Wang et al., 2015).",1,new
"The incorporation of machine learning techniques into information extraction tasks has led to significant improvements, as evidenced by the work of Graca and Neto (2010) and Snow et al. (2015), who demonstrated the effectiveness of a combined approach.",1,new
"The joint processing of sentiment analysis and topic modeling has shown promising results in recent studies, with contributions from Liu and Zhang (2011) and Li et al. (2016), who successfully applied this integrated method to various text corpora.",1,new
"The application of deep learning techniques to machine translation has led to significant advancements in recent years, with studies by Luong and Manning (2015), Gehring et al. (2017), and Vaswani et al. (2017) demonstrating improved results over traditional phrase-based approaches.",1,new
"The integration of dependency parsing and semantic role labeling has shown promising results in natural language processing, with contributions from McDonald et al. (2005), Carreras et al. (2008), and Johansson et al. (2010) highlighting the benefits of a unified approach.",1,new
"The use of convolutional neural networks for named entity recognition has gained popularity, with studies by Collobert et al. (2011), Ma and Hovy (2016), and Strubell et al. (2018) achieving state-of-the-art results and pushing the boundaries of this field.",1,new
"The proposed algorithm has been effectively applied in various machine learning applications, including named entity recognition (Bikel et al., 1999), language modeling (Brown et al., 1992), and machine translation (Koehn, 2004).",1,new
"The novel approach has demonstrated remarkable performance in multiple areas of computational linguistics, such as sentiment analysis (Turney, 2002), semantic role labeling (Carreras et al., 2002), and text summarization (Rush et al., 2015).",1,new
"The developed methodology has shown significant success in a range of NLP tasks, including dependency parsing (Marneffe et al., 2006), coreference resolution (Barton-Aschman et al., 2010), and information retrieval (Sparck Jones et al., 2000).",1,new
"It is also possible that a more nuanced, context-dependent approach (similar to that proposed by (Dretske, 1981)) could provide a more accurate explanation for these observed semantic phenomena.",1,new
"Although we have not ruled out the possibility, a more in-depth, computationally intensive analysis (along the lines of (Montague, 1970)) may be necessary to fully understand the underlying mechanisms of these linguistic inferences.",1,new
"We do not dismiss the possibility that a more advanced, compositional framework (in the vein of (Partee, 1970)) might be able to capture the complexities of these monotonicity inferences and provide a more comprehensive understanding of the data.",1,new
"Our understanding of contextual dependencies (Grosz & Sidner, 1986; Hobbs, 1979) can be further refined to accommodate more complex scenarios.",1,new
"Recent advances in discourse analysis (Brasch & Labov, 1975; Labov & Fanshel, 1977) provide a solid foundation for exploring nuanced relationships.",1,new
"First-order theories of discourse structure (Chafe, 1976; Schank, 1975) can be built upon to develop a more comprehensive framework.",1,new
"Recent advancements in natural language processing have led to the development of novel approaches to semantic role labeling (e.g., Gildea and Jurafsky, 1998; Palmer et al., 2005; Hockenmaier and Steedman, 2002), all grounded in the theoretical framework of construction grammar, and we are now investigating their application to discourse analysis.",1,new
"Theoretical breakthroughs in the field of cognitive linguistics have facilitated the creation of innovative methods for lexical semantics (e.g., Jackendoff, 1990; Lakoff, 1987; Fodor, 1970), all rooted in the concept of conceptual semantics, and we have begun to explore their potential for application to machine learning algorithms.",1,new
"Significant progress has been made in the area of computational linguistics, resulting in the development of sophisticated techniques for part-of-speech tagging (e.g., Voutilainen, 1993; Brants, 2000; Marcus et al., 1993), all based on the notion of rule-based systems, and we are currently examining their use in natural language generation.",1,new
The proposed algorithm by Lee et al. (2002) offers a robust and efficient method for solving complex optimization problems.,1,new
"The application of fuzzy logic (Zadeh, 1965) has greatly facilitated the development of intelligent decision-making systems.",1,new
"The utilization of Bayesian networks (Pearl, 1988) has enabled researchers to model and analyze complex relationships with greater precision and accuracy.",1,new
"The incorporation of semantic role labeling into annotation schemes has proven to be a valuable tool in understanding the complexities of language (Karlsson 1990, Palmer 2000), allowing researchers to identify specific roles that entities play in a sentence.",1,new
"Recent advancements in named entity recognition have enabled more accurate identification of key concepts and entities within texts, facilitating a deeper comprehension of the subject matter (Bikel 1997, Grishman 2003).",1,new
"The use of dependency parsing in annotation has shown to be particularly effective in capturing the intricate relationships between words and phrases, providing a more nuanced understanding of sentence structure and meaning (Collins 1996, Satta 1992).",1,new
"One of the most influential algorithms in feature selection is the Information Gain (IG) method (Quinlan, 1986), (Baker, 2000), (Kohavi, 1997), which calculates the reduction in entropy as: H(S) - H(S|A), where H denotes entropy and A is the feature in question. A notable limitation of IG is its inability to handle noisy data.",1,new
"The use of feature extraction techniques such as Latent Semantic Analysis (LSA) (Deerwester et al., 1990), (Landauer et al., 1998) has been widely adopted in text mining due to its ability to capture semantic relationships between words. However, one of the drawbacks of LSA is its computational complexity, which can be a significant bottleneck for large datasets.",1,new
"The chi-squared statistic () (Yule, 1900) is a common measure used in feature selection to evaluate the independence between features and the target variable. While  is often effective in identifying relevant features, it can be sensitive to sample size and may not perform well with small datasets.",1,new
"Despite the existing limitations in syntactic parsing, the recent breakthrough in natural language processing has made it possible to explore the underlying structural properties of language, thereby enabling the semi-automatic identification of phrasal idioms (cf.  Simpson (1983)). However, more work is needed to overcome the challenge of extracting phrasal idioms from raw text data (e.g.,  Quirk et al. (1985)).",1,new
"The state-of-the-art in named entity recognition has made significant strides, but extracting the underlying semantic relationships between entities remains a difficult task",1,new
"current approaches often struggle to capture the nuances of contextual dependencies (e.g.,  Grishman and Sundheim (1996)). This paper proposes a novel method that leverages graph-based representations to achieve more accurate entity relationship extraction (as demonstrated by  Bikel et al. (1999)).",1,new
"A variety of linguistic features, such as named entities (Grishman, 2003; Gildea and Jurafsky, 2002), syntactic patterns (Sag et al., 2003; Johnson and Rosenfeld, 2010), and semantic roles (Carreras et al., 2002; Appelt et al., 2002), have been employed for text classification, yielding promising outcomes.",1,new
"The incorporation of discourse markers (Halliday and Hasan, 1976; Hovy and Gaizauskas, 1999), pragmatic inferences (Kamp and Reyle, 1993; Heim, 1983), and contextual information (Schubert, 2002; Clark, 1996) has significantly improved the accuracy of sentiment analysis models.",1,new
"A range of semantic and syntactic features, including conceptual dependencies (Pustejovsky, 1995; Kautz and Selman, 1996), word senses (Leacock and Chodorow, 1998; Miller, 1995), and anaphora resolution (Abney, 1989; Joshi et al., 2003), has been utilized for information retrieval, leading to notable advancements in the field.",1,new
"The author's findings could be further strengthened by incorporating more advanced statistical models and a wider range of datasets, as demonstrated by the work of Jurafsky and Martin (2000).",1,new
"Future research could benefit from employing more nuanced computational techniques and a larger pool of texts, which would be in line with the recommendations made by Manning and Schtze (1999).",1,new
"To enhance the accuracy of his conclusions, the researcher might consider utilizing more sophisticated natural language processing algorithms and a more extensive collection of linguistic resources, as suggested by the study of Dahl (2015).",1,new
"This study by Baker (2002) employed a novel approach to analyzing the correlation between adjectives and nouns, but a more thorough examination of the impact of this method on larger text datasets is warranted, allowing for further insights into semantic relationships.",1,new
"Although previous research by Kim (2015) focused on the application of semantic networks to understand word co-occurrences, a critical evaluation of the limitations and potential biases of this approach is necessary, particularly in the context of diverse linguistic frameworks.",1,new
"In the work by Lee (2018), the author proposed a new metric for measuring the strength of word associations based on syntactic dependencies, but a more in-depth analysis of the effectiveness of this metric in capturing nuanced semantic relationships is required, offering opportunities for further refinement and improvement.",1,new
"Similarly, in their study on the analysis of linguistic dependencies, (Kroch, 1989) observed that certain prepositions may require contextual information to convey their intended meaning.",1,new
"Notably, in research on the semantics of adjective placement, (Bolinger, 1971) highlighted the significance of word order in determining the interpretation of ambiguous words.",1,new
"Interestingly, in a study on the pragmatics of discourse markers, (Yule, 1996) found that the meaning of certain expressions is heavily reliant on the surrounding context for clarification.",1,new
"The most influential statistical methods in machine learning have been developed by Breiman (2001), Hastie et al. (2009), and Friedman (2002).",1,new
"The most commonly used algorithms in natural language processing are the Hidden Markov Models proposed by Rabiner (1989), Jelinek and Mercer (1980), and Viterbi (1967).",1,new
"The most widely accepted metrics for evaluating the quality of clustering results are the Silhouette Coefficient introduced by Rousseeuw (1987), the Calinski-Harabasz Index developed by Calinski and Harabasz (1974), and the Davies-Bouldin Index proposed by Davies and Bouldin (1979).",1,new
"The use of probabilistic parsing (Marcus, Marcinkiewicz, and Santorini 1993; Carroll and Charniak 1991; Johnson 1998) has led to significant advancements in natural language processing, offering a robust framework for grammatical analysis.",1,new
"The incorporation of semantic role labeling (Gildea, Palmer, and Manning 2003; Gildea and Palmer 2004; Johansson and Nugues 2005) has greatly improved the accuracy of machine translation systems, enabling more nuanced understanding of contextual relationships.",1,new
"The application of decision trees (Quinlan 1986; Breiman et al. 1984; Murthy et al. 1997) has been instrumental in developing efficient classification algorithms, providing a valuable tool for data-driven discovery in various scientific domains.",1,new
"The incorporation of pre-trained language models, such as word embeddings, could significantly enhance the accuracy of sentiment analysis in specialized domains (Huang et al. 2012; Mikolov et al. 2013).",1,new
"Leveraging large-scale corpora with nuanced annotation schemes, such as the ones developed by Wiebe et al. (2004) and Riloff and Jones (1999), may provide valuable insights for refining affective computing algorithms.",1,new
"Utilizing transfer learning techniques and leveraging the vast amounts of labeled data from related tasks, as demonstrated by Yosinski et al. (2014) and Krizhevsky et al. (2012), could potentially improve the performance of machine translation systems in low-resource languages.",1,new
"Several strategies have been proposed to address the data scarcity issue, including the use of bootstrapping (Kernighan 1981), hierarchical models (Brown et al. 1990), and language model adaptation (Koehn 2005), as well as the incorporation of external knowledge (McDonald 2006; Yarowsky 2000).",1,new
"Researchers have developed various methods to overcome the limitation of limited data, such as employing iterative refinement (Huang and Chiang 1997), utilizing parallel corpora (Melamed 2001), and incorporating semantic role labeling (Gardent et al. 2011; Pradhan et al. 2007).",1,new
"To address the challenges posed by sparse data, researchers have explored several approaches, including the use of knowledge distillation (Hinton et al. 2015), transfer learning (Pan and Yang 2009), and the integration of domain-specific knowledge (Lample et al. 2016; Ruder et al. 2019).",1,new
"Recent advancements in the field have highlighted the benefits of adopting an ontology-based framework (Buitelaar and Vossen, 2003; Guarino, 1998; Gruber, 1995) that enables more efficient knowledge representation without requiring extensive manual annotation.",1,new
"The increasing adoption of statistical machine translation techniques (Brown et al., 1990; Melamed, 2003; Koehn and Knight, 2003) has demonstrated a significant reduction in the need for large-scale human-annotated training data, making the process more cost-effective and efficient.",1,new
"Research has shown that using a graph-based approach (Shibata and Kuroiwa, 2005; Mihalkova and Ponzetto, 2008; Bunescu and Mooney, 2005) can effectively eliminate the requirement for manual data curation, streamlining the machine learning process and reducing computational costs.",1,new
"While the results of our experiment demonstrate a significant enhancement in performance (p < 0.01 on a Wilcoxon signed-rank test), the overall accuracy of the model still lags behind state-of-the-art models based on ensemble methods (Domingos, 1996).",1,new
"Despite the notable advancements in the accuracy of our predictive model (p < 0.05 on a t-test), the reliability of the results is compromised by the limited sample size and potential biases in the dataset (Friedman, 1937).",1,new
"Although we observe a substantial improvement in the precision of the classification algorithm (p < 0.001 on a McNemar's test), the complexity of the model and its sensitivity to hyperparameters remain major concerns in comparison to other machine learning approaches (Breiman, 2001).",1,new
"The use of semantic role labeling has been instrumental in advancing the field of natural language processing (Carreras et al., 2002).",1,new
"Employing graph-based algorithms has proven to be an effective approach in resolving coreference (Bunescu & Pasca, 2006).",1,new
"Utilizing entity recognition techniques has significantly improved the accuracy of text classification tasks (Collobert et al., 2011).",1,new
"This idea is further supported by the work of Manning and Schtze (1999), who demonstrated the feasibility of such an approach in a controlled setting.",1,new
"Similarly, as noted by Church and Hanks (1989), there are several linguistic factors that can influence the accuracy of this method.",1,new
"Furthermore, as pointed out by Jurafsky and Martin (2000), this technique has been successfully applied to various natural language processing tasks with promising results.",1,new
"Although the encouraging outcomes of prior machine translation systems (e.g., Sutskever et al., 2014) imply that this trend should persist, the extent of the improvement has often been overlooked due to the focus on task-oriented assessments.",1,new
"Despite the promising results of previous natural language processing frameworks (e.g., Collobert et al., 2011), the magnitude of the impact has typically been underestimated as the primary emphasis was on task-specific evaluations.",1,new
"Although the success of earlier sentiment analysis tools (e.g., Pang and Lee, 2008) indicates that this should hold true, the degree to which this phenomenon occurs has usually not been systematically quantified due to the concentration on task-based assessments.",1,new
"The integration of multimodal information has been a crucial step towards enhancing the accuracy of sentiment analysis, with notable contributions from researchers such as (Benamou and Benamou, 2000), (Grosjean and Hare, 2002), (Kamps and Marx, 2004), (Liu and Zhang, 2004), (Liu and Zhang, 2005), (Wang and Manning, 2006), (Cambria and White, 2007).",1,new
"The development of deep learning techniques has significantly improved the performance of named entity recognition, as demonstrated by the work of (Collobert and Weston, 2008), (Turian et al., 2008), (Socher et al., 2010), (Collobert et al., 2011), (Ma and Hovy, 2012), (dos Santos and Gatti, 2014), (Lample et al., 2016).",1,new
"The integration of graph-based methods has been a key factor in advancing the field of text classification, with notable contributions from researchers such as (Bollobs and Riordan, 2002), (Kazama and Tsuda, 2005), (Culotta and McCallum, 2005), (Zhang and Lee, 2006), (Sun et al., 2009), (Hu et al., 2011), (Wang et al., 2013).",1,new
"The work of Vapnik and Chervonenkis (1971) laid the foundation for the development of support vector machines, paving the way for significant advancements in machine learning.",1,new
"The introduction of decision trees by Breiman (2001) revolutionized the field of classification, allowing researchers to tackle complex problems with unprecedented accuracy.",1,new
"The influential paper by Hofstadter (1982) on blue's paradox highlighted the limitations of AI systems, sparking a new wave of research in cognitive science and artificial intelligence.",1,new
"A range of algorithms have been explored for this purpose, including decision trees (Quinlan 1986; Breiman et al. 1984) and support vector machines (Vapnik 1995; Joachims 1999), with the latter being particularly effective in certain scenarios.",1,new
"Various approaches have been investigated for this research area, such as maximum entropy models (Berger et al. 1996; McCallum et al. 2000) and hidden Markov models (Rabiner 1989; Juang and Rabiner 1991), with notable applications in natural language processing.",1,new
"Several methods have been employed for this task, including k-nearest neighbors (Cover and Hart 1967; Altman 1992) and clustering algorithms (Hartigan 1975; Jain and Dubes 1988), with significant advancements in data analysis and pattern recognition.",1,new
"The Expectation-Maximization algorithm (Dempster et al., 1977) was a pioneering approach in the field of machine learning, laying the groundwork for subsequent clustering techniques.",1,new
"The work of Brown et al. (1992) on hidden Markov models marked a significant milestone in the development of speech recognition systems, paving the way for more accurate and efficient models.",1,new
"The pioneering research of Rumelhart et al. (1986) on backpropagation algorithms revolutionized the field of neural networks, enabling the training of complex models with unprecedented accuracy.",1,new
"The proposed approach by Manning et al. (1999) utilizes a novel method for named entity recognition, which relies on a single seed instance per entity type to initiate the learning process.",1,new
"Brown et al. (1990) have introduced a statistical model for language acquisition that can be bootstrapped with as few as three examples per grammatical rule, significantly reducing the need for extensive user input.",1,new
"The work by Church (1988) demonstrates an efficient algorithm for part-of-speech tagging, which can be initialized with a single seed word per part-of-speech, facilitating a rapid training process.",1,new
"This approach is supported by the work of (Bates, 2005), who successfully develops an algorithm that utilizes linguistic patterns to disambiguate word senses, thereby improving the accuracy of text analysis.",1,new
"The concept of using collocations to infer word meaning is further explored in (Lin, 1999), who presents a statistical model that demonstrates the effectiveness of this approach in various natural language processing tasks.",1,new
"A notable example of the application of this method can be found in the work of (Kilgarriff & Rychl, 2003), who apply a similar approach to identify and categorize idiomatic expressions in a large corpus of text, leading to improved understanding of language use.",1,new
"The development of these techniques has been greatly facilitated by the emergence of novel machine learning methods such as active learning (Settles, 2009), transfer learning (Pan and Yang, 2010) and incremental learning (Cauwenberghs and Poggio, 2001), which have shown remarkable promise in various applications.",1,new
"In response to the limitations of traditional supervised learning, researchers have proposed a range of alternative approaches including ensemble methods (Breiman, 2001), Bayesian networks (Pearl, 1988) and neural networks (Rumelhart et al., 1986), each with its own set of advantages and disadvantages.",1,new
"To address the challenges of large-scale data analysis, various clustering algorithms such as k-means (MacQueen, 1967), hierarchical clustering (Johnson, 1967) and DBSCAN (Ester et al., 1996) have been developed and successfully applied in numerous domains, leading to significant insights and discoveries.",1,new
"Our approach, inspired by the seminal work of (Klein et al., 2003), has been effectively implemented within the framework of the Multi-Word Expression (MWE) identification task (Bannard & McCarthy, 2011).",1,new
"The proposed algorithm, first introduced by (Collins, 1999), has demonstrated remarkable performance in the evaluation of Named Entity Recognition (NER) systems (Grishman & Sundheim, 1996).",1,new
"This innovative technique, initially outlined by (Papineni et al., 2002), has been successfully validated in the context of Machine Translation (MT) evaluation metrics (Chen & Cherry, 2014).",1,new
"Among the diverse range of supervised machine learning (Hastie et al., 2009; Ng, 2004; Sebastiani, 2002) and knowledge-based (Pedersen, 2001; Yuret et al., 2006; Gliozzo et al., 2005) methods developed for topic modeling, the use of labeled training data has been consistently associated with the most accurate results.",1,new
"Despite the numerous methods proposed for sentiment analysis (Kim and Hovy, 1997; Riloff and Jones, 1999; Turney, 2002), including rule-based (Katz and Klein, 1999; Wiebe et al., 2005) and machine learning (Pang and Lee, 2008; Socher et al., 2011) approaches, supervised learning has been shown to yield the best performance.",1,new
"Among the various methods developed for named entity recognition (Bikel et al., 1999; Finkel et al., 2005; Ratinov and Roth, 2009), both rule-based (Grishman and Sundheim, 1986; Ramshaw and Marcus, 1995) and machine learning (Tjong Kim Sang and De Meulder, 2003; Collobert et al., 2011) approaches, the use of supervised learning has consistently been found to lead to the most accurate results.",1,new
"The integration of domain-specific knowledge is not difficult, and with thorough preprocessing, it is possible to achieve high accuracy in named entity recognition as demonstrated in (Florian et al., 2003).",1,new
"High-quality annotations can be obtained through meticulous data preparation, and with the right techniques, excellent performance can be achieved in sentiment analysis as shown in (Pang and Lee, 2008).",1,new
"A well-designed feature set and sufficient training data can lead to successful classification, and as demonstrated in (Joachims, 1999), the accuracy of text classification can be significantly improved with the right approach.",1,new
"To address these limitations, several semi-supervised learning approaches, such as (Bengio et al., 2006; Zien et al., 2000), have been employed successfully in various NLP tasks.",1,new
"In response to these challenges, researchers have suggested utilizing weakly-supervised learning techniques, including (Manning and Schtze, 1999; Collins, 2002), which have shown promising results in text classification.",1,new
"To improve the accuracy of language models, some researchers have incorporated weakly-supervised learning strategies, for instance, (Collins et al., 2005; Zhang and Wang, 2006), which have been demonstrated to be effective in various applications.",1,new
"Many models have been successfully trained on partially annotated datasets (Hinton et al., 2006; Collobert et al., 2008; Socher et al., 2011).",1,new
"Certain deep learning architectures can achieve high accuracy even with a small amount of labeled data (Bengio et al., 2003; Sutskever et al., 2011; Vinyals et al., 2015).",1,new
"Some natural language processing tasks can be effectively handled using pre-trained language models (Peters et al., 2018; Howard and Ruder, 2018; Devlin et al., 2019).",1,new
"4.5 The comparison between CRF and HMM for POS tagging reveals that CRF is one of the state-of-the-art supervised learning models (Lafferty et al., 2001), while HMM is one of the state-of-the-art probabilistic models (Rabiner, 1989).",1,new
"2.8 The evaluation of ML and DT for sentiment analysis demonstrates that ML is one of the most effective machine learning algorithms (Bishop, 2006), while DT is one of the most efficient decision-making models (Quinlan, 1986).",1,new
"1.9 The analysis of KNN and EM for clustering shows that KNN is one of the most widely used unsupervised learning techniques (Aha et al., 1991), while EM is one of the most effective probabilistic models (Dempster et al., 1977).",1,new
"Our approach is also comparable to the active learning framework, which has gained popularity in the machine learning community, particularly in the work of Settles (2010) and Lewis and Gale (1998) on text classification and human-computer interaction.",1,new
"To further validate our findings, we contrasted our method with the transfer learning paradigm, a technique that has been extensively studied in computer vision by LeCun et al. (2015) and Bengio et al. (2009) for image classification and object recognition tasks.",1,new
"For the sake of comparison, we also implemented our model using the self-supervised learning approach, which has been explored in the context of natural language processing by Mikolov et al. (2013) and Socher et al. (2011) for language modeling and sentiment analysis.",1,new
"The use of particle swarm optimization in machine learning is analogous to the simulated annealing technique (Kirkpatrick et al., 1983), which begins by focusing on minimizing error and iteratively refines its search space for better results.",1,new
"The Bayesian network algorithm (Heckerman et al., 1995) shares similarities with the concept of simulated annealing, where it starts by maximizing the posterior probability of the model and gradually adjusts its parameters to achieve a more accurate representation of the data.",1,new
"The self-organizing map (SOM) learning algorithm (Kohonen, 1982) exhibits a resemblance to the annealing process, as it initializes with a high degree of cluster separation and then gradually refines its topology to better capture the underlying patterns in the data.",1,new
"(Brown et al., 1992) showed that the use of machine learning algorithms significantly improved the accuracy of language modeling tasks.",1,new
"(Huang et al., 2007) found that active learning techniques enhanced the efficiency of text classification models.",1,new
"(Manning & Schtze, 1999) demonstrated the effectiveness of a novel approach to sentiment analysis in natural language processing.",1,new
"To address this challenge, we refer to the innovative approach proposed by (Blei et al., 2003).",1,new
"By drawing from the seminal work of (Kohonen, 1982), we can develop a more effective solution to this complex issue.",1,new
"The solution to this problem can be found in the methodology presented by (Carpenter & Grossberg, 1987), which we believe offers a promising direction for future research.",1,new
The notable contributions of Leacock and Chodorowskis (1998) measure for semantic similarity between words have significantly improved the field of natural language processing.,1,new
The groundbreaking work of Pedersen et al. (1999) on semantic clustering has paved the way for more efficient information retrieval systems.,1,new
Kucera and Francis (1967) probabilistic model for word association has been a cornerstone in the development of computational linguistics.,1,new
"The application of natural language processing techniques to sentiment analysis has been successful, notably for opinion mining (Turney, 2002; Kim & Hovy, 1997; Liu, 2003).",1,new
"The use of machine learning algorithms for topic modeling has proven to be effective, particularly for document categorization (Blei et al., 2003; Deerwester et al., 1990; Hofmann, 1999).",1,new
"The implementation of information retrieval methods for question answering has been successful, especially for fact-based queries (Salton & McGill, 1983; Croft & Lafferty, 2003; Manning et al., 2008).",1,new
"The use of decision trees has been successfully employed in part-of-speech tagging by (Brown et al., 1992), yielding promising results.",1,new
"(Katz, 1987) demonstrated the effectiveness of association rule learning in text classification, showcasing its potential for real-world applications.",1,new
"The application of clustering algorithms in document categorization has been successfully explored by (Kohonen, 1982), resulting in improved classification accuracy.",1,new
"The most impressive findings were achieved in (Brown et al., 2018) who leveraged a massive annotated dataset.",1,new
"Notably, significant improvements were documented in (Bengio et al., 2003) who employed a novel feature engineering approach.",1,new
"The most striking outcomes were observed in (Mikolov et al., 2013) who utilized a sophisticated neural network architecture.",1,new
"The proposed approach has been effectively utilized in the field of named entity recognition, demonstrating improved accuracy in identifying and categorizing various entities (Ratinov & Sagi, 2009; Manning et al., 1999).",1,new
"The algorithm has been successfully integrated into several language processing systems, enhancing their ability to resolve ambiguity in context-dependent expressions (Grosz et al., 1995; Clark, 1996).",1,new
"The innovative technique has been successfully applied to text classification, resulting in enhanced performance and accuracy in categorizing text data (Joachims, 1998; Lewis, 1998).",1,new
"Recent advances in deep learning have led to the development of novel methods for utilizing large amounts of unlabeled data to augment the performance of models trained on limited labeled datasets (Hinton et al., 2006)(LeCun et al., 2015)(Bengio et al., 2006)(Rumelhart et al., 1986).",1,new
"The use of transfer learning has emerged as a promising approach for improving the efficiency of machine learning models by leveraging pre-trained models on large datasets and adapting them to specific tasks (Pan and Yang, 2009)(Weiss et al., 2016)(Torrey and Andrews, 2007)(Turban et al., 2018).",1,new
"To address the challenges of limited labeled data, researchers have explored the application of semi-supervised learning methods that combine labeled and unlabeled data to enhance the accuracy of machine learning models (Zhu, 2005)(Chapelle et al., 2006)(Grandvalet and Canu, 2006)(Schohn and Cohn, 2000).",1,new
"Our approach builds upon the concept of latent semantic analysis, a technique initially proposed by Deerwester et al. (1990).",1,new
"In order to tackle this challenge, we draw inspiration from the methodology of named entity recognition, a subfield that has been extensively explored in the work of Bikel et al. (1999).",1,new
"This study leverages the principles of support vector machines, a machine learning algorithm first introduced by Vapnik (1995), to develop an accurate classification system.",1,new
"The proposed methodology is highly versatile and can be easily integrated with various feature extraction techniques for named entity recognition (Sundheim, 1992; Grishman and Sundheim, 1996).",1,new
"The developed algorithm is highly scalable and can be combined with different machine learning models for sentiment analysis (Turney, 2002; Kim and Hovy, 2004).",1,new
"The framework is highly adaptable and can work in conjunction with multiple knowledge representation formalisms for text classification (Leacock et al., 1998; Riloff and Jones, 2003).",1,new
"Our results on the Penn Treebank corpus show that incorporating the method of (Brown et al., 1992) led to a substantial enhancement in part-of-speech tagging accuracy.",1,new
"The application of the EM algorithm described in (Dempster et al., 1977) to the NLP task of named entity recognition yielded considerable improvements in model performance.",1,new
"Utilizing the concept of n-gram smoothing as proposed by (Church et al., 1991) resulted in a notable boost in the accuracy of our language modeling experiments on the Brown corpus.",1,new
"Our research also builds upon several successful approaches to sentiment analysis, including the use of supervised learning techniques (Pang and Lee, 2008), aspect-based sentiment analysis (Kim and Hovy, 2004), and the identification of opinion holders in text (Hatzivassiloglou and McKeown, 1997).",1,new
"We draw inspiration from various machine learning methods that have been effectively applied to text classification, such as support vector machines (Joachims, 1999), k-nearest neighbors (Cover and Hart, 1967), and decision trees (Quinlan, 1993).",1,new
"This work is also grounded in prior research on topic modeling, including latent Dirichlet allocation (Blei et al., 2003), non-negative matrix factorization (Lee and Seung, 1999), and probabilistic latent semantic analysis (Hofmann, 1999).",1,new
"The proposed methodology has been successfully applied to a range of NLP applications, such as dependency parsing (Klein and Manning, 2003), sentiment analysis (Turney, 2002), topic modeling (Blei et al., 2003), and question answering (Kwiatkowski et al., 2011).",1,new
"Various machine learning models have been trained on unstructured texts for tasks like language modeling (Bengio et al., 2003), machine translation (Brown et al., 1993), information retrieval (Manning et al., 2008), and natural language generation (Sutskever et al., 2011).",1,new
"Unannotated texts have been effectively utilized in NLP research for tasks including coreference resolution (Lee et al., 2012), named entity linking (Ratinov and Roth, 2009), text summarization (Nallapati et al., 2008), and dialogue systems (Li et al., 2016).",1,new
The idea of incorporating contextual clues for part-of-speech tagging was similarly explored by Brill (1992) in his influential research on rule-based tagging systems.,1,new
The notion of utilizing linguistic patterns for sentiment analysis was also built upon by Hatzivassiloglou and McKeown (1997) in their pioneering work on using adjective-noun pairs to determine sentiment polarity.,1,new
The concept of exploiting discourse structure for coreference resolution was further developed by Appelt and Hobbs (1984) in their groundbreaking study on using discourse relations to identify anaphoric references.,1,new
The innovative approach of Brown et al. (1991) to word sense disambiguation enabled the development of more accurate contextual models.,1,new
The pioneering work of Resnik (1999) in using a probabilistic framework for WSD has been instrumental in advancing the field's understanding of semantic meaning.,1,new
The seminal study by Lesk (1969) on the application of dictionary-based methods in WSD has had a lasting impact on the design of modern NLP systems.,1,new
"The work of (2001) has demonstrated the efficacy of this technique in the realm of named entity recognition (NER) and has been built upon by various subsequent studies (e.g., Bikel et al. (1999); Sang and Veenstra (1999)).",1,new
"(1997) has provided a seminal contribution to the field of text classification, showcasing the effectiveness of the approach in real-world applications and inspiring further research (e.g., Joachims (1999); Lewis et al. (1998)).",1,new
"(2005) has offered a significant advancement in the domain of sentiment analysis, illustrating the potential of the method in handling complex tasks and influencing subsequent studies (e.g., Pang and Lee (2004); Liu et al. (2005)).",1,new
The study by Johnson et al. (2010) demonstrated that semi-supervised learning approaches can achieve comparable results to fully supervised methods.,1,new
"According to a recent study by Kim and Kim (2018), unsupervised machine learning techniques have been shown to yield high precision comparable to traditional supervised learning algorithms.",1,new
Research by Wang et al. (2012) has found that unsupervised neural networks can match the performance of their supervised counterparts in various classification tasks.,1,new
"The most notable contributions to this field have been made by researchers such as Manning (Manning, 1999), (Manning, 2002), (Manning, 2008).",1,new
"The pioneering work of Jurafsky (Jurafsky, 1996), (Jurafsky, 2000), (Jurafsky, 2009) has significantly advanced our understanding of this area.",1,new
"Recent breakthroughs in the field have been achieved by the research of Collins (Collins, 1996), (Collins, 1999), (Collins, 2010).",1,new
"Although (Kessler, 1982) does not provide a comprehensive analysis of word sense induction in large corpora, there is no clear indication that the ""collocation-based clustering"" method (Kessler, 1987) would be ineffective for more extensive datasets.",1,new
"In spite of the limitations of (Liddy, 1995) in modeling the nuances of domain-specific terminology, it is reasonable to assume that the ""ontological categorization"" approach (Liddy, 1998) would still be applicable to more complex linguistic phenomena.",1,new
"While (Brown et al., 1990) does not address the challenges of word sense disambiguation in the context of named entities, there is no reason to believe that the ""supervised learning"" paradigm (Brown et al., 1992) would not be adaptable to this specific task.",1,new
"Our results (Lin, 2004) demonstrate a substantial improvement over (Hastie et al., 1996) in terms of accuracy when classifying high-dimensional data.",1,new
"The proposed approach (Blei et al., 2003) exhibits superior performance to (Jordan & Jacobs, 1994) in capturing underlying patterns in complex networks.",1,new
"A comparison between our method (Bishop, 1995) and (Moody, 1992) reveals that the former achieves significantly better results in clustering large datasets.",1,new
"The work of (Bengio et al., 2003) demonstrated significant improvement in speech recognition accuracy, with a notable increase from 85% to 92.1% when utilizing a hierarchical neural network approach.",1,new
"The results of (Hinton et al., 2006) show that the addition of a denoising autoencoder led to a substantial boost in image classification performance, from 78.5% to 91.2%.",1,new
"(LeCun et al., 1998) observed a notable enhancement in text classification accuracy, rising from 80.2% to 94.1%, when applying a convolutional neural network with a larger receptive field.",1,new
"The use of the Hidden Markov Model (Bakis et al., 1994) has led to significant advancements in speech recognition technology, demonstrating its efficacy in this domain.",1,new
"Recent studies employing the k-means clustering algorithm (MacQueen, 1967) have yielded impressive results in data compression and dimensionality reduction.",1,new
"The incorporation of the Support Vector Machine (SVM) (Cortes & Vapnik, 1995) in machine learning has shown substantial improvements in classification accuracy and efficiency.",1,new
"The concept of part-of-speech tagging has also been explored in the context of a simple English tagger (Brill, 1995), which only identifies the most frequent words in the training corpus.",1,new
"In a study by (Marcus et al., 1993), the accuracy of a basic parser was improved by focusing only on the words that are most common in a large dataset.",1,new
"According to (Krovetz & Hearst, 2000), a basic English tagger only considers the words that occur frequently enough to be represented in a typical language model.",1,new
"Significant advancements have been achieved in processing eastern languages, with notable contributions from researchers such as (Kurohashi 2001, Nakov 2006).",1,new
"Considerable progress has been made in handling morphologically rich languages like Arabic and Russian, thanks to innovative approaches by (Buckwalter 2004, Isahagamuwa 2011).",1,new
"Substantial strides have been taken in developing machine learning models for parsing German and French, with notable work by (Grimm 2010, Sagot 2015).",1,new
"The development of various machine learning algorithms has significantly improved the accuracy of sentiment analysis tools (Pang & Lee, 2008; Socher et al., 2013).",1,new
"Recent advancements in deep learning techniques have led to the creation of more efficient and effective natural language processing (NLP) systems (Collobert et al., 2011; Mikolov et al., 2010).",1,new
"Several commercially available software packages, such as Stanford CoreNLP, have become essential tools for researchers and practitioners in the field of NLP (Manning et al., 2014; Bird et al., 2009).",1,new
"The state-of-the-art parsers, such as those by Collins (1995) and Charniak (2000), heavily rely on probabilistic models to disambiguate word senses, thereby enhancing their overall accuracy.",1,new
"By leveraging the strengths of machine learning algorithms, recent parsers like those of Collins (2003) and Palmer (2004) have demonstrated significant improvements in resolving linguistic ambiguities through contextual dependency analysis.",1,new
"Notably, the performance of current parsers, as exemplified by the work of Collins (1999) and Ruppenhofer (2000), has been substantially bolstered by the incorporation of syntactic dependency features and statistical models for sense disambiguation.",1,new
"The machine learning algorithm proposed by Zhang and Liu (2019), when tested on a large-scale dataset, demonstrates a comparable performance to the state-of-the-art models of Collobert and Weston (2008) and Johnson and Zhang (2017).",1,new
"Furthermore, the empirical analysis by Kim and Park (2015) reveals that the proposed neural network architecture yields results that are on par with the top-performing models of Krizhevsky et al. (2012) and Sutskever et al. (2014).",1,new
"Moreover, the results obtained by the ensemble learning approach of Li and Wang (2020), when applied to a real-world problem, show a level of accuracy that is comparable to the best-performing methods of Breiman (2001) and Hastie et al. (2009).",1,new
"The use of machine learning algorithms in sentence parsing has led to the development of several state-of-the-art parsers that relax the assumption of a fixed set of rules, such as the integration of contextual information into the parsing process (Klein and Manning, 2003; Collins, 1997).",1,new
"Recent advancements in natural language processing have resulted in the creation of more sophisticated parsing models, which modify the parsing algorithm to accommodate contextual factors (Charniak, 1997; Petrov and Klein, 2007), thereby improving the overall accuracy of the parser.",1,new
"State-of-the-art parsers have begun to abandon the traditional assumption of a fixed rule set, instead incorporating context-dependent rules and backtransforms to enhance the parsing process (Johnson, 1998; Manning and Klein, 2003), leading to improved parsing accuracy and efficiency.",1,new
"The incorporation of contextual features in dependency-based parsing has led to substantial advancements in grammatical error detection (Klein & Manning, 2003; Petrov & Klein, 2007; McDonald et al., 2005).",1,new
"The employment of probabilistic models in semantic role labeling has resulted in considerable improvements in the accuracy of predicate-argument structures (Grosz et al., 1995; Palmer et al., 2005; Gildea & Jurafsky, 1998).",1,new
"The utilization of subcategorization frames in HPSG parsing has yielded significant gains in the identification of verb-argument relationships (Sag et al., 2003; Copestake et al., 2005; Baldridge & Kracht, 1999).",1,new
"The researchers compared their parser's output with the results of the widely-used Brill (1995) tagger, which they applied to the Penn Treebank corpus to evaluate its accuracy in identifying parts of speech.",1,new
"To evaluate the efficacy of their approach, the authors compared the output of their parser with the output of the popular Charniak (2000) parser on the Brown corpus, using the standard evaluation metrics for parsing accuracy.",1,new
"A key aspect of their methodology involved comparing the output of their parser with the results of the well-established King (2003) parser on the Wall Street Journal corpus, which they used to assess the parser's performance in handling complex sentence structures.",1,new
"The most accurate machine translation systems, as demonstrated by Koehn (2004), Brown (1990), and Hutchins and Somers (1992), rely on advanced statistical models and pruning techniques to significantly reduce the search-space.",1,new
"Recent studies on natural language processing, such as those conducted by Manning (1999), Collins (2003), and Jurafsky (1996), show that the use of probabilistic parsing algorithms can lead to substantial improvements in parsing accuracy.",1,new
"The top-performing speech recognition systems, including those developed by Jelinek (1997), Young et al. (1994), and Ney et al. (1994), all employ sophisticated statistical methods to efficiently prune the search-space and achieve high recognition rates.",1,new
"The work of Christopher Manning (1992, 1993, 1996) on part-of-speech tagging has had a profound impact on the development of computational linguistics.",1,new
"The contributions of John Hopcroft (1971, 1973, 1974) to the field of automata theory have been instrumental in shaping the foundations of computer science.",1,new
"The groundbreaking research of Terry Winograd (1968, 1972, 1976) on artificial intelligence has significantly advanced the capabilities of natural language understanding systems.",1,new
"The recent success of several state-of-the-art models on the Penn Treebank corpus (e.g., Collins 1997, 1999; Ratnaparkhi 1997; Palmer 2004; Petrov and Klein 2007) can be attributed to their use of machine learning techniques.",1,new
"Notably, several high-performing parsers on the OntoNotes 5.0 dataset (e.g., McDonald et al. 2006; Carreras and Marquez 2005; Zhang and Clark 2008; McDonald and Crammer 2007) demonstrate the effectiveness of incorporating semantic role labeling.",1,new
"The notable achievements of several top-performing models on the CoNLL-2000 shared task (e.g., Appelt et al. 2000; Charniak 2000; Collins 2000; Ding and Palmer 2005) underscore the importance of discriminative training methods.",1,new
"The proposed reinforcement learning framework has been successfully applied to various tasks, such as decision-making in finance (Puterman, 1994; Sutton & Barto, 1998), and has shown promising results in improving the accuracy of financial predictions.",1,new
"The use of dynamic programming in machine learning has led to significant advancements in solving complex optimization problems, including resource allocation (Bellman, 1957; Bertsekas, 2005) and has been widely adopted in various fields.",1,new
"The introduction of deep learning techniques has revolutionized the field of computer vision, resulting in improved object detection (Krizhevsky et al., 2012; Girshick et al., 2014) and has enabled the development of more sophisticated image recognition systems.",1,new
The incorporation of syntactic and semantic knowledge into probabilistic models has been effectively employed by researchers such as Johnson (2003) and Carroll (2008) in their parsing frameworks.,1,new
"Recent studies have demonstrated the effectiveness of using word-based representations in statistical machine translation models, as seen in the work of Koehn (2004) and Och (2003).",1,new
"Word-based lexicalizations of semantic models have been successfully utilized in the development of semantic role labeling systems, as exemplified by the research of Gildea (2002) and Palmer (2004).",1,new
"Lexicalized probabilistic models have garnered significant attention in recent years, with notable contributions from researchers such as (Klein and Manning 2003, 2004; Ratnaparkhi 1996).",1,new
"Dependency-based parsing techniques have gained popularity, with influential works including (Santorini 1990, 1992; Kallmeyer 2005, 2007).",1,new
"The use of probabilistic context-free grammars has become widespread, as evident from the work of (Shieber 1985, 1986; Johnson 1998, 2001).",1,new
"The use of semantic role labeling has been shown to significantly enhance parsing accuracy for Dutch (Gildea and Jurafsky, 2002; Palmer et al., 2005) and the approach proposed by Palmer et al. (2005) has been successfully applied to Arabic (Bod et al., 2003) and German (Ahn, 2006).",1,new
"The incorporation of named entity recognition can lead to substantial improvements in information extraction for Spanish (Borthwick et al., 1998; Riloff and Jones, 1999), and the entity-based model developed by Riloff and Jones (1999) has been successfully implemented in Portuguese (Hindle, 2000) and Italian (Seymore and McRoy, 2001).",1,new
"The adoption of machine learning techniques has resulted in substantial gains in part-of-speech tagging for French (Brill, 1993; Tjong Kim Sang and Veenstra, 1999), and the supervised learning model proposed by Tjong Kim Sang and Veenstra (1999) has been successfully applied to Swedish (Brants, 2000) and Danish (Nivre, 2006).",1,new
The findings of Yang (1995) and Chen and Lee (1998) further support the efficacy of the Leacock-Chodrow (1998) model for language processing tasks.,1,new
The studies conducted by Kim and Kim (2001) and Tanaka and Nakamura (2002) have shown the effectiveness of the Hopfield (1982) network for pattern recognition applications.,1,new
The research of Patel and Patel (1996) and Wong and Wong (1999) has highlighted the potential of the Hopfield (1982) model for solving complex optimization problems.,1,new
"The robustness of the proposed framework, as demonstrated by Figure 3, suggests that the efficacy of the Smith et al. (2019) approach is consistent, even when dealing with limited data samples.",1,new
"The analysis of Figure 2 reveals that the results of the Johnson (2001) model exhibit a consistent trend, indicating a stable performance, even for modestly sized training datasets.",1,new
"Notably, the evaluation metrics presented in Figure 4 confirm that the performance of the Lee et al. (2020) method remains reliable, even when trained on relatively small datasets.",1,new
"The use of neural networks has been demonstrated to enhance syntactic parsing results in the CoNLL dataset (e.g., McDonald et al. 2005; Petrov and McDonald 2012; Chiang 2005).",1,new
"Recent advances in probabilistic models have led to significant improvements in dependency parsing, as seen in the CoNLL shared task (e.g., Koo et al. 2007; McDonald and Nivre 2007; Nivre 2008).",1,new
"The integration of statistical models has been shown to improve parsing accuracy in the treebank corpus, as evidenced by the work of (e.g., Charniak 2000; Collins 1997; Carroll and Rooth 1998).",1,new
"2. Conclusion The development of statistical machine translation has shown significant advancements in the past decade, with models like phrase-based translation and hierarchical phrase-based translation achieving remarkable translation accuracy (e.g., Koehn et al. 2007; Och and Ney 2003).",1,new
"3. Background The application of neural networks to natural language processing has led to impressive results in sentiment analysis and text classification tasks, with models like deep neural networks and recurrent neural networks demonstrating high classification accuracy (e.g., Collobert et al. 2011; Socher et al. 2013).",1,new
"1. Literature Review Recent studies on topic modeling have demonstrated the effectiveness of non-negative matrix factorization in discovering underlying topics and themes in large document collections, with notable improvements in topic coherence and interpretability (e.g., Lee and Seung 2001; Kim and Park 2008).",1,new
"The analysis reveals that the adoption of incremental parsing techniques (Shieber, 1985; Carroll, 1993) and robust feature selection methods (Kroch, 1997) yields a significant reduction in computational complexity, indicating their potential for improved parsing efficiency in natural language processing.",1,new
"Furthermore, our results demonstrate that the application of graph-based representation learning (Bottou, 1998; Bengio, 2000) and node embedding techniques (Gao et al., 2018) results in a substantial improvement in the accuracy of dependency parsing models, underscoring their utility in modeling complex linguistic structures.",1,new
"Notably, the empirical results indicate that the employment of active learning strategies (Cohn et al., 1996; Settles, 2010) and semi-supervised learning approaches (Chapelle et al., 2006) leads to a notable decrease in the required amount of labeled training data, making them viable alternatives for efficient model training in natural language processing tasks.",1,new
"Their use in dependency parsing has been extensively studied (Bikel et al., 1999; Magerman, 1995; Sleator & Temperley, 1993), and their effectiveness is well-documented.",1,new
"These models have been a cornerstone of many machine learning algorithms (Bates & Weischedel, 1993; Hindle, 1990; Kay, 1973), and their simplicity belies their power.",1,new
"They have been a crucial component in the development of several NLP frameworks (Church, 1988; Marcus et al., 1993; Pollard & Sag, 1994), and their influence can still be seen today.",1,new
"We utilize a high-performance computational model (Kroch, 1989) to analyze the syntactic dependencies within each sentence, allowing us to pinpoint the roles of arguments (a), adjuncts (j), and modifiers (m).",1,new
"The proposed framework relies on a state-of-the-art named entity recognition system (Ruppenhofer et al., 2010) to accurately identify and categorize entities such as locations (l), organizations (o), and dates (d).",1,new
"Our approach incorporates a machine learning algorithm (Manning & Schtze, 1999) to classify the grammatical function of each word in a sentence, distinguishing between subjects (s), complements (c), and adjuncts (j).",1,new
"Previous studies on machine translation (e.g., Brown et al., 1993; Sutskever et al., 2014) have demonstrated significant advancements in fluency and accuracy through the use of neural networks.",1,new
"Our findings are consistent with those of previous research on sentiment analysis (e.g., Pang and Lee, 2008; Bojanowski et al., 2016), which have shown substantial improvements in classification performance with the incorporation of semantic features.",1,new
"The results of our experiments are in line with prior work on information retrieval (e.g., Salton and McGill, 1983; Bendersky and Croft, 2010), indicating that the adoption of knowledge graphs can lead to substantial gains in query efficiency and relevance.",1,new
"The significant advancements in deep learning techniques (Rumelhart et al., 1986; LeCun et al., 1989) have led to the development of more sophisticated natural language processing models, including those based on recurrent neural networks.",1,new
"Recent research has shown that the incorporation of cognitive science principles (Anderson, 1983; Levelt, 1989) into artificial intelligence has resulted in more effective and human-like language understanding systems.",1,new
"The integration of machine learning and symbolic reasoning (Minsky, 1961; Newell and Simon, 1972) has enabled the creation of more robust and accurate computational models of human cognition, with far-reaching implications for artificial intelligence research.",1,new
"Recent studies have led to the development of advanced machine translation systems for multiple languages, achieving outstanding performance in languages such as Spanish (Brown et al., 1988; Hutchins & Somers, 1992).",1,new
"Significant progress has been made in the area of speech recognition, with numerous models developed for various languages and exceptional results reported for, e.g., Mandarin Chinese (Huang et al., 1993; Lee & Huang, 1989).",1,new
"The field of natural language processing has witnessed substantial advancements, with researchers creating and testing robust models for diverse languages, including Arabic (Al-Shawi & Horne, 1989; Abdel-Rahman & Shaalan, 2008), resulting in remarkable improvements in language understanding.",1,new
"Recent advancements in machine learning have led to improved performance in part-of-speech tagging tasks, with notable contributions from models incorporating neural networks (Brown et al., 1990; Hopfield, 1982; Manning, 1992).",1,new
"The development of hybrid approaches has significantly enhanced the accuracy of named entity recognition, thanks to the incorporation of contextualized embeddings and rule-based systems (Graff, 1997; Sang and De Meulder, 2000; Finkel et al., 2005).",1,new
"The integration of statistical and rule-based methods has also led to notable improvements in semantic role labeling, with various researchers contributing to the field (Gildea and Palmer, 2002; Carreras and Marquez, 2005; Gildea, 2003).",1,new
"The development of advanced machine learning algorithms (Goodfellow et al., 2014; LeCun et al., 2015) is heavily dependent on the existence of large-scale datasets like ImageNet.",1,new
"The effectiveness of sentiment analysis techniques (Turney, 2002; Liu, 2010) greatly relies on the quality and availability of annotated text corpora.",1,new
"The progress in natural language processing (NLP) tasks (Baker et al., 1976; Manning & Schtze, 1999) has been significantly enhanced by the creation of well-structured linguistic resources like WordNet.",1,new
"Our selection of sections for training and testing is also guided by previous research (Hindle, 2000; Riezler et al., 2002; Macleod & Briscoe, 2003), where parsers were optimized on sections 2-20 and evaluated on section 22.",1,new
"The choice of sections for our experiment is motivated by the work of earlier studies (Leusch, 1996; Collins & Duffy, 2002; Johnson, 2001), which trained and tested parsers on sections 3-19 and 21, respectively.",1,new
"Our methodology is informed by the contributions of earlier researchers (Ratnaparkhi, 1998; Charniak, 1997; Collins, 1997), who developed and evaluated parsers on sections 2-20 and 23, providing a solid foundation for our own research.",1,new
"Recent advancements in the field of deep learning have led to notable improvements in the efficiency of dependency parsing, with notable studies by Socher et al. (2011) and Zeman and Zabokrtsky (2012) demonstrating enhanced accuracy and speed.",1,new
"Notwithstanding the initial challenges, significant strides have been made in the development of neural network architectures for semantic role labeling, as evidenced by the work of Ma and Hovy (2001) and Gildea and Jurafsky (2002).",1,new
"The introduction of recurrent neural networks has also facilitated substantial progress in the analysis of syntactic structures, as exemplified by the research of Bohnet and Eisenstein (2015) and Tackstrom et al. (2012).",1,new
"Our approach for named entity recognition utilizes the state-of-the-art model proposed by Grishman and Sundheim (1986), which has been shown to achieve high levels of accuracy in various NLP tasks.",1,new
"The machine learning algorithm employed in this study is based on the work of Mitchell (1997), a pioneer in the field of machine learning, whose contributions have significantly advanced our understanding of pattern recognition.",1,new
"For the analysis of sentiment analysis, we draw upon the framework developed by Turney (2002), which provides a robust method for detecting sentiment in text, enabling us to accurately identify positive and negative opinions.",1,new
"The development of novel machine learning algorithms has been significantly advanced by the introduction of recursive neural networks (RNNs) (Bengio et al., 1994; Elman, 1990).",1,new
"The introduction of dependency parsing has led to significant improvements in natural language processing tasks, as evident in the work of McDonald et al. (2005) and Nivre (2003).",1,new
"The use of vector space models has been instrumental in the advancement of information retrieval, with notable contributions from Deerwester et al. (1990) and Salton and McGill (1983).",1,new
"The development of the PropBank (Palmer et al., 2005), a semantic role labeling resource, has significantly contributed to the advancements in sentence understanding and argument structure analysis (Gardent et al., 2017; Sammons et al., 2007) for English.",1,new
"The creation of the OpenNLP Maxent Tagger (Lafferty et al., 2001), a machine learning-based part-of-speech tagger, has greatly facilitated the improvement in NLP tasks such as named entity recognition and language modeling (Bikel et al., 1999; Toutanova et al., 2003) for English.",1,new
"The establishment of the CoNLL shared task (Sang & De Meulder, 2003), a benchmark for parsing and semantic role labeling evaluation, has driven the progress in machine learning-based approaches for NLP (McDonald et al., 2005; McDonald & Crammer, 2006) and contributed to the development of more accurate parsing models.",1,new
"The results of our experiment show that the accuracy of named entity recognition is 92.5, precision 90.2, and recall 91.4, respectively, at a speed of 3500 tokens per second. Table 4: Performances of Named Entity Recognition (tokens per second) These values are comparable to the state-of-the-art results for the same task (Hindle 1990; Sang 1999).",1,new
"The results of our experiment show that the F1 score of part-of-speech tagging is 88.1, precision 86.5, and recall 89.7, respectively, at a speed of 4200 tokens per second. Table 5: Performances of Part-of-Speech Tagging (tokens per second) These results are in line with the current state-of-the-art for the same task (Brill 1995; Ratnaparkhi 1996).",1,new
"The results of our experiment show that the accuracy of sentiment analysis is 85.5, precision 83.1, and recall 87.9, respectively, at a speed of 3800 tokens per second. Table 6: Performances of Sentiment Analysis (tokens per second) These results are comparable to the state-of-the-art results for the same task (Pang 2002; Wiebe 2000).",1,new
"The work of Hirschman (1991, 1992) on discourse semantics is noteworthy, particularly their applications of discourse representation theory.",1,new
"The research by Kamp (1981, 1984) on dynamic semantics has been influential in the field of linguistic analysis, with their contributions to the study of tense and aspect.",1,new
"The methodologies employed by Gazdar (1979, 1981) in the study of generative grammar are also deserving of recognition, as they have significantly impacted the development of formal semantics.",1,new
"The incorporation of semantic role labeling (Kipfs and Palmer (2004), Palmer and Gildea (2003) et al.) into Phrase Structure Grammars (PSGs) has been shown to significantly enhance their applicability to natural language understanding tasks.",1,new
"As demonstrated by various researchers (Gildea and Jurafsky (2002), McKeown (1998), etc.), the integration of Discourse Representation Theory (DRT) with Dependency Grammars (DGs) has led to improved models for pragmatic inference.",1,new
"The transformation of Tree Adjoining Grammars (TAGs) into Lexicalized TAGs, as explored by (Sag et al. (2003), Joshi et al. (1991), etc.), has been instrumental in advancing the field of linguistic parsing and generation.",1,new
"Although cutting-edge machine learning models (LeCun et al., 2015; Krizhevsky et al., 2012) boast superior performance, the straightforwardness and expediency of rule-based models make them appealing in scenarios necessitating swift, low-complexity processing or handling of massive datasets.",1,new
"Despite the superior accuracy of recent probabilistic models (Bengio et al., 2003; Rabinovich et al., 2001), the elegance and speed of deterministic models render them suitable for applications requiring rapid, lightweight processing or efficient handling of voluminous data.",1,new
"While high-performing deep learning frameworks (Sutskever et al., 2014; Mnih et al., 2015) are often the preferred choice, the simplicity and reliability of traditional models make them attractive for contexts demanding fast, minimalistic processing or streamlined handling of extensive data.",1,new
"Recent advancements in machine learning have led to significant improvements in sentiment analysis (Turney, 2002; Hu & Liu, 2004; Wilson et al., 2005).",1,new
"Substantial progress has been made in the field of information retrieval, particularly in the development of effective search algorithms (Salton & McGill, 1983; Baeza-Yates & Ribeiro-Neto, 1999; Frakes & Baeza-Yates, 1992).",1,new
"There has been considerable growth in the study of natural language processing, with notable contributions from researchers in the areas of syntax and semantics (Chomsky, 1957; Huddleston, 1984; Aarts & Aarts, 2006).",1,new
"The recent surge in research on machine learning algorithms has led to significant advancements in natural language processing (Bengio et al., 2003; Jurafsky & Martin, 2000; Sutton & McCallum, 2011).",1,new
"The past few years have witnessed substantial progress in developing robust statistical models for sentiment analysis (Kim & Hovy, 2004; Turney, 2002; Liu et al., 2010).",1,new
"There has been substantial growth in the field of computational linguistics, with notable contributions from researchers in the areas of syntax and semantics (Gazdar et al., 1985; Pollard & Sag, 1994; Sag et al., 2003).",1,new
"It is noteworthy that, despite the significant body of research on how the complexity of treebanks influences the accuracy of dependency parsers (e.g., in the form 94 n1:NP [=] n2:VP [SUBJ=] n4:ADVP [=] GSC4ES n3:PP [=] n5:PP [SUBJ=] n6:NR [=] ESDO interview n7:NP [OBJ=] n8:NR [ADJUNCT] AIC1 Thai n9:NN [=] D3D2 president f1             PRED ESDO SUBJ f2  PRED GSC4ESNTYPE proper NUM sg   OBJ f3       PRED D3D2 NTYPE common NUM sg ADJUNCT   f4  PRED AIC1NTYPE proper NUM sg                         : N  F (n1)=(n3)=(n5)=f1 (n2)=(n4)=f2 (n6)=(n8)=f3 (n7)=f4 Figure 2: Cand f-structures with  links for the sentence GSC4ESESDOAIC1D3D2 of lexicalisation and grammaticalisation (Dixon, 1972) has garnered considerable attention, to our knowledge, there remains a notable dearth of research on this subject for discourse realisation, a process that is generally regarded as the reverse process of lexicalisation.",1,new
"The study of how the representational power of feature structures impacts the performance of a machine translation system (e.g., in the form 95 n1:NP [=] n2:VP [SUBJ=] n4:ADVP [=] GSC4ES n3:PP [=] n5:PP [SUBJ=] n6:NR [=] ESDO interview n7:NP [OBJ=] n8:NR [ADJUNCT] AIC1 Thai n9:NN [=] D3D2 president f1             PRED ESDO SUBJ f2  PRED GSC4ESNTYPE proper NUM sg   OBJ f3       PRED D3D2 NTYPE common NUM sg ADJUNCT   f4  PRED AIC1NTYPE proper NUM sg                         : N  F (n1)=(n3)=(n5)=f1 (n2)=(n4)=f2 (n6)=(n8)=f3 (n7)=f4 Figure 3: Cand f",1,new
"The incorporation of techniques such as dependency parsing (Klein & Manning, 2003; McDonald et al., 2005) and semantic role labeling (Carreras et al., 2008), has greatly enhanced the accuracy of natural language understanding models and led to substantial gains in downstream applications.",1,new
"The employment of machine learning approaches (Bengio et al., 2003; Collobert et al., 2011) and feature engineering methods (Levin, 1993), has been instrumental in improving the performance of NLP tasks and yielding notable advancements over traditional rule-based systems.",1,new
"The application of discourse-level processing (Asher & Lascarides, 2003; Lascarides & Asher, 2009) and pragmatics-based methods (Grice, 1975), has significantly contributed to the development of more sophisticated language understanding models and has shown considerable promise in addressing complex linguistic phenomena.",1,new
"3.2 A Knowledge-Based Approach The knowledge-based (KB) system, which utilizes pre-existing linguistic resources, has shown promising results in natural language processing (Levin, 1993; Pollard & Sag, 1994).",1,new
"4.5 A Statistical Model The statistical (SM) approach, which relies on large datasets and machine learning algorithms, has proven to be highly effective in sentiment analysis (Turney, 2002; Hatzivassiloglou & McKeown, 1997).",1,new
"2.1 A Hybrid Model The hybrid (HYB) model, which combines the strengths of both rule-based and statistical methods, has demonstrated significant improvements in machine translation (Brown et al., 1993; Melamed, 2001).",1,new
"The results of our experiments using machine learning algorithms for text classification (Krizhevsky et al., 2012) suggest that this approach outperforms traditional methods in many applications.",1,new
"The use of cognitive architectures (Newell, 1990) has been shown to significantly improve the performance of artificial intelligence systems in complex problem-solving tasks.",1,new
"Empirical studies have demonstrated that the integration of symbolic and connectionist models (Smolensky, 1988) can lead to more accurate and efficient natural language processing systems.",1,new
"Our findings align with previous studies on language modelling with weighted finite state transducers (Mohri et al., 1996; Mohri & Sproat, 1996), suggesting that our proposed approach to weighted finite state transducer decomposition yields optimal results in terms of both accuracy and efficiency.",1,new
"In accordance with the research of Marcus et al. (1983) on parsing with lexicalised context-free grammars, our study demonstrates that incorporating semantic information into the parsing process significantly improves the accuracy of part-of-speech tagging.",1,new
"Consistent with the results of Goldsmith (1991) on the use of Markov models in natural language processing, our experiment indicates that the proposed Markov model-based approach outperforms traditional methods in predicting linguistic dependencies.",1,new
"Our results concur with earlier findings on parsing with probabilistic tree-adjoining grammars (Joshi, 1985; Vijay-Shanker, 1985), suggesting that semantic features are more closely aligned with human interpretation and empirical evidence.",1,new
"In line with previous research on parsing with lexicalised categorial grammars (Baker, 1970; Steedman, 1987), we observe that statistics over syntactic, rather than semantic, features provide the most accurate reflection of human intuitions and experimental data.",1,new
"Consistent with recent studies on parsing with lexicalised phrase structure grammars (Shieber, 1985; Kaplan & Bresnan, 1982), we find that statistics over lexical, as opposed to morphological, features exhibit the strongest correlation with human judgments and experimental outcomes.",1,new
"The machine translation community boasts numerous efficient and precise automated translation systems, such as those developed by Koehn (2004), Och and Ney (2003) and Huang et al. (1997).",1,new
"The natural language generation community has developed several sophisticated and effective automated generation systems, including those produced by Reiter and Dale (2000), Gordon (2006) and Schlangen (2003).",1,new
"The speech recognition community has made significant progress with the development of numerous fast and accurate automated recognition systems, including systems created by Hermansky et al. (2010), Li et al. (2004) and Povey et al. (2011).",1,new
Recent studies have shown that Li and McKeown (2003) have successfully developed a system for identifying key concepts in large volumes of text data.,1,new
"Building on the work of Bikel and Miller (1998), researchers have made significant advancements in the area of named entity recognition, enabling more accurate extraction of relevant information.",1,new
"Following the lead of Grishman and Sundheim (1996), researchers have proposed innovative techniques for evaluating the performance of machine learning models in text analysis tasks.",1,new
"Dredze, J., and Jurgens, J. (2015) develop a robust method to identify and extract various types of NPs from text data with high precision.",1,new
"Liu, B. and Zhang, L. (2009) achieve promising results in automatically detecting and categorizing NPs using their novel machine learning approach.",1,new
"Pantel, P., and Pennacchiotti, M. (2009) propose a sophisticated algorithm to discover and annotate NPs in large text corpora with remarkable accuracy.",1,new
"The researchers (Manning et al., 1999) successfully employed Latent Semantic Analysis (Deerwester et al., 1990) in conjunction with clustering algorithms to achieve significant improvements in information retrieval tasks.",1,new
"The authors of (Koller & Sahami, 1997) evaluated the effectiveness of Bayesian networks in combination with decision trees (Quinlan, 1986) for classification problems in machine learning.",1,new
"In their study, (Salton & Buckley, 1990) explored the application of vector space models (Salton & McGill, 1983) in conjunction with query expansion techniques to enhance the accuracy of text retrieval systems.",1,new
"To mitigate overfitting, we utilize regularization techniques, as successfully demonstrated by Guyon and Elisseeff (2003).",1,new
"The potential for variance in the data is addressed by incorporating a bootstrapping method, similar to that employed by Efron (1979).",1,new
"To increase the reliability of our results, we employ a k-fold cross-validation approach, in line with the recommendations of Kohavi (1995).",1,new
"However, when employing complex features such as syntactic parse trees, we cannot utilize computationally intensive techniques such as inside-outside algorithms and the forward-backward algorithm (Baker, 1979) and hidden Markov models (Rabiner, 1989).",1,new
"Due to the presence of long-range dependencies, we cannot leverage efficient methods like dynamic programming and the Viterbi algorithm (Vapnik, 1998) and support vector machines (Joachims, 1999).",1,new
"In the case of incorporating semantic features, we are unable to apply time-consuming procedures like the inside-outside algorithm and the Baum-Welch algorithm (Jelinek, 1976) and Gaussian mixtures (Reynolds, 2002).",1,new
"The integration of novel deep learning architectures, such as Residual Networks (He et al., 2016) and Graph Convolutional Networks (Kipf and Welling, 2016), has been instrumental in enhancing the accuracy of image classification tasks, primarily due to their capacity to effectively capture hierarchical and spatial relationships within the data.",1,new
"The adoption of ensemble methods, including Bagging (Breiman, 1996) and Boosting (Freund and Schapire, 1997), has greatly improved the reliability of regression predictions, largely attributed to their ability to combine multiple models and reduce overfitting.",1,new
"The utilization of probabilistic graphical models, such as Hidden Markov Models (Rabiner, 1989) and Conditional Random Fields (Lafferty et al., 2001), has been pivotal in resolving the complexities of temporal data analysis, primarily due to their capacity to model sequential dependencies and capture patterns in stochastic processes.",1,new
"Our experimental setup employed a Gradient Boosting Classifier (Freund & Schapire, 1997) to optimize the ranking model, and we found it to be highly effective in improving the overall performance.3 Moreover, we followed the guidance of Crammer & Singer (2002) for parameter tuning.",1,new
"The results of our investigation were significantly enhanced by utilizing a Random Forest ranker (Breiman, 2001), as seen in Figure 1. We also drew inspiration from the work of Lewis (1998) on feature selection for ranking tasks.",1,new
"In our analysis, we utilized a Logistic Regression ranker (Hastie et al., 2001) to fine-tune the ranking model, which showed a substantial improvement in the prediction accuracy. This aligns with the recommendations of Dumais et al. (2003) for applying logistic regression in ranking problems.",1,new
"The Hierarchical Attention Model (Bahdanau et al., 2015) for machine translation tasks has shown to achieve superior performance compared to other state-of-the-art models, outperforming them in several metrics, including BLEU and ROUGE scores. However, one major limitation of this model is its computational complexity, which can be a significant bottleneck in large-scale deployments.",1,new
"The use of Long Short-Term Memory (LSTM) networks for time series forecasting, as proposed by (Hochreiter & Schmidhuber, 1997), has been shown to provide accurate predictions with minimal overfitting. However, a major drawback of this approach is its sensitivity to hyperparameter tuning, which can be time-consuming and requires significant expertise.",1,new
"The application of the Support Vector Machine (SVM) algorithm, as described in (Cortes & Vapnik, 1995), has been widely adopted for classification tasks due to its ability to provide high accuracy and robustness to outliers. Nevertheless, the main limitation of SVM is its slow training time, especially for large datasets, which can be a major obstacle in real-time applications.",1,new
"The use of recursive neural networks has been found to be particularly effective in modeling complex relationships between variables, as demonstrated in the work of Bengio et al. (2003; Socher et al., 2011).",1,new
"The incorporation of ensemble methods in machine learning has been widely adopted due to its ability to improve model robustness and accuracy, as shown by Dietterich (2000) and Breiman (2001).",1,new
"The technique of stacking has been successfully applied to improve the performance of support vector machines, as reported by Wolpert (1992) and Breiman (1996), and has been found to be a valuable tool in the field of pattern recognition.",1,new
"The use of regularization techniques, such as dropout (Srivastava et al., 2014), has proven to be an effective way to prevent overfitting in neural network training, and we have incorporated it into our model.",1,new
"Normalization of input data is a crucial step in preventing overfitting and improving the generalizability of our model, as demonstrated by the work of LeCun et al. (2015).",1,new
"Ensemble methods, such as bagging (Breiman, 2001), have been widely used to reduce overfitting and improve the accuracy of machine learning models, and we have employed this technique in our experiments.",1,new
"As demonstrated in the study of Support Vector Machines (SVMs) by Vapnik (1995), the classification process is often characterized by its high accuracy and robustness in handling complex datasets with minimal computational cost.",1,new
"In line with the findings of Rademacher (2002), the use of gradient descent in neural networks leads to efficient convergence and optimal performance with relatively few training epochs.",1,new
"As noted by Minsky and Papert (1969) in their pioneering work on multi-layer perceptrons, the incorporation of non-linear activation functions enables the network to learn and classify complex patterns with high precision.",1,new
"Our study incorporates the well-established supervised learning technique of support vector machines, as proposed by Cortes and Vapnik (1995).",1,new
"The proposed model employs the widely used stochastic gradient descent algorithm, initially introduced by Robbins and Monro (1951) and further refined by Bottou (1998).",1,new
"We utilize the efficient and effective decision tree learning algorithm, as first described by Breiman et al. (1984), to classify the dataset.",1,new
The convolutional neural network has a well-established mathematical foundation and has shown promising results in image classification tasks (LeCun et al. 1998).,1,new
The recursive neural tensor network has a robust theoretical basis and has been demonstrated to be successful in natural language inference tasks (Socher et al. 2013).,1,new
The long short-term memory network has a sound theoretical framework and has been proven to be effective in sequential data modeling tasks such as speech recognition (Hochreiter & Schmidhuber 1997).,1,new
"Our model's performance is significantly enhanced by the incorporation of the methodology proposed by Socher et al. (2011), resulting in a boost from 85.1% to 87.5% in accuracy.",1,new
"The implementation of the decision tree algorithm by Quinlan (1986) leads to a notable improvement in the model's precision, rising from 82.9% to 84.2%.",1,new
"According to the study by Manning and Schtze (1999), the addition of part-of-speech tagging yields a substantial increase in the model's recall, climbing from 92.1% to 93.8%.",1,new
"The proposed neural network model updates the model parameters after processing each instance in the dataset, effectively treating each instance as a separate training instance (Rumelhart et al., 1986). We adopt the strategy of normalizing the model parameters after each update to prevent overfitting.",1,new
"In the proposed deep learning framework, we incorporate a regularization technique that utilizes the L1 norm to prevent overfitting by penalizing large weights (Tibshirani, 1996). This approach has been shown to be effective in reducing overfitting and improving the generalizability of the model.",1,new
"Our proposed algorithm utilizes a stochastic gradient descent method that updates the model parameters after each instance in the dataset, thereby reducing the risk of overfitting (Bottou & LeCun, 2004). To further alleviate overfitting, we employ a dropout technique that randomly drops out neurons during training, resulting in a more robust model.",1,new
"Averaging models has been demonstrated to mitigate overfitting (Rosenberg, 2004) and alleviate the need for careful example ordering during the training process.",1,new
"The use of ensemble methods has been shown to effectively reduce overfitting (Breiman, 2001) and promote more generalizable results in machine learning models.",1,new
"Studies have found that averaging multiple models can significantly decrease overfitting (Dietterich, 2000) and minimize the impact of example order on training outcomes.",1,new
"Recent studies have demonstrated the effectiveness of convolutional neural networks in image classification tasks (Krizhevsky et al., 2012; Simonyan & Zisserman, 2015).",1,new
"The use of recurrent neural networks has shown promising results in natural language processing, as reported by numerous researchers (Sutskever et al., 2011; Graves et al., 2013).",1,new
"Long short-term memory networks have been successfully applied to various machine learning tasks, including speech recognition and language modeling (Hochreiter & Schmidhuber, 1997; Gers et al., 1999).",1,new
"The current studies have drawn upon the advancements in machine learning techniques, as outlined in the seminal works of (Bengio et al., 2003), (Sutton and McCallum, 1996), (Joachims, 1999), and (Manning and Schtze, 1999), which have been integrated into our proposed framework for enhanced performance.",1,new
"Our approach builds upon the foundation laid by the pioneering research of (Ratnaparkhi, 1996), (Koller and Sahami, 1996), (Hindle, 1990), and (Brown et al., 1990), whose contributions have been pivotal in shaping the current understanding of natural language processing.",1,new
"The methodology employed in this study leverages the insights gained from the works of (Levin, 1993), (Baker, 1995), (Manning, 1999), and (Collins, 1999), which have been instrumental in developing the algorithms and models used in our experiment.",1,new
"Following the groundbreaking work of (Johnson, 2015), notable advancements were made by (Kim et al., 2018) and (Lee et al., 2020), each contributing significantly to the field. Additionally, we have incorporated the results of (Perez and Rodriguez, 2019), which have since surpassed the initial breakthrough, and utilized their model in our preprocessing phase.",1,new
"Building upon the foundational research of (Smith et al., 2008), substantial progress was achieved by (Harris et al., 2012) and (Taylor et al., 2015). Notably, (Patel and Jain, 2016) have recently outperformed the previous benchmark, and we have leveraged their methodology in our feature extraction process.",1,new
"Expanding upon the work of (Brown et al., 2010), notable improvements were introduced by (Davis et al., 2014) and (Miller et al., 2017). Furthermore, the results of (Hall and White, 2013) have since surpassed the original contribution, and we have utilized their approach in our data augmentation phase.",1,new
"Our recent analysis shows that sequence-to-sequence models have outperformed traditional language models in several machine translation tasks, for instance, in translating rare languages like Welsh (Zhang et al. 2018), French (Cherry & Lee 2019) and Arabic (Hassan et al. 2020).",1,new
"The comparison of results indicates that rule-based systems have demonstrated superior performance over machine learning models in text classification tasks, particularly in sentiment analysis (Turney 2002), spam detection (Domingos & Pazzani 1997) and information retrieval (Baeza-Yates & Ribeiro-Neto 1999).",1,new
"According to the recent studies, deep learning architectures have surpassed traditional methods in several NLP applications, e.g., named entity recognition (Lample et al. 2016), dependency parsing (Dozat & Manning 2018) and question answering (Chen et al. 2017).",1,new
"We incorporated the multi-layer perceptron model proposed by Rumelhart et al. (1986) in our analysis, which demonstrated superior performance compared to the baseline model outlined in Figure 3.",1,new
"The efficacy of the gradient descent optimization technique developed by Cauchy (1847) was evaluated in our study, and it yielded more accurate results than the conventional method presented in Table 1.",1,new
"Our research employed the hidden Markov model of Rabiner (1989), which has been shown to outperform the traditional approach illustrated in Figure 5, allowing for more precise predictions in our dataset.",1,new
"The use of ensemble learning techniques has been demonstrated to mitigate overfitting (Kohavi, 1995).",1,new
"The incorporation of regularization methods has been shown to reduce overfitting in deep neural networks (Hastie et al., 2009).",1,new
"The application of cross-validation has been proven to alleviate overfitting in machine learning models (Powers, 2011).",1,new
"Our study utilizes the support vector machine-based approach introduced in (Joachims, 1999), which efficiently handles the class imbalance issue and provides accurate classification results.",1,new
"In this research, we employ the hidden Markov model, as described in (Rabiner, 1989), which effectively addresses the problem of sequence alignment and offers a robust framework for pattern recognition.",1,new
"We leverage the decision tree-based method outlined in (Breiman, 2001), which offers a flexible and interpretable solution to the regression problem, while providing reliable predictions with minimal overfitting.",1,new
"The significant contribution of this research lies in the application of a neural network approach to natural language processing, as demonstrated by the utilization of long short-term memory (LSTM) networks (Hochreiter & Schmidhuber, 1997).",1,new
"The development of a novel deep learning paradigm is exemplified by the use of convolutional neural networks (CNNs) in image classification tasks (LeCun et al., 1998).",1,new
"A groundbreaking study on machine learning algorithms is the implementation of support vector machines (SVMs) in text classification, showcasing their effectiveness in high-dimensional feature spaces (Vapnik, 1995).",1,new
"To enhance the accuracy of our model, we incorporated the incremental learning approach outlined in (Bishop, 1995), building upon the work of (Kumar and Daume, 2011).",1,new
"In order to improve the efficiency of our algorithm, we leveraged the divide-and-conquer strategy suggested in (Vapnik, 1998) and applied it in conjunction with the framework proposed by (Domingos, 1996).",1,new
"We optimized the training process by adopting the early stopping criterion described in (Prechelt, 1998) and combined it with the regularization techniques introduced in (Hastie et al., 2009).",1,new
"The analysis by Johnson and Thompson (2015) reveals that under these conditions, the following performance metric holds: AveragePrecisionUpda,k, BestWtk, a C20 BestLossk, a So it can be seen that the update from a to Upda, k, BestWtk, a is guaranteed to improve AveragePrecision by at least  W  k q C0  W C0 k qC16C17 3. As a result, the algorithms in Figures 5 and 6 could be adapted to incorporate the revised definitions of W  k and W C0 k.",1,new
"The findings of Smith and Lee (2018) demonstrate that under these circumstances, the following convergence guarantee holds: RegretUpda,k, BestWtk, a C20 Regretk, a So it can be observed that the update from a to Upda, k, BestWtk, a is guaranteed to decrease Regret by at least  W  k q C0  W C0 k qC16C17 1. Consequently, the algorithms in Figures 7 and 8 could be modified to take into account the revised definitions of W  k and W C0 k.",1,new
"According to the study by Patel and Kim (2020), under these assumptions, the following theoretical bound holds: ExpectedLossUpda,k, BestWtk, a C20 ExpectedLossk, a So it can be seen that the update from a to Upda, k, BestWtk, a is guaranteed to reduce ExpectedLoss by at least  W  k q C0  W C0 k qC16C17 4. As a result, the algorithms in Figures 9 and 10 could be refined to incorporate the revised definitions of W  k and W C0 k.",1,new
"For a comprehensive discussion of the theoretical underpinnings and mathematical derivations, see Freund and Schapire (1997).",1,new
"For detailed explanations of the algorithmic modifications and computational complexity analysis, refer to Vapnik and Chervonenkis (1971).",1,new
"For a thorough examination of the convergence rates and empirical performance evaluation, see Cortes and Vapnik (1995).",1,new
"Similar to the findings of Collins (2002), it has been observed that adjusting the regularization parameter in support vector machines can lead to improved model accuracy.",1,new
"In line with the work of Collins (2002), researchers have discovered that applying a feature selection method such as recursive feature elimination can enhance the performance of the decision tree algorithm.",1,new
"As noted by Collins (2002), lowering the confidence threshold for the k-nearest neighbors algorithm can result in significant improvements in classification accuracy and model robustness.",1,new
"The decision tree algorithm (Quinlan, 1986) has been shown to be effective in handling noisy data, allowing it to generalize well in real-world applications where data quality may be compromised.",1,new
"The use of support vector machines (Cortes & Vapnik, 1995) with a radial basis function kernel has proven to be successful in high-dimensional spaces, where the data is not easily separable by linear models.",1,new
"The AdaBoost algorithm (Freund & Schapire, 1997) has been found to be particularly effective in boosting the accuracy of weak classifiers, leading to improved performance in a variety of machine learning tasks.",1,new
"The integration of deep learning algorithms, such as Convolutional Neural Networks (CNNs, LeCun et al., 1998), Recurrent Neural Networks (RNNs, Elman, 1990), Long Short-Term Memory (LSTM, Hochreiter and Schmidhuber, 1997), and Gated Recurrent Units (GRUs, Cho et al., 2014), has significantly improved the performance of various NLP tasks.",1,new
"Recent advances in transfer learning have led to the development of various techniques, including Word2Vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), and FastText (Bojanowski et al., 2017), which have been successfully applied to text classification, sentiment analysis, and information retrieval tasks.",1,new
"The application of ensemble methods, such as Random Forest (Breiman, 2001), Gradient Boosting (Friedman, 2001), and AdaBoost (Freund and Schapire, 1997), has proven to be effective in improving the accuracy of various machine learning models, including those used for regression, classification, and clustering tasks.",1,new
"The use of convolutional neural networks (CNNs) was first introduced by LeCun et al. (1998), which has been demonstrated to significantly enhance image classification performance in Krizhevsky et al. (2012).",1,new
"The incorporation of attention mechanisms in recurrent neural networks (RNNs) was initially proposed by Bahdanau et al. (2015), leading to substantial improvements in natural language processing tasks as seen in Vaswani et al. (2017).",1,new
"The concept of transfer learning was pioneered by Yosinski et al. (2014), and its application has been shown to yield notable improvements in deep learning model performance, as evidenced in the work of Zagoruyko and Komodakis (2016).",1,new
"Recent advancements in deep learning have led to the development of sophisticated models such as Deep Neural Networks (Bengio et al., 2006), Recurrent Neural Networks (Hochreiter and Schmidhuber, 1997), and Long Short-Term Memory Networks (Hochreiter and Schmidhuber, 1997), which have significantly improved the performance of sequence labeling tasks.",1,new
"The introduction of ensemble methods, including Bagging (Breiman, 1996), Boosting (Freund and Schapire, 1997), and Stacking (Wolpert, 1992), has greatly enhanced the accuracy of machine learning models in various applications.",1,new
"The integration of structural and statistical approaches, exemplified by Conditional Random Fields (Lafferty et al., 2001), Hidden Markov Models (Rabiner, 1989), and Maximum-Margin Markov Networks (Taskar et al., 2004), has enabled researchers to tackle complex problems in natural language processing and computer vision.",1,new
"Regularization techniques, such as dropout (Srivastava et al., 2014), have been demonstrated to prevent overfitting in deep neural networks.",1,new
"The use of ensemble methods (Breiman, 2001) has been shown to significantly reduce overfitting in machine learning models.",1,new
"Regularization techniques, including L1 and L2 regularization (Tibshirani, 1996), have been shown to be effective in reducing overfitting in linear regression models.",1,new
"Recent advancements in named entity recognition (NER) have achieved impressive results, with current accuracy rates exceeding 95% for biomedical literature (Ratinov & Roth, 2009; Finkel et al., 2005).",1,new
"Significant progress has been made in machine learning approaches to sentiment analysis, with current models boasting an accuracy rate of over 90% for product reviews (Pang & Lee, 2008; Liu et al., 2005).",1,new
"The performance of deep learning-based models for topic modeling has surpassed expectations, with recent studies reporting accuracy rates of over 98% for news articles (Blei et al., 2003; Mikolov et al., 2010).",1,new
"Our model employs a combination of backpropagation and gradient descent to optimize the parameters  of the neural network, drawing inspiration from the work of Rumelhart et al. (1986), who pioneered the use of backpropagation in neural networks for solving complex problems in machine learning.",1,new
"The implementation of the decision tree algorithm in our model is based on the ID3 algorithm (Quinlan, 1986), which has been shown to be effective in handling missing values and noisy data, as demonstrated by Quinlan (1993) in his work on decision trees for machine learning.",1,new
"The use of the k-nearest neighbors (k-NN) algorithm in our model is motivated by the work of Cover and Hart (1967), who first introduced the k-NN algorithm as a method for pattern classification, and its subsequent improvements by Dasarathy (1991), which have led to its widespread adoption in various machine learning applications.",1,new
"The Long Short-Term Memory (LSTM) network (Hochreiter & Schmidhuber, 1997a), which has been effectively utilized in various sequence-to-sequence learning tasks (Sutskever et al., 2014; Hochreiter & Schmidhuber, 1997a), was employed for training rerank281 LSTM GEOQUERY P R F P R F SCISSOR 91.1 75.1 81.9 99.2 75.8 86.3 SCISSOR+ 88.5 79.5 83.9 96.1 78.1 86.7 Table 3: The performance of the baseline model SCISSOR+ compared with SCISSOR (with the best result in bold), where P = precision, R = recall, and F = F-measure.",1,new
"The stochastic gradient descent (SGD) algorithm (Bottou, 1998), which has been widely applied to various optimization tasks (Robbins & Monro, 1951; Bottou, 1998), was utilized for training rerank272 SGD GEOQUERY P R F P R F SCISSOR 90.8 76.3 82.5 98.8 76.5 85.1 SCISSOR+ 89.2 78.2 83.5 95.9 78.5 86.1 Table 4: The performance of the baseline model SCISSOR+ compared with SCISSOR (with the best result in bold), where P = precision, R = recall, and F = F-measure.",1,new
"The convolutional neural network (CNN) model (LeCun et al., 1998), which has been successfully applied to multiple computer vision tasks (Krizhevsky et al., 2012; LeCun et al., 1998), was employed for training rerank281 CNN GEOQUERY P R F P R F SCISSOR 92.5 77.9 84.1 99.5 78.3 86.7 SCISSOR+ 90.1 80.1 84.9 97.2 79.1 86.9 Table 5: The performance of the baseline model SCISSOR+ compared with SCISSOR (with the best result in bold), where P = precision, R = recall, and F = F-measure.",1,new
"2.2 The use of the Support Vector Machine (SVM) algorithm (Joachims, 1999) has been widely adopted in various classification tasks (Joachims, 1999; Joachims, 2002), and in this study, we utilized it to improve the accuracy of our sentiment analysis model.",1,new
"1.5 The Long Short-Term Memory (LSTM) network architecture (Hochreiter & Schmidhuber, 1997) has been successfully applied to numerous sequence modeling tasks (Hochreiter & Schmidhuber, 1997; Gers et al., 2000), and in this research, we incorporated it into our neural machine translation system.",1,new
"3.1 The Conditional Random Field (CRF) model (Lafferty et al., 2001) has been effectively employed in several labeling tasks (Lafferty et al., 2001; Sutton & McCallum, 2012), and in this paper, we leveraged it to enhance the performance of our named entity recognition system.",1,new
"The incorporation of gradient descent optimization algorithms (Ruder, 2017) significantly enhanced the convergence rate of our model.",1,new
"The implementation of early stopping (Prechelt, 1998) led to a substantial reduction in overfitting, resulting in improved model accuracy.",1,new
"Utilizing transfer learning from a pre-trained language model (Howard & Ruder, 2018) enabled our approach to achieve state-of-the-art results in the domain.",1,new
"Our research has employed the use of Decision Trees (Breiman, 2001; Quinlan, 1993) and Naive Bayes (John and Langley, 1995) to enhance classification accuracy.",1,new
"The implementation of Support Vector Machines (Cortes and Vapnik, 1995; Mangasarian, 1999) and k-Nearest Neighbors (Cover and Hart, 1967) has significantly improved the efficiency of our model.",1,new
"We have also utilized the Random Forest algorithm (Ho, 1998; Breiman, 2001) and the Expectation-Maximization algorithm (Dempster et al., 1977) to boost the performance of our predictive model.",1,new
"Our analysis employed the decision tree algorithm of Breiman (2001), a method that has been widely recognized for its ability to handle complex interactions (Hastie et al. 2009).",1,new
"The results of our study utilized the k-nearest neighbors algorithm of Cover and Hart (1967), a technique that has been found to be highly effective in high-dimensional spaces (Duda et al. 2001).",1,new
"We incorporated the stochastic gradient descent method of Robbins and Monro (1951) into our model, a technique that has been shown to be efficient in optimizing non-linear functions (Bottou 1998).",1,new
"The use of decision trees and their ensemble variants, such as boosting or bagging, has gained significant attention in recent years due to their efficiency in handling complex data and ease of interpretation (e.g., Breiman 2001).",1,new
"The support vector machine algorithm has also seen a rise in popularity due to its ability to handle high-dimensional data and its robustness to overfitting, making it a preferred choice for many researchers (e.g., Cortes and Vapnik 1995).",1,new
"Moreover, the random forest algorithm and its variants, e.g., the gradient boosting machine, have become increasingly popular due to their high accuracy and scalability, making them a popular choice for many real-world applications (e.g., Ho 1998).",1,new
"2.2 The proposed support vector machine algorithm (Cortes & Vapnik, 1995) was introduced to improve the generalizability of the model by reducing the impact of noise in the training data.",1,new
"2.3 The radial basis function network (Bishop, 1995) was developed to overcome the limitations of traditional neural networks by providing a more robust representation of the input data.",1,new
"2.4 The use of ensemble learning (Breiman, 2001) has been widely adopted in machine learning to enhance the accuracy of predictions by combining the strengths of multiple models.",1,new
"The purpose of our analysis is to compare our novel ensemble learning method with a widely-used gradient boosting algorithm (Friedman, 2001).",1,new
"Our evaluation aims to highlight the advantages of our proposed neural network architecture over a traditional decision tree model (Quinlan, 1993).",1,new
"To assess the effectiveness of our new clustering technique, we contrast it with a well-established hierarchical clustering algorithm (Ward, 1963).",1,new
"We employ the stochastic gradient descent algorithm (Bottou, 1998) due to its efficiency and speed, which is significantly higher than that of the backpropagation through time method.",1,new
"Our implementation utilizes the k-means clustering algorithm (MacQueen, 1967) as it offers a more straightforward and efficient approach to data partitioning compared to hierarchical clustering techniques.",1,new
"We leverage the random forest algorithm (Breiman, 2001) in this study, as it has been shown to outperform other ensemble methods, such as AdaBoost, in terms of accuracy and computational complexity.",1,new
"The use of ensemble methods has been demonstrated to lead to more accurate predictions and improved model generalizability (Baker et al., 2015).",1,new
"This technique has been shown to significantly enhance the robustness of the model and reduce the impact of noise in the data (Kim & Lee, 2018).",1,new
"The incorporation of regularization techniques has been found to produce more reliable results and mitigate overfitting in machine learning models (Taylor, 2019).",1,new
"Our study built upon existing research (Kim et al., 2010; Lee, 2012) by employing a novel combination of machine learning algorithms (Bishop, 2006; Vapnik, 1998) to optimize the feature extraction process. This allowed us to leverage the strengths of both generative and discriminative models, resulting in improved accuracy and efficiency.",1,new
"To ensure the validity of our results, we adopted the same data partitioning strategy as previous studies (Rogers et al., 2009; Sutskever et al., 2009) and utilized the annotated datasets provided by the Penn Treebank (Marcus et al., 1993). The parser was trained using the logistic regression algorithm (Hastie et al., 2009), which offered a good balance between model complexity and computational resources.",1,new
"We drew inspiration from the work of earlier researchers (Brown et al., 1990; Jelinek, 1997) and implemented a hybrid approach that integrated rule-based and statistical methods (Katz, 1987; Manning and Schtze, 1999) to enhance the overall performance of the parser. The use of this multi-faceted approach enabled us to achieve significant improvements in parsing accuracy and speed.",1,new
"Our study utilizes the Support Vector Machine (SVM) algorithm (Burges, 1998), which offers competitive results to CRFs but boasts significantly faster computation times, making it a prime candidate for our model.",1,new
"Another notable method we draw inspiration from is the Hidden Markov Model (HMM) (Rabiner, 1989), which demonstrates comparable accuracy to CRFs while providing a more efficient training process, allowing us to build upon its strengths.",1,new
"We also leverage the Naive Bayes algorithm (John & Langley, 1995), which, although not as complex as CRFs, achieves satisfactory results and can be trained at a much faster rate, making it an ideal choice for our research framework.",1,new
"The Hidden Markov Model The Hidden Markov Model, first introduced by Baum and Petrie (1966), has been a cornerstone in speech recognition systems, providing robustness and accuracy in language processing.",1,new
"The Naive Bayes Classifier The Naive Bayes Classifier, proposed by Johnstone (1990), has been widely adopted in text classification tasks, demonstrating its simplicity and efficiency in machine learning applications.",1,new
"The Viterbi Algorithm The Viterbi Algorithm, developed by Viterbi (1967), has revolutionized the field of dynamic programming, enabling fast and accurate sequence alignment in bioinformatics and natural language processing.",1,new
"To mitigate the issue of overfitting on the training set, we employ the regularization technique described by Tikhonov (1963) in the optimization process outlined in Algorithm 2.",1,new
"The application of data augmentation techniques, as proposed by Simard et al. (1992), is used to reduce overfitting and improve the robustness of the model presented in Algorithm 3.",1,new
"To combat overfitting on the training examples, we utilize the early stopping criterion, as introduced by Prechelt (1998), during the training of the neural network described in Algorithm 4.",1,new
"The decision tree model (Breiman, 2001) is chosen for its ease of interpretation and ability to handle non-linear relationships, making it a suitable choice for our analysis.",1,new
"The use of the support vector machine (SVM) algorithm (Cortes & Vapnik, 1995) is preferred due to its robustness and capacity to handle high-dimensional data, ensuring accurate classification results.",1,new
"We opt for the k-nearest neighbors (k-NN) algorithm (Cover & Hart, 1967) for its simplicity and ability to adapt to complex data distributions, making it an ideal choice for our clustering task.",1,new
"The incorporation of early stopping criteria (Kearns, 1992) is essential to prevent overtraining and enhance model robustness.",1,new
"Our approach employs the use of regularization techniques (Tikhonov, 1943) to mitigate overfitting and improve model generalizability.",1,new
"The utilization of ensembling methods (Breiman, 2001) allows us to combine multiple models and achieve superior performance and stability.",1,new
"The dataset used in this study, which is a collection of labeled examples compiled by Brown et al. (1992), demonstrates the efficacy of the proposed machine learning approach.",1,new
"The implementation of the decision tree algorithm on the Reuters data, as suggested by Breiman et al. (1984), produces a satisfactory model for predicting stock prices.",1,new
"The utilization of the Naive Bayes classifier on the 20 Newsgroups dataset, as described by Lewis (1998), yields a reliable model for text categorization.",1,new
"The adaptation of the radial basis function (Bishop, 1996) and the use of early stopping (Prechelt, 1998) both contribute to mitigating over-fitting in neural networks.",1,new
"The implementation of regularization techniques, such as L1 and L2 norm (Tibshirani, 1996), has proven effective in preventing over-training in linear regression models.",1,new
"The incorporation of ensemble methods, including bagging (Breiman, 1996) and boosting (Freund and Schapire, 1999), helps to reduce over-specialization in machine learning algorithms.",1,new
"The integration of the decision tree algorithm with the genetic algorithm is reminiscent of the approach employed by Goldberg (1989). The decision tree algorithm is a viable option due to its ability to efficiently prune the search space, typically requiring only a handful of iterations to converge (Breiman et al., 1984; Quinlan, 1979).",1,new
"The application of the k-means clustering algorithm in conjunction with the expectation-maximization algorithm bears some similarity to the methodology proposed by MacQueen (1967). This combination is advantageous because it allows for robust and efficient cluster identification, often achieving accurate results within a limited number of iterations (Hartigan, 1975; Lloyd, 1957).",1,new
"The utilization of the hidden Markov model in conjunction with the Viterbi algorithm is analogous to the approach described by Rabiner (1989). This pairing is beneficial because it enables accurate sequence prediction and decoding, usually requiring only a few passes over the training data (Baum and Eagon, 1967; Levinson, 1980).",1,new
"The recent advancements in deep learning have greatly improved the accuracy of speech recognition systems, surpassing the limitations of traditional Hidden Markov Models (Dahl et al., 2012; Hinton et al., 2012; Graves et al., 2013).",1,new
"The introduction of ensemble methods has significantly mitigated the overfitting issue in machine learning models, outperforming the traditional approach of individual models (Bauer and Kohavi, 1999; Freund and Schapire, 1997; Zhou et al., 2002).",1,new
"The emergence of graph-based models has provided a more effective solution for community detection in social networks, addressing the limitations of traditional centrality measures (Newman, 2004; Clauset et al., 2004; Fortunato, 2010).",1,new
"Lee et al. (2018) proposed the use of gradient clipping, which has been found to significantly improve the stability of deep learning models and enhance their overall performance.",1,new
"According to Rodriguez (2015), the incorporation of early stopping in neural networks leads to a substantial reduction in overtraining and improved generalization capabilities.",1,new
"In their seminal work, Zhang et al. (2020) demonstrated that the application of dropout regularization can effectively prevent overfitting and yield better results in various machine learning tasks.",1,new
We opted for the support vector machine due to its demonstrated efficiency in image classification tasks; previous studies by Vapnik (1995) have highlighted its superior performance compared to other machine learning algorithms.,1,new
The decision tree classifier was selected for this study due to its ability to handle high-dimensional data effectively; research by Breiman (2001) has consistently shown its advantages in classification tasks over other decision-making models.,1,new
"We employed the hidden Markov model for sequence prediction because of its proven success in speech recognition tasks; as observed by Rabiner (1989), it outperformed other statistical models in terms of accuracy and speed.",1,new
"The number of iterations is fixed at 1000, after which the learning rate is reduced by half to prevent overfitting (Rennie et al., 2003).",1,new
"Once convergence is reached on the validation set, the model parameters are frozen to prevent further overfitting and to ensure that the generalization performance is not compromised (Brown et al., 1992).",1,new
"The training process stops when the accuracy on the validation set stabilizes, indicating that the model has achieved optimal performance and further training would lead to overfitting (Golub & Van Loan, 1989).",1,new
"The application of techniques such as support vector machines (e.g., Joachims (1999), Vapnik (2000)) and decision trees (e.g., Quinlan (1993), Breiman (2001)) have also demonstrated significant improvements in various NLP tasks, thereby setting a new standard in the field.",1,new
"Recent studies utilizing ensemble methods (e.g., Freund and Schapire (1997), Breiman (2001)) and probabilistic models (e.g., Koller and Friedman (2009), Murphy (2012)) have achieved impressive results in NLP, showcasing their potential as a powerful tool for advancing the discipline.",1,new
"The incorporation of latent semantic analysis (LSA) (e.g., Landauer and Dumais (1997), Deerwester et al. (1990)) and long short-term memory (LSTM) networks (e.g., Hochreiter and Schmidhuber (1997), Gers et al. (1999)) into NLP has led to substantial breakthroughs, providing a robust foundation for further research and development in the field.",1,new
"We utilize six natural language processing datasets, including the seminal IMDB dataset (Maas et al., 2011) and five datasets containing text from various social media platforms, such as Twitter (TWI), Reddit (RED), Quora (QRO), LinkedIn (LIN), and YouTube (YTB) (Baldwin & Kim, 2010).",1,new
"The present study employs eight text classification datasets, including the popular 20 Newsgroups dataset (Lang, 1995) and seven datasets containing reviews of various products from the Yelp platform (YEL1, YEL2, YEL3, YEL4, YEL5, YEL6, YEL7) (Joachims, 1998).",1,new
"Our research utilizes nine sentiment analysis datasets, including the widely-used SST dataset (Socher et al., 2013) and eight datasets containing text from different types of online forums, such as Health-Insurance (HIS), Beauty-Products (BEA), and Travel-Reviews (TRA) (Turney, 2002).",1,new
"Unsupervised learning algorithms such as Latent Dirichlet Allocation (LDA) have been effectively utilized in topic modeling and proven to be highly effective (Blei et al., 2003; Griffiths and Steyvers, 2004; Steyvers and Griffiths, 2007).",1,new
"Neural networks have been widely adopted in natural language processing tasks, demonstrating remarkable performance in text classification and yielding impressive results (Hinton et al., 2006; Bengio et al., 2003; Collobert et al., 2011).",1,new
"Rule-based approaches including Part-of-Speech Tagging (POS) have been employed in sentiment analysis, exhibiting robustness and reliability in various applications (Brill, 1995; Marcus et al., 1993; Veenstra, 2004).",1,new
"The Random Forest algorithm has been demonstrated to be effective for regression tasks (Breiman, 2001), and has shown impressive results in predicting continuous values (Merkle and Shaffer, 2007; Genuer et al., 2010; Crimmins, 2004).",1,new
"Neural networks have been shown to be highly successful in image classification tasks (LeCun et al., 1998), and have previously achieved remarkable performance in object detection experiments (Sermanet et al., 2014; Girshick et al., 2014; Krizhevsky et al., 2012).",1,new
"Clustering algorithms, such as K-Means, have been found to be useful for data mining tasks (MacQueen, 1967), and have demonstrated good performance in identifying patterns in large datasets (Hartigan and Wong, 1979; Kaufman and Rousseeuw, 1990; Jain, 2010).",1,new
"Previous studies have demonstrated that the use of word embeddings, particularly Word2Vec models (Mikolov et al., 2013), has led to significant improvements in text classification tasks, including sentiment analysis, by capturing nuanced word relationships and semantics.",1,new
"The application of n-gram features in machine learning models has been widely explored (Church and Hanks, 1990; Manning and Schtze, 1999), yielding positive results in various NLP tasks, including sentiment analysis and text categorization.",1,new
"The incorporation of TF-IDF weighting techniques into machine learning models has been shown to enhance performance in information retrieval and text classification tasks (Salton and McGill, 1983; Robertson and Sparck Jones, 1976), including the accurate identification of sentiment in text data.",1,new
"Our research utilized a well-structured and diverse dataset, which we sourced from the seminal work of Brun et al. (2015) and further expanded upon by (Krizhevsky et al., 2012). The dataset comprised 500 images with corresponding labels, featuring a wide range of objects and scenes, making it an ideal choice for object detection tasks.",1,new
"We opted for a dataset that would provide a robust testing ground for our algorithm, which is why we chose to utilize the benchmark dataset established by (Sutskever et al., 2014) and later refined by (Goodfellow et al., 2014). This dataset consisted of 2000 images, each with a unique set of features and annotations, allowing for comprehensive evaluation of our approach.",1,new
"For the purposes of our study, we employed a dataset that would be both challenging and informative, drawing from the work of (Rosenblatt, 1958) and building upon the findings of (Bishop, 1995). The resulting dataset comprised 1500 examples, each with a complex set of patterns and relationships, making it an excellent choice for testing our machine learning model's capabilities.",1,new
"The current state-of-the-art techniques for sentiment analysis can be broadly categorized into three approaches, namely, rule-based approach (Kushman and Manning, 1999), corpus-based approach (Hu and Liu, 2004), and deep learning approach (Socher et al., 2011), among which the latter has gained significant traction in recent years.",1,new
"The existing research on natural language processing can be divided into three primary paradigms, namely, symbolic approach (Lehnert, 1992), connectionist approach (Rumelhart et al., 1986), and hybrid approach (Jones et al., 2006), with the latter being increasingly popular due to its ability to leverage the strengths of both paradigms.",1,new
"The major methodologies employed in text classification can be classified into three main categories, namely, traditional machine learning approach (Domingos and Pazzani, 1997), knowledge-based approach (Resnik, 1999), and ensemble approach (Breiman, 2001), with the ensemble approach being widely adopted due to its improved performance and robustness.",1,new
"The ImageNet dataset is a widely used benchmark for image classification tasks (Deng et al., 2009).",1,new
"The IMDB dataset is a well-established resource for sentiment analysis research, particularly in the realm of movie reviews (Maas et al., 2011).",1,new
"The Reuters Corpus is a valuable dataset for text classification and sentiment analysis, often employed in natural language processing studies (Lewis et al., 2004).",1,new
"The application of decision trees in (Quinlan, 1986) marked a crucial milestone in the development of rule-based classification methods, paving the way for more sophisticated machine learning techniques.",1,new
"The introduction of neural networks in (LeCun et al., 1998) not only improved the accuracy of image recognition tasks but also fueled further research in deep learning methodologies.",1,new
"The pioneering work of (Mitchell, 1997) in machine learning theory laid the foundation for the development of more advanced algorithms, including those employed in natural language processing applications.",1,new
"The groundbreaking research of (Lee et al., 2015) revealed that ensemble methods consistently yielded superior results over the traditional approach of relying on single feature extraction techniques in sentiment analysis.",1,new
"In a pivotal study, (Kim et al., 2010) showed that the incorporation of semantic role labeling significantly enhanced the accuracy of sentiment classification, outperforming the conventional bag-of-words method.",1,new
"A notable contribution of (Wang et al., 2018) was the development of a novel framework that effectively combined rule-based and machine learning approaches, leading to substantial improvements in sentiment classification tasks compared to standalone rule-based systems.",1,new
"Previous studies have shown that rule-based approaches to sentiment analysis have yielded disappointing results (Hatzivassiloglou & McKeown, 1997), while machine learning algorithms have consistently outperformed these methods (Turney, 2002).",1,new
"Despite the limitations of early work in sentiment analysis, recent advances in deep learning have led to significant improvements in accuracy (Socher et al., 2013), surpassing the capabilities of traditional machine learning models (Kumar & Ravi, 2010).",1,new
"Research has demonstrated that hybrid approaches combining rule-based and machine learning techniques have shown promise (Kim & Hovy, 2004), although these methods often struggle to match the performance of dedicated machine learning models (Cohn & Blitzer, 2005).",1,new
"The proposed method is evaluated on six image classification datasets, including the well-known CIFAR-10 dataset (Krizhevsky et al., 2009) and five datasets that contain images of various objects from the Caltech-101 dataset (Fei-Fei et al., 2007).",1,new
"To assess the performance of our approach, we conduct experiments on four text classification datasets, including the widely-used 20 Newsgroups dataset (Lang, 1995) and three datasets that contain articles from the Reuters Corpus (Lewis et al., 2004).",1,new
"For evaluation purposes, we utilize eight object detection datasets, including the challenging PASCAL VOC dataset (Everingham et al., 2010) and seven datasets that contain images of various objects from the ImageNet dataset (Deng et al., 2009).",1,new
"Our research utilizes the BLEU (Papineni et al., 2002) score to assess the fluency and grammatical correctness of our machine-generated text, which has been consistently shown to align with human evaluations.",1,new
"The BERTScore (Zhang et al., 2020) is employed to evaluate the similarity between our generated text and human-written text, and it has been found to be highly correlated with human ratings in previous studies.",1,new
"In order to validate the coherence of our summaries, we rely on the METEOR (Banerjee et al., 2005) metric, which has been widely used and accepted as a reliable measure for evaluating the semantic similarity between machine-generated and human-written text.",1,new
"Our experiments also utilized the METEOR (Banerjee & Lavie, 2005) metric for automatic evaluation of our text simplification outputs, which has been widely used in the SMT evaluation community.",1,new
"The evaluation of our machine translation systems employed the BLEU (Papineni et al., 2002) score, a popular metric that has been extensively used for evaluating machine translation systems in various research studies.",1,new
"We evaluated the effectiveness of our question answering system using the F1-score (Hosseinian-Far et al., 2016) metric, which is a widely accepted measure for evaluating the performance of question answering systems in various applications.",1,new
"We opt to utilize the widely accepted BLEU score (Papineni et al., 2002) for our evaluation metrics.",1,new
"In our analysis, we leverage the well-established METEOR metric (Banerjee & Lavie, 2005) for assessing machine translation quality.",1,new
"For this study, we rely on the popular TERp score (Snover et al., 2006) to evaluate the similarity between translations.",1,new
"The BERTScore model (Zhang et al., 2020) was utilized for evaluation. Specifically, we concentrated on BERTScore-1 in the analysis, as it has been demonstrated to exhibit a high correlation with human judgment (Zhang et al., 2020; Miller, 2019).",1,new
"The METEOR metric (Banerjee et al., 2005) was employed for assessment. Notably, we focused on METEOR-1 in the discussion, due to its established strong correlation with human evaluation (Banerjee et al., 2005; Lavie and Denkowski, 2004).",1,new
"BLEU+ metrics (Papineni et al., 2002) were used for evaluation. Notably, we highlighted BLEU+1 in our analysis, as it has been shown to have a high correlation with human assessment (Papineni et al., 2002; Koehn, 2004).",1,new
BLEU score has also been utilized in machine translation evaluation and demonstrated highly effective results (Papineni et al. 2002).,1,new
"METEOR, SARI, and CIDEr have been successfully employed in evaluating summarization tasks and shown outstanding performance (Banerjee and Lavie 2005).",1,new
"TER, F1, and NIST have been applied in automatic evaluation of machine translation and yielded very impressive results (Snover et al. 2006).",1,new
"The widely accepted metric BLEU was chosen for automatic evaluation due to its strong correlation with human judgments (Papineni et al., 2002; Snover et al., 2006).",1,new
"The commonly used tool METEOR was selected for evaluation purposes because it has been shown to have a high correlation with human ratings (Banerjee and Lavie, 2005; Lavie and Denoual, 2005).",1,new
"The popular evaluation metric NIST was adopted for automatic assessment because it was demonstrated to have a strong correlation with human scores (Doddington, 2002; Doddington et al., 2004).",1,new
"Our results were assessed using METEOR (Banerjee and Lavie, 2005) metrics, a widely recognized measure for evaluating the quality of machine translation.",1,new
"We evaluated the performance of our model using BLEU (Papineni et al., 2002) scores, a popular metric for assessing the fluency and accuracy of machine translation systems.",1,new
"The validity of our findings was confirmed by using F1-score (Joulin et al., 2016) as a metric for evaluating the accuracy of named entity recognition in our proposed approach.",1,new
"Our results demonstrate that METEOR, METEOR-4, and BLEU-4 show strong correlations with human assessments of machine translation quality, as reported in the literature (Banerjee and Lavie, 2005).",1,new
"The evaluation metrics of BLEU, NIST, and METEOR have been found to be effective indicators of the quality of machine translation systems, aligning with the findings of previous research (Papineni et al., 2002).",1,new
"We observe a high correlation between the automatic metrics of ROUGE-2, ROUGE-L, and ROUGE-SU4 with human evaluations of summary quality, consistent with the results of earlier studies (Recasens et al., 2013).",1,new
"The LSA (Latent Semantic Analysis) model (Deerwester et al., 1990) has been a cornerstone in the field of text analysis.",1,new
"The BLEU (Bilingual Evaluation Understudy) metric (Papineni et al., 2002) has been extensively employed for machine translation evaluation.",1,new
"The METEOR (Metric for Evaluation of Translation with Explicit ORdering) score (Banerjee & Lavie, 2005) has been widely adopted in the evaluation of machine translation systems.",1,new
"The results of several studies have consistently demonstrated that BLEU scores exhibit a strong correlation with human assessment in machine translation (Papineni et al., 2002).",1,new
"A recent analysis has revealed that the METEOR metric is closely associated with human judgment in evaluating the quality of machine translation (Banerjee and Lavie, 2005).",1,new
"Research has shown that the TER score is highly correlated with human evaluation in assessing the fluency of machine translation (Snover et al., 2006).",1,new
"The BLEU (Papineni et al., 2002) score has been demonstrated to effectively measure the similarity between machine-generated and human-written texts in various tasks.",1,new
"The METEOR (Banerjee and Lavie, 2005) metric has been found to provide a robust evaluation of the fluency and grammatical correctness of machine translation outputs.",1,new
"The CIDEr (Vedantam et al., 2015) score has been shown to highly correlate with human judgments of image captioning quality, making it a reliable evaluation metric for this task.",1,new
"The development of the METEOR metric (Banerjee and Lavie, 2005; Lavie and Denoual, 2005) is another notable achievement of the WMT, allowing for more accurate evaluation of machine translation systems and facilitating the comparison of different approaches.",1,new
"The Bilingual Evaluation Understudy (BLEU) metric (Papineni et al., 2002) owes its creation to the efforts of the WMT, enabling researchers to quantify the performance of machine translation systems and identify areas for improvement.",1,new
"The establishment of the WMT evaluation metrics such as TER (Snover et al., 2006) has greatly facilitated the evaluation of machine translation systems, providing a standardized framework for comparison and improvement of translation quality.",1,new
"The Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) methods have gained significant attention in text summarization, as they provide an effective means of capturing the semantic relationships within documents (Landauer and Dumais, 1997; Blei et al., 2003).",1,new
"The TextRank algorithm and Latent Semantic Analysis (LSA) have been widely employed in text summarization, as they offer a robust approach to identifying key phrases and sentence extraction (Mihalcea and Tarau, 2004; Deerwester et al., 1990).",1,new
"The use of sentence clustering and Latent Semantic Analysis (LSA) has been increasingly adopted in text summarization, as it enables the identification of coherent topics and key sentences (Gao et al., 2004; Deerwester et al., 1990).",1,new
"The integration of multimodal data in NLP models has been largely unexplored (notable exceptions include works by Collobert and Weston (2008)), and further research is needed to unlock its full potential, yet the initial findings demonstrate a promising direction for improved performance.",1,new
"A comprehensive analysis of the effects of word order on sentence interpretation has been lacking (a notable study in this area is that of Gibson and Pearlmutter (1994)), and additional investigation is required to elucidate its impact, but preliminary results indicate a significant contribution to the field.",1,new
"The application of reinforcement learning in sequence-to-sequence tasks has received limited attention (a notable exception is the work of Sutskever et al. (2014)), and further research is necessary to fully harness its capabilities, although initial results suggest a substantial improvement in task completion rates.",1,new
"Other notable metrics include BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), and CIDEr (Vedantam et al., 2015), among others.",1,new
"Well-known evaluation metrics include PER (Chen and Cherry, 2008), Mover's score (Denkowski and Lavie, 2011), and the Bilingual Evaluation Understudy (BLEU) metric (Papineni et al., 2002).",1,new
"In addition to these, several other evaluation metrics have been proposed, such as TER (Snover et al., 2006), CIDEr (Vedantam et al., 2015), and the F-score (Chakrabarty et al., 2018).",1,new
The study by Lavie and Banerjee (2005) found that METEOR's emphasis on recall over precision leads to improved alignment with human evaluation scores.,1,new
"According to Banerjee and Lavie (2005), the METEOR metric's bias towards recall results in a more accurate correlation with human judgment.",1,new
The research by Banerjee and Lavie (2005) suggests that METEOR's higher recall-oriented weighting contributes to its superior performance in matching human evaluation criteria.,1,new
"The analysis reveals that our proposed metric outperforms several existing metrics, including Word Sense Induction (Agirre et al., 2014), Intrinsic Evaluation (Doddington, 2002), and F1-score (Papineni et al., 2002), in terms of evaluation accuracy.",1,new
"Compared to traditional metrics, our proposed framework demonstrates superior performance in evaluation tasks, as evidenced by its higher correlation with other metrics such as Discourse Evaluation (Marcu and Echihabi, 2002), BLEU+ (Chen et al., 2014), and ROUGE (Lin, 2004).",1,new
"In contrast to previous metrics, our research indicates that the proposed metric yields higher correlation with other evaluation metrics, such as Precision (Chen and Lee, 2010), Recall (Zhang et al., 2011), and F1-score (Liu et al., 2013), in the context of machine translation evaluation.",1,new
"In a comprehensive analysis of 20,000 English-Spanish sentence pairs from the Europarl parallel corpus with human evaluation from the European Commission, we evaluate the performance of the syntax-based scoring model against other widely used metrics such as ROUGE (Lin, 2004), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006), and demonstrate that incorporating semantic role labeling yields a more reliable evaluation that aligns closely with human assessment.",1,new
"We compare the efficacy of our novel machine learning approach with established metrics like BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and LASER (Conneau et al., 2018) in a study involving 15,000 French-English sentence pairs from the WMT17 dataset, annotated with human ratings from the WMT18 evaluation campaign, and find that our method outperforms the baseline in terms of correlation with human judgments.",1,new
"In a large-scale evaluation of 30,000 German-English sentence pairs from the WMT14 dataset, with human evaluation from the WMT15 evaluation campaign, we examine the effectiveness of the neural network-based evaluation metric against other popular metrics such as BLEU (Papineni et al., 2002), TER (Snover et al., 2006), and chrF (Popovi, 2015), and show that our approach yields a more accurate evaluation that closely mirrors human assessment.",1,new
"While these findings are based on a limited number of subjects, and we have not conducted any experiments to assess the statistical significance of the differences in  translation quality, the results are still noteworthy, as four metrics exhibit higher correlation than Bleu:??Sentence similarity (Lin, 1998), which makes its appearance in this study??TER (Snover et al., 2006), which incorporates a model of acceptable variation in translation that utilizes automatically generated paraphrases (Cohn and Lapata, 2008)??NIST (Papineni et al., 2002) which also allows for variation by introducing synonyms and by adaptively matching words using lemmatization.",1,new
"Although these results are derived from a relatively small dataset, and we have not performed any statistical analysis to determine whether the variations in  sentence length are statistically significant, the outcomes are intriguing, as five metrics show higher correlation than BLEU:??Perplexity (Kumar et al., 2010), which makes its first appearance in this conference??WER (Cram et al., 2007), which includes a model of permissible variation in translation that leverages automatically generated paraphrases (Huang et al., 2006)??Meteor-UNED (Agirre et al., 2009) which also allows for variation by introducing synonyms and by flexibly matching words using stemming.",1,new
"While these results are based on a small number of instances, and we have not conducted any tests to evaluate the statistical significance of the differences in  grammatical error rates, the outcomes are still interesting, as three metrics have higher correlation than METEOR:??F1-score (Mckeown et al., 2005), which makes its debut in this workshop??BLEU+ (Koehn, 2004), which incorporates a model of acceptable variation in translation that uses automatically generated paraphrases (Costa-juss et al., 2007)??TERp (Snover et al., 2008) which also allows for variation by introducing synonyms and by adaptively matching words using lemmatization.",1,new
"The field of named entity recognition (NER) has experienced significant advancements in recent years, as evident in the outstanding results of the CoNLL Shared Tasks (Tjong Kim Sang and De Meulder, 2003), (Ratinov and Roth, 2009), (Chiu et al., 2016).",1,new
"The development of machine translation has shown remarkable growth, particularly in the context of the WMT Shared Tasks (Koehn, 2005), (Och and Ney, 2003), (Nakazawa et al., 2010).",1,new
"The area of sentiment analysis has witnessed substantial progress, as reflected in the improvements achieved by the Sentic Net (Cambria et al., 2012), (Balahur et al., 2010), (Kiritchenko et al., 2014).",1,new
A notable mention is the research conducted by Smith and Johnson (2018).,1,new
Noteworthy contributions have been made by Lee and Kim (2003) in the field of artificial intelligence.,1,new
"Of particular interest is the study by Patel and Brown (2012), which has significantly advanced our understanding of machine learning algorithms.",1,new
"The proposed methodology, as demonstrated in the work of (Jiang et al., 2011; Jiang et al., 2012; Jiang, 2013), has shown promising results in both named entity recognition and language modeling tasks.",1,new
"Our approach, as discussed in (Lin et al., 2009; Lin et al., 2010; Lin, 2011), has been effective in addressing the challenges of text classification and sentiment analysis.",1,new
"The experimental results of (Lee et al., 2015; Lee et al., 2016; Lee, 2017) have consistently demonstrated the efficacy of our proposed algorithm in machine translation and language understanding tasks.",1,new
"The application of multi-task learning in computer vision has been shown to be effective for object detection and image classification (Krizhevsky et al., 2012; Sermanet et al., 2014).",1,new
"Recent studies have demonstrated the potential of ensemble methods for improving the accuracy of regression tasks in machine learning (Bauer & Kohavi, 1999; Freund et al., 1997).",1,new
"The use of transfer learning has been successfully applied to various natural language processing tasks, including text classification and language modeling (Donahue et al., 2014; Yosinski et al., 2014).",1,new
"We investigate the utility of Word Embedding techniques (Bengio et al., 2003) in enhancing the accuracy of Named Entity Recognition (NER), a widely employed task in NLP research.",1,new
"The performance of our proposed framework is evaluated in comparison to the state-of-the-art method of Active Learning (Cohn et al., 1994), which has been shown to significantly improve the efficiency of text classification tasks.",1,new
"We leverage the strengths of Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) to develop an innovative approach for topic modeling, building upon the foundation laid by previous work on Latent Dirichlet Allocation (Blei et al., 2003).",1,new
"Our study found that the use of Transfer Component Analysis (TCA) (Pan et al., 2011) has been shown to significantly improve the performance of multilingual models in various NLP tasks.",1,new
"The literature suggests that the technique of Multi-Task Learning (MTL) (Caruana, 1997) has emerged as a powerful approach to enhance the generalizability of deep neural networks in complex domains.",1,new
"Recent research has highlighted the effectiveness of the Domain-Adversarial Neural Network (DANN) (Ganin et al., 2016) in reducing the gap between source and target domains in transfer learning scenarios.",1,new
"Our previous research has demonstrated that the application of Graph-Based Methods to Text Classification has shown remarkable success in various NLP tasks (Li et al., 2015; Li et al., 2018).",1,new
"The use of Transfer Learning has been widely adopted in NLU tasks, yielding impressive results in tasks such as Question Answering and Language Modeling (Pan et al., 2016; Pan et al., 2019).",1,new
"So far, the integration of Active Learning with Deep Neural Networks has been successfully applied to various NLP applications, including Named Entity Recognition and Part-of-Speech Tagging (Settles, 2012; Settles, 2017).",1,new
"This technique has been extensively documented in the literature: it was first proposed by Liu et al (2002) and further developed by Kim et al (2010), and is comparable to other greedy algorithms for sequence alignment, so we will provide a brief overview.",1,new
"The methodology has been previously described by Johnson (1999) and Smith et al (2015), and is closely related to other statistical learning algorithms, thus we will focus on its key aspects.",1,new
"This approach has been well-established in the field: it was initially introduced by Patel et al (2008) and later refined by Lee et al (2012), and shares similarities with other machine learning techniques for data classification, so we will only provide a concise summary.",1,new
"The development of computational models for semantic role labeling has been extensively studied in various fields, particularly in natural language processing, where researchers have employed innovative linguistic theories and machine learning techniques to accurately represent and analyze predicate-argument structures (Palmer et al., 2005; Gildea and Palmer, 2006; Carreras et al., 2008; Pradhan et al., 2008; Gildea and Henderson, 2009; Hacioglu et al., 2009).",1,new
"To investigate the relationship between syntax and semantics, researchers have leveraged various machine learning algorithms and linguistic frameworks, such as dependency grammars and graph-based models, to capture the complex interactions between word order and meaning (Bod, 2009; Goldberg, 2010; McDonald et al., 2011; Tsarfaty et al., 2011; Dozat and Manning, 2017).",1,new
"In the realm of speech recognition, the design of robust acoustic models has been a significant area of research, with scientists employing sophisticated techniques, including deep learning architectures and statistical methods, to improve the accuracy of phoneme recognition and improve the overall performance of speech-to-text systems (Young et al., 2002; Hinton et al., 2012; Dahl et al., 2012; Graves et al., 2013; Sainath et al., 2015).",1,new
The results of this study are consistent with those reported by Johnson and Thompson (2012) for a related approach to machine learning.,1,new
"For a comprehensive overview of the underlying theory, we suggest referring to the work of Lee and Kim (2015).",1,new
The methodology employed in this research is similar to that described by Patel and Brown (2008) for the development of natural language processing systems.,1,new
"The proposed technique can be applied to real-time systems by utilizing an adaptive algorithm (Leutenegger and Lopez-Ortiz, 2000) for efficient resource allocation, thereby minimizing latency and improving overall system performance.",1,new
"To mitigate the effects of memory constraints, we suggest employing a novel data compression method (Storer and Szymanski, 1991) or an efficient indexing technique (Hinrichs, 1988) that reduces memory footprint without compromising query performance.",1,new
"When faced with limited resources, researchers can leverage a data sampling approach (Kohavi et al., 1997) in conjunction with a probabilistic data structure (Floyd and Rivest, 1975) to effectively manage memory usage and enhance the scalability of their models.",1,new
"The use of machine learning algorithms to identify sentiment polarity in text can be effectively addressed by employing techniques of dependency parsing (Katz and Kim, 2002).",1,new
"The challenge of extracting relevant information from unstructured data can be overcome by utilizing methods of named entity recognition in conjunction with shallow parsing (Grishman, 2003).",1,new
"The incorporation of statistical methods for part-of-speech tagging can significantly improve the accuracy of text classification tasks, as demonstrated by the work of Brill (1992).",1,new
"Clark and Thompson (Clark and Thompson, 2007) successfully implemented a novel approach to text segmentation using a combination of rule-based and machine learning techniques.",1,new
"Mann and Thompson (Mann and Thompson, 2012) effectively utilized a probabilistic framework to improve the accuracy of part-of-speech tagging in natural language processing tasks.",1,new
"Gimenez and Marquez (Gimenez and Marquez, 2008) successfully applied a hybrid approach that combined supervised and unsupervised learning methods to achieve state-of-the-art results in named entity recognition.",1,new
"The results of the study by Manning and Schutze (1999) demonstrate that the use of part-of-speech tagging significantly improves the accuracy of named entity recognition (Fz=95.5), outperforming the baseline models by a considerable margin.",1,new
"The experiments conducted by Jurafsky and Martin (2000) indicate that incorporating semantic role labeling enhances the performance of sentiment analysis (Fz=94.2), leading to a substantial improvement in the overall accuracy of the system.",1,new
"The findings of the research by Collins (1996) reveal that the application of treebank parsing yields superior results in phrase structure identification (Fz=91.8) compared to other parsing techniques, highlighting the potential of this approach in natural language processing.",1,new
"The results indicate a comparable performance in sentence parsing, with a slight edge over the (Krovetz and McKeown, 1995) study (Fz=1=92.2).",1,new
"Compared to the (Hindle, 1990) model, our system demonstrated a notable improvement in part-of-speech tagging (Fz=1=94.1).",1,new
"Notably, our approach outperformed the (Lesk, 1997) method in named entity recognition, achieving a higher accuracy rate (Fz=1=95.5).",1,new
"The MEAD (Maximum Entropy Discriminative) algorithm, first proposed by (McCallum, 1996), has been consistently proven to be an effective method for text classification tasks.",1,new
"The HMM (Hidden Markov Model) tagger, developed by (Rabiner, 1989), has demonstrated superior performance in part-of-speech tagging tasks compared to other models.",1,new
"The CRF (Conditional Random Field) model, introduced in (Lafferty et al., 2001), has shown excellent results in sequence labeling tasks due to its ability to capture complex dependencies between labels.",1,new
"This work (Lin and Wu, 2002) has significantly contributed to the field of natural language processing with the introduction of a novel parsing algorithm.",1,new
"The development of a new linguistic framework (Grosz and Sidner, 1986) has been hailed as a major breakthrough in the study of discourse analysis.",1,new
"The innovative use of machine learning techniques (Bishop, 1995) has led to a ""substantial"" improvement in the accuracy of part-of-speech tagging models.",1,new
"The seminal study by Collins and Quinlan (1998) presented a significant advance in decision tree learning, proposing novel methods for attribute selection and pruning.",1,new
"The groundbreaking research of Sutskever, Vinyals, and Wouters (2011) introduced a new approach to sequence-to-sequence learning, utilizing beam search and convolutional neural networks.",1,new
"The innovative work of Manning and Schtze (1999) made a substantial contribution to natural language processing, introducing a probabilistic framework for part-of-speech tagging and named entity recognition.",1,new
"The most commonly used tag set is the IOBES scheme (Bies et al., 1995), where B denotes the beginning of a named entity, I denotes an entity in the middle, O denotes an entity that is not the beginning or middle, E denotes the end of an entity, and S denotes a single word that is an entity.",1,new
"The Penn Treebank tag set (Marcus et al., 1993) is widely adopted for part-of-speech tagging, where U denotes an unknown word, X denotes punctuation, and. denotes a period.",1,new
"The HMM-based tagger by Viterbi (Viterbi, 1967) is a classic approach for part-of-speech tagging, where each tag corresponds to a specific part-of-speech category, such as noun or verb.",1,new
"Our team opted for a dynamic programming approach to the Part-of-Speech tagging task, building upon the foundational work of De Marcken (1996), who first introduced this method to the field.",1,new
"The decision to utilize a discriminative model for sentiment analysis was heavily influenced by the pioneering work of Pang and Lee (2004), which set the stage for the widespread adoption of this approach in natural language processing.",1,new
"We chose to adopt a probabilistic framework for named entity recognition, drawing inspiration from the seminal work of Bikel et al. (1999), who laid the groundwork for this methodology and its subsequent applications in information extraction.",1,new
"Building upon the work of Hovy and Marcu (2000), the current state-of-the-art approach to text summarization can be seen as a sequence labeling task, where each sentence is labeled as (B)eginning, (I)nside or (O)utside of the summary.",1,new
"Following the framework established by Manning and Schutze (1999), the task of named entity recognition can be viewed as a classification problem, where each word is categorized as (B)eginning, (I)nside or (O)utside of a named entity.",1,new
"In line with the methodology proposed by Collins (1996), the problem of part-of-speech tagging can be reformulated as a sequence labeling task, where each word is assigned a part-of-speech label, such as (B)eginning, (I)nside or (O)utside of a specific grammatical category.",1,new
"The machine learning algorithms investigated, including decision trees (Quinlan, 1986; Breiman et al., 1984), random forests (Breiman, 2001), and support vector machines (Cortes and Vapnik, 1995), have demonstrated significant performance on numerous pattern recognition tasks, such as image classification (Duda and Hart, 1973), handwritten digit recognition (LeCun et al., 1998), speaker identification (Sankar et al., 1997), and text categorization (Joachims, 1997).",1,new
"Among the statistical methods explored, Bayesian networks (Pearl, 1988) have shown promise on various machine learning tasks, including collaborative filtering (Resnick et al., 1994), recommendation systems (Schafer et al., 1999), sentiment analysis (Turney, 2002), and topic modeling (Blei et al., 2003).",1,new
"The deep learning techniques examined, such as convolutional neural networks (LeCun et al., 1998) and recurrent neural networks (Elman, 1990), have achieved impressive results on several natural language processing tasks, including speech recognition (Waibel et al., 1996), machine translation (Brown et al., 1990), named entity recognition (Rappaport, 1996), and sentiment analysis (Kim et al., 2014).",1,new
"Our team has selected sections 5-7 of the OntoNotes dataset for the task, leveraging its widespread use in semantic role labeling research (Gildea and Palmer, 2002), as training data and section 9 for evaluation purposes.",1,new
"For the BioCreative VI challenge, we have opted to use the same subset of the GENIA corpus (Kim et al., 2003) that has been employed in previous studies on gene mention recognition, with sections 2-4 serving as our training data and section 6 as the test set.",1,new
"In our approach to the SemEval task, we have chosen to draw upon the same annotated data from the Reuters Corpus (Reed et al., 1993) that has been utilized in various sentiment analysis studies, utilizing sections 8-10 as our training material and section 12 for testing.",1,new
"Recent years have witnessed substantial advancements in the application of machine learning and statistical techniques for the development of robust part-of-speech taggers (Brill, 1992; Marcus et al., 1993; Toutanova and Manning, 2000; Toutanova et al., 2003; Palmer et al., 2001), thereby facilitating more accurate identification of grammatical categories (Krovetz and Hearst, 2000; Schmid, 1994; Tjong Kim Sang and Buchholz, 2000; Nadeau and Sekine, 2001).",1,new
"Consequently, the integration of computational models and linguistic theories has led to notable improvements in the recognition of semantic roles and argument identification (Kipfs et al., 2000; Gildea et al., 2001; Gildea and Jurafsky, 2002; Gildea and Manning, 2000; Palmer et al., 2001), ultimately enhancing the precision of natural language processing tasks (Sutton et al., 2001; Charniak et al., 2000; Collins and Duffy, 2002).",1,new
"The past decade has seen significant strides in the utilization of probabilistic and machine learning methods for the analysis of syntactic dependencies and constituent parsing (Klein and Manning, 2003; Bikel et al., 2005; Toutanova et al., 2003; Reddy et al., 2002), resulting in enhanced parsing capabilities and improved understanding of sentence structure (Yamada and Matsumoto, 2003; Charniak, 2000; Petrov and Klein, 2004).",1,new
"Our analysis of previous studies on machine learning algorithms for part-of-speech tagging has revealed that neural network-based approaches (Huang et al., 2005; Plank et al., 2014) generally outperform traditional rule-based models (Kupiec, 1992; Brill, 1993) in terms of accuracy and efficiency.",1,new
"Recent research on text classification techniques has demonstrated that ensemble methods (Dietterich, 2000; Freund et al., 1997) often produce superior results to single-model approaches (Schapire, 1990; Valiant, 1984), as reported by various studies (Kuncheva, 2004; Opitz and Maclin, 1999).",1,new
"Comparisons of different NLP architectures have shown that deep learning-based models (Collobert et al., 2011; Mikolov et al., 2010) tend to outperform traditional statistical methods (Church and Hanks, 1989; Manning and Schutze, 1999) in tasks such as named entity recognition and dependency parsing, according to the findings of recent studies (Collins, 2003; Toutanova et al., 2003).",1,new
"Our evaluation results were compared with the Conditional Random Field (Lafferty et al., 2001) due to its high performance in labeling Chinese characters, where it achieved an accuracy of 92.5% on a large dataset.",1,new
"We opted to compare our parser with the popular Hidden Markov Model (Rabiner, 1989) as it demonstrated superior results on Arabic texts, boasting a 90.2% token accuracy in a recent study.",1,new
"The Dependency Treebank (Santorini, 1990) was chosen for a comparison with our parser due to its well-established reputation and high accuracy (88.1%) on English texts, making it an ideal benchmark for evaluation purposes.",1,new
"a.1 The expectation-maximization algorithm is widely used in handling missing data issues and has been effectively employed by numerous researchers (Dempster et al., 1977; Little & Rubin, 1987; Little, 1988; Rubin, 1987).",1,new
"a.3 The Expectation-Maximization algorithm has proven to be a reliable tool for estimating parameters in complex models and has been utilized by many researchers (Dempster et al., 1977; McLachlan & Krishnan, 1997; McLachlan, 2004; Winkler, 2003).",1,new
"a.4 The Variational Bayes method has been shown to be particularly useful in Bayesian inference and has been employed by several researchers (Beal, 2003; Attias, 1999; Winn & Bishop, 2005; Winn, 2004).",1,new
"The cutting-edge models have demonstrated exceptional performance, achieving a remarkable 95% accuracy on the Brown Corpus (which encompasses 1M words) utilizing a combination of techniques from Brown, 1987 and Church, 1988.",1,new
"Recent advancements in NLP have enabled the development of highly effective systems, which have attained a remarkable 99% accuracy on the Penn Treebank Corpus (comprising 2M words) by incorporating insights from Marcus et al., 1993 and Manning, 1993.",1,new
"The latest research has led to the creation of sophisticated systems that have achieved an impressive 98% accuracy on the Switchboard Corpus (containing 10M words) through the application of innovative methods from Dahl et al., 1994 and Jelinek, 1997.",1,new
"Compared to other machine learning algorithms, such as Support Vector Machines (Cortes and Vapnik, 1995) and Gradient Boosting (Friedman, 2001), Hidden Markov models are a straightforward and efficient choice, but they can struggle with handling complex interactions between features.",1,new
"In contrast to generative models like Latent Dirichlet Allocation (Blei et al., 2003) and Non-Negative Matrix Factorization (Lee and Seung, 2001), Hidden Markov models are simple to implement and interpret, but they may not fully leverage the potential of high-dimensional feature spaces.",1,new
"Unlike neural network architectures, such as Recurrent Neural Networks (Rumelhart et al., 1986) and Convolutional Neural Networks (LeCun et al., 1998), Hidden Markov models are computationally lightweight and easy to train, but they may not be able to capture the nuances of sequential data.",1,new
"The novel approach incorporates a robust part-of-speech tagging system based on Hidden Markov Models (Rabiner 1989; Young et al. 2006), enabling efficient identification of word categories in the text.",1,new
"A critical component of our algorithm is a Support Vector Machine classifier (Cortes and Vapnik 1995; Joachims 1999), which effectively categorizes words in a sentence and improves the overall accuracy of the model.",1,new
"The proposed methodology utilizes a Conditional Random Field (Lafferty et al. 2001) for sentence parsing, which significantly enhances the performance of the system by accurately assigning lexical categories to words in a sentence.",1,new
"The Dynamic Time Warping (DTW) algorithm has been effectively utilized in various speech recognition and time series analysis applications (Krogh and Valente, 1995; Sakoe and Chiba, 1978; Rabiner, 1989).",1,new
"The Expectation-Maximization (EM) algorithm has been successfully employed in numerous clustering and density estimation tasks (Dempster et al., 1977; McLachlan and Krishnan, 2008; Celeux and Diebolt, 1985).",1,new
"The Hidden Markov Model (HMM) has been widely applied in natural language processing and bioinformatics, with notable contributions to speech recognition and gene prediction (Rabiner, 1989; Baum and Petrie, 1966; Durbin et al., 1998).",1,new
"The work of (Krovetz and McRoy, 1998) and (Brill, 1995) on part-of-speech tagging has been notable in the field of NLP, but their approaches have been more suitable for languages with less inflectional complexity, such as (Bikel et al., 1997) and (Ratnaparkhi, 1996), which achieved impressive results, but still fall short of the accuracy of the English tagging system.",1,new
"Despite the challenges posed by (Sampson, 2000) and (Marcus et al., 1993) in the area of morphological analysis, researchers have made significant progress in languages like (Hajic et al., 2001) and (Toutanova and Manning, 2000), which have shown promising results, but there is still a gap in performance compared to the English language, as demonstrated by (Ratnaparkhi, 1996).",1,new
"The development of (Klein and Manning, 2003) and (Magerman and Hed, 1992) has addressed some of the difficulties in tagging languages with complex morphology, such as (Abeille et al., 1998) and (Bod, 1995), but these systems have not yet achieved the level of accuracy seen in (Ratnaparkhi, 1996) for English, which remains the gold standard in this area.",1,new
"This model has been successfully applied to several complex sentiment analysis tasks, including opinion mining (Turney, 2002), emotion detection (Kim & Hovy, 1997), and author profiling (Jurgens, 2013), yielding superior results.",1,new
"Its performance has been demonstrated in a range of challenging machine translation tasks, such as syntax-based parsing (Melamed, 2001), semantic role labeling (Gibson et al., 2009), and text summarization (Radev et al., 2004), consistently outperforming existing models.",1,new
"The proposed approach has been utilized in various natural language understanding tasks, including question answering (Cui et al., 2004), text classification (Joachims, 1998), and dialogue systems (Bui et al., 2016), achieving state-of-the-art accuracy.",1,new
"Recent studies have demonstrated that hidden Markov models have been remarkably successful in parsing tasks, such as part-of-speech tagging (Viterbi 1967) and named entity recognition (Grishman 1996).",1,new
"Maximum likelihood estimators have been found to be highly effective in clustering algorithms, including hierarchical clustering (Hartigan 1975) and k-means clustering (MacQueen 1967).",1,new
"The application of expectation-maximization algorithms has been shown to be highly beneficial in unsupervised learning tasks, such as Gaussian mixture models (Dempster et al. 1977) and principal component analysis (Jolliffe 1986).",1,new
"Our machine learning models have demonstrated exceptional performance on various natural language processing tasks, such as sentiment analysis (Turney 2002) and topic modeling (Blei et al. 2003).",1,new
Recent studies have shown that deep learning architectures have been highly effective in tasks such as machine translation (Vaswani et al. 2017) and text classification (Kim 2014).,1,new
"According to recent research, neural network models have achieved impressive results in areas like question answering (Hermann et al. 2015) and language modeling (Mnih et al. 2015).",1,new
"The use of recurrent neural networks (RNNs) (Mikolov et al., 2010; Graves, 2013) has revolutionized the field of natural language processing by enabling efficient modeling of sequential data.",1,new
"Recent studies employing graph-based algorithms (Kipf and Welling, 2016; Velickovic et al., 2018) have demonstrated their effectiveness in node classification tasks, showcasing the power of graph neural networks.",1,new
"The application of transformer models (Vaswani et al., 2017; Devlin et al., 2019) has led to significant improvements in machine translation and text classification, solidifying their position as a cornerstone of modern NLP research.",1,new
"The most notable contributions to the field of sentiment analysis include the use of supervised learning approaches (Pang & Lee, 2008), rule-based systems (Whitelaw et al., 2005), hybrid models (Goldberg & Elkan, 1993), and graph-based methods (Blei & Lafferty, 2001).",1,new
"The most significant advancements in natural language processing include the development of decision trees (Quinlan, 1986), support vector machines (Vapnik, 1995), neural networks (Rumelhart et al., 1986), and hidden Markov models (Baum & Petrie, 1966).",1,new
"Notable examples of successful feature extraction techniques include the use of bag-of-words (Baeza-Yates & Ribeiro-Neto, 1999), n-grams (Manning & Schtze, 1999), long short-term memory networks (Hochreiter & Schmidhuber, 1997), and word embeddings (Mikolov et al., 2013).",1,new
"The proposed approach resulted in a significant enhancement of the model's performance in sentiment analysis tasks, as demonstrated in the study by Socher et al. (2013).",1,new
"The incorporation of this technique yielded substantial improvements in the accuracy of named entity recognition, as reported in the work by Collobert et al. (2008).",1,new
"This innovative method led to a substantial increase in the efficiency of language translation, as noted in the research by Brown et al. (1990).",1,new
"Our approach also exhibited promising results in named entity recognition, outperforming other state-of-the-art models even with a limited training dataset of 1,000 examples (Grishman and Sundheim, 1996), and the use of a dynamic grammar also showed significant improvement in sentiment analysis (Kim and Hovy, 1997).",1,new
"The proposed algorithm demonstrated excellent performance in dependency parsing, outdoing other popular parsing methods even with a small grammar size (Bikel et al., 1999), and the incorporation of semantic role labeling also yielded impressive results in relation extraction (Joshi et al., 2003).",1,new
"Our model also achieved remarkable success in semantic role labeling, rivaling the performance of more complex models even with a reduced feature set (Carreras and Marquez, 2005), and the application of a hierarchical parsing algorithm also showed notable improvement in coreference resolution (Lee et al., 2007).",1,new
"Their approach has been successful in predicting the accuracy of linguistic models in several investigations (Bod, 1995; Dahl, 2004; Ney, 2004).",1,new
"The proposed method has shown promise in estimating the frequency of rare events in various corpora (Church, 1988; Jurafsky, 1996; Manning, 1999).",1,new
"Their technique has demonstrated effectiveness in determining the distribution of unknown tokens in numerous studies (Sampson, 2000; Kneser, 1995; Brown, 1992).",1,new
"The incorporation of graph-based models (Koller & Friedman, 2009) could also be beneficial in enhancing the word sense disambiguation task, as it allows us to capture the relationships between words and their contexts more effectively, thereby reducing the need for cumbersome feature engineering.",1,new
"A comparative study of the statistical and connectionist approaches (Bengio et al., 2003; Schmidhuber, 2015) may provide valuable insights into the strengths and limitations of each method, ultimately leading to a more robust word sense disambiguation system.",1,new
"By leveraging the power of deep learning techniques (Hinton et al., 2006), we can potentially develop a more accurate word sense disambiguation system that can handle the complexities of language and improve the overall performance of the model, without requiring extensive feature engineering.",1,new
"The current state-of-the-art methods for named entity recognition include Conditional Random Fields (Lafferty et al. 2001), Support Vector Machines (Joachims 1999), and decision trees (Kohavi 1995).",1,new
"Recent advancements in natural language processing have led to the development of effective techniques such as Latent Semantic Analysis (Landauer & Dumais 1997), Latent Dirichlet Allocation (Blei et al. 2003), and Hopfield networks (Hopfield 1982).",1,new
"In the realm of speech recognition, notable approaches include Gaussian Mixture Models (Rabiner 1989), Dynamic Time Warping (Sakoe & Chiba 1978), and Hidden Semi-Markov Models (Juang & Rabiner 1985).",1,new
"The use of Recurrent Neural Networks (RNNs) (Elman, 1990) and Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) has proven to be effective in modeling sequential data, and has been successfully applied to various NLP tasks (Sutskever et al., 2011; Graves et al., 2009; Mikolov et al., 2010).",1,new
"The combination of Decision Trees (Quinlan, 1986) and Random Forests (Breiman, 2001) offers a robust approach to classification and regression problems, and has been successfully applied to various real-world datasets (Cortes and Vapnik, 1995; Dietterich, 2000; Ho, 1995).",1,new
"The use of Convolutional Neural Networks (CNNs) (LeCun et al., 1998) and Transfer Learning (Yosinski et al., 2014) has revolutionized the field of image classification, and has been successfully applied to various computer vision tasks (Krizhevsky et al., 2012; Simonyan and Zisserman, 2015; Girshick et al., 2014).",1,new
"The application of long short-term memory (LSTM) networks to natural language processing tasks has seen considerable advancements (Hochreiter & Schmidhuber, 1997; Gers et al., 1999).",1,new
"Recent studies have demonstrated the effectiveness of using attention mechanisms in deep learning models for text classification (Bahdanau et al., 2014; Vinyals et al., 2015).",1,new
"The development of transformer models has greatly improved the efficiency of sequence-to-sequence tasks in NLP (Vaswani et al., 2017; Devlin et al., 2019).",1,new
"The hidden Markov model (Jelinek, 1969; Rabiner, 1989) has been widely adopted in speech recognition tasks due to its flexibility and ability to handle sequential data effectively (Bakis et al., 1994; Juang et al., 2000).",1,new
"The Gaussian mixture model (Dempster et al., 1972; Reynolds, 2000) has gained significant attention in the machine learning community due to its ability to model complex distributions and provide robust results in clustering tasks (McLachlan, 2004; Redner, 2001).",1,new
"The support vector machine (Vapnik, 1995; Cristianini and Shawe-Taylor, 2000) has become a popular choice in classification tasks due to its ability to handle high-dimensional data and provide accurate results (Burges, 1998; Scholkopf et al., 2001).",1,new
"The proposed methodology successfully integrates the broad contextual understanding of distributional semantics (Kilgarriff, 2001; Baroni et al., 2009) with the precise feature extraction of binary classification models (Joachims, 1998; Sebastiani, 2002).",1,new
"By leveraging the strengths of generative models (Collins, 1999; Goodman, 2001), our approach is able to capture the nuanced relationships between words and their contexts, while also benefiting from the specificity of rule-based systems (Rapp, 2002; Charniak, 1997).",1,new
"This innovative framework effectively combines the robustness of supervised learning (Manning and Schtze, 1999; Collins, 2001) with the interpretability of feature-based approaches (Joachims, 1998; Hacioglu and Ward, 2001), resulting in a powerful tool for NLP tasks.",1,new
"Recent advancements in machine learning have led to the development of highly accurate parsers, such as the popular shift-reduce parser (Collins, 2003; Chiang, 2005).",1,new
"The field of natural language processing has seen significant progress in the past two decades, with the introduction of robust part-of-speech taggers and named entity recognizers (Brill, 1992; Tjong Kim Sang and Buchholz, 2000).",1,new
"The use of statistical methods in NLP has enabled the creation of accurate sentence parsing systems, including the widely used probabilistic context-free grammar parser (Johnson, 1998; Taskar et al., 2003).",1,new
"The use of Conditional Random Fields (CRFs) (Lafferty et al 2001) and their variants (Sha & Pereira 2003, Sutton & McCallum 2006) has been instrumental in achieving accurate named entity recognition in various NLP tasks.",1,new
"Recent studies employing Support Vector Machines (SVMs) (Cortes & Vapnik 1995) and their extensions (Joachims 1999, Platt 1999) have demonstrated significant improvements in sentiment analysis and opinion mining.",1,new
"The application of Hidden Markov Models (HMMs) (Rabiner 1989) and their refinements (Juang & Rabiner 1991, Young et al 2002) has led to substantial advancements in speech recognition and language modeling.",1,new
"Recent studies have made significant breakthroughs with the application of Bayesian neural networks (BNNs) (Neal, 1996; Bishop, 1994; MacKay, 1992), demonstrating improved performance in complex modeling tasks.",1,new
"The introduction of Long Short-Term Memory (LSTM) architectures has led to substantial advancements in sequential data modeling (Hochreiter & Schmidhuber, 1997; Gers et al., 2000; Graves et al., 2005), showcasing their potential in various real-world applications.",1,new
"The incorporation of graph neural networks (GNNs) has shown remarkable promise in modeling complex relationships and interactions (Kipf & Welling, 2017; Scarselli et al., 2009; Defferrard et al., 2016), opening up new avenues for research and innovation.",1,new
"Recent studies employing hybrid approaches to named entity recognition have shown promising results for both coreference resolution and semantic role labeling (Hindle, 2003; Gildea & Manning, 2000; Palmer et al., 2005).",1,new
"The incorporation of discourse-level features has led to significant improvements in sentiment analysis and aspect-based sentiment analysis (Turney, 2002; Liu et al., 2005; Wiebe et al., 2005).",1,new
"Models that integrate linguistic and statistical methods have achieved excellent results in part-of-speech tagging and dependency parsing (Klein & Manning, 2003; Sag et al., 2003; Bikel et al., 1997).",1,new
"His innovative approach has led to remarkable advancements in machine translation by leveraging the effectiveness of Hidden Markov Models (Jelinek, 1976) and statistical parsing (Katz, 1987).",1,new
"Recent breakthroughs in speech recognition have been achieved through the application of dynamic programming (Bellman, 1957) and context-free grammar (Chomsky, 1957).",1,new
"The researcher's utilization of decision trees (Breiman, 2001) and maximum likelihood estimation (Fisher, 1922) has resulted in outstanding performance in natural language processing tasks.",1,new
"Our model leverages the same type of n-gram features that have been instrumental in the development of numerous state-of-the-art tagging systems, as evident from the work of (Brill, 1993), (McDonald, 1995), and (Bikel, 1997).",1,new
"By incorporating the same type of linguistic patterns that have been widely adopted in prominent tagging models, our approach builds upon the foundational work of (Church, 1988), (Lafferty et al., 1992), and (Ratnaparkhi, 1996).",1,new
"Our proposed method draws inspiration from the same statistical techniques that have been successfully employed in various tagging models, including (Kupiec, 1992), (Merialdo, 1994), and (Brill and Resnik, 1994).",1,new
"Jing and McKeown (2000) have proposed a rule-based algorithm for sentence combination, but no results have been reported.",2,original
"Many approaches for POS tagging have been developed in the past, including rule-based tagging (Brill, 1995), HMM taggers (Brants, 2000; Cutting and others, 1992), maximum-entropy models (Rathnaparki, 1996), cyclic dependency networks (Toutanova et al. , 2003), memory-based learning (Daelemans et al. , 1996), etc. All of these approaches require either a large amount of annotated training data (for supervised tagging) or a lexicon listing all possible tags for each word (for unsupervised tagging).",2,original
"Brill's results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging (Jelinek, 1985; Church, 1988; DeRose, 1988; Cutting et al. , 1992; Weischedel et al. , 1993), as well as showing promise for other applications.",2,original
"Several papers have looked at higher-order representations, but have not examined the equivalence of syn/para distributions when formalized as Markov chains (Schutze and Pedersen, 1993; Lund and Burgess, 1996; Edmonds, 1997; Rapp, 2002; Biemann et al., 2004; Lemaire and Denhi`ere, 2006).",2,original
"This method was preferred against other related methods, like the one introduced in (Mihalcea et al., 2004), since it embeds all the available semantic information existing in WordNet, even edges that cross POS, thus offering a richer semantic representation.",2,original
A potential caveat with Lins (1998) distributional similarity measure is its reliance on syntactic information for obtaining dependency relations.,2,original
"Unfortunately, there is no straightforward generalization of the method of Smith and Smith (2007) to the two edge marginal problem.",2,original
"Unlike Johnson (2007), who found optimal performance when  was approximately 104, we observed monotonic increases in performance as  dropped.",2,original
"5Since the test data of (Svore et al., 2007) is not publicly available we were unable to carry out a more detailed comparison.",2,original
"Our approach not only outperformed a notoriously difficult baseline but also achieved similar performance to the approach of (Svore et al., 2007), without requiring their third-party data resources.",2,original
"We want to note that our WordNetbased method outperforms that of Hughes and Ramage (2007), which uses a similar method.",2,original
"Although this Wikipedia gazetteer is much smaller than the English version used by Kazama and Torisawa (2007) that has over 2,000,000 entries, it is the largest gazetteer that can be freely used for Japanese NER.",2,original
"Surprisingly, although JESS-CM is a simpler version of the hybrid model in terms of model structure and parameter estimation procedure, JESS-CM provides F-scores of 94.45 and 88.03 for CoNLL00 and 03 data, respectively, which are 0.15 and 0.83 points higher than those reported in (Suzuki et al., 2007) for the same configurations.",2,original
"Unsupervised methods have been developed for WSD, but despite modest success have not always been well understood statistically (Abney, 2004).",2,original
 The automatically generated patterns in PairClass are slightly more general than the patterns of Turney (2006).,2,original
" The morphological processing in PairClass (Minnen et al., 2001) is more sophisticated than in Turney (2006).",2,original
"2Mutual information, though potentially of interest as a measure of collocational status, was not tested due to its well-known property of overemphasising the significance of rare events (Church and Hanks, 1990).",2,original
"Hanks and Church (1990) proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs.",2,original
"Unlike Church and Hanks (1990), Smadja (1993) goes beyond the ""two-word"" limitation and deals with ""collocations of arbitrary length"".",2,original
"This method was shown to outperform the class based model proposed in (Brown et al., 1992) and can thus be expected to discover better clusters of words.",2,original
"This is in contrast to purely statistical systems (e.g. , \[Brown et al. , 1992\]), which are difficult to inspect and modify.",2,original
"For example, we would like to know that if a (JJ, JJ) 7We also tried using word clusters (Brown et al. , 1992) instead of POS but found that POS was more helpful.",2,original
"In addition, the clustering methods used, such as HMMs and Browns algorithm (Brown et al., 1992), seem unable to adequately capture the semantics of MNs since they are based only on the information of adjacent words.",2,original
"Our method is a natural extension of those proposed in (Brown et al. , 1992) and (Li and Abe, 1996), and overcomes their drawbacks while retaining their advantages.",2,original
"While we have shown an increase in performance over a purely syntactic baseline model (the algorithm of (Brown et al., 1992)), there are a number of avenues to pursue in extending this work.",2,original
"Other statistical systems that address word classification probleans do not emphasize the use of linguistic knowledge and do not deal with a specific word class\[Brown et al. , 1992\], or do not exploit as much linguistic knowledge as we do \[Pereira et al. , 1993\].",2,original
"As with similar work (e.g. Brown et al 1992), the size of the corpus makes preprocessing such as lemmatization, POS tagging or partial parsing, too costly.",2,original
"Clustering algorithms have been previously shown to work fairly well for the classification of words into syntactic and semantic classes (Brown et al. 1992), but determining the optimum number of classes for a hierarchical cluster tree is an ongoing difficult problem, particularly without prior knowledge of the item classification.",2,original
It is faster and more mnemonic than the one in Dunning (1993).,2,original
"While several methods have been proposed to automatically extract compounds (Smadja 1993, Suet al. 1994), we know of no successful attempt to automatically make classes of compounds.",2,original
"Therefore, sublanguage techniques such as Sager (1981) and Smadja (1993) do not work.",2,original
"It also differs from previous proposals on lexical acquisition using statistical measures such as (Church et al. , 1991; Brent, 1991; Brown et al. , 1993) which either deny the prior existence of linguistic knowledge or use linguistic knowledge in ad hoc ways.",2,original
"For example, the statistical word alignment in IBM translation models (Brown et al. 1993) can only handle word to word and multi-word to word alignments.",2,original
"2 Statistical Word Alignment Statistical translation models (Brown, et al. 1993) only allow word to word and multi-word to word alignments.",2,original
"Furthermore, we provide a 63.8% error reduction compared to IBM Model 4 (Brown et al., 1993).",2,original
"This is a problem with other direct translation models, such as IBM model 1 used as a direct model rather than a channel model (Brown et al., 1993).",2,original
"Numbers in the table correspond to the percentage of experiments in which the condition at the head of the column was true (for example figure in the first row and first column means that for 98.9 percent of the language pairs the BLEU score for the bidirectional decoder was better than that of the forward decoder) proach (Brown et al., 1993)).",2,original
"2 Related Work One of the major problems with the IBM models (Brown et al. , 1993) and the HMM models (Vogel et al. , 1996) is that they are restricted to the alignment of each source-language word to at most one targetlanguage word.",2,original
"While in traditional word-based statistical models (Brown et al. , 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999).",2,original
"IBM Model1 (Brown et al., 1993) is a simplistic model which takes no account of the subtler aspects of language translation including the way word order tends to differ across languages.",2,original
"At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al. 1993) for training translation systems automatically.",2,original
"A word order correlation bias, as well as the phrase structure biases in Brown et al.'s (1993b) Models 4 and 5, would be less beneficial with noisier training bitexts or for language pairs with less similar word order.",2,original
"Our system outperforms competing approaches, including the standard machine translation alignment models (Brown et al. 1993; Vogel, Ney, and Tillmann 1996) and the state-of-the-art Cut and Paste summary alignment technique (Jing 2002).",2,original
"In terms of alignment, this wordnumber difference means that multiword connections must be considered, a task which 334 Sue J. Ker and Jason S. Chang Word Alignment is beyond the reach of methods proposed in recent alignment works based on Brown et al.'s (1993) Model 1 and 2.",2,original
"The ATTM attempts to overcome the deficiencies of word-to-word translation models (Brown et al. , 1993) through the use of phrasal translations.",2,original
"1 Phrase-based Unigram Model Various papers use phrase-based translation systems (Och et al. , 1999; Marcu and Wong, 2002; Yamada and Knight, 2002) that have shown to improve translation quality over single-word based translation systems introduced in (Brown et al. , 1993).",2,original
"By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation (Brown et al. 1993) and information retrieval (Franz, M. and McCarley, S. 2002).",2,original
"By 17 0 10 20 30 40 50 60 70 80 90 100 10000 100000 1e+06 1e+07 Test Set Items with Translations (%) Training Corpus Size (num words) unigrams bigrams trigrams 4-grams Figure 1: Percent of unique unigrams, bigrams, trigrams, and 4-grams from the Europarl Spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al. , 1993).",2,original
"stance, the IBM models (Brown et al. , 1993) can be improved by adding more context dependencies into the translation model using a ME framework rather than using only p(f j |e i ) (Garcia-Varea et al. , 2002).",2,original
"Lexical relationships under the standard IBM models (Brown et al. , 1993) do not account for many-to-many mappings, and phrase extraction relies heavily on the accuracy of the IBM word-toword alignment.",2,original
"Compared to earlier word-based methods such as IBM Models (Brown et al. , 1993), phrasebased methods such as PHARAOH are much more effective in producing idiomatic translations, and are currently the best performing methods in SMT (Koehn and Monz, 2006).",2,original
"By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation (Brown et al. 1993) and information retrieval (Franz, M. and McCarley, S. 2002).",2,original
"Although the first three are particular cases where N=1 and/or M=1, the distinction is relevant, because most word-based translation models (eg IBM models (Brown et al. , 1993)) can typically not accommodate general M-N alignments.",2,original
"2 2.1 Word Alignment Adaptation Bi-directional Word Alignment In statistical translation models (Brown et al. , 1993), only one-to-one and more-to-one word alignment links can be found.",2,original
"For the results in this paper, we have used Pointwise Mutual Information (PMI) instead of IBM Model 1 (Brown et al. , 1993), since (Rogati and Yang, 2004) found it to be as effective on Springer, but faster to compute.",2,original
"By increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al. , 1993), in particular:  The Brown et al.",2,original
"These methods go beyond the original IBM machine translation models (Brown et al. , 1993), by allowing multi-word units (phrases) in one language to be translated directly into phrases in another language.",2,original
"1 Introduction Phrase-based translation models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004), which go beyond the original IBM translation models (Brown et al. , 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations.",2,original
"In pursuit of better translation, phrase-based models (OchandNey,2004)havesignificantlyimprovedthe quality over classical word-based models (Brown et al. , 1993).",2,original
"1 Introduction For statistical machine translation (SMT), phrasebased methods (Koehn et al. , 2003; Och and Ney, 2004) and syntax-based methods (Wu, 1997; Alshawi et al. 2000; Yamada and Knignt, 2001; Melamed, 2004; Chiang, 2005; Quick et al. , 2005; Mellebeek et al. , 2006) outperform word-based methods (Brown et al. , 1993).",2,original
"1 Introduction The field of machine translation has seen many advances in recent years, most notably the shift from word-based (Brown et al., 1993) to phrasebased models which use token n-grams as translation units (Koehn et al., 2003).",2,original
"This approach addresses the problematic aspects of both pure knowledge-based generation (where incomplete knowledge is inevitable) and pure statistical bag generation (Brown et al. , 1993) (where the statistical system has no linguistic guidance).",2,original
"Although the authors of (Brown et al. , 1993) stated that they would discuss the search problem in a follow-up arti cle, so far there have no publications devoted to the decoding issue for statistical machine translation.",2,original
"(Vogel et al. , 1996) report better perplexity results on the Verbmobil Corpus with their HMMbased alignment model in comparison to Model 2 of (Brown et al. , 1993).",2,original
"A word based approach depends upon traditional statistical machine translation techniques such as IBM Model1 (Brown et al. , 1993) and may not always yield satisfactory results due to its inability to handle difficult many-to-many phrase translations.",2,original
"Several teams had approaches that relied (to varying degrees) on an IBM model of statistical machine translation (Brown et al. , 1993), with different improvements brought by different teams, consisting of new submodels, improvements in the HMM model, model combination for optimal alignment, etc. Se-veral teams used symmetrization metrics, as introduced in (Och and Ney, 2003) (union, intersection, refined), most of the times applied on the alignments produced for the two directions sourcetarget and targetsource, but also as a way to combine different word alignment systems.",2,original
"1 Introduction In recent years, various phrase translation approaches (Marcu and Wong, 2002; Och et al. , 1999; Koehn et al. , 2003) have been shown to outperform word-to-word translation models (Brown et al. , 1993).",2,original
"1 Introduction Phrase-based approaches (Och and Ney, 2004) to statistical machine translation (SMT) have recently achieved impressive results, leading to significant improvements in accuracy over the original IBM models (Brown et al. , 1993).",2,original
"1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al. , 2003) significantly outperform the historical word-based modeling (Brown et al. , 1993).",2,original
"(2006) tried a different generative phrase translation model analogous to IBM word-translation Model 3 (Brown et al. , 1993), and again found that the standard model outperformed their generative model.",2,original
"One prominent constraint of the IBM word alignment models (Brown et al., 1993) is functional alignment, that is each target word is mapped onto at most one source word.",2,original
"4 Conclusions Compared with other word alignment algorithms (Brown et al. , 1993; Gale and Church, 1991a), word_align does not require sentence alignment as input, and was shown to produce useful alignments for small and noisy corpora.",2,original
"The program takes the output of char_align (Church, 1993), a robust alternative to sentence-based alignment programs, and applies word-level constraints using a version of Brown el al.'s Model 2 (Brown et al. , 1993), modified and extended to deal with robustness issues.",2,original
"The method was intended as a replacement for sentence-based methods (e.g. , (Brown et al. , 1991a; Gale and Church, 1991b; Kay and Rosenschein, 1993)), which are very sensitive to noise.",2,original
"1 Introduction Despite a surge in research using parallel corpora for various machine translation tasks (Brown et al. 1993),(Brown et al. 1991; Gale & Church 1993; Church 1993; Dagan & Church 1994; Simard et al. 1992; Chen 1993; Melamed 1995; Wu & Xia 1994; Wu 1994; Smadja et aI.",2,original
"For instance, about 38% of verbs in the training sections of the Penn Treebank (PTB) (Marcus et al., 1993) occur only once  the lexical properties of these verbs (such as their most common subcategorization frames ) cannot be represented accurately in a model trained exclusively on the Penn Treebank.",2,original
"a time-consuming process (Litman and Pan, 2002; Marcus et al. , 1993; Xia et al. , 2000; Wiebe, 2002).",2,original
"This is because their training data, the Penn Treebank (Marcus et al., 1993), does not fully annotate NP structure.",2,original
"This cost can often be substantial, as with the Penn Treebank (Marcus et al. , 1993).",2,original
"For example, 10 million words of the American National Corpus (Ide et al. , 2002) will have manually corrected POS tags, a tenfold increase over the Penn Treebank (Marcus et al. , 1993), currently used for training POS taggers.",2,original
"Since Czech is a language with relatively high degree of word-order freedom, and its sentences contain certain syntactic phenomena, such as discontinuous constituents (non-projective constructions), which cannot be straightforwardly handled using the annotation scheme of Penn Treebank (Marcus et al. , 1993; Linguistic Data Consortium, 1999), based on phrase-structure trees, we decided to adopt for the PCEDT the dependency-based annotation scheme of the Prague Dependency Treebank  PDT (Linguistic Data Consortium, 2001).",2,original
"It has been difficult to identify all and only those cases where a token functions as a discourse connective, and in many cases, the syntactic analysis in the Penn TreeBank (Marcus et al. , 1993) provides no help.",2,original
"More recent work (McCallum 2003; Zhou et al. 2003; Riezler and Vasserman 2004) has considered methods for speeding up the feature selection methods described in Berger, Della Pietra, and Della Pietra (1996), Ratnaparkhi (1998), and Della Pietra, Della Pietra, and Lafferty (1997).",2,original
"But without the global normalization, the maximumlikelihood criterion motivated by the maximum entropy principle (Berger et al. , 1996) is no longer a feasible option as an optimization criterion.",2,original
"Despite ME theory and its related training algorithm (Darroch and Ratcliff, 1972) do not set restrictions on the range of feature functions1, popular NLP text books (Manning and Schutze, 1999) and research papers (Berger et al. , 1996) seem to limit them to binary features.",2,original
"The class-based kappa statistic of (Cohen, 1960; Carletta, 1996) cannot be applied here, as the classes vary depending on the number of ambiguities per entry in the lexicon.",2,original
"Ever since its introduction in general (Cohen, 1960) and in computational linguistics (Carletta, 1996), many researchers have pointed out that there are quite some problems in using  (e.g.",2,original
"Inside-out alignments (Wu, 1997), such as the one in Example 1.3, cannot be induced by any of these theories; in fact, there seems to be no useful synchronous grammar formalisms available that handle inside-out alignments, with the possible exceptions of synchronous tree-adjoining grammars (Shieber and Schabes, 1990), Bertsch and Nederhof (2001) and generalized multitext grammars (Melamed et al., 2004), which are all way more complex than ITG, STSG and (2,2)-BRCG.",2,original
"String alignment with synchronous grammars is quite expensive even for simple synchronous formalisms like ITG (Wu, 1997)but Duchi et al.",2,original
"Other statistical machine translation systems such as (Wu, 1997) and (Alshawi et al. , 2000) also produce a tree a15 given a sentence a16 . Their models are based on mechanisms that generate two languages at the same time, so an English tree a15 is obtained as a subproduct of parsing a16 . However, their use of the LM is not mathematically motivated, since their models do not decompose into Pa4a5a2a9a8a3a10a6 and a12a14a4a5a3a7a6 unlike the noisy channel model.",2,original
Wu (1997) provides anecdotal evidence that only incorrect alignments are eliminated by ITG constraints.,2,original
"Synchronous grammar formalisms that are capable of modeling such complex relationships while maintaining the context-free property in each language have been proposed for many years, (Aho and Ullman, 1972; Wu, 1997; Yamada and Knight, 2001; Melamed, 2003; Chiang, 2005), but have not been scaled to large corpora and long sentences until recently.",2,original
"The utility of ITG as a reordering constraint for most language pairs, is well-known both empirically (Zens and Ney, 2003) and analytically (Wu, 1997), howeverITGsstraight (monotone)andinverted (reverse) rules exhibit strong cohesiveness, which is inadequate to express orientations that require gaps.",2,original
"The work reported in Wu (1997), which uses an inside-outside type of training algorithm to learn statistical contextfree transduction, has a similar motivation to the current work, but the models we describe here, being fully lexical, are more suitable for direct statistical modelling.",2,original
"An alternative method (Wu, 1997) makes decisions at the end but has a high computational requirement.",2,original
"Besides, our model, as being linguistically motivated, is also more expressive than the formally syntax-based models of Chiang (2005) and Wu (1997).",2,original
"While the idea of exploiting multiple news reports for paraphrase acquisition is not new, previous efforts (for example, Shinyama et al. 2002; Barzilay and Lee 2003) have been restricted to at most two news sources.",2,original
"2This can explain why previous attempts to use WordNet for generating sentence-level paraphrases (Barzilay and Lee, 2003; Quirk et al. , 2004) were unsuccessful.",2,original
"If we consider these probabilities as a vector, the similarities of two English words can be obtained by computing the dot product of their corresponding vectors.2 The formula is described below: similarity(ei, ej) = Nsummationdisplay k=1 p(ei|fk)p(ej|fk) (3) Paraphrasing methods based on monolingual parallel corpora such as (Pang et al. , 2003; Barzilay and Lee, 2003) can also be used to compute the similarity ratio of two words, but they dont have as rich training resources as the bilingual methods do.",2,original
"Experiments, by using 4 algorithms and through visualization techniques, revealed that clustering is a worthless effort for paraphrase corpora construction, contrary to the literature claims (Barzilay & Lee, 2003).",2,original
"Table 2: Figures about clustering algorithms Algorithm # Sentences/# Clusters S-HAC 6,23 C-HAC 2,17 QT 2,32 EM 4,16 In fact, table 2 shows that most of the clusters have less than 6 sentences which leads to question the results presented by (Barzilay & Lee, 2003) who only keep the clusters that contain more than 10 sentences.",2,original
"With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT (Koehn et al., 2003) in a more effective manner.",2,original
"Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by a conventional phrase-based approach (Koehn et al. , 2003).",2,original
"1 Introduction Statistical phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) have consistently delivered state-of-the-art performance in recent machine translation evaluations, yet these systems remain weak at handling word order changes.",2,original
"In contrast, standard phrase-based models (Koehn et al., 2003) assume a mostly monotone mapping between source and target, and therefore cannot adequately model these phenomena.",2,original
"1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT.",2,original
"The problem is typically presented in log-space, which simplifies computations, but otherwise does not change the problem due to the monotonicity of the log function (hm = log hprimem) log p(t|s) = summationdisplay m m hm(t,s) (3) Phrase-based models (Koehn et al., 2003) are limited to the mapping of small contiguous chunks of text.",2,original
"However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003).",2,original
"For comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) Intersection of both directions (Aligner(int)); (2) Union of both directions (Aligner(union)); and (3) The previously bestknown heuristic combination approach called growdiag-final (Koehn et al. , 2003) (Aligner(gdf)).",2,original
"Like WASP1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++ (Koehn et al. , 2003), which performs poorly when applied directly to MRLs (Section 3.2).",2,original
"The process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (Koehn et al. , 2003), but it is not obvious which one should be chosen for a given language pair.",2,original
"1 Introduction Currently, most of the phrase-based statistical machine translation (PBSMT) models (Marcu and Wong, 2002; Koehn et al., 2003) adopt full matching strategy for phrase translation, which means that a phrase pair (tildewidef,tildewidee) can be used for translating a source phrase f, only if tildewidef = f. Due to lack of generalization ability, the full matching strategy has some limitations.",2,original
"In such a process, original phrase-based decoding (Koehn et al., 2003) does not take advantage of any linguistic analysis, which, however, is broadly used in rule-based approaches.",2,original
"It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al. , 2003).",2,original
"2 Previous Work It is helpful to compare this approach with recent efforts in statistical MT. Phrase-based models (Koehn et al. , 2003; Och and Ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order.",2,original
"1 Introduction Translations tables in Phrase-based Statistical Machine Translation (SMT) are often built on the basis of Maximum-likelihood Estimation (MLE), being one of the major limitations of this approach that the source sentence context in which phrases occur is completely ignored (Koehn et al. , 2003).",2,original
"In such tasks, feature calculation is also very expensive in terms of time required; huge sets of extracted rules must be sorted in two directions for relative frequency calculation of such features as the translation probability p(f|e) and reverse translation probability p(e|f) (Koehn et al., 2003).",2,original
"While the amount of parallel data required to build such systems is orders of magnitude smaller than corresponding phrase based statistical systems (Koehn et al., 2003), the variety of linguistic annotation required is greater.",2,original
"1 Introduction The dominance of traditional phrase-based statistical machine translation (PBSMT) models (Koehn et al., 2003) has recently been challenged by the development and improvement of a number of new models that explicity take into account the syntax of the sentences being translated.",2,original
"This implies that the complexity of structure divergence between two languages is higher than suggested in literature (Fox, 2002; Galley et al., 2004).",2,original
"Current tree-based models that integrate linguistics and statistics, such as GHKM (Galley et al., 2004), are not able to generalize well from a single phrase pair.",2,original
"Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of (Galley et al. , 2004).",2,original
"We presented some theoretical arguments for not limiting extraction to minimal rules, validated them on concrete examples, and presented experiments showing that contextually richer rules provide a 3.63 BLEU point increase over the minimal rules of (Galley et al. , 2004).",2,original
"However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al. , 2004; Marcu et al. , 2006; Koehn et al. , 2003).",2,original
"Our interpretation is more useful than past interpretations involving marginal constraints (Kneser and Ney, 1995; Chen and Goodman, 1998) or maximum-entropy models (Goodman, 2004) as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results.",2,original
"While most parsing methods are currently supervised or semi-supervised (McClosky et al. 2006; Henderson 2004; Steedman et al. 2003), they depend on hand-annotated data which are difficult to come by and which exist only for a few languages.",2,original
"V B N P  J J R ( a ) ( b ) V 2 V 1 V 2 ' V 1 ' V P V B N P w ill b e J J R  Figure 1: Two different binarizations (a) and (b) of the same SCFG rule distinguished by the solid lines and dashed lines                         ( W e  h o p e  t h e  s i t u a t i o n  w i l l  b e  b e t t e r  . )           N P        J J R     d e c o d i n g m a t c h  8 7 4  r u l e s m a t c h  6 2  r u l e s c o m p e t i n g  e d g e s :  8 0 1 c o m p e t i n g  e d g e s :  5 7 Figure 2: Edge competitions caused by different binarizations  The edge competition problem for SMT decoding is not addressed in previous work (Zhang et al., 2006; Huang, 2007) in which each SCFG rule is binarized in a fixed way.",2,original
"The experimental results show that our method outperforms the synchronous binarization method (Zhang et al., 2006) with over 0.8 BLEU scores on both NIST 2005 and NIST 2008 Chinese-to-English evaluation data sets.",2,original
"Although this method is comparatively easy to be implemented, it just achieves the same performance as the synchronous binarization method (Zhang et al., 2006) for syntaxbased SMT systems.",2,original
"The 74.6% final accuracy on apartments is higher than any result obtained by Haghighi and Klein (2006) (the highest is 74.1%), higher than the supervised HMM results reported by Grenager et al.",2,original
"Allomorphs (e.g., deni and deny) are also automatically identified in (Dasgupta, 2007), but the general problem of recognizing highly irregular forms is examined more extensively in (Yarowsky and Wicentowski, 2000).",2,original
"However, it seems unrealistic to expect a one-size-fits-all approach to be achieve uniformly high performance across varied languages, and, in fact, it doesnt. Though the system presented in (Dasgupta and Ng, 2007) outperforms the best systems in the 2006 PASCAL challenge for Turkish and Finnish, it still does significantly worse on these languages than English (F-scores of 66.2 and 66.5, compared to 79.4).",2,original
"They reported that their method is superior to BLEU (Papineni et al. , 2002) in terms of the correlation between human assessment and automatic evaluation.",2,original
"Unfortunately, this is not the case for such widely used MT evaluation metrics as BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002).",2,original
"Although, there are various manual/automatic evaluation methods for these systems, e.g., BLEU (Papineni et al. 2002), these methods are basically incapable of dealing with an MTsystem and a w/p-MT-system at the same time, as they have different output forms.",2,original
"This restriction is necessary because the problem of optimizing many-to-many alignments 5 Our preliminary experiments with n-gram-based overlap measures, such as BLEU (Papineni et al. 2002) and ROUGE (Lin and Hovy 2003), show that these metrics do not correlate with human judgments on the fusion task, when tested against two reference outputs.",2,original
"This strategy is commonly used in MT evaluation, because of BLEUs well-known problems with documents of small size (Papineni et al. , 2002; Koehn, 2004).",2,original
"The most commonly used metric, BLEU, correlates well over large test sets with human judgments (Papineni et al. , 2002), but does not perform as well on sentence-level evaluation (Blatz et al. , 2003).",2,original
"Due to limited variations in the N-Best list, the nature of ranking, and more importantly, the non-differentiable objective functions used for MT (such as BLEU (Papineni et al., 2002)), one often found only local optimal solutions to , with no clue to walk out of the riddles.",2,original
"Automatic evaluation methods such as BLEU (Papineni et al. , 2002), RED (Akiba et al. , 2001), or the weighted N-gram model proposed here may be more consistent in judging quality as compared to human evaluators, but human judgments remain the only criteria for metaevaluating the automatic methods.",2,original
"METEOR was chosen since, unlike the more commonly used BLEU metric (Papineni et al. , 2002), it provides reasonably reliable scores for individual sentences.",2,original
"The ongoing evaluationliteratureisperhapsmostobviousinthe machine translation communitys efforts to better BLEU (Papineni et al. , 2002).",2,original
"By doing so we must emphasize that, as described in the previous section, the BLEU score was not designed to deliver satisfactory results at the sentence level (Papineni et al., 2002), and this also applies to the closely related NIST score.",2,original
"They are a bit controversial in a proper machine translation, where the popular BLEU score (Papineni et al. , 2002), although widely accepted as a measure of translation accuracy, seems to favor stochastic approaches based on 91 an n-gram model over other MT methods (see the results in (Nist, 2001)).",2,original
"Even the creators of BLEU point out that it may not correlate particularly well with human judgment at the sentence level (Papineni et al. , 2002), a problem also noted by (Och et al. , 2003) and (Russo-Lassner et al. , 2005).",2,original
"Even the creators of BLEU point out that it may not correlate particularly well with human judgment at the sentence level (Papineni et al. , 2002).",2,original
"Even the 3 A demo of the parser can be found at http://lfgdemo.computing.dcu.ie/lfgparser.html creators of BLEU point out that it may not correlate particularly well with human judgment at the sentence level (Papineni et al. , 2002).",2,original
"Presently, there exist methods for learning oppositional terms (Marcu and Echihabi, 2002) and paraphrase learning has been thoroughly studied, but successfully extending these techniques to learn incompatible phrases poses difficulties because of the data distribution.",2,original
"2 Previous work on Sentiment Analysis Some prior studies on sentiment analysis focused on the document-level classification of sentiment (Turney, 2002; Pang et al. , 2002) where a document is assumed to have only a single sentiment, thus these studies are not applicable to our goal.",2,original
"Point-wise mutual information (PMI) is commonly used for computing the association of two terms (e.g., Turney 2002), which is defined as: nullnullnull null null,null null nullnullnull nullnullnullnull,nullnull nullnull null null null nullnullnullnullnull . However, we argue that PMI is not a suitable measure for our purpose.",2,original
"Turneys method did not work well although they reported 80% accuracy in (Turney and Littman, 2002).",2,original
"While other systems, such as (Hu and Liu, 2004; Turney, 2002), have addressed these tasks to some degree, OPINE is the first to report results.",2,original
"While we do not have a direct comparison, we note that Turney (2002) performs worse on movie reviews than on his other datasets, the same type of data as the polarity dataset.",2,original
"Our focus is on the sentence level, unlike (Pang et al. , 2002) and (Turney, 2002); we employ a significantly larger set of seed words, and we explore as indicators of orientation words from syntactic classes other than adjectives (nouns, verbs, and adverbs).",2,original
"In the thriving area of research on automatic analysis and processing of product reviews (Hu and Liu 2004; Turney 2002; Pang and Lee 2005), little attention has been paid to the important task studied here  assessing review helpfulness.",2,original
"??word class: Turney (2002) measures polarity using only adjectives, however in our approach we consider the noun, the verb, the adverb and the adjective content words.",2,original
"Note that the minimum error rate training (Och, 2003) uses only the target sentence with the maximum posterior probability whereas, here, the whole probability distribution is taken into account.",2,original
"We will show that some achieve significantly better results than the standard minimum error rate training of (Och, 2003).",2,original
"The ubiquitous minimum error rate training (MERT) approach optimizes Viterbi predictions, but does not explicitly boost the aggregated posterior probability of desirable n-grams (Och, 2003).",2,original
"This method has the advantage that it is not limited to the model scaling factors as the method described in (Och, 2003).",2,original
"Unlike minimum error rate training (Och, 2003), our system is able to exploit large numbers of specific features in the same manner as static reranking systems (Shen et al. , 2004; Och et al. , 2004).",2,original
"1 Introduction The most widely applied training procedure for statistical machine translation IBM model 4 (Brown et al. , 1993) unsupervised training followed by post-processing with symmetrization heuristics (Och and Ney, 2003) yields low quality word alignments.",2,original
"1 Introduction Hierarchical approaches to machine translation have proven increasingly successful in recent years (Chiang, 2005; Marcu et al., 2006; Shen et al., 2008), and often outperform phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) on target-language fluency and adequacy.",2,original
"The size of the development set used to generate 1 and 2 (1000 sentences) compensates the tendency of the unsmoothed MERT algorithm to overfit (Och, 2003) by providing a high ratio between number of variables and number of parameters to be estimated.",2,original
"Unfortunately, longer sentences (up to 100 tokens, rather than 40), longer phrases (up to 10 tokens, rather than 7), two LMs (rather than just one), higher-order LMs (order 7, rather than 3), multiple higher-order lexicalized re-ordering models (up to 3), etc. all contributed to increased system?s complexity, and, as a result, time limitations prevented us from performing minimum-error-rate training (MERT) (Och, 2003) for ucb3, ucb4 and ucb5.",2,original
"3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with sure/possible annotations to compute; lacking such annotations, we can compute alignment fmeasure instead.",2,original
"While minimum error training (Och, 2003) has by now become a standard tool for interpolating a small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.",2,original
"When compared to other kernel methods, our approach performs better than those based on the Tree kernel (Collins and Duffy, 2002; Collins and Roark, 2004), and is only 0.2% worse than the best results achieved by a kernel method for parsing (Shen et al. , 2003; Shen and Joshi, 2004).",2,original
"Although generating training examples in advance without a working parser (Turian & Melamed, 2005) is much faster than using inference (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004), our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor.",2,original
"Although generating training examples in advance without a working parser (Sagae & Lavie, 2005) is much faster than using inference (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004), our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor.",2,original
"(2006) examine the FS of the weighted log-likelihood ratio (WLLR) on the movie review dataset and achieves an accuracy of 87.1%, which is higher than the result reported by Pang and Lee (2004) with the same dataset.",2,original
"The evaluation shows that our algorithm considerably outperforms (Cahill et al. , 2004)s with respect to Chinese data.",2,original
"As one can see in Table 4, the resulting parser ranks among the best lexicalized parsers, beating those of Collins (1999) and Charniak and Johnson (2005).8 Its F1 performance is a 27% reduction in error over Matsuzaki et al.",2,original
"While the model of (Matsuzaki et al. , 2005) significantly outperforms the constrained model of (Prescher, 2005), they both are well below the state-of-the-art in constituent parsing.",2,original
"Although several methods have already been proposed to incorporate non-local features (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al. , 2005; Roth and Yih, 2005; Krishnan and Manning, 2006; Nakagawa and Matsumoto, 2006), these present a problem that the types of non-local features are somewhat constrained.",2,original
"However, due to the lack of a fine grained NER tool at hand, we employ the Stanford NER package (Finkel et al., 2005) which identifies only four types of named entities.",2,original
"In a recent study by Finkel et al. , (2005), nonlocal information is encoded using an independence model, and the inference is performed by Gibbs sampling, which enables us to use a stateof-the-art factored model and carry out training efficiently, but inference still incurs a considerable computational cost.",2,original
"The simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like (Bunescu and Mooney, 2004) and (Finkel et al. , 2005).",2,original
"We also compare our performance against (Bunescu and Mooney, 2004) and (Finkel et al. , 2005) and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF.",2,original
"Although ITA rates and system performance both significantly improve with coarse-grained senses (Duffield et al., 2007; Navigli, 2006), the question about what level of granularity is needed remains.",2,original
"WSD systems have been far more successful in distinguishing coarsegrained senses than fine-grained ones (Navigli, 2006), but does that approach neglect necessary meaning differences?",2,original
"Sentence-level approximations to B exist (Lin and Och, 2004; Liang et al., 2006), but we found it most effective to perform B computations in the context of a setOof previously-translated sentences, following Watanabe et al.",2,original
"This latter point is a critical difference that contrasts to the major weakness of the work of (Liang et al. , 2006) which uses a top-N list of translations to select the maximum BLEU sentence as a target for training (so called local update).",2,original
"To our knowledge no systems directly address Problem 1, instead choosing to ignore the problem by using one or a small handful of reference derivations in an n-best list (Liang et al., 2006; Watanabe et al., 2007), or else making local independence assumptions which side-step the issue (Ittycheriah and Roukos, 2007; Tillmann and Zhang, 2007; Wellington et al., 2006).",2,original
"Both the global models (Liang et al., 2006; Watanabe et al., 2007) use fairly small training sets, and there is no evidence that their techniques will scale to larger data sets.",2,original
"Several studies have shown that large-margin methods can be adapted to the special complexities of the task (Liang et al., 2006; Tillmann and Zhang, 2006; Cowan et al., 2006) . However, the capacity of these algorithms to improve over state-of-the-art baselines is currently limited by their lack of robust dimensionality reduction.",2,original
"We have also illustrated that ASIA outperforms three other English systems (Kozareva et al., 2008; Pasca, 2007b; Snow et al., 2006), even though many of these use more input than just a semantic class name.",2,original
"We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al., 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%).",2,original
"However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al. , 2002; Wellington et al. , 2006).",2,original
"This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of (Cahill and van Genabith, 2006).",2,original
"In addition, uniform conditioning on mother grammatical function is more general than the case-phenomena specific generation grammar transform of (Cahill and van Genabith, 2006), in that it applies to each and every sub-part of a recursive input f-structure driving generation, making available relevant generation history (context) to guide local generation decisions.",2,original
"Even with the current incomplete set of semantic templates, the hypertagger brings realizer performance roughly up to state-of-the-art levels, as our overall test set BLEU score (0.6701) slightly exceeds that of Cahill and van Genabith (2006), though at a coverage of 96% insteadof98%.",2,original
"Our model improves the baseline provided by (Cahill and van Genabith, 2006): (i) accuracy is increased by creating a lexicalised PCFG grammar and enriching conditioning context with parent f-structure features; and (ii) coverage is increased by providing lexical smoothing and fuzzy matching techniques for rule smoothing.",2,original
"(2007) presented a history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation model of (Cahill and van Genabith, 2006).",2,original
"DeNero and Klein (2007) focus on alignment and do not present MT results, while May and Knight (2007) takesthesyntacticre-alignmentasaninputtoanEM algorithm where the unaligned target words are insertedintothetemplatesandminimumtemplatesare combinedintobiggertemplates(Galleyetal.,2006).",2,original
"13Huang and Chiang (2007) give an informal example, but do not elaborate on it.",2,original
"Although various approaches to SMT system combination have been explored, including enhanced combination model structure (Rosti et al., 2007), better word alignment between translations (Ayan et al., 2008; He et al., 2008) and improved confusion network construction (Rosti et al., 2008), most previous work simply used the ensemble of SMT systems based on different models and paradigms at hand and did not tackle the issue of how to obtain the ensemble in a principled way.",2,original
"In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment.",2,original
"2 Motivation and Prior Work While several authors have looked at the supervised adaptation case, there are less (and especially less successful) studies on semi-supervised domain adaptation (McClosky et al., 2006; Blitzer et al., 2006; Dredze et al., 2007).",2,original
"The combination is significantly better than (Shen et al., 2007) at a very high level, but more importantly, Shens results (currently representing the replicable state-of-the-art in POS tagging) have been significantly surpassed also by the semisupervised Morce (at the 99 % confidence level).",2,original
"In addition, the semi-supervised Morce performs (on single CPU and development data set) 77 times faster than the combination and 23 times faster than (Shen et al., 2007).",2,original
"Most recently, (Suzuki and Isozaki, 2008) published their Semi-supervised sequential labelling method, whose results on POS tagging seem to be optically better than (Shen et al., 2007), but no significance tests were given and the tool is not available for download, i.e. for repeating the results and significance testing.",2,original
"For comparison purposes, we revisit a fullygenerative Bayesian model for unsupervised coreference resolution recently introduced by Haghighi and Klein (2007), discuss its potential weaknesses and consequently propose three modifications to their model (Section 3).",2,original
Experimental results indicate that our model outperforms Haghighi and Kleins (2007) coreference model by a large margin on the ACE data sets and compares favorably to a modified version of their model.,2,original
"For comparison purposes, we revisit Haghighi and Kleins (2007) fully-generative Bayesian model for unsupervised coreference resolution, discuss its potential weaknesses and consequently propose three modifications to their model.",2,original
12Poon and Domingos (2008) outperformed Haghighi and Klein (2007).,2,original
"Our system improves over the latent named-entity tagging in Haghighi and Klein (2007), from 61% to 87%.",2,original
"Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches (Cherry and Bergsma, 2005; Haghighi and Klein, 2007) must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances.",2,original
"Thirdly, (Shen et al., 2008) deploys the dependency language model to augment the lexical language model probability be1183 tween two head words but never seek a full dependency graph.",2,original
"This is in direct contrast to recent reported results in which other filtering strategies lead to degraded performance (Shen et al., 2008; Zollmann et al., 2008).",2,original
"This provides a compelling advantage over previous dependency language models for MT (Shen et al., 2008),whichusea5-gramLMonlyduringreranking.",2,original
"In comparison, the 2D model in Figure 2(c) used in previous work (Ding et al., 2008) can only model the interaction between adjacent questions.",2,original
"Our graphical representation has two advantages over previous work (Ding et al., 2008): unifying sentence relations and incorporating question interactions.",2,original
"Previous work (Ding et al., 2008) performs the extraction of contexts and answers in multiple passes of the thread (with each pass corresponding to one question), which cannot address the interactions well.",2,original
"In addition, the performance of the adapted model for Joint S&T obviously surpass that of (Jiang et al., 2008), which achieves an F1 of 93.41% for Joint S&T, although with more complicated models and features.",2,original
"Previous literature on GB parsing /Wehrli, 1984; Sharp, 1985; Kashket, 1986; Kuhns, 1986; Abney, 1986/has not addressed the issue of implementation of the Binding theory) The present paper intends in part to fill this gap.",2,original
"Formal complexity analysis has not been carried out, but my algorithm is simpler, at least conceptually, than the variable-word-order parsers of Johnson (1985), Kashket (1986), and Abramson and Dahl (1989).",2,original
"Although the parser is not yet complete, we expect that its breath of coverage of the language will be substantially larger than that of other Government-binding parsers recently reported in the literature (Kashket (1986), Kuhns (1986), Sharp (1985), and Wehrli (1984)).",2,original
"Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues (Basili et al. 1991, 1993a; Hindle and Rooths 1991,1993; Sekine 1992) (Bogges et al. 1992), sense preference (Yarowski 1992), acquisition of selectional restrictions (Basili et al. 1992b, 1993b; Utsuro et al. 1993), lexical preference in generation (Smadjia 1991), word clustering (Pereira 1993; Hindle 1990; Basili et al. 1993c), etc. In the majority of these papers, even though the (precedent or subsequent) statistical processing reduces the number of accidental associations, very large corpora (10,000,000 words) are necessary to obtain reliable data on a ""large enough"" number of words.",2,original
"Our syntactic-relation-based thesaurus is based on the method proposed by Hindle (1990), although Hindle did not apply it to information retrieval.",2,original
"Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie (Hindle, 1990), although Hindle did not apply it to information retrieval.",2,original
"Regardless of whether it takes the form of dictionaries (Lesk 1986; Guthrie et al. 1991; Dagan, Itai, and Schwall 1991; Karov and Edelman 1996), thesauri (Yarowsky 1992; Walker and Amsler 1986), bilingual corpora (Brown et al. 1991; Church and Gale 1991), or hand-labeled training sets (Hearst 1991; Leacock, Towell, and Voorhees 1993; Niwa and Nitta 1994; Bruce and Wiebe 1994), providing information for sense definitions can be a considerable burden.",2,original
"Although previous work (Yarowsky, 1995; Blum and Mitchell, 1998; Abney, 2000; Zhang, 2004) has tackled the bootstrapping approach from both the theoretical and practical point of view, many key problems still remain unresolved, such as the selection of initial seed set.",2,original
"6 Conclusions In this paper, we showed that it is sometimes possible indeed, preferableto eliminate the initial bit of supervision in bootstrapping algorithms such as the Yarowsky (1995) algorithm for word sense disambiguation.",2,original
"Our experiments on the Canadian Hansards show that our unsupervised technique is significantly more effective than picking seeds by hand (Yarowsky, 1995), which in turn is known to rival supervised methods.",2,original
"Supervised approaches which make use of a small hand-labeled training set (Bruce and Wiebe, 1994; Yarowsky, 1993) typically outperform unsupervised approaches (Agirre et al. , 2000; Litkowski, 2000; Lin, 2000; Resnik, 1997; Yarowsky, 1992; Yarowsky, 1995), but tend to be tuned to a speci c corpus and are constrained by scarcity of labeled data.",2,original
"Unlike well-known bootstrapping approaches (Yarowsky, 1995), EM and CE have the possible advantage of maintaining posteriors over hidden labels (or structure) throughout learning; bootstrapping either chooses, for each example, a single label, or remains completely agnostic.",2,original
"Although a rich literature covers bootstrapping methods applied to natural language problems (Yarowsky, 1995; Riloff, 1996; Collins and Singer, 1999; Yangarber et al. , 2000; Yangarber, 2003; Abney, 2004) several questions remain unanswered when these methods are applied to syntactic or semantic pattern acquisition.",2,original
"However, our system is the unsupervised learning with small POS-tagged corpus,and we do not restrict the word's sense set within either binary senses(Yarowsky,1995; Karov, 1998) or dictionary's homograph level(Wilks, 1997).",2,original
"Bilexical context-free grammars have been presented in (Eisner and Satta, 1999) as an abstraction of language models that have been adopted in several recent real-world parsers, improving state-of-the-art parsing accuracy (A1shawl, 1996; Eisner, 1996; Charniak, 1997; Collins, 1997).",2,original
"These scores are higher than those of several other parsers (e.g. Collins 1997, 99; Charniak 1997), but remain behind tim scores of Charniak (2000) who obtains 90.1% LP and 90.1% LR for sentences _< 40 words.",2,original
"In order to capture the dependency relationship between lexcial heads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways.",2,original
"(2006) produced a corpus of 4,000 questions annotated with syntactic trees, and obtained an improvement in parsing accuracy for Bikels reimplementation of the Collins parser (Collins, 1997) by training a new parser model with a combination of newspaper and question data.",2,original
"(1999) applied the parser of Collins (1997) developed for English, to Czech, and found thatthe performance wassubstantially lower when compared to the results for English.",2,original
"In particular, the model in Collins (1997) failed to generate punctuation, a deficiency of the model.",2,original
"Another consequence of not generating posthead conjunctions and punctuation as first-class words is that they 19 In fact, if punctuation occurs before the head, it is not generated at alla deficiency in the parsing model that appears to be a holdover from the deficient punctuation handling in the model of Collins (1997).",2,original
(2005) have implemented a dependency parser with good accuracy (it is almost as good at dependency parsing as Charniak (2000)) and very impressive speed (it is about ten times faster than Collins (1997) and four times faster than Charniak (2000)).,2,original
"Section 5 presents an error analysis for Collinss (1997) lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra.",2,original
"However, such constructions prove to be difficult for stochastic parsers (Collins et al. , 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997).",2,original
"In general, these authors have found that existing lexicalized parsing models for English (e.g. , Collins 1997) do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English.",2,original
"This is well illustrated by the Collins parser (Collins, 1997; Collins, 1999), scrutinized by Bikel (2004), where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation.",2,original
"The 75.4% results may seen low compared to parsing results like the 88% precision and recall in (Collins, 1997), but those parsing results include many easier-to-parse constructs.",2,original
"three models in (Collins, 1997) are susceptible to the O(n 3) method (cf.",2,original
"Statistical disambiguation such as (Collins and Brooks, 1995) for PP-attachment or (Collins, 1997; Charniak, 2000) for generative parsing greatly improve disambiguation, but as they model by imitation instead of by understanding, complete soundness has to remain elusive.",2,original
"2.3 Collinss (Bikels) Parser Collinss statistical parser (CBP; (Collins, 1997)), improved by Bikel (Bikel, 2004), is based on the probabilities between head-words in parse trees.",2,original
"While these approaches have had som e success to date (Collins, 1997; Charniak, 1997a), their usability as parsers in systems for natural language understanding is suspect.",2,original
"Methods like McDonalds, including the wellknown Maximal Marginal Relevance (MMR) algorithm (Goldstein et al., 2000), are subject to another problem: Summary-level redundancy is not always well modeled by pairwise sentence-level redundancy.",2,original
Our study also shows that the simulated-annealing algorithm (Kirkpatrick et al. 1983) is more effective 1552 than the perceptron algorithm (Collins 2002) for feature weight tuning.,2,original
"However, work in that direction has so far addressed only parse reranking (Collins and Duffy, 2002; Riezler et al. , 2002).",2,original
"The generalized perceptron proposed by Collins (2002) is closely related to CRFs, but the best CRF training methods seem to have a slight edge over the generalized perceptron.",2,original
"At any rate, regularized conditional loglinear models have not previously been applied to the problem of producing a high quality part-of-speech tagger: Ratnaparkhi (1996), Toutanova and Manning (2000), and Collins (2002) all present unregularized models.",2,original
"Whereas Ratnaparkhi (1996) used feature support cutoffs and early stopping to stop overfitting of the model, and Collins (2002) contends that including low support features harms a maximum entropy model, our results show that low support features are useful in a regularized maximum entropy model.",2,original
"Moreover, the parameters of the model must be estimated using averaged perceptron training (Collins, 2002), which can be unstable.",2,original
"Collins (2000) and Collins and Duffy (2002) rerank the top N parses from an existing generative parser, but this kind of approach 1Dynamic programming methods (Geman and Johnson, 2002; Lafferty et al. , 2001) can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.",2,original
"While both (Johnson, 2001) and (Klein and Manning, 2002) propose models which use the parameters of the generative model but train to optimize a discriminative criteria, neither proposes training algorithms which are computationally tractable enough to be used for broad coverage parsing.",2,original
"Although such approaches have been employed effectively (Pang et al. , 2002), there appears to remain considerable room for improvement.",2,original
"A number of studies have investigated sentiment classification at document level, e.g., (Pang et al. , 2002; Dave et al. , 2003), and at sentence level, e.g., (Hu and Liu, 2004; Kim and Hovy, 2004; Nigam and Hurst, 2005); however, the accuracy is still less than desirable.",2,original
"Despite relying on a the same concept, our approach outperforms BE in most comparisons, and it often achieves higher correlations with human judgments than the string-matching metric ROUGE (Lin, 2004).",2,original
"In what concerns the evaluation process, although ROUGE (Lin, 2004) is the most common evaluation metric for the automatic evaluation of summarization, since our approach might introduce in the summary information that it is not present in the original input source, we found that a human evaluation was more adequate to assess the relevance of that additional information.",2,original
"We considered a variety of tools like ROUGE (Lin, 2004) and METEOR (Lavie and Agarwal, 2007) but decided they were unsuitable for this task.",2,original
"Although evaluated on a different test set, our method also outperforms the correlation with human scores reported in Liu and Gildea (2005).",2,original
"Our method, extending this line of research with the use of labelled LFG dependencies, partial matching, and n-best parses, allows us to considerably outperform Liu and Gildea?s (2005) highest correlations with human judgement (they report 0.144 for the correlation with human fluency judgement, 0.202 for the correlation with human overall judgement), although it has to be kept in mind that such comparison is only tentative, as their correlation is calculated on a different test set.",2,original
"In Owczarzak (2008), the method achieves equal or higher correlations with human judgments than METEOR (Banerjee and Lavie, 2005), one of the best-performingautomaticMTevaluationmetrics.",2,original
"To analyze our methods on IV and OOV words, we use a detailed evaluation metric than Bakeoff 2006 (Levow, 2006) which includes Foov and Fiv.",2,original
"2 Motivation and Prior Work While several authors have looked at the supervised adaptation case, there are less (and especially less successful) studies on semi-supervised domain adaptation (McClosky et al., 2006; Blitzer et al., 2006; Dredze et al., 2007).",2,original
"While SCL has been successfully applied to PoS tagging and Sentiment Analysis (Blitzer et al., 2006; Blitzer et al., 2007), its effectiveness for parsing was rather unexplored.",2,original
"HMM-smoothing improves on the most closely related work, the Structural Correspondence Learning technique for domain adaptation (Blitzer et al., 2006), in experiments.",2,original
"Again the best result was obtained with IOB1 (F~=I =92.37) which is an imI)rovement of the best reported F,~=1 rate for this data set ((Ramshaw and Marcus, 1995): 92.03).",2,original
"This time the chunker achieved a F~=l score of 93.81 which is half a point better than the results obtained by (Ramshaw and Marcus, 1995): 93.3 (other chunker rates for this data: accuracy: 98.04%; precision: 93.71%; recalh 93.90%).",2,original
"With all but two formats IBI-IG achieves better FZ=l rates than the best published result in (Ramshaw and Marcus, 1995).",2,original
"Type Precision Recall Fa=l Overall 96.40 96.47 96.44 NP 96.49 96.99 96.74 VP 97.13 97.36 97.25 ADJP 89.92 88.15 89.03 ADVP 91.52 87.57 89.50 97.13 97.36 PP 97.25 Table 16: Results of 25-fold cross-validation chunking experiments with the merged context-dependent lexicon Tables 14 and 16 shows that our new chunk tagger greatly outperforms other reported chunk taggers on the same training data and test data by 2%-3%.(Buchholz S. , Veenstra J. and Daelmans W.(1999), Ramshaw L.A. and Marcus M.P.(1995), Daelemans W. , Buchholz S. and Veenstra J.(1999), and Veenstra J.(1999)).",2,original
"For the Penn Treebank, (Ratnaparkhi, 1996) reports an accuracy of 96.6% using the Maximum Entropy approach, our much simpler and therefore faster HMM approach delivers 96.7%.",2,original
"As the tagger of Ratnaparkhi (1996) cannot tag a word lattice, we cannot back off to this tagging.",2,original
"Though taggers based on dependency networks (Toutanova et al. , 2003), SVM (Gimenez and M`arquez, 2003), MaxEnt (Ratnaparkhi, 1996), CRF (Smith et al. , 2005), and other methods may reach slightly better results, their train/test cycle is orders of magnitude longer.",2,original
"A maximum entropy approach has been applied to partof-speech tagging before (Ratnaparkhi 1996), but the approach's ability to incorporate nonlocal and non-HMM-tagger-type evidence has not been fully explored.",2,original
"Ratnaparkhi (1996: 134) suggests use of an approximation summing over the training data, which does not sum over possible tags: "" h E f j = 2 P( ~)p(ti l hi)f j(hi,ti) i=1 However, we believe this passage is in error: such an estimate is ineffective in the iterative scaling algorithm.",2,original
One conclusion that we can draw is that at present the additional word features used in Ratnaparkhi (1996) looking at words more than one position away from the current do not appear to be helping the overall performance of the models.,2,original
"Some are the result of inconsistency in labeling in the training data (Ratnaparkhi 1996), which usually reflects a lack of linguistic clarity or determination of the correct part of speech in context.",2,original
"Both Charniak (2000) and Bikel (2004) were trained using the goldstandard tags, as this produced higher accuracy on the development set than using Ratnaparkhi (1996)s tags.",2,original
"For unknown words, SCL gives a relative reduction in error of 19.5% over Ratnaparkhi (1996), even with 40,000 sentences of source domain training data.",2,original
"Lee and Kim (2015) have suggested a machine learning approach for text summarization, but its limitations in handling long documents remain unexplored.",2,new
"Chen et al. (2002) proposed a statistical model for predicting protein structure, yet its accuracy for membrane proteins has not been thoroughly evaluated.",2,new
"Although Liu and Wang (2018) presented a novel method for image classification, its performance on edge cases is still a topic of ongoing research.",2,new
"Despite the introduction of a new framework by Patel and Jain (2019), the issue of high computational cost remains unresolved.",2,new
"According to Zhang and Li (2001), a neural network-based solution for natural language processing has been proposed, but its scalability for large datasets is a significant concern.",2,new
"The research by Kim and Lee (2012) on sentiment analysis using deep learning has shown promise, but its applicability to real-world scenarios is yet to be demonstrated.",2,new
"Although a study by Taylor and Martin (2017) investigated the effectiveness of a new data compression algorithm, its impact on system performance is still being debated.",2,new
"A recent study by Davis and Patel (2015) introduced a new method for data visualization, but its limitations in representing complex relationships have not been fully addressed.",2,new
"Despite the development of a new statistical model by Hall and White (2003), the problem of data overfitting remains a significant challenge.",2,new
"A proposed solution by Lee and Kim (2019) for improving the efficiency of a specific algorithm has been presented, but its practical implementation is still in its infancy.",2,new
"Several methods for named entity recognition have been proposed, such as rule-based approaches (Grosjohan, 1998), machine learning algorithms (Riloff and Jones, 1999; McCallum and others, 1998), support vector machines (Crammer and Singer, 2001), and memory-based learning (Wu and others, 1997). However, all these techniques necessitate either extensive annotated training data (for supervised learning) or a comprehensive dictionary of all possible entities (for unsupervised learning).",2,new
"The development of various models for sentiment analysis has led to the creation of several methods, including statistical approaches (Turney, 2002), machine learning algorithms (Pang and Lee, 2004; Wiebe and others, 2005), and hybrid models (Baldi and Cardoso, 2003). However, all these approaches require either a substantial amount of labeled training data (for supervised learning) or a predefined sentiment lexicon (for unsupervised learning).",2,new
"The history of topic modeling has seen the emergence of several techniques, including latent semantic analysis (Deerwester et al., 1990), probabilistic latent semantic analysis (Hofmann, 1999), and non-negative matrix factorization (Lee and Seung, 2001). However, all these methods necessitate either a large corpus of text data (for supervised learning) or a pre-defined set of topics (for unsupervised learning).",2,new
"The field of speech recognition has witnessed the development of various techniques, such as dynamic programming (Levinson, 1986), hidden Markov models (Rabiner and Juang, 1993), and neural networks (Waibel and others, 1996). However, all these approaches require either a substantial amount of annotated audio data (for supervised learning) or a pre-defined set of acoustic models (for unsupervised learning).",2,new
"The creation of several models for machine translation has led to the emergence of various methods, including rule-based approaches (Kay and Roscheisen, 1997), statistical machine translation (Brown et al., 1993), and example-based machine translation (Brown and others, 1990). However, all these techniques necessitate either a large corpus of bilingual text data (for supervised learning) or a pre-defined set of translation rules (for unsupervised learning).",2,new
"The study of information retrieval has seen the development of several techniques, including vector space models (Salton and McGill, 1983),",2,new
"Our study shows that this novel methodology surpasses the traditional Naive Bayes classifier in accuracy for text classification tasks (Lewis, 1998; McCallum & Nigam, 1998; Rennie et al., 2003), suggesting its potential for broader applications.",2,new
"The proposed framework outperforms the standard Support Vector Machine approach in sentiment analysis (Pang & Lee, 2004; Turney, 2002; Hu & Liu, 2004), indicating its potential for real-world impact.",2,new
"In comparison to the baseline Decision Tree algorithm, our results indicate that this technique excels in predictive modeling (Quinlan, 1986; Breiman et al., 1984; Murthy, 1998), opening up new avenues for research.",2,new
"Our experiment demonstrates that this innovative technique can outperform the conventional K-Means clustering algorithm in data mining (MacQueen, 1967; Hartigan, 1975; Jain & Dubes, 1988), revealing its potential for improved data analysis.",2,new
"The findings of this study reveal that this approach is superior to the standard Random Forest model in regression tasks (Breiman, 2001; Ho, 1995; Amit & Geman, 1997), highlighting its potential for real-world applications.",2,new
"Our research shows that this methodology surpasses the traditional Gradient Boosting Machine in time series forecasting (Friedman, 2001; Hastie et al., 2001; Chen et al., 2006), suggesting its potential for improved prediction accuracy.",2,new
"In comparison to the baseline neural network, our results indicate that this technique excels in image classification (LeCun et al., 1998; Yann LeCun et al., 1998; Bengio et al., 2007), opening up new possibilities for computer vision research.",2,new
"The results of this study demonstrate that this approach is superior to the standard k-Nearest Neighbors algorithm in anomaly detection (Cover & Hart, 1967; Dasarathy, 1991; Knerr et al., 1990), highlighting its potential for improved security applications.",2,new
"Our experiment shows that this innovative technique can outperform the traditional Logistic Regression model in recommendation systems (Resnick et al., 1994; Breese et al., 1998; Herlocker et al., 2004), revealing its potential for improved personalized recommendations.",2,new
The findings of this research reveal that this approach is superior to the standard Expectation-M,2,new
"Previous studies have focused on the application of contextualized word embeddings, but few have explored the relationship between semantic similarity and contextualized word representations (Bengio et al., 2003; Mikolov et al., 2013; Pennington et al., 2014; Le and Mikolov, 2014; Goldberg and Levy, 2014).",2,new
"While various studies have utilized word embeddings for sentiment analysis, none have examined the impact of embedding dimensionality on model performance (Turney, 2002; Nakagawa and Mori, 2002; Klinger et al., 2013; Wang et al., 2012; Glorot et al., 2011).",2,new
"Several papers have investigated the use of neural networks for natural language processing, but have not explored the effects of network architecture on task accuracy (Rumelhart et al., 1986; LeCun et al., 1998; Hinton et al., 2006; Collobert et al., 2008; Seide et al., 2011).",2,new
"Despite the growing interest in deep learning for NLP, few studies have looked into the role of regularization techniques in improving model generalizability (Bengio et al., 2006; Srivastava et al., 2014; Ma et al., 2015; Xu et al., 2015; Kim et al., 2015).",2,new
"Many researchers have applied word embeddings to machine translation, but have not examined the relationship between embedding quality and translation accuracy (Brown et al., 1990; Koehn and Knight, 2003; Zou et al., 2009; Bahdanau et al., 2014; Vaswani et al., 2017).",2,new
"Previous research has focused on the application of reinforcement learning in NLP, but has not explored the impact of reward functions on learning efficiency (Sutton and Barto, 1998; Mnih et al., 2013; Mnih et al., 2015; Silver et al., 2016; Wang et al., 2016).",2,new
"While various studies have utilized dependency parsing for sentiment analysis, none have examined the relationship between parse tree complexity and model performance (Marneffe et al., 2006; McDonald et al., 2005; Nivre et al., 2006; Sag et al., 2003; Kubler et al., 2009).",2,new
Several papers,2,new
"The proposed approach outperformed existing techniques, such as the semantic role labeling method suggested in (Gildea & Jurafsky, 2002), by incorporating more comprehensive context from the domain ontology, providing a more nuanced understanding of the relationships between entities.",2,new
"In contrast to other methods, like the one presented in (Baker et al., 1998), this technique excels in handling complex syntactic dependencies, resulting in a more accurate parsing of the input data.",2,new
"When compared to the method outlined in (Leacock et al., 1998), our approach demonstrated superior performance in retaining the semantic consistency of the input text, even with varying sentence structures.",2,new
"The current method surpasses other techniques, such as the one described in (Brown et al., 1990), by effectively capturing long-range semantic dependencies, leading to a more coherent representation of the input data.",2,new
"Compared to the approach introduced in (Chen & Manning, 1999), our method yields better results in capturing the subtle nuances of semantic relationships, particularly in cases of polysemy and homonymy.",2,new
"The proposed technique outshines the method presented in (Collins, 1999) by providing a more robust handling of semantic ambiguity, resulting in a more accurate representation of the input text.",2,new
"Our approach outperforms other methods, such as the one discussed in (Church, 1988), by effectively leveraging the structural properties of the input data to improve semantic understanding.",2,new
"In comparison to the method outlined in (Hindle, 1990), this technique excels in capturing the semantic implications of idiomatic expressions, leading to a more comprehensive understanding of the input text.",2,new
"The current method surpasses the approach described in (Levin, 1993) by providing a more detailed representation of semantic roles, resulting in a more accurate parsing of the input data.",2,new
"Our technique outperforms other techniques, such as the one presented in (McDonald et al., 2006), by effectively handling the nuances of semantic relationships in the input text, even in cases of high ambiguity.",2,new
"A possible limitation of the Vector Space Model (Deerwester et al., 1990) is its susceptibility to noise in word embeddings.",2,new
"The reliance on shallow parsing in the Lexical Functional Grammar (LFG) framework (Bresnan, 2001) can lead to inaccuracies in semantic role labeling.",2,new
"A major drawback of the dependency parser in the Stanford Parser (Klein & Manning, 2003) is its sensitivity to out-of-vocabulary words.",2,new
"The use of heuristics in the Maximum Entropy Markov Model (MAXENT) (Berger et al., 1996) can result in suboptimal parsing decisions.",2,new
"The application of the HPSG framework (Pollard & Sag, 1994) can be hindered by its complexity and computational requirements.",2,new
"The lack of contextual information in the Word2Vec model (Mikolov et al., 2013) can lead to poor performance in tasks requiring nuanced understanding.",2,new
A potential shortcoming of the Part-of-Speech Tagging model by Brill (1995) is its limited ability to handle out-of-domain data.,2,new
"The reliance on rule-based approaches in the Head-Driven Phrase Structure Grammar (HPSG) (Pollard & Sag, 1994) can lead to inflexibility in handling ambiguous sentences.",2,new
"The use of the Naive Bayes classifier in the Named Entity Recognition (NER) task (Ratinov & Roth, 2009) can be hindered by its assumption of independence among features.",2,new
"A major limitation of the Hidden Markov Model (HMM) in speech recognition (Rabiner, 1989) is its sensitivity to noise and variability in acoustic signals.",2,new
The proposed approach by Johnson et al. (2015) lacks a clear extension to the case of multiple interacting agents.,2,new
"Unfortunately, the method of Davis and Lee (2012) does not directly translate to the scenario of dynamic network analysis.",2,new
A major limitation of the model of Brown et al. (2009) is its inability to generalize to systems with varying parameter values.,2,new
The findings of Chen and Patel (2018) cannot be directly applied to the context of non-linear dynamics.,2,new
It is unclear how the framework of Kim et al. (2011) can be adapted to address the issue of data sparsity.,2,new
The work of Rodriguez and Taylor (2016) has significant limitations when dealing with high-dimensional data.,2,new
"Unfortunately, the approach of White and Martin (2013) is not directly applicable to the problem of multi-objective optimization.",2,new
A major drawback of the method of Hall and Kim (2014) is its poor performance in the presence of noise.,2,new
The results of Lee and Kim (2017) do not provide a clear solution to the problem of time-series prediction.,2,new
The application of the model of Taylor and White (2010) to the field of image processing is severely restricted due to its limitations.,2,new
"In contrast to the findings of Smith (2012), who reported a peak in efficiency at a value of 0.75, our results indicate a consistent decrease in efficiency as  approached 0.",2,new
"Contrary to the results of Lee et al. (2015), which showed a maximum in accuracy at a threshold of 0.42, we observed a steady decline in accuracy as  decreased.",2,new
"Unlike the study by Davis (2009), which found an optimal solution at a cost of 500, our findings suggest a linear increase in cost as  rose.",2,new
"In contrast to the research of Patel (2010), which reported a maximum yield at a temperature of 25C, our results demonstrate a continuous decrease in yield as temperature increased.",2,new
"Unlike the study by Brown et al. (2018), which found a peak in performance at a sample size of 100, our results indicate a monotonic decrease in performance as sample size increased.",2,new
"Contrary to the findings of Taylor (2011), which showed a minimum in time required at a speed of 10 m/s, we observed a steady increase in time required as speed decreased.",2,new
"Unlike the research of Martin (2008), which found an optimal result at a distance of 50 km, our results suggest a linear increase in time required as distance increased.",2,new
"In contrast to the study by Kim et al. (2016), which reported a maximum in quality at a concentration of 0.05 M, our findings demonstrate a continuous decrease in quality as concentration increased.",2,new
"Unlike the findings of White (2006), which showed a peak in efficiency at a voltage of 12 V, our results indicate a monotonic decrease in efficiency as voltage increased.",2,new
"Contrary to the results of Chen et al. (2013), which found a minimum in cost at a volume of 100 L, our results suggest a steady increase in cost as volume increased.",2,new
"Due to the limited access to the experimental setup of (Kim et al., 2019), our study was unable to replicate their findings with the same level of accuracy.",2,new
"The lack of open-source code in (Taylor et al., 2015) hindered our ability to implement their algorithm with the modifications required for our analysis.",2,new
"Unfortunately, the proprietary nature of the dataset used in (Lee et al., 2020) prevented us from conducting a thorough evaluation of their proposed method.",2,new
"We were unable to verify the results of (Patel et al., 2018) due to the unavailability of their raw data for independent analysis.",2,new
"The absence of a publicly accessible control group in (Brown et al., 2012) made it challenging to assess the efficacy of their treatment.",2,new
"Our investigation was limited by the lack of information provided in (Davis et al., 2016) on their sampling procedure.",2,new
"We were unable to replicate the results of (Huang et al., 2017) due to the proprietary nature of their software.",2,new
"The lack of a clear description of the experimental protocol in (Peters et al., 2013) made it difficult for us to reproduce their study.",2,new
"The unavailability of the survey instrument used in (Wong et al., 2014) restricted our ability to validate their conclusions.",2,new
"Due to the limited availability of the computational resources required by (Liu et al., 2015), our analysis was unable to achieve the same level of resolution as their study.",2,new
"Our proposed method not only surpassed the challenging baseline but also rivaled the efficacy of the approach presented in (Zhang et al., 2019), without necessitating their large-scale external datasets.",2,new
"Unlike previous studies (Kumar et al., 2015), our novel approach outperformed the benchmark, while also avoiding the need for their proprietary software tools.",2,new
"Our algorithm not only outdid the state-of-the-art baseline but also matched the results of the method described in (Lee et al., 2012), without relying on their costly hardware resources.",2,new
"In contrast to the methods proposed in (Patel et al., 2018), our approach not only exceeded the performance of the baseline but also circumvented the requirement for their specialized laboratory equipment.",2,new
"The results of our study demonstrated that our technique not only outperformed the established benchmark but also paralleled the outcomes of the research conducted by (Kim et al., 2016), without necessitating their extensive computational resources.",2,new
"Our innovative method not only outdid the notoriously difficult baseline but also rivaled the efficacy of the approach presented in (Wang et al., 2017), without requiring their time-consuming data preprocessing steps.",2,new
"Unlike the approaches discussed in (Gupta et al., 2013), our novel approach outperformed the benchmark, while also avoiding the need for their costly data annotation services.",2,new
"Our study showed that our method not only outperformed the baseline but also matched the results of the method described in (Chen et al., 2014), without relying on their large-scale experimental setup.",2,new
"The findings of our research demonstrated that our approach not only outdid the challenging baseline but also paralleled the outcomes of the research conducted by (Huang et al., 2015), without necessitating their complex software frameworks.",2,new
"Our proposed technique not only outperformed the established benchmark but also rivaled the efficacy of the approach presented in (Singh et al., 2019), without requiring their high-performance computing infrastructure.",2,new
"Our proposed approach demonstrates superior performance compared to the methodology employed by Kowalski and May (2012), which relies heavily on lexical analysis.",2,new
"In contrast to the framework presented by Lee and Kim (2015), our novel approach yields more accurate results, showcasing its efficacy in sentiment analysis tasks.",2,new
"We observe that our method outshines the one developed by Brown and colleagues (2010), which utilizes a combination of rule-based and machine learning techniques.",2,new
"Notably, our proposed algorithm surpasses the performance of the method described by Kim and Park (2018), which utilizes a shallow parsing approach.",2,new
"In a comparative study, we found that our approach outperforms the methodology of Chen and Liu (2014), which relies on a Naive Bayes classifier.",2,new
"Our results indicate that the proposed method excels in sentiment analysis when compared to the approach of Patel and Jain (2016), which uses a decision tree-based framework.",2,new
"A notable advantage of our method is its ability to outperform the methodology of Davis and Wilson (2013), which employs a combination of supervised and unsupervised learning.",2,new
"We observe that our proposed model yields more accurate results than the approach of Kim and Lee (2019), which utilizes a deep learning-based architecture.",2,new
"In comparison to the method developed by Lee and Kim (2017), our approach demonstrates superior performance in sentiment analysis tasks, particularly in handling nuanced language.",2,new
"Our research indicates that the proposed method outperforms the methodology of Brown and Davis (2011), which relies on a combination of rule-based and machine learning techniques.",2,new
"Although the current dataset of annotated examples is significantly smaller than the benchmark set proposed by Brown et al. (2018), it still serves as a valuable resource for training NLP models.",2,new
"In comparison to the comprehensive database of Charniak and Johnson (2005), our gazetteer is limited in scope but remains a useful starting point for linguistic research.",2,new
"The present study's sample size is notably smaller than the extensive corpus compiled by Manning and Schtze (1999), yet it provides a focused examination of the phenomenon in question.",2,new
"Despite being smaller than the large-scale ontology developed by Navigli et al. (2003), our taxonomy offers a more streamlined and easily accessible classification system.",2,new
"Although the current implementation lacks the extensive coverage of the system designed by Grishman and Sundheim (1996), it demonstrates a clear understanding of the underlying principles.",2,new
"The proposed algorithm's performance is inferior to the state-of-the-art model presented by Collobert et al. (2011), but it showcases innovative techniques for handling complex tasks.",2,new
"The current results are less comprehensive than the detailed analysis of the data by Jurafsky and Martin (2000), but they highlight the importance of careful data selection.",2,new
"Although our approach is less sophisticated than the method employed by Collins (1999), it remains a viable option for practitioners seeking a straightforward solution.",2,new
"The present study's findings are not as robust as the extensive study by Vapnik (1998), but they contribute to the ongoing discussion in the field.",2,new
"Compared to the large-scale evaluation by Manning et al. (1999), our experiment is smaller in scope, but it provides valuable insights into the efficacy of the proposed method.",2,new
"Our analysis reveals that the lightweight approach of JESS-ML, in comparison to the complex architecture of the original model, yields improved results, with precision rates of 92.12 and 85.19 for CoNLL00 and 03 data, respectively, surpassing the performance reported in (Kim et al., 2015) by 0.21 and 0.62 points.",2,new
"Despite its streamlined design, the modified model, JESS-EM, demonstrates enhanced F-scores of 96.03 and 89.02 for CoNLL00 and 03 data, respectively, representing a notable improvement of 1.13 and 0.87 points over the results presented in (Lee et al., 2018).",2,new
"Notably, the simplified implementation of JESS-MM, in contrast to the intricate model structure, achieves F-scores of 93.21 and 87.45 for CoNLL00 and 03 data, respectively, outperforming the outcomes in (Peng et al., 2012) by 0.28 and 0.55 points.",2,new
"In contrast to the complex model architecture, the streamlined JESS-DM delivers precision rates of 91.59 and 84.19 for CoNLL00 and 03 data, respectively, which are 0.35 and 0.71 points higher than those documented in (Tanaka et al., 2010).",2,new
"Our results indicate that the modified model, JESS-HM, provides F-scores of 95.61 and 90.13 for CoNLL00 and 03 data, respectively, exceeding the performance reported in (Wang et al., 2019) by 1.02 and 0.53 points.",2,new
"The lightweight approach of JESS-AM, as opposed to the original model's complexity, yields precision rates of 90.81 and 83.59 for CoNLL00 and 03 data, respectively, surpassing the results in (Yoon et al., 2016) by 0.29 and 0.49 points.",2,new
"Notably, JESS-LM's simplified design results in F-scores of 94.89 and 88.55 for CoNLL00 and 03 data, respectively, outperforming the outcomes in (Zhang et al., 2014) by 0.34 and 0.73 points.",2,new
"In contrast to the intricate model architecture, the streamlined JESS-GM",2,new
"Despite the growing interest in machine learning, the application of these techniques to NLP tasks has not always yielded consistent results (Bengio et al., 2003).",2,new
"Recent studies on deep learning models have shown promise, but the lack of clear evaluation metrics has hindered progress in the field (LeCun et al., 2015).",2,new
"Although significant advances have been made in NLP in recent years, the lack of standardization in data preprocessing remains a major challenge (Grefenstette, 2013).",2,new
"Despite the development of various natural language processing techniques, the task of sentiment analysis remains a difficult problem (Pang & Lee, 2008).",2,new
"The increasing use of big data has led to the development of new methods for text analysis, but the need for robust evaluation metrics has not been adequately addressed (Kirkpatrick et al., 2011).",2,new
"While the field of NLP has seen significant growth, the lack of clear guidelines for model evaluation has hindered the comparison of different approaches (Carrasco-Cabrera et al., 2017).",2,new
"The application of machine learning to NLP has shown some success, but the need for more nuanced understanding of the underlying mechanisms remains a significant challenge (Bottou & Montague, 2011).",2,new
"Although various methods have been proposed for text classification, the lack of a standardized evaluation framework has limited the advancement of the field (Joachims, 2002).",2,new
"The development of new NLP techniques has been rapid, but the need for more rigorous testing and evaluation has not been adequately addressed (Golding & Elliott, 1997).",2,new
"Despite the growing importance of NLP in many applications, the lack of clear benchmarks for model evaluation has hindered the development of more effective methods (Granger, 1999).",2,new
The proposed model's classification accuracy in this study is marginally lower than the results obtained by Agarwal and Dhar (2014).,2,new
"Although the new algorithm performs well, its reliance on shallow linguistic features is less robust than the deep learning approach employed by Collobert et al. (2011).",2,new
"In contrast to the findings of Jurgens and Ruhmann (2017), our analysis reveals that the data preprocessing step has a more significant impact on the overall model performance.",2,new
The results of our experiment indicate that the suggested method is less effective than the well-established technique described by Manning and Schtze (1999).,2,new
The automatically generated patterns in our system are less specific than the hand-crafted features developed by Liu et al. (2009).,2,new
"Compared to the results of the state-of-the-art model by Kim et al. (2016), our approach has a lower recall rate.",2,new
Our study shows that the novel technique is less accurate than the conventional method described by Brown et al. (1992).,2,new
"The proposed method's results are not as strong as the findings of the study by Hassan and Kowalski (2011), which achieved better precision.",2,new
The outcomes of our analysis suggest that the new algorithm is less efficient than the optimized technique developed by Chen et al. (2015).,2,new
The generated patterns in our system are less comprehensive than the manually curated features used by Ramrez et al. (2018).,2,new
"The implementation of sentiment analysis in Affective Norms for English Words (ANEW) (Bradley & Lang, 1999) is more sophisticated than in SenticNet (Balahur & Mihalcea, 2012).",2,new
"The feature extraction in TextRank (Mihalcea & Tarau, 2004) is more sophisticated than in the graph-based approach proposed by Wang et al. (2013).",2,new
"The named entity recognition in Stanford CoreNLP (Manning et al., 2014) is more sophisticated than in the rule-based approach used by Yangarber et al. (2001).",2,new
"The clustering in K-Means (MacQueen, 1967) is more sophisticated than in Hierarchical Agglomerative Clustering (Johnson, 1967).",2,new
"The object detection in YOLO (Redmon et al., 2016) is more sophisticated than in R-CNN (Girshick et al., 2014).",2,new
"The topic modeling in Latent Dirichlet Allocation (Blei et al., 2003) is more sophisticated than in Non-Negative Matrix Factorization (Lee & Seung, 2001).",2,new
"The machine translation in Google Translate (Wu et al., 2016) is more sophisticated than in the rule-based approach used by Kittredge & Lehrberger (1982).",2,new
"The spam detection in Naive Bayes (Domingos & Pazzani, 1997) is more sophisticated than in the decision tree-based approach proposed by Quinlan (1993).",2,new
"The information retrieval in BM25 (Robertson & Walker, 1994) is more sophisticated than in the vector space model used by Salton & McGill (1983).",2,new
"The recommender system in Matrix Factorization (Koren et al., 2009) is more sophisticated than in the content-based approach proposed by Pazzani & Billsus (1997).",2,new
"The author's use of regression analysis, although a common statistical technique, was deemed inappropriate for this study due to its limitations in accounting for non-linear relationships (Bartlett, 1937).",2,new
"3However, the proposed machine learning approach, while touted as an innovative solution, was not implemented in this study due to its high computational requirements and potential for overfitting (Mitchell, 1997).",2,new
"Although the inclusion of sentiment analysis was considered, it was ultimately excluded from the study due to its susceptibility to noise and the risk of biased results (Turney, 2002).",2,new
"The incorporation of clustering algorithms, although potentially useful for data visualization, was not explored further due to their high computational complexity and the need for large datasets (Everitt, 1977).",2,new
"The author's decision to focus on correlation analysis, while a fundamental statistical technique, was made with caution due to its inability to establish causality and the risk of spurious relationships (Yule, 1926).",2,new
"The use of decision trees, although a popular machine learning method, was not employed in this study due to its tendency to overfit the data and the risk of poor generalizability (Breiman, 2001).",2,new
"Although the inclusion of natural language processing techniques was considered, it was ultimately not pursued due to the high cost of computational resources and the need for large amounts of training data (Jurafsky and Martin, 2000).",2,new
"The author's reliance on descriptive statistics, while providing a broad overview of the data, was limited in its ability to provide insights into the underlying mechanisms (Freedman et al., 2007).",2,new
"The exclusion of principal component analysis, although a powerful dimensionality reduction technique, was made due to its sensitivity to the choice of parameters and the risk of losing important information (Jolliffe, 1986).",2,new
"The use of bootstrap resampling, although a useful technique for estimating variability, was not employed in this study due to its high computational requirements and the risk of overestimating precision (Efron and Tibshirani, 1993).",2,new
"The study by Lee et al. (2015) suggested employing statistical models to predict protein structures; nonetheless, these models often fail to accurately capture the complexities of non-redundant protein sequences.",2,new
"Although the technique proposed by Kim and Kim (2002) for detecting anomalies in network traffic showed promise, it may not be effective for high-traffic networks due to its computational limitations.",2,new
"In their paper, Thompson et al. (1998) introduced a new method for identifying gene expressions; however, the approach has been criticized for its inability to handle noisy data.",2,new
"Despite the efforts by Chen et al. (2018) to develop a more efficient algorithm for solving complex optimization problems, the method still requires significant computational resources.",2,new
"The research by Patel et al. (2001) on machine learning techniques for image classification showed some success; yet, the models often fail to generalize to new, unseen data.",2,new
"The study by Brown et al. (1990) proposed using Hidden Markov Models for speech recognition; unfortunately, the method is prone to errors in noisy environments.",2,new
"Although the work by Lee and Kim (2010) on data compression techniques showed promising results, the method may not be suitable for compressing large datasets.",2,new
"In their paper, Johnson et al. (2005) introduced a new technique for natural language processing; however, the approach has limitations in handling out-of-vocabulary words.",2,new
"The research by Davis et al. (2012) on network security showed some potential; yet, the methods proposed are not effective against advanced cyber attacks.",2,new
"The study by Martin et al. (1995) suggested using neural networks for pattern recognition; unfortunately, the method is not robust to overfitting.",2,new
"Unlike previous studies by Miller and Chomsky (1956), our research delves into more complex linguistic phenomena, such as multi-word expressions.",2,new
"In contrast to the simplified approach of Fillmore (1968), our analysis focuses on the nuances of idiomatic expressions and their semantic relationships.",2,new
"Unlike the narrow scope of Zellig Harris's (1952) work, our study explores the broader context of phrasal verbs and their grammatical implications.",2,new
"Unlike the constraints of the ""one-word"" paradigm proposed by Hockett (1958), our research considers the intricate structures of compound predicates.",2,new
"Contrary to the binary classification system of Katz and Fodor (1963), our methodology incorporates a more detailed categorization of phrasal verbs based on their syntactic properties.",2,new
"Unlike the static approach of Firth (1957), our dynamic model accounts for the evolving nature of language and its impact on phrasal verb usage.",2,new
"Unlike the emphasis on individual words in the work of Harris (1951), our research highlights the importance of context in shaping the meaning of phrasal verbs.",2,new
"Unlike the limited focus of Chafe (1970), our study examines the role of phrasal verbs in various linguistic theories and their implications for language acquisition.",2,new
"In contrast to the simplistic model of Katz and Fodor (1963), our research develops a more sophisticated framework for analyzing the syntax and semantics of phrasal verbs.",2,new
"Unlike the restrictive framework of Hockett (1958), our approach considers the variability and adaptability of phrasal verbs in different linguistic environments.",2,new
"The proposed technique demonstrated a substantial improvement over the model presented in (Johnson et al., 2005), suggesting that it can yield more accurate classification results.",2,new
"This novel approach outperformed the existing framework outlined in (Smith et al., 2010), indicating its potential to identify more precise patterns in the data.",2,new
"The methodology described in this study proved superior to the one introduced in (Lee et al., 2012), allowing for more effective data analysis.",2,new
"The results of this investigation revealed that the proposed method surpassed the benchmark established by (Davis et al., 1999), showing its ability to uncover more relevant insights.",2,new
"In comparison to the technique presented in (Hall et al., 2003), the method outlined in this paper exhibited greater efficiency and accuracy.",2,new
"The findings of this research showed that the developed approach outshone the method proposed in (Kim et al., 2008), providing a more comprehensive understanding of the phenomenon under investigation.",2,new
"This study demonstrated that the suggested approach excelled the technique described in (Taylor et al., 2015), enabling the discovery of more nuanced relationships in the data.",2,new
"In contrast to the framework introduced in (Patel et al., 2011), the methodology presented in this paper achieved superior performance and precision.",2,new
"The proposed technique was found to outperform the model developed in (Wong et al., 2001), indicating its potential to uncover more detailed information.",2,new
"This research showed that the developed method surpassed the approach outlined in (Chen et al., 2006), allowing for more accurate predictions and conclusions.",2,new
"In contrast to traditional machine learning approaches (e.g., \[Smith et al., 2010\]), which often rely on complex algorithms that are challenging to interpret.",2,new
"Unlike purely computational models (e.g., \[Johnson et al., 2005\]), our approach allows for a more transparent and modifiable framework.",2,new
"This is in contrast to data-driven methods (e.g., \[Williams et al., 1995\]), which can be difficult to adjust and refine in real-world applications.",2,new
"Unlike purely theoretical models (e.g., \[Davis et al., 2001\]), our approach offers a more practical and applicable solution.",2,new
"In contrast to purely rule-based systems (e.g., \[Miller et al., 2015\]), our approach provides a more flexible and adaptive framework.",2,new
"Unlike traditional knowledge-based systems (e.g., \[Taylor et al., 2009\]), our approach allows for a more dynamic and responsive architecture.",2,new
"This is in contrast to purely symbolic models (e.g., \[Harris et al., 2003\]), which can be difficult to implement and maintain.",2,new
"Unlike purely data-intensive approaches (e.g., \[Walker et al., 2012\]), our approach prioritizes interpretability and modifiability.",2,new
"In contrast to purely model-based systems (e.g., \[Martin et al., 2007\]), our approach emphasizes a more human-centered design.",2,new
"Unlike purely optimization-based methods (e.g., \[Brown et al., 1992\]), our approach focuses on a more intuitive and user-friendly interface.",2,new
"However, we found that the adoption of a (JJ, JJ) 5approach by Smith et al. (2018) did not significantly improve the model's performance.",2,new
"Notably, the use of a hybrid (NN) 3method, as proposed by Johnson and Williams (2001), did not yield the desired results in our experiment.",2,new
"In contrast to the findings of Lee et al. (2015), who suggested using a (JJ) 6machine learning algorithm, we discovered that a rule-based approach was more effective in our study.",2,new
"Unfortunately, the implementation of a (NN) 2framework by Davis and Thompson (1999) did not lead to the expected improvements in our research.",2,new
"Our results show that the use of a (JJ, JJ) 8approach, as described in the work of Taylor et al. (2003), was not beneficial in our case.",2,new
"Conversely, the (NN) 1approach by Martin and Patel (2007) was not as successful in our experiment as we had anticipated.",2,new
It is worth noting that the (JJ) 4method proposed by Brown and Hall (2000) did not demonstrate the desired outcomes in our study.,2,new
"In our investigation, the (JJ, JJ) 9method, as outlined by White and Lee (2012), did not provide the expected results.",2,new
The adoption of a (NN) 4framework by Kim et al. (2008) did not yield the anticipated improvements in our research.,2,new
"Unlike the findings of Patel and Martin (2011), who suggested using a (JJ) 7approach, we found that a (JJ) 5approach was more effective in our study.",2,new
"The proposed neural network architecture, despite its complexity, falls short in capturing the subtleties of linguistic nuances due to its reliance on shallow linguistic features (Bengio et al., 2003).",2,new
"The application of traditional machine learning algorithms, such as decision trees and random forests (Breiman, 2001), to predict protein structures is limited by their inability to incorporate structural information (Kabsch, 1976).",2,new
"Although the authors employed advanced techniques like spectral clustering, the results are marred by the oversimplification of complex relationships between gene expressions (Eisen et al., 1998).",2,new
"The use of classical sequence alignment methods, such as Needleman-Wunsch and Smith-Waterman (Needleman & Wunsch, 1970), fails to account for the intricacies of genomic variability (Muller et al., 2008).",2,new
"The model's inability to generalize beyond the training data is largely due to the reliance on superficial linguistic patterns rather than deeper semantic meaning (Hofmann, 1999).",2,new
"The study's conclusion is undermined by the inadequate representation of long-range dependencies in the sentence structures (Sedgewick, 1998).",2,new
"The application of traditional statistical techniques, such as linear regression and ANOVA (Bartlett, 1937), to analyze gene expression data is hampered by their failure to capture non-linear relationships (Tusher et al., 2001).",2,new
"The authors' attempts to incorporate domain knowledge into the model are hindered by the lack of a robust semantic representation of the underlying domain (Hirst & St. Onge, 1999).",2,new
"The reliance on shallow linguistic features, such as part-of-speech tagging and named entity recognition, limits the model's ability to capture the complexities of human language (Lafferty et al., 2001).",2,new
"The use of traditional machine learning algorithms, such as support vector machines and k-nearest neighbors, is insufficient for modeling the nuances of human behavior due to their inability to capture contextual information (Cover & Thomas, 1991).",2,new
"Our approach is a natural progression from the frameworks introduced in (Kumar et al., 2010) and (Wang and Lee, 2015), addressing their limitations while preserving their core principles.",2,new
"Building upon the groundwork laid by (Johnson and Taylor, 1988) and (Martin and White, 2000), our technique improves upon their methods and expands their scope.",2,new
"The development of our model is rooted in the foundational research of (Davis and Smith, 2002) and (Harris and Thompson, 2003), and our solution rectifies their shortcomings while maintaining their effectiveness.",2,new
"Our contribution is a logical extension of the theories proposed in (Lee and Kim, 2004) and (Patel and Jain, 2005), offering a more comprehensive solution to the existing challenges.",2,new
"Our approach is an evolution of the ideas presented in (Chen and Brown, 2012) and (Kim and Lee, 2013), which we have enhanced and adapted to better suit the current needs.",2,new
"Our methodology is a refinement of the concepts introduced in (Hall and Martin, 1998) and (Parker and Davis, 1999), addressing their drawbacks and providing a more robust framework.",2,new
"The present study is a natural outgrowth of the research conducted by (Wong and Li, 2001) and (Hall and Kim, 2002), and our results build upon their findings to offer a more detailed understanding.",2,new
"Our method is an extension of the models proposed in (Garcia and Rodriguez, 2007) and (Thomas and Patel, 2008), and we have successfully mitigated their limitations to provide a more reliable outcome.",2,new
"Our approach is a logical progression from the theories presented in (Nguyen and Tran, 2009) and (Liu and Chen, 2011), which we have expanded and refined to better tackle the existing issues.",2,new
"Our research is an improvement upon the methods described in (Santos and Lee, 2006) and (Kim and Park, 2007), addressing their flaws and providing a more comprehensive solution to the problem.",2,new
"Despite the improvement over a baseline model (the approach of (Smith et al., 2001)), we still observe limitations in our current implementation.",2,new
"Although we have made progress in comparison to a simple baseline (the methodology of (Johnson et al., 2015)), there are areas for further investigation.",2,new
"While our results show an enhancement over a basic model (the framework of (Davis et al., 1998)), our study is not without its drawbacks.",2,new
"In comparison to a standard baseline (the technique of (Miller et al., 2008)), we have achieved some gains, but our work is not without its limitations.",2,new
"Despite the advancements over a basic model (the theory of (Williams et al., 2003)), we have identified several areas for improvement.",2,new
"Although we have demonstrated an improvement over a control model (the algorithm of (Lee et al., 2012)), there are aspects of our work that require refinement.",2,new
"While our findings show an increase in performance over a simple baseline (the method of (Brown et al., 1995)), we have not fully explored the potential of this approach.",2,new
"In contrast to a typical baseline (the model of (Hall et al., 2010)), our results indicate some progress, but our study is not exhaustive.",2,new
"Despite the enhancement over a standard model (the approach of (Taylor et al., 2009)), we have encountered several challenges in our research.",2,new
"Although we have made strides in comparison to a basic control (the methodology of (White et al., 2006)), our work is not without its shortcomings.",2,new
"Our approach differs from other machine learning frameworks that do not incorporate semantic role labeling \[Kralj and Pulman, 2010\], which limits their ability to capture the nuances of word meaning.",2,new
"Unlike previous studies, we utilize a more comprehensive set of linguistic features \[Gupta and Lehal, 2009\], enabling us to better classify words and phrases in context.",2,new
"Other researchers have focused on rule-based systems for word classification \[Jurafsky and Martin, 2000\], but our approach leverages machine learning to improve accuracy and adaptability.",2,new
"In contrast to statistical models that rely heavily on co-occurrence data \[Harris, 1954\], our system incorporates a more nuanced understanding of linguistic patterns.",2,new
"Many existing systems fail to account for the subtleties of word semantics \[Fillmore, 1968\], which can lead to inaccurate classification and poor performance.",2,new
"Our approach also diverges from those that rely solely on word frequency analysis \[Zipf, 1935\], as we incorporate a range of linguistic features to inform our classification.",2,new
"Unlike previous work, we do not restrict our word classification to a single linguistic theory \[Chomsky, 1957\], allowing for a more comprehensive understanding of word meaning.",2,new
"Other machine learning frameworks often overlook the importance of syntactic context \[Chomsky, 1957\], which we address by incorporating a range of syntactic features.",2,new
"Our system improves upon previous approaches that do not consider the role of pragmatics in word classification \[Grice, 1975\], enabling us to better capture the nuances of human communication.",2,new
"In contrast to other statistical models, we do not rely on a fixed set of word classes \[Trier, 1931\], allowing our system to adapt to new and emerging linguistic patterns.",2,new
"The limitations of the current dataset make it difficult to implement advanced machine learning algorithms, similar to the challenges faced by previous researchers (e.g. Smith et al 2001).",2,new
"The vast amount of data in the corpus renders certain preprocessing techniques, such as named entity recognition or dependency parsing, computationally infeasible.",2,new
"Similar to past studies (e.g. Johnson et al 2015), the sheer size of the dataset hinders the application of complex linguistic analysis techniques.",2,new
"The enormous size of the corpus poses significant challenges for data annotation, much like the difficulties encountered by earlier researchers (e.g. Williams et al 2010).",2,new
"As observed in previous research (e.g. Davis et al 2018), the large dataset size makes it impractical to implement certain machine learning models.",2,new
"The current corpus size makes it unfeasible to apply certain types of data visualization, similar to the limitations encountered by researchers in the field (e.g. Lee et al 2012).",2,new
"The size of the corpus is a significant hindrance to the application of certain natural language processing techniques, similar to the findings of earlier studies (e.g. Brown et al 1995).",2,new
"Similar to the challenges faced by other researchers (e.g. Martin et al 2013), the current dataset is too large to implement certain types of text analysis.",2,new
"The size of the corpus makes it impractical to apply certain types of statistical analysis, similar to the difficulties encountered by earlier researchers (e.g. Thompson et al 2003).",2,new
"The current dataset size is a major obstacle to the application of certain machine learning algorithms, similar to the findings of past studies (e.g. Hall et al 2016).",2,new
"Despite the advancement of machine learning techniques, determining the optimal threshold for anomaly detection in time series data remains a challenging task (Kumar et al. 2018), especially when dealing with non-stationary data.",2,new
"The application of deep learning models for image classification has shown promising results (LeCun et al. 2015), but the evaluation of their robustness to adversarial attacks is still an open issue.",2,new
"Although significant progress has been made in natural language processing, the task of sentiment analysis remains a difficult problem (Pang et al. 2008), particularly when dealing with sentiment shifts and ambiguities.",2,new
"The use of ensemble methods for improving the accuracy of regression models has been explored (Breiman 2001), but selecting the optimal combination of base models is still a complex task.",2,new
"Despite the development of various clustering algorithms, determining the number of clusters in a dataset remains a challenging problem (Halkidi et al. 2001), especially when dealing with high-dimensional data.",2,new
"The evaluation of the performance of speech recognition systems has been a long-standing issue (Davis & Mermelstein 1980), particularly in noisy environments and with non-native speakers.",2,new
"The application of machine learning techniques to recommender systems has shown promising results (Sarwar et al. 2001), but the cold start problem and sparsity of user-item interactions remain significant challenges.",2,new
"Although significant progress has been made in the field of computer vision, the task of object detection in cluttered scenes remains a difficult problem (Felzenszwalb et al. 2010), particularly when dealing with varying lighting conditions.",2,new
"The use of reinforcement learning for robotics has been explored (Sutton & Barto 2018), but the problem of exploration-exploitation trade-off in complex environments is still an open issue.",2,new
"The evaluation of the robustness of neural networks to adversarial attacks has been a growing concern (Goodfellow et al. 2014), particularly in safety-critical applications such as autonomous vehicles.",2,new
The new algorithm presented in this study is more efficient and easier to implement than the one proposed by Knuth (1968).,2,new
This method demonstrates significant advantages over the earlier approach of Baeza-Yates and Gonnet (1992).,2,new
Our results indicate that the novel technique is more accurate and less prone to errors than the one developed by Press et al. (1992).,2,new
"In contrast to the outdated model of Harrison (1970), our new framework is more adaptable and scalable.",2,new
The proposed technique outperforms the one described in the study of Cormen et al. (2001) in terms of computational speed.,2,new
We observed that the new methodology is more robust and less susceptible to noise than the approach of Kohonen (1995).,2,new
Our findings suggest that the innovative approach of Li et al. (2003) is less reliable than the one presented in this study.,2,new
"Compared to the traditional method of Hopfield (1982), our new model is more effective and produces better results.",2,new
The novel technique is more intuitive and easier to understand than the one introduced by Hopcroft et al. (2006).,2,new
The results of our study indicate that the new approach of Kleinberg (2000) is less accurate than the one described in this study.,2,new
"Despite numerous proposals for automatic sentiment analysis (Turney 2002, Whitelaw et al. 2003), we are not aware of any successful implementation in a real-world setting.",2,new
"Despite several attempts to develop robust machine learning algorithms (Kohavi et al. 1997, Provost et al. 1998), we still lack a reliable method for accurate prediction.",2,new
"While various techniques have been suggested for automatic information extraction (Soderland 1999, Grishman et al. 2001), none have proven effective for large-scale datasets.",2,new
"Despite numerous studies on text classification (Joachims 1999, Sebastiani 2002), we have yet to find a method that generalizes well across different domains.",2,new
"Although several methods have been proposed for named entity recognition (Bikel et al. 1997, Flache et al. 1999), their performance is often limited to specific applications.",2,new
"We are not aware of any successful attempt to automatically extract key phrases (Hearst 1997, Kupiec et al. 1995) that are relevant to a particular task.",2,new
"Despite the numerous attempts to develop unsupervised learning algorithms (Bishop 1995, MacKay 1998), we still lack a robust method for unsupervised text classification.",2,new
"Several methods have been proposed for automatic text summarization (Mani et al. 1999, Lin et al. 1999), but none have demonstrated consistent performance across different types of documents.",2,new
"We know of no successful implementation of a system for automatic question answering (Pasca et al. 1999, Moldovan et al. 1999) that rivals human performance.",2,new
"Despite the proposed methods for topic modeling (Hofmann 1999, Landauer et al. 1998), we still lack a method that can accurately capture the underlying structure of a large corpus.",2,new
The study by Johnson and Thompson (1998) also failed to yield conclusive results.,2,new
"In contrast to previous research, the experiments by Lee et al. (2005) did not provide a viable solution.",2,new
"Unfortunately, the methodology employed by Kim and Lee (2010) was not effective in addressing the issue.",2,new
"The attempts by Patel and Kumar (2012) to replicate the findings were unsuccessful, indicating a potential flaw in the initial study.",2,new
Our analysis of the data by Brown and Davis (2015) revealed several significant limitations.,2,new
The use of computational methods by Hernandez and Martin (2002) did not produce the desired outcome.,2,new
"As evident from the study by Chen and Wong (2008), the current approach has several critical drawbacks.",2,new
The investigation by Taylor and White (2003) failed to uncover any meaningful insights.,2,new
"In a surprising turn of events, the results by Singh and Rao (2011) contradicted the existing literature.",2,new
The theoretical framework proposed by Mitchell and Johnson (2009) was found to be inadequate in explaining the phenomenon.,2,new
"This approach diverges from the conventional methods of phonological analysis as presented in the works of Halle and Stevens (1964) and Chomsky and Halle (1968), which oversimplify the complexities of sound patterns.",2,new
"In contrast, our study rejects the simplistic assumptions of earlier researchers such as Liberman and Studdert-Kennedy (1967) and Jakobson (1968), who relied heavily on auditory cues.",2,new
"Unlike the methodologies employed by Miller and Nicely (1955) and Laver (1994), our investigation eschews the reliance on subjective perception and instead focuses on objective acoustic measures.",2,new
"Our approach diverges from the theoretical frameworks proposed by Noam Chomsky (1957) and Morris Halle (1959), which have been widely criticized for their lack of empirical support.",2,new
"This study differs significantly from the work of researchers such as Fromkin (1973) and Ladefoged (1975), who have been accused of neglecting the role of phonetic variation in language acquisition.",2,new
"In opposition to the findings of researchers like Trubetzkoy (1939) and Jakobson (1941), our study demonstrates the importance of considering the socio-cultural context in phonological development.",2,new
"Our research methodology diverges from the statistical models used by researchers like Church and Hanks (1990) and Brent (1991), which have been shown to be inadequate for capturing the complexities of language acquisition.",2,new
"Unlike the work of researchers such as Luce (1986) and Pisoni (1993), our study rejects the notion that phonological development is solely driven by auditory experience.",2,new
"This study rejects the simplistic views on language acquisition presented by researchers like Skinner (1957) and Brown (1973), which have been widely discredited by the scientific community.",2,new
"Our approach diverges from the theoretical frameworks proposed by researchers such as Chomsky and Miller (1958) and Halle and Stevens (1964), which have been criticized for their lack of empirical support.",2,new
The application of machine learning algorithms in natural language processing (Bengio et al. 2003) has significant limitations when it comes to handling out-of-vocabulary words.,2,new
The use of rule-based systems in language translation (Katz and Resnik 1997) often results in poor performance when dealing with idiomatic expressions.,2,new
The data-driven approach to sentiment analysis (Turney 2002) is limited by its reliance on large amounts of labeled training data.,2,new
The traditional approach to named entity recognition (Rabinovich et al. 2001) has been criticized for its lack of flexibility in handling entities with complex relationships.,2,new
The rigid framework of statistical machine translation (Koehn 2005) can lead to suboptimal results when dealing with domain-specific terminology.,2,new
The use of hand-coded rules in language generation (Elhadad 1998) is often time-consuming and prone to errors.,2,new
The statistical method of topic modeling (Blei et al. 2003) is limited by its assumption of a fixed number of topics.,2,new
The traditional approach to text classification (Dumais et al. 1998) has been shown to be less effective than more modern machine learning techniques.,2,new
The rule-based approach to machine translation (Brown et al. 1990) is often unable to capture the nuances of human language.,2,new
The data-driven approach to question answering (Chen et al. 2006) is limited by its reliance on pre-existing knowledge bases.,2,new
"This limitation is a significant drawback of the proposed neural machine translation framework (Kalchbrenner & Blunsom, 2013), as it restricts the model's ability to capture complex sentence structures.",2,new
"The traditional Hidden Markov Model (HMM) approach to natural language processing (Rabiner, 1989) has several limitations, including its inability to handle out-of-vocabulary words.",2,new
"A major shortcoming of the Memory-Augmented Neural Machine Translation model (Bahdanau et al., 2015) is its reliance on a fixed-size memory buffer, which can lead to information loss during long sequences.",2,new
"The current implementation of the Long Short-Term Memory (LSTM) network (Hochreiter & Schmidhuber, 1997) is not suitable for real-time applications due to its high computational requirements.",2,new
A significant drawback of the statistical machine translation method proposed by Brown et al. (1993) is its inability to capture context-dependent word relationships.,2,new
"The lack of contextual information in the Vector Space Model (VSM) (Salton & McGill, 1983) makes it less effective for tasks that require a deeper understanding of the relationship between words.",2,new
"The proposed reinforcement learning approach to natural language generation (Williams, 1992) has several limitations, including its reliance on a pre-defined reward function.",2,new
"A major limitation of the Word2Vec model (Mikolov et al., 2013) is its inability to capture nuances of word meaning in context.",2,new
"The current implementation of the Generative Adversarial Network (GAN) (Goodfellow et al., 2014) is not suitable for tasks that require a high degree of control over the generated output.",2,new
"A significant shortcoming of the Dependency Parsing algorithm (Collins, 1996) is its sensitivity to the quality of the input sentence.",2,new
Our results demonstrate a notable 51.2% decrease in misclassification rates when compared to the baseline model proposed by Johnson and Zhai (2017).,2,new
"In comparison to the traditional approach outlined by Smith et al. (2019), our method yields a 72.5% improvement in predictive accuracy.",2,new
A significant 42.1% reduction in computational time is achieved when utilizing our optimized algorithm over the method presented by Lee and Kim (2020).,2,new
Our findings show a substantial 68.9% decrease in system latency when contrasted with the architecture designed by Patel and Jain (2015).,2,new
"Compared to the conventional technique described by Davis and Taylor (2018), our approach exhibits a 55.8% enhancement in processing speed.",2,new
"Notably, our model displays a 58.5% decrease in false positive rates compared to the model suggested by White and Hall (2012).",2,new
"The results indicate a 62.3% improvement in model efficiency when our technique is applied, as opposed to the methodology outlined by Kim and Lee (2014).",2,new
"We observe a notable 75.6% reduction in data noise when utilizing our proposed method, in contrast to the method proposed by Brown and Taylor (2016).",2,new
Our study reveals a 54.1% increase in system reliability when compared to the conventional approach described by Johnson and Smith (2013).,2,new
"A substantial 60.8% decrease in model complexity is achieved when implementing our optimized technique, as opposed to the method presented by Davis and Lee (2019).",2,new
"A limitation of this approach is that it does not account for the nuances of language, similar to other statistical models like the Stanford model (Jurafsky & Martin, 2000).",2,new
"This approach is not without its drawbacks, as seen with other machine translation models, such as the Moses model, which often struggle with idiomatic expressions (Koehn, 2004).",2,new
"One major issue with this model is its reliance on pre-existing knowledge, a problem also encountered with other machine translation models, such as the SMT system (Brown et al., 1993).",2,new
"The proposed model is not without its limitations, as it shares some of the same flaws as other statistical machine translation models, including the log-linear model (Chen & Rosenfeld, 2000).",2,new
"A notable issue with this approach is its inability to capture subtle nuances of language, a problem also present in other statistical models, such as the n-gram model (Jelinek & Mercer, 1993).",2,new
"This model's performance is hindered by its reliance on pre-existing knowledge, a common issue with other machine translation models, such as the phrase-based model (Koehn et al., 2007).",2,new
"A significant limitation of this approach is its failure to account for the complexities of language, a problem also encountered with other machine translation models, such as the hierarchical phrase-based model (Zhang et al., 2006).",2,new
"The proposed model has several drawbacks, including its inability to handle out-of-vocabulary words, a problem also present in other statistical machine translation models, such as the phrase-based statistical model (Chen et al., 2001).",2,new
"One major shortcoming of this model is its reliance on a pre-existing dictionary, a limitation also shared by other machine translation models, such as the rule-based model (Melamed, 2001).",2,new
"This approach has several limitations, including its inability to capture the subtleties of language, a problem also encountered with other machine translation models, such as the example-based model (Brown et al., 1990).",2,new
"The results in table 2 indicate that only 12.5% of trials showed significant improvement in model accuracy when using the proposed algorithm (Krizhevsky et al., 2012).",2,new
"In contrast, our study found that the novel approach failed to yield any statistically significant results in 85.2% of the analyzed cases (LeCun et al., 2015).",2,new
"The figures presented in table 3 demonstrate that the performance of the control group surpassed that of the experimental group in 92.1% of the experiments (Bengio et al., 2003).",2,new
"The data in table 1 reveal that the existing method outperformed the proposed approach in 75.6% of the trials (Rumelhart et al., 1986).",2,new
"The results of the experiment reported in table 4 suggest that the new technique was less effective than the standard method in 98.5% of the cases (Sejnowski et al., 1986).",2,new
"Our analysis of the data in table 5 showed that the proposed method was inferior to the baseline approach in 81.9% of the scenarios (Hinton et al., 2006).",2,new
"The findings in table 6 indicate that the introduction of the novel feature did not lead to any notable improvements in 87.4% of the instances (Schmidhuber et al., 1997).",2,new
"The table 7 data reveal that the performance of the system using the proposed method was inferior to that of the system using the existing technique in 91.8% of the cases (Werbos et al., 1995).",2,new
"The results in table 8 suggest that the new approach was outperformed by the traditional method in 83.2% of the experiments (Bishop, 1995).",2,new
"The statistics in table 9 show that the proposed algorithm was less effective than the existing method in 95.6% of the trials (Patterson, 2004).",2,new
"The lack of flexibility in the proposed method (Kumar et al., 2018) is a significant drawback, as it only considers a single possible alignment for each source word.",2,new
"A major limitation of the machine learning approach (Lee et al., 2002) is its inability to handle complex cases where a single source word is aligned to multiple target words.",2,new
"The proposed algorithm (Wang et al., 2015) suffers from a major flaw in its reliance on a single, rigid alignment strategy that fails to account for nuances in language translation.",2,new
"A notable shortcoming of the statistical model (Chen et al., 2001) is its inability to adapt to varying language structures and syntax.",2,new
"The current implementation (Patel et al., 2012) is hindered by its simplistic approach to handling out-of-vocabulary words, which can lead to inaccurate translations.",2,new
"The existing methodology (Kim et al., 2008) is plagued by its reliance on a static dictionary that fails to capture the dynamic nature of language.",2,new
"A significant drawback of the rule-based system (Hall et al., 1997) is its inability to generalize to unseen language pairs.",2,new
"The proposed framework (Srivastava et al., 2019) is limited by its assumption of a fixed word order, which is not always applicable in natural language translation.",2,new
"A major criticism of the deep learning approach (Zhang et al., 2013) is its lack of interpretability, making it difficult to understand the reasoning behind its decisions.",2,new
"The current research (Gupta et al., 2005) is marred by its failure to address the issue of polysemy, where a single word has multiple meanings.",2,new
"In contrast to traditional rule-based approaches (Kumar & Seabrook, 2005), the probabilistic framework of phrase-based models recognizes the importance of compositional semantics, allowing for a more nuanced understanding of sentence structure and meaning.",2,new
"Although earlier studies (Melamed, 2001) focused primarily on word-level analysis, recent advancements in statistical machine translation (Chen & Zhai, 2005) have incorporated the insights of syntax-based models, leading to improved translation accuracy.",2,new
"Unlike earlier lexical-based methods (Church, 1988), the phrase-based framework (Koehn et al., 2007) has been instrumental in capturing the subtleties of idiomatic expressions and colloquialisms, thereby enhancing the overall translation quality.",2,new
"Traditional machine translation models (Brown et al., 1993) relied on a word-centric approach, whereas modern phrase-based systems (Huang et al., 2006) have demonstrated the importance of incorporating phrasal structures and their associated semantics.",2,new
"Historically, statistical models (Kneser & Ney, 1995) have been limited by their reliance on word-level analysis; however, recent advances in phrase-based translation (Och & Ney, 2002) have shown the value of considering phrasal units in the translation process.",2,new
"Prior research (Melamed, 2001) has highlighted the challenges of word-based models in capturing idiomatic language; in contrast, phrase-based approaches (Koehn et al., 2007) have made significant strides in addressing these issues.",2,new
"Earlier studies (Kumar & Seabrook, 2005) often overlooked the importance of phrasal units in language; however, the phrase-based model (Chen & Zhai, 2005) has successfully incorporated this insight, leading to improved translation performance.",2,new
"Traditional machine translation systems (Church, 1988) were often criticized for their oversimplification of language; the phrase-based framework (Huang et al., 2006) has mitigated these limitations by considering the complexities of phrasal structures.",2,new
"Word-based models (Brown et al., 1993) have been shown to be inadequate for capturing the nuances of idiomatic language; in contrast, the phrase-based approach (Och & Ney, 2002) has demonstrated its ability to address these challenges.",2,new
"The phrase-based model (Koehn et al., 2007) has been instrumental in improving the accuracy of machine translation by incorporating the",2,new
"The earlier model proposed by Levene and Raffo (2000) has several limitations, including its inability to capture the nuances of idiomatic expressions in the target language.",2,new
"The work by Collins (1996) falls short in its assumption that sentence structure is the primary factor influencing translation quality, neglecting the impact of contextual factors.",2,new
"Despite its popularity, the machine translation model developed by Hutchins (1992) fails to account for the complexities of cultural references and allusions that are often present in source texts.",2,new
"The simplistic approach employed by the IBM Model2 (Brown et al., 1993) neglects the importance of pragmatics in translation, leading to unnatural and often inaccurate translations.",2,new
"The model proposed by Kay and Ross (2003) has a significant flaw in its handling of homographs, which can lead to misunderstandings and misinterpretations in the target language.",2,new
"The lack of consideration for stylistic variations in the work by Melby et al. (1998) results in translations that are often overly formal or informal, failing to capture the intended tone.",2,new
"The model developed by White (1991) is limited by its inability to handle idiomatic expressions, which are common in many languages and play a crucial role in conveying meaning.",2,new
"The oversimplification of linguistic phenomena in the work by Leacock et al. (2005) leads to a lack of accuracy in translation, particularly when dealing with figurative language and metaphors.",2,new
"The model proposed by Papineni et al. (2002) has a significant drawback in its handling of out-of-vocabulary words, which can lead to inaccurate translations and a loss of context.",2,new
The neglect of phonological aspects in the work by Charniak (1996) results in translations that often sound unnatural and fail to capture the musicality of the original text.,2,new
"Our method outperforms the technique proposed by Johnson et al. (2001) for predicting protein structures, offering several key advantages.",2,new
"In contrast to the approach of Smith et al. (1995), our method has the ability to handle complex data more efficiently.",2,new
"Our research demonstrates that the algorithm developed by Lee et al. (2009) has significant limitations when dealing with large datasets, which our method addresses effectively.",2,new
"The proposed methodology of Davis et al. (2010) falls short in comparison to our approach, which provides a more accurate solution to the problem.",2,new
"Our results indicate that the method of Patel et al. (2015) has a higher error rate than our proposed method, particularly in noisy environments.",2,new
"Unlike the technique described by Kim et al. (2007), our approach offers a more robust solution for real-world applications.",2,new
"In comparison to the work of Chen et al. (2012), our research shows that our method has a faster computation time while maintaining high accuracy.",2,new
"Our findings suggest that the approach of Taylor et al. (2003) has a lower precision than our method, especially when dealing with large datasets.",2,new
"The method of Hall et al. (2008) lacks the ability to adapt to changing conditions, which is a key feature of our proposed approach.",2,new
"Our study reveals that the technique of Martin et al. (2011) has a higher computational cost than our method, making it less suitable for practical applications.",2,new
"The results of their experiment would be less reliable in cases where the word order correlation was not a strong indicator of grammatical function, as seen in languages with freer word order, such as Japanese or Arabic.",2,new
"The proposed models would be less effective in handling languages with complex morphological paradigms, as demonstrated by the poor performance of their algorithm on languages like Arabic and Russian.",2,new
"A word order correlation bias was also observed in the results of their analysis, which would hinder the performance of their model on languages with subject-verb-object word order, such as many African languages.",2,new
"The proposed methodology would be less suitable for languages with a high degree of morphological complexity, such as those found in the indigenous languages of the Americas.",2,new
"The results of their experiment showed that the models were less accurate in languages with a high degree of inflectional morphology, such as German and Russian.",2,new
"A comparison of their results with those from other studies suggests that the word order correlation bias would be a significant issue for languages with non-Subject-Verb-Object word order, such as many Native American languages.",2,new
"The proposed models would be less effective in languages with a high degree of phonological complexity, as seen in the results of their analysis on languages like Vietnamese and Khmer.",2,new
"The methodology employed by the authors would be less applicable to languages with a complex system of honorifics, such as those found in Japanese and Korean.",2,new
"The results of their experiment would be less generalizable to languages with a high degree of lexical variability, as seen in the results of their analysis on languages like Swahili and Yoruba.",2,new
"A critical examination of their results reveals that the proposed models would be less suitable for languages with a high degree of phonological and morphological complexity, such as those found in the languages of Papua New Guinea.",2,new
Our proposed algorithm surpasses existing deep learning architectures (Hinton et al. 2006; Bengio et al. 2007) and the widely-used sentence embedding methods (Le and Mikolov 2014).,2,new
"In comparison to traditional machine learning techniques (Mitchell 1997; Russell and Norvig 2003), our approach yields significantly better results.",2,new
Our model outperforms the conventional neural machine translation models (Vaswani et al. 2017; Bahdanau et al. 2015) and the recently-introduced transformer-based summarization methods (See et al. 2017).,2,new
Our proposed methodology surpasses the state-of-the-art speech recognition systems (Rabiner and Schafer 1980; Davis and Mermelstein 1980) in terms of accuracy and efficiency.,2,new
"In contrast to the widely-adopted Naive Bayes classifier (Rennie et al. 2003), our decision tree-based approach yields superior performance in the classification task.",2,new
Our system outperforms the conventional rule-based expert systems (Newell and Simon 1972; Feigenbaum and Buchanan 1983) in terms of adaptability and scalability.,2,new
"In comparison to the existing natural language generation models (Elman 1990; Williams and Zipser 1989), our proposed model achieves state-of-the-art performance in text generation.",2,new
Our approach outperforms the conventional statistical machine learning models (Domingos 1999; Langley 2000) in terms of predictive power and accuracy.,2,new
Our system surpasses the state-of-the-art text classification models (Joachims 1999; Freund and Schapire 1997) in terms of precision and recall.,2,new
Our methodology outperforms the widely-used clustering algorithms (Kaufman and Rousseeuw 1990; Hartigan 1975) in terms of efficiency and effectiveness.,2,new
"The proposed methodology falls short in addressing the complexity of long-distance dependencies, a limitation that is exacerbated by the restrictive assumptions of the current state-of-the-art models, such as those presented by Brown et al. (1993) in their Models 1 and 2.",2,new
"The introduction of new syntactic features to the word alignment task, as proposed by recent studies, does not adequately account for the subtleties of language that are beyond the scope of existing methods, including those developed by Sue J. Ker and Jason S. Chang.",2,new
"In contrast to the simplistic approach of recent word alignment techniques, the nuances of linguistic structure require a more sophisticated treatment, one that is currently beyond the capabilities of models such as Model 1 and Model 2 proposed by Brown et al. (1993).",2,new
"The word alignment methods proposed in recent studies are insufficient for handling the intricate relationships between words, a challenge that is highlighted by the work of Sue J. Ker and Jason S. Chang, which demonstrates the limitations of current approaches.",2,new
"The current state-of-the-art word alignment models, including those developed by Brown et al. (1993) in Models 1 and 2, fail to capture the full range of linguistic phenomena, a shortcoming that is underscored by the work of researchers such as Sue J. Ker and Jason S. Chang.",2,new
"The proposed word alignment techniques are hampered by the restrictive assumptions of existing models, including those presented by Brown et al. (1993) in Models 1 and 2, which do not adequately account for the complexities of language.",2,new
"Recent word alignment methods, such as those proposed by Brown et al. (1993) in Models 1 and 2, are not equipped to handle the intricacies of linguistic structure, a limitation that is well-documented in the work of researchers like Sue J. Ker and Jason S. Chang.",2,new
"The current word alignment approaches, including those based on the models of Brown et al. (1993), are not sufficient to address the challenges of language understanding, a shortcoming that is highlighted by the work of Sue J. Ker and Jason S. Chang.",2,new
"In contrast to the current state-of-the-art, the work of Sue J. Ker and Jason S. Chang demonstrates the need for more advanced word alignment techniques that can capture the subtleties of language, a requirement that is not met by existing models such as those proposed by Brown et al. (1993) in Models 1 and 2.",2,new
The word alignment methods,2,new
"The proposed methodology tries to address the limitations of traditional sentence-based models (Sutskever et al., 2014) by incorporating contextualized representations.",2,new
"This approach endeavors to rectify the shortcomings of statistical machine translation methods (Koehn, 2004) through the incorporation of syntactic knowledge.",2,new
"The novel framework aims to surpass the inadequacies of rule-based systems (Melamed, 2001) by leveraging large-scale corpora and neural networks.",2,new
"The researchers attempt to overcome the constraints of purely linguistic models (Lample et al., 2017) by integrating multimodal information.",2,new
"The authors strive to improve upon the deficiencies of symbolic AI systems (Newell, 1982) through the use of connectionist architectures.",2,new
"The new paradigm seeks to address the drawbacks of rigid parsing methods (Jurafsky & Martin, 2000) by incorporating dynamic language models.",2,new
"This study aims to rectify the limitations of discrete representations (Hinton et al., 2006) by employing continuous embeddings.",2,new
"The proposed model endeavors to surmount the shortcomings of knowledge-based systems (Bauer, 2004) through the use of probabilistic reasoning.",2,new
"The researchers attempt to improve upon the inadequacies of rule-based approaches (Kumar, 2015) by incorporating probabilistic grammar.",2,new
"The authors aim to overcome the constraints of purely linguistic models (Collobert et al., 2011) by integrating visual information.",2,new
"The proposed syntax-based translation models (Wu, 1997; Koehn, 2004) have been shown to be less effective compared to the more recent neural machine translation models (Sutskever et al., 2014; Bahdanau et al., 2015).",2,new
"In contrast to the widely used grammar-based translation systems (Katz, 1967; Fillmore, 1968), the use of statistical machine translation methods (Brown et al., 1993) has been met with limited success in various studies (Manning and Schtze, 1999; Melamed, 2001).",2,new
"Several researchers have attempted to improve upon the traditional rule-based translation systems (Kay and Roscheisen, 1993; Alshawi et al., 1995) with the introduction of hybrid machine translation models (Huang et al., 1995; Collins et al., 1997), but their results have been disappointing.",2,new
"Various studies have demonstrated the limitations of phrase-based translation systems (Chen and Chen, 2003; Och and Ney, 2002) in handling idiomatic expressions and figurative language, which are crucial for high-quality translation.",2,new
"The early attempts at machine translation using rule-based systems (Melamed, 2001; Katz, 1967) have been outperformed by more recent approaches based on statistical machine translation (Brown et al., 1993; Manning and Schtze, 1999).",2,new
"Despite the widespread adoption of syntax-based translation models (Koehn, 2004; Wu, 1997), their limitations in handling complex linguistic phenomena have been well-documented in the literature (Sutskever et al., 2014; Bahdanau et al., 2015).",2,new
"The performance of grammar-based translation systems (Katz, 1967; Fillmore, 1968) has been consistently surpassed by more advanced machine translation models that utilize neural networks (Sutskever et al., 2014; Bahdanau et al., 2015).",2,new
"The use of phrase-based translation models (Och and Ney, 2002; Chen and Chen, 2003) has been shown to be less effective than the more recent approaches based on neural machine translation (Bahdanau et al., 2015; Sutskever et al., 2014).",2,new
"In contrast to the more successful neural machine translation models (Bahdanau et al.,",2,new
"By analyzing linguistic patterns at the phoneme level, researchers have been able to enhance the accuracy of speech recognition systems (Miller & Nicely, 1955) and text-to-speech synthesis (Hillenbrand et al., 1995).",2,new
"Incorporating sociolinguistic factors into language models can lead to a decline in the effectiveness of sentiment analysis tools (Biber & Finegan, 1989) and opinion mining (Schutze, 1998).",2,new
"Focusing on the semantic representation of words can compromise the performance of question answering systems (Leacock & Chodorow, 1998) and semantic search engines (Brown, D. & Yule, G., 1983).",2,new
"By neglecting the syntactic structure of languages, researchers have observed a decrease in the quality of machine translation (Katz, J. J. & Fodor, J. A., 1963) and grammar checking software (Weischedel, R. M., 1982).",2,new
"Ignoring the pragmatic aspects of language can impair the functionality of dialogue systems (Grice, H. P., 1975) and human-computer interaction (Searle, J. R., 1969).",2,new
"The oversimplification of linguistic rules can hinder the development of language learning systems (Krashen, S., 1981) and language teaching software (Van Ek, J. A., 1986).",2,new
"The failure to account for language variation can lead to a reduction in the effectiveness of speech recognition (Pierrehumbert, J. B., 1990) and speech synthesis (Haskins Laboratories, 1988).",2,new
"Focusing solely on statistical methods can compromise the performance of machine learning models (Vapnik, V., 1995) and natural language processing (Domingos, P., 1999).",2,new
"By neglecting the cognitive aspects of language, researchers have observed a decrease in the accuracy of language understanding systems (Newell, A., 1980) and language generation (Levelt, W. J. M., 1989).",2,new
"The lack of consideration for cultural and social context can impair the functionality of language translation (Nida, E. A., 1964) and language teaching (Kramsch, C., 1993).",2,new
"The introduction of new features such as Named Entity Recognition (NER) in the basic unit of translation has been shown to alleviate many of the issues associated with the original word-based formulation of statistical machine translation (Vapnik et al., 2015).",2,new
"By increasing the size of the training corpus, the percentage of unique N-grams extracted from the test sentences is significantly reduced, indicating a more robust machine translation system (Collins et al., 2005).",2,new
"The use of more complex NLP techniques such as Dependency Parsing has been shown to improve the accuracy of phrase-based machine translation, reducing many of the errors associated with the original word-based approach (Klein et al., 2003).",2,new
"The findings of the study suggest that the increase in training corpus size has a direct impact on the quality of the generated translations, with a notable decrease in errors related to the original word-based formulation (Kumar et al., 2018).",2,new
"The shift from word-based to phrase-based machine translation has been widely adopted in the field, resulting in improved translation accuracy and a reduction in errors associated with the original approach (Melamed et al., 2003).",2,new
"The introduction of subword modeling has been shown to improve the performance of machine translation systems, addressing many of the issues associated with the original word-based formulation (Sennrich et al., 2016).",2,new
"A study on the impact of training corpus size on machine translation accuracy found that increasing the size of the basic unit of translation leads to a significant reduction in errors associated with the original word-based approach (Chen et al., 2019).",2,new
"The use of more advanced NLP techniques such as Semantic Role Labeling has been shown to improve the accuracy of machine translation, reducing many of the errors associated with the original word-based formulation (Manning et al., 2014).",2,new
"The results of the study indicate that the increase in training corpus size has a positive impact on the quality of the generated translations, with a notable improvement in accuracy compared to the original word-based approach (Lee et al., 2017).",2,new
"The shift from word-based to phrase-based machine translation has been widely adopted in the industry, resulting in improved translation accuracy and a reduction in errors associated with the original approach (Huang et al., 2006).",2,new
"The current study by (Kolmogorov, 1933) has several limitations, which can be addressed by incorporating a more robust statistical framework as proposed by (Lehmann, 1959) to improve the accuracy of the results.",2,new
"In contrast to the approach used by (De Morgan, 1847), our method (Liu et al., 2018) can be further enhanced by integrating a machine learning algorithm to better handle the complexity of the data.",2,new
"The findings of (Fisher, 1925) can be refined by incorporating additional data points as suggested by (Tukey, 1977), which would provide a more comprehensive understanding of the phenomenon under study.",2,new
"The traditional model presented by (Newton, 1687) has several drawbacks, which can be mitigated by applying the principles of (Einstein, 1905) to achieve a more accurate representation of the underlying mechanisms.",2,new
"The study by (Darwin, 1859) has some limitations in its current form, which can be addressed by adopting the theoretical framework proposed by (Lamarck, 1809) to provide a more nuanced understanding of the evolutionary process.",2,new
"In contrast to the approach used by (Gauss, 1801), our method (Riemann, 1854) can be improved by incorporating a more sophisticated mathematical framework to better model the underlying patterns.",2,new
"The results of (Cavendish, 1798) can be refined by incorporating additional experimental data as suggested by (Galileo, 1632), which would provide a more accurate understanding of the phenomenon under study.",2,new
"The traditional model presented by (Maxwell, 1864) has several flaws, which can be addressed by applying the principles of (Faraday, 1831) to achieve a more accurate representation of the underlying electromagnetic phenomena.",2,new
"The study by (Mendel, 1865) has some limitations in its current form, which can be addressed by adopting the theoretical framework proposed by (Wattebled, 1862) to provide a more comprehensive understanding of the genetic inheritance.",2,new
"In contrast to the approach used by (Rutherford, 1911), our method (Bohr, 1913) can be enhanced by incorporating a more detailed atomic model to better explain the behavior of subatomic particles.",2,new
"The results of the previous study (Baker et al., 2008) indicate that the current implementation of part-of-speech tagging falls short in handling inflected languages.",2,new
"A critical examination of the data preprocessing steps reveals that the current approach to tokenization (Marcus et al., 1993) is prone to errors in non-standard languages.",2,new
"Despite its popularity, the bag-of-words model (Turney, 2002) has several limitations, including its inability to capture semantic relationships and context.",2,new
"The application of traditional clustering algorithms (Kaufman & Rousseeuw, 1990) to high-dimensional data is often hindered by the curse of dimensionality and poor initialization.",2,new
"A critical review of the current state-of-the-art models (Harris et al., 2014) shows that they are not well-suited for handling imbalanced datasets and class overlap.",2,new
"The current evaluation metrics (Vapnik, 1998) used in machine learning research are often biased towards binary classification and do not account for multi-class problems.",2,new
"The reliance on manual annotation (Cohen, 1996) in natural language processing tasks can lead to high costs and inconsistent results.",2,new
"A comparative analysis of the existing algorithms (Duda et al., 2001) reveals that they often fail to generalize well to new, unseen data.",2,new
"The assumption of stationarity (Box et al., 1994) in time series analysis is not always met in real-world scenarios, leading to poor model performance.",2,new
"The current implementation of decision trees (Breiman et al., 1984) is not robust to feature selection and attribute interactions.",2,new
"In comparison to traditional rule-based approaches such as Verbmobil (Haberland et al., 2000), more recent methods like neural machine translation (NMT) have shown significant improvements in translation quality, particularly in capturing idiomatic expressions.",2,new
"Compared to earlier rule-based systems such as Eurotra (Carl et al., 1993), phrase-based models like Moses (Koehn et al., 2007) have demonstrated superior performance in statistical machine translation, with notable advancements in handling out-of-vocabulary words.",2,new
"Compared to older methods like the Verbmobil system (Haberland et al., 2000), the use of word embedding techniques in recent statistical machine translation (SMT) systems (Mikolov et al., 2013) has led to a substantial increase in translation accuracy.",2,new
"In contrast to traditional phrase-based methods such as Moses (Koehn et al., 2007), the application of attention mechanisms in neural machine translation (NMT) has resulted in notable improvements in translation quality, particularly in conveying nuanced context.",2,new
"Compared to earlier SMT systems such as the IBM Model 4 (Brown et al., 1993), the incorporation of subword units in recent NMT models (Sennrich et al., 2016) has shown a significant boost in translation performance, especially in handling rare words.",2,new
"In comparison to older rule-based systems like Eurotra (Carl et al., 1993), recent advancements in SMT systems, particularly the use of neural networks, have led to a substantial improvement in translation quality, with notable advancements in idiomatic expression handling.",2,new
"Compared to traditional statistical machine translation (SMT) systems like Moses (Koehn et al., 2007), the application of pre-training techniques in NMT models (Devlin et al., 2018) has resulted in a significant increase in translation accuracy, particularly in capturing nuances of human language.",2,new
"In contrast to earlier NMT models such as the Google Neural Machine Translation System (Wu et al., 2016), the use of multi-task learning in recent SMT systems (Johnson et al., 2017) has demonstrated notable improvements in translation quality, particularly in handling out-of-vocabulary words.",2,new
"Compared to older methods like the IBM Model 1 (Brown et al., 1993), the incorporation of attention mechanisms in recent NMT models (Vaswani et al., 2017) has led to a substantial increase in translation accuracy, especially in",2,new
"The application of neural networks to text classification has several limitations, including the inability to capture nuanced linguistic features (Krizhevsky et al. 2012).",2,new
"The use of pre-trained word embeddings in natural language processing has shown to be ineffective in certain domains, particularly in low-resource languages (Gouws et al. 2018).",2,new
"However, the incorporation of discourse analysis in sentiment analysis has not yielded significant improvements, suggesting that this approach may not be a viable solution (Polanyi, L. 1985).",2,new
The reliance on shallow parsing techniques in natural language processing can lead to a lack of understanding of contextual relationships (Marcus et al. 1993).,2,new
"The use of rule-based approaches in machine translation has been shown to be time-consuming and error-prone, making it a less desirable option (Kay, M. 2002).",2,new
The application of machine learning algorithms to text generation has been hindered by the lack of large-scale annotated datasets (Papineni et al. 2002).,2,new
The current state of speech recognition technology is limited by its inability to accurately handle out-of-vocabulary words (Bahl et al. 1983).,2,new
"The reliance on keyword-based approaches in information retrieval can lead to irrelevant results and decreased accuracy (Baeza-Yates, R. and Ribeiro-Neto, B. 1999).",2,new
"The use of shallow semantic parsing in natural language processing can fail to capture the underlying meaning of complex sentences (Carpenter, B. 1992).",2,new
The application of statistical machine translation has been hindered by the lack of robustness in handling idiomatic expressions (Brown et al. 1990).,2,new
"The limitations of current machine learning models (e.g., Word2Vec (Mikolov et al., 2013)) become apparent when dealing with more complex N-M alignments, where N>3 or M>3.",2,new
"In general, rule-based translation systems (e.g., Hull et al., 2011) are not equipped to handle diverse M-N alignments, which are common in many language pairs.",2,new
"The distinction between M-N alignments is crucial, as most statistical machine translation systems (e.g., SMT models (Koehn, 2004)) rely on pre-defined rules that are not adaptable to complex N-M pairs.",2,new
"While certain phonetic-based models (e.g., Levenshtein distance (Levenshtein, 1966)) can handle some N-M alignments, they often struggle with the nuances of human language, leading to suboptimal results.",2,new
"The constraints of current linguistic theory (e.g., dependency grammar (Mel'uk, 1988)) make it challenging to model N-M alignments effectively, leading to a significant gap in translation accuracy.",2,new
"Most neural machine translation models (e.g., LSTM (Sutskever et al., 2014)) are not designed to accommodate the intricacies of N-M alignments, resulting in poor performance on such tasks.",2,new
"In the context of machine translation, the distinction between N-M alignments is essential, as most phrase-based models (e.g., Moses (Koehn et al., 2007)) are not equipped to handle the complexity of multiple word-to-word correspondences.",2,new
"The current state of knowledge in linguistics (e.g., work on linguistic typology (Croft, 2001)) does not provide a comprehensive framework for modeling N-M alignments, leading to a significant challenge in translation research.",2,new
"The limitations of current NLP tools (e.g., part-of-speech tagging (Brill, 1992)) become apparent when attempting to model N-M alignments, as they often rely on simplistic assumptions about language structure.",2,new
"While certain types of linguistic analysis (e.g., prosody-based models (Beckman & Halle, 1995)) can provide some insight into N-M alignments, they are not sufficient to overcome the limitations of current machine translation systems.",2,new
"In machine learning models (Hastie et al., 2009), the assumption of linear separability often leads to suboptimal results in classification tasks.",2,new
"The use of pre-trained word embeddings in neural machine translation (Vaswani et al., 2017) is limited by their inability to capture context-dependent nuances in language.",2,new
"In the development of speech recognition systems (Rabiner & Juang, 1993), the reliance on Gaussian Mixture Models can result in poor performance on non-stationary signals.",2,new
"The application of traditional clustering algorithms (Jain et al., 1999) to image segmentation tasks often yields unsatisfactory results due to the complexity of visual data.",2,new
"The assumption of normality in statistical hypothesis testing (Gosset, 1908) can be violated in real-world datasets, leading to incorrect conclusions.",2,new
"In the field of natural language processing, the use of bag-of-words models (Blei et al., 2003) neglects the semantic relationships between words, resulting in inaccurate text analysis.",2,new
"The reliance on parametric methods in time series analysis (Box et al., 1978) can be problematic when dealing with non-linear patterns in data.",2,new
"In the study of recommender systems (Resnick et al., 1994), collaborative filtering methods often suffer from cold start problems, leading to suboptimal recommendations.",2,new
"The use of traditional optimization techniques (Nelder & Mead, 1965) in non-linear programming can result in slow convergence rates and poor solution quality.",2,new
"The application of classical regression models (Freedman, 2009) to complex, high-dimensional data often fails to capture underlying relationships and patterns.",2,new
"This paper utilizes Latent Dirichlet Allocation (LDA) instead of Non-Negative Matrix Factorization (NMF) (Paatero, 1997), as Lee and Seung (2000) demonstrated its superiority on a larger dataset.",2,new
"Given the limitations of the original approach, we employed Support Vector Machines (SVMs) (Cortes and Vapnik, 1995) over Random Forests (Breiman, 2001), as they provided better results on our specific problem.",2,new
"In contrast to the traditional Naive Bayes approach (John and Langley, 1995), we opted for the more accurate K-Nearest Neighbors (KNN) algorithm (Cover and Hart, 1967), which has been shown to perform well in similar domains.",2,new
"Due to the computational costs associated with the original algorithm, we replaced it with the more efficient Expectation-Maximization (EM) algorithm (Dempster et al., 1977), as implemented by McLachlan and Krishnan (2007).",2,new
"This study adopts the Stochastic Gradient Descent (SGD) optimization method (Robbins and Monro, 1951) over the more complex Quasi-Newton method (Broyden, 1970), as it yielded better convergence rates in our experiments.",2,new
"We have chosen to utilize the Principal Component Analysis (PCA) (Hotelling, 1933) over the more computationally expensive Independent Component Analysis (ICA) (Comon, 1994), as it provided a more accurate representation of our data.",2,new
"In light of the high dimensionality of our dataset, we resorted to the faster and more effective k-Means clustering algorithm (MacQueen, 1967) instead of Hierarchical Clustering (Johnson, 1967), as demonstrated by Jain and Dubes (1988).",2,new
"To address the issues with the original approach, we replaced it with the more robust and efficient Hidden Markov Model (HMM) (Rabiner, 1989) as implemented by Rabiner and Juang (1993).",2,new
"Due to the instability of the original algorithm, we opted for the more stable and widely used k-Medoids clustering algorithm (Kaufman and Rousseeuw, 1990) over the more sensitive DBSCAN algorithm (Ester et al., 1996).",2,new
"We have selected the more efficient and accurate gradient boosting method (Freund and Schapire, 1997) over",2,new
"The introduction of the new approach to statistical machine translation, which relies on a sentence-based model (Katz, 2003), has eliminated several key issues associated with the traditional word-based methods, primarily:  The Katz model's ability to capture long-range dependencies in language.",2,new
"By shifting from a word-based to a document-based translation framework (Och & Ney, 2002), many of the limitations of the original approach are addressed, notably:  The Och & Ney method's improved handling of out-of-vocabulary words.",2,new
"The move from a word-centric to a segment-based translation paradigm (Vogel et al., 2005) has significantly reduced the problems inherent in the earlier model, particularly:  Vogel et al.'s solution to the issue of lexical ambiguity.",2,new
"The adoption of a phrase-based model in machine translation (Chen & Zhai, 2004) has resolved several of the difficulties encountered in the word-based approach, notably:  Chen & Zhai's method for handling idiomatic expressions.",2,new
"The transition from a word-based to a sentence-based translation system (Melamed, 2004) has greatly mitigated the problems associated with the original formulation, particularly:  Melamed's technique for improving translation accuracy.",2,new
"The development of the phrase-based machine translation framework (KOCH et al., 2009) has eliminated several of the issues associated with the word-based model, specifically:  KOCH et al.'s solution to the problem of statistical significance.",2,new
"The shift to a document-based approach in machine translation (Collins et al., 2005) has addressed several of the limitations of the traditional word-based methods, particularly:  Collins et al.'s method for improving translation quality.",2,new
"The introduction of the segment-based translation model (Huang et al., 2006) has greatly reduced the problems associated with the earlier word-based approach, particularly:  Huang et al.'s technique for handling domain adaptation.",2,new
"The development of the sentence-based machine translation system (Li et al., 2004) has resolved several of the difficulties encountered in the word-based approach, notably:  Li et al.'s method for improving translation fluency.",2,new
"The adoption of the phrase-based translation framework (Zhang et al., 2006) has eliminated several of the issues associated with the word-based model, specifically:  Zhang et al.'s solution to the problem of lexical choice.",2,new
"The proposed approach significantly surpasses the limitations of earlier statistical machine translation models (Katz, 1987), enabling the direct translation of idiomatic expressions into their corresponding equivalents.",2,new
"This innovative technique builds upon the foundational work of phrase-based models (Chen & Rosenfeld, 1997), but expands upon their capabilities by allowing for more nuanced translations.",2,new
"In contrast to traditional machine translation systems (Sadaoui, 2003), this method enables the translation of contextualized phrases, resulting in more accurate and natural-sounding translations.",2,new
"By leveraging recent advances in neural machine translation (Wu et al., 2016), this technique overcomes the limitations of earlier phrase-based models, producing more idiomatic and fluent translations.",2,new
"This new approach goes beyond the scope of earlier rule-based translation systems (Melamed, 2003), allowing for the direct translation of phrases with cultural and contextual nuances.",2,new
"The proposed method extends the work of statistical machine translation models (Jelinek, 1976), enabling the translation of complex phrases that capture the subtleties of human language.",2,new
"In contrast to earlier machine translation systems (Hutchins, 1986), this technique allows for the translation of phrases with a more natural flow and rhythm.",2,new
"This innovative method builds upon the foundation of phrase-based translation models (Foster et al., 2003), but takes a significant leap forward by enabling the translation of idiomatic expressions.",2,new
"The proposed approach improves upon the limitations of earlier machine translation models (Brown et al., 1990), allowing for the direct translation of phrases with a more precise and accurate meaning.",2,new
"By incorporating recent advances in neural machine translation (Zhang et al., 2019), this technique overcomes the limitations of earlier phrase-based models, producing more fluent and natural-sounding translations.",2,new
"The use of neural network-based language models (Mikolov et al., 2010; Sutskever et al., 2011; Bengio et al., 2013) has been criticized for not adequately addressing the issue of semantic drift in text generation, a limitation that has hindered their adoption in real-world applications.",2,new
"Despite the advancements in deep learning techniques (LeCun et al., 2015; Goodfellow et al., 2016), the incorporation of semantic role labeling in natural language processing has remained a challenging task, with many existing models failing to capture the nuances of human language (Kingsbury, 2006).",2,new
"The application of kernel methods to text classification (Joachims, 1999; Weston et al., 2001) has been widely explored, but their performance often falls short of expectation when dealing with high-dimensional feature spaces and complex linguistic structures (Scholkopf et al., 2001).",2,new
"The development of reinforcement learning algorithms (Sutton and Barto, 1998; Mnih et al., 2013) has led to significant breakthroughs in sequential decision-making, yet their ability to generalize to novel environments remains a subject of ongoing research and debate (Lake et al., 2017).",2,new
"The integration of cognitive architectures with symbolic AI (Langley et al., 2009; Laird et al., 2017) has shown promise in addressing the limitations of neural networks, but their scalability and adaptability in real-world scenarios are yet to be fully evaluated (Kaelbling, 2014).",2,new
"The use of attention mechanisms in neural machine translation (Bahdanau et al., 2015; Vaswani et al., 2017) has improved translation quality, but their dependence on large amounts of parallel data remains a significant drawback (Koehn et al., 2003).",2,new
"The application of transfer learning in natural language processing (Yosinski et al., 2014; Donahue et al., 2014) has been shown to be effective, but its transferability across tasks and domains is still an open question (Pan and Yang, 2010).",2,new
"The development of meta-learning algorithms (Finn et al., 2017; Vinyals et al., 2016) has the potential to adapt to new tasks with minimal training data, but their ability to generalize to unseen tasks remains a subject of ongoing research (Thrun, 1995).",2,new
The incorporation of,2,new
"The introduction of neural machine translation (Vaswani et al., 2017) has revolutionized the field of natural language processing, significantly surpassing the accuracy of rule-based systems (Kaplan et al., 2009).",2,new
"In contrast to traditional rule-based approaches (Melamed, 2004), the use of statistical machine translation (Brown et al., 1993) has shown limited success in real-world applications.",2,new
"Recent advances in deep learning have led to the development of sequence-to-sequence models (Sutskever et al., 2014), which have outperformed traditional phrase-based models (Och and Ney, 2003) in various translation tasks.",2,new
"The use of pre-trained language models (Devlin et al., 2019) has improved the performance of machine translation systems, but they still lag behind the capabilities of human translators.",2,new
"In an effort to improve the efficiency of machine translation, researchers have turned to the development of lightweight models (Klein et al., 2017), which have shown promising results in certain domains.",2,new
"The performance of machine translation systems has been hindered by the lack of parallel corpora (Koehn and Knight, 2003), which has limited the ability to train and evaluate models effectively.",2,new
"In contrast to the success of neural machine translation, the performance of statistical machine translation has remained largely stagnant (Brown et al., 1993).",2,new
"The introduction of attention mechanisms (Bahdanau et al., 2015) has improved the performance of machine translation systems, but the quality of the output still lags behind human translation.",2,new
"The development of machine translation systems has been hindered by the lack of standardization in evaluation metrics (Hutchins, 1990), which has made it difficult to compare the performance of different models.",2,new
"Recent studies have shown that the use of transfer learning (Ruder, 2019) can improve the performance of machine translation systems, but the results are still not as good as those obtained by human translators.",2,new
"However, for data compression algorithms, lossless compression methods (Huffman, 1952; Shannon, 1948) outperform dictionary-based methods (Lempel and Ziv, 1977; Storer and Szymanski, 1982).",2,new
"In the field of natural language processing, rule-based approaches (Jelinek et al., 1986; Young and Hirschberg, 2000) have been surpassed by statistical methods (Chen and Rosenfeld, 1997; Jelinek, 1998).",2,new
"For speech recognition systems, hidden Markov models (Rabiner, 1989; Juang et al., 1990) have proven more effective than template-based methods (Bahl et al., 1983; Rabiner and Juang, 1993).",2,new
"In image processing, wavelet-based methods (Mallat, 1989; Daubechies, 1992) have outperformed traditional block-based approaches (Burt and Adelson, 1983; Jain, 1989).",2,new
"In the realm of natural language generation, corpus-based methods (Elman et al., 1996; Kukich, 1983) have surpassed rule-based systems (Sampson, 1975; Kay, 1984).",2,new
"In the area of information retrieval, vector space models (Salton and McGill, 1983; Deerwester et al., 1990) have proven more effective than Boolean-based methods (Salton, 1971; van Rijsbergen, 1979).",2,new
"For sentiment analysis, supervised learning methods (Pang and Lee, 2008; Liu et al., 2005) have outperformed rule-based approaches (Turney, 2002; Whitelaw et al., 2005).",2,new
"In machine learning, ensemble methods (Breiman, 2001; Dietterich, 2000) have surpassed traditional decision tree-based approaches (Quinlan, 1986; Quinlan, 1993).",2,new
"In the field of recommender systems, collaborative filtering methods (Sarwar et al., 2001; Herlocker et al., 2004) have outperformed content-based approaches (Pazzani and Billsus, 1997; Pazzani, 1999).",2,new
"For topic modeling, Latent Dirichlet Allocation (Blei et al.",2,new
"Despite the progress made in the field of natural language processing, the limitations of current speech recognition systems remain a significant challenge (Sethy et al., 2015), particularly in noisy environments (Varga et al., 2018).",2,new
"The development of more accurate sentiment analysis models has been hindered by the lack of standardized datasets (Bostrom et al., 2014), making it difficult to compare and evaluate different approaches (Kumar et al., 2017).",2,new
"The advancement of neural networks has led to significant improvements in image classification tasks, but the field still struggles with the issue of overfitting (Goodfellow et al., 2014), particularly when dealing with small datasets (Zhang et al., 2016).",2,new
"The integration of deep learning techniques has improved the performance of recommender systems, but the complexity of user preferences remains a significant challenge (Ricci et al., 2015), making it difficult to develop more personalized recommendations (Adomavicius et al., 2011).",2,new
"The growing field of Explainable AI has yet to overcome the issue of interpretability, with many models struggling to provide clear and transparent explanations for their decisions (Lipton, 2018), hindering their adoption in high-stakes applications (Miller, 2019).",2,new
"The development of more accurate machine learning models has been hindered by the lack of robust evaluation metrics (Gupta et al., 2017), making it difficult to assess the performance of different models (Srivastava et al., 2016).",2,new
"The field of computer vision has made significant progress in recent years, but the issue of bias in training datasets remains a significant challenge (Krause et al., 2018), leading to inaccurate results in real-world applications (Buolamwini et al., 2018).",2,new
"The integration of human-computer interaction principles has improved the usability of various systems, but the field still struggles with the issue of user engagement (Hutchinson et al., 2015), making it difficult to develop more effective interfaces (Ducheneaut et al., 2013).",2,new
"The development of more accurate speech recognition systems has been hindered by the lack of standardized speech datasets (Kumat et al., 2017), making it difficult to compare and evaluate different approaches (Wu et al., 2019).",2,new
"The field of natural language generation has made significant progress in recent years, but the issue of coherence and fluency remains a significant",2,new
"The proposed methodology falls short in reconciling the limitations of knowledge-based and rule-based approaches (Duda et al., 2001), which often yield inconsistent results due to the lack of domain expertise.",2,new
"The current framework fails to adequately address the drawbacks of both model-based and data-driven approaches (Bishop, 2006), leading to suboptimal performance in complex scenarios.",2,new
"This approach neglects the fundamental flaws of purely statistical and machine learning-based methods (Mitchell, 1997), which can lead to overfitting and poor generalizability.",2,new
"The proposed solution does not effectively mitigate the shortcomings of both rule-based and knowledge-based systems (Newell & Simon, 1972), resulting in a lack of adaptability and robustness.",2,new
"The methodology presented here overlooks the critical issues associated with model-based and knowledge-based generation (Charniak, 1997), such as the inability to handle ambiguity and uncertainty.",2,new
"The authors' approach fails to address the inherent limitations of both symbolic and connectionist AI (Rosenblatt, 1958), leading to a narrow and inflexible framework.",2,new
"This research neglects the fundamental trade-offs between knowledge-based and statistical approaches (Quinlan, 1986), ultimately resulting in a subpar solution.",2,new
"The proposed methodology does not adequately address the drawbacks of both model-based and data-driven methods (Koza, 1992), which can lead to biased and inaccurate results.",2,new
"The authors' approach ignores the critical limitations of rule-based and knowledge-based systems (Winston, 1975), such as the lack of common sense and real-world applicability.",2,new
"The current framework fails to reconcile the fundamental differences between symbolic and connectionist AI (Minsky & Papert, 1969), resulting in a limited and ineffective solution.",2,new
"Despite the claims made by (Smith et al., 2001) that their model would be able to handle large datasets, our experiments showed that it struggled with even moderate-sized corpora.",2,new
"Unfortunately, the authors of (Johnson et al., 2015) failed to provide a detailed analysis of the potential biases in their proposed algorithm, leaving many questions unanswered.",2,new
"Although (Lee et al., 2018) discussed the importance of feature selection in machine learning, they did not provide a comprehensive comparison of different techniques, which is a significant limitation of their study.",2,new
"Contrary to the assertions of (Kim et al., 2009), our results suggest that the proposed method is not suitable for real-world applications due to its poor scalability.",2,new
"The authors of (Williams et al., 2012) stated that their approach would be more efficient than existing methods, but our evaluation showed that it was actually slower and less accurate.",2,new
"The lack of a systematic evaluation in (Davis et al., 2003) makes it difficult to determine the effectiveness of their proposed technique, which is a significant drawback of their study.",2,new
"Despite the claims of (Harris et al., 2016) that their model was able to handle noisy data, we found that it was highly sensitive to even small amounts of corruption.",2,new
"Unfortunately, (Taylor et al., 2010) did not provide a thorough discussion of the potential limitations of their approach, which is a major omission in their research.",2,new
"Although (Morgan et al., 2014) discussed the importance of data quality in machine learning, they did not provide a detailed analysis of the impact of poor data on their proposed algorithm.",2,new
"The authors of (White et al., 2008) stated that their method was more accurate than existing approaches, but our evaluation revealed that it was actually less accurate and more computationally expensive.",2,new
"Our study found that the performance of the proposed neural network architecture falls short of that reported by (LeCun et al., 2015), who achieved superior results on the MNIST dataset with their convolutional neural network model.",2,new
"In contrast to the findings of (Rosenblatt, 1962), which demonstrated the efficacy of perceptrons in solving simple pattern recognition tasks, our experiments failed to replicate these results using the same dataset.",2,new
"Despite our efforts to improve the speed and efficiency of the algorithm, the results of (Cormen et al., 2009) show that their greedy algorithm outperforms our approach in terms of execution time.",2,new
"The study conducted by (Kumar et al., 2018) reported better accuracy rates on the 20 Newsgroups dataset compared to our own implementation of a Naive Bayes classifier.",2,new
"Unlike the promising results obtained by (Dijkstra, 1959) in solving the shortest path problem, our graph-based algorithm failed to achieve comparable performance on large-scale networks.",2,new
"The recent study by (Srivastava et al., 2014) demonstrated the effectiveness of their LSTM-based model in language translation tasks, whereas our own experiments yielded subpar results.",2,new
"Our experiments on the IMDB dataset did not match the high accuracy rates achieved by (Zhang et al., 2017), who employed a deep learning approach with convolutional and recurrent neural networks.",2,new
"In contrast to the successful application of (Kolmogorov, 1933) in solving the traveling salesman problem, our genetic algorithm failed to find optimal solutions within a reasonable time frame.",2,new
"The results of (Russell and Norvig, 2003) on the game of Tic-Tac-Toe show that their minimax algorithm outperforms our own heuristic-based approach in terms of win rate.",2,new
"The study by (Hinton et al., 2006) demonstrated the effectiveness of their autoencoder-based method in dimensionality reduction, but our own implementation of principal component analysis failed to match these results.",2,new
"A rule-based approach is often limited by its reliance on outdated lexical databases such as WordNet (Fellbaum, 1998), resulting in poor translation accuracy for idiomatic expressions.",2,new
"Traditional phrase-based machine translation models like the IBM Model 2 (Brown et al., 1993) struggle to capture the nuances of human language, leading to suboptimal results in certain contexts.",2,new
"The use of hand-crafted grammatical rules in machine translation can be restrictive and may not accommodate the complexities of natural language, as seen in the work of Melcuk (1995).",2,new
"Statistical machine translation methods, such as IBM Model 1 (Brown et al., 1993), can be ineffective in handling rare or out-of-vocabulary words, compromising overall translation quality.",2,new
"A word-based approach to machine translation often falls short in capturing the subtleties of language, particularly when dealing with figurative language and idiomatic expressions, as noted by Sinclair (1991).",2,new
"The limitations of traditional machine translation methods, such as the reliance on rigid rule-based systems, are well-documented in the work of Kay (2002), highlighting their inability to adapt to the complexities of human language.",2,new
"The use of machine translation techniques based on IBM Model 2 (Brown et al., 1993) can result in poor translation accuracy for specialized domains, where domain-specific terminology and jargon are prevalent.",2,new
"Phrase-based machine translation models, such as the one proposed by Koehn (2004), may not be able to effectively handle the complexities of language, including homophones and polysemous words.",2,new
"A statistical approach to machine translation, as exemplified by IBM Model 1 (Brown et al., 1993), can be prone to errors in cases where the training data is limited or biased, leading to suboptimal results.",2,new
"The reliance on traditional machine translation methods, such as rule-based systems, can be restrictive and may not accommodate the nuances of human language, as demonstrated by the work of Melcuk (1995).",2,new
"The majority of the studies utilized a pre-existing neural network architecture (Rumelhart et al., 1986), with numerous research groups modifying it to suit their needs, introducing novel layers, enhancing the convolutional neural network, and experimenting with different ensemble techniques. However, most of these variations failed to significantly improve upon the original model.",2,new
"Several research groups attempted to improve upon the original probabilistic model (Katz, 1987), but their efforts were often hindered by the complexity of the model and the difficulty in training it effectively. As a result, many of these variations were unable to achieve substantial improvements over the baseline.",2,new
"A number of researchers employed various optimization techniques (Bertsekas, 1995) to fine-tune the performance of the original algorithm, but these efforts were often met with limited success. The modifications made to the algorithm's parameters and structure did not yield the desired improvements in accuracy.",2,new
"The majority of the studies based their approaches on an existing decision tree algorithm (Breiman, 2001), with different teams introducing new features, enhancing the tree's complexity, and experimenting with different pruning techniques. However, these variations often failed to demonstrate significant improvements over the original algorithm.",2,new
"Several research teams attempted to improve the performance of the original clustering algorithm (MacQueen, 1967), but their efforts were often marred by the high computational complexity of the algorithm and the difficulty in determining the optimal number of clusters.",2,new
"Most of the studies employed a variant of the original support vector machine algorithm (Cortes and Vapnik, 1995), with different groups introducing new kernels, enhancing the regularization techniques, and experimenting with different ensemble methods. However, these variations often failed to achieve substantial improvements over the baseline.",2,new
"A number of researchers based their approaches on an existing neural network model (Hopfield, 1982), with different teams modifying the architecture, introducing new layers, and experimenting with different training techniques. However, these variations often failed to demonstrate significant improvements in performance.",2,new
"Several research groups attempted to improve the performance of the original regression algorithm (Hastie et al., 2009), but their efforts were often hindered by the difficulty in selecting the optimal set of features and the high computational cost of the algorithm.",2,new
"The majority of the studies employed a variant of the original k-means algorithm (Hartigan and Wong, 1979), with different teams introducing new initialization methods, enhancing the convergence criteria, and experimenting with different distance metrics. However, these variations often failed",2,new
"Recent studies have shown that the application of machine learning algorithms (Bengio et al., 2003; Goodman, 2001) to natural language processing tasks has been met with limited success (Levin, 1993).",2,new
"The use of deep neural networks (Rumelhart et al., 1986; Hinton et al., 2006) in speech recognition has not yielded the expected improvements (Davis and Mermelstein, 1980).",2,new
"Despite advances in text summarization techniques (Mani and May, 1999; Marcu, 2000), the task remains a challenging one (Hovy and Lin, 1999).",2,new
"The adoption of statistical machine translation methods (Brown et al., 1993; Fraser and Marcu, 2007) has not lived up to the initial hype (Melamed, 2001).",2,new
"Research on sentiment analysis using rule-based approaches (Turney, 2002; Liu et al., 2005) has been outperformed by more advanced techniques (Pang and Lee, 2008).",2,new
"The use of reinforcement learning in natural language processing (Sutton and Barto, 1998; Singh et al., 1999) has not seen widespread adoption (Kaelbling, 1993).",2,new
"The development of more sophisticated language models (Bengio et al., 2006; Mikolov et al., 2010) has not led to significant improvements in language understanding (Levin, 1993).",2,new
"The application of knowledge graphs to information retrieval (Etzioni et al., 2005; Mihalcea et al., 2006) has not met the expected results (Baeza-Yates and Ribeiro, 1999).",2,new
"The use of active learning in text classification (Settles, 2009; Roy and McCallum, 2001) has not been widely adopted (Cohn, 1996).",2,new
"The integration of multimodal learning (Bregler et al., 2000; Wang et al., 2006) into natural language processing has been slow to gain traction (Lambert, 2002).",2,new
"Despite recent advances in deep learning-based approaches (Hinton et al., 2006) to natural language processing (NLP), phrase-based models (Koehn et al., 2003) still have room for improvement in terms of handling out-of-vocabulary words.",2,new
"The limitations of rule-based machine translation systems (Melamed, 2003) have hindered their widespread adoption, as they often struggle to capture nuances in language, unlike more recent statistical approaches (Crammer et al., 2002).",2,new
"Although the IBM models (Brown et al., 1993) laid the groundwork for modern statistical machine translation (SMT), their lack of robustness in handling ambiguity has been a major setback in achieving higher accuracy.",2,new
"The reliance on pre-existing linguistic resources (Brown et al., 1990) in phrase-based SMT has made it challenging to develop more comprehensive models, as these resources often fail to account for the complexities of modern language use.",2,new
"The traditional phrase-based approach (Koehn et al., 2003) to SMT has been largely surpassed by more advanced neural network-based methods (Bengio et al., 2003), which have consistently demonstrated superior performance in recent studies.",2,new
"The phrase-based models (Och and Ney, 2004) have shown promise in handling certain types of ambiguity, but their inability to generalize to more complex linguistic phenomena has hindered their widespread adoption in the field.",2,new
"Despite the significant progress made in phrase-based SMT, the lack of robust evaluation metrics (Chen and Zweig, 2006) has made it difficult to accurately assess the performance of these models and identify areas for improvement.",2,new
"The traditional rule-based approaches (Melamed, 2003) to machine translation have been largely surpassed by more advanced statistical methods (Crammer et al., 2002), which have demonstrated superior performance in a variety of evaluation metrics.",2,new
"The limitations of phrase-based SMT (Koehn et al., 2003) have become increasingly apparent in recent years, as more advanced neural network-based models (Bengio et al., 2003) have achieved state-of-the-art results in a range of tasks.",2,new
"The reliance on pre-existing linguistic resources (Brown et al., 1990) has been a major limitation of phrase-based SMT, as these resources often fail to capture the complexities of modern language use, leading to suboptimal performance in certain tasks.",2,new
"Recent studies on speech recognition systems (SR) indicate that the incorporation of deep learning techniques (Hinton et al., 2006; Graves et al., 2013) has led to a decline in the performance of traditional Hidden Markov Model (HMM) approaches (Rabiner, 1989).",2,new
"The analysis of recent research on natural language processing (NLP) tasks reveals that the adoption of graph-based models (Kipf and Welling, 2016; Hamilton et al., 2017) has surpassed the capabilities of traditional bag-of-words (BOW) models (Turney, 2000).",2,new
"The development of computer vision systems has been hindered by the limitations of traditional feature-based approaches (Lowe, 1999; Dalal and Triggs, 2005), which have been outperformed by the more recent deep learning-based methods (Krizhevsky et al., 2012; Sermanet et al., 2014).",2,new
"The evaluation of recent studies on information retrieval (IR) systems shows that the shift from traditional term-based models (Salton and McGill, 1983; Baeza-Yates and Ribeiro-Neto, 1999) to vector space models (VSM) (Salton and McGill, 1983) has resulted in a decrease in retrieval performance.",2,new
"The analysis of recent research on recommender systems reveals that the use of traditional collaborative filtering (CF) approaches (Sarwar et al., 2001; Linden et al., 2003) has been surpassed by more recent hybrid methods (Burke, 2002; Koren et al., 2009).",2,new
"The development of text classification systems has been hindered by the limitations of traditional Naive Bayes (NB) approaches (Domingos and Pazzani, 1997; Rennie et al., 2003), which have been outperformed by the more recent support vector machine (SVM) models (Cortes and Vapnik, 1995; Joachims, 1999).",2,new
"The evaluation of recent studies on clustering algorithms shows that the traditional hierarchical clustering methods (Johnson, 1967; Sneath and Sokal, 1973) have been outperformed by the more recent k-means clustering algorithm (MacQueen, 1967; Hartigan, 1975).",2,new
The analysis of recent research on topic modeling reveals that the traditional Latent Semantic Analysis (LSA,2,new
"Their experiment (2018) employed a neural machine translation model akin to the work by Bengio et al. (2003), yet the baseline model still surpassed their proposed system.",2,new
"A comparative study conducted by (2012) utilized a statistical machine translation model similar to the one described by Melamed (2004), but the results indicated that the conventional model excelled in overall performance.",2,new
"In a parallel experiment, (2015) drew inspiration from the language model developed by Zhai et al. (2001), only to see their custom model fall short of the standard approach.",2,new
"The researchers in (2009) attempted to replicate the success of the machine translation model presented by Koehn (2005), but their own model failed to match the baseline's efficiency.",2,new
"A recent investigation (2020) relied on the phrase-based machine translation model proposed by Och (2003), and, unfortunately, the conventional model outperformed their system.",2,new
"A study by (2011) emulated the word alignment model of Brown et al. (1990), but their results showed that the standard model outshone their custom system.",2,new
"The researchers in (2016) attempted to adapt the statistical machine translation model of Koehn and Knight (2004), but their model did not surpass the baseline's performance.",2,new
"In a controlled experiment (2014), (2008) drew upon the IBM word-translation Model 2 (Brown et al., 1990), and their proposed model was outperformed by the standard model.",2,new
"A comparative analysis by (2019) utilized the neural machine translation model of Sutskever et al. (2014), but the results showed that the conventional model excelled in overall performance.",2,new
"The researchers in (2007) drew inspiration from the phrase-based machine translation model of Koehn (2004), but their custom model failed to outperform the baseline model.",2,new
"A notable limitation of the HMM-based part-of-speech taggers (Church, 1988) is the reliance on pre-trained models, which may not generalize well to unseen data.",2,new
"One significant drawback of the maximum entropy taggers (McDonald et al., 2005) is the computational overhead associated with estimating the model parameters.",2,new
"A major constraint of the machine translation systems based on word alignment (Koehn et al., 2007) is the difficulty in handling out-of-vocabulary words.",2,new
"A significant limitation of the statistical machine translation models (Brown et al., 1990) is the poor performance on long sentences.",2,new
"The primary weakness of the hidden Markov models for language modeling (Bakis et al., 1994) is the slow convergence of the estimation algorithm.",2,new
"A major shortcoming of the word-based language models (Kneser & Ney, 1995) is the failure to capture long-range dependencies.",2,new
"The key limitation of the stochastic transducers (Becker et al., 1999) is the lack of robustness to noisy input data.",2,new
"A significant drawback of the discriminative language models (Chen & Rosenfeld, 1997) is the high computational cost of training.",2,new
"A major constraint of the generative language models (Jelinek et al., 1991) is the difficulty in handling multi-word expressions.",2,new
"The primary limitation of the memory-based language models (Werbos, 1990) is the large memory requirements for storing the learned patterns.",2,new
"In comparison to other machine learning models (LeCun et al., 1989; Rumelhart et al., 1986), the proposed algorithm fails to demonstrate significant improvements in image classification tasks for large datasets.",2,new
"Compared to traditional optimization techniques (Fletcher and Reeves, 1964; Polak, 1971), the gradient-based method does not outperform in terms of convergence speed and accuracy for complex optimization problems.",2,new
"Unlike other natural language processing frameworks (Jurafsky and Martin, 2009; Manning and Schtze, 1999), the proposed system falls short in handling out-of-vocabulary words and domain adaptation tasks.",2,new
"When compared to existing clustering algorithms (Hartigan, 1975; MacQueen, 1967), the new hierarchical clustering approach fails to provide consistent results in high-dimensional data spaces.",2,new
"The proposed neural network architecture (Krizhevsky et al., 2012; Sermanet et al., 2014) does not demonstrate a notable advantage over traditional convolutional neural networks in image recognition tasks.",2,new
"In contrast to other information retrieval systems (Baeza-Yates and Ribeiro-Neto, 1999; Salton and McGill, 1983), the proposed retrieval model does not show improved performance in query expansion and relevance feedback.",2,new
"Unlike other machine learning approaches (Bishop, 2006; Haykin, 1998), the kernel-based method does not exhibit a significant advantage in handling high-dimensional data and non-linear relationships.",2,new
"The proposed algorithm for topic modeling (Blei et al., 2003; Hofmann, 1999) does not outperform existing techniques in terms of topic discovery and coherence for large text corpora.",2,new
"Compared to other computer vision techniques (Fischler and Bolles, 1981; Horn, 1986), the proposed stereo matching method does not demonstrate improved accuracy and robustness in real-world scenarios.",2,new
"When compared to existing natural language generation models (Koehn et al., 2003; Papineni et al., 2002), the proposed sequence-to-sequence model fails to generate coherent and grammatically correct text for certain domains and styles.",2,new
"The analysis employed a modified version of the Smith et al. (2015) framework, incorporating additional parameters to account for the variability in linguistic context, a limitation of the original model.",2,new
"The proposed approach utilizes a combination of techniques from the work of Johnson (1998) and Lee et al. (2012), but falls short in its ability to capture nuances of idiomatic expressions.",2,new
"A novel application of the technique by Davis et al. (2019) was adapted to suit the needs of the current study, but the results showed a lack of generalizability across different datasets.",2,new
"The methodology drew upon the insights of Miller et al. (2000), yet failed to address the issue of data quality, leading to inconsistent results.",2,new
"The study leveraged an extension of the framework developed by Kim et al. (2011), but the findings were hindered by the restrictive nature of the experimental design.",2,new
"A modified version of the algorithm by Thompson (2001) was implemented, but the results were compromised by the presence of outliers in the dataset.",2,new
"The research built upon the work of Patel et al. (2018), but the study's conclusions were undermined by the small sample size and limited scope.",2,new
"The approach used a variant of the method proposed by Hall et al. (2016), but the outcomes were marred by the inability to account for individual differences.",2,new
"The study integrated elements of the framework by Taylor et al. (2013), but the results were inconclusive due to the presence of confounding variables.",2,new
"The analysis relied on a modified version of the model by White et al. (2017), but the findings were limited by the lack of longitudinal data.",2,new
"The approach was proposed as an alternative to word-based methods (e.g., (Chen et al., 2015a; Manning and Schtze, 1999b; Vapnik, 1998)), which are highly susceptible to errors.",2,new
"The proposed algorithm was designed to replace phrase-level methods (e.g., (Baker et al., 2008a; Jurafsky and Martin, 2000b; Manning and Sag, 1999)), which are often marred by inaccuracies.",2,new
"The new technique was intended to overcome sentence-based methods (e.g., (Goldberg, 1976; Hays, 1964; Winograd, 1972)), which are extremely sensitive to ambiguities.",2,new
"The approach was developed to supplant vector-space methods (e.g., (Deerwester et al., 1990; Salton and McGill, 1983; Van Rijsbergen, 1979)), which are frequently plagued by inconsistencies.",2,new
"The method was designed as a replacement for document-based methods (e.g., (Cohen et al., 1996; Lewis, 1992; Ponzetto and Strube, 2010)), which are very prone to bias.",2,new
"The proposed solution was intended to overcome term-based methods (e.g., (Baeza-Yates and Navarro, 1999; Croft et al., 2009; Salton and McGill, 1983)), which are often hampered by oversimplifications.",2,new
"The technique was developed to supplant corpus-based methods (e.g., (Grishman, 1986; Hobbs, 1990; Sager, 1991)), which are frequently limited by their scope.",2,new
"The approach was proposed as an alternative to token-based methods (e.g., (Harris, 1954; Joachims, 1998; Schtze, 1998)), which are highly susceptible to noise.",2,new
"The method was designed to replace feature-based methods (e.g., (Atkinson and Shiffrin, 1968; Kintsch, 1980; Rumelhart, 1980)), which are often marred by inaccuracies.",2,new
"The technique was developed to overcome metric-based methods (e.g., (Guetter, 1968; Kintsch, 1980; Quillian, 1968)), which are frequently plagued by inconsistencies.",2,new
2 Methodology The results of this study are in stark contrast to those of previous research employing machine learning techniques for natural language processing (Huang et al. 2001; Manning & Schutze 1999; Vapnik 1998; Freund & Schapire 1997; Lin 1998; Joachims 1999; Collins 1996; McCallum & Nigam 1998; Collins & Duffy 2002; Yarowsky 1995).,2,new
"3 Discussion Despite the advances in deep learning, the current study reveals a significant gap in the application of recurrent neural networks for text classification (Bengio et al. 2001; Seide et al. 2011; Graves 2012; Sutskever et al. 2011; Mikolov et al. 2010; Bengio et al. 2003; Mnih et al. 2012; Graves 2013; Graves & Jaitly 2014; Zhang et al. 2016).",2,new
4 Conclusion The findings of this study contradict previous research on the effectiveness of word embeddings for sentiment analysis (Turney 2002; Turney & Littman 2005; Le & Mikolov 2014; Goldberg & Levy 2014; Mikolov et al. 2013; Hill et al. 2015; Socher et al. 2013; Bojanowski et al. 2016; Pennington et al. 2014; Kiros et al. 2015).,2,new
5 Limitations The current study's results diverge from the outcomes of previous investigations into the use of convolutional neural networks for text feature extraction (LeCun et al. 1998; Krizhevsky et al. 2012; Sermanet et al. 2014; Simonyan & Zisserman 2014; Long et al. 2015; Szegedy et al. 2015; He et al. 2016; Szegedy et al. 2016; Girshick et al. 2014; Girshick et al. 2015).,2,new
The data collected in this study contrast sharply with the findings of previous research on the impact of pre-training on language model performance (Devlin et al. 2018; Howard & Ruder 2018; Radford et al. 2018; Vaswani,2,new
"The limited size and diversity of the Corpus of Contemporary American English (COCA) (Davies, 2010) restrict its effectiveness in capturing the nuances of modern language, particularly in the context of emerging trends and colloquial expressions.",2,new
"Despite its widespread use, the accuracy of part-of-speech tagging in the Brown Corpus (Kuera and Francis, 1967) is compromised by the presence of inconsistent annotation and outdated linguistic standards.",2,new
"The dearth of annotated data in the Open Multimodal Every-day Activity (OMEA) corpus (Rohrbach et al., 2012) hinders the development of robust models for multimodal analysis, limiting their applicability to real-world scenarios.",2,new
"The lack of contextual information in the Text REtrieval Conference (TREC) corpus (Voorhees and Harman, 2005) makes it unsuitable for training models that rely on nuanced understanding of query intent and user behavior.",2,new
"The absence of domain-specific terminology in the Reuters Corpus (Lewis et al., 2004) renders it inadequate for training models that require specialized knowledge in fields such as law, medicine, or finance.",2,new
"The insufficiency of sentence-level annotations in the Semcor (Miller et al., 1993) corpus restricts its utility in tasks that require fine-grained analysis of syntactic structure and semantic relationships.",2,new
"The sparse annotation of idiomatic expressions in the Wall Street Journal (WSJ) corpus (Francis and Kucera, 1979) impedes the development of models that can accurately identify and interpret figurative language.",2,new
"The limited geographical scope of the International Corpus of Learner English (ICLE) (Granger, 2002) limits its representativeness of non-native speaker language varieties, making it less useful for training models that aim to generalize across diverse linguistic backgrounds.",2,new
"The dearth of spoken language data in the Switchboard Corpus (Godfrey and Holliman, 1997) hampers the development of speech recognition systems that can accurately handle informal, conversational speech.",2,new
"The outdated nature of the Brown Corpus (Kuera and Francis, 1967) makes it less suitable for training models that require up-to-date knowledge of linguistic trends and shifts in language use.",2,new
"The analysis revealed several limitations in the current study, including a lack of generalizability to other populations (Gill and Johnson, 1997; Smith et al., 2004; Taylor, 2001; Martin, 2005).",2,new
"The implementation of the new algorithm was marred by a series of technical issues, including frequent crashes and slow processing times (Kim and Lee, 2008; Patel et al., 1999; Hall, 2003; Davis, 2006).",2,new
"A major flaw in the experimental design was the inconsistent use of control groups, which compromised the validity of the results (Brown and Wilson, 2001; Chen et al., 2007; Kim, 2002; Reed, 2004).",2,new
"The study's findings were hindered by a number of methodological issues, including sampling bias and incomplete data (Miller and Davis, 2003; Hall et al., 2009; Lee, 2005; Patel, 2000).",2,new
"The computational model's performance was hampered by a series of optimization problems, including slow convergence and poor generalization (Graham and Thompson, 1998; Brown et al., 2002; Martin et al., 2008; Davis, 2001).",2,new
"A critical evaluation of the study's methodology revealed several areas for improvement, including the need for more robust statistical analysis (Kim et al., 2006; Reed et al., 2003; Taylor et al., 2009; Hall, 2007).",2,new
"The results of the study were limited by a number of experimental design flaws, including a lack of randomization and inadequate sample size (Chen and Brown, 2004; Miller et al., 2008; Lee, 2002; Graham, 2000).",2,new
"The study's conclusions were compromised by several methodological issues, including the use of outdated data and biased sampling techniques (Smith and Johnson, 2005; Patel et al., 2001; Reed, 2003; Davis, 2009).",2,new
"The analysis of the data was complicated by a series of computational challenges, including data inconsistencies and algorithmic errors (Gill and Wilson, 2006; Kim, 2004; Brown, 2000; Taylor, 2008).",2,new
"The study's findings were hindered by a number of theoretical limitations, including a narrow scope and limited generalizability (Hall and",2,new
"The limitation of their proposed algorithm is due to its reliance on the outdated WordNet lexical database (Fellbaum, 1998).",2,new
"This is attributed to the fact that their model's training data, the Brown Corpus (Francis & Kucera, 1967), has a biased distribution of word frequencies.",2,new
"Their approach is hindered by the lack of adequate annotation in the Corpus of Contemporary American English (COCA) (Davies, 2008).",2,new
"The insufficiency of their methodology is a direct result of their reliance on the simplified annotation scheme of the Ontario Hindi-English Treebank (Kumar et al., 2007).",2,new
"Their results are compromised due to the incomplete annotation of the Prague Dependency Treebank (Bosque & Schlkopf, 2000).",2,new
"The authors' conclusion is weakened by the inadequate annotation of the Swedish Dependency Treebank (Ahlberg et al., 2006).",2,new
"The proposed method is limited by its dependence on the outdated annotation standards of the Lancaster Corpus of Mandarin Chinese (Xu et al., 2011).",2,new
"Their findings are compromised by the lack of detailed annotation in the Toronto Book Corpus (Burnard & Aston, 1998).",2,new
"The results of their study are marred by the incomplete annotation of the Leipzig Corpora Collection (Goldhahn et al., 2012).",2,new
"The authors' methodology is flawed due to their reliance on the simplified annotation of the Freiburg Corpus of Spoken English (Lenk et al., 2015).",2,new
"The computational expense of this approach can be considerable, as demonstrated in the work of Brown et al. (1990).",2,new
"The high cost of data annotation can be a significant barrier, as seen in the study of Church (1988).",2,new
"This method's computational requirements can be substantial, as highlighted in the research of Manning and Schtze (1999).",2,new
"The processing power needed for this task can be quite extensive, as shown in the paper of Jurafsky and Martin (2000).",2,new
"The expense associated with this approach can be substantial, as noted by the authors of the Stanford Natural Language Processing Group (2002).",2,new
"The computational resources required for this task can be significant, as reported by the study of Vapnik (1998).",2,new
"The high computational demands of this method can be a major drawback, as illustrated in the research of Goodfellow et al. (2016).",2,new
"The processing power needed for this task can be substantial, as demonstrated by the work of Lafferty et al. (2001).",2,new
"The cost of implementing this approach can be considerable, as observed by the authors of the MIT Speech and Language Processing Group (2015).",2,new
"The computational requirements of this method can be substantial, as highlighted in the study of Manning et al. (2008).",2,new
"The current benchmark dataset for sentiment analysis, the Stanford Sentiment Treebank (Socher et al., 2013), is severely limited by its focus on movie reviews, which only scratches the surface of the complexities of human emotions.",2,new
"The lack of a comprehensive dataset for named entity recognition, such as the one proposed by Bunescu and Pasca (2006), is a significant obstacle to advancements in this field.",2,new
"The widely used WordNet lexical database (Miller, 1995) falls short in capturing the nuances of word meanings, particularly in the context of figurative language and idioms.",2,new
"The small sample size of the popular ImageNet dataset (Deng et al., 2009) is a major limitation when training convolutional neural networks for image classification tasks.",2,new
"The limited availability of annotated data for machine translation tasks, such as the one provided by the Montreal Corpus (L'Hostis and Simard, 1993), hinders the development of more accurate translation models.",2,new
"The absence of a standard evaluation metric for natural language processing tasks, as discussed in the work of Ponte and Croft (1998), leads to inconsistent and unfair comparisons between models.",2,new
"The current state of the art in speech recognition technology is hindered by the lack of a large-scale, annotated speech dataset, such as the one proposed by Paul et al. (2010).",2,new
"The reliance on outdated data for training natural language processing models, such as the Brown Corpus (Francis and Kucera, 1979), can lead to suboptimal performance in real-world applications.",2,new
"The small number of participants in the widely used DARPA Communicator Spoken Language Understanding (SLU) corpus (Bilmes et al., 1999) is a significant limitation when training and testing spoken language understanding systems.",2,new
"The insufficiency of the widely used TRECVID dataset (Smeaton et al., 2001) for video analysis tasks, particularly in terms of diversity and size, is a major obstacle to advancements in this field.",2,new
"The proposed methodology for analyzing linguistic structures in the study of Inuktitut language (Roberge & Heinrich, 2008) is inadequate for handling complex morphological processes, such as polysynthesis and agglutination, which are prevalent in this language, necessitating the development of a more sophisticated annotation scheme, such as the one employed by the Inuktitut Dependency Treebank.",2,new
"The reliance on the Stanford Parser (Klein & Manning, 2003) for parsing Germanic languages is insufficient for capturing the intricate grammatical relationships in languages with free word order, such as Turkish, thus the use of the Turkish Dependency Treebank's annotation scheme (Kabak & Backus, 2008) is essential for a more accurate analysis.",2,new
"Due to the complexities of inflectional morphology in the Basque language, the annotation scheme used in the Penn Treebank (Marcus et al., 1993) is not suitable for representing the verb-subject-object word order, which often results in non-projective constructions, necessitating the adoption of the dependency-based annotation scheme of the Basque Dependency Treebank (Hovy et al., 2006).",2,new
"The annotation scheme employed in the Treebank of Russian (Bosco et al., 2006) is not capable of accurately representing the complex morphology and syntax of the Russian language, particularly the use of cases and declensional endings, thus a more suitable approach is the one used in the Russian Dependency Treebank (Krylov et al., 2010).",2,new
"The current annotation scheme used in the Chinese Treebank (Xue et al., 2004) is inadequate for representing the complex linguistic phenomena in Chinese, such as tone and diachronic changes, which are crucial for understanding the language's historical development, therefore the use of the Chinese Dependency Treebank's annotation scheme (Xu et al., 2003) is necessary.",2,new
"The application of the parse trees from the Prague Dependency Treebank (Linguistic Data Consortium, 2001) to the analysis of the Polish language is not effective due to the language's unique grammatical features, such as the use of cases and agreement, which require a more sophisticated annotation scheme, such as the one used in the Polish Dependency Treebank (Grzymaa-Busse & Szpyra-Kozowska, 2010).",2,new
"The annotation scheme used in the Treebank of English (Marcus et al., 1993) is insufficient for capturing the complexities of the",2,new
"The distinction between semantic and pragmatic inference has been challenging to establish in many cases, and the framework proposed by Hymes (1964) falls short in providing a clear solution.",2,new
"Determining the scope of a token's semantic role has proven to be a daunting task, and the lexical resources compiled by WordNet (Fellbaum 1998) have not been sufficient to address this issue.",2,new
"Identifying the nuances of context-dependent meaning has been a persistent problem, and the theoretical framework outlined by Grice (1975) has not provided a clear path forward.",2,new
"The task of pinpointing the exact moment when a linguistic structure shifts from one type to another has been difficult to accomplish, and the computational models developed by Jurafsky and Martin (2000) have not been able to accurately capture this phenomenon.",2,new
"It has been hard to discern the underlying motivations behind a speaker's choice of linguistic form, and the sociolinguistic analysis presented by Labov (1972) has not offered a comprehensive explanation.",2,new
"The challenge of isolating the role of cognitive factors in language processing has been an ongoing issue, and the cognitive models proposed by Levelt (1989) have not been able to fully account for the complexities involved.",2,new
"The task of distinguishing between formal and informal language has been a difficult one, and the linguistic theory developed by Labov (1972) has not provided a clear distinction between the two.",2,new
"The problem of identifying the specific factors that influence a speaker's language choice has been a persistent one, and the sociolinguistic study by Fishman (1972) has not been able to fully capture the complexity of this issue.",2,new
"It has been a challenge to determine the extent to which linguistic structure affects the interpretation of meaning, and the linguistic analysis presented by Chomsky (1957) has not been able to provide a complete explanation.",2,new
"The difficulty of isolating the role of pragmatics in language use has been a long-standing issue, and the pragmatic theory developed by Levinson (1983) has not been able to fully account for the nuances involved.",2,new
"Recent studies (Deng et al. 2001; Collins et al. 2002; Koller and Morgan 2003) have failed to replicate the findings of earlier work by Brown, Cocke, and Pietra (1988), Manning and Schtze (1999), and Vapnik (1995) on machine learning algorithms.",2,new
"Subsequent research (Li et al. 2004; McCallum et al. 2005; Zhang and Wallace 2006) has not built upon the theoretical framework proposed by Cover and Thomas (1991), Geman and Geman (1992), and Kolmogorov (1933) in the field of information theory.",2,new
"More recent work (Kumar et al. 2007; Taskar et al. 2004; Sutton and Barto 1998) has overlooked the contributions of earlier researchers like Pearl (1988), Spirtes and Glymour (1991), and Suppes (1970) in the area of causal inference.",2,new
"Current studies (Mnih et al. 2015; Silver et al. 2016; LeCun et al. 2015) have not improved upon the results of earlier research by Hopfield (1982), Anderson (1972), and Widrow and Hoff (1960) in the domain of neural networks.",2,new
"The work of subsequent researchers (Fei-Fei et al. 2006; Lowe et al. 2001; Viola and Jones 2001) has not expanded upon the ideas presented by earlier authors such as Marr (1982), Ullman (1979), and Marr and Nishihara (1978) in computer vision.",2,new
"Recent studies (Arjovsky et al. 2017; Goodfellow et al. 2014; Radford et al. 2015) have neglected the contributions of earlier researchers like Rosenblatt (1958), Minsky and Papert (1969), and Werbos (1974) in the field of deep learning.",2,new
"Subsequent research (Wang et al. 2018; He et al. 2016; Girshick et al. 2014) has not built upon the theoretical foundations laid by earlier researchers such as Duda and Hart (1973), Nilsson (1965), and Rosenfeld (1970) in the area of computer vision.",2,new
More recent work (Lipton et al. 201,2,new
"The application of the Viterbi algorithm (Viterbi, 1967) is hindered by its inability to account for the complexities of real-world sequential data when not accompanied by a proper smoothing technique.",2,new
"Without the incorporation of the Baum-Welch re-estimation method (Baum et al., 1970), the Hidden Markov Model's performance is severely compromised in practice.",2,new
"The reliance on the maximum likelihood estimation (MLE) principle (Kullback, 1959) without regularization is not a viable approach when dealing with overparameterized models.",2,new
"The absence of the Jeffreys prior (Jeffreys, 1946) significantly reduces the effectiveness of Bayesian inference in model selection.",2,new
"Without the incorporation of the Gibbs sampling method (Geman and Geman, 1984), MCMC algorithms are often trapped in local optima.",2,new
"The utilization of the least squares criterion (Gauss, 1809) as an optimization method is limited by its sensitivity to outliers in the data.",2,new
"The neglect of the EM algorithm's (Dempster et al., 1977) convergence properties leads to unreliable results in model fitting.",2,new
"The failure to account for the effects of overfitting (Hastie et al., 2009) when using the minimum description length principle (Rissanen, 1978) results in poor generalization performance.",2,new
"The reliance on the Laplace smoothing (Laplace, 1774) method alone is insufficient for handling the issue of word frequency estimation in language models.",2,new
"The exclusion of the Kalman filter's (Kalman, 1960) recursive estimation capabilities severely limits its applicability in real-time signal processing.",2,new
"Although recent studies on deep learning techniques (LeCun et al., 1989) emphasize the importance of feature engineering, existing literature (Domingos, 1996) and popular machine learning textbooks (Witten and Frank, 2000) often overlook the potential drawbacks of using engineered features.",2,new
"Despite the growing popularity of ensemble methods (Hastie et al., 2009), traditional statistical models (Friedman, 2001) and data mining research papers (Hand et al., 2001) tend to focus on individual model performance rather than their collective limitations.",2,new
"In contrast to the conventional wisdom in data analysis (Tukey, 1977), recent research on data visualization (Cleveland, 1993) highlights the potential pitfalls of relying solely on graphical representations of data.",2,new
"Although some studies suggest that neural networks can learn complex patterns (Bishop, 1995), many machine learning textbooks (Mitchell, 1997) and research papers (Breiman, 2001) fail to discuss the potential risks of overfitting.",2,new
"While many researchers emphasize the importance of model interpretability (Lipton, 2018), existing literature on model selection (Hastie et al., 2009) and algorithm design (Bishop, 2006) often neglect the trade-offs involved in making models more transparent.",2,new
"Despite the widespread use of clustering algorithms (Jain, 2010), some studies (Hartigan, 1975) and statistical texts (Everitt, 1993) point out the limitations of these methods in handling high-dimensional data.",2,new
"In contrast to the common practice of using simple metrics (Friedman, 2001), recent research on data quality (Donoho, 2006) highlights the need for more nuanced measures of data quality and their impact on model performance.",2,new
"Although some researchers focus on the benefits of regularization techniques (Tibshirani, 1996), many machine learning textbooks (Duda et al., 2001) and research papers (Bishop, 2006) overlook the potential side effects of regularization on model complexity.",2,new
"While many studies emphasize the importance of data preprocessing (Kohavi, 1995), existing literature on data mining (Fayyad et al., 1996) and data warehousing (Inmon, 2002) often neglect the impact of preprocessing on model accuracy.",2,new
In contrast to the conventional approach of relying on a single evaluation metric (Braun,2,new
"The application of the kappa coefficient (Cohen, 1960; Fleiss, 1971) is not feasible in this context due to the dynamic nature of the classification categories, which are influenced by the varying degrees of uncertainty in the dataset.",2,new
"The use of the Fleiss' kappa statistic (Fleiss, 1971) is inappropriate in this study, as the classification schemes are context-dependent and change in response to the complexity of the semantic relationships between words.",2,new
"The inter-rater reliability measures, such as Cohen's kappa (Cohen, 1960; Scott, 1955), cannot be employed here because the categorization systems are sensitive to the nuances of the linguistic context and the number of annotators involved.",2,new
"The kappa statistic (Cohen, 1960; Light, 1971) is not a suitable metric for evaluating the agreement between annotators in this study, due to the fact that the classification categories are not fixed and are influenced by the ambiguity of the linguistic expressions.",2,new
"The reliability coefficients, including the kappa statistic (Cohen, 1960; Landis & Koch, 1977), cannot be applied in this research because the classification systems are highly dependent on the context and the number of annotators involved.",2,new
"The application of the Cohen's kappa coefficient (Cohen, 1960; Byrt, 1996) is not feasible in this study due to the dynamic nature of the classification categories, which are influenced by the varying degrees of uncertainty in the dataset.",2,new
"The use of the Fleiss' kappa statistic (Fleiss, 1971) is not appropriate in this research, as the classification schemes are context-dependent and change in response to the complexity of the semantic relationships between words.",2,new
"The kappa statistic (Cohen, 1960; Altman, 1991) is not a suitable metric for evaluating the agreement between annotators in this study, due to the fact that the categorization systems are sensitive to the nuances of the linguistic context and the number of annotators involved.",2,new
"The reliability coefficients, including the Cohen's kappa (Cohen, 1960; Hallenbeck, 1989), cannot be applied in this research because the classification systems are highly dependent on the context and the number of annotators involved.",2,new
"The application of the kappa statistic (Cohen, 1960; Feinberg, 1977) is not feasible in this study due to the dynamic nature of the classification categories, which are influenced by the varying",2,new
"The application of machine learning algorithms to natural language processing has been met with significant challenges since its inception (Brown, 1987) and in the field of artificial intelligence (Russell & Norvig, 2003), where numerous researchers have highlighted several limitations.",2,new
"Despite the widespread adoption of sentiment analysis techniques since their introduction in the 1960s (Osgood et al., 1957) and in the field of computational linguistics (Jurafsky & Martin, 2000), various researchers have consistently criticized their accuracy.",2,new
"The use of deep learning methods in computer vision has been plagued by several issues since their introduction in the 1990s (LeCun et al., 1998) and in the field of robotics (Szeliski, 2010), where numerous experts have pointed out the need for improvement.",2,new
"Since its inception in the 1980s (Kuhn, 1981) and in the field of statistics (Berk, 2008), the application of regression analysis has been marred by several difficulties, with many researchers citing the need for more robust methods.",2,new
"The introduction of neural networks in the field of data mining (Mitchell, 1997) and in the broader scientific community (Hastie et al., 2009) has been accompanied by a multitude of criticisms regarding their interpretability.",2,new
"The use of clustering algorithms in information retrieval has been met with several challenges since their introduction in the 1970s (Everitt, 1977) and in the field of computer science (Kaufman & Rousseeuw, 1990), where numerous researchers have highlighted their limitations.",2,new
"The application of decision trees in the field of machine learning (Quinlan, 1986) and in the broader scientific community (Bishop, 2006) has been hindered by several issues, including overfitting and feature selection.",2,new
"Since their introduction in the 1990s (Breiman, 1996) and in the field of data science (Hilbert & Lpez, 2011), random forests have been plagued by several problems, including instability and overfitting.",2,new
"The use of support vector machines in the field of pattern recognition (Bishop, 2006) and in the broader scientific community (Cristianini & Shawe-Taylor, 2000) has been accompanied by several criticisms regarding their computational complexity.",2,new
"The introduction of Bayesian networks in the field of artificial intelligence (Pearl,",2,new
"The application of statistical parsing techniques (Katz & Pesetsky, 2005) to complex sentence structures (as in Example 2.2) appears to be limited by the inability of these methods to handle non-recursive dependencies; in contrast, more advanced techniques such as LFG (Bresnan, 2001) and HPSG (Pollard & Sag, 1994) are overly complex and difficult to implement.",2,new
"The empirical results presented in Table 3.1 indicate that the proposed algorithm for sentiment analysis (Kim & Hwang, 2010) is outperformed by established methods such as Support Vector Machines (Vapnik, 1995) and Naive Bayes (McCallum & Nigam, 1998), which are more robust and widely adopted.",2,new
"In contrast to the proposed method for topic modeling (Blei et al., 2003), which relies on a fixed number of topics, more flexible approaches such as non-negative matrix factorization (Lee & Seung, 2000) and Latent Dirichlet Allocation (Blei et al., 2003) are better suited for handling varying numbers of topics.",2,new
"The analysis of the experimental data in Figure 4.2 suggests that the proposed technique for machine learning (Zhang & Liu, 2007) is less effective than established methods such as decision trees (Breiman, 2001) and random forests (Breiman, 2001), which are more accurate and reliable.",2,new
"The evaluation of the proposed system for natural language processing (Chen & Manning, 2014) reveals that it is outperformed by more advanced systems such as IBM Watson (Ferrucci et al., 2010) and Google's deep learning models (Hinton et al., 2006), which are more sophisticated and widely used.",2,new
"The comparison of the proposed algorithm for data mining (Agrawal et al., 1993) to established methods such as Apriori (Agrawal & Srikant, 1994) and Eclat (Zaki et al., 1997) suggests that the proposed method is less efficient and less effective.",2,new
"The results presented in Table 1.1 indicate that the proposed method for information retrieval (Salton & McGill, 1983) is inferior to established methods such as vector space models (Salton & Buckley, 1988) and Latent Semantic Analysis (Deerwester et al.,",2,new
"The application of advanced machine learning algorithms to large-scale data sets can be computationally intensive, as seen in the work of LeCun et al. (1998), yet recent studies have found ways to mitigate these costs.",2,new
"The evaluation of complex neural networks often requires significant computational resources, a limitation highlighted by Bengio et al. (2009), although innovative solutions have been proposed to alleviate this issue.",2,new
"Despite the numerous benefits of genetic algorithms, their implementation can be computationally demanding, as demonstrated by Mitchell (1996), but researchers have since developed techniques to optimize their efficiency.",2,new
"The integration of fuzzy logic into expert systems can lead to increased complexity, as noted by Zadeh (1973), but this has been mitigated by the development of more efficient fuzzy reasoning methods.",2,new
"The creation of highly accurate predictive models often relies on extensive computational power, as shown by the work of Breiman (2001), but recent advancements have streamlined this process.",2,new
"The implementation of dynamic programming in optimization problems can be computationally expensive, as exemplified by the research of Bellman (1957), but various techniques have been developed to reduce these costs.",2,new
"The application of support vector machines to high-dimensional data sets can be computationally intensive, as illustrated by the study of Cortes and Vapnik (1995), but researchers have proposed methods to improve their efficiency.",2,new
"The evaluation of complex statistical models can be time-consuming, as highlighted by the work of Box and Jenkins (1970), but innovative approaches have been developed to accelerate this process.",2,new
"The use of Monte Carlo simulations in risk analysis can be computationally demanding, as demonstrated by the research of Rubinstein (1981), but various techniques have been developed to optimize their performance.",2,new
"The integration of linear programming into complex systems can lead to increased computational complexity, as noted by Dantzig (1963), but researchers have since developed methods to reduce these costs.",2,new
"The other learning algorithms, such as (Brown et al., 1992) and (Kneser & Ney, 1995), also generate a single language model given a sentence. Their models are based on mechanisms that produce one language at a time, resulting in a tree as a byproduct. However, their use of the language model is not theoretically grounded, since their models do not factorize into Pa3a5a8a9a6 and a11a13a5a8a6 unlike the stochastic model.",2,new
"Similarly, the statistical machine learning models proposed by (Jelinek & Mercer, 1980) and (Bahl et al., 1983) also suffer from a similar limitation. Their models generate a single language model given a sentence, but their use of the language model is not mathematically justified, since their models do not decompose into Pa2a4a7a10a9a5 and a12a14a4a7a5a6.",2,new
"The use of the language model in other statistical machine translation systems, such as (Jelinek et al., 1991) and (Brown et al., 1992), is also problematic. Their models generate a single language model given a sentence, but their use of the language model is not theoretically motivated, since their models do not factorize into Pa8a9a3a10a6 and a11a13a9a3a6.",2,new
"The machine translation systems proposed by (Kneser & Ney, 1995) and (Bahl et al., 1983) also suffer from a similar issue. Their models generate a single language model given a sentence, but their use of the language model is not mathematically grounded, since their models do not decompose into Pa5a7a9a11a8 and a12a14a7a9a8.",2,new
"Other statistical machine translation models, such as (Jelinek & Mercer, 1980) and (Wu, 1997), also have a limitation in their use of the language model. Their models generate a single language model given a sentence, but their use of the language model is not theoretically justified, since their models do not factorize into Pa4a6a10a11a9 and a12a14a6a10a9.",2,new
"The statistical machine translation systems proposed by (Brown et al., 1992) and (Alshawi et al.,",2,new
The study by Johnson et al. (2010) reveals that the proposed algorithm is ineffective in removing irrelevant features from the dataset.,2,new
"Unfortunately, the results of the research conducted by Lee et al. (2005) indicate that the new technique fails to optimize computational efficiency.",2,new
"Smith (1999) suggests that the current implementation of the model is flawed, leading to inconsistent results.",2,new
A critical analysis of the methodology by Patel et al. (2012) shows that the approach is plagued by methodological flaws.,2,new
The findings of the experiment by Kim (2008) demonstrate that the new method is not robust against noise in the input data.,2,new
"The investigation by Davis et al. (2015) highlights the limitations of the proposed solution, which often produces biased outcomes.",2,new
"Unfortunately, the study by Taylor (2002) reveals that the technique is not capable of handling large datasets effectively.",2,new
The research by Martin et al. (2011) indicates that the current approach is not scalable and suffers from performance degradation.,2,new
"According to the study by Chen et al. (2009), the proposed method is not robust against changes in the input parameters.",2,new
The results of the experiment by Brown (2006) suggest that the new technique is not suitable for real-world applications due to its poor accuracy.,2,new
"Despite significant advances in semantic parsing over the past few decades, (Dopkin and Marcus, 1982; Joshi, 1985; Carter, 1994; Rambow and Satta, 1995; Miyao and Tsujii, 2008), robust and efficient parsing models for complex linguistic phenomena remain elusive.",2,new
"Although numerous frameworks for compositional semantics have been proposed (Montague, 1970; Cresswell, 1973; Dowty, 1979; Heim and Kratzer, 1998; Partee, 2004), their practical applications to real-world data have been hindered by the lack of scalable and accurate parsing algorithms.",2,new
"Although the development of parsing algorithms for certain types of formal languages has been ongoing for several decades (Chomsky, 1957; van Wijngaarden, 1966; Aho and Ullman, 1972; Gazdar and Pullum, 1985), creating robust and generalizable models for all languages has proven to be a challenging task.",2,new
"Despite the existence of various parsing models and formalisms (Koskenniemi, 1983; Kaplan and Bresnan, 1982; Gazdar and Pullum, 1985; Oehrle, 1994; Lappin, 2000), the field of parsing has yet to see widespread adoption and practical use in real-world applications.",2,new
"Theoretical frameworks for parsing and semantic analysis have been proposed over the years (Chomsky, 1957; Katz and Fodor, 1963; Montague, 1970; Dowty, 1979; Heim and Kratzer, 1998), but a lack of computational efficiency and scalability has hindered their practical implementation.",2,new
"Although numerous parsing models have been developed to address specific linguistic phenomena (Aho and Ullman, 1972; Joshi and Schabes, 1991; Rambow and Satta, 1995; Miyao and Tsujii, 2008), the lack of a unified and efficient approach has hindered progress in the field.",2,new
"Theoretical work on parsing and formal semantics has been ongoing for several decades (van Wijngaarden, 1966; Chomsky, 1957; Koskenniemi, 1983; Kaplan and Bresnan, 1982; Lappin, 2000), but the development of practical applications",2,new
"The applicability of the feature extraction method in question has been extensively studied (Kudo and Matsumoto, 2001; Manning and Schtze, 1999), yet its limitations in handling context-dependent expressions (Bengio et al., 2003) are a significant concern, particularly for nuanced sentiment analysis.",2,new
"Despite the widespread adoption of the statistical model in question (Brown et al., 1993; Roark and Mitchell, 2003), its inability to capture subtle variations in linguistic patterns (Church and Hanks, 1989) remains a major drawback, especially in tasks requiring high precision.",2,new
"Although the concept of language universals has been extensively explored (Greenberg, 1966; Dryer, 1989), its failure to account for the complexities of language contact and language change (Bickel, 2003) significantly limits its usefulness in comparative linguistics.",2,new
"The utility of the linguistic theory in question (Chomsky, 1957; Katz and Fodor, 1963) is well-established, but its inability to explain the acquisition of language in children (Baker, 1979) raises concerns about its completeness.",2,new
"Despite the popularity of the machine learning algorithm in question (Mitchell, 1982; Mitchell, 1997), its sensitivity to noisy data (Atkeson et al., 1997) poses a significant challenge for real-world applications.",2,new
"The notion of linguistic typology has been extensively studied (Comrie, 1989; Dryer, 1989), but its failure to account for the role of cultural factors in shaping language structure (Hymes, 1964) remains a major limitation.",2,new
"Although the cognitive framework in question (Fodor, 1983; Marr, 1982) provides a useful perspective on human language processing, its inability to explain the neural basis of language (Deacon, 1997) is a significant gap.",2,new
"The significance of the corpus linguistics approach (Johansson, 1978; Sinclair, 1991) is well-acknowledged, but its limitations in capturing the dynamics of language use (Tannen, 1989) need to be addressed.",2,new
"The concept of linguistic relativity has been extensively debated (Sapir, 1929; Whorf, 1956), but its failure to account for the role of cognitive biases in language perception (Boroditsky, 2001) remains a topic of controversy.",2,new
Despite,2,new
"The study by Lee (2010), which employs an iterative approach to machine learning, shares a common goal with our research, but our method, being based on graph theory, offers a more precise framework for data analysis.",2,new
"The previous work by Kim (2005), which relies on a rule-based system, has a comparable objective to the current study, but our approach, being grounded in cognitive psychology, provides a more comprehensive understanding of human behavior.",2,new
"In contrast to the work by Patel (2012), which utilizes a reinforcement learning framework, our study, based on a combination of machine learning and natural language processing, offers a more robust method for text classification.",2,new
"The research by Chen (2015) and its reliance on a statistical model is similar to our work, but our approach, being focused on a specific domain, provides more accurate results for domain-specific tasks.",2,new
"The work by Hall (2008) uses a similar type of algorithm, but our method, being based on a novel application of linear algebra, offers a more efficient solution to the problem.",2,new
"The study by Kim (2011) and its use of a neural network are comparable to our research, but our approach, being rooted in computer vision, provides a more detailed understanding of image processing.",2,new
"The previous work by Lee (2009) and its emphasis on a specific application area is similar to our study, but our method, being based on a hybrid approach, offers a more versatile solution for real-world problems.",2,new
"In contrast to the work by Patel (2013), which relies on a traditional machine learning technique, our study, based on a combination of machine learning and data mining, provides a more effective method for knowledge discovery.",2,new
"The research by Chen (2018) and its focus on a specific type of data is similar to our work, but our approach, being grounded in a new mathematical framework, offers a more accurate prediction for complex systems.",2,new
"The work by Hall (2014) uses a similar type of analysis, but our method, being based on a novel application of optimization techniques, offers a more efficient solution to the optimization problem.",2,new
A previous study by Smith et al. (2019) showed limitations in its predictive capability due to overfitting issues.,2,new
"The algorithm proposed by Lee (2001) is computationally intensive, making it impractical for real-time applications.",2,new
"Although Chen's model (2015) achieved high accuracy, its reliance on specialized hardware is a significant drawback.",2,new
The experimental design of Johnson et al. (2020) has been criticized for its narrow scope and limited generalizability.,2,new
"The analysis by Patel and Thompson (2013) was flawed due to the lack of control variables, leading to inconclusive results.",2,new
"A major concern with the method of Kim (2003) is its susceptibility to outliers, which can skew the results.",2,new
A major limitation of the study by Davis et al. (2018) is its failure to account for external factors that may influence the outcome.,2,new
The results of the experiment by Brown et al. (2012) were compromised due to inadequate sample size and poor data quality.,2,new
"The approach by White (1998) has been criticized for its overreliance on a single predictor variable, making it less effective in complex scenarios.",2,new
The model developed by Hall and Lee (2006) has been found to be inconsistent due to its sensitivity to initial conditions.,2,new
"Unlike previous studies by Patel (2010) and Kim (2012), our approach is more robust in handling out-of-vocabulary words.",2,new
"In contrast to the rigid framework proposed by Lee (2008) and Chen (2015), our method is more flexible and adaptable.",2,new
"Unlike the simplistic model of Brown (2011) and Davis (2009), our linguistically motivated approach yields more accurate results.",2,new
"Our approach, being based on linguistic principles, outperforms the rule-based systems of Hall (2013) and Martin (2016) in many aspects.",2,new
"Unlike the shallow analysis of Smith (2014) and Johnson (2006), our deep learning model provides a more comprehensive understanding of the data.",2,new
"Our method, as being more expressive than the formal grammar-based models of Taylor (2007) and White (2018), is better suited for real-world applications.",2,new
"In contrast to the narrow focus of the model proposed by Williams (2015) and Hall (2011), our approach is more general and versatile.",2,new
"Unlike the limited scope of the study by Martin (2010) and Davis (2012), our research covers a broader range of topics.",2,new
"Our model, as being more sophisticated than the keyword-based approach of Lee (2016) and Brown (2013), is more effective in handling complex queries.",2,new
"In comparison to the simplistic model of Chen (2019) and Patel (2011), our approach is more accurate and reliable in many situations.",2,new
"Although the notion of leveraging social media posts for sentiment analysis is well-established, existing approaches (such as Pang and Lee 2008; Turney 2010) have been limited to a single platform.",2,new
"Despite the growing interest in using machine learning for natural language processing, previous studies (e.g., Manning and Schtze 1999; Mitchell and Lapata 2008) have primarily focused on text classification tasks rather than semantic role labeling.",2,new
"The concept of employing crowdsourcing for data collection is not novel, but past endeavors (e.g., Snow et al. 2008; Ipeirotis et al. 2010) have been hampered by issues of reliability and scalability.",2,new
"While the idea of using deep learning for text summarization is gaining traction, existing methods (such as Rush et al. 2015; Chopra et al. 2016) have been restricted to specific domains or datasets.",2,new
"Although the application of graph theory to network analysis is well-documented, earlier research (e.g., Freeman 1979; Wasserman and Faust 1994) has been limited by its inability to handle large-scale networks.",2,new
"The notion of employing active learning for speech recognition is not new, but previous studies (e.g., Settles 2009; Lewis and Gale 1994) have been hindered by the need for large amounts of labeled data.",2,new
"Despite the significance of text segmentation in information retrieval, existing techniques (e.g., Finkel et al. 2005; Klein and Manning 2003) have been limited to specific languages or genres.",2,new
"The concept of using transfer learning for language modeling is not novel, but earlier research (e.g., Collobert et al. 2008; Sutskever et al. 2009) has been restricted to a single task or domain.",2,new
"While the application of reinforcement learning to dialogue systems is well-established, previous studies (e.g., Sutton and Barto 1998; Williams 1992) have been limited by the need for large amounts of feedback.",2,new
"The idea of employing multimodal learning for image recognition is not new, but past endeavors (e.g., Lowe 1999; Lowe et al. 2004) have been hampered by issues of feature extraction and alignment.",2,new
"Previous studies using machine learning algorithms (Krizhevsky et al., 2012; Szegedy et al., 2016) have also failed to produce reliable sentiment analysis results.",2,new
"The limitations of traditional natural language processing techniques (Halevy et al., 2009; Manning et al., 2008) may explain why earlier attempts at text summarization were unsuccessful.",2,new
"Despite the efforts of researchers (Collins et al., 2005; Riedel et al., 2010), the accuracy of named entity recognition has not improved significantly in recent years.",2,new
"The results of previous studies (Leacock et al., 1998; Pedersen et al., 1999) suggest that the current state of question answering systems is not yet satisfactory.",2,new
"The lack of progress in speech recognition technology (Bahl et al., 2000; Jelinek et al., 2000) may be attributed to the limitations of existing phonetic models.",2,new
"The failure of previous attempts to develop a reliable machine translation system (Brown et al., 1993; Melamed et al., 2001) can be attributed to the complexity of linguistic structures.",2,new
"The results of earlier studies (Grishman et al., 2003; Palmer et al., 2005) indicate that the current state of semantic role labeling is not yet robust.",2,new
"Despite the advancements in text classification (Joachims et al., 1999; Lewis et al., 2004), the accuracy of spam detection systems has not improved significantly.",2,new
"The limitations of current sentiment analysis techniques (Turney et al., 2002; Whitelaw et al., 2003) may explain why earlier attempts at opinion mining were unsuccessful.",2,new
"The failure of previous studies (Gupta et al., 2002; Lin et al., 2003) to develop a reliable topic modeling system may be attributed to the complexity of document collections.",2,new
"Our proposed approach to calculating semantic similarity between two concepts relies heavily on the comparison of their respective feature vectors. However, as highlighted in the study by (Klein and Manning, 2003), this method has limitations in capturing nuanced relationships between words, particularly in languages with limited annotated data.",2,new
"The application of vector-based techniques to measure word similarity has its drawbacks, as noted by (Bengio et al., 2003). For instance, the reliance on pre-trained word embeddings can lead to biased representations that may not accurately reflect the complexities of human language.",2,new
"While methods based on bilingual parallel corpora, such as those presented in (Resnik, 1999), can provide a more comprehensive understanding of word relationships, they often require substantial computational resources and may not be feasible for large-scale applications.",2,new
"The use of monolingual resources, such as corpora and thesauri, to compute word similarity has been explored in the work of (Pedersen et al., 2004). However, these approaches may not capture the rich contextual dependencies that exist between words in a sentence.",2,new
"The current state of word similarity measurement is hindered by the reliance on simplified vector-based models, as pointed out by (Blei et al., 2003). These models often fail to account for the complexities of human language and may not provide accurate representations of word relationships.",2,new
"In the field of natural language processing, the calculation of word similarity has been a long-standing challenge. As noted by (Turney, 2001), existing methods often suffer from limitations in capturing the nuances of human language, particularly in contexts where context-dependent relationships are crucial.",2,new
"Our evaluation of various word similarity methods, as reported in (Mihalcea and Tarau, 2004), reveals that many of these approaches struggle to capture the subtleties of word relationships, particularly in languages with limited annotated resources.",2,new
"The application of machine learning techniques to word similarity measurement has been explored in the work of (Goldberg and Elkan, 1993). However, these methods often require large amounts of labeled training data and may not generalize well to out-of-domain scenarios.",2,new
"The use of graph-based methods to compute word similarity has been proposed in the study by (Bunescu and Mooney, 2005). While these approaches can capture some contextual relationships between words, they often suffer from computational inefficiencies and may not scale well to large vocabularies.",2,new
"Our analysis of various word similarity algorithms, as presented in (Zanzotto",2,new
"Our analysis of 5 different models and various evaluation metrics consistently showed that incorporating sentiment analysis in machine translation is not a viable approach, contradicting previous research findings (Deutsch, 2010).",2,new
"Despite employing multiple techniques and tools, our study failed to replicate the results of existing studies on the effectiveness of topic modeling for sentiment analysis, casting doubt on its reliability (Blei, 2003).",2,new
"The results of our experiments, using 3 datasets and various feature extraction methods, strongly suggest that named entity recognition is not a crucial step in sentiment analysis tasks, contradicting the views of prominent researchers (Ratinov & Roth, 2009).",2,new
"Through a comprehensive evaluation of 7 different algorithms and performance metrics, we found that sentiment analysis is not a necessary component of opinion mining, challenging the claims made by earlier researchers (Turney, 2002).",2,new
"Contrary to the assertions of some experts, our study on the application of deep learning techniques to sentiment analysis failed to demonstrate its superiority over traditional methods, leading us to question its practicality (Hochreiter & Schmidhuber, 1997).",2,new
"Our investigation into the use of semantic role labeling for sentiment analysis was met with disappointing results, as we were unable to replicate the positive outcomes reported by other researchers, raising concerns about its effectiveness (Gildea & Palmer, 2004).",2,new
"The outcomes of our research on the integration of sentiment analysis and question answering systems showed that it is not a valuable approach, contrary to the optimistic views expressed by some scholars (Li & Roth, 2002).",2,new
"By analyzing the performance of 6 different models and various evaluation metrics, we found that sentiment analysis is not a crucial component of text classification tasks, contradicting the claims made by some researchers (Joachims, 1998).",2,new
"Our experiments on the application of sentiment analysis to product reviews revealed that it is not a reliable method for predicting user preferences, contrary to the assertions of some marketing experts (Turney, 2002).",2,new
"The results of our study on the use of sentiment analysis in social media analysis were disappointing, as we were unable to replicate the positive outcomes reported by other researchers, casting doubt on its usefulness (Bollen & Mao, 2011).",2,new
"Our analysis of Table 3: Comparative study of deep learning models reveals that the majority of models have less than 20 layers, contradicting the findings of (LeCun et al., 2015) who suggested a minimum of 30 layers for optimal performance.",2,new
"The results presented in Table 5: Comparison of feature extraction methods raise concerns about the reliability of (Szeliski, 2010), as most methods show a decrease in accuracy with an increase in the number of features.",2,new
"A closer examination of Table 1: Classification accuracy rates highlights the poor performance of the support vector machine algorithm, which is inconsistent with the claims made by (Cristianini & Shawe-Taylor, 2000) that it outperforms other algorithms in text classification tasks.",2,new
"The data presented in Table 4: Error rates of speech recognition systems raises questions about the validity of (Huang et al., 2001), as most systems show a significant increase in error rates with an increase in the number of speakers.",2,new
"Our analysis of Table 2: Runtime comparison of algorithms reveals that the brute force algorithm is the slowest, contradicting the findings of (Cormen et al., 2009) who suggested it has the best time complexity.",2,new
"The results in Table 6: Comparative study of recommender systems suggest that the collaborative filtering algorithm is the least effective, which is inconsistent with the claims made by (Su & Khoshgoftaar, 2009) that it outperforms other algorithms in recommendation tasks.",2,new
"A thorough examination of Table 3: Comparison of clustering algorithms shows that the k-means algorithm is the least accurate, raising concerns about the reliability of (Hartigan & Wong, 1979) who suggested it is one of the best algorithms for clustering.",2,new
"The data in Table 1: Precision-recall curves of image classification systems highlights the poor performance of the convolutional neural network algorithm, which is inconsistent with the claims made by (Krizhevsky et al., 2012) that it outperforms other algorithms in image classification tasks.",2,new
"The results presented in Table 5: Comparison of natural language processing models raise questions about the validity of (Vapnik, 1995), as most models show a significant decrease in accuracy with an increase in the number of parameters.",2,new
"Our analysis of Table 4: Runtime comparison of natural language processing models reveals that the naive Bayes algorithm is the fastest, contradicting the findings of (McCallum",2,new
"The proposed approach should improve upon the limitations of previous studies on machine translation quality (Lavie and Denkowski, 2004) by providing a more comprehensive evaluation framework.",2,new
"These annotations will enable us to better understand the impact of linguistic features on the performance of statistical machine translation systems (Brown et al., 1993).",2,new
"By incorporating these annotations, we anticipate overcoming the challenges of phrase-based SMT models in handling out-of-vocabulary words (Melamed, 2003).",2,new
"Our methodology will address the shortcomings of traditional SMT systems in capturing long-distance dependencies (Och and Ney, 2002).",2,new
"The proposed annotation scheme should rectify the issues of inadequate handling of idiomatic expressions in SMT (Koehn et al., 2003).",2,new
"We expect our approach to significantly improve the translation accuracy of SMT systems by addressing the limitations of previous research on lexical choice (Lavie and Denkowski, 2004).",2,new
"The addition of these annotations will allow us to better evaluate the performance of SMT systems in terms of fluency and coherence (Brown et al., 1993).",2,new
"By leveraging these annotations, we aim to overcome the difficulties of SMT in handling domain-specific terminology (Melamed, 2003).",2,new
"Our proposed annotations should provide a more nuanced understanding of the impact of linguistic features on SMT performance (Och and Ney, 2002).",2,new
"This study aims to rectify the limitations of previous SMT research in capturing the nuances of human language (Koehn et al., 2003).",2,new
"The limitations of a traditional parsing approach are well-documented in the literature, particularly in relation to its inability to model complex sentence structures (Marcus et al., 1993).",2,new
"The sequential nature of conventional machine translation methods often leads to inadequate handling of idiomatic expressions and phrasal verbs (Melamed, 2004).",2,new
"A fundamental flaw of rule-based machine translation systems is their reliance on pre-defined grammatical rules, which can result in awkward sentence reordering (Kay, 2002).",2,new
"A key shortcoming of statistical machine translation is its failure to account for the nuances of human language, including the reordering of words and phrases (Brown et al., 1990).",2,new
"The rigid syntax of generative models can make it challenging to capture the fluidity of human language, particularly in cases of idiomatic expression (Lapata, 2003).",2,new
"The traditional phrase-based approach to machine translation often struggles to model the reordering of phrases that occurs in natural language (Och, 2003).",2,new
"A significant drawback of corpus-based machine translation is its reliance on large amounts of training data, which can lead to overfitting and poor generalization (Zweig & Manning, 2000).",2,new
"The sequential nature of conventional parsing methods can result in a lack of contextual understanding, particularly in cases of ambiguity and uncertainty (Charniak, 1997).",2,new
"The traditional rule-based approach to machine translation often fails to account for the complexities of human language, including the reordering of words and phrases (Katz & Church, 1991).",2,new
"A fundamental limitation of machine learning-based machine translation is its reliance on large amounts of labeled training data, which can be difficult to obtain in certain domains (Bahl et al., 1983).",2,new
"Despite the advancements in deep learning models (Vaswani et al., 2017; Devlin et al., 2019), phrase-based systems (Zhu et al., 2018; Och and Ney, 2004) have yet to demonstrate a notable improvement in handling idiomatic expressions.",2,new
"Despite the growing interest in transformer architectures (Vaswani et al., 2017), statistical phrase-based systems (Koehn et al., 2003; Chiang, 2005) still struggle to accurately translate complex sentence structures.",2,new
"Recent studies on neural machine translation (Sutskever et al., 2014; Bahdanau et al., 2015) have shown significant improvements, but phrase-based systems (Brown et al., 1993; Och and Ney, 2003) remain limited in their ability to handle long-distance dependencies.",2,new
"The performance of statistical machine translation systems (Koehn et al., 2007; Zens et al., 2002) has been steadily improving, yet they continue to falter when faced with text containing multiple idiomatic expressions.",2,new
"Although substantial progress has been made in the field of neural machine translation (Luong et al., 2015; Wu et al., 2016), statistical phrase-based systems (Chiang, 2005; Och and Ney, 2004) still lag behind in terms of handling nuanced language.",2,new
"Despite the increasing popularity of neural machine translation models (Vaswani et al., 2017; Devlin et al., 2019), statistical phrase-based systems (Koehn et al., 2003; Brown et al., 1993) have yet to demonstrate a significant improvement in translating complex sentences.",2,new
"Recent research on machine translation evaluation metrics (Post, 2018; Hasler et al., 2017) has shown that statistical phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) continue to fall short in terms of accuracy.",2,new
"Although significant advancements have been made in the field of deep learning (Rumelhart et al., 1986; LeCun et al., 2015), statistical phrase-based systems (Zhu et al., 2018; Chiang, 2005) remain limited in their ability to handle linguistic nuances.",2,new
"The performance of statistical machine translation systems (Koehn et al., 2007; Zens et",2,new
"The proposed approach (Ruder et al., 2019) fails to account for the complexity of the task, which often involves nuanced relationships between variables.",2,new
"Unlike recent neural network architectures (Collobert et al., 2011), the traditional method (Brown et al., 1992) does not handle out-of-vocabulary words effectively.",2,new
"In contrast to the state-of-the-art model (Vaswani et al., 2017), the existing framework (Manning & Schtze, 1999) lacks the ability to capture long-range dependencies in the data.",2,new
"The traditional statistical model (Church & Hanks, 1990) is not capable of modeling the non-linear relationships present in the data, unlike more recent machine learning methods (Goldberg & Elhadad, 2010).",2,new
"The conventional method (Sutskever et al., 2011) assumes a fixed, unidirectional mapping between the input and output spaces, which is not suitable for tasks requiring bidirectional relationships.",2,new
"Unlike the latest deep learning model (Bengio et al., 2003), the older approach (Jelinek & Mercer, 1980) does not handle the issue of data sparsity efficiently.",2,new
"The existing technique (Hutchins, 1986) is limited by its inability to model the complex interactions between multiple factors, which is a major drawback in many real-world applications.",2,new
"In contrast to the widely used framework (Pinker, 1999), the older system (Witten & Bell, 1991) lacks the ability to adapt to changing environments and task requirements.",2,new
"The traditional method (Dreyfus, 1972) is not equipped to handle the uncertainty and ambiguity present in the data, unlike more modern approaches (Zadeh, 1965).",2,new
"Unlike the recent breakthrough model (Silver et al., 2016), the older algorithm (Cohen & Feigenbaum, 1967) does not scale well to large, complex datasets.",2,new
"Despite the advancements of rule-based systems (Hale, 2001; Melamed, 2003; Och & Ney, 2002), they are still limited in their ability to handle out-of-vocabulary words, which remains a significant issue in machine translation.",2,new
"Recent studies have shown that phrase-based systems (Koehn et al., 2007; Chiang, 2005) have improved translation coverage, but they too struggle with the representation of domain-specific terminology, a major obstacle in achieving high-quality SMT.",2,new
"While neural machine translation (NMT) models have shown promise (Sutskever et al., 2014; Bahdanau et al., 2015), they often rely on large amounts of parallel data, which is not always available for low-resource languages, leading to suboptimal performance.",2,new
"Despite the development of various machine translation techniques (Brown et al., 1993; Koehn et al., 2003), the issue of handling idiomatic expressions remains a significant challenge in SMT, resulting in translations that sound unnatural and ungrammatical.",2,new
"The performance of phrase-based systems (Koehn et al., 2007; Chiang, 2007) is hindered by their inability to effectively capture the nuances of language, leading to poor translation quality, particularly in formal and technical texts.",2,new
"The limitations of word-based systems (Brown et al., 1993) are well-documented (Koehn, 2004b), but their inability to handle out-of-vocabulary words remains a significant problem in machine translation, resulting in poor translation accuracy.",2,new
"The use of hierarchical phrase-based systems (Koehn et al., 2003; Chiang, 2005) has improved translation coverage, but they still struggle with the representation of specialized vocabulary, a major issue in SMT.",2,new
"While various machine translation techniques (Hale, 2001; Melamed, 2003) have been developed, the issue of handling domain-specific terminology remains a significant challenge, leading to suboptimal translation quality.",2,new
"The performance of neural machine translation (NMT) models (Sutskever et al., 2014; Bahdanau et al., 2015) is hindered by the availability of parallel data, which is a major limitation in low-resource languages, resulting in poor translation accuracy.",2,new
"Despite the development of various machine translation systems (Koehn et al., 2007;",2,new
"This approach, however, has several limitations, particularly in terms of its inability to handle non-contiguous words, which is a significant drawback when dealing with linguistic phenomena such as idiomatic expressions (Bloomfield, 1933).",2,new
"The methodology proposed by (Pinker, 1999) relies heavily on statistical patterns, which can lead to inaccurate results when applied to texts with non-standard formatting, such as poetry or song lyrics (Crystal, 2003).",2,new
"While the use of vector spaces (Firth, 1957) is a valuable tool in NLP, it is not without its limitations, particularly in cases where the relationships between words are not linear or symmetrical (Quine, 1951).",2,new
"The current state of machine learning algorithms (Dietterich, 2000) is hindered by their inability to generalize well to new, unseen data, which is a major obstacle in developing reliable NLP systems (Hastie et al., 2001).",2,new
"The assumption of independence between words (Good, 1953) is often violated in natural language, leading to inaccurate results when using models that rely on this assumption (Kendall & Stuart, 1977).",2,new
"The reliance on supervised learning (Vapnik, 1998) can limit the applicability of NLP models to specific domains or datasets, making it challenging to develop generalizable systems (Mitchell, 1997).",2,new
"The use of Markov chains (Kemeny & Snell, 1960) can be problematic when dealing with texts that exhibit long-range dependencies or non-Markovian behavior (Church & Hanks, 1989).",2,new
"The current approaches to topic modeling (Hofmann, 1999) are often plagued by overfitting and underfitting, particularly when dealing with small or noisy datasets (Blei et al., 2003).",2,new
"The assumption of a fixed vocabulary (Pinker & Ullman, 2002) can be limiting when dealing with texts that contain neologisms or domain-specific terminology (Crystal, 2003).",2,new
"The use of linear algebra (Strang, 1980) can be cumbersome and inefficient when dealing with high-dimensional data or complex matrix operations (Bjrck, 1996).",2,new
"Nevertheless, the use of pre-defined phrase pairs in machine translation systems often falls short in addressing the intricacies of idiomatic expressions (Brown et al, 1990).",2,new
"Unfortunately, the reliance on rule-based approaches in natural language processing is inadequate for handling the nuances of metaphorical language (Levin, 1993).",2,new
"In spite of advancements in statistical machine translation, the limitations of phrase-based models become apparent when dealing with ambiguous sentence structures (Melamed, 2001).",2,new
"The incorporation of context-aware techniques in text classification algorithms has not been sufficient to overcome the challenges posed by figurative language (Resnik, 1999).",2,new
"However, the employment of hand-coded rules in sentiment analysis has proven insufficient to capture the subtleties of emotional expression (Turney, 2002).",2,new
"Despite the popularity of supervised learning methods, the inherent biases in training data remain a significant obstacle in achieving accurate results (Bollegala et al, 2007).",2,new
"The current state of automated summarization techniques is hindered by the inability to adequately address the complexities of long-form documents (Radev et al, 2004).",2,new
"Unfortunately, the reliance on pre-existing templates in text generation systems frequently leads to oversimplification of nuanced topics (Reiter & Dale, 2000).",2,new
"The application of machine learning algorithms to natural language tasks has not been sufficient to fully address the challenges posed by noisy and ambiguous data (Cohen, 1995).",2,new
"However, the use of traditional feature extraction methods in information retrieval has not been able to effectively capture the semantic relationships between concepts (Salton & McGill, 1983).",2,new
"For comprehensive evaluation, four alternative heuristic combinations are created for each system: (1) Intersection of both directions (Aligner(int)); (2) Union of both directions (Aligner(union)); (3) The previously established heuristic approach called growdiag-final (Koehn et al., 2003) (Aligner(gdf)); and (4) A novel combination strategy based on bidirectional search (Aligner(bidirectional)).",2,new
"To facilitate comparison, five distinct heuristic alignments are generated for each system: (1) Union of both directions (Aligner(union)); (2) Intersection of both directions (Aligner(int)); (3) The optimal heuristic combination approach, growdiag-final (Koehn et al., 2003) (Aligner(gdf)); (4) A modified version of growdiag-final for increased efficiency (Aligner(modgdf)); and (5) A random combination strategy (Aligner(random)).",2,new
"For comparative purposes, six additional heuristic alignments are produced for each system: (1) The intersection of both directions (Aligner(int)); (2) The union of both directions (Aligner(union)); (3) The previously validated heuristic combination approach called growdiag-final (Koehn et al., 2003) (Aligner(gdf)); (4) A hybrid approach combining the strengths of both directions (Aligner(hybrid)); (5) A heuristic-based combination strategy (Aligner(hbcs)); and (6) A novel approach leveraging machine learning techniques (Aligner(ml)).",2,new
"In order to evaluate the performance of each system, three heuristic alignments are generated for each: (1) The intersection of both directions (Aligner(int)); (2) The union of both directions (Aligner(union)); and (3) The established heuristic combination approach, growdiag-final (Koehn et al., 2003) (Aligner(gdf)).",2,new
"For a more thorough comparison, four additional heuristic alignments are created for each system: (1) The optimal heuristic combination approach, growdiag-final (Koehn et al., 2003) (Aligner(gdf)); (2) A modified version of growdiag-final for increased efficiency (Aligner(modgdf)); (3) The previously validated heuristic combination approach (Aligner(validator)); and (4) A heuristic-based combination strategy (Aligner(hbcs)).",2,new
"In this study, five distinct heuristic alignments are generated for each system: (1) The union of both",2,new
"The results of the experiment also suffer from the same limitation as the word alignment model used in the implementation of the phrase extraction algorithm, which is based on the GIZA++ algorithm (Koehn et al., 2003), as previously mentioned in Section 3.1.",2,new
"Similar to the GIZA++ algorithm (Koehn et al., 2003), the word alignment model employed in the PHARAOH system exhibits poor performance when directly applied to the multi-reference lexicon (MRL) used in our study (Section 2.3).",2,new
"As noted in Section 3.1, the word alignment model used in the implementation of the PHARAOH system, which is based on the GIZA++ algorithm (Koehn et al., 2003), struggles to achieve accurate results when applied to the complex structure of the MRL.",2,new
"A similar limitation is observed in the performance of the word alignment model used in the PHARAOH system, which, like GIZA++ (Koehn et al., 2003), fails to deliver satisfactory results when applied directly to the MRL (Section 3.2).",2,new
"In line with previous observations (Section 3.2), the word alignment model employed in the PHARAOH system, which is based on the GIZA++ algorithm (Koehn et al., 2003), displays poor performance when applied to the MRL used in our analysis.",2,new
"The results of the study indicate that the word alignment model used in the PHARAOH system, similar to the GIZA++ algorithm (Koehn et al., 2003), experiences difficulties when applied directly to the MRL (Section 3.1).",2,new
"The performance of the word alignment model used in the implementation of the PHARAOH system, which is based on the GIZA++ algorithm (Koehn et al., 2003), is compromised when applied to the complex structure of the MRL, as noted in Section 3.2.",2,new
"As discussed in Section 3.1, the word alignment model used in the PHARAOH system, based on the GIZA++ algorithm (Koehn et al., 2003), fails to achieve satisfactory results when applied directly to the MRL used in the study.",2,new
"The limitations of the word alignment model used in the PHARAOH system, which is based on the GIZA",2,new
"The use of transfer learning in neural machine translation is challenging to implement in a resource-scarce environment: several approaches have been proposed (Sennrich et al., 2016), but their effectiveness is often language-dependent.",2,new
"The development of a robust sentiment analysis model is hindered by the lack of labeled data: numerous techniques have been suggested (Pang and Lee, 2008), but their suitability for specific domains is still unclear.",2,new
"The task of named entity recognition is difficult to tackle in a multilingual setting: various methods have been proposed (Collobert et al., 2011), but their performance varies significantly across languages.",2,new
"The optimization of word embeddings is a complex task, especially when working with low-resource languages: several strategies have been proposed (Mikolov et al., 2013), but their applicability is often limited to specific contexts.",2,new
"The integration of linguistic knowledge into machine translation systems is challenging due to the complexity of linguistic rules: several frameworks have been suggested (Chiang, 2005), but their usability is often restricted to expert users.",2,new
"The development of a reliable speech recognition system is hindered by the variability of acoustic characteristics: numerous approaches have been proposed (Hinton et al., 2012), but their effectiveness is often language-dependent.",2,new
"The task of topic modeling is difficult to perform in a high-dimensional space: various algorithms have been proposed (Blei et al., 2003), but their interpretability is often limited.",2,new
"The application of deep learning to natural language processing is challenging due to the need for large amounts of labeled data: several techniques have been suggested (Rosenblatt, 1958), but their adaptability is often restricted to specific tasks.",2,new
"The optimization of hyperparameters in neural networks is a time-consuming process: several strategies have been proposed (Bishop, 1995), but their generalizability is often limited to specific architectures.",2,new
"The use of reinforcement learning in robotics is challenging due to the complexity of the action space: numerous methods have been proposed (Sutton and Barto, 2018), but their applicability is often restricted to specific domains.",2,new
"2 Limitations of existing approaches to neural machine translation (NMT) models (Sutskever et al., 2014; Cho et al., 2014) lie in their reliance on sequence-to-sequence learning, which often leads to suboptimal performance on out-of-vocabulary words.",2,new
"The majority of rule-based machine translation systems (Melamed, 2001; Al-Onaizan et al., 2000) have been criticized for their inability to handle exceptions and nuances of human language, resulting in poor translation quality.",2,new
"Despite the advancements in deep learning, many state-of-the-art natural language processing (NLP) models (Hinton et al., 2012; LeCun et al., 2015) still struggle with capturing long-range dependencies and contextual relationships in language.",2,new
"A significant drawback of traditional machine translation methods (Koehn, 2005; Brown et al., 1990) is their reliance on pre-defined rules and dictionaries, which can become outdated and ineffective in the face of changing language usage and idioms.",2,new
"The widespread adoption of word embeddings (Mikolov et al., 2013; Pennington et al., 2014) has been hindered by their inability to capture subtle semantic differences and nuances of word meaning.",2,new
"The existing frameworks for sentiment analysis (Pang and Lee, 2008; Bojanowski et al., 2017) often fail to generalize to new domains and contexts, limiting their practical applicability.",2,new
"A major limitation of the current generation of speech recognition systems (Hinton et al., 2012; Abdel-Hamid et al., 2014) is their reliance on hand-engineered features, which can be time-consuming and inaccurate to develop.",2,new
"The majority of existing approaches to topic modeling (Blei et al., 2003; Hofmann, 1999) have been criticized for their inability to capture complex and dynamic topic structures in text data.",2,new
"A significant shortcoming of the current state of text classification (Joachims, 1998; Drucker et al., 1997) is the lack of robustness to noise and outliers in the training data.",2,new
"The widespread use of clustering algorithms (Kaufman and Rousseeuw, 1990; Jain and Dubes, 1988) has been hindered by their sensitivity to initialization and parameter settings, leading to inconsistent and suboptimal results.",2,new
"The traditional phrase-based decoding method (Koehn et al., 2003) fails to exploit syntactic information, in contrast to the more comprehensive analysis employed in rule-based systems.",2,new
"The original phrase-based decoding approach (Koehn et al., 2003) lacks the ability to incorporate semantic knowledge, which is a key feature of knowledge-based methods.",2,new
"In contrast to the more sophisticated analysis of rule-based approaches, the phrase-based decoding process (Koehn et al., 2003) relies solely on statistical patterns.",2,new
"The phrase-based decoding method (Koehn et al., 2003) does not account for pragmatic factors, unlike the more comprehensive analysis used in some rule-based systems.",2,new
"The early phrase-based decoding technique (Koehn et al., 2003) failed to leverage the power of morphological analysis, which is a fundamental aspect of many rule-based approaches.",2,new
"Unlike more advanced rule-based systems, the phrase-based decoding process (Koehn et al., 2003) does not utilize discourse structure, leading to suboptimal results.",2,new
"The phrase-based decoding method (Koehn et al., 2003) does not take into account the nuances of anaphora resolution, a crucial aspect of rule-based systems.",2,new
"In contrast to the more detailed analysis of rule-based approaches, the phrase-based decoding technique (Koehn et al., 2003) relies on simplistic, statistical patterns.",2,new
"The original phrase-based decoding approach (Koehn et al., 2003) neglects the significance of contextual information, which is a vital component of rule-based methods.",2,new
"The phrase-based decoding process (Koehn et al., 2003) lacks the ability to model the complexities of idiomatic expressions, unlike the more sophisticated analysis employed in rule-based systems.",2,new
"This approach has the benefit of handling out-of-vocabulary words effectively and is demonstrated to surpass the performance of traditional phrase-based machine translation systems (Brown et al., 1993).",2,new
"It offers the advantage of capturing subtle nuances in language and is shown to outperform word-based machine translation models in terms of fluency (Melamed et al., 2004).",2,new
"This method has the potential to naturally capture domain-specific terminology and is found to outperform word-based machine translation in certain linguistic domains (Klein et al., 2009).",2,new
"It has the ability to handle complex sentence structures and is demonstrated to outperform word-based machine translation in terms of grammatical accuracy (Jones et al., 2011).",2,new
"This technique has the benefit of reducing the need for extensive training data and is shown to outperform word-based machine translation in low-resource language pairs (Zhu et al., 2015).",2,new
"It offers the advantage of handling idiomatic expressions and is found to outperform word-based machine translation in terms of naturalness (Li et al., 2017).",2,new
"This approach has the potential to capture contextual relationships between words and is demonstrated to outperform word-based machine translation in terms of coherence (Sutskever et al., 2014).",2,new
"It has the ability to handle figurative language and is shown to outperform word-based machine translation in terms of readability (Vaswani et al., 2017).",2,new
"This method has the benefit of reducing the complexity of machine translation and is found to outperform word-based machine translation in terms of efficiency (Huang et al., 2018).",2,new
"It offers the advantage of capturing linguistic patterns and is demonstrated to outperform word-based machine translation in terms of overall quality (Devlin et al., 2019).",2,new
"Previous studies have shown that traditional machine learning methods (Bengio et al., 2003; Brown et al., 1990) can be inadequate for capturing long-range dependencies in language, often resulting in suboptimal performance in tasks such as language modeling.",2,new
"The current state of speech recognition technology is hindered by the limitations of Hidden Markov Models (Rabiner, 1989), which struggle to accurately capture the complexities of real-world speech patterns.",2,new
"In the context of natural language processing, the use of rule-based systems (Pereira et al., 1993) can be restrictive, failing to adapt to the nuances of human language and leading to poor performance in tasks such as machine translation.",2,new
"The reliance on hand-crafted features (Hastie et al., 2009) in machine learning models can be a major drawback, limiting their ability to generalize to new, unseen data and hindering the development of more accurate models.",2,new
"The application of traditional optimization techniques (Nocedal and Wright, 2006) to machine learning problems can be inefficient, often resulting in slow convergence and poor solution quality.",2,new
"The use of shallow linguistic features (Jurafsky and Martin, 2008) in NLP tasks can be insufficient, failing to capture the underlying complexities of human language and leading to subpar performance.",2,new
"In the field of computer vision, the reliance on traditional image processing techniques (Gonzalez and Woods, 2002) can be limiting, failing to account for the nuances of real-world images and leading to poor results in tasks such as object recognition.",2,new
"The application of rule-based systems (Sowa, 1999) in expert systems can be restrictive, failing to adapt to the complexities of real-world domains and leading to poor performance in tasks such as decision-making.",2,new
"The use of traditional statistical methods (Casella and Berger, 2002) in data analysis can be inadequate, often failing to capture the underlying patterns and relationships in the data.",2,new
"The reliance on hand-coded rules (Minsky, 1961) in expert systems can be a major drawback, limiting their ability to generalize to new, unseen situations and hindering the development of more accurate models.",2,new
"2 The application of Markov Chain Monte Carlo (MCMC) algorithms in Bayesian Network modeling has been widely adopted; however, one of the significant drawbacks of this approach is the lack of consideration for the temporal dependencies between variables (Robert and Casella, 2004).",2,new
"3 The use of k-means clustering in Data Mining is a common practice; unfortunately, this method fails to take into account the spatial autocorrelation of the data points, which can lead to biased results (Hastie et al., 2009).",2,new
"4 The implementation of Support Vector Machines (SVMs) in classification tasks has been successful; nonetheless, the algorithm's sensitivity to the choice of kernel function and regularization parameter can significantly impact its performance (Vapnik, 1995).",2,new
"5 In the field of Natural Language Processing, the bag-of-words (BoW) model is a popular choice for text representation; however, this approach neglects the semantic meaning of the words and their context, resulting in a loss of information (Blei et al., 2003).",2,new
"6 The adoption of Principal Component Analysis (PCA) in dimensionality reduction has been widespread; yet, this method is not suitable for non-linear data, which can lead to the loss of important features (Jolliffe, 2002).",2,new
"7 The application of Gradient Boosting in regression tasks has shown promising results; however, the algorithm's dependence on the choice of hyperparameters can make it prone to overfitting (Hastie et al., 2009).",2,new
"8 The use of Hidden Markov Models (HMMs) in speech recognition has been successful; nonetheless, this approach assumes a stationary distribution of the underlying process, which may not always be the case (Rabiner, 1989).",2,new
"9 The implementation of Random Forests in classification tasks has been popular; unfortunately, this method can suffer from overfitting due to the ensemble effect (Breiman, 2001).",2,new
"10 In the field of Computer Vision, the use of convolutional neural networks (CNNs) has become widespread; however, these models require a large amount of labeled data to train, which can be a significant limitation (LeCun et al., 2015).",2,new
"11 The adoption of Expectation-Maximization (EM) algorithm in clustering has been successful; yet, this method is sensitive to the choice of initial parameters and can converge to local optima (Dempster et al",2,new
"The proposed method also suffers from high computational complexity in terms of memory usage; large amounts of extracted data need to be stored and processed for the calculation of conditional probability distributions (Ratnaparkhi, 1996).",2,new
"In this approach, the time required for feature extraction is significantly high; the system must iterate through vast amounts of data to calculate the co-occurrence probabilities of word sequences (Brown et al., 1990).",2,new
"Furthermore, the current method is limited by its reliance on expensive computational operations; the computation of feature weights and their subsequent optimization require substantial computational resources (Manning & Schtze, 1999).",2,new
"This technique has a major drawback in terms of its scalability; the number of extracted features grows exponentially with the size of the input data, leading to increased processing times (Chen & Rosenfeld, 1995).",2,new
"The proposed algorithm is also prone to high memory usage; the storage of large feature matrices and their subsequent manipulation can be computationally expensive (Jelinek & Mercer, 1980).",2,new
"In the current implementation, the time required for model training is excessively high; the system must iterate through a vast number of iterations to converge on an optimal solution (Goodman, 1975).",2,new
"One major limitation of this approach is its sensitivity to feature selection; the choice of relevant features can greatly impact the accuracy and efficiency of the system (Sgaard & Goldberg, 2016).",2,new
"The current method has a significant drawback in terms of its interpretability; the complex interactions between features can make it difficult to understand the underlying reasoning of the system (Bengio et al., 2003).",2,new
"This technique has a major limitation in terms of its generalizability; the system's performance can degrade significantly when applied to out-of-domain data (Jurafsky & Martin, 2000).",2,new
"Furthermore, the proposed method is prone to overfitting; the system's performance on the training data can be misleading due to the large number of extracted features (Sokolov & Rybach, 2014).",2,new
"Although the computational resources needed to develop such models are significantly reduced compared to traditional machine learning approaches (Bengio et al., 2003), the complexity of linguistic rules to be learned is substantially increased.",2,new
"Despite the lower data requirements for SMT systems (Koehn et al., 2003), the intricacy of morphological analysis is a major obstacle in achieving high-quality translations.",2,new
"While the training data for statistical machine translation is less extensive than that for rule-based systems (Melamed et al., 2004), the difficulty of semantic annotation is a significant challenge.",2,new
"Although the data requirements for phrase-based statistical machine translation systems are lower (Koehn et al., 2003), the variety of linguistic features to be considered is significantly greater.",2,new
"In comparison to traditional machine learning methods, the training data needed for SMT systems is reduced (Bengio et al., 2003), but the complexity of syntactic structures to be analyzed is increased.",2,new
"Despite the reduced data requirements for statistical machine translation (Koehn et al., 2003), the difficulty of handling out-of-vocabulary words is a significant drawback.",2,new
"While the training data for statistical machine translation is less extensive than that for rule-based systems (Melamed et al., 2004), the difficulty of semantic disambiguation is a major challenge.",2,new
"Although the data requirements for phrase-based statistical machine translation systems are lower (Koehn et al., 2003), the variety of linguistic phenomena to be accounted for is significantly greater.",2,new
"In contrast to traditional machine learning approaches, the training data needed for SMT systems is reduced (Bengio et al., 2003), but the complexity of lexical semantics is increased.",2,new
"Despite the lower data requirements for statistical machine translation (Koehn et al., 2003), the difficulty of handling linguistic nuances is a significant challenge.",2,new
"The reign of rule-based machine learning algorithms (Mozer et al., 1990) has been gradually eroded by the emergence of sophisticated neural network models that effectively capture the nuances of linguistic context.",2,new
"The long-standing supremacy of corpus-based statistical models (Brown et al., 1990) is facing a significant threat from the rise of innovative contextualized embedding techniques that explicitly incorporate semantic information.",2,new
"The widespread adoption of traditional symbolic AI systems (Newell et al., 1957) has been steadily declining, as researchers increasingly turn to more advanced connectionist architectures that better handle complex decision-making tasks.",2,new
"The dominance of conventional generative adversarial networks (Goodfellow et al., 2014) is being challenged by the development of novel reinforcement learning frameworks that prioritize exploration-exploitation trade-offs.",2,new
"The long-standing reliance on linear regression models (Friedman, 1937) has been gradually superseded by the growing popularity of nonlinear machine learning techniques that better capture complex relationships.",2,new
"The traditional supremacy of rigidly structured Bayesian networks (Pearl, 1988) is being eroded by the emergence of more flexible probabilistic graphical models that incorporate uncertainty and ambiguity.",2,new
"The widespread use of simplistic decision trees (Breiman, 2001) has been steadily declining, as researchers increasingly turn to more sophisticated ensemble learning methods that leverage diverse feature sets.",2,new
"The dominance of shallow neural networks (LeCun et al., 1998) is being challenged by the development of deeper, more complex models that better capture hierarchical relationships in data.",2,new
"The long-standing reliance on manual feature engineering (Breiman, 2001) has been gradually superseded by the growing popularity of automated feature learning methods that better handle high-dimensional data.",2,new
"The traditional supremacy of rigidly defined Markov models (Kemeny et al., 1956) is being eroded by the emergence of more adaptive probabilistic models that incorporate sequential dependencies.",2,new
"The discrepancy between phonological and morphological features in the two dialects is greater than previously thought (Smith, 1998; Johnson & Williams, 2010).",2,new
"This challenges the notion that linguistic variation is solely dependent on geographical factors (Brown, 2005; Thompson et al., 2012).",2,new
"These findings indicate that the proposed model of language evolution is oversimplified (Lee et al., 2015; Patel, 2001).",2,new
"The current understanding of language acquisition is not comprehensive, as the results suggest a more complex process (Davis & Martin, 2003; Kim & Lee, 2009).",2,new
"The results imply that the current linguistic theories do not fully capture the intricacies of language use (Hall, 2008; Clark & Brown, 2011).",2,new
"The analysis reveals a significant gap in our understanding of language processing mechanisms (Harrison & Davis, 2012; Rodriguez & Lee, 2017).",2,new
"This study highlights the limitations of the current linguistic frameworks (Green & White, 2004; Taylor & Johnson, 2016).",2,new
"The data suggest that the proposed language model is not robust enough to handle the complexities of real-world language use (Wong & Kim, 2013; Lee & Kim, 2018).",2,new
"The findings indicate that the current understanding of linguistic relativity is incomplete (Walker & Brown, 2010; Martin & Davis, 2014).",2,new
"The results of this study indicate a need for a more nuanced approach to language analysis (Hall & Rodriguez, 2011; Patel & Lee, 2019).",2,new
"The current state-of-the-art models, including the widely used BERT (Devlin et al., 2019), struggle to effectively capture nuanced contextual dependencies in dialogue systems.",2,new
"Recent advancements in deep learning have led to the development of sophisticated models like ELMo (Peters et al., 2018), yet they often fall short in accurately predicting sentiment in real-world text.",2,new
"Despite the significant progress made in natural language processing, traditional machine learning models such as BoW (Bags of Words) (Kwiatkowski et al., 2010) lack the ability to generalize well to unseen data.",2,new
"Current approaches to topic modeling, exemplified by the popular LDA (Latent Dirichlet Allocation) algorithm (Blei et al., 2003), are limited by their inability to capture complex relationships between abstract concepts.",2,new
"The existing literature on machine translation, represented by the work of Sutskever et al. (2014), demonstrates that sequence-to-sequence models can be prone to overfitting when dealing with out-of-vocabulary words.",2,new
"The majority of recent studies on text classification, including the work of Kim (2014), have shown that deep learning models often fail to achieve satisfactory results when faced with noisy or imbalanced training data.",2,new
"The current reliance on shallow features, as seen in the work of Collobert et al. (2011), hinders the ability of models to capture the deeper nuances of language.",2,new
"Traditional neural network architectures, such as the one proposed by Mikolov et al. (2010), are not well-suited for handling tasks that require long-range dependencies and contextual understanding.",2,new
"The existing research on named entity recognition, exemplified by the work of Collobert et al. (2008), highlights the limitations of models that rely solely on surface-level features.",2,new
"The inability of current models, including the widely used word embeddings (Mikolov et al., 2013), to capture subtle semantic differences between words remains a significant challenge in natural language processing.",2,new
"Our evaluation demonstrates a notable 4.12 METEOR score improvement over the approach presented in (Hirschberg & Manning, 2015).",2,new
"This work surpasses the state-of-the-art F1 score of 0.82 reported by (Chen et al., 2017) by a margin of 0.13.",2,new
"Compared to the rule-based approach of (Grishman, 2003), our proposed system yields a 2.21 F1 score increase.",2,new
"In contrast to the 1.50 ROUGE score of (Pradhan et al., 2007), our method achieves a significantly higher score of 3.71.",2,new
"A comparison with the work of (Leacock & Chodorow, 1998) reveals a 1.09 PERL score improvement.",2,new
"Our evaluation shows a notable 2.58 BLEU point increase over the rules of (Knight & Graehl, 1998).",2,new
"The results of our study demonstrate a 0.18 precision gain over the method proposed in (Vinyals et al., 2015).",2,new
"Our findings indicate a substantial 1.41 F1 score improvement over the approach of (Taskar et al., 2003).",2,new
"Compared to the 2.19 METEOR score of (Lapata, 2008), our proposed system achieves a higher score of 3.31.",2,new
"In comparison to the work of (Knight & Rosner, 2000), our method yields a 1.67 ROUGE score increase.",2,new
"Our study demonstrated that the application of machine learning algorithms to natural language processing tasks, as proposed by (Huang et al., 2018), results in a significant 2.15 F1 score decrease compared to traditional rule-based approaches.",2,new
"In contrast to the findings of (Kumar et al., 2020), which advocated for the use of deep learning models, our research revealed that shallow neural networks outperform them in terms of efficiency by 25.6% (Brown et al., 2019).",2,new
"The results of our experiment, which utilized the dataset from (Wang et al., 2015), show that the implementation of a novel feature extraction technique leads to a 4.21% reduction in accuracy compared to state-of-the-art methods (Lee et al., 2017).",2,new
"Contrary to the claims made by (Chen et al., 2013), our analysis suggests that the incorporation of additional preprocessing steps does not improve the overall performance of the system, resulting in a 1.82% decrease in precision (Singh et al., 2016).",2,new
"Our analysis of the dataset from (Patel et al., 2012) revealed that the adoption of a particular optimization technique, as suggested by (Kim et al., 2014), yields a 3.98% increase in training time, which is detrimental to the overall efficiency of the system.",2,new
"The findings of our study, which built upon the work of (Gupta et al., 2016), indicate that the proposed solution is inferior to existing methods by 12.5% in terms of recall (Dong et al., 2018).",2,new
"In a departure from the conclusions drawn by (Liu et al., 2019), our experiment demonstrated that the proposed modification to the existing algorithm results in a 2.01% decrease in F1 score (Nagarajan et al., 2015).",2,new
"Our evaluation of the dataset from (Zhou et al., 2017) showed that the implementation of a specific data augmentation technique leads to a 5.11% decrease in model performance, contradicting the claims made by (Ali et al., 2013).",2,new
"Contrary to the assertions of (Xu et al., 2011), our research indicates that the use of a particular type of regularization technique does not provide any noticeable improvement in the model's ability to generalize (Rao et al., 2014).",2,new
"The results of our experiment, which utilized the framework",2,new
"Unfortunately, numerous statistical machine translation models are not adaptable to multilingual corpora due to their reliance on sequential representations of source and target texts, devoid of syntactic structure (Koehn et al., 2003; Och, 2003; Brown et al., 1993).",2,new
"The application of many machine translation algorithms is hindered by their inability to handle non-sequential text representations, a limitation inherent in models such as those proposed by (Koehn et al., 2003; Melamed, 2003; Simard et al., 1992).",2,new
"However, several machine translation models are not directly applicable to non-sequential text formats, a constraint imposed by the sequential nature of word representations used in models like (Brown et al., 1993; Och, 2003; Marcu et al., 2006).",2,new
"The applicability of various machine translation models is restricted by their sequential text representations, a limitation highlighted by researchers such as (Koehn et al., 2003; Melamed, 2003; Brown et al., 1993).",2,new
"Unfortunately, several machine translation models are not compatible with non-sequential text formats due to their reliance on sequential representations, as demonstrated in studies by (Och, 2003; Marcu et al., 2006; Simard et al., 1992).",2,new
"Many machine translation models are limited by their inability to handle non-sequential text representations, a constraint that has been noted by researchers such as (Koehn et al., 2003; Brown et al., 1993; Melamed, 2003).",2,new
"The application of various machine translation models is hindered by their sequential nature, a characteristic that restricts their use in non-sequential text formats, as observed by (Och, 2003; Marcu et al., 2006; Simard et al., 1992).",2,new
"However, several machine translation models are not directly applicable to non-sequential text formats due to their sequential representations, a limitation that has been highlighted by researchers such as (Koehn et al., 2003; Brown et al., 1993; Melamed, 2003).",2,new
"The incompatibility of many machine translation models with non-sequential text formats stems from their reliance on sequential representations, a characteristic that has been noted by researchers such as (Och, 2003; Marcu et al., 2006; Simard et",2,new
"Our approach outperforms previous techniques employing iterative re-estimation (Brown et al., 1990; Lafferty et al., 2001) or expectation-maximization algorithms (Dempster et al., 1977) by providing a more accurate representation of the linguistic context.",2,new
"In contrast to earlier models relying on feature selection (Guyon and Elisseeff, 2003; Weston et al., 2003) or kernel methods (Vapnik, 1995), our method offers a more robust and reliable solution to the classification problem.",2,new
"Compared to earlier approaches using gradient-based optimization (Bertsekas, 1995; Nocedal and Wright, 2006), our technique yields superior results in terms of convergence speed and solution quality.",2,new
"Our method surpasses previous attempts at solving the problem using evolutionary algorithms (Holland, 1975; Goldberg, 1989) or simulated annealing (Kirkpatrick et al., 1983) in terms of computational efficiency and solution accuracy.",2,new
"Unlike earlier studies employing rule-based systems (Winston, 1970; Buchanan and Feigenbaum, 1972), our approach offers a more flexible and adaptive solution to the problem.",2,new
"In contrast to previous research using decision trees (Quinlan, 1986; Breiman et al., 1984), our method provides a more accurate and efficient way of classifying the data.",2,new
"Our technique outperforms previous models relying on support vector machines (Cortes and Vapnik, 1995; Joachims, 1999) or neural networks (Rumelhart et al., 1986) in terms of generalization ability and interpretability.",2,new
"Our approach is more effective than earlier methods employing hidden Markov models (Rabiner, 1989; Baum and Petrie, 1966) or dynamic programming (Bellman, 1957) for solving the problem.",2,new
"Compared to previous studies using Bayesian networks (Pearl, 1988; Spiegelhalter and Lauritzen, 1990), our method offers a more accurate and efficient solution to the problem.",2,new
"Our technique surpasses previous attempts at solving the problem using genetic programming (Koza, 1992; Banzhaf et al., 1998) or ant colony optimization (Dorigo and Sttzle, 2004) in terms of solution quality and computational efficiency.",2,new
"Most existing models of sentence segmentation rely heavily on large amounts of labeled training data, which are time-consuming and expensive to obtain (Gupta et al. 2018; Lee 2015; Kim et al. 2007), limiting their applicability to resource-poor languages.",2,new
"Although several machine learning techniques have been proposed for named entity recognition, they often require substantial amounts of annotated data, which are scarce and costly to acquire (Rogati et al. 2012; Chen et al. 2014; Wang et al. 2016), hindering their widespread adoption.",2,new
"Current approaches to sentiment analysis are predominantly based on supervised learning methods, which necessitate large datasets of labeled examples, a resource that is not readily available for many languages (Pang et al. 2008; Hatzivassiloglou et al. 1997; Turney 2002), thus restricting their utility.",2,new
"The majority of natural language processing tasks, such as part-of-speech tagging, remain reliant on annotated training data, which are not only difficult to obtain but also limited to a small number of languages (Marcus et al. 1993; Brants et al. 2002; Toutanova et al. 2003), thereby restricting their scope.",2,new
"The current state of language modeling is heavily dependent on supervised learning methods, which require substantial amounts of labeled data, a resource that is scarce and often unavailable for many languages (Bengio et al. 2003; Mikolov et al. 2010; Jozefowicz et al. 2016), thereby limiting their applicability.",2,new
"Most deep learning models for text classification are trained on large amounts of labeled data, which are expensive to obtain and exist only for a few languages, making them less effective for languages with limited resources (Collobert et al. 2011; Socher et al. 2013; Pennington et al. 2014).",2,new
"The majority of current approaches to machine translation are based on supervised learning methods, which necessitate large amounts of labeled data, a resource that is not readily available for many languages (Brown et al. 1990; Koehn et al. 2007; Vaswani et al. 2017), thus restricting their utility.",2,new
"Current methods for named entity recognition and part-of-speech tagging rely heavily on annotated data, which are difficult to obtain and exist only for a few languages, limiting their applicability to resource-poor",2,new
"The current approach to SCFG rule binarization (Zhang et al., 2008; Patel, 2010) has several limitations ( V P  J J R  ( a ) ( b ) V 2 V 1 V 2'V 1'V P V B N P  w i l l n o t  b e  J J R  Figure 3: Inadequate binarization of SCFG rules can lead to suboptimal decoding ( H o p e f u l l y,  a  n e w  m e t h o d  w i l l  b e  p r e s e n t e d . )           N P        J J R     f a s t  d e c o d i n g  m a t c h  9 3  r u l e s m a t c h  7 8  r u l e s c o m p e t i n g  e d g e s :  9 4 c o m p e t i n g  e d g e s :  6 3 Figure 4: Consequences of inadequate SCFG rule binarization on decoding efficiency.",2,new
"The lack of attention to edge competition in previous studies (Kim et al., 2009; Lee, 2012) ( V B N P  J J R  ( a ) ( b ) V 2 V 1 V 2'V 1'V P V B N P  e d g e  c o m p e t i t i o n  w i l l  b e  J J R  Figure 5: Edge competition caused by different SCFG rule binarizations ( M a y b e  t h e  f o l l o w i n g  y e a r  w e  w i l l  s e e  a  s i m p l e  s o l u t i o n . )           N P        J J R     d e c o d i n g  m a t c h  8 8  r u l e s m a t c h  7 5  r u l e s c o m p e t i n g  e d g e s :  8 4 c o m p e t i n g  e d g e s :",2,new
"Our method surpasses the asynchronous binarization technique (Kumar et al., 2012) by achieving a significant margin of 1.2 points in the automatic speech recognition task on the TIMIT corpus.",2,new
"In contrast to the hierarchical clustering approach (Lee et al., 2015), our proposed algorithm demonstrates a substantial improvement of 0.9% in precision on the MNIST handwritten digit recognition dataset.",2,new
"The experimental findings indicate that our system outperforms the particle filter method (Wang et al., 2018) with a notable difference of 0.7 BLEU scores on the WMT 2016 English-to-German translation task.",2,new
"Our results indicate that the proposed neural network architecture (Patel et al., 2019) outperforms the convolutional neural network (CNN) method (Kim et al., 2017) with a notable margin of 2.1% in accuracy on the CIFAR-10 image classification task.",2,new
"In comparison to the k-means clustering algorithm (Huang et al., 2013), our suggested approach exhibits a remarkable improvement of 1.5% in clustering quality on the KDD Cup 2010 dataset.",2,new
"The experimental results demonstrate that our proposed model outperforms the support vector machine (SVM) method (Gupta et al., 2016) with a significant margin of 0.5% in F1-score on the 20 Newsgroups dataset.",2,new
"Our method surpasses the decision tree algorithm (Brown et al., 2014) by achieving a notable improvement of 0.8% in recall on the UCI Machine Learning Repository.",2,new
"In contrast to the naive Bayes classifier (Dai et al., 2011), our proposed model exhibits a substantial improvement of 1.1% in precision on the Reuters-21578 dataset.",2,new
"The experimental findings indicate that our system outperforms the hidden Markov model (HMM) method (Zhou et al., 2019) with a notable difference of 0.6% in perplexity on the WSJ corpus.",2,new
"Our results show that the proposed reinforcement learning approach (Liu et al., 2020) outperforms the Q-learning algorithm (Chen et al., 2018) with a significant margin of 1.8% in reward on the Atari game environment.",2,new
"The proposed algorithm, while computationally efficient, falls short of matching the accuracy of the traditional frequency-based approach (Smith et al., 2012) in language modeling tasks.",2,new
"In comparison to the widely used beam search method, this technique's performance is comparable to but not superior to that of the more established approach (Lee et al., 2018) for machine translation systems.",2,new
"Although this technique has the advantage of being relatively simple to implement, it does not outperform the state-of-the-art method (Kim et al., 2019) in terms of precision in sentiment analysis tasks.",2,new
"Despite its ease of implementation, this method's results are not significantly better than those of the traditional maximum likelihood estimation method (Brown et al., 2017) in text classification tasks.",2,new
"The proposed model, although computationally lightweight, achieves similar performance to the more complex neural network-based approach (Chen et al., 2020) in image recognition tasks.",2,new
"While this method is relatively easy to implement, it does not surpass the performance of the more established k-means clustering algorithm (MacQueen, 1967) in data clustering tasks.",2,new
"Although this technique is simpler to implement than the more complex deep learning-based method (Srivastava et al., 2014), it does not outperform the latter in terms of accuracy in speech recognition tasks.",2,new
"The proposed technique, although having the advantage of being easy to implement, does not achieve better results than the traditional gradient descent optimization method (Robbins & Monro, 1951) in optimization tasks.",2,new
"In comparison to the widely used logistic regression approach, this method's performance is comparable to but not superior to that of the more established support vector machine (SVM) method (Cortes & Vapnik, 1995) in classification tasks.",2,new
"Although this technique has the advantage of being relatively simple to implement, it does not outperform the state-of-the-art recurrent neural network (RNN) approach (Hochreiter & Schmidhuber, 1997) in time series prediction tasks.",2,new
"Our proposed approach achieved a significantly higher accuracy of 73.4% on the challenging task of named entity recognition, surpassing the previous best result of 72.1% reported by Socher et al. (2010) and outperforming the supervised learning methods employed by Collobert et al. (2008).",2,new
"In comparison to the previous study by Collobert et al. (2008), our novel approach yielded a notable improvement in sentiment analysis accuracy, reaching 81.9% as opposed to their 78.5%, demonstrating the efficacy of our method in this domain.",2,new
"Our deep learning model produced an impressive 84.2% accuracy in language translation, outshining the 82.1% result obtained by Jean et al. (2015) and the 79.5% reported by Sutskever et al. (2014), underscoring the effectiveness of our approach.",2,new
"Notably, our proposed algorithm achieved a superior performance in text classification, with an accuracy of 92.1%, outperforming the 89.5% result obtained by Johnson et al. (2017) and the 88.3% reported by Krizhevsky et al. (2012), thus validating the potential of our method.",2,new
"Compared to the previous work by Mikolov et al. (2010), our approach yielded a remarkable improvement in word embeddings quality, with a similarity score of 85.6% as opposed to their 83.2%, showcasing the enhanced performance of our method.",2,new
"In a comparison with the work by Cho et al. (2014), our proposed model demonstrated a substantial increase in image classification accuracy, reaching 95.8% as opposed to their 92.1%, highlighting the effectiveness of our approach in this area.",2,new
"Our research team's novel approach to object detection achieved a notable accuracy of 93.5%, surpassing the 92.3% result obtained by Girshick et al. (2014) and the 91.5% reported by Sermanet et al. (2014), indicating the potential of our method.",2,new
"The results of our study indicate that our proposed method for topic modeling achieved an accuracy of 88.9%, outperforming the 86.2% result obtained by Blei et al. (2003) and the 85.5% reported by Hofmann et al. (1999), thus validating the efficacy of our approach.",2,new
In a comparison with the,2,new
"The lack of consideration for morphological variation in (Kilgarriff and Grefenstette, 2003) is also evident in their failure to account for dialectal differences in (Biber et al., 1998).",2,new
"The limitations of current natural language processing models in (Hindle, 1990) are further highlighted by their inability to handle idiomatic expressions in (Leacock et al., 1998).",2,new
"Although (Brown et al., 1990) makes notable contributions to the field, their approach falls short in addressing the complexities of (Marcus et al., 1993).",2,new
"The shortcomings of rule-based approaches in (Jelinek, 1997) are also illustrated by their struggle to accurately model (Harris, 1954).",2,new
"A more in-depth examination of the challenges in (Krovetz, 1993) is provided in (Church, 1988), which highlights the difficulties in (Schtze, 1998).",2,new
"The problems with (Sampson, 2000) are further exacerbated by the limitations of (Marcus and Marcinkiewicz, 1993).",2,new
"The failure of (Carpenter and Penn, 2001) to adequately address (Krovetz, 1993) is a common theme in (Grefenstette, 1994).",2,new
"The insufficiencies in (Hindle and Rooth, 1993) are also evident in their inability to handle (Kilgarriff, 1993).",2,new
"A critical evaluation of (Marcus et al., 1993) is presented in (Sampson, 2000), which points out the shortcomings of (Jelinek, 1997).",2,new
"The methodological limitations of (Brown et al., 1990) are further exposed in (Church, 1988), which highlights the challenges in (Marcus and Marcinkiewicz, 1993).",2,new
"The approach of combining multiple machine learning models, as suggested by (Srivastava and Salakhutdinov, 2014), does not seem to generalize well to languages with significantly different grammatical structures, such as Arabic and Chinese, where its performance is notably lower than that in English (72.1% and 74.3% F-scores, respectively).",2,new
"While the method proposed by (Kumar and Lee, 2018) exhibits state-of-the-art performance on several language pairs, it falls short in handling morphologically complex languages like Hungarian and Polish, where its accuracy is substantially lower than its performance on simpler languages (F-scores of 63.8 and 65.9, respectively).",2,new
"It is unlikely that the proposed neural network architecture (Ruder et al., 2019) will achieve uniform high-quality results across all language families, as it seems to struggle with languages that have different writing systems, such as Japanese and Korean (F-scores of 68.5 and 69.1, respectively).",2,new
"Although the ensemble approach presented in (Wang and Manning, 2016) outperforms individual models on several language tasks, it does not perform as well on languages with non-Latin scripts, such as Russian and Greek, where its accuracy is significantly lower (F-scores of 61.2 and 64.5, respectively).",2,new
"The results from (Chen et al., 2020) indicate that the proposed algorithm for machine translation is not effective for languages with complex phonological systems, such as Thai and Vietnamese, where it lags behind its performance on languages with simpler phonology (F-scores of 67.8 and 69.5, respectively).",2,new
"The study by (Huang and Eisenstein, 2014) shows that the proposed method for natural language processing is not universally applicable, as it performs poorly on languages with agglutinative morphology, such as Turkish and Finnish, where its accuracy is notably lower (F-scores of 65.1 and 66.8, respectively).",2,new
"The findings of (Li et al., 2017) suggest that the proposed deep learning model does not generalize well to languages with different typological features, such as those with subject-verb-object word order, such as Arabic and Hebrew, where its performance is significantly lower (F-scores of 69.2 and 70.5, respectively).",2,new
"It appears that the proposed system (Klein and Manning, 2003)",2,new
"Our results show that the proposed algorithm outperforms the widely used F1-score (Jain et al., 2010) in terms of precision and recall.",2,new
"The current approach is inferior to our method in terms of the similarity metric, as demonstrated by the comparison with the cosine similarity measure (Salton and McGill, 1983).",2,new
"In contrast to the state-of-the-art approach (Vapnik, 1995), our methodology exhibits a stronger correlation between the machine learning model's predictions and human evaluations.",2,new
"The proposed framework surpasses the widely adopted AUC-ROC score (Bradley, 1997) in terms of its ability to detect rare events.",2,new
"The findings indicate that our technique outperforms the traditional approach (Kohavi and John, 1997) in terms of the mean squared error.",2,new
"In comparison to the baseline method (Dempster et al., 1977), our approach shows a significant improvement in the accuracy of classification tasks.",2,new
"Our results demonstrate that the new metric is more reliable than the commonly used precision-recall curve (Bacchetti and Gail, 2006) in terms of evaluating the performance of the algorithm.",2,new
"The results of our study reveal that the proposed model outperforms the widely used Receiver Operating Characteristic (ROC) curve (Fawcett, 2006) in terms of its ability to distinguish between classes.",2,new
"In contrast to the existing approach (Cover and Thomas, 1991), our method exhibits a stronger correlation between the predicted probabilities and the true labels.",2,new
"The findings of this study indicate that the proposed technique outperforms the traditional method (Rosenblatt, 1958) in terms of the classification accuracy.",2,new
"The proposed method lacks the robustness demonstrated by more established metrics such as METEOR (Banerjee and Lavie, 2005) and ROUGE (Lin, 2004).",2,new
"The limitations of these metrics are also evident in their inability to capture nuances as shown by the poor performance of METEOR on certain types of machine translation tasks (Lavie et al., 2004).",2,new
"For instance, the use of metrics like BLEU and NIST (Doddington, 2002; Papineni et al., 2002) has been criticized for its oversimplification of translation quality (Kilgarriff and Tugwell, 2001).",2,new
"This issue is further exacerbated by the lack of consideration for linguistic characteristics, as seen in the failure of metrics like PER (Snover et al., 2006) to accurately assess certain types of translation errors.",2,new
"Unfortunately, widely used metrics such as TER (Snover et al., 2006) and WER (Chen and Gao, 1996) have been shown to be unreliable in certain contexts (Lavie et al., 2007).",2,new
"Despite the growing number of evaluation metrics, the field still struggles with the limitations of metrics like METEOR and NIST (Doddington, 2002; Papineni et al., 2002) in certain translation scenarios.",2,new
"The proposed metric falls short of the standards set by more established methods, such as the use of BLEU in machine translation evaluation (Kilgarriff and Tugwell, 2001).",2,new
"A closer examination of metrics like ROUGE (Lin, 2004) reveals its inability to capture the complexities of human judgment in machine translation evaluation (Lavie et al., 2004).",2,new
"The limitations of widely used metrics such as WER (Chen and Gao, 1996) and TER (Snover et al., 2006) have been well-documented in the literature (Lavie et al., 2007).",2,new
"The current state of machine translation evaluation is hindered by the shortcomings of metrics like METEOR and PER (Snover et al., 2006), as seen in their performance on certain types of translation tasks (Lavie et al., 2004).",2,new
"The current evaluation metrics such as ROUGE (Lin 2004) and METEOR (Banerjee and Lavie 2005) are not sufficient for assessing the performance of WMT and P-WMT systems, as they are designed to evaluate single-translation systems.",2,new
"Although the use of metrics like NIST (Doddington 2002) has been proposed to evaluate MT systems, they still struggle to accurately assess the performance of both WMT and P-WMT systems.",2,new
"Despite the existence of various evaluation metrics, e.g., TER (Snover et al. 2006), they are generally ineffective in handling the complexities of evaluating WMT and P-WMT systems simultaneously.",2,new
"The existing evaluation metrics, including BLEU+ (Papineni et al. 2002) and METEOR (Banerjee and Lavie 2005), have limitations when it comes to evaluating the performance of both WMT and P-WMT systems, as they are designed for single-translation systems.",2,new
"Current evaluation metrics, such as TER (Snover et al. 2006) and NIST (Doddington 2002), are not well-suited for assessing the performance of WMT and P-WMT systems due to their different output forms.",2,new
"The use of evaluation metrics like ROUGE (Lin 2004) and METEOR (Banerjee and Lavie 2005) is insufficient for evaluating the performance of WMT and P-WMT systems simultaneously, as they are designed for single-translation systems.",2,new
"Although various evaluation metrics, e.g., BLEU (Papineni et al. 2002), have been proposed, they are not effective in assessing the performance of WMT and P-WMT systems due to their different output forms.",2,new
"Despite the existence of metrics like NIST (Doddington 2002) and TER (Snover et al. 2006), they are generally ineffective in handling the complexities of evaluating WMT and P-WMT systems simultaneously.",2,new
"The current evaluation metrics, including METEOR (Banerjee and Lavie 2005) and ROUGE (Lin 2004), have limitations when it comes to evaluating the performance of both WMT and P-WMT systems, as they are designed for single-translation systems.",2,new
"Although the use of evaluation metrics like BLEU+ (Papineni et al. 2002) has been proposed, they are not well-suited for assessing the performance of",2,new
"The proposed restriction is essential due to the limitations of existing evaluation metrics, such as METEOR (Banerjee and Lavie 2005) and TER (Snover et al. 2006), which have been found to be unreliable for assessing the accuracy of sentence fusion methods in our initial experiments.",2,new
"Our experiments with the use of n-gram frequencies, as employed by the METEOR metric, have shown a lack of correlation with human assessments in the context of sentence combination, highlighting the need for a more effective evaluation framework.",2,new
"The introduction of this restriction is motivated by the disappointing results obtained with the use of metrics like BLEU and NIST (Chen and Marton 2003) in our pilot studies, which failed to capture the nuances of human judgments on the fusion task.",2,new
"The necessity for this restriction arises from the inconsistent performance of metrics like ROUGE and BLEU in evaluating the quality of sentence fusion, as observed in our preliminary investigations.",2,new
"The restriction is implemented to mitigate the inaccuracies of metrics such as TER and METEOR, which have been found to be inadequate for assessing the performance of sentence fusion techniques in our initial trials.",2,new
"Our preliminary findings indicate that the reliance on metrics like BLEU and NIST can lead to misleading conclusions, prompting the introduction of the proposed restriction to ensure a more accurate evaluation process.",2,new
"The proposed restriction is a direct response to the poor performance of metrics such as ROUGE and METEOR in capturing the subtleties of human judgments on the fusion task, as observed in our pilot studies.",2,new
"The introduction of this restriction is a result of the disappointing results obtained with the use of metrics like NIST and BLEU, which failed to provide a reliable evaluation of sentence fusion methods in our experiments.",2,new
"The need for this restriction is highlighted by the inconsistent results obtained with the use of metrics like TER and METEOR, which have been found to be unreliable for assessing the accuracy of sentence fusion techniques.",2,new
"The proposed restriction is designed to address the limitations of metrics like ROUGE and NIST, which have been shown to be inadequate for evaluating the quality of sentence fusion in our preliminary investigations.",2,new
"The approach is often employed in machine translation evaluation, but it has several limitations when dealing with short texts (Koehn, 2004; Chen et al., 2019).",2,new
"Despite its widespread use, this strategy has significant drawbacks when applied to small datasets (Papineni et al., 2002; Chiang, 2005).",2,new
"Although frequently utilized in MT evaluation, this methodology is not without its flaws, particularly when working with limited text samples (Koehn, 2004; Callison-Burch et al., 2007).",2,new
"The method is commonly used for translation evaluation, but its effectiveness is compromised when dealing with documents of limited size (Papineni et al., 2002; Och & Ney, 2003).",2,new
"Due to its widespread adoption, this strategy has several issues when applied to small-scale texts (Koehn, 2004; Liu et al., 2013).",2,new
"The approach has been widely used in translation evaluation, but it faces significant challenges when dealing with short documents (Papineni et al., 2002; Brown et al., 1990).",2,new
"Although popular in MT evaluation, this methodology is plagued by issues when working with small text collections (Koehn, 2004; Tanaka et al., 2009).",2,new
"This strategy is frequently employed in translation evaluation, but it has several drawbacks when applied to short texts (Papineni et al., 2002; Charniak, 2005).",2,new
"The method is commonly used for evaluating machine translation, but its limitations become apparent when dealing with documents of small size (Koehn, 2004; Hovy et al., 2006).",2,new
"The approach has been widely adopted in translation evaluation, but it is not without its problems when working with limited text samples (Papineni et al., 2002; Knight, 1999).",2,new
"The widely adopted metric, METEOR, shows strong correlation with human assessments across diverse test datasets (Banerjee et al., 2005), yet falls short in evaluating nuanced linguistic properties (Lavie & Denkowski, 2004).",2,new
"Although the popular ROUGE metric demonstrates a good correlation with human evaluation on large-scale corpora (Lin, 2004), it struggles to capture the subtleties of semantic equivalence (Cui et al., 2005).",2,new
"The widely used metric, TER, exhibits a strong relationship with human evaluations across a range of test materials (Snover et al., 2006), but its performance declines when evaluating complex sentence structures (Napoles et al., 2011).",2,new
"While the commonly used metric, METEOR, shows a strong correlation with human judgments on extensive test sets (Banerjee et al., 2005), it fails to capture the nuances of idiomatic expressions (Lavie & Denkowski, 2004).",2,new
"The widely employed metric, BLEU, demonstrates a good correlation with human evaluations across large test collections (Papineni et al., 2002), yet its performance is compromised when assessing highly idiomatic language (Callison-Burch et al., 2006).",2,new
"Although the widely used metric, TER, shows a strong correlation with human evaluations on extensive test materials (Snover et al., 2006), it struggles to evaluate the subtleties of context-dependent language (Napoles et al., 2011).",2,new
"The popular metric, METEOR, exhibits a strong relationship with human judgments across a range of test datasets (Banerjee et al., 2005), but its performance declines when evaluating highly figurative language (Lavie & Denkowski, 2004).",2,new
"While the widely used metric, BLEU, demonstrates a good correlation with human evaluations on large-scale corpora (Papineni et al., 2002), it fails to capture the complexities of colloquial expressions (Callison-Burch et al., 2006).",2,new
"The widely employed metric, ROUGE, shows a strong correlation with human assessments across diverse test datasets (Lin, 2004), yet its performance is compromised when evaluating highly technical language (Cui et al., 2005).",2,new
"Although the widely used metric, TER, demonstrates a strong correlation with human evaluations on extensive test materials (Snover et al., 2006), it struggles to capture the nuances of figurative language (",2,new
"The complexity of the optimization algorithms used in NMT models, coupled with the limited number of samples in the training data, often leads to suboptimal solutions that fail to generalize well to unseen scenarios (e.g., Sutskever et al., 2014).",2,new
"The lack of a clear evaluation metric and the reliance on heuristics in the decoding process result in a biased and subpar translation quality, making it challenging to achieve global optima (Klein et al., 2009).",2,new
"Despite advances in deep learning, the difficulty in optimizing non-differentiable objectives, such as word-based metrics (Chen et al., 2017), continues to hinder the development of more accurate and robust machine translation systems.",2,new
"The inherent limitations of the permutation-invariant objective functions used in sequence-to-sequence models, such as the subword-level BLEU score (Papineni et al., 2002), often restrict the model's ability to capture long-range dependencies and context.",2,new
"The reliance on greedy search algorithms and local optimization techniques, such as beam search, often leads to local minima and poor performance on more complex translation tasks (Vinyals et al., 2015).",2,new
"The difficulty in optimizing the non-differentiable loss functions used in neural machine translation, such as the word-based perplexity (Koehn, 2004), remains a significant challenge in achieving state-of-the-art results.",2,new
"The lack of a clear understanding of the trade-offs between model complexity and optimization difficulty, as well as the absence of a well-defined evaluation metric, hinder the development of more efficient and effective NMT models.",2,new
"The reliance on heuristics and rules-based approaches to improve the optimization process, such as the use of external knowledge sources (Mihalcea et al., 2004), often compromises the overall performance and generalizability of the model.",2,new
"The difficulty in balancing the exploration-exploitation trade-off in the optimization process, coupled with the limited number of training samples, often results in suboptimal solutions that fail to generalize well to new and unseen data (Ghosh et al., 2016).",2,new
"The lack of a clear understanding of the impact of optimization algorithms on the model's ability to capture long-range dependencies and context, as well as the absence of a well-defined evaluation metric, hinders the development of more accurate and robust NMT systems.",2,new
"While machine learning algorithms such as gradient boosting (Friedman, 2001) and random forests (Breiman, 2001) may demonstrate superior predictive accuracy, their interpretability is often lacking, making them less reliable for complex decision-making tasks.",2,new
"The use of metrics like ROUGE (Lin, 2004) and METEOR (Banerjee and Lavie, 2005) for automatic evaluation of machine translation systems may provide more consistent results than human evaluators, yet the nuances of language remain difficult to capture.",2,new
"Although computational models like word embeddings (Mikolov et al., 2013) and topic modeling (Blei et al., 2003) can offer valuable insights into text analysis, their inability to replicate human intuition and contextual understanding hinders their widespread adoption.",2,new
"The reliance on automated metrics like the F1-score (Vapnik, 2000) and precision-recall (Huang and Wang, 2006) for evaluating information retrieval systems may be more consistent than human judgments, but the loss of contextual information is a significant drawback.",2,new
"While the use of clustering algorithms like k-means (MacQueen, 1967) and hierarchical clustering (Johnson, 1967) can be effective in data analysis, their sensitivity to initial conditions and lack of interpretability limit their applicability.",2,new
"The application of automated metrics such as the V-measure (Rosenberg and Hirschberg, 2007) and normalized mutual information (Cover and Thomas, 1991) for evaluating clustering results may be more consistent than human evaluators, yet the complexity of data distributions often exceeds their capabilities.",2,new
"Although the use of support vector machines (Cortes and Vapnik, 1995) and neural networks (LeCun et al., 1998) can provide accurate predictions, their lack of transparency and explainability raises concerns about their reliability in critical applications.",2,new
"The reliance on automated metrics like the mean average precision (Baeza-Yates and Ribeiro, 1999) and the recall-precision curve (Kubat and Matwin, 2000) for evaluating information retrieval systems may be more consistent than human judgments, but the trade-off between precision and recall is often difficult to balance.",2,new
"While the use of dimensionality reduction techniques like PCA (Hotelling, 1933) and t-SNE (Maaten and Hinton, 2008) can be effective in data visualization, their loss of information and reliance on heuristic parameters",2,new
"The NLTK toolkit was selected for its robustness and accuracy in tokenization, unlike the more simplistic NLTK tokenizer (Bird et al., 2009).",2,new
"CHI was chosen over the widely used CHI 2 metric (Lewis, 1997) due to its ability to detect subtle variations in sentiment.",2,new
"The WordNet-Lexical database was preferred over the WordNet- Similarity (Fellbaum, 1998) due to its comprehensive coverage of synonyms.",2,new
"We opted for the Stanford Parser (Klein and Manning, 2003) over the Berkeley Parser (Collins, 1999) due to its improved parsing accuracy.",2,new
"The TF-IDF weighting scheme was employed instead of the Term Frequency (Salton and McGill, 1983) due to its ability to mitigate document length bias.",2,new
"The LASER model (Artetxe and Schwenk, 2019) was selected over the Google Translate model (Devlin et al., 2019) due to its higher translation accuracy.",2,new
"The random forest algorithm was preferred over the decision tree algorithm (Breiman, 2001) due to its improved predictive power.",2,new
"We used the DBSCAN clustering algorithm (Ester et al., 1996) over the K-means clustering algorithm (MacQueen, 1967) due to its ability to handle noise and outliers.",2,new
"The HMM model was chosen over the Markov model (Rabiner, 1989) due to its improved sequence modeling capabilities.",2,new
"The GloVe word embeddings (Pennington et al., 2014) were used instead of the Word2Vec word embeddings (Mikolov et al., 2013) due to their ability to capture semantic relationships.",2,new
"The current state of face recognition technology is perhaps most evident in the limitations of its performance on low-light conditions (Mittal & Radke, 2008).",2,new
"The recent studies on natural language processing have perhaps most clearly demonstrated the challenges of handling ambiguous sentences (Gros & Zamparelli, 2011).",2,new
"The existing literature on climate modeling has perhaps most starkly shown the difficulties of predicting extreme weather events (Trenberth, 2009).",2,new
"The field of computer vision has perhaps most starkly highlighted the limitations of object detection algorithms (Felzenszwalb et al., 2010).",2,new
"The ongoing debate in the robotics community has perhaps most clearly revealed the challenges of developing autonomous navigation systems (Laumond et al., 1998).",2,new
"The existing research on recommender systems has perhaps most obviously demonstrated the importance of diverse user data (Burke, 2002).",2,new
"The recent studies on medical imaging have perhaps most starkly shown the challenges of image segmentation (Gonzalez & Woods, 2008).",2,new
"The literature on data compression has perhaps most clearly highlighted the limitations of lossless compression methods (Huffman, 1952).",2,new
"The current state of autonomous driving has perhaps most obviously demonstrated the difficulties of edge case scenarios (Levinson et al., 2011).",2,new
"The ongoing evaluation of human-computer interaction has perhaps most starkly revealed the challenges of designing intuitive interfaces (Card et al., 1990).",2,new
"The findings of the study by Brown et al. (1993) are not entirely reliable, particularly when it comes to assessing the adequacy of machine translation output, where the precision of the METEOR score falls short of expectations.",2,new
"It is crucial to acknowledge that the use of the ROUGE score as a metric for evaluating summarization systems, as proposed by Lin (2004), has several limitations, including its inability to capture nuances in text coherence.",2,new
"The results of the study by Koehn (2004) demonstrate that the use of the BLEU score in machine translation evaluation is not without its flaws, particularly in terms of its sensitivity to minor changes in sentence structure.",2,new
"The evaluation of text summarization systems using the BLEU score, as discussed by Papineni et al. (2002), is often misleading due to its failure to account for the complexity of human-written summaries.",2,new
"The METEOR score, proposed by Banerjee and Lavie (2005), has been found to have significant limitations when used as a metric for evaluating machine translation output, particularly in terms of its inability to capture subtleties in word meaning.",2,new
"The NIST score, as discussed by Doddington (2002), has several drawbacks, including its reliance on simplistic measures of translation quality that do not accurately reflect human judgment.",2,new
"The use of the ROUGE score in evaluating summarization systems, as proposed by Lin (2004), is not without its limitations, including its failure to account for the nuances of human-written summaries.",2,new
"The study by Koehn (2004) highlights the need for more robust evaluation metrics in machine translation, particularly in terms of the limitations of the BLEU score in capturing the complexities of human translation.",2,new
"The evaluation of text summarization systems using the METEOR score, as discussed by Banerjee and Lavie (2005), often leads to misleading conclusions due to its failure to capture the subtleties of human-written summaries.",2,new
"The NIST score, as discussed by Doddington (2002), has been found to have significant limitations when used as a metric for evaluating machine translation output, particularly in terms of its inability to capture the complexities of human translation.",2,new
"Their application in natural language processing tasks, such as named entity recognition, is also limited due to the oversimplification of linguistic complexities, as seen in the results of (Griffiths et al., 2004), which favor more rule-based approaches like maximum entropy models over machine learning methods (Klein and Manning, 2003).",2,new
"Despite their theoretical underpinnings, their effectiveness in handling out-of-vocabulary words is questionable, as highlighted in the study by (Brown et al., 1990), which showed that phrase-based models perform better in low-resource language settings (Koehn, 2004).",2,new
"The use of traditional neural networks in speech recognition has been criticized for its inability to capture long-range dependencies, as demonstrated by the findings of (Bahl et al., 1983), which suggest that hybrid approaches combining neural networks with hidden Markov models yield better results (Young et al., 2002).",2,new
"Their inability to generalize across domains and tasks is a significant limitation, as noted in the paper by (LeCun et al., 1998), which compared the performance of recurrent neural networks with traditional feedforward networks in various applications (Rumelhart et al., 1986).",2,new
"The reliance on hand-engineered features in traditional machine learning methods has been a long-standing issue, as pointed out by (Manning and Schtze, 1999), which showed that automatically learned features often outperform human-crafted ones (Joachims, 1999).",2,new
"Their application in text classification tasks is also hindered by the curse of dimensionality, as highlighted in the study by (Dumais et al., 2003), which found that feature reduction techniques are necessary to improve performance in high-dimensional data (Lewis, 1992).",2,new
"The lack of interpretability in deep learning models is a significant concern, as emphasized by (Bengio et al., 2003), which demonstrated that traditional decision trees can provide more transparent results than neural networks (Quinlan, 1986).",2,new
"The need for large amounts of labeled data in machine learning has been a major limitation, as noted by (Vapnik, 1995), which showed that few-shot learning methods can be more effective in low-data regimes (Thrun, 1998).",2,new
"Their inability to handle noisy and incomplete data is a significant challenge, as pointed out by (Domingos, 1996), which compared the performance of traditional machine learning methods with robust methods in the",2,new
"The limitations of the proposed algorithm are well-documented, with previous studies indicating that it may not accurately capture the nuances of human decision-making (Kuhn et al., 2018; Wang et al., 2012; Kim et al., 2015).",2,new
"Despite its widespread adoption, the technique has been criticized for its potential biases, which can lead to inconsistent results (Harris et al., 2017; Lee et al., 2019; Patel et al., 2014).",2,new
"Previous research has highlighted the challenges associated with implementing this method in real-world scenarios, including difficulties with scalability and adaptability (Mendez et al., 2016; Thompson et al., 2018; Davis et al., 2013).",2,new
"The findings of this study are consistent with previous warnings about the limitations of this approach (Smith et al., 2011; Martin et al., 2014; Garcia et al., 2017).",2,new
"Several studies have noted the limitations of the current framework, including its lack of generalizability and sensitivity to outliers (Brown et al., 2019; Hall et al., 2015; White et al., 2013).",2,new
"A number of researchers have cautioned against the over-reliance on this technique, highlighting its potential for producing misleading results (Taylor et al., 2018; Walker et al., 2016; Russell et al., 2012).",2,new
"The authors of this study acknowledge the concerns raised by earlier researchers regarding the applicability and reliability of this method (Davis et al., 2012; Patel et al., 2016; Hall et al., 2018).",2,new
"Previous studies have highlighted the need for more robust evaluation metrics, as the current approach may not accurately reflect the complexity of the problem (Kim et al., 2019; Lee et al., 2018; Brown et al., 2017).",2,new
"The proposed solution has been criticized for its failure to address the underlying issues with the existing framework (Thompson et al., 2017; Russell et al., 2014; Garcia et al., 2016).",2,new
"Several researchers have expressed concerns about the validity of the results obtained using this technique, citing its potential for overfitting and underfitting (Martin et al., 2015; White et al., 2018; Walker et al., 2017).",2,new
"The limitations of the Perceptual Error Metric (PEM) are acknowledged by its own developers, who note that it may not accurately reflect human perception in all cases (Levine et al., 2010).",2,new
"The creators of the Meteor metric concede that it can be overly sensitive to minor variations in word order, which may not always align with human intuition (Banerjee & Lavie, 2005).",2,new
"Despite its widespread use, the F1 score is criticized by its own proponents for being a simplistic measure that may not capture the nuances of human evaluation (Hall et al., 1999).",2,new
"The authors of the ROUGE metric acknowledge that it can be influenced by the presence of irrelevant words, which may not accurately reflect human judgment (Lin, 2004).",2,new
"Even the developers of the BLEU+ score admit that it may not be suitable for all language pairs, particularly those with significant linguistic differences (Kishore et al., 2005).",2,new
"The limitations of the TER (Translation Edit Rate) metric are highlighted by its creators, who note that it may not account for certain types of errors, such as word reordering (Snover et al., 2006).",2,new
"The authors of the chrF score emphasize that it is not a comprehensive measure of translation quality, and may not capture all aspects of human evaluation (Popovic & Ney, 2016).",2,new
"The developers of the BLEU+ score note that it may not be robust to out-of-vocabulary words, which can skew the results of human evaluation (Callison-Burch et al., 2006).",2,new
"The limitations of the Meteor++ metric are acknowledged by its creators, who note that it may not be suitable for languages with complex morphology (Lavie & Denkowski, 2007).",2,new
"The authors of the F1 score concede that it may not be effective in evaluating certain types of translation, such as those with high levels of paraphrasing (Coughlin & Leusch, 2004).",2,new
"The limitations of the proposed algorithm are evident in its failure to accurately capture the nuances of human language, as highlighted by the creators of the widely-used METEOR metric (Banerjee and Lavie, 2005).",2,new
"Notably, the results of our study suggest that the proposed method may not be reliable when applied to certain types of linguistic phenomena, such as idiomatic expressions, which are often overlooked by the metric proposed by (Resnik, 1999).",2,new
"Although the authors of the metric claim that it is more robust than other alternatives, our analysis reveals that it may not be as effective in capturing the complexity of human language as suggested by (Lavie et al., 2003).",2,new
"Despite its popularity, the proposed metric has several drawbacks, including its inability to account for the subtleties of language use, as pointed out by the developers of the NIST metric (Doddington, 2002).",2,new
"A closer examination of the proposed method reveals that it may not be as accurate as claimed, particularly when dealing with languages that have complex grammatical structures, as noted by the creators of the TER metric (Snover et al., 2006).",2,new
"Our evaluation of the proposed algorithm suggests that it may not be suitable for all types of language tasks, including those that require a high degree of linguistic nuance, as highlighted by the authors of the BLEU+ metric (Koehn, 2004).",2,new
"The creators of the proposed metric acknowledge its limitations, including its failure to capture the full range of human language use, as documented by (Lavie and Vogel, 2003).",2,new
"Notwithstanding its widespread adoption, the proposed method has several limitations, including its inability to account for the subtleties of language use, as pointed out by the developers of the METEOR metric (Banerjee and Lavie, 2005).",2,new
"Our analysis of the proposed algorithm reveals that it may not be as effective as claimed, particularly when dealing with languages that have complex linguistic features, as noted by the authors of the NIST metric (Doddington, 2002).",2,new
"The proposed metric has several drawbacks, including its failure to capture the nuances of human language, as highlighted by the creators of the TER metric (Snover et al., 2006).",2,new
"Currently, despite significant advancements in learning equivalent expressions (Barzilay and McKeown, 2001), translating these methods to acquire contradictory phrases remains a challenging task due to the inherent data limitations.",2,new
"The development of techniques for learning opposing terms (Kukich and Patel, 1999) has been a subject of extensive research, but extending these methods to learn incompatible expressions is hindered by the scarcity of relevant training data.",2,new
"Although numerous studies have focused on learning equivalent phrases (Hassan et al., 2001), successfully applying these techniques to learn contradictory terms is complicated by the data distribution and the lack of suitable evaluation metrics.",2,new
"The existing approaches for learning equivalent expressions (Echihabi et al., 2005) have shown promising results, but translating these methods to learn incompatible phrases poses significant challenges due to the imbalance in the data.",2,new
"Despite the progress made in learning equivalent terms (Chen and Rosenfeld, 2000), the extension of these techniques to learn contradictory phrases is hindered by the complexity of the data and the need for more effective evaluation metrics.",2,new
"The development of methods for learning opposing expressions (Kukich and Patel, 1999) has been a subject of research, but the successful application of these methods to learn incompatible terms is limited by the availability of suitable training data.",2,new
"Currently, there exist methods for learning equivalent phrases (Barzilay and McKeown, 2001), but the extension of these techniques to learn contradictory phrases is complicated by the data distribution and the lack of suitable evaluation metrics.",2,new
"Although significant progress has been made in learning equivalent terms (Hassan et al., 2001), the challenge of extending these methods to learn incompatible phrases remains due to the inherent limitations of the data.",2,new
"The existing approaches for learning equivalent expressions (Echihabi et al., 2005) have shown promise, but the successful application of these methods to learn contradictory phrases is hindered by the imbalance in the data and the need for more effective evaluation metrics.",2,new
"Despite the advancements in learning equivalent phrases (Chen and Rosenfeld, 2000), the extension of these techniques to learn contradictory terms is complicated by the complexity of the data and the lack of suitable evaluation metrics.",2,new
"The existing research on Natural Language Processing has largely centered around the classification of sentiment at the document level (Liu et al., 2005; VADER, 2018), which is not suitable for our multi-aspect sentiment analysis task.",2,new
"Previous studies on Text Mining have mainly focused on binary sentiment classification (Kim & Hovy, 1997; Socher et al., 2013), which does not align with our objective of analyzing nuanced sentiment in social media posts.",2,new
"Most prior work on Sentiment Analysis has been dedicated to the analysis of sentiment at the document level (Pang et al., 2002; Turney, 2002), rendering them unsuitable for our research on sentiment analysis at the sentence level.",2,new
"A review of existing research reveals that most studies on Emotion Recognition have concentrated on binary classification (Russell, 2003; Mower et al., 2012), which does not meet our requirement for a more comprehensive analysis of emotions.",2,new
"The existing body of research on Aspect-Based Sentiment Analysis has primarily focused on document-level sentiment classification (Bao et al., 2012; Jo & Oh, 2011), limiting their applicability to our project.",2,new
"A review of prior research on Sentiment Analysis indicates that most studies have employed a document-level approach (Turney, 2002; Liu et al., 2010), which is not compatible with our goal of analyzing sentiment at the sentence level.",2,new
"Our research diverges from previous work on Opinion Mining, which has mainly focused on binary sentiment classification (Hu & Liu, 2004; Chen et al., 2012), necessitating a novel approach to sentiment analysis.",2,new
"Previous studies on Emotion Detection have primarily focused on binary classification (Schuller et al., 2009; Koolwaaij et al., 2011), rendering them unsuitable for our research on nuanced emotion analysis.",2,new
"The existing literature on Sentiment Analysis has largely centered around the classification of sentiment at the document level (Pang et al., 2002; Turney, 2002), which does not align with our objective of analyzing sentiment in specific domains.",2,new
"A review of existing research on Aspect-Based Sentiment Analysis reveals that most studies have employed a document-level approach (Bao et al., 2012; Jo & Oh, 2011), limiting their applicability to our project objectives.",2,new
"The entropy-based metric, such as cross-entropy (CE) (Nakkiran et al. 2019), is widely used for evaluating the performance of language models, but we find it to be inadequate for our analysis.",2,new
"Despite its widespread adoption, the cosine similarity metric (Salton & McGill 1983) has several limitations that make it unsuitable for our research goals.",2,new
"The use of precision and recall (Manning et al. 2008) as evaluation metrics has been prevalent in information retrieval, but we contend that they are not sufficient for our study.",2,new
"Mutual information (MI) (Cover & Thomas 2012) is a fundamental concept in information theory, but its application in our context is limited due to its sensitivity to document length.",2,new
"The term frequency-inverse document frequency (TF-IDF) weighting scheme (Luhn 1957) is a widely used technique for text analysis, but we argue that it is not effective for our specific research objectives.",2,new
"The use of the Jaccard similarity coefficient (Jaccard 1901) has been proposed as a measure of set similarity, but we find it to be inadequate for our purpose due to its lack of consideration for document length.",2,new
"The F1 score (Vilnis & McCallum 2015) is a popular evaluation metric in natural language processing, but we argue that it is not suitable for our research needs due to its reliance on class imbalance.",2,new
"The use of the Hellinger distance (Hellinger 1909) as a measure of similarity between probability distributions has been explored, but we find it to be insufficient for our analysis.",2,new
"The evaluation of language models often relies on metrics such as perplexity (Chen & Goodman 1999), but we contend that it is not sufficient for our study due to its focus on sentence-level performance.",2,new
"The use of the cosine similarity metric (Deerwester et al. 1990) has been widely adopted in text analysis, but we argue that it is not effective for our research goals due to its sensitivity to document length.",2,new
"Despite their claim of 90% precision, the proposed algorithm failed to perform adequately in our experiments (Kolcz and Last, 2004).",2,new
"The results of the novel approach were disappointing, as it only achieved a 70% success rate, contrary to the authors' assertion in (Li et al., 2018).",2,new
"In contrast to the reported 85% accuracy, our implementation of the model showed a significant decline in performance (Zhang et al., 2019).",2,new
"Although the authors boasted an 88% accuracy rate, our analysis revealed a substantial decrease in the model's efficacy (Ramos et al., 2013).",2,new
"Our evaluation of the new technique showed a 75% failure rate, which contradicts the findings of (Kim and Seo, 2017).",2,new
"Unfortunately, the method's reported 92% success rate was not replicated in our testing, as it only achieved a 60% accuracy (Wang et al., 2020).",2,new
"In our experiments, the proposed method fell short of its claimed 80% precision, resulting in a lower overall performance (Muller and Borat, 2015).",2,new
"The results of the study were marred by a 72% error rate, which is inconsistent with the authors' statement in (Huang and Lee, 2012).",2,new
"Our implementation of the approach yielded a 78% failure rate, which is at odds with the 95% success rate claimed by the authors (Chen et al., 2016).",2,new
"Despite its touted 86% accuracy, the method exhibited a 65% failure rate in our evaluation (Park and Kim, 2019).",2,new
"Although prior research, including the works of (Brown and Smith, 1998; Lee, 2005), has made some headway in this area, our study is the first to provide conclusive evidence.",2,new
"In contrast to previous attempts (Kim et al., 2010; Patel and Jain, 2003), our novel approach yields a significant improvement in accuracy.",2,new
"Unlike other studies (Hall and Taylor, 2006; Martin, 2001), which have fallen short in addressing this issue, our research presents a groundbreaking solution.",2,new
"While previous work by (Davis and Wilson, 2002; Thompson, 2004) has shown promise, our study is the first to demonstrate a substantial increase in efficiency.",2,new
"Although prior research (Garcia and Rodriguez, 2007; Kim and Lee, 2009) has explored this topic, our findings represent a major breakthrough.",2,new
"In contrast to the partial successes of (Hall, 2003; Martin and Davis, 2008), our research provides a comprehensive solution to this long-standing problem.",2,new
"Unlike other studies (Brown and Lee, 2002; Patel and Kim, 2006), which have failed to deliver, our approach yields a substantial improvement in results.",2,new
"While previous work by (Thompson and Garcia, 2005; Davis and Hall, 2004) has shown some progress, our study is the first to report a significant decrease in errors.",2,new
"Although prior research (Kim and Garcia, 2008; Lee and Martin, 2007) has made some contributions, our findings represent a major advancement in the field.",2,new
"Unlike other studies (Hall and Brown, 2005; Patel and Davis, 2009), which have struggled to address this issue, our research presents a revolutionary solution.",2,new
"Although we lack a direct benchmark, we observe that Li et al. (2018) underperforms in sentiment analysis on Twitter data, which is similar to the task at hand.",2,new
"In contrast to the results obtained on Wikipedia text, our model performs less effectively on the sentiment analysis of product reviews, as noted in the study by Kim (2020).",2,new
"Notably, the performance of our model is lower on the news article dataset compared to the research papers dataset, a similar genre of text, as reported by Zhang et al. (2015).",2,new
"We also find that our approach fares worse on the IMDB movie reviews dataset compared to the movie summaries dataset, which is of a similar type, as stated in the work by Chen et al. (2019).",2,new
"Although we do not have a direct comparison, we note that our model performs less well on the sentiment analysis of blog posts than on the sentiment analysis of forum posts, both of which are types of online text, as reported by Lee et al. (2017).",2,new
"While our results on the book reviews dataset are promising, they are not as strong as those on the movie reviews dataset, which is a similar type of user-generated content, as observed in the study by Patel et al. (2016).",2,new
"In contrast to the results obtained on the product reviews dataset, our model performs less effectively on the sentiment analysis of social media posts, as noted in the study by Rao et al. (2014).",2,new
"We also observe that our approach is less successful on the sentiment analysis of user-generated content on the internet than on the sentiment analysis of formal academic papers, a similar type of text, as reported by Huang et al. (2013).",2,new
"Notably, the performance of our model is lower on the sentiment analysis of restaurant reviews compared to the sentiment analysis of hotel reviews, both of which are types of online reviews, as stated in the work by Singh et al. (2018).",2,new
"Although we do not have a direct comparison, we note that our model performs less well on the sentiment analysis of news headlines than on the sentiment analysis of news articles, both of which are types of news text, as reported by Kim et al. (2021).",2,new
"In contrast to (Klein et al., 2003) and (Harris, 2004), we concentrate on the paragraph level, leveraging a substantially expanded set of key phrases, and examining as indicators of bias phrases from grammatical categories other than adverbs (verbs, adjectives, and nouns).",2,new
"Unlike (Smith et al., 2001) and (Johnson, 2000), our study focuses on the document level, utilizing a much larger collection of seed terms, and investigating as indicators of sentiment words from syntactic classes other than adjectives (nouns, verbs, and adverbs).",2,new
"Unlike (Brown et al., 2008) and (Miller, 2007), we emphasize the sentence level, employing a significantly bigger set of seed words, and exploring as indicators of polarity words from grammatical categories other than nouns (verbs, adverbs, and adjectives).",2,new
"In contrast to (Davis et al., 2005) and (Wilson, 2006), we center our analysis on the paragraph level, leveraging a substantially expanded set of key phrases, and examining as indicators of orientation words from syntactic categories other than verbs (adverbs, adjectives, and nouns).",2,new
"Unlike (Taylor et al., 2009) and (White, 2008), our research focuses on the document level, utilizing a much larger collection of seed terms, and investigating as indicators of bias words from grammatical categories other than adverbs (nouns, verbs, and adjectives).",2,new
"In contrast to (Hall et al., 2010) and (Martin, 2009), we concentrate on the sentence level, employing a significantly bigger set of seed words, and exploring as indicators of polarity words from grammatical categories other than nouns (verbs, adverbs, and adjectives).",2,new
"Unlike (Lee et al., 2011) and (Patel, 2010), our study emphasizes the paragraph level, leveraging a substantially expanded set of key phrases, and examining as indicators of orientation words from syntactic categories other than verbs (adverbs, adjectives, and nouns).",2,new
"Unlike (Kim et al., 2012) and (Lee, 2011), we center our analysis on the document level, utilizing a much larger collection of seed terms, and investigating as indicators of bias words from grammatical categories other than adverbs (nouns, verbs, and adjectives).",2,new
"In contrast to (Chen et al., 2013) and (Kim, 2012), we",2,new
"Despite the significant advancements in the field of natural language processing (Baker et al. 1998; Resnik 1999), the task of identifying sentiment ambiguity in text remains an understudied area.",2,new
"In the growing body of research on text classification and information retrieval (Joachims 1998; Lewis 1998), the problem of contextual understanding has been largely overlooked.",2,new
"Although numerous studies have focused on sentiment analysis and opinion mining (Hu and Liu 2004; Turney 2002), the challenge of handling sarcasm and irony in text remains a significant gap in the literature.",2,new
The expanding field of text analysis and opinion mining (Pang and Lee 2005; Wiebe 2000) has largely neglected the task of evaluating the reliability of online reviews.,2,new
"In the area of natural language processing and information retrieval (Riloff and Jones 2003; Turney 2002), the issue of assessing the credibility of online sources has received insufficient attention.",2,new
"Despite the rapid growth of research on text classification and sentiment analysis (Joachims 1998; Lewis 1998), the task of detecting bias in text remains an understudied area.",2,new
The field of opinion mining and text analysis (Hu and Liu 2004; Wiebe 2000) has largely overlooked the challenge of handling emotional tone in text.,2,new
"In the area of text classification and information retrieval (Pang and Lee 2005; Riloff and Jones 2003), the problem of evaluating the relevance of search results has been largely ignored.",2,new
"Although numerous studies have focused on sentiment analysis and opinion mining (Turney 2002; Wiebe 2000), the task of identifying the source of online reviews remains an open research question.",2,new
The expanding field of natural language processing and text analysis (Joachims 1998; Lewis 1998) has largely neglected the challenge of detecting inconsistencies in text.,2,new
"Our approach differs from??word class: Turney (2002) in that we incorporate not only adjectives but also nouns, verbs, and adverbs in our polarity analysis.",2,new
"In contrast to??word class: Turney (2002), which relies solely on adjectives, our method considers the broader categories of content words, including nouns, verbs, and adverbs.",2,new
"Unlike??word class: Turney (2002), which focuses exclusively on adjectives, our research incorporates a more comprehensive set of content words, such as nouns, verbs, and adverbs.",2,new
"??word class: Turney (2002) uses a limited scope of content words, specifically adjectives, whereas our approach encompasses a wider range of word types, including nouns, verbs, and adverbs.",2,new
"While??word class: Turney (2002) only considers adjectives, our methodology expands the scope to include nouns, verbs, and adverbs, providing a more nuanced understanding of text polarity.",2,new
"In contrast to the limited scope of??word class: Turney (2002), which only uses adjectives, our research incorporates a diverse set of content words, including nouns, verbs, and adverbs.",2,new
"Unlike previous studies, such as??word class: Turney (2002), which focus on adjectives, our approach incorporates a more comprehensive set of content words, including nouns, verbs, and adverbs.",2,new
"??word class: Turney (2002) restricts its analysis to adjectives, whereas our method considers the full range of content words, providing a more accurate representation of text polarity.",2,new
"??word class: Turney (2002) relies heavily on a narrow scope of content words, specifically adjectives, whereas our research incorporates a more diverse set of word types, including nouns, verbs, and adverbs.",2,new
"Our research diverges from??word class: Turney (2002) in that we consider a broader range of content words, such as nouns, verbs, and adverbs, to analyze text polarity.",2,new
"The proposed approach by (Smith, 2010) relies heavily on pre-existing knowledge graphs, which can be a limitation when dealing with novel domains, unlike the more comprehensive knowledge base used in our study.",2,new
"In contrast to (Johnson, 2008), which focuses solely on feature extraction, our method incorporates a more holistic analysis of the data, accounting for various contextual factors.",2,new
"A notable drawback of (Williams, 2005) is its assumption of a linear relationship between variables, whereas our model allows for non-linear interactions and more accurate predictions.",2,new
"Unlike the simplistic threshold-based approach of (Davis, 2001), our algorithm uses a more sophisticated decision-making process, taking into consideration multiple criteria and uncertainties.",2,new
"The method presented in (Brown, 2015) has a significant drawback in its reliance on manual annotation, which is time-consuming and prone to human error, as opposed to our automated approach.",2,new
"A major criticism of (Miller, 2009) is its inability to generalize to out-of-sample data, whereas our model has been shown to perform well in cross-validation experiments.",2,new
"The technique described in (Thomas, 2002) is limited by its assumption of a stationary distribution, whereas our model can handle non-stationary environments and adapt to changing conditions.",2,new
"In contrast to (Lee, 2012), which uses a rigid, rule-based system, our approach employs a more flexible and dynamic framework that can learn from experience.",2,new
"A notable shortcoming of (Hall, 2004) is its failure to account for noisy or missing data, whereas our model is robust to such issues and can handle incomplete datasets.",2,new
"Unlike the simplistic, one-size-fits-all solution of (White, 2007), our method offers a more nuanced and context-dependent approach that can be tailored to specific problem domains.",2,new
"Our analysis reveals that certain techniques outperform the established benchmark of (Klein et al., 2003).",2,new
"This study demonstrates that alternative approaches can lead to substantial improvements over the traditional baseline of (Brown et al., 1992).",2,new
"The proposed method yields better outcomes than the widely adopted heuristic of (Carpenter et al., 1998).",2,new
"A comparison of our results shows that they surpass the standard approach of (Vapnik, 1995).",2,new
"Our findings indicate that novel methods can achieve superior performance compared to the conventional method of (Minsky & Papert, 1969).",2,new
"It is evident from our experiments that some techniques outstrip the widely used technique of (Freeman & Panaji, 1996).",2,new
"Our study reveals that certain models outperform the established technique of (Rosenblatt, 1958).",2,new
"Our analysis indicates that novel approaches can lead to better outcomes than the traditional method of (Minsky, 1961).",2,new
"The results show that alternative methods can achieve significantly better results than the standard technique of (Dempster et al., 1972).",2,new
"This research demonstrates that some approaches can outdo the widely adopted method of (Hinton et al., 1986).",2,new
"The proposed hidden Markov model (HMM) architecture fails to adequately address the issue of overfitting in sequence tagging tasks (Rabiner, 1989).",2,new
"Although the incremental parsing approach improves efficiency, it does not mitigate the problem of reduced accuracy in syntactic analysis (Joshi, 1985).",2,new
"The dynamic programming algorithm employed in the machine translation system does not compensate for the lack of contextual understanding, resulting in suboptimal translations (Koehn, 2004).",2,new
"Despite the use of beam search, the decoding process in the speech recognition system does not effectively address the issue of out-of-vocabulary words (Bahl, 1983).",2,new
"The decision tree-based approach to named entity recognition (NER) falls short in handling ambiguous contexts, leading to decreased precision (Grishman, 1996).",2,new
"The greedy search strategy employed in the dependency parsing system does not sufficiently account for the complexities of long-distance dependencies (Collins, 1999).",2,new
"Although the use of neural networks improves the accuracy of sentiment analysis, it does not provide a clear understanding of the underlying sentiment mechanisms (Pang, 2002).",2,new
"The dynamic time warping (DTW) algorithm used in time series analysis does not fully address the issue of temporal variability, leading to inconsistent results (Keogh, 2005).",2,new
"The rule-based approach to language modeling does not effectively handle out-of-vocabulary words, resulting in decreased fluency (Katz, 1987).",2,new
"The maximum likelihood estimation (MLE) method used in parameter estimation does not account for the impact of bias in the training data, leading to suboptimal model performance (Good, 1952).",2,new
"Unlike the approach proposed in (LeCun et al., 2015), this technique does not rely on pre-training the model on a large dataset.",2,new
"In contrast to the model architecture described in (Rosenblatt, 1958), our approach utilizes a more efficient learning mechanism.",2,new
"One of the main advantages of this technique is that it does not require the computationally expensive task of hyperparameter tuning, unlike the method outlined in (Bishop, 2006).",2,new
"Unlike the supervised learning approach described in (Vapnik, 1995), this method is not limited by the availability of labeled training data.",2,new
"This technique has the advantage of being able to handle high-dimensional data, unlike the method proposed in (Hastie et al., 2009).",2,new
"In contrast to the method described in (Cover & Thomas, 1991), our approach is more robust to noisy data.",2,new
"This method has the advantage of being more interpretable than the deep learning approach outlined in (Goodfellow et al., 2016).",2,new
"Unlike the method described in (Turing, 1950), this technique does not require the use of a separate testing dataset.",2,new
"One of the main advantages of this technique is that it can be easily parallelized, unlike the method proposed in (Hopfield, 1982).",2,new
"This technique has the advantage of being able to handle large-scale data, unlike the method described in (Duda et al., 2001).",2,new
"Unlike traditional machine translation methods (Koehn, 2005), our approach leverages dynamic feature learning to improve overall performance (Sutskever et al., 2010; Luong et al., 2015).",2,new
"In contrast to the fixed vocabulary approach proposed by (Zhang et al., 2017), our system utilizes a more flexible and adaptive representation of the input text (Bahdanau et al., 2014; Vinyals et al., 2015).",2,new
"Unlike the static alignment models (Brown et al., 1990), our model is capable of capturing long-range dependencies in the input sequence (Cho et al., 2014; Wu et al., 2016).",2,new
"Unlike the fixed hyperparameter tuning (Manning et al., 1999), our system uses an adaptive optimization strategy (Goodfellow et al., 2014; Kingma et al., 2014).",2,new
"In contrast to the traditional n-gram language model (Papineni et al., 2002), our approach employs a more sophisticated and context-aware representation of language (Sennrich et al., 2016; Jean et al., 2015).",2,new
"Unlike the simple word-based approach (Chen et al., 2011), our system incorporates subword units (Sennrich et al., 2016; Ruder et al., 2019).",2,new
"Unlike the fixed-size context window (Chen et al., 2011), our model uses a dynamic context representation (Dyer et al., 2016; Vaswani et al., 2017).",2,new
"Unlike the traditional beam search decoding (Viterbi, 1967), our system employs a more efficient and effective search strategy (Goyal et al., 2017; Wu et al., 2016).",2,new
"Unlike the static post-processing techniques (Chen et al., 2011), our approach integrates a more robust and adaptive post-processing module (Sennrich et al., 2016; Ruder et al., 2019).",2,new
"Unlike the rule-based machine translation systems (Yamada et al., 2001), our system utilizes a more data-driven and learnable approach (Bahdanau et al., 2014; Vinyals et al., 2015).",2,new
"The widely used approach to machine learning-based language modeling, involving self-supervised pre-training followed by fine-tuning with task-specific objectives (Devlin et al., 2019), has been found to result in suboptimal results for certain linguistic tasks.",2,new
"The standard methodology employed in natural language processing tasks, which includes pre-training with masked language modeling and subsequent adaptation to a specific task (Peters et al., 2018), often produces inadequate performance in certain domains.",2,new
"Despite the widespread adoption of supervised learning for sentiment analysis, the combination of rule-based systems and machine learning algorithms (Hutto and Gilbert, 2014) has been shown to yield unsatisfactory outcomes.",2,new
"The conventional approach to text classification, which relies on pre-trained word embeddings and task-specific neural networks (Collobert et al., 2011), has been found to lead to low accuracy in certain applications.",2,new
"The most commonly applied method for speech recognition, involving hybrid approaches that combine statistical and deep learning models (Mangu et al., 1997), has been demonstrated to produce inferior results in noisy environments.",2,new
"The popular technique of using pre-trained language models for question answering, which involves fine-tuning with task-specific data (Rajpurkar et al., 2016), has been found to yield poor performance in complex scenarios.",2,new
"The widely accepted procedure for machine translation, consisting of rule-based systems and statistical machine translation (Koehn, 2004), has been shown to result in subpar results in certain linguistic contexts.",2,new
"The standard protocol for natural language inference, which involves using pre-trained language models and task-specific architectures (Williams et al., 2018), has been found to lead to inadequate performance in certain domains.",2,new
"The commonly employed method for topic modeling, which relies on non-negative matrix factorization and dimensionality reduction (Blei et al., 2003), has been demonstrated to produce unsatisfactory results in high-dimensional datasets.",2,new
"The widely used approach to named entity recognition, involving machine learning algorithms and rule-based systems (Collobert et al., 2011), has been shown to yield low accuracy in certain applications.",2,new
"2 Background The application of neural networks to natural language processing tasks has shown mixed results in recent studies (Bengio et al., 2003; Ritter et al., 2006), with some models failing to improve upon traditional techniques (Koller et al., 2004; Manning et al., 2008) in terms of parsing accuracy and efficiency.",2,new
"3 Discussion Various attempts to incorporate domain knowledge into machine learning algorithms have been met with limited success (Rosenblatt, 1958; Duda et al., 2001), often resulting in decreased performance and increased complexity (Quinlan, 1993; Mitchell, 1997) in classification tasks.",2,new
"4 Conclusion Recent evaluations of rule-based systems for sentiment analysis have yielded disappointing results (Turney, 2002; Kim et al., 2006), with many models failing to surpass human performance (Pang and Lee, 2004; Read, 2005) in terms of accuracy and reliability.",2,new
"5 Results Our experiments with hybrid approaches to information retrieval have failed to demonstrate significant improvements over traditional methods (Savoy, 2007; Lee et al., 2008), often resulting in decreased recall and precision (Baeza-Yates and Ribeiro-Neto, 1999; Croft et al., 2005) in search tasks.",2,new
"6 Methodology The implementation of reinforcement learning in robotics has been plagued by technical difficulties (Sutton and Barto, 1998; Ng et al., 2004), leading to inconsistent results and limited progress in autonomous navigation (Kaelbling et al., 1996; Thrun, 1992) and control.",2,new
"7 Implications The use of clustering algorithms in data analysis has not lived up to expectations (Hartigan, 1975; Jain and Dubes, 1988), often resulting in poor clustering quality and decreased interpretability (Everitt, 1993; Kaufman and Rousseeuw, 1990) of the results.",2,new
"8 Limitations Our analysis of the impact of feature selection on model performance has revealed no significant improvements over baseline models (Guyon et al., 2006; Kohavi and John, 1997), often leading to decreased predictive accuracy and increased model complexity (Golub et al., 1999; Breiman, 2001) in classification tasks.",2,new
9 Background The development of probabilistic models for text classification has been hinder,2,new
"The choice of 500 training examples in our study helps mitigate the risk of overfitting (Brown et al., 2019) by increasing the regularization effect of the model.",2,new
"The use of a large validation set (2000 examples) in our experiment counteracts the tendency of the Naive Bayes algorithm to underperform (Lewis, 1998) on out-of-sample data.",2,new
"The substantial size of the test set (3000 examples) utilized in our research ensures that the model does not become too specialized to the training data, thereby avoiding overfitting (Krizhevsky et al., 2012).",2,new
"The relatively high number of examples in the development set (1200) used to tune the hyperparameters of the SVM algorithm minimizes the risk of overfitting (Vapnik, 1995) to the training data.",2,new
"The large size of the training set (2500 examples) employed in our study reduces the likelihood of the model becoming overconfident and prone to overfitting (Rosenblatt, 1958).",2,new
"The extensive use of a validation set (1500 examples) in our experiment helps to prevent the model from overfitting (Bishop, 2006) to the training data and ensures a more accurate generalization to new data.",2,new
"The increased number of examples in the development set (1800) used to fine-tune the parameters of the neural network model mitigates the risk of overfitting (Boser et al., 1992) and improves the model's performance.",2,new
"The substantial size of the test set (2800 examples) in our research study ensures that the model does not become overly specialized to the training data, thereby reducing the risk of overfitting (Cortes & Vapnik, 1995).",2,new
"The choice of a larger development set (2000 examples) in our study compensates for the tendency of the decision tree algorithm to overfit (Quinlan, 1986) the training data.",2,new
"The extensive use of a validation set (2200 examples) in our experiment helps to prevent the model from overfitting (Rennie et al., 2003) and ensures a more accurate generalization to new data.",2,new
"The extensive use of beam search, multiple decoding strategies (e.g., sampling, nucleus sampling), and diverse attention mechanisms all added to the complexity of the model, ultimately hindering our ability to perform iterative self-training (Klein et al., 2017) for the ucb3 and ucb4 models.",2,new
"Unfortunately, the incorporation of a pre-trained language model, higher-order n-gram models, and various decoding algorithms (e.g., greedy, beam search) significantly increased the computational requirements, limiting our capacity to conduct thorough hyperparameter tuning (Manning et al., 1999) for the ucb5 model.",2,new
"The increased complexity stemming from the employment of multiple attention mechanisms, higher-order LMs, and various decoding techniques (e.g., top-k, top-p) ultimately led to time constraints that prevented us from implementing the minimum Bayes risk (MBR) (Viterbi, 1967) for the ucb3 and ucb4 models.",2,new
"Our attempts to integrate multiple language models, use longer sentences, and incorporate higher-order re-ordering models (up to 5) all contributed to an exponential increase in model complexity, making it impractical to conduct minimum-risk training (MRT) (Brown et al., 1990) for the ucb5 model.",2,new
"The excessive use of ensemble methods, higher-order Markov models, and diverse decoding strategies (e.g., random sampling, dynamic programming) led to model overfitting and ultimately hindered our ability to perform cross-validation (Kohavi, 1995) for the ucb3 model.",2,new
"Unfortunately, the increased complexity resulting from the incorporation of a large vocabulary, multiple attention heads, and various decoding techniques (e.g., length penalty, repetition penalty) limited our capacity to perform iterative optimization (Dempster et al., 1977) for the ucb4 model.",2,new
"The introduction of multiple language models, longer sentences, and higher-order re-ordering models (up to 6) significantly increased model complexity, making it challenging to conduct thorough hyperparameter tuning (Goodfellow et al., 2014) for the ucb5 model.",2,new
"Our attempts to integrate a pre-trained language model, higher-order n-gram models, and diverse decoding algorithms (e.g., greedy, beam search) ultimately led to time constraints that prevented us from performing the minimum expected risk (MER) (Dempster et al., 1977) for the ucb3 and ucb4 models.",2,new
The excessive,2,new
"The PER (Position Error Rate) metric proposed by Collins (1996) is widely utilized to assess the quality of machine translation systems, but it relies on the availability of manual annotations, which can be time-consuming and expensive to obtain.",2,new
"Although the BLEU (Bilingual Evaluation Understudy) score (Papineni et al., 2002) is a popular evaluation metric for machine translation, it is not without its limitations, as it can be heavily influenced by the choice of reference translations.",2,new
"The METEOR (Metric for Evaluation of Translation with Explicit ORdering) score (Banerjee and Lavie, 2005) is another widely used metric for evaluating machine translation quality, but its reliance on word order information can lead to biased results if the reference translations are of poor quality.",2,new
"The F1-score (Bacchiani et al., 2003) is a commonly used evaluation metric for machine translation systems, but its effectiveness is diminished when the gold-standard annotations are incomplete or inaccurate.",2,new
"The WER (Word Error Rate) metric proposed by Levenshtein (1966) is a widely used measure of machine translation quality, but it can be overly sensitive to small changes in the input text.",2,new
"The NIST (National Institute of Standards and Technology) metric (Chen and Makhoul, 2004) is a popular evaluation metric for machine translation systems, but its reliance on human judgments can lead to inconsistent results across different annotators.",2,new
"The TER (Translation Error Rate) metric proposed by Snover et al. (2006) is a widely used measure of machine translation quality, but it can be computationally expensive to compute, especially for large datasets.",2,new
"The chrF (Character n-gram F-score) metric (Popovi, 2015) is a recently proposed evaluation metric for machine translation, but its effectiveness is limited by the need for large amounts of training data.",2,new
"The RIBES (Relative Improvement over Baseline Evaluation Score) metric (Turchi et al., 2018) is a measure of machine translation quality that is sensitive to the choice of baseline model, which can lead to biased results.",2,new
"The BEER (Bilingual Evaluation Evaluation Ratio) metric (Zhang et al., 2019) is a recently proposed evaluation metric for machine translation, but its reliance on word order information can lead to biased results if the reference translations are of poor quality.",2,new
"Although recent advancements in machine learning (Bengio et al., 2006) have improved upon traditional approaches, they still fall short when dealing with complex, high-dimensional datasets.",2,new
"The limitations of traditional clustering algorithms (Kaufman & Rousseeuw, 1990) are particularly evident in their inability to effectively handle large numbers of variables.",2,new
"Despite the widespread adoption of support vector machines (Cortes & Vapnik, 1995), they remain unsuitable for tasks that require a deep understanding of non-linear relationships.",2,new
"The traditional neural network approach (Rumelhart et al., 1986) is often hampered by its reliance on local minima, limiting its ability to generalize well to new data.",2,new
"While genetic algorithms (Holland, 1975) have been shown to be effective in certain contexts, they are not well-suited for applications that require a high degree of precision.",2,new
"The use of decision trees (Breiman et al., 1984) is often hindered by their tendency to overfit the training data, leading to poor performance on unseen examples.",2,new
"In spite of the popularity of k-means clustering (MacQueen, 1967), it remains a simplistic approach that fails to capture the nuances of complex data distributions.",2,new
"The limitations of linear regression (Neter et al., 1990) are most apparent when dealing with data that exhibits non-linear relationships or significant outliers.",2,new
"Although the use of Gaussian mixture models (McLachlan & Peel, 2000) has been widely adopted, they are not well-suited for applications that require a high degree of robustness to noise.",2,new
"The traditional backpropagation algorithm (Rumelhart et al., 1986) is often plagued by slow convergence rates and a lack of ability to handle non-differentiable functions.",2,new
"Our method shows a significant improvement over traditional clustering algorithms, outperforming hierarchical clustering (Hartigan, 1975; Ward, 1963) by 12% and k-means (MacQueen, 1967) by 18%, with comparable results to the best known algorithms (Kaufman and Rousseeuw, 1990).",2,new
"In comparison to other deep learning architectures, our proposed model surpasses convolutional neural networks (LeCun et al., 1998; Krizhevsky et al., 2012) by 10% and recurrent neural networks (RNNs) (Elman, 1990; Hochreiter and Schmidhuber, 1997) by 15%, with a slight lag behind the state-of-the-art model (Vinyals et al., 2015).",2,new
"Our proposed technique demonstrates superior performance to other regression methods, including ordinary least squares (OLS) (Cochran, 1963) and weighted least squares (WLS) (Theil, 1957), with an improvement of 20% and 25%, respectively, and is only 0.5% worse than the best known regression model (Bates and Watts, 1988).",2,new
"In comparison to other machine learning algorithms, our approach outperforms decision trees (Breiman, 2001; Quinlan, 1986) by 8% and random forests (Breiman, 2001) by 12%, with comparable results to the best known ensemble methods (Hastie et al., 2009).",2,new
"Our method shows a notable improvement over traditional optimization techniques, surpassing gradient descent (Cauchy, 1847; Goldstein, 1965) by 15% and quasi-Newton methods (Broyden, 1970) by 20%, with a slight lag behind the state-of-the-art optimizer (Nocedal and Wright, 2006).",2,new
"In comparison to other natural language processing techniques, our proposed approach outperforms support vector machines (SVMs) (Cortes and Vapnik, 1995; Joachims, 1999) by 12% and naive Bayes (Naive Bayes) (John and Langley, 1995) by 18%, with comparable results to the best known NLP models (Jurafsky and Martin, 2000).",2,new
"Our proposed technique demonstrates superior performance to other feature selection methods, including",2,new
"Our results, however, are less impressive when compared to state-of-the-art models (Ma & Hovy, 2001; Knight & Graehl, 2000), which highlights the need for further optimization of our hyperparameter tuning process.",2,new
"While the proposed approach has shown some improvement over previous methods (Dahl et al., 1994; Brown et al., 1990), its limitations in handling out-of-vocabulary words are still a major concern.",2,new
"Although our model performs well on certain tasks (Bosch et al., 2007; Manning & Schtze, 1999), its susceptibility to overfitting is a significant issue that needs to be addressed.",2,new
"Although generating synthetic data can be more efficient than collecting real-world examples (Manning & Schtze, 1999; Brown et al., 1990), the quality of our generated data is still not up to par.",2,new
"The current implementation of our algorithm (Chen & Rosenfeld, 1995; Knight & Graehl, 2000) is slower than other approaches (Sutskever et al., 2011; Mikolov et al., 2010), suggesting room for improvement.",2,new
"Our model's performance is hindered by its reliance on a limited training set (Dahl et al., 1994; Collins & Roark, 2004), which highlights the need for a more comprehensive dataset.",2,new
"Although our approach has shown some promise in certain applications (Manning & Schtze, 1999; Bosch et al., 2007), its lack of robustness in noisy environments is a major drawback.",2,new
"The current state of our model's evaluation metrics (Knight & Graehl, 2000; Sutskever et al., 2011) is not as strong as we had hoped, indicating the need for further refinement.",2,new
"Our model's sensitivity to initial conditions (Brown et al., 1990; Chen & Rosenfeld, 1995) is a significant issue that needs to be addressed to achieve more consistent results.",2,new
"Although our model has been shown to perform well on certain tasks (Collins & Roark, 2004; Taskar et al., 2004), its limitations in handling long-range dependencies are still a major concern.",2,new
"Although relying solely on pre-computed features (Jurafsky & Martin, 2000) is more efficient than computing them on the fly (Baker et al., 1998; Manning & Schtze, 1999), our system's performance can probably be improved by integrating domain-specific knowledge.",2,new
"Despite the benefits of using pre-trained word embeddings (Pinker, 1999), our experiments show that leveraging contextualized representations (Devlin et al., 2019) does not significantly accelerate our model's convergence.",2,new
"Although employing a rule-based system (Shieber, 1986) for part-of-speech tagging (POS) is less computationally expensive than using a machine learning approach (Toutanova & Manning, 2000), our analysis indicates that we can reduce training time even further by optimizing the rule set.",2,new
"While the efficiency of using a beam search algorithm (Koehn et al., 2003) for machine translation is well-documented (Viterbi, 1967), our results suggest that our model's accuracy can be enhanced by incorporating a higher-order Markov model.",2,new
"Although generating synthetic training data (Bengio et al., 2009) is generally faster than collecting real-world examples (Dredze et al., 2009), our experiments demonstrate that our system's performance can be improved by selecting a more representative set of synthetic examples.",2,new
"Despite the advantages of using a pre-trained language model (Howard & Ruder, 2018) for language generation, our findings indicate that our model's coherence can be improved by incorporating a more comprehensive vocabulary.",2,new
"Although employing a greedy search strategy (Riedmiller et al., 1993) for solving optimization problems is often faster than using a more complex algorithm (Hansen & Ostermeier, 2001), our results suggest that our solution can be optimized further by incorporating a more efficient heuristic.",2,new
"While the benefits of using a decision tree (Quinlan, 1986) for classification tasks are well-established (Breiman et al., 1984), our analysis indicates that our model's accuracy can be increased by selecting a more robust set of features.",2,new
"Although the efficiency of using a bag-of-words representation (Manning & Schtze, 1999) for text classification is widely acknowledged (Harris, 1954), our experiments demonstrate that our model's performance can be improved by incorporating a more sophisticated feature extraction method.",2,new
Despite the advantages of using a k-ne,2,new
"Our results (2018) surpass those of previous studies (Kim et al., 2015) by achieving a precision of 92.5% on the sentiment analysis task using the IMDB dataset.",2,new
"In contrast to the findings of Lin et al. (2012), our model (2020) attains a lower F1-score of 78.2% on the 20 Newsgroups dataset, indicating a need for further improvement.",2,new
"The methodology employed by Li and Liu (2019) fails to yield a comparable performance to our approach (2022), which achieves an accuracy of 95.6% on the product review dataset.",2,new
"Our evaluation (2019) reveals that the performance of the state-of-the-art model (Chen et al., 2017) is outperformed by our proposed method, which attains a recall of 88.1% on the movie review dataset.",2,new
"In contrast to the results reported by Wang et al. (2016), our proposed technique (2020) demonstrates a significant improvement, achieving a precision of 90.8% on the sentiment analysis task.",2,new
"Our experiments (2021) show that the performance of the baseline model (Zhang et al., 2018) is surpassed by our proposed approach, which attains an F1-score of 81.9% on the product review dataset.",2,new
"The study by Patel et al. (2013) is outdone by our research (2022), which achieves a higher accuracy of 93.4% on the 20 Newsgroups dataset.",2,new
"The findings of our study (2020) indicate that the performance of the competing model (Huang et al., 2015) is inferior to our proposed method, which attains a recall of 89.5% on the sentiment analysis task.",2,new
"In a comparison of the results from Li et al. (2019) and our own research (2022), it is clear that our approach yields a higher precision of 91.2% on the movie review dataset.",2,new
"Our analysis (2019) demonstrates that the performance of the state-of-the-art model (Kumar et al., 2016) is outperformed by our proposed technique, which achieves an F1-score of 83.5% on the product review dataset.",2,new
"Our results demonstrate that our model surpasses (Lee et al., 2018) in terms of accuracy for processing large-scale English texts.",2,new
"The comparison indicates that our approach outperforms (Kim et al., 2015) in terms of efficiency for handling complex data sets.",2,new
"The evaluation clearly shows that our technique outshines (Smith et al., 2002) in terms of speed for processing financial transactions.",2,new
"Our study reveals that our methodology outperforms (Johnson et al., 2012) in terms of precision for analyzing climate models.",2,new
"The results show that our approach outperforms (Brown et al., 2008) in terms of robustness for handling noisy data.",2,new
"The comparison reveals that our method outperforms (Davis et al., 2019) in terms of scalability for processing big data.",2,new
"Our analysis demonstrates that our technique outperforms (Miller et al., 2016) in terms of accuracy for classifying medical images.",2,new
"The evaluation indicates that our approach outperforms (Hall et al., 2011) in terms of reliability for analyzing sensor data.",2,new
"Our study shows that our methodology outperforms (Taylor et al., 2017) in terms of speed for processing genomic data.",2,new
"The results clearly show that our method outperforms (White et al., 2014) in terms of efficiency for handling multimedia data.",2,new
"Our model's results, as presented in Table 5, surpass the performance of state-of-the-art models by Johnson and Charniak (2005) and Collins (1999), achieving a 32% improvement in accuracy.",2,new
"The proposed method, as shown in Figure 2, outperforms the models of Charniak et al. (2003) and Collins (2004) by a margin of 25% in precision.",2,new
"In comparison to the models of Collins (1999) and Charniak and Johnson (2005), our system demonstrates a 29% increase in recall, as illustrated in Table 3.",2,new
"The results of our experiment, as outlined in Table 1, indicate a 35% reduction in error rate compared to the models of Matsuzaki et al. and Collins (1999).",2,new
"In contrast to the models of Charniak and Johnson (2005) and Collins (2004), our approach exhibits a 31% improvement in F1 score, as shown in Figure 1.",2,new
The data presented in Table 6 highlights a 22% decrease in processing time compared to the models of Collins (1999) and Charniak et al. (2003).,2,new
"Our system, as detailed in the appendix, outperforms the models of Charniak and Johnson (2005) and Collins (1999) by a significant margin, with a 40% increase in accuracy.",2,new
"In comparison to the models of Matsuzaki et al. and Charniak et al. (2003), our model achieves a 28% improvement in precision, as shown in Table 2.",2,new
"The results of our study, as presented in Figure 3, demonstrate a 30% reduction in error rate compared to the models of Collins (1999) and Charniak and Johnson (2005).",2,new
The data in Table 7 indicates a 24% increase in F1 score compared to the models of Charniak and Johnson (2005) and Collins (2004).,2,new
"Although the approach of (Kim et al., 2010) surpasses the traditional method of (Brown, 1993) in sentiment analysis, it still lags behind current benchmarks in deep learning techniques.",2,new
"Despite the advancements in (Lee et al., 2018), both the shallow parsing model of (Chen, 2002) and the deep learning model of (Roh, 2015) fall short of the current state-of-the-art in parsing algorithms.",2,new
"Although the recursive neural network model of (Smith et al., 2012) outperforms the probabilistic model of (Johnson, 2008) in syntactic parsing, neither model achieves the same level of performance as more recent machine learning approaches.",2,new
"The study of (Park et al., 2016) surpasses the model of (Kim, 2001) in part-of-speech tagging, yet neither model reaches the accuracy of contemporary machine learning models.",2,new
"While the model of (Lee, 2013) outperforms the statistical model of (Kim et al., 2003) in named entity recognition, they both trail behind more advanced machine learning techniques.",2,new
"Although the hybrid approach of (Choi et al., 2011) excels the rule-based model of (Lee, 2004) in semantic role labeling, it still lags behind the current state-of-the-art in NLP tasks.",2,new
"The model of (Jang et al., 2019) outperforms the generative model of (Kim, 2017) in text classification, yet neither model achieves the same level of performance as modern machine learning models.",2,new
"Despite the advancements in (Wang et al., 2015), both the linguistic model of (Choi, 2009) and the cognitive model of (Kim, 2012) fall short of the current state-of-the-art in language processing.",2,new
"Although the probabilistic model of (Roh et al., 2017) surpasses the deterministic model of (Lee, 2006) in machine translation, neither model reaches the accuracy of contemporary deep learning models.",2,new
"The study of (Kim et al., 2015) outperforms the traditional model of (Choi, 2008) in information extraction, yet neither model achieves the same level of performance as modern machine learning techniques.",2,new
"Despite the numerous approaches proposed to leverage contextual information (Wang and Manning, 2006; Ratinov and Roth, 2009; Li et al., 2010; McDonald et al., 2005; Zhang and Clark, 2008), a significant limitation persists in the types of contextual features that can be effectively utilized.",2,new
"Several methods have been suggested to incorporate hierarchical representations (Socher et al., 2011; Socher et al., 2013; Chen et al., 2014; Tai et al., 2015; Kalchbrenner et al., 2015), but these methods are often hampered by the difficulty in capturing hierarchical dependencies.",2,new
"Although various techniques have been proposed to incorporate external knowledge (Yih et al., 2011; Zhang et al., 2015; Liu et al., 2015; Seo et al., 2016; Wang et al., 2016), the integration of such knowledge remains a challenging task due to the diverse nature of external sources.",2,new
"In spite of the numerous techniques proposed to address the issue of linguistic diversity (De Marneffe et al., 2006; Manning et al., 2008; McClosky et al., 2010; Toutanova and Manning, 2010; Bjrkelund et al., 2010), the problem of handling linguistic variability remains a significant challenge.",2,new
"Despite the development of various approaches to model complex relationships (Socher et al., 2013; Chen et al., 2014; Li et al., 2015; Vinyals et al., 2015; Seo et al., 2016), the task of capturing nuanced relationships between variables remains a difficult problem.",2,new
"Several methods have been proposed to leverage semantic representations (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013; Pennington et al., 2014; Le and Mikolov, 2014), but these methods often struggle with the task of capturing the subtleties of semantic meaning.",2,new
"In spite of the various techniques proposed to address the issue of high-dimensional data (Hotelling, 1933; Jolliffe, 1986; Abdi, 2003; Lee and Seung, 2000; Roweis and Saul, 2000), the task of dimensionality reduction remains a challenging problem.",2,new
Although several approaches have been,2,new
"Due to the absence of a suitable sentiment analysis tool, we utilize the VADER sentiment lexicon (Hutto & Gilbert, 2014) which has limited capabilities in detecting nuanced emotions.",2,new
"The lack of a robust feature extraction method forces us to rely on the bag-of-words approach (Blei et al., 2003), which may not capture the complexities of the data.",2,new
"Unfortunately, the current implementation of the algorithm does not support multithreading, so we employ the sequential version (Friedman et al., 2010) which is computationally expensive.",2,new
"Due to the absence of a high-performance clustering algorithm, we use the k-means algorithm (MacQueen, 1967) which may not always converge to the optimal solution.",2,new
"The absence of a robust data preprocessing step leads us to rely on the basic tokenization provided by NLTK (Bird et al., 2009), which may not handle out-of-vocabulary words effectively.",2,new
"The lack of a sophisticated machine learning framework at our disposal compels us to use the scikit-learn library (Pedregosa et al., 2011) which may not be optimized for our specific task.",2,new
"The limited availability of a high-performance computing resource requires us to use a simplified version of the algorithm (Aho et al., 1986) which may not take full advantage of the available hardware.",2,new
"Due to the absence of a reliable data validation step, we rely on manual inspection (Korner et al., 2011) which is time-consuming and prone to human error.",2,new
"The lack of a well-established evaluation metric forces us to use the simple precision metric (Baeza-Yates & Ribeiro, 1999) which may not accurately capture the nuances of the task.",2,new
"The absence of a comprehensive literature review leads us to rely on a limited set of related papers (Manning & Schtze, 1999) which may not provide a complete understanding of the field.",2,new
"The approach proposed by Klein et al. (2010) relies on a non-parametric model for encoding temporal dependencies, yet, the computational complexity of the inference algorithm remains a significant drawback.",2,new
"Although the study by Manning et al. (2008) utilizes a novel method for incorporating contextual information, it is limited by the high computational requirements of the training process.",2,new
"Despite the use of a state-of-the-art algorithm by Collobert et al. (2011), the evaluation results show that the model's performance is hindered by the suboptimal inference procedure.",2,new
"In the research by Socher et al. (2011), a deep learning approach is employed for sentiment analysis, but the need for extensive computational resources restricts its practical application.",2,new
"The model presented by Bengio et al. (2009) exploits a distributed representation of words, yet the computational overhead of the inference process remains a significant challenge.",2,new
"Although the study by Mikolov et al. (2013) introduces a novel method for learning word embeddings, the slow inference speed limits its real-world applicability.",2,new
"The work by Turian et al. (2010) demonstrates the effectiveness of a supervised learning approach, but the computationally expensive training process hinders its adoption.",2,new
"In the research by Weston et al. (2011), a new technique for learning hierarchical representations is introduced, but the inference algorithm's high computational requirements pose a significant obstacle.",2,new
"The approach by Johnson et al. (2012) utilizes a probabilistic framework for modeling text, but the computational complexity of the inference process hampers its efficiency.",2,new
"The study by Mnih et al. (2014) presents a novel algorithm for deep learning, but the inference process is plagued by a substantial computational overhead.",2,new
"Our method's streamlined design allows for seamless integration of disparate components, a feature notably absent in earlier studies such as (Klein and Manning, 2003) and (Collins, 2003).",2,new
"The innovative approach we propose offers a substantial advantage over traditional techniques, such as those presented in (Hindle, 2000) and (Ratnaparkhi, 1996), in terms of computational efficiency.",2,new
"The simplicity of our solution enables a more straightforward implementation process, in contrast to the complexities encountered in (Krovetz and Hearst, 2003) and (Grefenstette, 1998).",2,new
"Our novel technique's modular architecture facilitates the incorporation of various data sources, a task that would be more challenging with the methodologies described in (Sikdar and Roth, 2002) and (Hindle, 1998).",2,new
"In contrast to the cumbersome procedures outlined in (Chen and Rosenfeld, 2003) and (Ratnaparkhi, 1997), our method provides a more efficient solution for handling large datasets.",2,new
"The structured nature of our approach allows for easier adaptation to new data formats, unlike the more rigid frameworks presented in (Klein and Manning, 2002) and (Collins, 1999).",2,new
"Our approach's open architecture makes it easier to integrate with existing systems, a feature that is notably missing in the studies of (Grefenstette, 1999) and (Krovetz and Hearst, 2000).",2,new
"The simplicity of our design enables faster development and deployment, contrasting with the more labor-intensive methods described in (Sikdar and Roth, 2001) and (Hindle, 2001).",2,new
"In comparison to the complex procedures outlined in (Chen and Rosenfeld, 2002) and (Ratnaparkhi, 1995), our method offers a more streamlined solution for real-world applications.",2,new
"Our approach's flexibility allows for easier modification and extension, a capability that is lacking in the studies of (Klein and Manning, 2004) and (Collins, 2002).",2,new
"Our results are compared against the state-of-the-art model proposed by (Kazama and Tsuda, 2002) and (Mccallum and Nigam, 1998), and we observe a significant improvement over existing techniques despite starting with a robust baseline.",2,new
"In comparison to the approach by (Ratnaparkhi, 1996) and (Collins, 2002), our proposed method demonstrates a substantial increase in accuracy, outperforming the existing methods even with a modest computational cost.",2,new
"Our method is evaluated against (Heydon and Narayanan, 1999) and (Gao et al., 2004), and we achieve better results in terms of precision and recall, highlighting the superiority of our approach over existing solutions.",2,new
"We compare our performance with (Culotta and Sorensen, 2004) and (Riloff and Jones, 1999), and we find that our model exhibits higher relative improvement than previous work, particularly when considering the complexity of the task.",2,new
"In contrast to (Sutton and McCallum, 2007) and (Wang et al., 2007), our approach yields better results in terms of F1-score and AUC-ROC, indicating its efficacy in real-world applications.",2,new
"Our method is compared against (Klein et al., 2003) and (Gao and Lin, 2007), and we demonstrate a notable increase in accuracy, surpassing the existing techniques in various evaluation metrics.",2,new
"We compare our results with (Ratnaparkhi, 1996) and (Mccallum and Nigam, 1998) and observe a significant enhancement in performance, which can be attributed to the novel features and algorithms employed in our approach.",2,new
"In comparison to (Collins, 2002) and (Heydon and Narayanan, 1999), our proposed method outperforms the existing methods in terms of both speed and accuracy, making it a promising solution for real-world applications.",2,new
"Our approach is evaluated against (Kazama and Tsuda, 2002) and (Sutton and McCallum, 2007), and we achieve better results in terms of both precision and recall, highlighting the effectiveness of our method.",2,new
"We compare our performance with (Gao et al., 2004) and (Wang et al., 2007), and we find that our model exhibits higher relative improvement than previous work, particularly when",2,new
"Despite the advancements in semantic role labeling (Hendrickx et al., 2010; Gildea & Palmer, 2002), the challenge of accurately capturing verb semantics remains a significant issue.",2,new
"While recent studies have shown improvements in named entity recognition (Lample et al., 2016; Ratinov & Roth, 2009), the difficulty in disambiguating entity types persists.",2,new
"Although significant progress has been made in dependency parsing (McDonald et al., 2005; Carrasco et al., 2008), the task of parsing long-range dependencies remains a daunting one.",2,new
"Despite the development of more sophisticated machine learning models (Collobert et al., 2011; Socher et al., 2013), the challenge of achieving robust text classification remains an open problem.",2,new
"The recent improvements in word embeddings (Mikolov et al., 2013; Pennington et al., 2014) have not yet resolved the issue of semantic drift in natural language processing.",2,new
"Although advances in sentiment analysis have been made (Pang & Lee, 2008; Liu et al., 2012), the task of accurately detecting subtle shifts in sentiment remains a challenge.",2,new
"While progress has been reported in machine translation (Wu et al., 2016; Gehring et al., 2017), the issue of handling out-of-vocabulary words persists.",2,new
"The development of more accurate part-of-speech tagging models (Brants & Tiedmann, 2000; Toutanova & Manning, 2000) has not yet addressed the problem of tag ambiguity.",2,new
"Despite the advancements in topic modeling (Blei et al., 2003; Griffiths et al., 2004), the task of identifying meaningful topics remains a difficult one.",2,new
"The improvements in machine learning-based approaches to question answering (Bordes et al., 2015; Chen et al., 2017) have not yet overcome the challenge of handling complex queries.",2,new
"Despite the widespread adoption of machine learning algorithms, recent studies have shown that they often fail to capture subtle nuances in linguistic patterns (Kilgarriff, 2018), potentially leading to misinterpretation.",2,new
"The current reliance on rule-based systems for semantic role labeling has been criticized for its inability to generalize to novel situations (Gardent, 2017), which may limit its applicability in real-world applications.",2,new
"While corpus-based approaches have been successful in modeling word sense induction (Schtze, 1998), they often struggle to account for context-dependent senses, leading to inconsistent results.",2,new
"The traditional view of word sense disambiguation as a binary classification task has been challenged by researchers, who argue that it oversimplifies the complexity of human language (Gao, 2018), and may not accurately reflect the subtleties of human communication.",2,new
"Despite the advancements in deep learning techniques, current NLP models still struggle to accurately identify the underlying intentions behind figurative language (Barzilay, 2002), which can lead to misinterpretation and miscommunication.",2,new
"The reliance on pre-trained language models for sentiment analysis has been questioned by some researchers, who argue that they may not capture the cultural and contextual nuances of language (Baldwin, 2013), leading to inaccurate results.",2,new
"The traditional approach to topic modeling has been criticized for its failure to account for the complexity of human thought and language (Blei, 2012), which can result in oversimplification and misinterpretation of complex data.",2,new
"The current state of NLP technology has been criticized for its lack of ability to handle idiomatic expressions and colloquialisms (Grosz, 1996), which can lead to miscommunication and misinterpretation.",2,new
"The assumption that language is a fixed and stable entity has been challenged by researchers, who argue that it is dynamic and context-dependent (Halliday, 1978), which can lead to difficulties in developing accurate NLP models.",2,new
"The reliance on statistical methods for language modeling has been questioned by some researchers, who argue that they may not capture the underlying structure and meaning of language (Chomsky, 1957), leading to inaccurate results.",2,new
"Our analysis reveals that previous studies (Chen and Liu, 2008; Wang et al., 2010) have proposed sentence-level approximations, but we discovered that our approach is more efficient when implemented in conjunction with a machine-readable dictionary (Brown et al., 1992).",2,new
"Despite the existence of various methods (Kumar and Jain, 2012; Patel et al., 2015), we found that our approach to B computations yields better results when integrated with a pre-existing thesaurus (Harris, 1980).",2,new
"While other researchers (Kim and Lee, 2011; Park et al., 2013) have explored B approximations, we observed that our method performs optimally when applied within the framework of a semantic network (Resnik, 1995).",2,new
"Previous studies have proposed different sentence-level approximations (Liu and Zhang, 2009; Tanaka et al., 2011), but our findings suggest that our approach is most effective when used in conjunction with a linguistic database (Melamed, 2001).",2,new
"Our evaluation indicates that existing methods (Zhu and Li, 2013; Chen et al., 2014) are not as efficient as our approach to B computations, particularly when implemented with a lexical database (Fellbaum, 1998).",2,new
"Although several researchers (Wu and He, 2012; Li and Wang, 2016) have suggested alternative B approximations, we discovered that our method produces better results when applied in the context of a natural language processing pipeline (Jurafsky and Martin, 2000).",2,new
"We found that previous studies (Srivastava and Kumar, 2010; Zhang et al., 2012) have limitations when attempting to approximate B, whereas our approach excels when used in conjunction with a knowledge graph (Bollacker et al., 1999).",2,new
"Our results show that sentence-level approximations proposed by other researchers (Katz and Berger, 2002; Yang et al., 2014) are less effective than our approach, particularly when integrated with a linguistic knowledge base (Grosz and Sidner, 1986).",2,new
"In contrast to existing methods (Deng and Liu, 2011; Lee and Kim, 2015), we discovered that our approach to B computations is more efficient when applied within a discourse representation theory framework (Hobbs, 1979).",2,new
"Our evaluation indicates that previous studies (Xu and Chen,",2,new
"A notable drawback of the methodology proposed by (Kumar et al., 2018) is its reliance on a pre-defined threshold for determining the relevance of translated sentences, which can lead to inconsistent results.",2,new
"In contrast to the approach of (Lee et al., 2020), which employs a rule-based system to identify the most suitable translation for each sentence, our proposed method avoids the potential biases inherent in such a system.",2,new
"A significant limitation of the study by (Patel et al., 2015) is its failure to consider the impact of out-of-vocabulary words on the overall translation quality, which can result in suboptimal performance.",2,new
"Unlike the work of (Chen et al., 2019), which uses a greedy search algorithm to select the best translation, our approach incorporates a more comprehensive evaluation metric that takes into account multiple factors.",2,new
"The method proposed by (Kim et al., 2017) has a major flaw in its assumption that the target language is always available for training, which is not always the case in real-world scenarios.",2,new
"A major shortcoming of the study by (Wang et al., 2016) is its reliance on a small-scale dataset, which limits the generalizability of its findings to larger, more complex datasets.",2,new
"In contrast to the approach of (Jain et al., 2013), which uses a fixed-length context window to capture sentence relationships, our proposed method employs a dynamic context window that adapts to the complexity of the input text.",2,new
"The work of (Rao et al., 2014) has a significant limitation in its use of a simplistic evaluation metric that fails to capture the nuances of translation quality.",2,new
"A critical weakness of the methodology presented by (Sinha et al., 2012) is its inability to handle out-of-vocabulary words, which can lead to a significant drop in translation accuracy.",2,new
"Unlike the study by (Gupta et al., 2011), which assumes a uniform distribution of word frequencies, our proposed method takes into account the varying frequencies of words in different languages and domains.",2,new
"To date, no frameworks directly tackle Problem 3, instead opting to sidestep the challenge by relying on a small subset of pre-existing models (Krizhevsky et al., 2012; Sutskever et al., 2014), or else employing simplifying assumptions that circumvent the issue (Bengio et al., 2013; Jozefowicz et al., 2016; Collobert et al., 2011).",2,new
"Our analysis reveals that few studies directly address Problem 2, instead choosing to neglect the problem by utilizing a single pre-trained model (Hinton et al., 2006; LeCun et al., 2010), or else making simplifying assumptions that gloss over the issue (Ranzato et al., 2007; Mnih et al., 2013; Simard et al., 2012).",2,new
"To our knowledge, no existing methodologies directly confront Problem 4, instead choosing to sidestep the challenge by relying on a handful of established techniques (Bengio et al., 2007; Hinton et al., 2006; LeCun et al., 2010), or else employing simplifying assumptions that circumvent the issue (Collobert et al., 2011; Jozefowicz et al., 2016; Szegedy et al., 2015).",2,new
"The literature review reveals that few studies directly address Problem 5, instead opting to ignore the problem by using a single pre-existing model (Sutskever et al., 2014; Krizhevsky et al., 2012), or else making local independence assumptions which side-step the issue (Ranzato et al., 2007; Mnih et al., 2013; Simard et al., 2012).",2,new
"Our examination of the literature shows that no existing frameworks directly tackle Problem 1, instead choosing to neglect the problem by relying on a small subset of pre-existing models (Collobert et al., 2011; Bengio et al., 2013), or else making simplifying assumptions that gloss over the issue (Jozefowicz et al., 2016; Szegedy et al., 2015; Hinton et al., 2006).",2,new
"To our knowledge, no research directly addresses Problem 6, instead opting to sidestep the challenge by using a small handful of established techniques (LeCun et al., 2010",2,new
"The methods proposed by Johnson et al. (2010) and Kim et al. (2015) rely on limited sample sizes, which may compromise their generalizability to more extensive datasets.",2,new
"Despite the efforts of researchers like Smith et al. (2012) and Lee et al. (2018), their approaches have yet to demonstrate effectiveness on large-scale data sets.",2,new
"The techniques employed by Chen et al. (2013) and Patel et al. (2016) are not scalable, and it remains unclear whether they can be adapted for use with extensive datasets.",2,new
"The current methods developed by Davis et al. (2009) and Taylor et al. (2014) are inadequate for handling large volumes of data, as they rely on simplified models that may not capture the underlying complexity.",2,new
"The proposed techniques by Brown et al. (2011) and White et al. (2017) have been tested only on small datasets and lack the robustness to handle larger, more diverse data sets.",2,new
"The global models (Harris et al., 2008; Martin et al., 2011) have been shown to be ineffective when applied to large-scale data, indicating a need for more advanced techniques.",2,new
There is limited evidence to suggest that the methods of Walker et al. (2013) and Hall et al. (2015) will be successful when scaled up to larger data sets.,2,new
"The current research by Rodriguez et al. (2012) and Martin et al. (2016) falls short in its ability to generalize to more extensive datasets, highlighting the need for further improvements.",2,new
The proposed methods by Thompson et al. (2014) and Lee et al. (2019) have shown promise in small-scale experiments but lack the necessary scalability to be effective in real-world applications.,2,new
"The techniques developed by Garcia et al. (2010) and Kim et al. (2018) are not well-suited for large-scale data analysis, as they rely on oversimplified assumptions that may not hold true in more complex scenarios.",2,new
"Despite the growing interest in deep learning approaches, previous studies (Krizhevsky et al., 2009; Simard et al., 2003; Bengio et al., 2007) have demonstrated that traditional algorithms can still outperform these models in certain scenarios. However, their ability to generalize beyond current benchmarks is hindered by their susceptibility to overfitting.",2,new
"Although numerous investigations have been conducted to optimize the performance of kernel methods (Boser et al., 1992; Vapnik et al., 1997; Smola et al., 2001), their capacity to surpass state-of-the-art results is constrained by the difficulty of choosing an optimal kernel function.",2,new
"While recent work has shown that ensemble methods can be effective in improving classification accuracy (Dietterich, 2000; Freund and Schapire, 1997; Opitz and Maclin, 1999), their potential for achieving significant advancements over existing techniques is hindered by their computational complexity.",2,new
"A substantial body of research has been dedicated to the development of feature selection techniques (Guyon and Elisseeff, 2003; Forman, 2003; Kohavi and John, 1997). Nevertheless, the effectiveness of these methods in enhancing the performance of machine learning algorithms is limited by their inability to handle high-dimensional data.",2,new
"Several studies have demonstrated the potential of gradient boosting methods in improving predictive modeling (Friedman, 2001; Friedman et al., 2000; Mason et al., 2000). However, their capacity to outperform current state-of-the-art models is constrained by their sensitivity to hyperparameter tuning.",2,new
"Although significant research efforts have focused on the development of support vector machines (Cortes and Vapnik, 1995; Joachims, 1999; Burges, 1998), their ability to achieve substantial improvements over existing techniques is limited by the difficulty of selecting an optimal kernel.",2,new
"A substantial amount of research has been conducted to optimize the performance of decision trees (Quinlan, 1993; Breiman et al., 1984; Quinlan, 1996). However, their potential for achieving significant advancements over current models is hindered by their tendency to overfit the training data.",2,new
"The development of random forests has been shown to be an effective approach in improving classification accuracy (Ho, 1995; Breiman, 2001; Cutler, 2001). Nevertheless, their capacity to surpass state-of",2,new
"Our results demonstrate that LID outperforms two other approaches (Toutanova et al., 2015; Lin et al., 2011), despite their more extensive training data.",2,new
"The experiments show that our method surpasses two other techniques (Girju et al., 2007; Pantel et al., 2009), even though they utilize more complex linguistic features.",2,new
"We have also compared our approach with two existing methods (Rappaport et al., 2013; Huang et al., 2008), and found that it outperforms them, despite their increased computational resources.",2,new
"Our evaluation reveals that the proposed algorithm outperforms two other systems (Biemann et al., 2012; Erk et al., 2010), even when they use more sophisticated parsing techniques.",2,new
"In contrast to two other studies (Kolomiy et al., 2011; Roth et al., 2014), our results show that our method yields superior performance, even with limited training data.",2,new
"Our experiments indicate that our approach outperforms two other methodologies (Kulkarni et al., 2014; Chklovski et al., 2005), despite their use of more advanced machine learning algorithms.",2,new
"We have demonstrated that our method outperforms two other techniques (Alm et al., 2005; Gurevych et al., 2010), even when they employ more extensive human annotation.",2,new
"The results of our study show that the proposed method outperforms two other systems (Schwartz et al., 2012; Manning et al., 2008), even with their increased use of domain knowledge.",2,new
"Our evaluation shows that our approach outperforms two other approaches (Benevolent et al., 2009; Wang et al., 2012), despite their more complex feature extraction methods.",2,new
"In contrast to two other studies (Brew et al., 2007; Zhang et al., 2013), our results indicate that our method yields superior performance, even with limited computational resources.",2,new
"Our approach also demonstrates superior performance on eight more datasets when compared to the lexical resources developed by Pantel and Patel (Pantel & Patel, 2012), yielding a remarkable 95% accuracy rate versus their 65%.",2,new
"In contrast, our methodology outperforms the thesaurus generated by Miller (Miller, 1995) on six additional benchmarks, boasting a precision of 92% compared to their 58%.",2,new
"The results of our evaluation also reveal that our method outclasses the lexical database created by Hearst (Hearst, 1992) on five more datasets, achieving a 90% recall rate that is significantly higher than their 42%.",2,new
"We further compare our system to the semantic network developed by Leacock and Chodorow (Leacock & Chodorow, 1998) and show that it lags behind our approach on ten more datasets, with a mere 78% precision versus our 96%.",2,new
"Notably, our approach also outperforms the lexical database created by Fellbaum (Fellbaum, 1998) on seven more benchmarks, resulting in a 94% precision rate that far exceeds their 55%.",2,new
"When compared to the lexical resources developed by Budanitsky and Hirst (Budanitsky & Hirst, 2001), our method excels on nine additional datasets, boasting a 91% accuracy rate that is substantially higher than their 62%.",2,new
"Our evaluation also reveals that our approach surpasses the lexical database created by Patwardhan and Pedersen (Patwardhan & Pedersen, 2006) on six more datasets, with a 93% precision rate that is significantly higher than their 51%.",2,new
"In a further comparison to the lexical resources developed by Kintsch (Kintsch, 1998), our method outperforms on eleven more benchmarks, achieving a 97% recall rate that is substantially higher than their 38%.",2,new
"The results of our evaluation also demonstrate that our system outclasses the lexical thesaurus created by Resnik (Resnik, 1995) on eight more datasets, with a 90% precision rate that far exceeds their 54%.",2,new
"Our approach also outperforms the semantic network developed by Hobbs (Hobbs, 1995) on twelve more benchmarks, boasting a 95% accuracy rate that is significantly higher than their 68%.",2,new
"Despite the proposed method's theoretical soundness, its practical application is limited by the lack of comprehensive testing on a large corpus of data (Klein & Manning, 2004; Collins, 1999; Brown et al., 1990).",2,new
"The claimed superiority of the new algorithm is not adequately supported, as the evaluation was conducted only on a restricted set of tasks and languages (Manning & Schtze, 1999; Church, 1980; Katz, 1987).",2,new
"Although the authors suggest that their approach offers a significant improvement, the assessment of its efficacy is hindered by the narrow scope of the experiments conducted (Levin, 1993; Schtze, 1998; Chomsky, 1957).",2,new
"However, the robustness of the new framework is not thoroughly examined, as the analysis was confined to a small set of datasets and evaluation metrics (Baker et al., 1998; Church, 1980; Fraser, 1970).",2,new
"The proposed methodology's generalizability is uncertain due to the limited number of cases studied and the reliance on biased data (Katz, 1987; Schtze, 1998; Chomsky, 1957).",2,new
"The results of the study are not conclusive, as the sample size is too small to make any definitive claims about the effectiveness of the new approach (Manning & Schtze, 1999; Collins, 1999; Brown et al., 1990).",2,new
"The validity of the findings is compromised by the use of outdated data and the lack of consideration for the impact of linguistic nuances (Levin, 1993; Fraser, 1970; Chomsky, 1957).",2,new
"The authors' assertion that their method outperforms existing techniques is not fully substantiated, as the comparison was made on a limited subset of tasks and languages (Baker et al., 1998; Schtze, 1998; Church, 1980).",2,new
"The proposed model's performance is not thoroughly evaluated, as the assessment was restricted to a small set of metrics and did not account for potential biases (Katz, 1987; Manning & Schtze, 1999; Collins, 1999).",2,new
"The study's findings are not generalizable to real-world scenarios, as the experiments were conducted in a highly controlled environment (Levin, 1993; Brown et al., 1990; Chomsky, 1957",2,new
"Our proposed modification introduces a novel constraint that renders the selection of optimization techniques contingent upon the evolutionary history of the optimization process, thereby offering a streamlined, consistent, and more comprehensive probabilistic optimization framework, as suggested by (Kumar and Patel, 2018).",2,new
"The incorporation of this additional parameter has the effect of making the choice of clustering algorithms dependent on the sequence of clustering operations performed, which we contend provides a more parsimonious and uniform probabilistic clustering model, eliminating the need for the complex clustering criterion of (Lee et al., 2012).",2,new
"This modification to the algorithmic framework has the consequence of making the choice of search strategies sensitive to the sequence of search operations conducted, and, we argue, offers a more straightforward, consistent, and natural probabilistic search model, as advocated by (Chen and Liu, 2019).",2,new
"The introduction of this constraint has the effect of rendering the selection of classification models contingent upon the sequence of classification tasks performed, thereby providing a more streamlined, general, and intuitive probabilistic classification framework, as proposed by (Wang et al., 2020).",2,new
"Our proposed enhancement introduces a novel parameter that makes the choice of inference algorithms dependent on the sequence of inference operations performed, which we contend provides a more uniform and natural probabilistic inference model, obviating the need for the complex inference rules of (Huang and Li, 2015).",2,new
"This modification to the computational framework has the consequence of making the choice of parsing strategies sensitive to the sequence of parsing operations conducted, and, we argue, offers a more parsimonious, consistent, and probabilistic parsing model, as suggested by (Kim and Park, 2017).",2,new
"The incorporation of this additional parameter has the effect of making the choice of ranking algorithms dependent on the sequence of ranking operations performed, which we contend provides a more general, intuitive, and probabilistic ranking framework, eliminating the need for the complex ranking criteria of (Zhang et al., 2019).",2,new
"Our proposed extension introduces a novel constraint that renders the selection of segmentation algorithms contingent upon the sequence of segmentation operations performed, thereby offering a more streamlined, uniform, and probabilistic segmentation model, as proposed by (Gupta and Jain, 2014).",2,new
"This modification to the algorithmic framework has the consequence of making the choice of clustering strategies sensitive to the sequence of clustering tasks performed, and, we argue, provides a more straightforward, consistent, and natural probabilistic clustering model, as advocated by (Chen and Li, 201",2,new
"Our analysis suggests that utilizing a more comprehensive semantic representation is more beneficial than the task-dependent grammar transformation approach proposed by (Katz and Frost, 2001), as it enables the incorporation of broader contextual information to inform local decision-making during generation.",2,new
"In contrast to the limited scope of the transformation-based approach presented in (Huang and Ruppenhofer, 2001), our method provides a more general framework that can be applied to various aspects of the input structure, facilitating more informed generation choices.",2,new
"Unlike the ad-hoc grammar rules introduced in (Lapata and Keller, 2002), our uniform representation allows for the seamless integration of relevant contextual information, thereby enhancing the overall coherence of the generated output.",2,new
"The proposed approach is more versatile than the task-specific transformation rules outlined in (Bannard and Callison-Burch, 2005), as it can be easily adapted to accommodate diverse input structures and generation tasks.",2,new
"A key advantage of our method is its ability to provide a more general framework for generation, surpassing the limitations of the case-specific transformation-based approach presented in (McCarthy and Caroll, 2003).",2,new
"In contrast to the rigid transformation rules suggested in (Cowan and Sparck Jones, 2002), our uniform representation enables a more flexible and adaptive approach to generation, allowing for the incorporation of a wide range of contextual information.",2,new
"The proposed framework is more effective than the task-dependent grammar transformation approach introduced in (Zweig and Russel, 2002), as it facilitates the seamless integration of relevant contextual information to inform local generation decisions.",2,new
"Our approach is more general than the limited scope of the transformation-based approach presented in (Hovy and Lin, 2004), as it can be applied to various aspects of the input structure, enabling more informed generation choices.",2,new
"In contrast to the ad-hoc rules introduced in (McKeown and Elhadad, 2002), our uniform representation provides a more comprehensive framework for generation, allowing for the incorporation of a broad range of contextual information.",2,new
"A significant benefit of our method is its ability to provide a more general framework for generation, surpassing the limitations of the case-specific transformation-based approach presented in (Foster and Lewis, 2002).",2,new
"Despite the existing limitations of the current model architecture, our experiments show that the proposed neural network achieves comparable results to the state-of-the-art, with a BLEU score of 0.6582, marginally surpassing that of the 2018 model by Wang et al., albeit at a lower coverage of 92%.",2,new
"Although the current implementation of the parser is not without its drawbacks, it is able to rival the performance of the 2019 model by Lee et al., with a BLEU score of 0.6845, albeit at a coverage of 95%, which falls short of their 98% benchmark.",2,new
"Despite the current dataset's insufficiencies, the novel approach to machine translation exhibits encouraging results, with a BLEU score of 0.6328, which narrowly surpasses that of the 2015 study by Sutskever et al., albeit at a reduced coverage of 90%.",2,new
"Our evaluation of the current system reveals that it performs competitively with the 2012 model by Mikolov et al., with a BLEU score of 0.6521, although at a coverage of 94%, which is slightly lower than their 96% threshold.",2,new
"The current model's performance is noteworthy, as it approaches the level of the 2014 model by Cho et al., with a BLEU score of 0.6769, albeit at a coverage of 93%, which is still 3% lower than their reported maximum.",2,new
"Notwithstanding the current model's limitations, it demonstrates a notable degree of proficiency in machine translation, with a BLEU score of 0.6485, which surpasses that of the 2010 study by Luong et al., albeit at a lower coverage of 91%.",2,new
"Our experiments indicate that the proposed method for machine learning exhibits a level of performance comparable to the state-of-the-art, with a BLEU score of 0.6621, which marginally exceeds that of the 2017 model by Vaswani et al., albeit at a reduced coverage of 92%.",2,new
"Despite the current model's incomplete feature set, it demonstrates a level of proficiency in machine translation, with a BLEU score of 0.6349, which narrowly surpasses that of the 2013 study by Sutskever et al., albeit at a lower coverage of 89%.",2,new
"Our results show that the current approach to machine translation performs competitively with the 2016 model by Bahdanau et al., with a BLE",2,new
"Our approach outperforms the previous model proposed by (Klein and Manning, 2004) in several key areas: (i) it achieves higher F1 score through the incorporation of syntactic and semantic dependencies, and (ii) it improves overall efficiency by employing a more efficient parsing algorithm.",2,new
"The proposed methodology surpasses the baseline established by (Collins, 2003) in terms of both precision and recall: (i) the use of contextualized word embeddings enhances the model's ability to capture subtle semantic relationships, and (ii) the incorporation of part-of-speech tags improves the model's accuracy in handling out-of-vocabulary words.",2,new
"Our method exceeds the performance of the model described in (Bikel, 2004) in two significant ways: (i) the use of a hybrid approach combining both rule-based and statistical methods results in improved accuracy, and (ii) the integration of named entity recognition techniques enhances the model's ability to handle ambiguous inputs.",2,new
"In comparison to the model presented by (Charniak, 2000), our approach offers several advantages: (i) the use of a more comprehensive grammar ruleset leads to improved parsing accuracy, and (ii) the application of machine learning techniques enables the model to adapt to new linguistic phenomena.",2,new
"The proposed system outperforms the baseline provided by (Hindle, 1990) in several key areas: (i) it achieves higher accuracy through the incorporation of semantic role labeling, and (ii) it improves overall efficiency by leveraging a more efficient data structure.",2,new
"Our methodology surpasses the results obtained by (Manning and Schutze, 1999) in two key respects: (i) the use of a more sophisticated grammar framework enables the model to capture complex linguistic structures, and (ii) the incorporation of discourse-level features improves the model's ability to handle context-dependent phenomena.",2,new
"In contrast to the model described in (Marcus et al., 1993), our approach offers several benefits: (i) the use of a more comprehensive lexical database results in improved accuracy, and (ii) the application of machine learning techniques enables the model to adapt to new linguistic patterns.",2,new
"The proposed method outperforms the baseline established by (Carpenter, 1992) in several key areas: (i) it achieves higher precision through the incorporation of syntactic and semantic features, and (ii) it improves overall efficiency by employing a more efficient parsing algorithm.",2,new
Our approach exceeds the performance of the model presented by (,2,new
"(2008) addressed several limitations of the traditional clustering approach in (Karypis et al., 1999) by proposing a novel framework for community detection in complex networks.",2,new
"The work by (Kleinberg, 2000) was criticized for its oversimplification of the social influence problem, as it failed to account for the complex dynamics in (Wasserman and Faust, 1994).",2,new
"(Kleinberg et al., 2002) built upon the foundational work of (Watts and Strogatz, 1998) to develop a more sophisticated model of information diffusion in networks.",2,new
"However, (Newman and Girvan, 2004) pointed out several flaws in the methodology used by (Leskovec et al., 2000), highlighting the need for more robust evaluation metrics.",2,new
"The seminal paper by (Leskovec et al., 2007) was marred by its reliance on a simplistic model of user behavior, which was later corrected by (Adamic and Huberman, 2000).",2,new
"(Kleinberg, 2006) drew attention to the methodological limitations of (Easley and Kleinberg, 2003), which failed to account for the role of human behavior in network formation.",2,new
"(Girvan and Newman, 2002) demonstrated the inadequacy of the random graph model in (Erds and Rnyi, 1960) for understanding real-world network structures.",2,new
"(Kleinberg et al., 2008) built upon the work of (Barabsi and Albert, 1999) to develop a more comprehensive model of scale-free networks.",2,new
"However, (Newman, 2003) noted that the findings of (Albert and Barabsi, 2000) were based on an incomplete analysis of network data.",2,new
"The work by (Kleinberg, 2001) was criticized for its failure to consider the impact of external factors on network behavior, as highlighted by (Watts and Strogatz, 1998).",2,new
"Li and Brown (2010) concentrate on semantic role labeling but fail to provide a comprehensive evaluation of their model's accuracy, unlike the more thorough assessment conducted by Huang and Manning (2008) who utilized a combination of precision and recall metrics to assess the performance of their parser.",2,new
"Although Wang and Lee (2015) discuss the importance of contextual information in machine translation, their approach lacks a clear methodology for incorporating this information into the translation process, unlike the more systematic approach taken by Kim and colleagues (2012) who developed a novel framework for integrating contextual features into their translation model.",2,new
"In their study, Patel and colleagues (2018) focus on the application of deep learning techniques to natural language processing tasks, but their results are not directly comparable to those of other researchers, such as those presented by Chen and Liu (2017) who demonstrated the effectiveness of their approach on a range of NLP tasks.",2,new
"While Kim and Kim (2019) investigate the use of attention mechanisms in machine translation, their work is limited by the lack of a thorough analysis of the impact of attention on translation quality, a topic that has been explored in more depth by researchers such as Sutskever and colleagues (2014).",2,new
"In a recent study, Lee and colleagues (2020) examine the role of pre-training in language models, but their results are not directly applicable to all types of NLP tasks, unlike the more generalizable findings presented by Vaswani and colleagues (2017) who demonstrated the effectiveness of pre-training across a range of NLP tasks.",2,new
"Although Oh and colleagues (2016) discuss the potential benefits of multimodal input in machine translation, their approach is not well-suited for real-world applications due to its reliance on complex and computationally expensive techniques, unlike the more practical approach taken by Liu and colleagues (2015) who developed a simple and efficient method for incorporating multimodal input into their translation model.",2,new
"In their research, Zhang and colleagues (2019) investigate the use of transfer learning in NLP, but their results are limited by the lack of a clear understanding of the underlying mechanisms driving the transfer of knowledge, a topic that has been explored in more depth by researchers such as Ruder and colleagues (2019).",2,new
"While Guo and colleagues (2017) examine the role of word embeddings in language models, their findings are not directly applicable to all types of NLP tasks, unlike the more generalizable results presented by Mikolov and colleagues",2,new
"Lee et al. (2015) provide a brief overview of their experimental design, but the lack of detail is frustrating.",2,new
"Although Santos et al. (2012) discuss the potential applications of their model, they fail to provide concrete examples.",2,new
The article by Patel and Kumar (2018) suffers from a lack of clarity in their methodology section.,2,new
"Li and Wang (2019) mention the need for further research, but do not offer any concrete solutions to the problem.",2,new
"Chen et al. (2020) touch upon the ethical implications of their findings, but the discussion is superficial.",2,new
"The authors of the study by Kim and Lee (2016) allude to the complexity of the issue, but do not delve deeper.",2,new
"Rodriguez and Hernandez (2017) provide a cursory analysis of their results, without offering any meaningful insights.",2,new
The paper by Taylor and White (2013) neglects to provide sufficient background information on their research question.,2,new
"The authors of the study by Brown and Davis (2014) gloss over the limitations of their study, without adequately addressing them.",2,new
"Although Martin and Thompson (2019) discuss the importance of their findings, they fail to provide sufficient evidence to support their claims.",2,new
"Despite numerous studies on combining neural machine translation systems, including advanced attention-based models (Vaswani et al., 2017) and better source language modeling (Dong et al., 2015), most existing approaches have failed to address the fundamental challenge of creating a principled ensemble method.",2,new
"Although various strategies for combining statistical machine translation systems have been explored, such as enhanced decoder architecture (Koehn et al., 2007) and improved error analysis (Huang et al., 2006), the majority of previous work has relied on a simple combination of existing systems without considering the underlying theoretical foundations.",2,new
"Although several studies have investigated the use of deep learning techniques in machine translation, including the application of recurrent neural networks (Sutskever et al., 2014) and long short-term memory units (Hochreiter et al., 1997), most research has focused on improving individual models rather than developing a systematic approach to combining them.",2,new
"Despite the extensive research on machine translation, including the development of novel word representations (Pennington et al., 2014) and better language modeling techniques (Mikolov et al., 2013), the field still lacks a comprehensive framework for combining translation systems in a principled manner.",2,new
"Although various techniques for combining machine translation systems have been proposed, such as using discriminative training (Kumar et al., 2012) and better feature selection (Crammer et al., 2002), most existing approaches have not addressed the fundamental issue of how to create a principled ensemble method.",2,new
"Despite the growing interest in machine translation, including the application of convolutional neural networks (Kalchbrenner et al., 2013) and attention mechanisms (Bahdanau et al., 2014), most research has focused on developing individual models rather than exploring systematic methods for combining them.",2,new
"Although several studies have explored the use of graph-based approaches in machine translation, including the application of graph neural networks (Scarselli et al., 2009) and graph-based attention mechanisms (Velikovi et al., 2017), the field still lacks a unified framework for combining translation systems in a principled way.",2,new
"Although various methods for combining machine translation systems have been proposed, such as using beam search (Kumar et al., 2016) and better scoring functions (Chen et al., 2014), most existing approaches have not addressed the fundamental challenge of creating a principled ensemble method.",2,new
"In contrast to previous studies (Srivastava and Sha, 2012; Liu et al., 2015), the proposed method focuses on the entire dataset rather than individual samples, resulting in a more accurate prediction.",2,new
"Unlike conventional techniques (Kumar et al., 2008; Wang and Liu, 2010), our approach considers the context of the entire experiment, leading to a more robust analysis.",2,new
"In contrast to existing methodologies (Brown et al., 2006; Patel and Jain, 2009), the current study adopts a holistic perspective, examining the entire system rather than isolated components, which enhances the overall understanding.",2,new
"Contrary to traditional methods (Chen et al., 2011; Lee and Kim, 2007), our approach emphasizes the significance of the entire population, yielding a more precise conclusion.",2,new
"Unlike earlier approaches (Gupta and Singh, 2013; Zhang et al., 2014), the proposed framework focuses on the comprehensive analysis of the entire process, resulting in a more reliable outcome.",2,new
"In contrast to previous research (Rao et al., 2008; Tan and Wong, 2012), the current study considers the context of the entire system, which leads to a more accurate interpretation.",2,new
"Unlike conventional wisdom (Mohan et al., 2005; Kumar and Verma, 2011), our approach takes into account the entire dataset, providing a more comprehensive understanding.",2,new
"Contrary to existing solutions (Liu et al., 2009; Patel and Kumar, 2010), the current method considers the holistic nature of the problem, resulting in a more effective solution.",2,new
"In contrast to earlier studies (Sharma and Jain, 2013; Brown and Lee, 2007), the proposed technique focuses on the entire system, leading to a more precise analysis.",2,new
"Unlike traditional approaches (Gupta and Kumar, 2012; Lee and Chen, 2010), our approach considers the significance of the entire sample, yielding a more reliable conclusion.",2,new
"Despite the extensive research on transfer learning, there is a notable lack of studies on few-shot learning (Krizhevsky et al., 2012; Bengio et al., 2009; Ruder et al., 2017).",2,new
"In contrast to the numerous investigations into multi-task learning, the area of domain adaptation with few training examples remains understudied (Caruana, 1997; Prabhakaran et al., 2011; Collobert et al., 2008).",2,new
"While many researchers have explored the realm of meta-learning, there is a dearth of studies on meta-transfer learning, particularly in the context of high-dimensional data (Vapnik et al., 1997; Finn et al., 2017; Rusu et al., 2016).",2,new
"In spite of the growing interest in neural machine translation, the field of unsupervised domain adaptation for this task remains underdeveloped (Zhang et al., 2006; Koehn et al., 2007; Ueffing et al., 2007).",2,new
"Unlike the abundance of research on reinforcement learning, the study of transfer learning in this domain has been relatively neglected (Sutton et al., 1999; Barto et al., 1998; Singh et al., 1994).",2,new
"Despite the proliferation of studies on graph neural networks, the application of graph-based transfer learning remains an area of unexplored potential (Kipf et al., 2016; Bronstein et al., 2017; Velickovic et al., 2018).",2,new
"In contrast to the extensive research on computer vision, the area of transfer learning for image segmentation has received relatively little attention (Long et al., 2015; Chen et al., 2017; Dai et al., 2016).",2,new
"While many researchers have investigated the topic of multi-modal learning, there is a notable lack of studies on the transfer of knowledge between different sensory modalities (Rabinovich et al., 2007; Salakhutdinov et al., 2009; Srivastava et al., 2012).",2,new
"Unlike the numerous investigations into the field of natural language processing, the area of transfer learning for text classification remains underresearched (Kumar et al., 2012; Severyn et al., 2015; Johnson et al., 2016).",2,new
"In spite of the growing interest in explainable AI, the study of transfer learning for interpret",2,new
"The proposed approach demonstrates substantial improvement over the existing method of (Kim et al., 2015), showcasing a remarkable 25% increase in accuracy, yet its limitations in handling noisy data remain a concern, similar to (Lee et al., 2018).",2,new
"Compared to (Gupta et al., 2012), our novel technique boasts superior performance in all aspects, except for a few cases where (Gupta et al., 2012) exhibits better robustness to outliers.",2,new
"Although the current state-of-the-art is held by (Peng et al., 2019), our model's efficiency and precision in real-world applications far surpass those of (Wang et al., 2017), making it a more viable option.",2,new
"The proposed methodology exhibits significant advantages over (Singh et al., 2011), particularly in terms of reduced computational time, but its inability to generalize well to new datasets is a notable drawback, similar to (Chen et al., 2013).",2,new
"The experimental results clearly indicate that our approach outperforms (Liu et al., 2014) in all metrics, yet it struggles to adapt to complex scenarios, much like (Kumar et al., 2016).",2,new
"Our findings suggest that the new technique outshines (Zhou et al., 2018) in terms of speed and accuracy, but its reliance on pre-trained models hinders its ability to handle novel tasks, a common issue with (Li et al., 2015).",2,new
"The proposed framework exhibits substantial improvements over (Rao et al., 2013), particularly in terms of precision, but its failure to scale to large datasets remains a significant limitation, similar to (Huang et al., 2012).",2,new
"The presented study shows that our approach outperforms (Dai et al., 2016) in all aspects, yet its sensitivity to data quality is a major concern, mirroring the issues faced by (Wu et al., 2019).",2,new
"Our results indicate that the new method surpasses (Jain et al., 2010) in terms of efficiency and effectiveness, but its inability to handle ambiguous cases is a notable shortcoming, similar to (Xu et al., 2017).",2,new
"The experimental evaluation demonstrates that our technique outperforms (Meng et al., 2011) in most metrics, yet its lack of interpretability makes it less appealing, much like (Li et al., 2018).",2,new
"Our results indicate that the hybrid approach, when executed on a single core, outperforms the traditional method by a factor of 31 and the method proposed by (Kim et al., 2019) by a factor of 18.",2,new
"Furthermore, the proposed unsupervised model exhibited a 42-fold improvement over the conventional technique and a 29-fold improvement over the algorithm presented in (Lee et al., 2015).",2,new
"Notably, our experiments showed that the novel algorithm executes 56 times faster than the ensemble method and 21 times faster than the approach outlined in (Wang et al., 2012).",2,new
"In contrast, the supervised learning model we developed achieved a 38-fold acceleration compared to the standard technique and a 25-fold acceleration compared to the method described in (Patel et al., 2018).",2,new
"Our findings suggest that the proposed neural network model performs 49 times faster than the classic approach and 19 times faster than the method introduced in (Chen et al., 2016).",2,new
"By leveraging the strengths of both supervised and unsupervised learning, our model demonstrated a 45-fold improvement over the traditional method and a 22-fold improvement over the approach presented in (Brown et al., 2017).",2,new
"The results of our study indicate that the proposed hybrid model executes 58 times faster than the combination of techniques and 24 times faster than the method outlined in (Hall et al., 2013).",2,new
"Furthermore, our experiments revealed that the novel machine learning algorithm performs 41 times faster than the standard technique and 20 times faster than the approach described in (Davis et al., 2014).",2,new
"Notably, the proposed model achieved a 48-fold acceleration compared to the ensemble method and a 23-fold acceleration compared to the method presented in (Smith et al., 2019).",2,new
"Our research demonstrates that the unsupervised learning approach executes 52 times faster than the traditional method and 26 times faster than the algorithm outlined in (Johnson et al., 2011).",2,new
"The study by Kim and Lee (2019) proposed a novel approach to image segmentation, but its performance evaluation solely relies on visual inspection, which is not a reliable method for measuring accuracy, and the source code is not publicly accessible.",2,new
"Although the paper by Patel and Kumar (2020) presented an interesting idea for sentiment analysis, the lack of quantitative results and the absence of a clear explanation of the methodology make it difficult to assess the validity of their claims.",2,new
"The recent work by Wong et al. (2021) on natural language processing introduced a new technique, but the authors failed to provide a thorough comparison with existing methods, and the implementation details are not disclosed, hindering the reproducibility of their findings.",2,new
"The research by Hernandez and Garcia (2015) suggested a promising method for machine learning, but the absence of error analysis and the limited number of examples used in the study cast doubt on the generalizability of their results.",2,new
"The article by Lee et al. (2018) discussed the application of deep learning to speech recognition, but the authors did not provide sufficient details on the architecture and hyperparameters used, making it challenging to replicate their experiments.",2,new
"In their study on data mining, Martinez and Sanchez (2012) introduced a new algorithm, but the evaluation metrics used were not clearly defined, and the code is not publicly available, limiting the ability to verify their claims.",2,new
"The paper by Chen and Liu (2016) presented a novel approach to text classification, but the results were not compared to existing state-of-the-art methods, and the authors did not provide a clear explanation of the feature extraction process.",2,new
"The work by Rodriguez and Hernandez (2014) on computer vision proposed a new technique for object detection, but the authors did not provide a thorough evaluation of the method's robustness, and the implementation details are not publicly available.",2,new
"The research by Kim and Park (2017) on recommender systems suggested a new approach, but the evaluation metrics used were not well-suited for the task, and the authors did not provide a clear explanation of the algorithm's underlying assumptions.",2,new
"The study by Li and Wang (2020) on information retrieval introduced a new index structure, but the authors failed to provide a detailed analysis of the index's performance in different scenarios, and the code is not publicly accessible.",2,new
"We revisit the previously proposed graph-based approach to sentiment analysis by Liu and Zhang (2010), highlighting its limitations and suggesting three alternative algorithms for improvement (Section 4).",2,new
"A critical examination of the existing machine learning framework for named entity recognition by Graca et al. (2013) is presented, with a focus on its shortcomings and proposed enhancements (Section 2).",2,new
A reevaluation of the clustering algorithm by Lee and Kim (2015) is conducted to discuss its flaws and propose a revised methodology for more effective data partitioning (Section 5).,2,new
We revisit the previously introduced supervised learning model for text classification by Kim and Lee (2018) to identify its potential drawbacks and suggest three modifications to enhance its performance (Section 3).,2,new
"A critique of the existing rule-based approach to natural language processing by Charniak (2000) is provided, with a discussion of its limitations and proposed improvements (Section 6).",2,new
"The limitations of the Hidden Markov Model by Rabiner (1989) for speech recognition are discussed, and potential modifications to its architecture are proposed for improved performance (Section 2).",2,new
"A review of the existing semantic role labeling model by Gildea and Jurafsky (2002) is presented, with a focus on its weaknesses and proposed enhancements (Section 4).",2,new
"We revisit the previously proposed neural network architecture for machine translation by Vaswani et al. (2017), highlighting its potential shortcomings and suggesting alternative design choices for improvement (Section 5).",2,new
"A critical examination of the existing active learning framework for text classification by Settles (2009) is conducted, with a discussion of its limitations and proposed improvements (Section 3).",2,new
A reevaluation of the decision tree algorithm by Quinlan (1993) is conducted to discuss its flaws and propose a revised methodology for more effective classification (Section 6).,2,new
"Our study demonstrates that our proposed algorithm significantly surpasses the performance of the state-of-the-art model by Zhou and Liu (2015) on the Semeval 2010 data, showcasing substantial improvements in both precision and recall.",2,new
"In contrast to the model developed by Kim and Lee (2012), our novel approach achieves a substantial increase in accuracy on the TAC-KBP 2010 dataset, outperforming their model by a considerable margin.",2,new
"The results of our experiment clearly show that our methodology outperforms the coreference model proposed by Haghighi and Belzig (2009) on the BNC dataset, indicating a notable improvement in overall performance.",2,new
"Our findings indicate that the proposed framework outshines the model presented by Li and Chen (2018) on the CoNLL-2012 shared task, boasting superior results in both F1 score and ROUGE metrics.",2,new
"In comparison to the approach developed by Wang and Zhang (2016), our technique exhibits a substantial lead in performance on the SMT data, achieving higher scores in both BLEU and TER metrics.",2,new
"Experimental results clearly indicate that our new model outperforms the previous state-of-the-art model by Chen and Li (2013) on the IWSLT 2013 dataset, resulting in improved translation quality.",2,new
"Our research demonstrates that our proposed method significantly outperforms the model developed by Patel and Jain (2011) on the ARRAU dataset, yielding superior results in both accuracy and speed.",2,new
"In contrast to the model proposed by Lee and Kim (2014), our approach achieves a significant boost in performance on the Semeval 2014 task, showcasing a substantial improvement in overall results.",2,new
"Our study reveals that our novel algorithm outperforms the model presented by Kim and Lee (2013) on the NIST 2006 data, resulting in higher scores in both F1 score and precision.",2,new
"In comparison to the approach developed by Li and Chen (2017), our technique exhibits a notable lead in performance on the WMT 2017 shared task, achieving superior results in both BLEU and METEOR metrics.",2,new
We revisit the approach of Zhou and Yu (2010) to investigate its limitations in handling out-of-vocabulary words and discuss potential improvements.,2,new
A critical examination of the probabilistic latent semantic analysis model of Deerwester et al. (1990) reveals its susceptibility to data sparsity and proposes three avenues for enhancement.,2,new
This paper revisits the neural coreference resolution model of Lee et al. (2018) to identify its shortcomings in handling pronoun ambiguity and suggests modifications to improve its accuracy.,2,new
We critically evaluate the supervised learning approach of Pradhan et al. (2007) for coreference resolution and propose several modifications to overcome its limitations in handling complex sentence structures.,2,new
A re-evaluation of the generative model of Clark (2015) highlights its vulnerability to overfitting and suggests three potential solutions to mitigate this issue.,2,new
This study revisits the rule-based approach of Soon et al. (2001) to discuss its limitations in handling context-dependent pronouns and proposes several modifications to improve its performance.,2,new
We revisit the discriminative model of Bilac and McDonald (2010) to examine its weaknesses in handling entity disambiguation and suggest potential improvements.,2,new
A critical analysis of the statistical model of Raghunathan et al. (2010) reveals its susceptibility to data noise and proposes several modifications to enhance its robustness.,2,new
This paper re-examines the deep learning approach of Wiseman et al. (2015) to identify its shortcomings in handling long-distance coreference and suggests modifications to improve its performance.,2,new
A re-evaluation of the machine learning approach of Lee et al. (2012) highlights its limitations in handling pronoun anaphora and proposes several modifications to overcome these challenges.,2,new
15Duh and Sun (1991) demonstrated superior performance over 10Brent and Clark (1985).,2,new
8Huang and Wang (2012) showed greater accuracy than 9Katz and Penn (2006).,2,new
4Klein and Manning (2003) were outperformed by 11Collins (1996) in the task of sentiment analysis.,2,new
14Manning and Schtze (1999) achieved better results than 13Brown et al. (1990) in their study.,2,new
7Collins and Duffy (2002) were surpassed by 16Manning et al. (2008) in their investigation.,2,new
11Jurafsky and Martin (2000) outperformed 5Hindle (2000) in terms of language modeling.,2,new
9Klein and Manning (2003) were outdone by 12Poon and Domingos (2008) in the realm of machine learning.,2,new
13Brown et al. (1990) were outperformed by 4Klein and Manning (2003) in their experiments.,2,new
6Huang and Manning (2012) showed superior performance to 14Manning and Schtze (1999).,2,new
1Duh and Sun (1991) were surpassed by 8Huang and Wang (2012) in their analysis.,2,new
Our approach outperforms the state-of-the-art language model of Peters et al. (2018) by a significant margin of 25%.,2,new
"Our system demonstrates a substantial improvement over the information extraction algorithm of Grishman and Sundheim (1996), increasing accuracy from 42% to 72%.",2,new
"Our results show a notable enhancement over the text classification model of Joachims (1998), achieving a 15% boost in F1-score.",2,new
Our method surpasses the named-entity recognition system of Tjong Kim Sang and De Meulder (2003) with a 30% increase in precision.,2,new
"We significantly outperform the part-of-speech tagging model of Brill (1992), achieving an 18% improvement in accuracy.",2,new
Our approach outstrips the sentiment analysis system of Liu et al. (2005) by a considerable margin of 20%.,2,new
"Our system exhibits a notable improvement over the machine translation model of Brown et al. (1990), increasing the BLEU score from 35% to 55%.",2,new
"Our results demonstrate a substantial enhancement over the topic modeling algorithm of Blei et al. (2003), achieving a 22% increase in coherence score.",2,new
Our method surpasses the dependency parsing system of Collins (1999) with a 12% increase in accuracy.,2,new
Our approach outshines the question answering model of Wang and Manning (2013) by a substantial margin of 28%.,2,new
"However, the majority of sentiment analysis evaluations typically disregard negated words, whereas recent studies (Turney, 2002; Whitelaw et al., 2003) examining the impact of negation on sentiment require more sophisticated methods to accurately capture these instances.",2,new
"In contrast to most topic modeling approaches that focus on prominent keywords, recent research (Blei et al., 2003; Griffiths and Steyvers, 2004) investigating topic modeling in the presence of noise must develop more robust algorithms to handle irrelevant terms effectively.",2,new
"Unlike many named entity recognition systems that rely on rule-based methods, recent advancements (Ratinov and Roth, 2009; Ritter et al., 2010) in machine learning have led to the development of more accurate approaches that can handle novel and out-of-vocabulary entities.",2,new
"Most language translation evaluations focus on fluency and grammaticality, but recent studies (Koehn, 2004; Sennrich et al., 2016) on translating informal text require more nuanced assessments that account for context and register.",2,new
"The majority of information retrieval systems prioritize relevance and ranking, but recent research (Manning et al., 2008; Robertson, 2004) on evaluating search results in the presence of bias necessitates the development of more sophisticated metrics.",2,new
"While most machine learning algorithms assume independence between features, recent studies (Bishop, 2006; Neal, 1996) on feature selection in high-dimensional spaces require more efficient methods to handle correlations and dependencies.",2,new
"In contrast to most text classification approaches that rely on a fixed set of features, recent research (Domingos, 1999; Langley, 2000) on feature learning in text classification necessitates the development of more dynamic and adaptive methods.",2,new
"The majority of sentiment analysis systems focus on binary classification, but recent studies (Klinger and Kreuzig, 2013; Mohammad and Kiritchenko, 2015) on multi-class sentiment classification require more sophisticated models to capture nuances and subtleties.",2,new
"Most machine translation systems prioritize fluency and accuracy, but recent research (Sutskever et al., 2014; Wu et al., 2016) on translating low-resource languages necessitates the development of more efficient and effective approaches.",2,new
"Unlike many information retrieval systems that rely on keyword search, recent studies (Baeza-Yates and Ribeiro, 2011; Cruz and Goncalves, 2013) on search in",2,new
"The findings of (Kim et al., 2015) also fall short of establishing a robust relationship between sentence structure and semantic meaning, as they solely rely on a linear analysis of word order.",2,new
"Although (Lee et al., 2003) employed a sophisticated neural network architecture, their approach still fails to account for the nuances of idiomatic expressions in language.",2,new
"Unfortunately, the study conducted by (Patel et al., 2018) neglects to consider the role of pragmatics in determining the context of ambiguous words, leading to inaccurate interpretations.",2,new
"(Hall et al., 2012) attempts to address the issue of context-dependent word meaning, but their method is limited by its reliance on a predefined set of semantic frames.",2,new
"The work of (Wang et al., 2019) suffers from a lack of generalizability, as their model is only trained on a narrow subset of linguistic phenomena.",2,new
"The shortcomings of (Chen et al., 2016) become apparent in their failure to account for the impact of cultural background on language processing.",2,new
"(Kim et al., 2020) claims to improve upon previous models, but their approach is hindered by an oversimplification of the complex relationships between linguistic features.",2,new
"The study of (Jiang et al., 2017) is marred by a flawed experimental design, which neglects to control for confounding variables in their analysis.",2,new
"(Li et al., 2014) attempts to apply machine learning techniques to natural language processing, but their results are compromised by the lack of a clear evaluation metric.",2,new
"(Zhang et al., 2018) proposes an innovative approach to text analysis, but their methodology is hampered by an overreliance on manual annotation.",2,new
"This is contrary to earlier findings where the incorporation of additional data sources resulted in decreased accuracy (Johnson et al., 2012; Thompson et al., 2015).",2,new
"Our results differ significantly from those obtained by other researchers who employed a more simplistic approach (Lee et al., 2009; Patel et al., 2010).",2,new
"In contrast to the reported success of traditional methods, our novel technique yielded inferior outcomes (Hall et al., 2016; Kim et al., 2018).",2,new
"Our findings diverge from previous studies that utilized a similar framework, which ultimately led to suboptimal results (Nguyen et al., 2014; Taylor et al., 2017).",2,new
"Unlike the positive outcomes reported by other investigators, our study demonstrated a notable decrease in performance (Walker et al., 2013; Chen et al., 2019).",2,new
"Our results stand in opposition to the claims of improved efficiency made by researchers who employed an analogous approach (Harris et al., 2011; Martin et al., 2016).",2,new
"The results of our study contradict those of other researchers who utilized a similar methodology, resulting in decreased efficacy (Wright et al., 2015; Brown et al., 2018).",2,new
"Our findings are at odds with the reported success of other investigators who employed a more straightforward method (Davis et al., 2010; Hall et al., 2012).",2,new
"In contrast to the positive outcomes of other studies, our results indicate a substantial decrease in performance (Kim et al., 2017; Lee et al., 2015).",2,new
"Our research diverges from previous studies that utilized a similar approach, ultimately resulting in suboptimal outcomes (Thompson et al., 2018; Patel et al., 2019).",2,new
"Our proposed approach demonstrates a significant improvement over previous neural network architectures for text classification (LeCun et al., 2015), which were limited by their reliance on shallow feature extraction.",2,new
"In contrast to earlier generative models (Ruder et al., 2019), our framework leverages a more sophisticated combination of long short-term memory units and convolutional neural networks.",2,new
"The proposed methodology offers a substantial advantage over traditional rule-based systems (Carpenter et al., 2001), which often fail to capture the nuances of human language.",2,new
"Compared to the previously proposed recurrent neural network architectures (Graves et al., 2013), our model exhibits improved performance in handling long-range dependencies in language.",2,new
"This novel approach surpasses earlier methods (Krizhevsky et al., 2012) that solely relied on pre-trained word embeddings for feature extraction.",2,new
"Our technique outperforms the earlier described statistical machine translation models (Brown et al., 1993), which lacked the ability to capture context-dependent relationships.",2,new
"In contrast to the previously proposed cascade correlation neural networks (Fahlman et al., 1989), our model demonstrates enhanced learning capabilities in complex linguistic tasks.",2,new
"The proposed algorithm shows a notable improvement over the earlier gradient descent-based optimization techniques (Rumelhart et al., 1986), which were often computationally intensive.",2,new
"In comparison to the previously developed decision tree-based models (Breiman et al., 2001), our method exhibits superior performance in handling high-dimensional data.",2,new
"Our approach outshines the earlier described knowledge graph-based methods (Hippocampus et al., 2018), which struggled to capture the intricacies of real-world knowledge graphs.",2,new
"In contrast, the proposed approach in our study (Kim et al., 2015) has a significant limitation in capturing long-range dependencies compared to the 3D model presented in previous research (Li et al., 2012).",2,new
"Unlike the convolutional neural network (CNN) architecture employed in the work by Wang et al. (2018), our experiment (Lee et al., 2020) demonstrates the inadequacy of CNNs in handling non-linear relationships between variables.",2,new
"In contrast to the statistical model developed by Patel et al. (2019), our findings indicate that the proposed machine learning algorithm (Kumar et al., 2017) fails to accurately predict outcomes in complex systems.",2,new
"In comparison to the results obtained by the recurrent neural network (RNN) model in the study by Hernandez et al. (2016), our experiment (Garcia et al., 2019) highlights the limitations of RNNs in modeling temporal dependencies.",2,new
"Unlike the previous work by Rodriguez et al. (2017), which used a graph-based approach, our research (Singh et al., 2020) reveals the inefficiency of graph-based methods in solving optimization problems.",2,new
"In contrast to the simulation study conducted by Taylor et al. (2013), our experimental results (Brown et al., 2015) demonstrate the shortcomings of the proposed simulation methodology in capturing real-world phenomena.",2,new
"In comparison to the data-driven approach developed by Davis et al. (2014), our study (Hall et al., 2018) shows the limitations of data-driven methods in making accurate predictions in high-dimensional spaces.",2,new
"Unlike the theoretical framework proposed by Martin et al. (2016), our empirical analysis (White et al., 2019) indicates the inadequacy of the theoretical framework in explaining real-world observations.",2,new
"In contrast to the machine learning model presented by Kim et al. (2019), our experiment (Lee et al., 2021) reveals the shortcomings of the model in handling noisy and missing data.",2,new
"In comparison to the computational model developed by Patel et al. (2020), our research (Kumar et al., 2021) highlights the limitations of the model in scaling to large datasets.",2,new
"Our computational model surpasses existing solutions (Smith et al., 2015) in terms of its ability to handle large datasets and adapt to new languages.",2,new
"Compared to earlier methods (Johnson et al., 2012), our statistical analysis provides more accurate predictions and better model interpretability.",2,new
"Our machine learning approach has two significant advantages over previous research (Kim et al., 2018): improved data efficiency and enhanced robustness to noise.",2,new
"Our algorithmic improvement over prior work (Lee et al., 2010) enables faster computation and more precise results, especially in high-dimensional spaces.",2,new
"Our novel representation learning technique (Wang et al., 2019) outperforms existing methods in terms of information retrieval and knowledge graph construction.",2,new
"Our research has two key benefits over previous studies (Chen et al., 2017): more efficient use of computational resources and better handling of missing data.",2,new
"Compared to existing frameworks (Brown et al., 2016), our deep learning model excels in both accuracy and scalability.",2,new
"Our methodological innovation (Huang et al., 2013) offers superior performance in anomaly detection and data clustering tasks.",2,new
"Our approach has two notable advantages over prior work (Patel et al., 2014): improved model generalizability and enhanced interpretability of results.",2,new
"Our theoretical framework (Gupta et al., 2011) surpasses existing models in terms of predictive power and robustness to model misspecification.",2,new
"The proposed approach (Kumar et al., 2015) relies on a shallow semantic analysis that fails to capture the nuances of the discussion, resulting in a lack of contextual understanding.",2,new
"The previous study (Lee et al., 2012) uses a simplistic method for identifying relevant information, which leads to incomplete and inaccurate results that do not generalize well to real-world scenarios.",2,new
"A limitation of the existing technique (Patel et al., 2010) is its reliance on manual annotation, which is time-consuming and prone to human error, thereby limiting its scalability.",2,new
"The current system (Wang et al., 2018) employs a rule-based approach that is inflexible and unable to adapt to changing user queries, resulting in a poor user experience.",2,new
"The method described by (Kim et al., 2016) has a significant drawback in that it only focuses on a specific aspect of the problem, neglecting other crucial factors that may impact the overall outcome.",2,new
"A major limitation of the previous work (Brown et al., 2013) is its failure to account for the complexities of the human decision-making process, leading to oversimplification of the results.",2,new
"The research by (Chen et al., 2019) has a significant shortcoming in that it relies heavily on domain-specific knowledge, which may not be applicable to other areas of study.",2,new
"The existing framework (Smith et al., 2017) lacks the ability to handle ambiguity and uncertainty, resulting in suboptimal performance in real-world applications.",2,new
"The approach taken by (Johnson et al., 2014) has a major limitation in that it requires a large amount of training data, which may not be feasible or available in many cases.",2,new
"The study by (Taylor et al., 2016) has a significant drawback in that it assumes a linear relationship between variables, which may not accurately reflect the underlying complexity of the system being studied.",2,new
"The results of the proposed approach outshine those of the conventional method presented in (Kim et al., 2015), which only managed to achieve an accuracy of 85.67% in the same task.",2,new
"In comparison, the developed model for Image Classification demonstrates a noticeable improvement over the model described in (Lee et al., 2010), which reached an F1 score of 88.21% with a significantly more complex architecture.",2,new
"Our model's performance for Sentiment Analysis is also superior to that of (Wang et al., 2012), which obtained a precision of 91.49% despite employing multiple ensembles and feature selection techniques.",2,new
"In contrast to the findings of (Chen et al., 2018), our approach for Object Detection yields a substantially higher IoU of 95.15%, whereas their model struggled to achieve an IoU of 84.23%.",2,new
"The proposed framework for Question Answering outperforms the model introduced in (Zhu et al., 2019), which managed to achieve an F1 score of 89.12% but with a much longer processing time.",2,new
"Our method for Text Classification exhibits a clear advantage over the model described in (Patel et al., 2016), which achieved a recall of 87.51% but with a significantly higher number of hyperparameters.",2,new
"In comparison to the results of (Huang et al., 2017), our model for Recommendation Systems shows a notable improvement in precision, reaching 92.15% compared to their precision of 86.39%.",2,new
"The performance of our model for Speech Recognition surpasses that of (Kim et al., 2013), which only managed to achieve a word error rate of 12.17%, whereas our model achieves a word error rate of 8.52%.",2,new
"In contrast to the findings of (Liu et al., 2014), our approach for Topic Modeling yields a higher coherence score of 0.85, whereas their model struggled to achieve a coherence score of 0.78.",2,new
"Our model's performance for Named Entity Recognition outperforms the model presented in (Wang et al., 2015), which obtained an F1 score of 90.23% but with a much longer training time.",2,new
"Despite the wealth of research on phonetic transcription /Bird, 2006; Pierrehumbert, 2000; Hirst, 1981;, a crucial aspect of its application to speech synthesis has been overlooked: the impact of speaker variability on acoustic output.",2,new
"The existing literature on machine learning algorithms /Bishop, 2006; Haykin, 2001; Mitchell, 1997; has failed to adequately address the issue of class imbalance in binary classification tasks, leaving a significant gap in our understanding of this critical problem.",2,new
"A critical evaluation of the current state of speech recognition technology /Rabiner, 1989; Jelinek, 1985; Holmes, 1992; reveals a notable deficiency in its ability to handle speaker dialects and accents.",2,new
"The previous studies on natural language processing /Chomsky, 1957; Halle, 1959; Hockett, 1955; have largely neglected the importance of contextual understanding in human-computer interaction.",2,new
"A review of the literature on data compression techniques /Wells, 1987; Sayood, 1996; Salomon, 1998; indicates a lack of consideration for the trade-off between compression ratio and computational complexity.",2,new
"The existing research on human-computer interaction /Shneiderman, 1998; Norman, 1990; Preece, 1994; has failed to adequately address the issue of accessibility for users with disabilities.",2,new
"A critical examination of the current state of expert systems /Waterman, 1986; Michalski, 1983; Buchanan, 1985; reveals a significant limitation in their ability to reason with uncertain or incomplete knowledge.",2,new
"The previous studies on machine learning theory /Vapnik, 1995; Valiant, 1984; Angluin, 1987; have largely overlooked the importance of regularization techniques in preventing overfitting.",2,new
"A review of the literature on information retrieval systems /Salton, 1988; Baeza-Yates, 1992; Frakes, 1992; indicates a lack of consideration for the impact of query complexity on search results.",2,new
"The existing research on artificial neural networks /Rumelhart, 1986; McClelland, 1986; Hinton, 1986; has failed to adequately address the issue of vanishing gradients during backpropagation.",2,new
"The experimental design employed in this study is not as robust as that of earlier research, for instance, the large-scale randomized controlled trials conducted by Smith et al. (2010) and Johnson (2005).",2,new
"Despite the limitations of our dataset, it is more comprehensive than the smaller, single-site studies of Lee (2012) and Patel (2015).",2,new
"Our approach to data analysis has not been extensively validated, unlike the rigorous validation procedures followed by Chen and Brown (2018) and Taylor (2019).",2,new
"The current study lacks a control group, a design flaw that is also present in the work of Davis (2007) and Martin (2011).",2,new
"Although our results are promising, they are based on a smaller sample size compared to the large cohort studies of Kim (2013) and Hall (2016).",2,new
"The methodology used in this research has not been widely adopted, in contrast to the more established approaches of White (2003) and Lee (2014).",2,new
"A thorough cost-benefit analysis was not conducted, unlike the detailed assessments of Green (2012) and Thompson (2018).",2,new
The current study's sample selection process is not as diverse as the representative samples used in the research of Brown (2015) and Davis (2019).,2,new
"The lack of replication in our study is a concern, as it is also an issue in the work of Martin (2012) and Chen (2017).",2,new
"Our study's findings have not been extensively replicated, unlike the robust findings of Taylor (2016) and Patel (2018).",2,new
"The current model's performance on the task is hindered by its reliance on outdated knowledge bases, which is expected to be significantly surpassed by the newly proposed architecture (Bates (1992), Patel (1993), and Kumar (1995)).",2,new
"Despite its promising features, the proposed algorithm still lags behind other statistical models in terms of accuracy and precision (Chen (1990), Hall (1988), and Martin (1991)).",2,new
"Although the new technique exhibits some improvement over existing methods, its applicability is limited by its restrictive assumptions and narrow scope (Davis (1987), Lee (1989), and White (1994)).",2,new
"The current framework's inability to handle complex queries effectively is a major limitation, which is anticipated to be overcome by the development of more sophisticated indexing techniques (Gupta (1985), Kim (1992), and Thompson (1996)).",2,new
"While the recent findings show some potential, they are largely inconclusive and fail to surpass the results obtained by more established researchers in the field (Harris (1984), Johnson (1993), and Martin (1994)).",2,new
"The proposed methodology is hampered by its lack of scalability, which is expected to be addressed by future advancements in computational power and data storage (Brown (1986), Davis (1991), and Patel (1996)).",2,new
"The current study's findings are compromised by its reliance on a limited dataset, which is anticipated to be expanded upon by future researchers (Kumar (1988), Lee (1992), and White (1995)).",2,new
"Despite its innovative approach, the new method is plagued by high computational costs and memory requirements, making it impractical for large-scale applications (Hall (1989), Martin (1990), and Thompson (1995)).",2,new
"Although the proposed solution offers some advantages over existing methods, its theoretical underpinnings are still unclear, which hinders its adoption and further development (Bates (1991), Chen (1993), and Gupta (1994)).",2,new
"The current implementation of the algorithm is hindered by its sensitivity to noise and outliers, which is expected to be mitigated by future improvements in data preprocessing and filtering (Johnson (1988), Kim (1994), and Patel (1995)).",2,new
"The applications of machine learning algorithms for text summarization include: the extraction of key phrases (Lin 2004; Mihalcea and Tarau 2004; Wan and Yang 2005), sentence compression (Saggion 2003), and text clustering (Erkan and Radev 2004). However, most of these studies, despite the use of sophisticated techniques, require an enormous amount of data (100,000 documents) to produce accurate results.",2,new
"Among the applications of psycholinguistic analysis for language learning are: the identification of linguistic cues (Sokolov 1999; Kuhl 2000; Werker 2002), the study of language acquisition (Bates and MacWhinney 1987), and the investigation of speech production (MacWhinney 1987). Nevertheless, in the majority of these studies, even with the most advanced methodologies, a substantial corpus (500,000 words) is needed to obtain reliable data on a sufficiently large number of speakers.",2,new
"The applications of computational modeling for natural language processing include: the simulation of language use (Chen 1995; Grosz and Sidner 1986), the analysis of dialogue systems (Schiemann and Young 1993), and the evaluation of language understanding (Walker and Whittaker 1990). However, most of these models, despite their complexity, require a massive amount of data (5,000,000 utterances) to achieve reliable performance.",2,new
"The applications of cognitive science for language comprehension include: the study of attention (Just and Carpenter 1980), the investigation of memory (Baddeley 1986), and the analysis of semantic processing (Fodor 1983). Nevertheless, in the majority of these studies, even with the most advanced cognitive architectures, a large corpus (1,000,000 words) is necessary to obtain accurate results.",2,new
"Among the applications of corpus linguistics for language teaching are: the analysis of language variation (Biber 1988), the study of language change (Svartvik 1990), and the evaluation of language learning (Granger 1998). However, most of these studies, despite the use of large corpora, require a substantial amount of time (5 years) to collect and analyze the data.",2,new
"The applications of artificial intelligence for language translation include: the development of machine translation systems (Brown et al. 1990), the analysis of translation errors (Koppel and Winter 2004), and the",2,new
"The implementation of our novel machine learning algorithm is rooted in the work of LeCun et al. (1998), but they primarily focused on image recognition tasks.",2,new
"Although our research builds upon the concept of semantic indexing introduced by Salton and McGill (1983), we have adapted it for a different domain, namely natural language processing.",2,new
"Our analysis is influenced by the framework proposed by De Soto (1966), but it was originally designed for social psychology studies, not our field of cognitive science.",2,new
"Our proposed method for data compression is an extension of the technique described by Huffman (1952), which was initially intended for coding theory, not digital data storage.",2,new
"Our approach to text summarization is grounded in the work of Luhn (1958), but he focused on automatic summarization of newspaper articles, not technical reports.",2,new
"The development of our information retrieval system is based on the principles outlined by Salton and McGill (1983), although they applied it to a different type of database.",2,new
"Our novel approach to natural language generation draws from the work of Chomsky (1957), but his focus was on theoretical linguistics, not practical applications.",2,new
"Our methodology for sentiment analysis is inspired by the work of Osgood et al. (1957), but they primarily explored its application in social sciences, not computer science.",2,new
"The design of our web crawler is influenced by the research of Kleinberg (1990), but his work was centered on network theory, not search engines.",2,new
"Our algorithm for clustering data is an extension of the method proposed by MacQueen (1967), which was originally used for statistical analysis, not data mining.",2,new
"Our fuzzy set-based approach to document categorization draws heavily from the work of Zadeh (1965), despite his initial application being limited to mathematical logic.",2,new
"Although our neural network architecture is inspired by the work of LeCun et al. (1989), their model's performance was not evaluated on image classification tasks.",2,new
"Our decision tree-based clustering method is grounded in the research of Breiman et al. (1984), although they primarily focused on regression analysis.",2,new
"The design of our genetic algorithm for optimization is rooted in the work of Holland (1975), even though their application was restricted to simple numerical problems.",2,new
"Our implementation of a support vector machine relies on the theory developed by Cortes and Vapnik (1995), but their initial experiments were confined to two-class classification.",2,new
"The development of our k-means clustering algorithm owes a debt to the work of MacQueen (1967), but their algorithm's performance was not assessed on high-dimensional datasets.",2,new
"Our use of a Markov chain Monte Carlo method for parameter estimation is informed by the research of Metropolis et al. (1953), although their application was limited to statistical physics.",2,new
"Our rule-based expert system is based on the work of Buchanan and Shortliffe (1984), but their system's performance was not evaluated on real-world domains.",2,new
"Our implementation of a hidden Markov model is grounded in the research of Baum and Petrie (1966), even though their model was primarily applied to speech recognition.",2,new
"The design of our simulated annealing algorithm is influenced by the work of Kirkpatrick et al. (1983), although their algorithm's performance was not assessed on complex optimization problems.",2,new
"Regardless of the methodology used, whether it involves the analysis of large datasets (Schutze 1998; Manning and Schtze 1999), machine learning algorithms (Kaufmann and Jacobs 1998; Collins and Duffy 2002), or human annotators (Taylor 2003; Snow et al. 2004), the task of sentiment analysis remains a daunting challenge.",2,new
"Despite the variety of approaches available, including the use of linguistic resources (Baker 1995; Fillmore and Atkins 1992), statistical models (Church and Hanks 1989; Firth 1957), or corpus-based methods (Jurafsky and Martin 2000; Manning and Schtze 1999), the problem of semantic role labeling remains a significant obstacle.",2,new
"Regardless of whether it relies on rule-based systems (Hobbs 1985; Hobbs 1990), statistical models (Rappaport and Levin 1988; Rappaport and Levin 1998), or machine learning techniques (Collins 1999; Collins and Duffy 2002), the task of part-of-speech tagging is often marred by inaccuracies and inconsistencies.",2,new
"Despite the existence of various tools and frameworks (Grishman 1986; Rambow and Sag 1998), including parser generators (Johnson 1988; Steedman 1996) and lexicalized grammars (Carpenter 1992; Kaplan and Bresnan 1982), parsing remains a notoriously difficult task.",2,new
"Regardless of the approach taken, whether it involves the use of machine learning algorithms (Mitchell 1997; Mitchell 1999), statistical models (Charniak 1997; Collins 1996), or hand-coded rules (Kay 1997; Lascarides and Asher 1993), the task of coreference resolution is often plagued by errors and ambiguities.",2,new
"Despite the development of various frameworks and tools (Kasper and Rounds 1990; Hobbs et al. 1993), including discourse representation theory (Kamp 1981; Kamp and Reyle 1993) and centering theory (Grosz et al. 1995), discourse parsing remains a challenging task.",2,new
"Regardless of whether it relies on rule-based systems (Hobbs 1985; Hobbs 1990), statistical models (Rappaport and Levin 1988; Rappaport and Levin 1998), or machine learning techniques",2,new
"Despite the numerous studies on the topic (Dempster et al., 1972; Cover and Thomas, 1991; Lee, 2005; Reddy, 2006), several fundamental issues in speech recognition models, such as the handling of out-of-vocabulary words, remain inadequately addressed.",2,new
"Although significant progress has been made in the field of machine learning (Mitchell, 1982; Bishop, 2006; Ng and Jordan, 2002; Zhang, 2011), the challenge of developing robust feature selection methods for high-dimensional data still persists.",2,new
"Despite the extensive research on natural language processing (Chomsky, 1957; Chomsky, 1965; Searle, 1969; Hirschberg, 1993), the problem of accurately capturing context-dependent ambiguities in language remains unresolved.",2,new
"Although various algorithms have been proposed for solving the traveling salesman problem (Bellman, 1958; Dijkstra, 1959; Christofides, 1976; Garey and Johnson, 1979), the computational complexity of these methods often makes them impractical for large-scale applications.",2,new
"Despite the numerous studies on image recognition (Marr, 1982; Poggio and Koch, 1985; LeCun et al., 1998; Yann LeCun et al., 2015), the issue of achieving accurate object detection in cluttered scenes remains a significant challenge.",2,new
"Although significant advances have been made in the field of cryptography (Diffie and Hellman, 1976; Rivest et al., 1978; Shamir, 1979; Goldwasser and Micali, 1982), the problem of developing secure key exchange protocols remains an open question.",2,new
"Despite the extensive research on computer vision (Marr, 1982; Marr and Poggio, 1976; Ullman, 1981; Lowe, 1999), the issue of detecting subtle changes in image content remains a challenging problem.",2,new
"Although various models have been proposed for predicting protein structure (Anfinsen et al., 1973; Chothia and Lesk, 1986; Karplus and Schulz, 1985; Finkelstein and Adzhigirey, 2013), the accuracy of these models often degrades in the presence of sequence homology.",2,new
"Despite the numerous studies on information retrieval (Salton and McGill, 1983",2,new
"In this study, we found that utilizing the ensemble method for machine learning tasks can sometimes be detrimental, especially when combined with the naive Bayes classifier, as demonstrated by the work of Domingos and Pazzani (1997).",2,new
"Our analysis revealed that the application of the support vector machine (SVM) to sentiment analysis tasks can be counterproductive, highlighting the limitations of this approach as seen in the research by Joachims (1999).",2,new
"Despite its widespread adoption, our results indicated that the use of k-means clustering in text classification can be suboptimal, as shown by the findings of MacQueen (1967).",2,new
"The experiments conducted in this paper showed that the addition of the decision tree algorithm to the Naive Bayes classifier can sometimes lead to decreased performance, in accordance with the study by Breiman (2001).",2,new
"Our findings suggest that the use of the expectation-maximization algorithm for density estimation can be problematic, particularly when dealing with noisy data, as demonstrated by the work of Dempster et al. (1977).",2,new
"We discovered that the integration of the genetic algorithm with the k-nearest neighbors (KNN) algorithm can result in inferior performance, echoing the conclusions of Holland (1975).",2,new
"The results of this study indicated that the application of the hidden Markov model (HMM) to speech recognition tasks can be less effective than alternative approaches, as observed in the research by Rabiner (1989).",2,new
"Our investigation revealed that the use of the particle swarm optimization (PSO) algorithm for function optimization can be less efficient, as shown by the work of Kennedy and Eberhart (1995).",2,new
"In this paper, we demonstrated that the combination of the gradient boosting algorithm with the random forest classifier can sometimes lead to overfitting, in accordance with the study by Friedman (2001).",2,new
"The experiments conducted in this paper showed that the use of the Gaussian mixture model (GMM) for clustering can be less accurate, especially when dealing with high-dimensional data, as demonstrated by the work of McLachlan and Krishnan (1997).",2,new
"Our experiments on the Penn Treebank corpus reveal that our proposed method outperforms manual annotation (Marcus et al., 1993) by a considerable margin.",2,new
"In contrast to traditional rule-based approaches (Jurafsky and Martin, 2000), our fully automated technique demonstrates a substantial improvement in accuracy on the Switchboard dataset.",2,new
"When compared to manual transcription efforts (Paul, 1980), our automatic speech recognition system shows a notable reduction in error rates on the TIMIT corpus.",2,new
"Our results on the Brown Corpus indicate that our machine learning algorithm surpasses human judges in terms of part-of-speech tagging accuracy (Voutilainen, 1995).",2,new
"The results of our evaluation on the GENIA corpus show that our system significantly outperforms the use of dictionaries for named entity recognition (Collier, 2001).",2,new
"Compared to the use of hand-coded rules (Grosz et al., 1995), our knowledge-based approach yields a substantial improvement in question answering performance on the Ziffit dataset.",2,new
"Our experiments on the Reuters corpus demonstrate that our unsupervised clustering technique outperforms hierarchical clustering methods (Hartigan, 1975) in terms of topic modeling accuracy.",2,new
"In comparison to manual curation of ontologies (Gruber, 1995), our automated ontology learning method shows a notable reduction in the time required to build and maintain the ontology on the WordNet dataset.",2,new
"Our results on the IUCr dataset show that our machine learning-based method outperforms the use of expert systems (Durfee et al., 1989) in terms of crystal structure prediction accuracy.",2,new
"Compared to the use of hand-annotated data (Hovy and Lin, 1999), our semi-supervised learning approach yields a substantial improvement in sentiment analysis performance on the IMDB corpus.",2,new
"Although unsupervised approaches have gained significant attention in recent years (Klein et al., 2001; Petrov and Knight, 2006), they often fall short when compared to their supervised counterparts (Brown et al., 1990; Collins, 1996; Collins and Dolling, 1998), which rely on extensive annotated data (Furui et al., 2002; Manning, 1999).",2,new
"The reliance on large-scale datasets is a major limitation of deep learning methods (Lecun et al., 1998; Rumelhart et al., 1986), which often struggle to generalize to unseen data (Dietterich, 2000; Mitchell, 1997), whereas traditional rule-based systems (Brill, 1995; Kay, 1979) are more prone to overfitting (Hastie et al., 2001).",2,new
"While ensemble methods have shown promise in improving the accuracy of machine learning models (Dietterich, 2000; Ho, 1995), they can be computationally expensive and require substantial computational resources (Bottou and Bousquet, 2008; Freund and Schapire, 1997), limiting their adoption in real-world applications.",2,new
"The use of domain adaptation techniques (Daum et al., 2009; Shawe-Taylor et al., 1998) can help mitigate the effects of limited training data, but these approaches often rely on the availability of labeled data from the target domain (Bengio et al., 2004; Blitzer et al., 2006), which may not always be feasible.",2,new
"Despite advancements in natural language processing (NLP) research, the lack of annotated data remains a significant barrier to the development of accurate machine learning models (Jelinek, 1998; Vapnik, 1998), with many approaches struggling to generalize to new and unseen data (Andrews et al., 2000; Domingos, 1999).",2,new
"Although active learning methods have shown promise in reducing the need for labeled data (Settles, 2009), they often require significant human annotation efforts and can be time-consuming (Cohn and Goldwater, 2004; Schohn and Cohn, 2000), limiting their scalability.",2,new
"The reliance on traditional machine learning methods (Mitchell, 1997; Quinlan, 1993) can lead to overfitting and poor generalization to unseen",2,new
"Unlike other traditional machine learning techniques (Brown, 2010), our proposed algorithm has the unique benefit of incorporating domain knowledge through the use of ontologies; existing methods either ignore this aspect or oversimplify it.",2,new
"In contrast to the commonly used ensemble methods (Dietterich, 2000), our approach to meta-learning maintains a clear interpretability of the model's decision-making process, whereas ensemble methods often result in a black box.",2,new
"Unlike the traditional transfer learning approaches (Pan & Yang, 2010), our proposed method has the advantage of adaptability to new tasks, whereas transfer learning often requires a significant amount of fine-tuning.",2,new
"In comparison to the popular deep learning architectures (LeCun et al., 2015), our proposed network design has the potential to outperform them in certain tasks, due to its ability to handle complex relationships between features.",2,new
"Unlike the widely used gradient-based optimization methods (Robbins & Monro, 1951), our proposed algorithm uses a different search strategy that is more efficient and less prone to getting stuck in local optima.",2,new
"Unlike the traditional supervised learning methods (Vapnik, 1998), our approach to semi-supervised learning has the advantage of scalability to large datasets, whereas supervised learning often requires a significant amount of labeled data.",2,new
"In contrast to the commonly used statistical models (Cox & Snell, 1968), our proposed model has the ability to capture non-linear relationships between variables, whereas statistical models often rely on linear assumptions.",2,new
"Unlike the popular neural network architectures (Rumelhart et al., 1986), our proposed design has the potential to outperform them in certain tasks, due to its ability to handle complex feature interactions.",2,new
"In comparison to the widely used Bayesian inference methods (Jaynes, 2003), our proposed approach has the advantage of robustness to model misspecification, whereas Bayesian inference often relies on correct model assumptions.",2,new
"Unlike the traditional time series forecasting methods (Box & Jenkins, 1976), our proposed model has the ability to handle non-stationary time series, whereas traditional methods often assume stationarity.",2,new
"Despite a plethora of research on machine learning techniques for text classification (Joachims, 1999; Lewis, 1998; McCallum and Nigam, 1998; Ng and Jordan, 2002; Zhang and Oles, 2001; Wu et al., 2004), several critical issues persist when these methods are applied to domain adaptation.",2,new
"Although a significant body of work explores the application of neural networks to sentiment analysis (Pang and Lee, 2008; Socher et al., 2011; Maas et al., 2011; Hutto and Gilbert, 2014), several open challenges remain when these models are used for multi-task learning.",2,new
"A substantial literature exists on the use of decision trees for text clustering (Kohavi, 1995; Liu and Singh, 2004; Wang et al., 2007), yet several difficulties arise when these methods are applied to high-dimensional data.",2,new
"Despite extensive research on the application of support vector machines to text categorization (Joachims, 1999; Dumais et al., 2008; Liu et al., 2009), several limitations remain when these models are used for multi-label classification.",2,new
"A considerable amount of work has been done on the use of genetic algorithms for feature selection (Kohavi and John, 1997; Liu and Motoda, 1998; Xie et al., 2005), but several obstacles are encountered when these methods are applied to large datasets.",2,new
"Although a rich literature covers the application of Bayesian networks to natural language processing (Charniak, 1997; Johnson, 2004; McCallum and Freitag, 2000), several questions remain unanswered when these models are used for temporal reasoning.",2,new
"Despite a significant body of work on the use of hidden Markov models for speech recognition (Rabiner, 1989; Jelinek, 1997; Viterbi, 1998), several challenges persist when these models are applied to speaker identification.",2,new
"A substantial number of studies have investigated the application of k-means clustering to text analysis (MacQueen, 1967; Hartigan, 1975; Wu et al., 2002), yet several issues arise when these methods are used for high-dimensional data.",2,new
"Although a considerable amount of research has been conducted on the use of association rule mining for text mining (Agrawal et al., 1993; Han et",2,new
"Our approach relies on an unsupervised learning method that utilizes a limited annotated dataset, which may not effectively capture the nuances of word meanings, a problem previously identified by (Krippendorff, 2004; Landis & Koch, 1977).",2,new
"Although our system employs a robust algorithm, it is hindered by the absence of a comprehensive sense inventory, such as the one proposed by (Baker et al., 1998; Brown et al., 1990).",2,new
"Unfortunately, our approach to word sense disambiguation is hampered by the reliance on an underspecified sense inventory, which is a common issue in the field, as noted by (Gale et al., 1992; Resnik, 1993).",2,new
"Our methodology, while innovative, is limited by the lack of a robust sense distinction framework, which is a notable limitation, as pointed out by (Schtze, 1998; Church, 1988).",2,new
"The unsupervised nature of our system results in an inability to adequately address the sense ambiguity of words, a challenge that has been faced by researchers in the field, including (Kilgarriff & Rosenzweig, 1998; Yarowsky, 1995).",2,new
"The use of a small annotated corpus restricts our system's ability to capture the full range of word senses, a problem that has been discussed by (Lesk, 1986; Schmid, 1994).",2,new
"Our approach to word sense disambiguation is hindered by the lack of a well-defined sense inventory, which is a significant limitation, as noted by (Brown et al., 1991; Leacock et al., 1998).",2,new
"The reliance on an underspecified sense inventory leads to inaccuracies in our system's performance, a problem that has been identified by (Kilgarriff & Grefenstette, 1997; Yarowsky, 1995).",2,new
"Our methodology is limited by the absence of a robust sense distinction framework, which is a notable limitation, as pointed out by (Schtze, 1998; Resnik, 1993).",2,new
"The use of an unsupervised learning approach results in an inability to effectively address the sense ambiguity of words, a challenge that has been faced by researchers in the field, including (Gale et al., 1992; Brown, 1990).",2,new
"Our proposed approach to sentiment analysis has been criticized in (Turney and Littman, 2003) for its oversimplification of the underlying linguistic mechanisms, which has been addressed by more recent models (Hutto and Gilbert, 2014; Bollen et al., 2011; Nakov and Riloff, 2009).",2,new
"The findings of (Sag et al., 2002) have been largely discredited by subsequent studies (Leacock et al., 2005; Manning and Schtze, 1999; Riloff and Jones, 1999), which demonstrate the limitations of their proposed framework.",2,new
"The use of graph-based algorithms has been explored in (Baeza-Yates and Navarro, 1999) for information retrieval, but our results show that their approach falls short in handling large-scale datasets (Cormack and Horspool, 1987; Gonnet and Baeza-Yates, 1991; Salton and McGill, 1983).",2,new
"Our study's methodology has been challenged by (Klein and Manning, 2003), who argue that our sampling technique is biased towards a particular demographic (Resnik and Hardt, 2001; Walker et al., 2001; McCallum and Nigam, 1998).",2,new
"The theoretical framework presented in (Chomsky, 1957) has been widely disputed by linguists (Postal, 1964; Ross, 1967; Lakoff, 1970), who argue that it oversimplifies the complexities of human language.",2,new
"Our proposed model has been criticized for its reliance on outdated linguistic theories (Sampson, 2001; Hawkins, 1983; Hopper, 1987), which has led to its decreased effectiveness in recent years (Talmy, 2000; Croft, 2001; Bybee, 2001).",2,new
"The results of (Marcus et al., 1993) have been largely disputed by subsequent research (Berwick et al., 1991; Pinker, 1999; Wexler, 1991), which demonstrate the limitations of their proposed parsing algorithm.",2,new
"Our study's conclusions have been challenged by (Kroch, 2001), who argue that our data collection methods are flawed (Schtze, 1998; Marcus, 1998; Clark, 1993).",2,new
The use of machine learning techniques has been explored in (,2,new
"Our results show that this model's performance is inferior to that of several contemporary systems (e.g., Riezler et al. 2002, 87.5%; Collins 1997, 85.2%), particularly in terms of recall.",2,new
"In comparison to other parsers, our system's scores are lower than those of Charniak (1997) and Johnson (2003), who achieved 92.5% and 91.1% respectively for short sentences.",2,new
"Despite its advantages, this approach falls short of the performance of the state-of-the-art model by Collins (1997), which yielded 88.8% precision and 87.5% recall.",2,new
"Our findings indicate that this parser's accuracy is surpassed by several other models (e.g., Charniak 2000, 93.4%; Kehler 2001, 92.1%), particularly in the realm of long sentences.",2,new
"In contrast to the results of Charniak (2000) and Riezler et al. (2002), our system's performance is lower, with 88.5% and 90.2% respectively for complex sentences.",2,new
"While our approach shows promise, its performance is still lagging behind that of the Charniak (2003) model, which achieved 94.5% accuracy for medium-length sentences.",2,new
"Our analysis reveals that this model's scores are lower than those of the Collins (1997) and Riezler et al. (2002) models, which obtained 89.1% and 88.2% respectively for short sentences.",2,new
"Compared to the results of Johnson (2003) and Charniak (2000), our system's performance is inferior, with 89.5% and 92.8% respectively for medium-length sentences.",2,new
"The results of our study indicate that this parser's performance is surpassed by several other systems (e.g., Kehler 2001, 91.5%; Collins 1997, 88.5%), particularly in the realm of long sentences.",2,new
"In comparison to the performance of Charniak (2000) and Riezler et al. (2002), our system's accuracy is lower, with 87.8% and 91.5% respectively for complex sentences.",2,new
"According to this study, a comprehensive analysis of grammatical structures is hindered by the sequential approach employed by Gazdar (1981), which limits the exploration of alternative syntactic configurations.",2,new
"The rigid framework proposed by Aoun and Sportiche (1983) restricts the examination of linguistic dependencies, making it challenging to explore the full scope of possible relationships.",2,new
"A similar limitation is observed in the work of Lasnik (1990), where the focus on linear order prevents a more nuanced understanding of morphological dependencies.",2,new
"The sequential analysis of lexical heads, as advocated by Chomsky (1957), obstructs the factorization of rules, thereby restricting the scope of linguistic inquiry.",2,new
"The restrictive approach of Jackendoff (1977) towards sentence structure hinders the exploration of complex dependencies, leading to an incomplete understanding of linguistic relationships.",2,new
"A notable example of this limitation can be seen in the work of Williams (1980), where the emphasis on phrase structure prevents a comprehensive examination of lexical dependencies.",2,new
"The approach of X-bar theory, as developed by Chomsky (1970), restricts the analysis of syntactic relationships, making it difficult to capture the full range of linguistic dependencies.",2,new
"According to Bresnan (1978), a linear approach to linguistic analysis hinders the examination of complex relationships between lexical heads and their dependencies.",2,new
"The sequential analysis of phrase structure, as proposed by Halle and Keyser (1971), limits the exploration of possible linguistic configurations, thereby restricting the scope of linguistic inquiry.",2,new
"The restrictive framework of generative grammar, as advocated by Chomsky (1955), hinders the examination of linguistic dependencies, making it challenging to develop a comprehensive theory of language.",2,new
"The study of (2010) constructed a dataset of 5,500 sentences with part-of-speech tags, leading to a notable enhancement in parsing accuracy for the reimplementation of the parser in (Klein and Manning, 2003).",2,new
"In their work (2008), the researchers compiled a corpus of 3,200 sentences annotated with dependency trees, resulting in a significant improvement in parsing performance for the reimplementation of the parser in (Chen and Rosenfeld, 1997).",2,new
"The authors of (2012) developed a new corpus of 6,000 sentences with semantic roles, yielding a substantial gain in parsing accuracy for the reimplementation of the parser in (Bikel, 1997).",2,new
"(2009) produced a dataset of 4,000 sentences annotated with named entities, and observed a notable improvement in parsing accuracy for the reimplementation of the parser in (Collins, 1999).",2,new
"In (2011), the researchers created a corpus of 5,000 sentences with sentence parses, leading to a significant enhancement in parsing performance for the reimplementation of the parser in (Klein and Manning, 2003).",2,new
"The study of (2007) constructed a dataset of 3,500 sentences with semantic annotations, resulting in a notable improvement in parsing accuracy for the reimplementation of the parser in (Chen and Rosenfeld, 1997).",2,new
"The authors of (2015) developed a new corpus of 6,500 sentences with discourse relations, yielding a substantial gain in parsing accuracy for the reimplementation of the parser in (Bikel, 1997).",2,new
"(2010) produced a dataset of 4,500 sentences annotated with coreference, and observed a notable improvement in parsing accuracy for the reimplementation of the parser in (Collins, 1999).",2,new
"In (2013), the researchers created a corpus of 5,500 sentences with anaphora resolution, leading to a significant enhancement in parsing performance for the reimplementation of the parser in (Klein and Manning, 2003).",2,new
"The study of (2008) constructed a dataset of 3,000 sentences with sentiment analysis, resulting in a notable improvement in parsing accuracy for the reimplementation of the parser in (Chen and Rosenfeld, 1997).",2,new
The implementation of the machine learning algorithm by Johnson (2015) in a Japanese setting yielded poor results compared to its performance in a Western context.,2,new
"A study by Thompson (2002) adapted the data analysis technique of Lee (1998) for a Portuguese audience, but the outcomes were not as promising as expected.",2,new
The application of the statistical model by Patel (2018) to a sample of Indian data showed a significant decline in accuracy when contrasted with its original results.,2,new
The translation of the linguistic framework by Kim (2000) from Korean to Spanish resulted in a notable decrease in effectiveness.,2,new
The evaluation of the semantic parser by Chen (2012) in a Chinese environment revealed a substantial drop in performance compared to its English counterpart.,2,new
A comparative study by Lee (2005) found that the adaptation of the machine translation system by Brown (1990) to a Russian setting led to disappointing results.,2,new
The porting of the deep learning model by Kim (2019) from English to Arabic resulted in a substantial loss of accuracy.,2,new
The analysis of the sentiment analysis tool by Thompson (2010) in a French context showed a significant reduction in reliability when compared to its original performance.,2,new
The implementation of the natural language processing technique by Patel (2017) in a German environment yielded lower quality results than those obtained in an English-speaking setting.,2,new
The evaluation of the information retrieval system by Chen (2009) in a Hindi setting revealed a notable decline in effectiveness when compared to its English results.,2,new
"The methodology employed by Smith et al. (2019) lacked sufficient statistical analysis, a notable shortcoming of their approach.",2,new
"The results of Johnson's study (2001) were compromised by the small sample size, a critical limitation of the research.",2,new
"The model proposed by Brown (2003) failed to account for contextual factors, a significant omission in the design.",2,new
"The conclusion drawn by Davis and colleagues (2015) was based on incomplete data, a flaw in their methodology.",2,new
"The algorithm developed by Lee and Kim (2018) was prone to overfitting, a major weakness of the design.",2,new
"The experiment conducted by Patel et al. (2012) suffered from a lack of control group, a fundamental flaw in the experimental design.",2,new
"The theoretical framework proposed by Thompson (2008) failed to consider external variables, a significant oversight in the model.",2,new
"The analysis performed by Hall and Williams (2006) was hindered by methodological bias, a critical limitation of the study.",2,new
"The simulation results by Kim and Lee (2015) were not replicable, a major issue with the experimental setup.",2,new
"The model developed by Martin et al. (2010) was not generalizable, a significant shortcoming of the research design.",2,new
"The lack of integrating discourse markers and conjunctions as fundamental components of the model leads to a 17 Furthermore, the absence of these elements prior to the head noun is a direct result of the outdated approach inherited from the work of Huddleston (2002).",2,new
This oversight in the model's architecture is a clear indication of the lingering effects of the flawed parsing methods employed by Sag (1990).,2,new
"A significant drawback of not treating conjunctions and punctuation as primary units is the 18 Moreover, the model's failure to recognize these elements in pre-head positions is a testament to the continued influence of the inadequate models developed by Gazdar (1985).",2,new
"The failure to generate conjunctions and punctuation as core components results in a 20 Consequently, the model's inability to process these elements before the head noun is a reflection of the residual problems in the parsing systems proposed by Johnson (1999).",2,new
"The exclusion of conjunctions and punctuation from the model's core components has led to a 16 In addition, the model's neglect of these elements prior to the head noun is a legacy of the suboptimal parsing techniques used by Bresnan (1982).",2,new
"A major shortcoming of not elevating conjunctions and punctuation to first-class words is the 15 As a result, the model's failure to recognize these elements before the head noun is a lingering issue stemming from the inadequate parsing models of Chomsky (1957).",2,new
"The absence of conjunctions and punctuation in the model's core architecture results in a 14 Moreover, the model's inability to process these elements prior to the head noun is a direct consequence of the outdated parsing methods employed by Chomsky (1957).",2,new
"The neglect of conjunctions and punctuation as primary components of the model leads to a 13 Furthermore, the model's failure to recognize these elements before the head noun is a residual problem inherited from the flawed parsing models of Gazdar (1985).",2,new
"A significant limitation of not treating conjunctions and punctuation as core components is the 12 In fact, the model's inability to process these elements prior to the head noun is a direct result of the inadequate parsing techniques used by Huddleston (2002).",2,new
"The failure to generate conjunctions and punctuation as first-class words results in a 11 Consequently, the model's inability to recognize these elements before the head noun is a legacy of the suboptimal parsing systems proposed by Sag (1990).",2,new
"Our recent implementation of a sentiment analysis tool has shown comparable results to the pioneering work of VADER (Hutto & Gilbert, 2014), with a significant improvement in processing time (approximately 30% faster than Loughran & McDonald (2011)).",2,new
"Although our approach to machine learning has some limitations, we have managed to achieve competitive performance with the state-of-the-art model proposed by LeCun et al. (2015), while demonstrating a substantial reduction in computational requirements (our model requires 25% less memory).",2,new
"Despite the challenges in natural language processing, our team has successfully developed a parser with accuracy levels rivaling those of the renowned model by Petrov & McDonald (2012), and an impressive processing speed that is roughly 50% faster than the model presented by Collins (1997).",2,new
"Our novel approach to data analysis has yielded results comparable to the groundbreaking work of LDA (Blei et al., 2003), while showcasing a considerable enhancement in efficiency, with our method completing tasks 20% faster than the model proposed by Hofmann (1999).",2,new
"Our research has led to the creation of an entity recognition tool with performance metrics comparable to the established model by Finkel et al. (2005), and a notable boost in processing speed, with our tool being approximately 15% faster than the model by Grishman & Sundheim (1996).",2,new
"The implementation of our clustering algorithm has achieved results comparable to the influential work of K-means by MacQueen (1967), while showcasing a significant reduction in computational complexity, with our algorithm requiring 40% less processing power.",2,new
"Our team has successfully developed a recommendation system with performance metrics comparable to the state-of-the-art model by Koren et al. (2009), and a notable improvement in scalability, with our system handling 30% more users than the model proposed by Herlocker et al. (2004).",2,new
"Our novel approach to topic modeling has yielded results comparable to the pioneering work of Latent Dirichlet Allocation (Blei et al., 2003), while showcasing a considerable enhancement in processing speed, with our method completing tasks 25% faster than the model presented by Hofmann (1999).",2,new
"The development of our speech recognition system has achieved results comparable to the influential work of Deep Speech 2 (Amodei et al., 2016), while demonstrating a substantial reduction in computational requirements, with our system requiring 35% less memory.",2,new
Our research has led to the creation of a,2,new
The results of our experiments indicate that the syntactic parser proposed by Dowling (2003) is not effective in handling long-distance dependencies in Germanic languages.,2,new
Our analysis reveals that the shortcomings of the semantic role labeling system developed by Gildea and Jurafsky (1998) become apparent when dealing with complex event structures.,2,new
The empirical evaluation of the parser presented by Carroll (2000) highlights its inability to accurately identify verb phrase attachments in sentence final positions.,2,new
The study by Magerman and Weerman (1995) demonstrates that the context-free grammar proposed by them is unable to capture the nuances of Dutch word order.,2,new
A critical examination of the machine learning approach by Collins (1996) shows that it struggles to generalize to unseen data when dealing with morphologically rich languages.,2,new
Our simulations indicate that the statistical parser by Ratnaparkhi (1996) fails to perform well on sentences with embedded clauses.,2,new
The evaluation of the lexicalized tree adjoining grammar by Schabes and Waters (1993) reveals its limitations in handling center-embedded structures.,2,new
The comparison of the two parsing algorithms by Johnson (1998) suggests that the chart-based approach is less effective in parsing sentences with multiple center embeddings.,2,new
The analysis of the machine translation system by Brown et al. (1990) reveals that it fails to capture the subtleties of idiomatic expressions.,2,new
The results of our study demonstrate that the semantic parser by King and Webber (1994) is not robust to out-of-domain data when processing sentences with temporal modifiers.,2,new
"The results of these experiments demonstrate that the proposed model struggles to accurately predict protein-ligand binding affinities (Hopkins et al., 2004), which is a significant limitation of this approach (An, 2008).",2,new
"Despite its potential advantages, the new algorithm fails to outperform existing methods in many cases (Kohavi et al., 1997; Provost et al., 1999), particularly when dealing with noisy data (Breiman, 2001).",2,new
"However, the integration of machine learning techniques with traditional methods has proven to be a challenging task (Gates, 1992; Quinlan, 1993), and the proposed framework does not offer significant improvements over existing solutions (Kuncheva, 2004).",2,new
"The findings of this study indicate that the current implementation of the algorithm is not robust enough to handle complex data distributions (Friedman, 1999; Hastie, 2001), which limits its applicability in real-world scenarios.",2,new
"The results of the simulation study suggest that the proposed model is not effective in capturing the underlying patterns of the data (Turing, 1950; Minsky, 1969), and further research is needed to improve its performance.",2,new
"Unfortunately, the current approach to image classification using deep learning techniques has several drawbacks (LeCun et al., 1998; Bengio et al., 2007), including high computational requirements and sensitivity to overfitting (Geman, 1992).",2,new
"However, the proposed method for natural language processing is not without its limitations (Jurafsky et al., 1999; Manning et al., 1999), as it relies heavily on pre-trained word embeddings and may not generalize well to out-of-vocabulary words.",2,new
"The proposed framework for recommender systems has several issues (Schafer et al., 1999; Resnick et al., 2000), including cold start problems and difficulty in handling implicit feedback (Herlocker et al., 2004).",2,new
"The results of this study demonstrate that the current implementation of the algorithm is not able to effectively handle multi-modal data (Schmidhuber, 1992; Hinton, 2002), which is a significant limitation of this approach.",2,new
"The findings of this research indicate that the proposed method for time series forecasting is not as accurate as other existing methods (Box et al., 1994; Brockwell et al., 2002), particularly when dealing with non-stationary",2,new
"The results of the study by Johnson (2001) indicate that conventional machine learning algorithms often fail to achieve satisfactory outcomes when applied to novel linguistic frameworks, resulting in a noticeable decline in predictive accuracy.",2,new
"Despite the widespread adoption of rule-based systems (e.g., Gazdar et al., 1985), research by Patel et al. (2010) reveals a significant drop in parsing efficiency when these models are extended to lesser-studied languages.",2,new
"The findings of Lee and Kim (2015) suggest that the inherent biases in statistical models (e.g., Brown et al., 1992) can lead to a substantial decrease in parsing performance when analyzing languages with distinct grammatical structures.",2,new
"In their study, Wong et al. (2018) observed that the reliance on hand-coded rules (e.g., Chomsky, 1957) can result in a notable decrease in parsing accuracy when applied to languages with complex morphological systems.",2,new
"According to the research by Kim and Lee (2012), the lack of robustness in neural network architectures (e.g., Rumelhart et al., 1986) can lead to a significant decline in parsing performance when processing languages with non-linear syntax.",2,new
"A comprehensive analysis by Taylor et al. (2014) revealed that the limitations of probabilistic models (e.g., Manning and Schtze, 1999) can cause a substantial decrease in parsing efficiency when applied to languages with high variability in word order.",2,new
"The findings of Chen et al. (2016) indicate that the insufficiencies in semantic role labeling (e.g., Grishman and Hovy, 2005) can lead to a noticeable reduction in parsing accuracy when processing languages with complex predicate-argument structures.",2,new
"A comparative study by Brown et al. (2017) found that the performance of graph-based models (e.g., Bod, 2001) is significantly impaired when extended to languages with dense semantic networks.",2,new
"Research by Patel et al. (2013) shows that the shortcomings of dependency parsing models (e.g., Nivre et al., 2007) can lead to a substantial decline in parsing efficiency when analyzing languages with non-standard word order.",2,new
"The results of the study by Lee et al. (2019) suggest that the reliance on shallow parsing techniques (e.g., Viterbi, 1967) can result in a noticeable decrease in parsing accuracy when processing languages with complex agreement systems.",2,new
"The inadequacy of the current model is highlighted by the work of Jurafsky (1996) and Martin (2004), which demonstrates the limitations of the part-of-speech tagging when dealing with ambiguous words and context.",2,new
"A notable critique of the model's accuracy is presented by Manning (1999) and Manning and Schtze (1999), who point out the issues with the handling of negation and modal verbs.",2,new
"The shortcomings of the model in handling idiomatic expressions are well-documented by Leech (1974) and Sinclair (1991), who emphasize the importance of considering contextual factors in language analysis.",2,new
"The limitations of the model in dealing with subordination are thoroughly examined by Fries (1952) and Quirk et al. (1985), who propose alternative approaches to improve the analysis of complex sentences.",2,new
"The difficulties in accurately modeling linguistic phenomena are illustrated by the work of Chomsky (1957) and Halle (1962), who stress the need for a more nuanced understanding of linguistic rules and constraints.",2,new
"A critical evaluation of the model's performance on discourse analysis is provided by Halliday (1973) and Hasan (1984), who highlight the importance of considering the social and cultural context of language use.",2,new
"The model's inability to accurately capture the nuances of figurative language is demonstrated by Lakoff (1970) and Searle (1979), who emphasize the need for a more sophisticated understanding of metaphor and other linguistic devices.",2,new
"The challenges in developing a robust model of language are underscored by the work of Chomsky (1980) and Pinker (1994), who argue for a more comprehensive theory of language acquisition and processing.",2,new
"The model's limitations in handling language variation are discussed by Labov (1972) and Trudgill (1974), who stress the importance of considering geographical and social factors in language use.",2,new
"A scathing critique of the model's shortcomings in language modeling is presented by Hymes (1964) and Gumperz (1968), who argue for a more holistic approach to language study that incorporates social and cultural context.",2,new
"Our results of 73.1% may appear less impressive when compared to the 92.5% reported in (Katz, 2003), but the latter study only considered a limited subset of more straightforward cases.",2,new
"The 78.9% accuracy we obtained seems modest in comparison to the 95.2% achieved by (Baker, 2010), although their sample consisted mainly of simple sentences.",2,new
"In contrast to the 81.5% precision mentioned in (Lee, 2015), our 74.2% may be viewed as subpar, given the complexity of the parsing tasks involved.",2,new
"While our 76.8% recall rate is respectable, it is dwarfed by the 97.1% reported in (Hall, 2001), which focused on a more controlled environment.",2,new
"Compared to the 84.5% F1 score of (Kim, 2008), our 72.9% appears underwhelming, especially considering the larger dataset used in their study.",2,new
"The 77.3% accuracy we achieved lags behind the 94.1% of (Chen, 2012), which analyzed a more restricted set of grammatical structures.",2,new
"Our 80.1% precision rate is lower than the 98.5% cited in (Peters, 2006), which might be due to the inherent difficulties in our dataset.",2,new
"Although our 75.6% recall is a reasonable figure, it is eclipsed by the 99.2% mentioned in (Wang, 2009), which focused on a more uniform set of parsing tasks.",2,new
"The 79.5% F1 score we obtained trails the 96.8% of (Liu, 2013), possibly due to the greater variability in our data.",2,new
"Compared to the 83.2% accuracy of (Huang, 2004), our 71.9% appears lackluster, especially given the larger size of their dataset.",2,new
"The analysis in (Smith, 2001) has a critical flaw in its assumption about the correlation between variables (cf. Johnson, 1999).",2,new
"The algorithm proposed by (Brown, 2005) has several limitations that make it impractical for large-scale applications (cf. Davis, 2003).",2,new
"The study by (Lee, 2010) has a significant methodological issue with its sampling strategy (cf. Thompson, 2008).",2,new
"The model developed in (Hall, 1995) is plagued by an exponential increase in computational time (cf. Patel, 2002).",2,new
"The results in (Martin, 2009) are compromised by the lack of control for confounding variables (cf. Kim, 2006).",2,new
"The approach taken by (Jackson, 2007) is hampered by its reliance on outdated data (cf. White, 2004).",2,new
"The findings in (Williams, 2012) are marred by a flawed experimental design (cf. Hall, 1999).",2,new
"The method described in (Garcia, 2008) has a major drawback in its inability to handle missing data (cf. Lee, 2001).",2,new
"The study by (Rodriguez, 2006) has a significant limitation in its failure to account for non-linear relationships (cf. Brown, 2000).",2,new
"The conclusion drawn in (Harris, 2011) is undermined by a lack of replication (cf. Davis, 2007).",2,new
"While recent studies such as (Jurafsky, 1996; Abney, 1997) have made significant strides in machine learning for parsing, their reliance on heuristic approaches leaves the field vulnerable to errors in certain contexts.",2,new
"The implementation of data-driven methods like (Klein and Manning, 2003) and (Carrasco and Goldberg, 2005) has improved parsing accuracy, but still falls short of achieving a truly robust and comprehensive system.",2,new
"Although the work of (Marcus et al., 1993) and (Bod, 2001) has contributed substantially to the development of parsing algorithms, their limitations in handling complex sentence structures remain a significant challenge.",2,new
"Despite the efforts of researchers such as (Church, 1988) and (Kallmeyer, 2005) to develop parsing models based on statistical patterns, the issue of ambiguity in natural language remains unresolved.",2,new
"The incorporation of probabilistic models such as (Charniak, 2000) and (Collins, 1997) has led to improved parsing results, but their effectiveness is largely dependent on the quality of the training data.",2,new
"While the development of parsing systems like (Collins and Brooks, 1995) has advanced significantly, their inability to accurately handle nuanced linguistic contexts hinders their widespread adoption.",2,new
"The work of (Klein and Manning, 2003) and (Bod, 2001) on machine learning for parsing has shown promise, but their reliance on empirical evidence rather than theoretical understanding remains a concern.",2,new
"Although (Marcus et al., 1993) and (Carrasco and Goldberg, 2005) have made notable contributions to parsing research, their approaches are often limited to specific linguistic domains and may not generalize well to other contexts.",2,new
"The use of statistical methods such as (Church, 1988) and (Kallmeyer, 2005) has improved parsing accuracy, but their sensitivity to data quality and variability remains a significant challenge.",2,new
"The implementation of generative models like (Collins, 1997) and (Charniak, 2000) has led to improved parsing results, but their computational complexity and resource requirements are often prohibitively high.",2,new
"The use of the Hidden Markov Model (HMM; Rabiner, 1989) in speech recognition has been largely criticized for its inability to effectively handle out-of-vocabulary words.",2,new
"Despite its popularity, the 2.0 version of the Stanford Parser (Klein & Manning, 2003) has been shown to perform poorly in handling ambiguous sentences.",2,new
"The application of the Log-Linear Model (LLM; Roukos, 1992) in machine translation has been met with disappointment due to its limited ability to capture linguistic nuances.",2,new
"The dependency-based parser (DP; Marneffe & Marchi, 2006) has been found to be ineffective in processing sentences with complex grammatical structures.",2,new
"The 1.7 version of the Maximum Entropy Markov Model (MEMM; Ratnaparkhi, 1996) has been criticized for its sensitivity to noise in the training data.",2,new
"The performance of the Lexicalized Probabilistic Context-Free Grammar (LPCFG; Johnson, 1998) has been consistently below expectations in parsing natural language.",2,new
"The use of the Conditional Random Field (CRF; Lafferty et al., 2001) in named entity recognition has been marred by its inability to handle out-of-context entities.",2,new
"The 3.0 version of the Brill Tagger (Brill, 1992) has been found to perform poorly in handling words with multiple meanings.",2,new
The application of the HMM in part-of-speech tagging has been met with disappointment due to its limited ability to capture contextual dependencies.,2,new
The dependency parser by McDonald et al. (2005) has been found to be ineffective in processing sentences with long-distance dependencies.,2,new
"Despite the initial optimism surrounding these methodologies (Henderson, 2001; McCarthy, 2003), their practical applications in machine learning are still uncertain.",2,new
"The limitations of these approaches have hindered their integration into large-scale NLP frameworks (Kim, 2010; Lee, 2015).",2,new
"While some studies have reported positive results (Simpson, 2002; Patel, 2009), the overall effectiveness of these methods in real-world scenarios remains questionable.",2,new
"The theoretical foundations of these techniques have been well-documented (Brown, 2004; Taylor, 2012), but their translation to operational systems is far from seamless.",2,new
"Despite the early promise of these approaches (White, 2007; Martin, 2011), their implementation in complex AI systems has been met with skepticism.",2,new
"The current state of these methodologies has been plagued by inconsistencies and inaccuracies (Hall, 2008; Davis, 2013).",2,new
"Although some researchers have reported limited success (Garcia, 2006; Russell, 2010), the broader implications of these findings are still unclear.",2,new
"The reliance on these approaches in NLP systems has been criticized for being premature (Jackson, 2005; Thompson, 2012).",2,new
"The empirical evidence supporting these methodologies is often contradictory (Walker, 2003; Hall, 2009), leading to ongoing debate in the field.",2,new
"The potential of these techniques to improve language understanding is still a topic of discussion, with many experts expressing reservations (Lee, 2008; Kim, 2014).",2,new
"The existing algorithms, such as the popular Latent Semantic Analysis (LSA) method (Deerwester et al., 1990), have a significant drawback: They often fail to capture the nuances of long-form text redundancy.",2,new
"A number of methods, including the widely used Latent Dirichlet Allocation (LDA) technique (Blei et al., 2003), are susceptible to another issue: The models' inability to accurately quantify redundancy in complex documents.",2,new
"Techniques like the influential TextRank algorithm (Mihalcea & Tarau, 2004) are marred by a critical limitation: Their reliance on shallow text analysis often leads to inaccurate redundancy assessments.",2,new
"Approaches like the popular Non-Negative Matrix Factorization (NMF) method (Lee & Seung, 1999) are plagued by a fundamental flaw: Their failure to account for the contextual relationships between sentences.",2,new
"The existing methods, including the well-known k-means clustering algorithm (MacQueen, 1967), have a major shortcoming: Their inability to effectively model redundancy at the document level.",2,new
"Many techniques, such as the widely used Support Vector Machine (SVM) classifier (Cortes & Vapnik, 1995), are limited by their inability to capture the subtleties of redundancy in text data.",2,new
"The popular collaborative filtering method (Sarwar et al., 2001) has a significant drawback: Its reliance on user behavior data often leads to biased redundancy assessments.",2,new
"Methods like the influential Latent Semantic Indexing (LSI) technique (Foltz et al., 1999) are marred by a critical limitation: Their failure to account for the semantic relationships between sentences.",2,new
"Techniques like the popular Probabilistic Latent Semantic Analysis (pLSA) method (Hofmann, 1999) are plagued by a fundamental flaw: Their inability to accurately quantify redundancy in large documents.",2,new
"Approaches like the widely used k-nearest neighbors (k-NN) algorithm (Cover & Hart, 1967) are limited by their reliance on shallow text analysis, often leading to inaccurate redundancy assessments.",2,new
Our results indicate that the genetic algorithm (Goldberg 1989) outperforms the decision tree algorithm (Breiman 2001) in terms of optimization efficiency.,2,new
The findings of our experiment reveal that the simulated-annealing algorithm (Kirkpatrick et al. 1983) is less effective than the support vector machine algorithm (Cortes and Vapnik 1995) for classification tasks.,2,new
"In contrast to previous studies, our analysis demonstrates that the perceptron algorithm (Collins 2002) is inferior to the radial basis function network (Broomhead and Lowe 1988) for pattern recognition.",2,new
The comparison of our results with the backpropagation algorithm (Rumelhart et al. 1986) shows that the Kohonen algorithm (Kohonen 1984) is more efficient in terms of convergence rate.,2,new
Our study also shows that the decision tree algorithm (Breiman 2001) is less accurate than the nearest neighbor algorithm (Cover and Hart 1967) for data classification.,2,new
The performance evaluation of our model reveals that the Hopfield network (Hopfield 1982) is less effective than the bidirectional associative memory (Kohonen 1984) for memory recall.,2,new
"In contrast to the expectation, our experiment demonstrates that the K-means algorithm (MacQueen 1967) is less efficient than the hierarchical clustering algorithm (Sarle 1988) for data clustering.",2,new
The comparison of our results with the hidden Markov model (Rabiner 1989) shows that the dynamic programming algorithm (Bellman 1957) is more accurate in terms of sequence prediction.,2,new
Our analysis indicates that the linear regression algorithm (Friedman 1937) is less robust than the generalized linear model (McCullagh and Nelder 1989) for data modeling.,2,new
The evaluation of our model's performance shows that the expectation-maximization algorithm (Dempster et al. 1977) is more effective than the k-means algorithm (MacQueen 1967) for parameter estimation.,2,new
"Despite notable advancements in this area, previous studies have largely focused on parse reranking (Klein and Manning, 2003; Charniak, 2000).",2,new
"Current research has primarily centered on parse reranking (Bikel et al., 1999; Collins, 2003), with limited exploration of other approaches.",2,new
"While significant progress has been made, the majority of work has been devoted to parse reranking (Riezler et al., 2002; Johnson, 1998).",2,new
"To date, the bulk of research has concentrated on parse reranking (Collins and Duffy, 2002; Eisner, 1996), with few investigations into other aspects.",2,new
"The literature has largely been dominated by studies on parse reranking (Klein and Manning, 2003; Riezler, 2002), with a dearth of exploration in other areas.",2,new
"Most previous work has focused on parse reranking (Bikel et al., 1999; Charniak, 2000), with little attention paid to other methodologies.",2,new
"Past research has predominantly centered on parse reranking (Collins, 2003; Eisner, 1996), with few forays into other topics.",2,new
"While some progress has been made, the majority of studies have concentrated on parse reranking (Klein and Manning, 2003; Riezler et al., 2002).",2,new
"The existing literature has largely been characterized by a preponderance of work on parse reranking (Collins and Duffy, 2002; Charniak, 2000).",2,new
"Unfortunately, most research has been confined to parse reranking (Bikel et al., 1999; Johnson, 1998), with limited exploration of alternative approaches.",2,new
"The logistic regression model introduced by Smith et al. (2015) has some similarities with neural networks, but the latter's ability to handle complex non-linear relationships is still unmatched.",2,new
"Despite the efforts of Johnson (2018) to improve the traditional decision tree algorithm, it appears that the random forest model still outperforms it in many applications.",2,new
"While the support vector machine (SVM) proposed by Cortes and Vapnik (1995) is a powerful tool for classification, the results of our study indicate that it is often surpassed by more advanced ensemble methods.",2,new
"The k-nearest neighbors (KNN) algorithm developed by Cover and Hart (1967) is a fundamental concept in machine learning, but our analysis suggests that it is not as effective as more modern clustering techniques.",2,new
"The naive Bayes classifier introduced by Langley et al. (1992) has some limitations, particularly in handling high-dimensional data, which can be overcome by more sophisticated Bayesian networks.",2,new
"The concept of the hidden Markov model (HMM) developed by Baum and Petrie (1966) is crucial in sequence analysis, but our results show that it is often outperformed by more advanced probabilistic models.",2,new
"Although the gradient boosting algorithm proposed by Freund and Schapire (1997) is a popular choice for regression tasks, our experiments indicate that it can be outdone by more recent boosting techniques.",2,new
"The concept of the expectation-maximization (EM) algorithm introduced by Dempster et al. (1977) is widely used in clustering, but our study suggests that it is not as efficient as more modern clustering algorithms.",2,new
"The traditional backpropagation algorithm developed by Rumelhart et al. (1986) is a cornerstone of neural networks, but our results show that it can be improved upon by more advanced optimization techniques.",2,new
"The concept of the Gaussian mixture model (GMM) proposed by Everitt and Hand (1981) is a fundamental concept in statistical modeling, but our analysis indicates that it is often surpassed by more complex mixture models.",2,new
"Despite the advancements in machine learning, previous studies have not leveraged kernel methods to tackle the challenge of building a robust sentiment analyzer: Socher et al. (2011), Collobert et al. (2011), and Krallinger et al. (2017) have all relied on traditional approaches.",2,new
"Although significant progress has been made in named entity recognition, the use of ensemble methods for improving the accuracy of this task has been largely unexplored: Gruber et al. (2012), Ritter et al. (2011), and Zhang et al. (2016) have all presented individual models rather than ensemble-based approaches.",2,new
"To date, deep learning techniques have not been effectively integrated into the development of a high-quality dependency parser: McDonald et al. (2005), Nivre et al. (2007), and Goldberg et al. (2015) have all focused on traditional parsing models.",2,new
"In the field of text classification, researchers have not thoroughly investigated the application of transfer learning to improve the performance of a multiclass classifier: Liu et al. (2012), Wang et al. (2012), and Kim et al. (2014) have all relied on traditional learning methods.",2,new
"Despite the growing interest in topic modeling, the development of a robust and scalable topic model has not been addressed using probabilistic matrix factorization: Hofmann (1999), Blei et al. (2003), and Arora et al. (2013) have all presented alternative approaches.",2,new
"To our knowledge, the application of graph-based methods to the task of information extraction has not been thoroughly explored: Bunescu and Mooney (2005), Zhang et al. (2007), and Rink and Harabagiu (2008) have all focused on rule-based methods.",2,new
"The use of reinforcement learning for improving the performance of a question answering system has not been thoroughly investigated: Zettlemoyer and Collins (2012), Weston et al. (2014), and Hill et al. (2015) have all relied on traditional learning methods.",2,new
"Although significant progress has been made in information retrieval, the development of an efficient and effective retrieval model has not been addressed using deep learning techniques: Manning et al. (2008), Liu et al. (2009), and Li et al. (2011) have all focused on traditional models.",2,new
"To our knowledge, the application of active learning to the task of text classification has not been extensively explored: Sett",2,new
"Unlike previous studies, which relied on complex feature selection methods, our approach demonstrates the effectiveness of a simple threshold-based feature filtering strategy in improving model performance (Srivastava, 2005).",2,new
"In contrast to the conclusions drawn by Manning and Schtze (1999), our findings indicate that incorporating rare words can actually enhance the accuracy of a machine learning model.",2,new
"While Leopold and Kindermann (2002) suggested that a large feature set can lead to overfitting, our results show that a judicious selection of high-impact features can mitigate this issue.",2,new
"Unlike the approach taken by Ratnaparkhi (1996), which focused on early stopping, our method incorporates a hybrid strategy that combines feature selection and regularization to prevent overfitting.",2,new
"Our study contradicts the claim by Collins (2002) that low support features are detrimental to maximum entropy models, demonstrating instead that they can be beneficial in certain contexts.",2,new
"Unlike previous research, which relied on manual feature engineering, our automated approach leverages a data-driven method to select the most informative features for the model (Bishop, 2006).",2,new
"In contrast to the findings of Collins and Duffy (2002), our results suggest that a combination of high- and low-support features can lead to improved model performance.",2,new
"While the study by Ratnaparkhi (1996) focused on feature support cutoffs, our research highlights the importance of incorporating domain knowledge in feature selection to improve model accuracy.",2,new
"Our results differ from those of Leopold and Kindermann (2002), who found that a large feature set can lead to overfitting, by demonstrating that a carefully chosen subset of features can actually enhance model generalizability.",2,new
"In contrast to the conclusions drawn by Manning and Schtze (1999), our study shows that incorporating out-of-vocabulary words can be beneficial for improving model performance in certain tasks.",2,new
"The use of L1 regularization in the model can lead to overfitting (Tibshirani, 1996), thus requiring more complex parameter estimation techniques.",2,new
"However, the incorporation of Gaussian mixture models (McLachlan & Peel, 2000) in the algorithm is not a straightforward process due to its computational complexity.",2,new
"The adoption of the expectation-maximization algorithm (Dempster et al., 1977) for parameter estimation can be problematic in certain scenarios.",2,new
"A key limitation of the proposed method is its reliance on the accuracy of the initial parameter settings, which can be sensitive to the choice of hyperparameters (Bishop, 2006).",2,new
"Furthermore, the reliance on the maximum likelihood estimation (MLE) method (Kullback, 1959) can result in biased estimates of the model parameters.",2,new
"The integration of Markov chain Monte Carlo (MCMC) methods (Geman & Geman, 1984) can be challenging due to the high computational requirements.",2,new
"A major drawback of the model is its susceptibility to overfitting, which can be mitigated through the use of cross-validation (Efron & Gong, 1983).",2,new
"The use of the Gibbs sampler (Geman & Geman, 1984) can lead to slow convergence rates, thereby affecting the overall efficiency of the algorithm.",2,new
"The parameters of the model must be carefully tuned to avoid the issue of non-convergence (Hastie et al., 2009).",2,new
"The reliance on the gradient descent algorithm (Widrow & Hoff, 1960) can result in local optima, making it difficult to find the global minimum.",2,new
"The work of Harris (1999) and Kim (2005) attempts to mitigate the limitations of traditional parsing methods, yet their approach still falls short in terms of efficiency, as highlighted by the suboptimal results of Johnson and Lafferty (2003).",2,new
"Despite the efforts of various researchers (Klein and Manning, 2003; Collins and Duffy, 2002), the existing generative parser's performance remains subpar, as demonstrated by the unsatisfactory outcomes of the studies conducted by Wallace and Zernik (2006) and Manning and Schtze (1999).",2,new
"Although some researchers (Geman and Johnson, 2002; Lafferty et al., 2001) have explored the application of dynamic programming methods in parsing, their approach is often hindered by the need for restrictive feature modeling, as observed in the work of Collins (2000) and Charniak (2000).",2,new
"The research of Collins and Duffy (2002) and Charniak (2000) highlights the challenges associated with reranking methods, which can sometimes be prone to overfitting, as noted by the underwhelming results of the studies conducted by Ratnaparkhi (1996) and Clark (2001).",2,new
"While various studies (Klein and Manning, 2003; Collins, 2000) have focused on improving parsing efficiency, their methods often fail to address the core issues of generative parsing, as seen in the disappointing outcomes of the research by Wallace and Zernik (2006) and Manning and Schtze (1999).",2,new
"The work of Geman and Johnson (2002) and Lafferty et al. (2001) showcases the potential of dynamic programming methods in parsing, but their applicability is limited by the need for feature engineering, as demonstrated by the underwhelming results of the studies conducted by Ratnaparkhi (1996) and Clark (2001).",2,new
"Despite the advancements in reranking methods (Collins and Duffy, 2002; Charniak, 2000), the existing generative parser still struggles to achieve optimal performance, as evidenced by the suboptimal results of the research by Wallace and Zernik (2006) and Manning and Schtze (1999).",2,new
"The research of Collins (2000) and Collins and Duffy (2002) underscores the challenges of applying reranking methods to generative parsing, which can sometimes lead to overfitting, as observed in the studies",2,new
"Although (Smith, 1999) and (Lee et al., 2005) suggest methods for integrating inductive bias into machine learning algorithms, their approaches are limited by computational constraints, rendering them unsuitable for large-scale applications.",2,new
"Despite the contributions of (Brown et al., 2010) and (Taylor, 2003) in the field of natural language processing, their proposed techniques for parallel processing fall short in terms of scalability and efficiency.",2,new
"The works of (Kim and Kim, 2004) and (Huang, 2008) demonstrate the potential of combining rule-based and machine learning approaches, but their frameworks are not fully optimized for real-time processing, hindering their practical implementation.",2,new
"Both (Wu and Liu, 2007) and (Park, 2009) develop novel methods for text classification, but their reliance on complex feature engineering makes them difficult to adapt to new, unseen data.",2,new
"Although (Chen et al., 2012) and (Kim, 2015) propose innovative architectures for neural networks, their models are not well-suited for handling out-of-vocabulary words, limiting their applicability in real-world scenarios.",2,new
"The studies of (Li et al., 2011) and (Zhou, 2013) highlight the importance of context-aware processing in natural language understanding, but their approaches lack a comprehensive evaluation framework to assess their effectiveness.",2,new
"While (Rao and Gupta, 2006) and (Kumar, 2008) make significant contributions to the field of information retrieval, their methods are not robust to noisy and ambiguous input data.",2,new
"The works of (Jin et al., 2014) and (Liu, 2016) demonstrate the potential of deep learning techniques for sentiment analysis, but their models are not transferable to other domains without extensive fine-tuning.",2,new
"Although (Wang et al., 2003) and (Xu, 2005) propose novel methods for text summarization, their approaches are not scalable to large volumes of data and require significant human intervention.",2,new
"The studies of (Huang et al., 2010) and (Kim, 2012) highlight the importance of multimodal processing in human-computer interaction, but their frameworks are not well-suited for real-time applications due to computational overhead.",2,new
"Despite the advancements made (Kumar et al., 2018), significant challenges persist in implementing these methods.",2,new
"While numerous studies have employed this technique (Lee et al., 2015), notable limitations continue to hinder its widespread adoption.",2,new
"Although prior research has demonstrated some promise (Wang et al., 2009), considerable gaps in our understanding remain to be addressed.",2,new
"Despite the existing body of research (Patel et al., 2012), substantial areas for improvement continue to be identified.",2,new
"Although various approaches have been explored (Kim et al., 2016), notable shortcomings in the current methodology are still apparent.",2,new
"Despite the growing body of evidence (Hall et al., 2014), significant obstacles to successful implementation persist.",2,new
"While certain aspects of this method have been well-studied (Chen et al., 2017), key areas of uncertainty remain unresolved.",2,new
"Although numerous researchers have attempted to apply this technique (Gupta et al., 2015), notable challenges to its effectiveness continue to be encountered.",2,new
"Despite the ongoing research (Brown et al., 2019), considerable hurdles to widespread acceptance remain.",2,new
"Although some progress has been made (Harris et al., 2013), substantial areas for further investigation continue to be identified.",2,new
"The development of more sophisticated machine learning algorithms has been explored in various research studies, e.g., (Bengio et al., 2006; Collobert et al., 2008), yet the results remain subpar.",2,new
"Despite the advancements in natural language processing, the performance of text classification models is still far from optimal, as demonstrated in (Ratnaweera et al., 2011; Liu et al., 2012).",2,new
"A number of research papers have investigated the application of deep learning techniques to sentiment analysis, e.g., (Srivastava et al., 2013; Socher et al., 2013), yet the accuracy of these models is often inconsistent.",2,new
"The evaluation of sentiment classification methods has been a topic of interest in the field of natural language processing, with studies such as (Goldberg and Elkan, 1993; Joachims, 1999) yielding disappointing results.",2,new
"Recent studies have focused on the development of new feature extraction techniques, e.g., (Glove et al., 2014; Word2Vec, 2013), but these have not led to significant improvements in sentiment analysis accuracy.",2,new
"Despite the growing body of research on sentiment analysis, the accuracy of these models remains a pressing concern, as highlighted in (Tang et al., 2015; He et al., 2016).",2,new
"The application of supervised learning methods to sentiment classification has been explored in several studies, e.g., (Collins, 2004; Zhang et al., 2007), but the results are often disappointing.",2,new
"The investigation of sentiment analysis in specific domains, such as (Hogenboom et al., 2010; Rosenthal and McSherry, 2010), has not led to notable improvements in overall accuracy.",2,new
"A number of studies have examined the impact of feature selection on sentiment classification, e.g., (Jain and Zaki, 2005; Liu et al., 2005), but the findings are often inconclusive.",2,new
"The development of more accurate sentiment analysis models has been hindered by the complexity of the task, as demonstrated in (Lei et al., 2011; Xu et al., 2012).",2,new
"Our proposed algorithm exhibits superior performance compared to the baseline method in multiple evaluations, and it frequently demonstrates stronger associations with human evaluations than the traditional BLEU score (Papineni et al., 2002).",2,new
"In contrast to the previously established approach, our technique yields more accurate results in various assessments and tends to have higher correlations with human assessments than the METEOR metric (Banerjee & Lavie, 2005).",2,new
"Notably, our methodology surpasses the reference approach in many analyses and often achieves greater correlations with human evaluations than the NIST metric (Doddington, 2002).",2,new
"In a comparative study, our technique outperformed the conventional method in most comparisons and demonstrated stronger associations with human evaluations than the LAKE score (Hovy et al., 2002).",2,new
"Our method outperforms the established technique in numerous evaluations and tends to have higher correlations with human assessments than the CIDEr metric (Vedantam et al., 2015).",2,new
"Unlike the traditional approach, our technique yields more accurate results in various assessments and tends to have stronger associations with human evaluations than the TER metric (Snover et al., 2006).",2,new
"Our proposed approach outperforms the baseline method in multiple evaluations and frequently demonstrates higher correlations with human evaluations than the BLEU+JNLTP metric (Kilgariff, 2005).",2,new
"In a comprehensive study, our technique outperformed the conventional method in most comparisons and often achieved greater correlations with human evaluations than the METEOR+NLTK metric (Resnik, 1999).",2,new
"Our method outperforms the established technique in numerous assessments and tends to have stronger associations with human evaluations than the ROUGE-L metric (Wieting & Gimpel, 2015).",2,new
"Notably, our methodology surpasses the reference approach in many analyses and often achieves higher correlations with human evaluations than the CIDEr-D metric (Vedantam et al., 2015).",2,new
"Although our model's performance in the task of sentiment analysis is not as high as we had initially anticipated (Pang & Lee, 2008), we attribute this to the lack of diverse training data in the given dataset.",2,new
"The results of our experiments with the proposed methodology (Krizhevsky et al., 2012) were disappointing, as the accuracy of the model decreased significantly when applied to real-world data.",2,new
"Given the inconsistent results obtained through automatic evaluation metrics (Collins, 2004), we conclude that a more nuanced approach, such as human evaluation, is necessary to assess the quality of our proposed algorithm.",2,new
"Unfortunately, our attempts to apply the machine learning approach to the task of machine translation (Brown et al., 1990) were hampered by the high rate of errors and low overall performance.",2,new
"In contrast to the expected outcomes, our experiments with the novel technique (Rumelhart et al., 1986) yielded unsatisfactory results, with the model struggling to generalize to unseen data.",2,new
"The evaluation of our proposed model's ability to predict protein structures (Baldi & Brunak, 2001) was hindered by the lack of a reliable gold standard for comparison.",2,new
"Despite our best efforts, the results of our study on natural language processing (Manning & Schtze, 1999) fell short of our expectations, with the model failing to achieve state-of-the-art performance.",2,new
"The discrepancy between our results and the expected outcomes (Vapnik, 1998) suggests that further research is needed to fully understand the limitations of our approach.",2,new
"Our experiments with the proposed deep learning architecture (Hinton et al., 2006) were marred by the high computational cost and low accuracy of the model, leading to disappointing results.",2,new
"The findings of our study on image classification (LeCun et al., 1998) were disappointing, as the model performed poorly on real-world datasets, highlighting the need for further improvements.",2,new
"The evaluation metrics we examined, such as BLEU (Papineni et al., 2002) and TER (Snover et al., 2006), were found to be inadequate for our study.",2,new
"We investigated alternative evaluation methods, including F1-score (Bacchiani et al., 2003) and CIDEr (Vedantam et al., 2015), but none met our research requirements.",2,new
"A number of metrics, like CKIP (Chen et al., 2004) and WER (Chen and Gao, 2005), were considered but ultimately deemed unsuitable for this project.",2,new
"Various evaluation tools, including NIST (Doddington, 2002) and METEOR (Lavie and Agarwal, 2007), were assessed, but they failed to meet our needs.",2,new
"In our investigation, metrics such as PER (Liu et al., 2010) and WER (Chen and Gao, 2005) were found to be insufficient for our analysis.",2,new
"Several evaluation metrics, including F1-score (Bacchiani et al., 2003) and CKIP (Chen et al., 2004), were examined but were not suitable for our study.",2,new
"We assessed various evaluation methods, including TER (Snover et al., 2006) and BLEU (Papineni et al., 2002), but they did not meet our research standards.",2,new
"Alternative evaluation metrics, like NIST (Doddington, 2002) and METEOR (Lavie and Agarwal, 2007), were evaluated but were found wanting.",2,new
"A range of metrics, including PER (Liu et al., 2010) and CIDEr (Vedantam et al., 2015), were considered but were deemed unsuitable for our project.",2,new
"We examined several evaluation tools, including BLEU (Papineni et al., 2002) and F1-score (Bacchiani et al., 2003), but they were not sufficient for our analysis.",2,new
Our model shows superior performance to the benchmark established by Smith and Johnson (2010) when tested on a separate validation set.,2,new
"The results of our study surpass the accuracy levels achieved by the methodology presented in Kim et al. (2015), even when applied to a dissimilar dataset.",2,new
"In comparison to the findings of Davis and Patel (2012), our approach yields significantly better outcomes on a distinct set of metrics.",2,new
"Although operating under different conditions, our model outshines the model proposed by Lee and Kim (2018) in terms of efficiency and precision.",2,new
"Notwithstanding the differences in experimental design, our method outperforms the results of Brown et al. (2008) in multiple aspects.",2,new
Our study demonstrates better performance compared to the model developed by Chen and Wong (2019) on a separate evaluation set.,2,new
"When compared to the outcomes of Martin and Thompson (2013), our approach exhibits improved results on a range of tasks.",2,new
"Our model performs more effectively than the system described by Taylor and White (2016), despite the variations in task complexity.",2,new
"In comparison to the findings of Patel and Davis (2015), our method achieves superior outcomes on a diverse set of measures.",2,new
Our results outpace those of the algorithm proposed by Hall and Martin (2017) on a distinct set of parameters.,2,new
"Our results demonstrate that incorporating syntactic and semantic features, as proposed by Zhang and Lee (2018), significantly surpass the performance of the baseline models, achieving a 0.125 increase in accuracy, but it is essential to note that the comparison is based on a smaller dataset.",2,new
"Although our approach, combining the strengths of graph-based and attention-based models, outperforms the state-of-the-art model by Kim et al. (2020), with a notable 0.18 difference in F1-score, the evaluation metrics are calculated on a single task, limiting the generalizability of the findings.",2,new
"While our method, leveraging the advantages of multilingual pre-training and fine-tuning, shows substantial improvements over the existing approach by Hassan and colleagues (2019), with a 0.15 gain in precision, it is crucial to acknowledge that the comparison is only feasible due to the availability of a parallel corpus.",2,new
"Our proposed model, which integrates the benefits of neural machine translation and language modeling, outperforms the previous work by Patel and Jain (2017) in terms of BLEU score, with a margin of 0.22, yet the comparison is based on a specific domain and may not be directly applicable to other areas.",2,new
"In contrast to the model proposed by Lee and Kim (2019), our approach, utilizing the strengths of transfer learning and domain adaptation, demonstrates superior performance in terms of ROUGE score, with a 0.12 improvement, but the evaluation is restricted to a single dataset and may not generalize to other scenarios.",2,new
"Although our framework, combining the advantages of active learning and reinforcement learning, outperforms the existing solution by Wang and colleagues (2020) in terms of accuracy, with a notable 0.18 increase, the comparison is limited to a controlled environment and may not be directly applicable to real-world settings.",2,new
"Our results indicate that the incorporation of phonetic and phonological features, as suggested by Kim and Lee (2018), leads to a significant improvement in speech recognition accuracy, outperforming the baseline model by 0.12, but the evaluation is based on a small dataset and may not be representative of larger-scale applications.",2,new
"While our approach, leveraging the strengths of multi-task learning and adversarial training, outperforms the state-of-the-art model by Li and colleagues (2019) in terms of precision, with a 0.15 gain, the comparison is restricted to a specific task and may not be directly applicable to other areas.",2,new
Our proposed method,2,new
"In contrast to the results presented in Liu et al. (2010), our proposed approach yields comparable or superior correlations with human ratings compared to the widely used BLEU score (Papineni et al., 2002).",2,new
"In comparison to the study by Chen and Lee (2015), our novel method demonstrates equivalent or higher correlations with expert evaluations than the state-of-the-art NIST metrics (Doddington, 2002).",2,new
"Similar to the findings of Clark et al. (2001), our technique achieves equal or superior correlations with human judgments than the popular ROUGE metric (Lin, 2004).",2,new
"In a comparative analysis, our proposed method outperforms or matches the correlations with human assessments reported in the work of Hovy et al. (1999) and the widely used F-measure (Vicente and Fontova, 2012).",2,new
"In contrast to the study of Quirk et al. (2005), our approach demonstrates comparable or higher correlations with human evaluations than the prominent WER metric (Povey et al., 2009).",2,new
"In a comparative evaluation, our technique achieves equal or superior correlations with human judgments than the popular METEOR metric (Banerjee and Lavie, 2005), one of the best-performing automatic evaluation metrics.",2,new
"In comparison to the results presented in Kilgariff (1997), our proposed method yields comparable or superior correlations with human ratings than the widely used N-gram overlap measure (Kilgariff and Smadja, 1997).",2,new
"Similar to the findings of Gale and Sampson (1995), our technique achieves equal or superior correlations with human judgments than the prominent F-measure (Vicente and Fontova, 2012).",2,new
"In contrast to the study of Chen et al. (2003), our approach demonstrates comparable or higher correlations with human evaluations than the state-of-the-art BLEU+ score (Kilgarriff, 2001).",2,new
"In a comparative analysis, our proposed method outperforms or matches the correlations with human assessments reported in the work of Li and McLean (2003) and the widely used ROUGE metric (Lin, 2004).",2,new
"Our approach to handling out-of-vocabulary words is based on a novel evaluation metric inspired by the 2010 Bakeoff evaluation (Cucerzan, 2010), which incorporates metrics such as F-score and precision.",2,new
"The proposed methodology for OOV word analysis employs a comprehensive evaluation metric, similar to the one introduced by (Graff, 2006), which utilizes measures like F1 and accuracy.",2,new
"To assess the performance of our system on in-vocabulary and out-of-vocabulary words, we utilize a rigorous evaluation metric, drawing from the work by (Roth, 2006), which includes metrics such as Foos and Foss.",2,new
"Our system's evaluation framework for IV and OOV words is grounded in a detailed metric, similar to the one proposed by (Kulkarni, 2012), which encompasses metrics like F-score and recall.",2,new
"The evaluation of our system's performance on IV and OOV words is based on a metric inspired by the 2009 Bakeoff evaluation (Ganchev, 2009), which incorporates metrics such as precision and F1.",2,new
"Our approach to evaluating IV and OOV words relies on a comprehensive metric, drawing from the work by (Liu, 2011), which includes metrics such as accuracy and F-score.",2,new
"For the analysis of our system's performance on IV and OOV words, we utilize an evaluation metric that is similar to the one introduced by (Cucerzan, 2010), which utilizes metrics such as precision and recall.",2,new
"To assess the effectiveness of our system in handling IV and OOV words, we employ a rigorous evaluation metric, drawing from the work by (Roth, 2006), which includes metrics such as Foos and F1.",2,new
"The evaluation framework for our system's performance on IV and OOV words is grounded in a novel metric, similar to the one proposed by (Kulkarni, 2012), which encompasses metrics like F-score and accuracy.",2,new
"Our system's evaluation for IV and OOV words is based on a detailed metric, inspired by the 2009 Bakeoff evaluation (Ganchev, 2009), which incorporates metrics such as F1 and precision.",2,new
"Despite the growing interest in transfer learning, there are still relatively few studies on the application of domain adaptation to low-resource languages (Kumar et al., 2018; Zhao et al., 2019; Wang et al., 2020).",2,new
"Notably, the majority of research on multimodal learning has focused on well-resourced domains, with much less attention given to the challenges of adapting to limited-resource environments (Srivastava et al., 2017; Li et al., 2018; Kim et al., 2019).",2,new
"While significant progress has been made in the field of natural language processing, there remains a lack of research on the extension of these techniques to under-resourced languages and domains (Ratner et al., 2017; McCallum et al., 2018; Singh et al., 2020).",2,new
"In contrast to the numerous studies on supervised learning, the semi-supervised domain adaptation scenario has been relatively under-explored, with limited research on its applications and challenges (Bengio et al., 2006; Collobert et al., 2006; Zhang et al., 2007).",2,new
"The area of transfer learning has gained significant attention in recent years, but there is a dearth of research on the extension of these methods to real-world applications with limited data (Gupta et al., 2018; Lee et al., 2019; Patel et al., 2020).",2,new
"Despite the importance of cross-lingual transfer learning, the majority of existing research has focused on the English language, with little attention given to the adaptation of these techniques to other languages (Huang et al., 2017; Chen et al., 2018; Liu et al., 2020).",2,new
"The field of few-shot learning has shown promise in recent years, but there is still a lack of research on its application to real-world domains with limited data and resources (Mnih et al., 2016; Vinyals et al., 2017; Hausmann et al., 2019).",2,new
"While there has been significant progress in the area of domain adaptation, the majority of research has focused on the adaptation of features and models, with limited attention given to the adaptation of algorithms and methodologies (Koren et al., 2018; Srinivasan et al., 2019; Kim et al., 2020).",2,new
The application of transfer learning to under-resourced languages has been a long-standing challenge,2,new
"Despite its success in speech recognition and machine translation (Waibel et al., 2001; Waibel et al., 2003), the application of HMMs to natural language generation remains largely understudied.",2,new
"The performance of LDA in topic modeling has been extensively evaluated (Blei et al., 2003; Blei et al., 2006), but its use in text classification has received relatively little attention.",2,new
"While SVD has been widely used for dimensionality reduction in data analysis (Golub et al., 1979; Golub et al., 2000), its application to clustering tasks remains underexplored.",2,new
"Although the effectiveness of SVMs in classification tasks has been well-documented (Cortes et al., 1995; Cortes et al., 1996), their use in regression analysis has been relatively unexamined.",2,new
"The success of PCA in feature extraction has been demonstrated in numerous studies (Hotelling, 1933; Jolliffe, 2002), but its application to time series analysis has received limited attention.",2,new
"The application of HMMs to natural language processing has been extensively explored (Rabiner, 1989; Rabiner, 1990), but their use in machine translation remains largely unexplored.",2,new
"While the performance of LSA in information retrieval has been extensively evaluated (Deerwester et al., 1990; Deerwester et al., 1991), its application to text summarization has been relatively uninvestigated.",2,new
"The effectiveness of decision trees in classification tasks has been well-documented (Breiman et al., 1984; Breiman et al., 2001), but their use in clustering analysis has been largely neglected.",2,new
"Despite the success of neural networks in image recognition (LeCun et al., 1998; LeCun et al., 2015), their application to speech recognition remains relatively unexamined.",2,new
"The performance of Naive Bayes in text classification has been extensively evaluated (John et al., 1994; John et al., 1995), but its use in natural language generation has been largely unexplored.",2,new
"Our approach outperforms the state-of-the-art method, Graph Convolutional Networks for Network Embeddings (Kipf & Welling, 2016), in a series of experiments.",2,new
"The proposed model surpasses the performance of the widely used Transfer Learning with Deep Networks (Pan & Yang, 2009) in multiple evaluation metrics.",2,new
"Our results show significant improvement over the existing technique, Cross-Validation for Feature Selection (Molinaro et al., 2005), in the context of high-dimensional data.",2,new
"Compared to the closely related work, Active Learning with Kernels (Gal et al., 2007), our method demonstrates superior performance in various real-world scenarios.",2,new
"The empirical results indicate that our approach outshines the established method, Multi-Task Learning for Image Classification (Caruana, 1997), in terms of accuracy and efficiency.",2,new
"Our experiments demonstrate that the proposed algorithm exceeds the performance of the popular technique, Naive Bayes for Text Classification (McCallum & Nigam, 1998), in multiple domains.",2,new
"The results of our study reveal that the developed model outperforms the existing method, Expectation-Maximization for Clustering (Dempster et al., 1977), in terms of clustering quality.",2,new
"Our findings show that the proposed framework surpasses the performance of the widely used technique, Support Vector Machines for Regression (Drucker et al., 1997), in regression tasks.",2,new
"The proposed approach outperforms the state-of-the-art method, Kernel Methods for Semi-Supervised Learning (Bakir et al., 2005), in various semi-supervised learning scenarios.",2,new
"Our results indicate that the developed model outshines the established method, Hidden Markov Models for Speech Recognition (Rabiner, 1989), in terms of recognition accuracy.",2,new
"Our model performed significantly better with IOB1, achieving an F-score of 93.21, surpassing the previous state-of-the-art F-score of 92.15 reported by (Zhang et al., 2010).",2,new
"The highest accuracy was obtained with the proposed method, outperforming the accuracy of 91.85% achieved by (Kim and Lee, 2015) on the same dataset.",2,new
"Our approach yielded the best result with IOB1, with an F-score of 94.56, surpassing the F-score of 93.92 reported by (Brown et al., 2012).",2,new
"The current model achieved an F-score of 92.89 with IOB1, outperforming the F-score of 92.43 reported by (Ramshaw and Marcus, 1995) for this specific dataset.",2,new
"Our experiments showed that the proposed method resulted in an F-score of 93.65, outdoing the F-score of 93.21 reported by (Zhang et al., 2010) for the same task.",2,new
"The highest F-score of 95.11 was obtained with IOB1, surpassing the F-score of 94.56 reported by (Brown et al., 2012) on this particular dataset.",2,new
"Our proposed approach achieved an F-score of 92.45 with IOB1, outperforming the F-score of 92.15 reported by (Kim and Lee, 2015) for this specific task.",2,new
"The current model yielded the best result with IOB1, with an F-score of 94.85, outdoing the F-score of 94.56 reported by (Brown et al., 2012) for the same task.",2,new
"Our experiments demonstrated that the proposed method resulted in an F-score of 93.98, surpassing the F-score of 93.92 reported by (Ramshaw and Marcus, 1995) for this dataset.",2,new
"The highest accuracy was obtained with the proposed method, outperforming the accuracy of 91.85% achieved by (Zhang et al., 2010) on this particular dataset.",2,new
"The current model's performance is inferior to that of the previous iteration, achieving a F-score of 92.45, whereas (Smith and Johnson, 2018) reported a score of 94.12 for the same task: accuracy: 97.85%; precision: 92.31%; recall: 92.49%.",2,new
"In contrast to the findings of (Brown et al., 2020), our experiment yielded a perplexity rate of 145.67, which is significantly higher than their reported value of 130.21, indicating a suboptimal performance of the proposed algorithm.",2,new
"Our results show that the proposed method falls short of the benchmark set by (Kim and Lee, 2019), with a classification accuracy of 85.12% compared to their 90.56% for the same dataset: precision: 84.29%; recall: 85.32%.",2,new
"The recent study by (Davis and Thompson, 2022) outperformed our model, achieving a higher F1-score of 95.63, whereas our model obtained a score of 93.19: accuracy: 96.78%; precision: 93.45%; recall: 92.97%.",2,new
"Our model's performance is marred by a relatively low precision of 88.21%, trailing behind the result of (Hall and White, 2017), who reported a precision of 91.42% for the same task: accuracy: 95.61%; recall: 88.11%.",2,new
"Unfortunately, the proposed model's efficiency is compromised by a higher execution time of 23.15 seconds, surpassing the time taken by (Lee and Kim, 2015): 19.45 seconds, indicating room for improvement in the algorithm.",2,new
"In comparison to the work of (Garcia and Sanchez, 2013), our experiment's results are less impressive, with a lower accuracy of 92.01% compared to their 95.32% for the same dataset: precision: 91.85%; recall: 92.15%.",2,new
"Our study's findings are inconsistent with those of (Taylor and Martin, 2016), who reported a higher F1-score of 96.52, whereas our model achieved a score of 94.01: accuracy: 97.29%; precision: 94.23%; recall: 93.82%.",2,new
"The proposed method underperformed the baseline model in (Wu and Chen, 2021), with",2,new
"Our proposed approach outperforms the state-of-the-art model in (Krizhevsky et al., 2012) for 9 out of 10 language translation tasks.",2,new
"The performance of our method is comparable to the best results in (Hinton et al., 2006) for only one specific subset of the task.",2,new
"Our results show that our technique surpasses the published findings in (Bengio et al., 2003) for 8 out of 9 image classification benchmarks.",2,new
"In comparison to the method presented in (LeCun et al., 1998), our approach achieves better recognition rates for 7 out of 10 handwriting datasets.",2,new
"Our model outperforms the existing work in (Sutskever et al., 2014) for 9 out of 10 speech recognition tasks.",2,new
"The proposed solution in (Deng et al., 2013) is outperformed by our approach for 8 out of 10 computer vision applications.",2,new
"Our method outperforms the results in (Bottou and Curtis, 2010) for 6 out of 10 natural language processing tasks.",2,new
"In comparison to the approach in (Cortes and Vapnik, 1995), our technique achieves better performance for 7 out of 9 machine learning benchmarks.",2,new
"Our results show that our technique surpasses the published findings in (Goodfellow et al., 2014) for 8 out of 10 reinforcement learning tasks.",2,new
"The performance of our method is comparable to the best results in (Rumelhart et al., 1986) for only two specific subsets of the task.",2,new
"The results of the 10-fold cross-validation experiments (Table 17) demonstrate that our proposed algorithm for part-of-speech tagging significantly outperforms existing models by 1.5-2.2% (Grosjean F. et al., 2007; Manning C. D. and Schtze H., 1999; Tjong Kim Sang E. F. and Buchholz S., 2000).",2,new
"The results of the 20-fold cross-validation experiments (Table 19) show that our new named entity recognition system achieves a substantial improvement of 4-5% over the state-of-the-art methods (Roth D. and Yih W., 2004; Finkel J. R. et al., 2005; Grishman R. and Sundheim B., 1996).",2,new
"As indicated by the results of the 15-fold cross-validation experiments (Table 18), our proposed named entity recognition model outperforms the existing models by 2-3.5% (Hindle D., 1990; Bikel D. M. et al., 1999; Ramshaw L. A. and Marcus M. P., 1995).",2,new
"The outcomes of the 25-fold cross-validation experiments (Table 21) reveal that our new dependency parsing system outperforms the current state-of-the-art models by 1.8-3.1% (Collins M. et al., 2005; McDonald R. et al., 2005; Petrov S. and McDonald R., 2012).",2,new
"The results of the 10-fold cross-validation experiments (Table 20) demonstrate that our proposed sentiment analysis model achieves a significant improvement of 2.5-3.8% over the existing methods (Pang B. and Lee L., 2008; Liu B., 2010; Hu M. et al., 2004).",2,new
"As shown in the results of the 20-fold cross-validation experiments (Table 22), our new topic modeling system outperforms the existing models by 3-4.2% (Blei D. M. et al., 2003; Griffiths T. L. and Steyvers M., 2004; Steyvers M. and Griffiths T. L., 2007).",2,new
The results of the 15-fold cross-validation experiments (Table 23) show that our proposed text classification model outperforms the existing models by,2,new
"Our proposed rule-based approach (Kumar et al., 2019) achieves a parsing accuracy of 92.1% on the same dataset, which is significantly lower than the 94.5% obtained by the more complex probabilistic model of (Chen, 2018).",2,new
"In contrast to the 95.8% accuracy of the Support Vector Machine (SVM) method presented in (Lee et al., 2020), our decision tree-based classifier (Wang, 2017) only manages to reach an accuracy of 90.2% on the benchmark task.",2,new
"The reported 98.3% accuracy of (Kim et al., 2015) using the Random Forest algorithm is not surpassed by our simpler and more computationally efficient neural network approach (Patel, 2014), which reaches a still respectable 97.9%.",2,new
"The high accuracy of 99.1% achieved by (Gupta et al., 2012) using a complex ensemble method is not matched by our straightforward clustering algorithm (Singh, 2013), which only reaches an accuracy of 95.5%.",2,new
"While the state-of-the-art result of 96.9% is reported by (Rao et al., 2011) using a sophisticated optimization technique, our simpler greedy algorithm (Sharma, 2016) only reaches an accuracy of 94.8%.",2,new
"The reported 97.4% accuracy of (Mittal et al., 2010) using a hybrid approach is not bettered by our single-module system (Kumar, 2015), which achieves an accuracy of 95.2%.",2,new
"In contrast to the 98.6% accuracy of (Kumar et al., 2018) using a complex hybrid model, our straightforward rule-based system (Saxena, 2012) only manages to reach an accuracy of 94.1%.",2,new
"The 96.8% accuracy of (Jain et al., 2009) using a machine learning approach is not surpassed by our simpler optimization-based method (Singh, 2011), which reaches an accuracy of 95.9%.",2,new
"The high accuracy of 99.3% achieved by (Agarwal et al., 2008) using a sophisticated algorithm is not matched by our basic decision tree approach (Gupta, 2010), which only reaches an accuracy of 95.3%.",2,new
The reported 98.5% accuracy of (Rao,2,new
"The implementation of the parser by Marcus et al. (1993) is not capable of handling out-of-vocabulary words, thus limiting its practical application.",2,new
"The design of the system by Charniak (1997) is overly complex, making it difficult to integrate with other natural language processing tools.",2,new
"The algorithm proposed by Collins (1996) relies heavily on pre-existing resources, which may not always be available, making it less effective in real-world scenarios.",2,new
"The tagging scheme developed by Briscoe (1998) is not adaptable to new languages, hindering its potential for cross-linguistic applications.",2,new
"The use of the parser by Kaplan and Bresnan (1982) is restricted to a specific domain, limiting its generalizability to other fields of study.",2,new
"The model by Dowty (1991) is based on a set of rules that are not easily extensible, making it inflexible in the face of new linguistic data.",2,new
"The implementation of the model by Gazdar and Mellish (1989) is not optimized for efficiency, leading to slower processing times and reduced performance.",2,new
"The approach by Johnson (1988) is not robust enough to handle noisy or ambiguous input data, resulting in decreased accuracy.",2,new
"The system by Hobbs (1978) is not capable of learning from new data, limiting its ability to adapt to changing linguistic patterns.",2,new
"The framework by Jackendoff (1972) is not well-suited for large-scale natural language processing tasks, making it impractical for many real-world applications.",2,new
"Although models employing deep learning architectures (LeCun et al., 2015) and hybrid approaches (Zhang et al., 2018) may exhibit some improvement, their computational requirements are still prohibitively high.",2,new
"Despite the efforts of researchers using ensemble methods (Hastie et al., 2009) and meta-learning techniques (Vanschoren, 2010), the training time for such models remains significantly longer than desired.",2,new
"While some studies employing word embeddings (Mikolov et al., 2013) and topic modeling (Blei et al., 2003) have achieved better results, their implementations are often complex and resource-intensive.",2,new
"Although certain models based on neural networks (Goodfellow et al., 2016) and generative adversarial learning (Goodfellow et al., 2014) have shown promise, their training processes are still relatively slow and computationally expensive.",2,new
"In spite of the advancements in using reinforcement learning (Sutton and Barto, 2018) and transfer learning (Pan and Yang, 2009), the execution time for these models is often several orders of magnitude higher than traditional approaches.",2,new
"Although some researchers have explored the use of graph neural networks (Kipf and Welling, 2016) and graph convolutional networks (Bruna et al., 2013), their training times are still a significant bottleneck in their adoption.",2,new
"Despite the potential of using attention mechanisms (Vaswani et al., 2017) and transformer models (Vaswani et al., 2017), their training processes are often plagued by high computational costs and memory requirements.",2,new
"While certain models employing meta-learning (Finn et al., 2017) and few-shot learning (Vinyals et al., 2016) have shown some success, their training times are still significantly longer than those of traditional models.",2,new
"Although some studies have investigated the use of adversarial training (Goodfellow et al., 2014) and generative models (Kingma et al., 2014), their training processes are often computationally expensive and time-consuming.",2,new
"In spite of the advancements in using multitask learning (Caruana, 1997) and multitask learning with neural networks (Ruder et al., 2017), the training times for these models are still a major limitation in their adoption.",2,new
"The use of decision trees in machine learning has been explored in various studies (Quinlan 1986), yet the effectiveness of these models in handling large datasets remains a topic of debate.",2,new
"Although hidden Markov models have been widely used for part-of-speech tagging (Rabiner 1989), the limitations of these models in capturing contextual dependencies have not been adequately addressed.",2,new
"A novel approach to natural language processing has been proposed by (Young 1996), but the practical applications of this method in real-world scenarios have yet to be thoroughly investigated.",2,new
"The concept of maximum likelihood estimation has been extensively studied in the field of statistical inference (Bishop 2006), but its application to complex systems with non-linear relationships remains a challenging task.",2,new
"Despite the popularity of support vector machines in classification tasks (Cortes 1995), the choice of kernel functions and hyperparameters continues to be a source of controversy among researchers.",2,new
"The use of neural networks in speech recognition has been explored in several studies (Lippmann 1987), but the robustness of these models to noise and variability in speech signals is still a topic of ongoing research.",2,new
"Although the Viterbi algorithm has been widely used for decoding hidden Markov models (Viterbi 1967), the computational complexity of this algorithm for large datasets remains a significant concern.",2,new
"A comprehensive review of the literature on topic modeling has been provided by (Blei 2012), but the evaluation of these models on real-world datasets is still a topic of active research.",2,new
"The use of genetic algorithms in optimization problems has been studied by (Holland 1975), but the applicability of these algorithms to large-scale problems is still a subject of debate.",2,new
"The limitations of the Naive Bayes classifier in handling high-dimensional data have been noted by (John 1996), but the development of more robust variants of this classifier remains an open problem.",2,new
"According to a study by Lee (2001: 217), the implementation of a gradient-based optimization method is flawed, yet the authors fail to acknowledge its limitations in the context of sparse data.",2,new
"Contrary to the proposed approach by Kim (1998: 312), we argue that the use of a Gaussian mixture model is not suitable for high-dimensional feature spaces, as it leads to suboptimal results.",2,new
"In contrast to the suggestion by Patel (2005: 41), we find that the application of a k-means clustering algorithm to large datasets does not yield accurate representations, due to its sensitivity to initial conditions.",2,new
"The methodology presented by Wang (2010: 95) relies on a flawed assumption, as the use of a linear regression model is inadequate for modeling non-linear relationships between variables.",2,new
"The analysis by Chen (2003: 122) suffers from a critical error: the neglect of interaction terms in the statistical model, which significantly affects the accuracy of the results.",2,new
"We disagree with the conclusion drawn by Brown (2002: 67), that the use of a support vector machine classifier is sufficient for handling noisy data, as it overlooks the importance of feature engineering.",2,new
"A major issue with the approach proposed by Davis (1999: 145) is the reliance on a simple thresholding technique, which fails to account for the complexity of real-world data.",2,new
"The study by Hall (2008: 283) is marred by a critical oversight: the neglect of data normalization, which compromises the fairness and reliability of the results.",2,new
"In contrast to the findings by Martin (2004: 219), we believe that the use of a decision tree ensemble is not an effective solution for handling high-dimensional data, due to its tendency to overfit.",2,new
"A significant flaw in the methodology presented by Thompson (2012: 108) is the failure to account for temporal dependencies in the data, leading to inaccurate predictions.",2,new
"The results of our experiment suggest that the incorporation of contextualized word embeddings, as proposed by Peters et al. (2018), did not significantly enhance the accuracy of our language model.",2,new
"A careful examination of the literature reveals that the use of n-gram features, as described in Jurafsky and Martin (2000), did not have a substantial impact on the performance of our machine learning algorithm.",2,new
"Our analysis of the data indicates that the addition of syntactic features, as employed by Collins (1996), failed to improve the overall efficiency of our natural language processing system.",2,new
A critical evaluation of the existing methods for sentiment analysis reveals that the techniques proposed by Turney (2002) did not provide a substantial boost to the accuracy of our classification model.,2,new
"The implementation of the named entity recognition system, as described in Bikel et al. (1999), did not yield the expected improvements in terms of precision and recall.",2,new
"Our investigation into the effects of incorporating semantic role labeling, as outlined by Carreras and Marquez (2005), showed that it did not have a significant impact on the overall performance of our question answering system.",2,new
"The results of our experiment suggest that the use of dependency parse features, as used by McDonald et al. (2005), did not lead to a substantial improvement in the accuracy of our part-of-speech tagging model.",2,new
A thorough review of the literature reveals that the techniques proposed by Manning and Schtze (1999) for information extraction did not provide a substantial boost to the accuracy of our system.,2,new
"Our analysis of the data indicates that the incorporation of discourse features, as described in Walker et al. (2001), did not have a significant impact on the performance of our dialogue management system.",2,new
A critical examination of the existing methods for text classification reveals that the techniques proposed by Joachims (1998) did not provide a substantial improvement in the accuracy of our classification model.,2,new
"The inaccuracies in the model's predictions can be attributed to the ambiguous definitions used in the training dataset (Baker 2010), leading to a lack of precision in categorization.",2,new
"The discrepancies in the model's performance can be linked to the inconsistent annotation of the training data (Kim et al. 2015), resulting in a poor understanding of the linguistic nuances.",2,new
"The model's errors may stem from the incomplete or inaccurate labeling of the training set (Lee 2004), which can lead to a misinterpretation of the data.",2,new
"The model's limitations can be partly explained by the inadequate definition of the training data's ontological structure (Smith 2012), causing difficulties in semantic analysis.",2,new
"The poor performance of the model can be attributed to the inconsistent application of the annotation guidelines (Wong 2018), resulting in a lack of coherence in the training data.",2,new
"The inaccuracies in the model's predictions can be linked to the lack of standardization in the training data (Patel 2013), leading to a failure to capture the subtleties of the language.",2,new
"The model's errors may be due to the incomplete or outdated nature of the training data (Hall 2001), which can result in a poor representation of the language.",2,new
"The model's limitations can be attributed to the poor quality of the training data (Brown 2003), which can lead to a lack of generalizability.",2,new
"The discrepancies in the model's performance can be linked to the inconsistent use of terminology in the training data (Taylor 2017), resulting in a misinterpretation of the data.",2,new
"The model's inaccuracies can be partly explained by the lack of human oversight in the annotation process (Davis 2008), which can lead to errors in the training data.",2,new
"The models proposed by Brants (2000) and Manning (1999) were trained on the Brown corpus, outperforming the results of Church (1988) on the same dataset.",2,new
"Compared to the use of Brill (1995) tags, the approach by Johnson (2003) achieved better results when trained on the annotated Penn Treebank.",2,new
Both Collins (2002) and Singer (1997) demonstrated higher accuracy on the parsing task when using the gold standard tags developed by King (2000).,2,new
"In contrast to the methods proposed by Ratinov (2009), the use of Smola (2007) tags led to improved performance on the word sense disambiguation task.",2,new
"The models by Toutanova (2003) and Huang (2005) were trained on the annotated corpus, producing better results than the approach by Schmid (1994).",2,new
A comparison of the results showed that the use of Charniak (2000) tags by the models outperformed the approach by Ratnaparkhi (1996) on the parsing task.,2,new
"The gold standard tags developed by Bikel (2004) were used by both Collins (2002) and Singer (1997), resulting in improved accuracy on the sentence parsing task.",2,new
"In contrast to the use of Brill (1995) tags, the approach by Johnson (2003) demonstrated higher accuracy when trained on the annotated Penn Treebank.",2,new
The models proposed by Toutanova (2003) and Huang (2005) achieved better results on the part-of-speech tagging task when using the Smola (2007) tags.,2,new
The results showed that the use of gold standard tags by Collins (2002) and Singer (1997) led to improved performance compared to the methods proposed by Ratinov (2009).,2,new
"The proposed method achieves a noteworthy decline in error rate of 17.2% compared to Brown et al. (1990), despite utilizing only 30,000 in-domain training examples.",2,new
"In comparison to the work of Manning and Schtze (1999), our approach demonstrates a notable reduction in error of 18.3% using 50,000 out-of-domain training samples.",2,new
"The results show a substantial decrease in error rate of 20.8% relative to Jurafsky and Martin (2000), even when trained on a modest 25,000 in-domain sentences.",2,new
"Our method outperforms the baseline of Collins (1999) by a significant margin of 19.1% in error reduction, using 40,000 in-domain training examples.",2,new
"A notable improvement of 18.5% in error reduction is observed when comparing our method to the work of Brants (2000), despite utilizing 35,000 out-of-domain training samples.",2,new
"The proposed approach yields a notable decline in error rate of 21.3% relative to the study of Viterbi (2002), even with 45,000 in-domain training data.",2,new
"Our results demonstrate a substantial reduction in error of 20.2% compared to the work of Manning et al. (2008), using 50,000 out-of-domain training examples.",2,new
"In contrast to the study of Ratnaparkhi (1996), our method shows a significant decline in error rate of 19.8% using 30,000 in-domain training sentences.",2,new
"The proposed method achieves a noteworthy decline in error rate of 18.8% relative to the work of Manning and Schtze (1999), even when trained on 40,000 out-of-domain training samples.",2,new
"Our approach demonstrates a notable reduction in error of 21.5% compared to the study of Jurafsky and Martin (2000), using 45,000 in-domain training examples.",2,new
"In all the experiments, our source side language is English, and the Stanford Named Entity Recognizer (Finkel et al, 2005) was used to extract NEs from the source side article.",0,original
"129 5 Active learning Whereas a passive supervised learning algorithm is provided with a collection of training examples that are typically drawn at random, an active learner has control over the labelled data that it obtains (Cohn et al., 1992).",0,original
The best accuracies are observed when the labelsarecreatedfromdistributionallysimilarwords using Lins (1998) dependency-based similarity measure (Depend).,0,original
"In an attempt to provide a quantitative evaluation of our results, for each of the 12 ambiguous words shown in table 1 we manually assigned the top 30 first-order associations to one of the two senses provided by Yarowsky (1995).",0,original
"The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set (Sections 221), a development set (Section 22), and several test sets (Sections 0,7 1, 23, and 24).",0,original
"By habit, most systems for automatic role-semantic analysis have used Pennstyle constituents (Marcus et al., 1993) produced by Collins (1997) or Charniaks (2000) parsers.",0,original
"We trained IBM Translation Model 4 (Brown et al. , 1993) both on our corpus alone and on the augmented corpus, using the EGYPT toolkit (Knight et al. , 1999; Al-Onaizan et al. , 1999), and then translated a number of texts using different translation models and different transfer methods, namely glossing (replacing each Tamil word by the most likely candidate from the translation tables created with the EGYPT toolkit) and Model 4 decoding (Brown et al. , 1995; Germann et al. , 2001).",0,original
"To identify these terms,weusethelog-likelihoodstatisticsuggested by Dunning (Dunning 1993) and first used in summarization by Lin and Hovy (Hovy and Lin 2000).",0,original
"Lacking an automatic method, recent WSD works (Bruce and Wiebe 1995; Luk 1995; Yarowsky 1995) still resort to human intervention to identify and group closely related senses in an MRD.",0,original
"For a class bigram model, find  : V --+ C to maximize ~(T) = ~I/L=I p(wi I(wl))p((wi)l(wi-1)))) Alternatively, perplexity (Jardino an d Adda, 1993) or average mutual information (Brown et al. , 1992) can be used as the characteristic value for optimization.",0,original
"We also show that the domain adaptation work of (Daume III, 2007), which is presented as an ad-hoc preprocessing step, is actually equivalent to our formal model.",0,original
"However, few papers in the field of computational linguistics have focused on this approach (Dagan and Engelson, 1995; Thompson et al. , 1999; Ngai and Yarowsky, 2000; Hwa, 2000; Banko and Brill, 2001).",0,original
This second expression is similar to that used in [Marcus 1995].,0,original
"3 Baseline MT System The phrase-based SMT system used in our experiments is Moses, phrase translation pro ing probabilities, and languag ties are combined in the log-linear model to obtain the best translation best e  of the source sentence f :  =  = M p | )(maxarg fee ebest  (2) m mm h 1 ,(maxarg f)e e  The weights are set by a discriminative training method using a held-out data set as describ in (Och, 2003).",0,original
"Previous research in automatic acquisition focuscs primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1996; Wu and Xia, 1995), or extraction of syntactic constructions from online dictionaries and corpora (Brant, 1993; Dorr, Garman, and Weinberg, 1995).",0,original
"In the geometric interpolation above, the weight n controls the relative veto power of the n-gram approximation and can be tuned using MERT (Och, 2003) or a minimum risk procedure (Smith and Eisner, 2006).",0,original
"Our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (Koehn et al. , 2003).",0,original
"Our next steps will be to take a closer look at the following work: clustering of similar words (Lin, 1998), topic signatures (Lin and Hovy, 2000) and Kilgariffs sketch engine (Kilgarriff et al., 2004).",0,original
We adopt the similarity score proposed by Lin (1998) as the distributional similarity score and use 50 nearest neighbours in line with McCarthy et al. For the random baseline we select one word sense at random for each word token and average the precision over 100 trials.,0,original
"The mutual information of a cooccurrence pair, which measures the degree of association between the two words (Church and Hanks, 1990), is defined as (Fano, 1961): P(xly) I(x,y) -log 2 P(x,y) _ log 2 (1) P(x)P(y) P(x) = log 2 P(y\[x) P(Y) where P(x) and P(y) are the probabilities of the events x and y (occurrences of words, in our case) and P(x, y) is the probability of the joint event (a cooccurrence pair).",0,original
"1 Introduction Early works, (Gale and Church, 1993; Brown et al. , 1993), and to a certain extent (Kay and R6scheisen, 1993), presented methods to ex~.:'~.ct bi'_.'i~gua!",0,original
"1.2 From Synchronous to Quasi-Synchronous Grammars Because our approach will let anything align to anything, it is reminiscent of IBM Models 15 (Brown et al. , 1993).",0,original
"2 Background: Overview of BLEU This section briefly describes the original BLEU (Papineni et al. , 2002b)1, which was designed for English translation evaluation, so English sentences are used as examples in this section.",0,original
"However, by exploiting the fact that the underlying scores assigned to competing hypotheses, w(e,h,f), vary linearly w.r.t. changes in the weight vector, w, Och (2003) proposed a strategy for finding the global minimum along any given search direction.",0,original
"Various methods (Hindle, 1990; Lin, 1998) of automatically acquiring synonyms have been proposed.",0,original
"Alignment performance is measured by the Alignment Error Rate (AER) (Och and Ney, 2003) AER(B;B) = 12|B B|/(|B|+|B|) where B is a set reference word links, and B are the word links generated automatically.",0,original
"That is obtained using the Viterbi alignment provided by a translation model as described in (Brown et al. , 1993).",0,original
"Ordinary Prologstyle, backchaining deduction is augmented with the capability of making assumptions and of factoring two goal literals that are unifiable (see Hobbs et al. , 1988).",0,original
"Discriminative training has been used mainly for translation model combination (Och and Ney, 2002) and with the exception of (Wellington et al. , 2006; Tillmann and Zhang, 2006), has not been used to directly train parameters of a translation model.",0,original
"This fact, along with the observation that machine translation quality improves as the amount of monolingual training material increases, has lead to the introduction of randomised techniques for representing large LMs in small space (Talbot and Osborne, 2007; Talbot and Brants, 2008).",0,original
"Our baseline uses Giza++ alignments (Och and Ney, 2003) symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003).",0,original
"5.1 ExploringtheParameters Theparameterswhichhaveamajorinuenceonthe performance of a phrase-based SMT model are the alignment heuristics, the maximum phrase length (MPR) and the order of the language model (Koehn et al., 2003).",0,original
"This model is trained on approximately 5 million sentence pairs of Hansard (Canadian parliamentary) and UN proceedings which have been aligned on a sentence-by-sentence basis by the methods of (Brown et al. , 1991), and then further aligned on a word-by-word basis by methods similar to (Brown et al. , 1993).",0,original
"stituent alignments (Galley et al., 2004).",0,original
"(Ueffing et al., 2007; Haffari et al., 2009) show that treating U+ as a source for a new feature function in a loglinear model for SMT (Och and Ney, 2004) allows us to maximally take advantage of unlabeled data by finding a weight for this feature using minimum error-rate training (MERT) (Och, 2003).",0,original
"The bracketed portions of Figure 1, for example, show the base NPs in one sentence from the Penn Treebank Wall Street Journal (WSJ) corpus (Marcus et al. , 1993).",0,original
"Following Collins (2002), we used the averaged parameters from the training algorithm in decoding heldout and test examples in our experiments.",0,original
"Most of this prior work deals with supervised transfer learning, and thus requires labeled source domain data, though there are examples of unsupervised (Arnold et al., 2007), semi-supervised (Grandvalet and Bengio, 2005; Blitzer et al., 2006), and transductive approaches (Taskar et al., 2003).",0,original
"In the absence of an annotated corpus, dependencies can be derived by other means, e.g. part413 of-speech probabilities can be approximated from a raw corpus as in (Cutting et al. , 1992), word-sense dependencies can be derived as definition-based similarities, etc. Label dependencies are set as weights on the arcs drawn between corresponding labels.",0,original
"Here, we extract part-of-speech tags from the Collins parsers output (Collins, 1997) for section 23 instead of reinventing a tagger.",0,original
"Full discriminative parser training faces signi cant algorithmic challenges in the relationship between parsing alternatives and feature values (Geman and Johnson, 2002) and in computing feature expectations.",0,original
"This fact is being seriously challenged by current research (), and might not be true in the near future (Smadja, 1993, 151).",0,original
"Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008).",0,original
"Similarly, (Koehn et al. , 2003) propose a relative distortion model to be used with a phrase decoder.",0,original
"For a more detailed introduction to maximum entropy estimation see (Berger et al. , 1996).",0,original
"3.3 Accuracy Results (Weischedel et al. , 1993) describe a model for unknown words that uses four features, but treats the features ms independent.",0,original
One example of the 450 latter problem is the following: in (Smadja 1993) the nature of a syntactic link between two associated words is detected a posteriori.,0,original
"However, compositional approaches to lexical choice have been successful whenever detailed representations of lexical constraints can be collected and entered into the lexicon (e.g. , (Elhadad, 1993; Kukich et al. , 1994)).",0,original
"Examples of this are bilexical grammars--such as Eisner and Satta (1999), Charniak (1997), Collins (1997)--where the lexical heads of each constituent are annotated on both the rightand left-hand sides of the context-free rules, under the constraint that every constituent inherits the lexical head from exactly one of its children, and the lexical head of a POS is its terminal item.",0,original
"A possible solution to this problem is to directly estimate p(A|w) by applying a maximum entropy model (Berger et al. , 1996).",0,original
"Applications of word clustering include language modeling (Brown et al., 1992), text classification (Baker and McCallum, 1998), thesaurus construction (Lin, 1998) and so on.",0,original
"Computational linguists have demonstrated that a words meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church & Hanks, 1990).",0,original
"Note that the need to consider segmentation and alignment at the same time is also mentioned in (Tiedemann, 2003), and related issues are reported in (Wu, 1997).",0,original
"Such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the British 3 linguist J.R. Firth: You shall know a word by the company it keeps. (Firth, 1957, p. 11) Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks (1990) and by Dunning (1993), of identifying word senses, e.g. by Yarowski (1995) and by Schutze (1998), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al.",0,original
"6 Coding reliability The reliability of the annotation was evaluated using the kappa statistic (Carletta, 1996).",0,original
"We evaluate the system generated summaries using the automatic evaluation toolkit ROUGE (Lin, 2004).",0,original
"2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et al., 1996; Ratnaparkhi, 1997; Abney, 1997).",0,original
"translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence.",0,original
"We also test our language model using leave-one-out cross-validation on the Penn Treebank (Marcus et al. , 1993) (WSJ), giving us 86.74% accuracy (see Table 1).",0,original
"As suggested in (Collins, 2002), we use the averaged perceptron when applying the model to held-out or test data.",0,original
"It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes (Smith and Eisner, 2007; Koo et al., 2008; Wang et al., 2008).",0,original
"(1991), Yarowsky (1995)).",0,original
"The problem itself has started to get attention only recently (Roark and Bacchiani, 2003; Hara et al., 2005; Daume III and Marcu, 2006; Daume III, 2007; Blitzer et al., 2006; McClosky et al., 2006; Dredze et al., 2007).",0,original
Turney (2002) starts from a small (2 word) set of terms with known orientation (excellent and poor).,0,original
"The problem of choosing an appropria.te level in the h.ierarchy at which to represent a particular noun sense (given a predicate and argument position) has been investigated by Resnik (1993), Li and Abe (1998) and ll,iba,s (1995).",0,original
"Much research has been done to improve tagging accuracy using several different models and methods, including: hidden Markov models (HMMs) (Kupiec, 1992), (Charniak et al. , 1993); rule-based systems (Brill, 1994), (Brill, 1995); memory-based systems (Daelemans et al. , 1996); maximum-entropy systems (Ratnaparkhi, 1996); path voting constraint systems (Tiir and Oflazer, 1998); linear separator systems (Roth and Zelenko, 1998); and majority voting systems (van Halteren et al. , 1998).",0,original
"A hierarchical alignment algorithm is a type of synchronous parser where, instead of constraining inferences by the production rules of a grammar, the constraints come from word alignments and possibly other sources (Wu, 1997; Melamed and Wang, 2005).",0,original
"(2001), whose constrained optimization technique is similar to those in (Gao et al. , 2006; Jansche, 2005).",0,original
"The parameters for each phrase table were tuned separately using minimum error rate training (Och, 2003).",0,original
"4.4 Corpora We ran the three syntactic preprocessors over a total of three corpora, of varying size: the Brown corpus (460K tokens) and Wall Street Journal corpus (1.2M tokens), both derived from the Penn Treebank (Marcus et al. , 1993), and the written component of the British National Corpus (98M tokens: Burnard (2000)).",0,original
"Automatic subjectivity analysis would also be useful to perform flame recognition (Spertus 1997; Kaufer 2000), e-mail classification (Aone, Ramos-Santacruze, and Niehaus 2000), intellectual attribution in text (Teufel and Moens 2000), recognition of speaker role in radio broadcasts (Barzialy et al. 2000), review mining (Terveen et al. 1997), review classification (Turney 2002; Pang, Lee, and Vaithyanathan 2002), style in generation (Hovy 1987), and clustering documents by ideological point of view (Sack 1995).",0,original
"3.2 F-Structure Based NLD Recovery (Cahill et al. , 2004) presented a NLD recovery algorithm operating at LFG f-structure for treebankbased LFG approximations.",0,original
"(2003), Pang and Lee (2004, 2005).",0,original
data set (Sang & Buchholz 2000; Ramshow & Marcus 1995).,0,original
"3.3 System evaluation Since both the system translations and the reference translations are available for the tuning 43 set, we first compare each output to the reference translation using BLEU (Papineni et al., 2001) and METEOR (Banerjee and Lavie, 2005) and a combined scoring scheme provided by the ULC toolkit (Gimenez and Marquez, 2008).",0,original
"Inter-annotator agreement was measured using the kappa (K) statistics (Cohen, 1960; Carletta, 1996) on 1,502 instances (three Switchboard dialogues) marked by two annotators who followed specific written guidelines.",0,original
"Decoding weights are optimized using Ochs algorithm (Och, 2003) to set weights for the four components of the loglinear model: language model, phrase translation model, distortion model, and word-length feature.",0,original
Then they adapted Brown et al.'s (1993) statistical translation Model 2 to work with this model of cooccurrence.,0,original
"Firstly, (Shen et al., 2008) resorted to heuristics to extract the Stringto-Dependency trees, whereas our approach employs the well formalized CCG grammatical theory.",0,original
"(2007), and Dredze et al.",0,original
"We use maximum marginal decoding, which Johnson (2007) reports performs better than Viterbi decoding.",0,original
"The last important fact is that it is possible to demonstrate that (Ei,j) = k P(Ri,jT| ei,j) 1P(Ri,jT|ei,j) = = kodds(Ri,j) where k is a constant (see (Snow et al., 2006)) that will be neglected in the maximization process.",0,original
"Fortunately, there is a straightforward parallel between our object recognition formulation and the statistical machine translation problem of building a lexicon from an aligned bitext (Brown et al. , 1993; Al-Onaizan et al. , 1999).",0,original
"We first added sister-head dependencies for NPs (following Collinss (1997) original proposal) and then for PPs, which are flat in Negra, and thus similar in structure to NPs (see Section 2.2).",0,original
"Part-of-Speech (POS) annotation for example can be seen as the task of choosing the appropriate tag for a word from an ontology of word categories (compare for example the Penn Treebank POS tagset as described in (Marcus et al. , 1993)).",0,original
"More recently, Haffari and Sarkar (2007) have extended the work of Abney (2004) and given a better mathematical understanding of self-training algorithms.",0,original
"Therefore, we also carried out evaluations using the NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), WER (Hunt, 1989), PER (Tillmann et al., 1997) and TER (Snover et al., 2005) machine translation evaluation techniques.",0,original
"Nevertheless, in the problem described in this article, the source and the target sentences are given, and we are focusing on the optimization of the aligment a. The translation probability Pr(f,a|e) can be rewritten as follows: Pr(f,a|e) = Jproductdisplay j=1 Pr(fj,aj|fj11,aj11,eI1) = Jproductdisplay j=1 Pr(aj|fj11,aj11,eI1) Pr(fj|fj11,aj1,eI1) (2) The probability Pr(f,a|e) can be estimated by using the word-based IBM statistical alignment models (Brown et al. , 1993).",0,original
"4.2 Further practical issues of SCL In practice, there are more free parameters and model choices (Ando and Zhang, 2005; Ando, 2006; Blitzer et al., 2006; Blitzer, 2008) besides the ones discussed above.",0,original
"Work at the University of Dundee (e.g. , Aim et al, 1992; Todman and Alm, this volume) has shown that the extensive use of fixed text for sequences such as greetings and prestored narratives is beneficial in AAC.",0,original
"Instead of using Inversion Transduction Grammar (ITG) (Wu, 1997) directly, we will discuss an ITG extension to accommodate gapping.",0,original
"with parse action sequences for 40,000 Wall Street Journal sentences derived from the Penn Treebank (Marcus et al. , 1993).",0,original
"3.5 Anaphoricity Determination Finally, several coreference systems have successfully incorporated anaphoricity determination 660 modules (e.g. Ng and Cardie (2002a) and Bean and Riloff (2004)).",0,original
"(Koo and Collins, 2005; Matsuzaki et al. , 2005; Riezler et al. , 2002)).",0,original
"1 Introduction Sentiment classification is a special task of text categorization that aims to classify documents according to their opinion of, or sentiment toward a given subject (e.g., if an opinion is supported or not) (Pang et al., 2002).",0,original
"The rationale for using Kappa is explained in (Carletta, 1996).",0,original
"3 Related work Word collocation Various collocation metrics have been proposed, including mean and variance (Smadja, 1994), the t-test (Church et al. , 1991), the chi-square test, pointwise mutual information (MI) (Church and Hanks, 1990), and binomial loglikelihood ratio test (BLRT) (Dunning, 1993).",0,original
"S  S0,n Si,k  Si,j Sj,k Si1,i  pii Figure 1: A grammar for a large neighborhood of permutations, given one permutation pi of length n. The Si,k rules are instantiated for each 0  i < j < k  n, and the Si1,i rules for each 0 <in. We say that two permutations are neighbors iff they can be aligned by an Inversion Transduction Grammar (ITG) (Wu, 1997), which is a familiar reordering device in machine translation.",0,original
"The kappa statistic (Krippendorff, 1980; Carletta, 1996) has become the de facto standard to assess inter-annotator agreement.",0,original
"The classical Bayes relation is used to introduce a target language model (Brown et al. , 1993): e = argmaxe Pr(e|f) = argmaxe Pr(f|e)Pr(e) where Pr(f|e) is the translation model and Pr(e) is the target language model.",0,original
"Huang and Chiang (2007) searches with the full model, but makes assumptions about the the amount of reordering the language model can trigger in order to limit exploration.",0,original
The Penn Wall Street Journal treebank (Marcus et al. 1993) was used as training and test data.,0,original
"As with other randomised models we construct queries with the appropriate sanity checks to lower the error rate efficiently (Talbot and Brants, 2008).",0,original
"Thus, Nakagawa (2007) and Hall (2007) both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme.",0,original
Tillmann and Zhang (2006) avoided the problem by precomputing the oracle translations in advance.,0,original
"Based on annotation differences in the datasets (Dredze et al., 2007) and a bug in their system (Shimizu and Nakagawa, 2007), their results are inconclusive.",0,original
"The preprocessed training data was filtered for length and aligned using the GIZA++ implementation of IBM Model 4 (Och and Ney, 2003) in both directions and symmetrized using the grow-diag-final-and heuristic.",0,original
"The refined grammar is estimated using a variant of the forward-backward algorithm (Matsuzaki et al. , 2005).",0,original
"Word alignment models were first introduced in statistical machine translation (Brown et al. , 1993).",0,original
"Some of this work focuses on classifying the semantic orientation of individual words or phrases, using linguistic heuristics or a pre-selected set of seed words (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2002).",0,original
"In the similaritybased approaches (Dagan et al. , 1993 & 1994; Grishman et al. , 1993), rather than a class, each word is modelled by its own set of similar words derived from statistical data collected from corpora.",0,original
"1999), OpenCCG (White, 2004) and XLE (Crouch et al., 2007), or created semi-automatically (Belz, 2007), or fully automatically extracted from annotated corpora, like the HPSG (Nakanishi et al., 2005), LFG (Cahill and van Genabith, 2006; Hogan et al., 2007) and CCG (White et al., 2007) resources derived from the Penn-II Treebank (PTB) (Marcus et al., 1993).",0,original
"In his Xtract system, Smadja (1993) first extracted significant pairs of words that consistently co-occur within a single syntactic structure using statistical scores called distance, strength and spread, and then examined concordances of the bi-grams to find longer frequent multiword units.",0,original
"This second point is emphasized by the second paper on self-training for adaptation (McClosky et al., 2006b).",0,original
"1 Introduction Syntactic methods are an increasingly promising approach to statistical machine translation, being both algorithmically appealing (Melamed, 2004; Wu, 1997) and empirically successful (Chiang, 2005; Galley et al. , 2006).",0,original
"Compared to the Penn Treebank (PTB; Marcus et al. 1993), the POS tagset of the French Treebank is smaller (13 tags vs. 36 tags): all punctuation marks are represented as the single PONCT tag, there are no separate tags for modal verbs, whwords, and possessives.",0,original
"should appear with at most one value in each announcement, although the field and value may be repeated (Finkel et al. , 2005).",0,original
3.2.1 Proxy items There is a potential risk of redundancy if we represent related statistics using the log-frequency BF scheme presented in Talbot and Osborne (2007).,0,original
"For practical reasons, the maximum size of a token was set at three for Chinese, andfour forKorean.2 Minimum error rate training (Och, 2003) was run on each system afterwardsand BLEU score (Papineni et al., 2002) was calculated on the test sets.",0,original
"The application of this algorithm to the basic problem using a parallel bilingual corpus aligned on the sentence level is described in (Brown et al. , 1993).",0,original
"However, such methods require the existence of either a parallel corpus/machine translation engine for projecting/translating annotations/lexica from a resource-rich language to the target language (Banea et al., 2008; Wan, 2008), or a domain that is similar enough to the target domain (Blitzer et al., 2007).",0,original
Maximum Entropy models implement the intuition that the best model is the one that is consistent with the set of constraints imposed by the evidence but otherwise is as uniform as possible (Berger et al. 1996).,0,original
"2Note that sentence extraction does not solve the problem of selecting and ordering summary sentences to form a coherent There are several approaches to modeling document content: simple word frequency-based methods (Luhn, 1958; Nenkova and Vanderwende, 2005), graph-based approaches (Radev, 2004; Wan and Yang, 2006), as well as more linguistically motivated techniques (Mckeown et al., 1999; Leskovec et al., 2005; Harabagiu et al., 2007).",0,original
"An early exception to this was (Collins, 1997) itself, where Model 2 used function tags during the training process for heuristics to identify arguments (e.g. , the TMP tag on the NP in Figure 1 disqualifies the NP-TMP from being treated as an argument).",0,original
"The supervised component is Collins parser (Collins, 1997), trained on the Wall Street Journal.",0,original
"The most relevant to our work are Kazama and Torisawa (2007), Toral and Muoz (2006), and Cucerzan (2007).",0,original
"For detailed descriptions of SMT models see for example (Brown et al. , 1993; Och and Ney, 2003).",0,original
"1 Introduction In global linear models (GLMs) for structured prediction, (e.g., (Johnson et al., 1999; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003; Taskar et al., 2004)), the optimal label y for an input x is y = arg max yY(x) w f(x,y) (1) where Y(x) is the set of possible labels for the input x; f(x,y)  Rd is a feature vector that represents the pair (x,y); and w is a parameter vector.",0,original
Lin (1998) proposed a word similarity measure based on the distributio nal pattern of words which allows to construct a thesaurus using a parsed corpus.,0,original
"The boosting approach to ranking has been applied to named entity segmentation (Collins 2002a) and natural language generation (Walker, Rambow, and Rogati 2001).",0,original
"Following recent research about disambiguation models on linguistic grammars (Abney, 1997; Johnson et al. , 1999; Riezler et al. , 2002; Clark and Curran, 2003; Miyao et al. , 2003; Malouf and van Noord, 2004), we apply a log-linear model or maximum entropy model (Berger et al. , 1996) on HPSG derivations.",0,original
"Most previous work on paraphrase has focused on high quality rather than coverage (Barzilay and Lee, 2003; Quirk et al. , 2004), but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications.",0,original
"We used the Wall Street Journal (WSJ) part of the Penn Treebank (Marcus et al. , 1993), where extraction is represented by co-indexing an empty terminal element (henceforth EE) to its antecedent.",0,original
"The reader is referred to (Koehn and Hoang, 2007; Koehn et al., 2007) for detailed information about phrase-based statistical machine translation.",0,original
"Most current approaches emphasize within-sentence dependencies such as the distortion in (Brown et al. , 1993), the dependency of alignment in HMM (Vogel et al. , 1996), and syntax mappings in (Yamada and Knight, 2001).",0,original
"Also, we used Adwait Ratnaparkhis part-of-speech tagger (Ratnaparkhi, 1996) to tag unknown words in the test data.",0,original
Word Alignment Quality Metrics 3.1 Alignment Error Rate is Not a Useful Measure We begin our study of metrics for word alignment quality by testing AER (Och and Ney 2003).,0,original
"Previous work on linguistic annotation pipelines (Finkel et al., 2006; Hollingshead and Roark, 2007) has enforced consistency from one stage to the next.",0,original
"D. Hindle, Noun classification from predicate argument structures, in (ACL,1990).",0,original
"One is to find unknown words from corpora and put them into a dictionary (e.g. , (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g. , (Kashioka et al. , 1997; Nagata, 1999)).",0,original
"To quickly (and approximately) evaluate this phenomenon, we trained the statistical IBM wordalignment model 4 (Brown et al. , 1993),1 using the GIZA++ software (Och and Ney, 2003) for the following language pairs: ChineseEnglish, Italian English, and DutchEnglish, using the IWSLT-2006 corpus (Takezawa et al. , 2002; Paul, 2006) for the first two language pairs, and the Europarl corpus (Koehn, 2005) for the last one.",0,original
"We use the semi-supervised EMD algorithm (Fraser and Marcu, 2006b) to train the model.",0,original
"4 Experiment 4.1 Evaluation Method We evaluated each sentence compression method using word F-measures, bigram F-measures, and BLEU scores (Papineni et al. , 2002).",0,original
"Some studies exploit topically related articles derived from multiple news sources (Barzilay and Lee, 2003; Shinyama and Sekine, 2003; Quirk et al. , 2004; Dolan et al. , 2004).",0,original
An alternative representation for baseNPs has been put tbrward by Ramshaw and Marcus (1995).,0,original
"Finally, we compare against the mapping from WordNet to the Oxford English Dictionary constructed in (Navigli, 2006), equivalent to clustering based solely on the OED feature.",0,original
"1 Introduction Deep and accurate text analysis based on discriminative models is not yet efficient enough as a component of real-time applications, and it is inadequate to process Web-scale corpora for knowledge acquisition (Pantel, 2007; Saeger et al., 2009) or semi-supervised learning (McClosky et al., 2006; Spoustov et al., 2009).",0,original
"A total of 216 collocations were extracted, shown in Appendix A. We compared the collocations in Appendix A with the entries for the above 10 words in the NTC's English Idioms Dictionary (henceforth NTC-EID) (Spears and Kirkpatrick, 1993), which contains approximately 6000 definitions of idioms.",0,original
"Standard CI Model 1 training, initialised with a uniform translation table so that t(ejf) is constant for all source/target word pairs (f,e), was run on untagged data for 10 iterations in each direction (Brown et al., 1993; Deng and Byrne, 2005b).",0,original
"Ratnaparkhi, 1996), a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence.",0,original
"The tagger used is thus one that does not need tagged and disambiguated material to be trained on, namely the XPOST originally constructed at Xerox Parc (Cutting et al. 1992, Cutting and Pedersen 1993).",0,original
"c2008 Association for Computational Linguistics Refining Event Extraction through Cross-document Inference   Heng Ji Ralph Grishman Computer Science Department New York University New York, NY 10003, USA (hengji, grishman)@cs.nyu.edu       Abstract We apply the hypothesis of One Sense Per Discourse (Yarowsky, 1995) to information extraction (IE), and extend the scope of discourse from one single document to a cluster of topically-related documents.",0,original
The line search is an extension of that described in (Och 2003; Quirk et al. 2005.,0,original
"2 Related work Our approach for emotion classification is based on the idea of (Hatzivassiloglou and McKeown, 1997) and is similar to those of (Turney, 2002) and (Turney and Littman, 2003).",0,original
"6 Bracketing of Compound Nouns The first analysis task we consider is the syntactic disambiguation of compound nouns, which has received a fair amount of attention in the NLP literature (Pustejovsky et al. , 1993; Resnik, 1993; Lauer, 1995).",0,original
"Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction (Smadja, 1993; Fung and Wu, 1994), phrasal translation (Smadja et al. , 1996; Kupiec, 1993; Wu, 1995; Dagan and Church, 1994), target word selection (Liu and Li, 1997; Tanaka and Iwasaki, 1996), domain word translation (Fung and Lo, 1998; Fung, 1998), sense disambiguation (Brown et al. , 1991; Dagan et al. , 1991; Dagan and Itai, 1994; Gale et al. , 1992a; Gale et al. , 1992b; Gale et al. , 1992c; Shiitze, 1992; Gale et al. , 1993; Yarowsky, 1995), and even recently for query translation in cross-language IR as well (Ballesteros and Croft, 1998).",0,original
"As an alternative to linear interpolation, we also employ a weighted product for phrase-table combination: p(s|t)  productdisplay j pj(s|t)j (3) This has the same form used for log-linear training of SMT decoders (Och, 2003), which allows us to treateachdistributionasafeature,andlearnthemixing weights automatically.",0,original
"Restricting phrases to syntactic constituents has been shown to harm performance (Koehn et al., 2003), so we tighten our definition of a violation to disregard cases where the only point of overlap is obscured by our phrasal resolution.",0,original
" 00: the current input token and the previous one have the same parent  90: one ancestor of the current input token and the previous input token have the same parent  09: the current input token and one ancestor of the previous input token have the same parent  99 one ancestor of the current input token and one ancestor of the previous input token have the same parent Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus(1995)~, structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represents each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence.",0,original
"as follows: p(synI1|trgI1) = ( Iproductdisplay i=1 p(syni|trgi) (4)  pprime(trgi|syni)prime  pw(syni|trgi)w  pwprime(trgi|syni)wprime  pd(syni,trgi)d)  lw(synI1)l  c(synI1)c  pLM(synI1)LM For estimation of the feature weights vector defined in equation (4) we employed minimum error rate (MER) training under the BLEU measure (Och, 2003).",0,original
"3 Monolingual comparable corpus: Similar to the methods in (Shinyama et al., 2002; Barzilay and Lee, 2003), we construct a corpus of comparable documents from a large corpus D of news articles.",0,original
"5.1 Agreement between translators In an attempt to quantify the agreement between the two groups of translators, we computed the Kappa coefficient for annotation tasks, as defined by Carletta (1996).",0,original
"The underlying translation model is Model 2 from (Brown et al. , 1993).",0,original
"Smadja (1993) also detailed techniques for collocation extraction and developed a program called XTRACT, which is capable of computing flexible collocations based on elaborated statistical calculation.",0,original
"What, therefore, has to be explored are various similarity metrics, defining similarity in a concrete way and evaluate the results against human annotations (see Papineni et al. , 2002).",0,original
"We measure translation performance by the BLEU score (Papineni et al, 2002) with one reference for each hypothesis.",0,original
"The window size may vary, Church and Hanks (1990) used windows of size 2 and 5.",0,original
"Finally, our newly constructed parser, like that of (Collins 1997), was based on a generative statistical model.",0,original
"Monte Carlo sampling methods and Variational Bayes are two kinds of approximate inference methods that have been applied to Bayesian inference of unsupervised HMM POS taggers (Goldwater and Griffiths, 2007; Johnson, 2007).",0,original
"For instance, BLEU and ROUGE (Lin and Och, 2004) are based on n-gram precisions, METEOR (Banerjee and Lavie, 2005) and STM (Liu and Gildea, 2005) use word-class or structural information, Kauchak (2006) leverages on paraphrases, and TER (Snover et al., 2006) uses edit-distances.",0,original
"Recent research [Yamamoto et al. , 2001] shows that using different clusters for predicted and conditional words can lead to cluster models that are superior to classical cluster models, which use the same clusters for both words [Brown et al. , 1992].",0,original
"Its roots are the same as computational linguistics (CL), but it has been largely ignored in CL until recently (Dunning, 1993; Carletta, 1996; Kilgarriff, 1996).",0,original
"(2007) present a chart generator using wide-coverage PCFG-based LFG approximations automatically acquired from treebanks (Cahill et al., 2004).",0,original
"4 Related work Algorithms for retrieving collocations has been described (Smadja, 1993) (Haruno et al. , 1996).",0,original
"As resolving direct anaphoric descriptions (the ones where anaphor and antecedent have the same head noun) is a much simpler problem with high performance rates as shown in previous results (Vieira et al. , 2000; Bean and Riloff, 1999), these heuristics should be applied first in a system that resolves definite descriptions.",0,original
"ps(arc) is increased by 1110 1/(k+1) if the hypothesis ranking k in the system s contains the arc (Rosti et al., 2007a; He et al., 2008).",0,original
" Statistical Phrase-based Translation (Koehn et al. , 2003): Here phrase-based means subsequence-based, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases.",0,original
"For each differently tokenized corpus, we computed word alignments by a HMM translation model (Och and Ney, 2003) and by a word alignment refinement heuristic of grow-diagfinal (Koehn et al. , 2003).",0,original
"Either pruning (Stolcke, 1998; Church et al., 2007) or lossy randomizing approaches (Talbot and Brants, 2008) may result in a compact representation for the application run-time.",0,original
"At the same time, grammar theoreticians have proposed various generative synchronous grammar formalisms for MT, such as Synchronous Context Free Grammars (S-CFG) (Wu, 1997) or Synchronous Tree Adjoining Grammars (S-TAG) (Shieber and Schabes, 1990).",0,original
"(2006) develop a bottom-up decoder for BTG (Wu, 1997) that uses only phrase pairs.",0,original
"Then the alignments are symmetrized using a refined heuristic as described in (Och and Ney, 2003).",0,original
"Generally, two edges can be re-combined if they satisfy the following two constraints:  1) the LHS (left-hand side) nonterminals are identical and the sub-alignments are the same (Zhang et al., 2006); and 2) the boundary words 1  on both sides of the partial translations are equal between the two edges (Chiang, 2007).",0,original
"Accuracy on sentiment classification in other domains exceeds 80% (Turney, 2002).",0,original
"4.1 Data Sets Our results are based on syntactic data drawn from the Penn Treebank (Marcus et al., 1993), specifically the portion used by CoNLL 2000 shared task (Tjong Kim Sang and Buchholz, 2000).",0,original
"The f are optimized by Minimum-Error Training (MERT) (Och, 2003).",0,original
"Previous publications on Meteor (Lavie et al., 2004; Banerjee and Lavie, 2005; Lavie and Agarwal, 2007) have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics.",0,original
"Our statistical tagging model is adjusted from standard bi-grams using the Viterbi-search (Cutting et al. , 1992) plus on-the-fly extra computing of lexical probabilities for unknown morphemes.",0,original
"Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).",0,original
"Some researchers (Hindle, 1990; Grefenstette, 1994; Lin, 1998) classify terms by similarities based on their distributional syntactic patterns.",0,original
"In some cases, class (or part of speech) n-grams are used instead of word n-grams(Brown et al. , 1992; Chang and Chen, 1996).",0,original
"As in (Rosti et al., 2007), confusion networks built around all skeletons are joined into a lattice which is expanded and rescored with language models.",0,original
He used the Ramshaw and Marcus (1995) representation as well (IOB1).,0,original
"Most of the annotation approaches tackling these issues, however, are aimed at performing classifications at either the document level (Pang et al. , 2002; Turney, 2002), or the sentence or word level (Wiebe et al. , 2004; Yu and Hatzivassiloglou, 2003).",0,original
"Even for semantically predictable phrases, the fact that the words occur in fixed patterns can be very useful for the purposes of disambiguation, as demonstrated by (Yarowsky, 1995).",0,original
"Evaluating the algorithm on the output of Charniaks parser (Charniak, 2000) and the Penn treebank (Marcus et al. , 1993) shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.",0,original
"The sentences were processed with the Collins parser (Collins, 1997) to generate automatic parse trees.",0,original
" Most existing work to capture labelconsistency, has attempted to create all parenleftbign2parenrightbig pairwise dependencies between the different occurrences of an entity, (Finkel et al. , 2005; Sutton and McCallum, 2004), where n is the number of occurrences of the given entity.",0,original
"In this paper we adopt a maximum entropy model (Berger et al. , 1996) to estimate the local probabilities a28 a14 a1 a25 a19a1 a25a30a29 a2 a9a22a21 since it can incorporate diverse types of features with reasonable computational cost.",0,original
"We have (11) Hypernym Patterns based on patterns proposed by (Hearst, 1992) and (Snow et al., 2005), (12) Sibling Patterns which are basically conjunctions, and (13) Part-of Patterns based on patterns proposed by (Girju et al., 2003) and (Cimiano and Wenderoth, 2007).",0,original
(1993) study the shortest hyperpath problem and Nielsen et al.,0,original
"It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (Koehn et al. , 2003).",0,original
"In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993).",0,original
"It has shown promise in improving the performance of many tasks such as name tagging (Miller et al. , 2004), semantic class extraction (Lin et al. , 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004) and text classification (Blum and Mitchell, 1998).",0,original
"The two systems we use are ENGCG (Karlsson et al. , 1994) and the Xerox Tagger (Cutting et al. , 1992).",0,original
The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks 1990; Zernik and Jacobs 1990; Hindle 1990; Smadja 1993).,0,original
"(Galley, 2006) considered some location constrains in meeting summarization evaluation, which utilizes speaker information to some extent.",0,original
"Hindle uses the observed frequencies within a specific syntactic pattern (subject/verb, and verb/object) to derive a cooccu,> rence score which is an estimate of mutual information (Church and Hanks, 1990).",0,original
"Finally, Section 4 reports the results of parsing experiments using our exhaustive k-best CYK parser with the concise PCFGs induced from the Penn WSJ treebank (Marcus et al. , 1993).",0,original
"The parameters, j, were trained using minimum error rate training (Och, 2003) to maximise the BLEU score (Papineni et al. , 2002) on a 150 sentence development set.",0,original
"Dependency relations are produced using a version of the Collins parser (Collins, 1997) that has been adapted for building dependencies.",0,original
"9.1 Training Methodology Given a training set, we first run a variant of IBM alignment model 1 (Brown et al., 1993) for 100 iterations, and then initialize Model I with the learned parameter values.",0,original
"This idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs has its roots in the BLEU metric for machine translation (Papineni et al. , 2002) and the ROUGE (Lin and Hovy, 2003) metric for summarization.",0,original
"A similar view underlies the class-based methods cited in Section 2.4.3 (Brown et al. 1992; Pereira and Tishby 1992; Pereira, Tishby, and Lee 1993).",0,original
"Pivots are features occurring frequently and behaving similarly in both domains (Blitzer et al., 2006).",0,original
"Movie and product reviews have been the main focus of many of the recent studies in this area (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002).",0,original
"Currently, the scheme supports PhraseChunks with subtypes such as NP, VP, PP, or ADJP (Marcus et al. , 1993).",0,original
ROUGE-LCS calculated the longest common 2 Details of our official DUC 2004 headline generation system can be found in Doran et al.,0,original
"4.1 NER features We used the features generated by the CRF package (Finkel et al., 2005).",0,original
"Introduction Recently, there has been an increased interest in approaches to automatically learning to recognize shallow linguistic patterns in text \[Ramshaw and Marcus, 1995, Vilain and Day, 1996, Argamon et al. , 1998, Buchholz, 1998, Cardie and Pierce, 1998, Veenstra, 1998, Daelemans et aI.",0,original
"The toolkit also implements suffix-array grammar extraction (Lopez, 2007) and minimum error rate training (Och, 2003).",0,original
"This is exactly the standard lexicon probability a27a28a18a26a4 a20a12 a22 employed in the translation model described in (Brown et al. , 1993) and in Section 2.",0,original
"Models of that form include hidden Markov models (Rabiner, 1989; Bikel et al. , 1999) as well as discriminative tagging models based on maximum entropy classification (Ratnaparkhi, 1996; McCallum et al. , 2000), conditional random fields (Lafferty et al. , 2001; Sha and Pereira, 2003), and large-margin techniques (Kudo and Matsumoto, 2001; Taskar et al. , 2003).",0,original
"It has been shown by Shapiro and Stephens (1991) and Wu (1997, Sec.",0,original
"Perhaps the most widely accepted convention is that of ignoring punctuation for the purposes of assigning constituent span, under the perspective that, fun788 Phrase Evaluation Scenario System Type (a) (b) (c) Modified All 98.37 99.72 99.72 Truth VP 92.14 98.70 98.70 Li and Roth All 94.64 (2001) VP 95.28 Collins (1997) All 92.16 93.42 94.28 VP 88.15 94.31 94.42 Charniak All 93.88 95.15 95.32 (2000) VP 88.92 95.11 95.19 Table 1: F-measure shallow bracketing accuracy under three different evaluation scenarios: (a) baseline, used in Li and Roth (2001), with original chunklink script converting treebank trees and context-free parser output; (b) same as (a), except that empty subject NPs are inserted into every unary SVP production; and (c) same as (b), except that punctuation is ignored for setting constituent span.",0,original
"The recurrence property had been utilized to extract keywords or key-phrases from text (Chien 1999, Fung 1998, Smadja 1993).",0,original
"Some of the differences between our approach and those of Turney (2002) are mentioned below: ??objectives: Turney (2002) aims at binary text classification, while our objective is six class classification of one-liner headlines.",0,original
"(owenOcogentex.com) 1 Introduction Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesni~re's work from the thirties3 Recently, it has gained renewed attention as empirical methods in parsing are discovering the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly do, but context-free phrasestructure grammars do not.",0,original
"The first is identifying words and phrases that are associated with subjectivity, for example, that think is associated with private states and that beautiful is associated with positive sentiments (e.g. , (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Kamps and Marx, 2002; Turney, 2002; Esuli and Sebastiani, 2005)).",0,original
"We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000).",0,original
"In the experiment, only the first 500 sentences were used to train the log-linear model weight vector, where minimum error rate (MER) training was used (Och, 2003).",0,original
"3.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy (Berger et al. , 1996) model.",0,original
5 Translation performance was measured using the automatic BLEU evaluation metric (Papineni et al. 2002) on four reference translations.,0,original
The algorithm proposed by Turney (2008) is labeled as Turney-PairClass.,0,original
"Clustering-based approaches usually represent word contexts as vectors and cluster words based on similarities of the vectors (Brown et al., 1992; Lin, 1998).",0,original
"The resulting intercoder reliability, measured with the Kappa statistic(Carletta,1996), is considered excellent (= 0.80).",0,original
"The model cleanly incorporates both syntax and lexical semantics using quasi-synchronous dependency grammars (Smith and Eisner, 2006).",0,original
"Negation was processed in a similar way as previous works (Pang et al. , 2002).",0,original
"We extracted tagged sentences from the parse trees.5 We split the data into training, development, and test sets as in (Collins, 2002).",0,original
"Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files (Miller et al. , 1993), we have counted the occurrences of content words which previously appear in the same discourse file.",0,original
"However, in the experiments described here, we focus on alignment at the level of sentences, this for a number of reasons: First, sentence alignments have so far proven their usefulness in a number of applications, e.g. bilingual lexicography (Langlois, 1996; Klavans and Tzoukermann, 1995; Dagan and Church, 1994), automatic translation verification (Macklovitch, 1995; Macklovitch, 1996) and the automatic acquisition of knowledge about translation (Brown et al. , 1993).",0,original
"It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (Cohen, 2004; Kazama and Torisawa, 2007a; Toral and Munoz, 2006; Florian et al., 2003).",0,original
"However, because these estimates are too sparse to be relied upon, we use interpolated estimates consisting of mixtures of successively lowerorder estimates (as in Placeway et al. 1993).",0,original
"Bilingual configurations that condition on tprime,wprime (2) are incorporated into the generative process as in Smith and Eisner (2006a).",0,original
Och and Ney (2003) state that AER is derived from F-Measure.,0,original
"The tool set for TEA is constantly being extended, recent additions include a prototype symbolic classifier, shallow parser (Choi, Forthcoming), sentence segmentation algorithm (Reynar and Ratnaparkhi, 1997) and a POS tagger (Ratnaparkhi, 1996).",0,original
"A large corpus is vahmble as a source of such nouns (Church and Hanks, 1990; Brown et al. , 1992).",0,original
The benefits of using grammatical information for automatic WSD were first explored by Yarowsky (1995) and Resnik (1996) in unsupervised approaches to disambiguating single words in context.,0,original
"The model weights of the transducer are tuned based on the development set using a grid-based line search, and the translation results are evaluated based on a single Chinese reference6 using BLEU-4 (Papineni et al., 2002).",0,original
Note that the algorithm from Collins (2002) was designed for discriminatively training an HMM-style tagger.,0,original
"part-of-speech language model  We use factored translation models (Koehn and Hoang, 2007) to also output part-of-speech tags with each word in a single phrase mapping and run a second n-gram model over them.",0,original
Therefore in Collins (1997) grammar rules are already factorized into a set of probabilities.,0,original
"Much of the work in sentiment analysis in the computational linguistics domain has focused either on short segments, such as sentences (Wilson et al. , 2005), or on longer documents with an explicit polarity orientation like movie or product reviews (Turney, 2002).",0,original
"Collins and Koo Discriminative Reranking for NLP Della Pietra 1996; Della Pietra, Della Pietra, and Lafferty 1997), or conjugate gradient methods (Malouf 2002).",0,original
"We describe the experiment in greater detail 2The particular verbs selected were looked up in (Levin, 1993) and the class for each verb in the classification system defined in (Stevenson and Merlo, 1997) was selected with some discussion with linguists.",0,original
"2.2 The Choice of Co-occurrence ~qeasure and Matrix Distance There :~:c many alternatives to measure cooccurrence between two words x and y (Church, 1990; Dunning, 1993).",0,original
"We compare system performance between (Snow et al., 2006) and our framework in Section 5.",0,original
Haghighi and Klein (2006) use a small list of labeled prototypes and no dictionary.,0,original
"Tuning was done using Maximum BLEU hill-climbing (Och, 2003).",0,original
"We argue that linguistic knowledge could not only improve results (Krenn, 2000b; Smadja, 1993) but is essential when extracting collocations from certain languages: this knowledge provides other applications (or a lexicon user, respectively) with a ne-grained description of how the extracted collocations are to be used in context.",0,original
"Then P(eI1jfj1) = summationtextaI 1 P(eI1,aI1jfj1) (Brown et al., 1993).",0,original
"Much of this work has utilized the fundamental concept of semantic orientation, (Turney, 2002); however, sentiment analysis still lacks a unified field theory.",0,original
"The latter problem of developing methods that can work with incomplete supervisory information is addressed in a subsequent effort (Stoyanov and Cardie, 2006).",0,original
"The decision rule was based on the standard loglinear interpolation of several models, with weights tunedbyMERTonthedevelopmentset(Och,2003).",0,original
"The translation model used in (Koehn et al. , 2003) is the product of translation probability a34a35a4 a29 a0 a33 a6 a29 a2 a33 a8 and distortion probability a36a37a4a39a38 a33a41a40a43a42a44a33a46a45 a32 a8, a3a5a4a35a29 a0 a30 a32 a6 a29 a2 a30 a32 a8 a10 a30 a47 a33a49a48 a32 a34a35a4 a29 a0a22a33 a6 a29 a2 a33a50a8 a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 (1) where a38 a33 denotes the start position of the source phrase translated into the a54 -th target phrase, and a42 a33a53a45 a32 denotes the end position of the source phrase translated into the a4a53a54 a40a56a55 a8 -th target phrase.",0,original
"Berry et al (1993)) to yield W  W = U  S  V T as Figure 3 shows, where, for some order R lessmuch min(M,N) of the decomposition, U is a MR left singular matrix with rows ui, i = 1,,M, S is a RR diagonal matrix of singular values s1  s2    sR greatermuch 0, and V is NR a right singular matrix with rows vj, j = 1,,N. For each i, the scaled R-vector uiS may be viewed as representing wi, thei-th word in the vocabulary, and similarly the scaled R-vector vjS as representing dj, j-th document in the corpus.",0,original
"Following Hatzivassiloglou and McKeown (1997) and Turney (2002), we decided to observe how often the words from the headline co-occur with each one of the six emotions.",0,original
The preliminary labeling by keyword matching used in this paper is similar to the seed collocations used by Yarowsky (1995).,0,original
"Statistical techniques, both supervised learning from tagged corpora (Yarowsky, 1992), (Ng and Lee, 1.996), and unsupervised learning (Yarowsky, 1995), (Resnik, 1997), have been investigated.",0,original
"This curve plots the average labeled attachment score over Basque, Chinese, English, and Turkish as a function of parsing time per token.4 Accuracy of only 1% below the maximum can be achieved with average processing time of 17 ms per token, or 60 tokens per second.5 We also refer the reader to (Titov and Henderson, 2007b) for more detailed analysis of the ISBN dependency parser results, where, among other things, it was shown that the ISBN model is especially accurate at modeling long dependencies.",0,original
"2.3.4 Word Translation Probability Estimation Many methods are used to estimate word translation probabilities from unparallel or parallel bilingual corpora (Koehn and Knight, 2000; Brown et al. , 1993).",0,original
"Independently, in AI an effort arose to encode large amounts of commonsense knowledge (Hayes, 1979; Hobbs and Moore, 1985; Hobbs et al. 1985).",0,original
"The only trainable approaches (known to the author) to surface generation are the purely statistical machine translation (MT) systems such as (Berger et al. , 1996) and the corpus-based generation system described in (Langkilde and Knight, 1998).",0,original
"In paraphrase generation, a text unit that matches a pattern P can be rewritten using the paraphrase patterns of P. Avarietyofmethodshavebeenproposedonparaphrase patterns extraction (Lin and Pantel, 2001; Ravichandran and Hovy, 2002; Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003; Pang et al., 2003; Szpektor et al., 2004).",0,original
The cube-pruning by Chiang (2007) and the lazy cube-pruning of Huang and Chiang (2007) turn the computation of beam pruning of CYK decoders into a top-k selection problem given two columns of translation hypotheses that need to be combined.,0,original
")|(maxarg* STPT T = (1) Then we assume that the tagging of one character is independent of each other, and modify formula 1 as  == = = = n i ii tttT nn tttT ctP ccctttPT n n 1 2121 * )|(maxarg )|(maxarg 21 21 (2) Beam search (n=3) (Ratnaparkhi,1996) is applied for tag sequence searching, but we only search the valid sequences to ensure the validity of searching result.",0,original
"One approach here is that of Wu (1997), in which word-movement is modeled by rotations at unlabeled, binary-branching nodes.",0,original
"Two are conditionalized phrasal models, each EM trained until performance degrades:  C-JPTM3 as described in (Birch et al. , 2006)  Phrasal ITG as described in Section 4.1 Three provide alignments for the surface heuristic:  GIZA++ with grow-diag-final (GDF)  Viterbi Phrasal ITG with and without the noncompositional constraint We use the Pharaoh decoder (Koehn et al. , 2003) with the SMT Shared Task baseline system (Koehn and Monz, 2006).",0,original
"Translation quality is reported using case-insensitive BLEU (Papineni et al., 2002).",0,original
"(Chiang, 2005) (Imamura et al., 2004) (Galley et al., 2004).",0,original
"The concept of mutual information, taken from information theory, was proposed as a measure of word association (Church 1990; ""Jelinek et al. 1990,1992; Dagan, 1995;).",0,original
"1 Introduction Syntax-based translation models (Eisner, 2003; Galley et al. , 2006; Marcu et al. , 2006) are usually built directly from Penn Treebank (PTB) (Marcus et al. , 1993) style parse trees by composing treebank grammar rules.",0,original
"1 Motivation Most of the noisy-channel-based models used in statistical machine translation (MT) (Brown et al. , 1993) are conditional probability models.",0,original
"The recent emphasis on improving these components of a translation system (Brants et al., 2007) is likely due in part to the widespread availability of NLP tools for the language that is most frequently the target: English.",0,original
"1 Introduction Maximum Entropy (ME) modeling has received a lot of attention in language modeling and natural language processing for the past few years (e.g. , Rosenfeld, 1994; Berger et al 1996; Ratnaparkhi, 1998; Koeling, 2000).",0,original
"4 Training This section discusses how to extract our translation rules given a triple nullnull,null null ,nullnull . As we know, the traditional tree-to-string rules can be easily extracted from nullnull,null null ,nullnull  using the algorithm of Mi and Huang (2008) 2 . We would like  2  Mi and Huang (2008) extend the tree-based rule extraction algorithm (Galley et al., 2004) to forest-based by introducing non-deterministic mechanism.",0,original
"For the efficiency of minimum-errorrate training (Och, 2003), we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data.",0,original
"6 Related Work As suggested in (Och, 2003), an alternative method for the optimization of the unsmoothed error count is Powells algorithm combined with a grid-based line optimization (Press et al., 2007, p. 509).",0,original
"1 Introduction During the last decade, statistical machine translation (SMT) systems have evolved from the original word-based approach (Brown et al. , 1993) into phrase-based translation systems (Koehn et al. , 2003).",0,original
"We perform minimum-error-rate training (Och, 2003) to tune the feature weights of the translation model to maximize the BLEU score on development set.",0,original
"2 Translation Model The algorithm for fast translation, which has been described previously in some detail (McCarley and Roukos, 1998) and used with considerable success in TREC (Franz et al. , 1999), is a descendent of IBM Model 1 (Brown et al. , 1993).",0,original
"Two main approaches have generally been considered: rule-based (Klein and Simmons 1963; Brodda 1982; Paulussen and Martin 1992; Brill et al. 1990) probabilistic (Bahl and Mercer 1976; Debili 1977; Stolz, Tannenbaum, and Carstensen 1965; Marshall 1983; Leech, Garside, and Atwell 1983; Derouault and Merialdo 1986; DeRose 1988; Church 1989; Beale 1988; Marcken 1990; Merialdo 1991; Cutting et al. 1992).",0,original
"Dredze et al. yielded the second highest score1 in the domain adaptation track (Dredze et al., 2007).",0,original
"For instance, some approaches coarsely discriminate between biographical and non-biographical information (Zhou et al., 2004; Biadsyetal.,2008),whileothersgobeyondbinary distinction by identifying atomic events  e.g., occupation and marital status  that are typically included in a biography (Weischedel et al., 2004; Filatova and Prager, 2005; Filatova et al., 2006).",0,original
"We utilise the automatic annotation algorithm of (Cahill et al. , 2004b) to derive a version of Penn-II where each node in each tree is annotated with an LFG functional annotation (i.e. an attribute value structure equation).",0,original
"4 Semantic Class Induction from Wikipedia Wikipedia has recently been used as a knowledge source for various language processing tasks, including taxonomy construction (Ponzetto and Strube, 2007a), coreference resolution (Ponzetto and Strube, 2007b), and English NER (e.g., Bunescu and Pasca (2006), Cucerzan (2007), Kazama and Torisawa (2007), Watanabe et al.",0,original
"Previous work from (Wang et al. , 1996) showed improvements in perplexity-oriented measures using mixture-based translation lexicon (Brown et al. , 1993).",0,original
"We also report on applying Factored Translation Models (Koehn and Hoang, 2007) for English-to-Arabic translation.",0,original
"Semantic DSN: The construction of this network is inspired by (Lin, 1998).",0,original
"We might find better suited metrics, such as METEOR (Banerjee and Lavie, 2005), which is oriented towards word selection8.",0,original
"We employ loglinear models (Berger et al. , 1996) for the disambiguation.",0,original
"This was a difcult challenge as many participants in the task failed to obtain any meaningful gains from unlabeled data (Dredze et al., 2007).",0,original
"Translation results are given in terms of the automaticBLEUevaluation metric (Papineni et al., 2002) as well as the TER metric (Snover et al., 2006).",0,original
"These methods have been used in machine translation (Brown et al. , 1990; Sadler, 1989), terminology research and translation aids (Isabelle, 1992; Ogden and Gonzales, 1993), bilingual lexicography (Klavans and Tzoukermann, 1990), collocation studies (Smadja, 1992), word-sense disambiguation (Brown et al. , 1991b; Gale et al. , 1992) and information retrieval in a multilingual environment (Landauer and Littman, 1990).",0,original
"To identify conjunctions, lists, and appositives, we first parsed the corpus, using an efficient statistical parser (Charniak et al. , 1998), trMned on the Penn Wall Street Journal Treebank (Marcus et al. , 1993).",0,original
"One way of obtaining a suitable granularity of nodes is to introduce latent classes, such as the Semi-Markov class model (Okanohara and Tsujii, 2007).",0,original
"Similar to BLEU score, we also use the similar Brevity Penalty BP (Papineni et al., 2002) to penalize the short translations in computing RAcc.",0,original
"1 Introduction Bilingual data (including bilingual sentences and bilingual terms) are critical resources for building many applications, such as machine translation (Brown, 1993) and cross language information retrieval (Nie et al., 1999).",0,original
"The original Ramshaw and Marcus (1995) publication evaluated their NP chunker on two data sets, the second holding a larger amount of training data (Penn Treebank sections 02-21) while using 00 as test data.",0,original
"(1993b), this model is symmetric, because both word bags are generated together from a joint probability distribution.",0,original
"To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al. 2005), and word similarity lists (Hindle 1990).",0,original
"The noun phrases in this data set are the same as in the Treebank and therefore the baseNPs in this data set are slightly different from the ones in the (Ramshaw and Marcus, 1995) data sets.",0,original
"In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al. , 2000; Akiba et al. , 2001; Papineni et al. , 2002; NIST, 2002; Leusch et al. , 2003; Turian et al. , 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gimenez et al. , 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently.",0,original
"In order to incorporate a new dependency which contains extra information other than the bilingual sentence pair, we modify Eq.2 by adding a new variable v: Pr(a|e,f,v) = exp[ summationtextM m=1 mhm(a,e,f,v)]summationtext aprime exp[ summationtextM m=1 mhm(aprime,e,f,v)](4) Accordingly, we get a new decision rule: a = argmax a braceleftbigg Msummationdisplay m=1 mhm(a,e,f,v) bracerightbigg (5) Note that our log-linear models are different from Model 6 proposed by Och and Ney (2003), which defines the alignment problem as finding the alignment a that maximizes Pr(f, a|e) given e. 3 Feature Functions In this paper, we use IBM translation Model 3 as the base feature of our log-linear models.",0,original
"This sparse information, however, can be propagated across all data based on distributional similarity (Haghighi and Klein, 2006).",0,original
"For Penn Treebank II style annotation (Marcus et al. , 1993), in which a nonterminal symbol is a category together with zero or more functional tags, we adopt the following scheme: the atomic pattern a matches any label with category a or functional tag a; moreover, we define Boolean operators^,_, and:.",0,original
"The probabilities from these back-off levels are interpolated using the techniques in (Collins, 1997).",0,original
"In this work, we use the prototype lists originally defined by Haghighi and Klein (2006) (HK06) and subsequently used by Chang et al.",0,original
"Previous approaches for training CRFs have either (1) opted for a training method that no longer maximizes the likelihood, (e.g. McCallum and Wellner (2004), Roth and Yih (2005)) 1, or (2) opted for a 1 Both McCallum and Wellner (2004) and Roth and Yih (2005) used the voted perceptron algorithm (Collins, 2002) to train intractable CRFs.",0,original
"3.1 Phrase-Based Models According to the translation model presented in (Koehn et al. , 2003), given a source sentence f, the best target translation can be obtained using the following model best e 288 )( )()(maxarg )(maxarg | | e e e eef fee length LM best pp p = = (1) Where the translation model can be decomposed into )( | efp  =  = I i i iii i i II aefpbadef efp 1 1 1 1 ),|()()|( )|(   w (2) Where )|( i i ef is the phrase translation probability.",0,original
This feature is implemented by using the IBM-1 lexical parameters (Brown et al. 1993; Och et al. 2004).,0,original
The cohesion between two words is measured as in Church and Hanks (1990) by an estimation of the mutual information based on their collocation frequency.,0,original
"Pointwise mutual information (Fano, 1961) was used to measure strength of selection restrictions for instance by Church and Hanks (1990).",0,original
"1 Introduction Current methods for large-scale information extraction take advantage of unstructured text available from either Web documents (Banko et al., 2007; Snow et al., 2006) or, more recently, logs of Web search queries (Pasca, 2007) to acquire useful knowledge with minimal supervision.",0,original
"These wordbased models are used to find the latent wordalignments between bilingual sentence pairs, from which a weighted string transducer can be induced (either finite state (Koehn et al., 2003) or synchronous context free grammar (Chiang, 2007)).",0,original
"The annotation can be considered reliable (Krippendorff, 1980) with 95% agreement and a kappa (Carletta, 1996) of.88.",0,original
"a1 Graduated in March 2006 Standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (Koehn et al. , 2003; Och and Ney, 2004).",0,original
"Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn  et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008).",0,original
"Our work expands on the general approach taken by (DeNero et al., 2006; Moore and Quirk, 2007) but arrives at insights similar to those of the most recent work (Zhang et al., 2006), albeit in a completely different manner.",0,original
"(2005), Kim and Hovy (2006)), source extraction (e.g. Bethard et al.",0,original
"This can be done by smoothing the observed frequencies 7 (Church and Mercer 1993) or by class-based methods (Brown et al. 1991; Pereira and Tishby 1992; Pereira, Tishby, and Lee 1993; Hirschman 1986; Resnik 1992; Brill et al. 1990; Dagan, Marcus, and Markovitch 1993).",0,original
"Practically, the grammar relaxation is done via the introduction of non-standard CCG rules (Zettlemoyer and Collins, 2007).",0,original
"Decoding used beam search with the cube pruning algorithm (Huang and Chiang, 2007).",0,original
"Work on learning with hidden variables can be used for both CRFs (Quattoni et al. , 2004) and for inference based learning algorithms like those used in this work (Liang et al. , 2006).",0,original
"Jiao et al. propose semi-supervised conditional random fields (Jiao et al., 2006) that try to maximize the conditional log-likelihood on the training data and simultaneously minimize the conditional entropy of the class labels on the unlabeled data.",0,original
"Following Church and Hanks (1990), they use mutual information to select significant two-word patterns, but, at the same time, a lexical inductive process is incorporated which, as they claim, can improve the collection of domain-specific terms.",0,original
"In the first, a separate language model is trained on each column of the database and these models are then used to segment and label a given text sequence (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007).",0,original
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan & Brockett, 2004) and word N-gram overlap for (Barzilay & Lee, 2003).",0,original
"This criticism leads us to automatic approaches for building thesauri from large corpora \[Hirschman et al. , 1975; Hindle, 1990; Hatzivassiloglou and McKeown, 1993; Pereira et al. , 1993; Tokunaga et aL, 1995; Ushioda, 1996\].",0,original
"It can be proven that the probability distribution p satisfying the above assumption is the one with the highest entropy, is unique and has the following expone ntial form (Berger et al. 1996): (1)  = = k j cajf jcZcap 1 ),( )( 1)|( a where Z(c) is a normalization factor, fj(a,c) are the values of k features of the pair (a,c) and correspond to the linguistic cues of c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy.",0,original
"The supervised training described in (Collins, 2002) uses manually annotated data for the estimation of the weight coefficients .",0,original
"However, there is little agreement on what types of knowledge are helpful: Some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in Meteor (Banerjee and Lavie, 2005) or MaxSim (Chan and Ng, 2008).",0,original
"Classes can be induced directly from the corpus (Pereira et al. , 1993; Brown et al. , 1992) or taken from a manually crafted taxonomy (Resnik, 1993).",0,original
"We participated in the multilingual track of the CoNLL 2007 shared task (Nivre et al. , 2007), and evaluated the system on data sets of 10 languages (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003).",0,original
Notice that most in-context and dictionary translations of source words are bounded within the same category in a typical thesaurus such as the LLOCE (McArthur 1992) and CILIN (Mei et al. 1993).,0,original
"For these first SMT systems, translation-model probabilities at the sentence level were approximated from word-based translation models that were trained by using bilingual corpora (Brown et al. 1993).",0,original
"Given a set of terms with unknown sentiment orientation, Turney (2002) then uses the PMI-IR algorithm (Turney 2001) to issue queries to the web and determine, for each of these terms, its pointwise mutual information (PMI) with the two seed words across a large set of documents.",0,original
"1 Introduction Several recent syntax-based models for machine translation (Chiang, 2005; Galley et al. , 2004) can be seen as instances of the general framework of synchronous grammars and tree transducers.",0,original
"Log-likelihood ratio (G2) (Dunning, 1993) with respect to a large reference corpus, Web 1T 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns.",0,original
"We use MXPOST tagger (Adwait, 1996) for POS tagging, Charniak parser (Charniak, 2000) for extracting syntactic relations, and David Blei?s version of LDA1 for LDA training and inference.",0,original
"Our test set is 3718 sentences from the English Penn treebank (Marcus et al., 1993) which were translated into German.",0,original
"The NP chunks in the shared task data are base-NP chunks  which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995).",0,original
"Our results on Chinese data confirm previous findings on English data shown in (McClosky et al., 2006a; Reichart and Rappoport, 2007).",0,original
"5 Results and Discussion The system with online learning and Nivres parsing algorithm was trained on the data released by CoNLL Shared Task Organizers for all the ten languages (Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003).",0,original
"Hyperparameter  is automatically selected from 2Although Kanayama and Nasukawa (2006) that  for their dataset similar to ours was 0.83, this value cannot be directly compared with our value because their dataset includes both individual words and pairs of words.",0,original
"5 Related Work There has not been much previous work on graphical models for full parsing, although recently several latent variable models for parsing have been proposed (Koo and Collins, 2005; Matsuzaki et al. , 2005; Riezler et al. , 2002).",0,original
"Consider the lexical model pw(ry|rx), defined following Koehn et al (2003), with a denoting the most frequent word alignment observed for the rule in the training set.",0,original
"The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it.",0,original
"109 machine translation evaluation (e.g., Banerjee and Lavie, 2005; Lin and Och, 2004),paraphraserecognition (e.g., Brockett and Dolan, 2005; Hatzivassiloglou et al., 1999), and automatic grading (e.g., Leacock,2004;Marn, 2004).",0,original
"Many methods for calculating the similarity have been proposed (Niessen et al. , 2000; Akiba et al. , 2001; Papineni et al. , 2002; NIST, 2002; Leusch et al. , 2003; Turian et al. , 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gimenez et al. , 2005).",0,original
"2 Statistical Machine Translation We use a log-linear approach (Och, 2003) in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: e = argmax e wT h( f, e) (1) where h( f, e) is a large-dimension feature vector.",0,original
"A broad view of the possible scope of lexical semantics would thus be one which tries to chart out the systematic, generalizable aspects of word meanings, and of the relations between words, drawing on readily accessible sources of lexical knowledge, such as machine readable dictionaries, encyclopedias, and representative corpora, coupled with the kind of analytic apparatus that is needed to fruitfully explore such sources, for instance custom-built parsers to cope with dictionary definitions (Vossen 1990), statistical programs to deal with the distributional properties of lexical items in large corpora (Church & Hanks 1990) etc. At the same time this kind of massive data-acquisition should be made sensitive to the borders between perceptual experience, lexical knowledge and expert knowledge.",0,original
"Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval (Nie et al., 1999; Monz and Dorr, 2005), cross-language text classification (Gliozzo and Strapparava, 2006), lexical choice in machine translation (Och and Ney, 2000; Bangalore et al., 2007), induction of translation lexicons (Schafer and Yarowsky, 2002), cross-language annotation and resource projections to a second language (Riloff et al., 2002; Hwa et al., 2002; Mohammad et al., 2007).",0,original
"Moreover, this evaluation concern dovetails with a frequent engineering concern, that sentence-level scores are useful at various points in the MT pipeline: for example, minimum Bayes risk decoding (Kumar and Byrne, 2004), selecting oracle translations for discriminative reranking (Liang 614 et al., 2006; Watanabe et al., 2007), and sentenceby-sentence comparisons of outputs during error analysis.",0,original
"Between these two extremes, there has been a relatively modest amount of work in sentence simplification (Chandrasekar, Doran, and Bangalore 1996; Mahesh 1997; Carroll et al. 1998; Grefenstette 1998; Jing 2000; Knight and Marcu 2002) and document compression (Daume III and Marcu 2002; Daume III and Marcu 2004; Zajic, Dorr, and Schwartz 2004) in which words, phrases, and sentences are selected in an extraction process.",0,original
"Our focus is on the sentence level, unlike (Pang et al. , 2002) and (Turney, 2002); we employ a significantly larger set of seed words, and we explore as indicators of orientation words from syntactic classes other than adjectives (nouns, verbs, and adverbs).",0,original
"Ranking algorithms, such as Kleinbergs HITS algorithm (Kleinberg, 1999) or Googles PageRank (Brin and Page, 1998), have been traditionally and successfully used in Web-link analysis (Brin and Page, 1998), social networks, and more recently in text processing applications (Mihalcea and Tarau, 2004), (Mihalcea et al. , 2004), (Erkan and Radev, 2004).",0,original
"Three recent papers in this area are Church and Hanks (1990), Hindle (1990), and Smadja and McKeown (1990).",0,original
"Similarly, if the task is to distinguish between binary, coarse sense distinction, then current WSD techniques can achieve very high accuracy (in excess of 96% when tested on a dozen words in (Yarowsky, 1995)).",0,original
"There are also automatic methods for summary evaluation, such as ROUGE (Lin, 2004), which gives a score based on the similarity in the sequences of words between a human-written model summary  and  the  machine  summary.",0,original
"We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996)) to estimate the alignment model.",0,original
"Based on this assumption, (Smadja, 1993) stored all bigrams of words along with their relative position, p (-5 < p _~ 5).",0,original
"Let us suppose that we have two bilingual lexicons L f L p and L p L e . We obtain word alignments of these lexicons by applying GIZA++ (Och and Ney, 2003), and grow-diag-final heuristics (Koehn et al., 2007).",0,original
"Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni (2006) showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score (Papineni et al., 2002) of at best 69%and that only when restricted to keep most words very close to their source positions.",0,original
"To counteract this, we introduce two brevity penalty measures (BP) inspired by BLEU (Papineni et al. , 2002) which we incorporate into the loss function, using a product, loss = 1PrecBP: BP1 = exp(1max(1, rc)) (6) BP2 = exp(1max(cr, rc)) where r is the reference length and c is the candidate length.",0,original
"The text was split at the sentence level, tokenized and PoS tagged, in the style of the Wall Street Journal Penn TreeBank (Marcus et al., 1993).",0,original
More details on the different parameter settings and instance selection algorithms as well as trends in the performance of different settings can be found in Stoyanov and Cardie (2006).,0,original
"At the sentence level, (Barzilay and Lee, 2003) employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora.",0,original
"Some researchers (Cucerzan, 2007; Nguyen and Cao, 2008) have explored the use of Wikipedia information to improve the disambiguation process.",0,original
"3 OverviewofExtractionWork 3.1 English As one mightexpect,the bulk of the collocation extractionwork concernsthe English language: (Choueka,1988;Churchet al. ,1989;Churchand Hanks,1990; Smadja,1993; Justesonand Katz, 1995;Kjellmer, 1994;Sinclair, 1995;Lin,1998), amongmany others1.",0,original
"In recent years, many researchers build alignment links with bilingual corpora (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003; Wu et al. , 2005; Zhang and Gildea, 2005).",0,original
"1 Introduction Text-to-text generation is an emerging area of research in NLP (Chandrasekar and Bangalore, 1997; Caroll et al. , 1999; Knight and Marcu, 2000; Jing and McKeown, 2000).",0,original
"Modeling reordering as the inversion in order of two adjacent blocks is similar to the approach taken by the Inverse Transduction Model (ITG) (Wu, 1997), except that here we are not limited to a binary tree.",0,original
"We used the Berkeley Parser 2 to train such grammars on sections 2-21 of the Penn Treebank (Marcus et al., 1993).",0,original
"Step 3) Answer Extraction: We select the top 5 ranked sentences and return them as Collins, 1997), can be used to capture the binary dependencies between the head of each phrase.",0,original
"Only one word is labeled with the concept; the syntactic head word (Collins, 1997) is preferred.",0,original
"Relatedness scores are computed for each pair of senses of the grammatically linked pair of words (w1; w2; GR), using the WordNet-Similarity-1.03 package and the lesk 759 option (Pedersen et al., 2004).",0,original
"3.1 The Corpus The systems are applied to examples from the Penn Treebank (Marcus et al. , 1993; Marcus et al. , 1994; Bies et al. , 1994) a corpus of over 4.5 million words of American English annotated with both part-of-speech and syntactic tree information.",0,original
"Here, ppicker shows the accuracy when phrases are extracted by using the N-best phrase alignment method described in Section 4.1, while growdiag-final shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (Koehn et al. , 2003).",0,original
"(2008)), and distributional methods (e.g., Bergsma et al.",0,original
David Yarowsky (1995) showed it was accurate in the word sense disambiguation.,0,original
"Parsers that attempt to disambiguate the input completely  full parsing  typically first employ some kind of dynamic programming algorithm to derive a packed parse forest and then applies a probabilistic top-down model in order to select the most probable analysis (Collins, 1997; Charniak, 2000).",0,original
"We perform word alignment using GIZA++ (Och and Ney, 2003), symmetrize the alignments using the grow-diag-final-and heuristic, and extract phrases up to length 3.",0,original
"Thus, it may not suffer from the issues of non-isomorphic structure alignment and non-syntactic phrase usage heavily (Wellington et al., 2006).",0,original
Hindle (1990) classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs.,0,original
"The performance of PB-SMT system is measured with BLEU score (Papineni et al., 2002).",0,original
For colnparison~ we refer here to Smadja's method (1993) because this method and the proposed method have much in connnon.,0,original
"We compare against several competing systems, the first of which is based on the original IBM Model 4 for machine translation (Brown et al. 1993) and the HMM machine translation alignment model (Vogel, Ney, and Tillmann 1996) as implemented in the GIZA++ package (Och and Ney 2003).",0,original
"Neither (Hindle and Rooth, 1993) with 67% nor (Ratnaparkhi et al. , 1994) with 59% noun attachment were anywhere close to this figure.",0,original
"(Macklovitch, 1994; Melamed, 1996b)), concordancing for bilingual lexicography (Catizone et al. , 1993; Gale & Church, 1991), computerassisted language learning, corpus linguistics (Melby.",0,original
"Even if the idea of using Wikipedia links for disambiguation is not novel (Cucerzan, 2007), it is applied for the first time to FrameNet lexical units, considering a frame as a sense definition.",0,original
"We run Maximum BLEU (Och, 2003) for 25 iterations individually for each system.",0,original
"Aware of this problem, Resnik and Yarowsky suggest creating the sense distance matrix based on results in experimental psychology such as Miller and Charles (1991) or Resnik (1995b).",0,original
"2 Related Work Question Answering has attracted much attention from the areas of Natural Language Processing, Information Retrieval and Data Mining (Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002; Hermjakob et al. , 2000).",0,original
"In the second pass, 5-gram and 6-gram zero-cutoff stupid-backoff (Brants et al., 2007) language models estimated using 4.7 billion words of English newswire text are used to generate lattices for phrasal segmentation model rescoring.",0,original
"In another line of research, (Yarowsky, 1995) and (Blum and Mitchell, 1998) have shown that it is possible to reduce the need for supervision with the help of large amounts of unannotated data.",0,original
Wu (1996) adopted chammls that eliminate syntactically unlikely alignments and Wang et al.,0,original
"The method described by Kazama and Torisawa (2007) is to rst extract the rst (base) noun phrase after the rst is, was, are, or were in the rst sentence of a Wikipedia article.",0,original
"The overall POS tag distribution learnt by EM is relatively uniform, as noted by Johnson (2007), and it tends to assign equal number of tokens to each tag label whereas the real tag distribution is highly skewed.",0,original
"The parameters, j, were trained using minimum error rate training (Och, 2003) to maximise the BLEU score (Papineni et al. , 2002) on a 150 sentence development set.",0,original
"Jiang & Zhai (2007) gave a systematic examination of the efficacy of unigram, bigram and trigram features drawn from different representations  surface text, constituency parse tree and dependency parse tree.",0,original
"Our evaluation metrics is casesensitive BLEU-4 (Papineni et al., 2002).",0,original
"This finding has been previously reported, among others, in Liu and Gildea (2005).",0,original
"Much work has been performed on learning to identify and classify polarity terms (i.e. , terms expressing a positive sentiment (e.g. , happy) or a negative sentiment (e.g. , terrible)) and exploiting them to do polarity classification (e.g. , Hatzivassiloglou and McKeown (1997), Turney (2002), Kim and Hovy (2004), Whitelaw et al.",0,original
Smadja (1993)finds significant bigrams using an estimate of z-score (deviation from an expected mean).,0,original
"The previous studies, with the exception of Kazama and Torisawa (2007), used smaller gazetteers than ours.",0,original
"Text similarity has been also used for relevance feedback and text classification (Rocchio, 1971), word sense disambiguation (Lesk, 1986), and more recently for extractive summarization (Salton et al. , 1997b), and methods for automatic evaluation of machine translation (Papineni et al. , 2002) or text summarization (Lin and Hovy, 2003).",0,original
"Thispaperfocusesontheframeworkintroduced in Figure 2 for two reasons: (a) cautious al50 gorithms were shown to perform best for several NLP problems (including acquisition of IE patterns), and (b) it has nice theoretical properties: Abney (2004) showed that, regardless of the selection procedure, sequential bootstrapping algorithms converge to a local minimum of K, where K is an upper bound of the negative log likelihood of the data.",0,original
"Also relevant is previous work that applied machine learning approaches to MT evaluation, both with human references (Corston-Oliver et al. , 2001; Kulesza and Shieber, 2004; Albrecht and Hwa, 2007; Liu and Gildea, 2007) and without (Gamon et al. , 2005).",0,original
"For example, in the IBM Models (Brown et al. , 1993), each word ti independently generates 0, 1, or more 2Note that we refer to t as the target sentence, even though in the source-channel model, t is the source sentence which goes through the channel model P(s|t) to produce the observed sentence s. words in the source language.",0,original
Some research into factored machine translation has been published by (Koehn and Hoang 2007).,0,original
"To model p(t,a|s), we use a standard loglinear approach: p(t,a|s)  exp bracketleftBiggsummationdisplay i ifi(s,t,a) bracketrightBigg where each fi(s,t,a) is a feature function, and weights i are set using Ochs algorithm (Och, 2003) to maximize the systems BLEU score (Papineni et al. , 2001) on a development corpus.",0,original
"4.1 Overview In this work, factored models (Koehn and Hoang, 2007) are experimented with three factors : the surface form, the lemma and the part of speech (POS).",0,original
"The problem itself has started to get attention only recently (Roark and Bacchiani, 2003; Hara et al., 2005; Daume III and Marcu, 2006; Daume III, 2007; Blitzer et al., 2006; McClosky et al., 2006; Dredze et al., 2007).",0,original
"2.1 Alignment Sentences from different systems are aligned in pairs using a modified version of the METEOR (Banerjee and Lavie, 2005) matcher.",0,original
"The simple idea that words in a source chunk are typically aligned to words in a single possible target chunk is used to discard alignments which link words from 2We use IBM-1 to IBM-5 models (Brown et al., 1993) implemented with GIZA++ (Och and Ney, 2003).",0,original
"Barzilay and Lee (Barzilay and Lee, 2003) learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases.",0,original
"61 Distributional cluster (Brown et al. , 1992): tie, jacket, suit Word 'tie' (7 alternatives) 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 draw, standoff, tie, stalemate affiliation, association, tie, tie-up: a social or business relationship tie, crosstie, sleeper: subconcept of brace, bracing necktie, tie link, linkup, tie, tie-in: something that serves to join or link drawstring, string, tie: cord used as a fastener tie, tie beam: used to prevent two rafters, e.g., from spreading apart Word 'jacket' (4 alternatives) 0.0000 book jacket, dust cover: subeoncept of promotional material 0.0000 jacket crown, jacket: artificial crown fitted over a broken or decayed tooth 0.0000 jacket: subconceptofwrapping, wrap, wrapper 1.0000 jacket: a short coat Word 'suit' (4 alternatives) 0.0000 suit, suing: subconcept of entreaty, prayer, appeal 1.0000 suit, suit of clothes: subconcept of garment 0.0000 suit: any of four sets of13"" cards in a paek 0.0000 legal action, action, case, lawsuit, suit: a judicial proceeding This cluster was derived by Brown et al. using a modification of their algorithm, designed to uncover ""semantically sticky"" clusters.",0,original
"1 Introduction: Defining SCMs The work presented here was done in the context of phrase-based MT (Koehn et al. , 2003; Och and Ney, 2004).",0,original
"All of the features of the ATR/Lancaster Treebank that are described below represent a radical departure from extant large-scale (Eyes and Leech, 1993; Garside and McEnery, 1993; Marcus et al. , 1993) treebanks.",0,original
"We tuned Pharaohs four parameters using minimum error rate training (Och, 2003) on DEV.12 We obtained an increase of 0.8 9As in the POS features, we map each phrase pair to its majority constellation.",0,original
"For example, Och (2003) shows how to train a log-linear translation model not by maximizing the likelihood of training data, but maximizing the BLEU score (among other metrics) of the model on 53 the data.",0,original
"Both models have been used to achieve state-of-the-art accuracy for a wide range of languages, as shown in the CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007), but McDonald and Nivre (2007) showed that a detailed error analysis reveals important differences in the distribution of errors associated with the two models.",0,original
"et al., 2007)) and unigrams (used by many researchers, e.g., (Pang and Lee, 2004)).",0,original
"They generally perform less well on low-frequency words (Weeds and Weir, 2005; van der Plas, 2008).",0,original
"The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003).",0,original
"5 Augmenting the corpus with an extracted dictionary Previous research (Callison-Burch et al., 2004; Fraser and Marcu, 2006) has shown that including word aligned data during training can improve translation results.",0,original
"To perform minimum error rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on development set, we used the script optimizeV5IBMBLEU.m (Venugopal and Vogel, 2005).",0,original
These weights or scaling factors can be optimized with respect to some evaluation criterion (Och 2003).,0,original
"This direction has been forming the mainstream of research on opinion-sensitive text processing (Pang et al. , 2002; Turney, 2002, etc.).",0,original
"In the following experiments, we run two machine learning classifiers: Bayes Point Machines (BPM) (Herbrich et al., 2001), and the maximum entropy model (ME) (Berger et al., 1996).",0,original
"This source is very important for repairs that do not have initial retracing, and is the mainstay of the ""parser-first"" approach (e.g. , 550 Heeman and Allen Modeling Speakers' Utterances Dowding et al. 1993)--keep trying alternative corrections until one of them parses.",0,original
"2 Statistical Word Alignment According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in Equation (1).",0,original
"Examples are Andersen (2006; 2007), Okanohara and Tsujii (2007), Sun et al.",0,original
"(1972); later elaborations and refinements have been implemented in a number of systems, notably CHAT-80 (Pereira 1983), TEAM (Grosz et al. 1986), and CLE (Moran 1988; Alshawi et al. 1989).",0,original
"This allows us to compute the conditional probability as follows (Berger et al. , 1996): ag~ (h .f) P(/Ih)1L ' (2) Z (h) ct i .",0,original
"2 Translation Models A translation model can be constructed automatically from texts that exist in two languages (bitexts) (Brown et al. , 1993; Melamed, 1997).",0,original
"173 The standard features for genre classification models include words, part-of-speech (POS) tags, and punctuation (Kessler et al., 1997; Stamatatos et al., 2000; Lee and Myaeng, 2002; Biber, 1993), but constituent-based syntactic categories have also been explored (Karlgren and Cutting, 1994).",0,original
"Generation of paraphrase examples was also investigated (Barzilay and Lee, 2003; Quirk et al. , 2004).",0,original
"Several other measures like Log-Likelihood (Dunning, 1993), Pearsons a2a4a3 (Church et al. , 1991), Z-Score (Church et al. , 1991), Cubic Association Ratio (MI3), etc. , have been also proposed.",0,original
"Chunks can be represented with bracket structures but alternatively one can use a tagging representation which classifies words as being inside a chunk (I), outside a chunk (O) or at a chunk boundary (B) (Ramshaw and Marcus, 1995).",0,original
"The variance semiring is essential for many interesting training paradigms such as deterministic 40 annealing (Rose, 1998), minimum risk (Smith and Eisner, 2006), active and semi-supervised learning (Grandvalet and Bengio, 2004; Jiao et al., 2006).",0,original
"Other languagesfor which this is the case include English (with the Penn treebank (Marcus et al., 1993), the Susanne Corpus (Sampson, 1993), and the British section of the ICE Corpus (Wallis and Nelson, 2006)) and Italian (with ISST (Montegmagni et al., 2000) and TUT (Bosco et al., 2000)).",0,original
"The system uses WordNet-based 1http://senserelate.sourceforge.net measures of semantic relatedness2 (Pedersen et al. , 2004) to measure the relatedness between the different senses of the target word and the words in its context.",0,original
"When we have a junction tree for each document, we can efficiently perform belief propagation in order to compute argmax in Equation (1), or the marginal probabilities of cliques and labels, necessary for the parameter estimation of machine learning classifiers, including perceptrons (Collins, 2002), and maximum entropy models (Berger et al., 1996).",0,original
"Several approaches have been proposed in the context of word sense disambiguation (Yarowsky, 1995), named entity (NE) classification (Collins and Singer, 1999), patternacquisitionforIE(Riloff,1996; Yangarber, 2003), or dimensionality reduction for text categorization (TC) (Yang and Pedersen, 1997).",0,original
"With the success of collaborative sites like Amazons Mechanical Turk 1, one 1http://www.mturk.com/ 59 can provide the task of annotation to multiple oracles on the internet (Snow et al., 2008).",0,original
"(2000) that draws on a stochastic tagger (see (Cutting et al. , 1992) for details) as well as the SPECIALIST Lexicon5, a large syntactic lexicon of both general and medical English that is distributed with the UMLS.",0,original
"4 Testing the Four Hypotheses The question of why self-training helps in some cases (McClosky et al., 2006; Reichart and Rappoport, 2007) but not others (Charniak, 1997; Steedman et al., 2003) has inspired various theories.",0,original
"There has also been previous work on determining whether a given text is factual or expresses opinion (Yu& Hatzivassiloglu, 2003; Pang & Lee, 2004); again this work uses a binary distinction, and supervised rather than unsupervised approaches.",0,original
"It has a lower bound of 0, no upper bound, better scores indicate better translations, and it tends to be highly correlated with the adequacy of outputs ;  mWER (Och 2003) or Multiple Word Error Rate is the edit distance in words between the system output and the closest reference translation in a set.",0,original
"Model Bits / Character ASCII Huffman code each char Lempel-Ziv (Unix TM compress) Unigram (Huffman code each word) Trigram Human Performance 8 5 4.43 2.1 (Brown, personal communication) 1.76 (Brown et al. 1992) 1.25 (Shannon 1951) The cross entropy, H, of a code and a source is given by: H(source, code) = ~ ~ Pr(s, h I source) log 2 Pr(s I h, code) s h where Pr(s, h I source) is the joint probability of a symbol s following a history h given the source.",0,original
"The most similar work to ours is (Daume III and Marcu, 2005), in which two most common synsets from WordNet for all words in an NP and their hypernyms are extracted as features.",0,original
"For example, the adjective unpredictable may have a negative orientation in an automotive review, in a phrase such as unpredictable steering, but it could have a positive orientation in a movie review, in a phrase such as unpredictable plot, as mentioned in (Turney, 2002) in the context of his sentiment word detection.",0,original
"1 Introduction Statistical machine translation (Brown et al. , 1993) has seen many improvements in recent years, most notably the transition from wordto phrase-based models (Koehn et al. , 2003).",0,original
"The unit of utterance corresponds to the unit of segment in the original BLEU and NIST studies (Papineni et al. , 2002; NIST, 2002).",0,original
(1999) 91.6% 91.6% F/3=1 93.86 93.26 92.8 92.03 91.6 Table 3: The overall pertbrmance of the majority voting combination of our best five systems (selected on tinting data perfbrnmnce) applied to the standard data set pnt tbrward by Ramshaw and Marcus (1995) together with an overview of earlier work.,0,original
"Dunning (1993) argues for the use of G 2 rather than X 2, based on an analysis of the sampling distributions of G 2 and X 2, and results obtained when using the statistics to acquire highly associated bigrams.",0,original
"After each step the annotations were compared using the ~ statistic as reliability measure for all classification tasks (Carletta, 1996).",0,original
"A tight integration of morphosyntactic information into the translation model was proposed by (Koehn and Hoang, 2007) where lemma and morphological information are translated separately, and this information is combined on the output side to generate the translation.",0,original
"This is most prominently evidenced by the PENN TREEBANK (Marcus et al. , 1993).",0,original
"Early examples of this work include (Alshawi, 1996; Wu, 1997); more recent models include (Yamada and Knight, 2001; Eisner, 2003; Melamed, 2004; Zhang and Gildea, 2005; Chiang, 2005; Quirk et al., 2005; Marcu et al., 2006; Zollmann and Venugopal, 2006; Nesson et al., 2006; Cherry, 2008; Mi et al., 2008; Shen et al., 2008).",0,original
"For example, the Penn Treebank (Marcus et al. , 1993; Marcus et al. , 1994; Bies et al. , 1994) provides a large corpus of syntactically annotated examples mostly from the Wall Street Journal.",0,original
"Most previous work on compositionality of MWEs either treat them as collocations (Smadja, 1993), or examine the distributional similarity between the expression and its constituents (McCarthy et al. , 2003; Baldwin et al. , 2003; Bannard et al. , 2003).",0,original
"It extracts all consistent phrase pairs from word-aligned bitext (Koehn et al. , 2003).",0,original
"But such general word lists were shown to perform worse than statistical models built on sufficiently large in-domain training sets of movie reviews (Pang et al., 2002).",0,original
"For example, a statistical machine translation system such as ISIs AlTemp SMT system (Och 2003) can generate a list of n-best alternative translations given a source sentence.",0,original
"In (Post and Gildea, 2008; Shen et al., 2008), target trees were employed to improve the scoring of translation theories.",0,original
"The performance figures given below are based on training each method on the 1-million-word Brown corpus \[Ku~:era and Francis, 1967\] and testing it on a 3/4-million-word corpus of Wall Street Journal text \[Marcus et al. , 1993\].",0,original
"With regard to the local update, (B), in Algorithm 4.2, early updates (Collins and Roark, 2004) and y-good requirement in (Daume III and Marcu, 2005) resemble our local update in that they tried to avoid the situation where the correct answer cannot be output.",0,original
"Model Overall Unknown Word Accuracy Accuracy Baseline, 96.72% 84.5% J Ratnaparkhi 96.63% 85.56% (1996) Table 3 Baseline model performance This table also shows the results reported in Ratnaparkhi (1996: 142)for COnvenience.",0,original
"This makes it suitable for discriminative SMT training, which is still a challenge for large parameter sets (Tillmann and Zhang, 2006; Liang et al. , 2006).",0,original
"A contrasting approach (Turney, 2002) relies only upon documents whose labels are unknown.",0,original
Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994).,0,original
"The word alignment used in GHKM is usually computed independent ofthesyntacticstructure,andasDeNeroandKlein (2007) and May and Knight (2007) have noted, Ch-En En-Ch Union Heuristic 28.6% 33.0% 45.9% 20.1% Table 1: Percentage of corpus used to generate big templates, based on different word alignments 9-12 13-20 21 Ch-En 18.2% 17.4% 64.4% En-Ch 15.9% 20.7% 63.4% Union 9.8% 15.1% 75.1% Heuristic 24.6% 27.9% 47.5% Table 2: In the selected big templates, the distribution of words in the templates of different sizes, which are measured based on the number of symbols in their RHSs is not the best for SSMT systems.",0,original
Perceptron Learning a discriminative structure prediction model with a perceptron update was first proposed by Collins (2002).,0,original
"1 Introduction Statistical phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) have consistently delivered state-of-the-art performance in recent machine translation evaluations, yet these systems remain weak at handling word order changes.",0,original
"The sentences included in the gold standard were chosen at random from the BNC, subject to the condition that they contain a verb which does not occur in the training sections of the WSJ section of the PTB (Marcus et al. , 1993).",0,original
"One of the theoretical problems with phrase based SMT models is that they can not effectively model the discontiguous translations and numerous attempts have been made on this issue (Simard et al., 2005; Quirk and Menezes, 2006; Wellington et al., 2006; Bod, 2007; Zhang et al., 2007).",0,original
"Models of this type include: (Brown et al., 1992; Zitouni, 2007), which use semantic word clustering, and (Bahl et al., 1990), which uses variablelength context.",0,original
A period should therefore be interpreted as an abbreviation marker and not as a sentence boundary marker if the two tokens surrounding it can indeed be considered as a collocation according to Dunnings (1993) original log-likelihood ratio amended with the one-sidedness constraint introduced in Section 2.2.,0,original
"This may stem from the differences between the two models' feature templates, thresholds, and approximations of the expected values for the features, as discussed in the beginning of the section, or may just reflect differences in the choice of training and test sets (which are not precisely specified in Ratnaparkhi (1996)).",0,original
"In this spirit, we introduce a generalization of the classic k-gram models, widely used for string processing (Brown et al. , 1992; Ney et al. , 1995), to the case of trees.",0,original
"It is potentially useful in other natural language processing tasks, such as the problem of estimating n-gram models (Brown et al. 1992) or the problem of semantic tagging (Cucchiarelli and Velardi 1997).",0,original
"Equation (3) reads If the target noun appears, then it is distinguished by the majority . The log-likelihood ratio (Yarowsky, 1995) decides in which order rules are applied to the target noun in novel context.",0,original
"(2008), we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10way jackknifing to generate tags for the training set.",0,original
"3ThePOS taggers The two POS taggers used in the experiments are TNT, a publicly available Markov model tagger (Brants, 2000), and a reimplementation of the maximum entropy (ME) tagger MXPOST (Ratnaparkhi, 1996).",0,original
"1 Introduction The best performing systems for many tasks in natural language processing are based on supervised training on annotated corpora such as the Penn Treebank (Marcus et al. , 1993) and the prepositional phrase data set first described in (Ratnaparkhi et al. , 1994).",0,original
"The data sets used are the standard data sets for this problem (Ramshaw and Maxcus, 1995; Argamon et al. , 1999; Mufioz et al. , 1999; Tjong Kim Sang and Veenstra, 1999) taken from the Wall Street Journal corpus in the Penn Treebank (Marcus et al. , 1993).",0,original
"For example, our system configuration for the shared task incorporates a wrapper around GIZA++ (Och and Ney, 2003) for word alignment and a wrapper around Moses (Koehn et al., 2007) for decoding.",0,original
"2 Statistical Word Alignment Model According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in equation (1).",0,original
"Two main extensions from that work that we are making use of are: 1) proofs falling below a user defined cost threshold halt the search 2) a simple variable typing system reduces the number of axioms written and the size of the search space (Hobbs et al. , 1988, pg 102).",0,original
"(Dahl et al. , 1987; Hull and Gomez, 1996) use hand-coded slot-filling rules to determine the semantic roles of the arguments of a nominalization.",0,original
"In Machine Translation, for example, sentences are produced using application-specific decoders, inspired by work on speech recognition (Brown et al. , 1993), whereas in Summarization, summaries are produced as either extracts or using task-specific strategies (Barzilay, 2003).",0,original
"Labeled data for one domain might be used to train a initial classifier for another (possibly related) domain, and then bootstrapping can be employed to learn new knowledge from the new domain (Blitzer et al., 2007).",0,original
"We could also introduce new variables, e.g., nonterminal refinements (Matsuzaki et al., 2005), or secondary linksMij (not constrained by TREE/PTREE) that augment the parse with representations of control, binding, etc.",0,original
"These dependencies differ from those used by Liu and Gildea (2005), in that they are extracted according to the rules of the LFG grammar and they are labelled with a type of grammatical relation that connects the head and the modifier, such as subject, determiner, etc. The presence of grammatical relation labels adds another layer of important linguistic information into the comparison and allows us to account for partial matches, for example when a lexical item finds itself in a correct relation but with an incorrect partner.",0,original
"Much of this work has been fueled by the availability of large corpora annotated with syntactic structures, especially the Penn Treebank (Marcus et al. , 1993).",0,original
"BLEU Score: BLEU is an automatic metric designed by IBM, which uses several references (Papineni et al., 2002).",0,original
"We hence chose transformation-based learning to create this (shallow) segmentation grammar, converting the segmentation task into a tagging task (as is done in 85 (Ramshaw and Marcus, 1995), inter alia).",0,original
"These categories were automatically generated using the labeled parses in Penn Treebank (Marcus et al., 1993) and the labeled semantic roles of PropBank (Kingsbury et al., 2002).",0,original
"With our best performing features, we get ROUGE-2 (Lin, 2004) scores of 0.11 and 0.0925 on 2007 and 2006 5This threshold was derived experimentally with previous data.",0,original
"et al., 2004; Collins-Thompson and Callan, 2005; Hughes and Ramage, 2007).",0,original
"One can also examine the distribution of character or word ngrams, e.g. Language Modeling (Croft and Lafferty, 2003), phrases (Church and Hanks, 1990; Lewis, 1992), and so on.",0,original
"The parameters of the refined productions Ax  By Cz, where Ax is a subcategory of A, By of B, and Cz of C, can then be estimated in various ways; past work has included both generative (Matsuzaki et al., 2005; Liang et al., 2007) and discriminative approaches (Petrov and Klein, 2008).",0,original
"4.1 Data Preparation NP chunking results have been reported on two slightly different data sets: the original RM data set of Ramshaw and Marcus (1995), and the modi ed CoNLL-2000 version of Tjong Kim Sang and Buchholz (2000).",0,original
"The MBT (Daelemans et al. , 1996) 180 Tagger Type Standard Trigram (Weischedel et al. , 1993) MBT (Daelemans et al. , 1996) Rule-based (Brill, 1994) Maximum-Entropy (Ratnaparkhi, 1996) Full Second-Order HMM SNOW (Roth and Zelenko, 1998) Voting Constraints (Tiir and Oflazer, 1998) Full Second-Order HMM Known Unknown Overall Open/Closed Lexicon?",0,original
"3.2 Rare Word Accuracy For these experiments, we use the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993).",0,original
Chen and Martin (2007) explored the use of a range of syntactic and semantic features in unsupervised clustering of documents.,0,original
"All 8,907 articles were tagged by the Xerox Part-ofSpeech Tagger (Cutting et al. , 1992) 4.",0,original
"Themodeling approachhere describedis discriminative, and is based on maximum entropy (ME) models, firstly applied to natural language problems in (Berger et al., 1996).",0,original
"Many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of constituents (Collins 1997, 1999; Eisner 1997), leaving it as an open question whether there exist important statistical dependencies that go beyond linguistically motivated dependencies.",0,original
"Many studies focus on rare words (Dunning, 1993; Moore, 2004); butterflies are more interesting than moths.",0,original
"In (Matsuzaki et al. , 2005) non-terminals in a standard PCFG model are augmented with latent variables.",0,original
"3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al. , 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al. , 1998), Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmers errors, see (Krovetz, 1993).",0,original
"Instead of using the NP bracketing information present in the tagged Treebank data, Ramshaw and Marcus modified the data so as to include bracketing information related only to the non-recursive, base NPs present in each sentence while the subject verb phrases were taken as is. The data sets include POS tag information generated by Ramshaw and Marcus using Brill's transformational part-of-speech tagger (Brill, 1995).",0,original
"Two more recent investigations are by Yarowsky, (Yarowsky, 1995), and later, Mihalcea, (Mihalcea, 2002).",0,original
"translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence.",0,original
"Most work on discriminative training for SMT has focussed on linear models, often with margin based algorithms (Liang et al., 2006; Watanabe et al., 2006), or rescaling a product of sub-models (Och, 2003; Ittycheriah and Roukos, 2007).",0,original
"In computational linguistics, our pattern discovery procedure extends over previous approaches that use surface patterns as indicators of semantic relations between nouns or verbs ((Hearst, 1998; Chklovski and Pantel, 2004; Etzioni et al., 2004; Turney, 2006; Davidov and Rappoport, 2008) inter alia).",0,original
"Thus, equation (3) can be rewritten as  = i p i iii i i eppfef )|()|()|(  (4) 4.2 Lexical Weight Given a phrase pair ),( ef and a word alignment a between the source word positions ni,,1= and the target word positions mj,,1=, the lexical weight can be estimated according to the following method (Koehn et al. , 2003).",0,original
"5 Phrase Pair Induction A common approach to phrase-based translation is to extract an inventory of phrase pairs (PPI) from bitext (Koehn et al. , 2003), For example, in the phraseextract algorithm (Och, 2002), a word alignment am1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : am1 : aj  [i1,i2] iff j  [j1,j2] .",0,original
"This analysis depends on the SPECIALIST Lexicon and the Xerox part-of-speech tagger (Cutting et al. , 1992) and provides simple noun phrases that are mapped to concepts in the UMLS Metathesaurus using MetaMap (Aronson, 2001).",0,original
"1 Introduction Base noun phrases (baseNPs), broadly the initial portions of non-recursive noun phrases up to the head (Ramshaw and Marcus, 1995), are valuable pieces of linguistic structure which minimally extend beyond the scope of named entities.",0,original
"A reranking parser (see also (Koo and Collins, 2005)) is a layered model: the base layer is a generative statistical PCFG parser that creates a ranked list of k parses (say, 50), and the second layer is a reranker that reorders these parses using more detailed features.",0,original
"Incremental Sigmoid Belief Networks (Titov and Henderson, 2007) differ from simple dynamic SBNs in that they allow the model structure to depend on the output variable values.",0,original
"1PMI is subject to overestimation for low frequency items (Dunning, 1993), thus we require a minimum frequency of occurrence for the expressions under study.",0,original
"This wrong translation of content words is similar to the incorrect omission reported in (Och et al., 2003), which both hurt translation adequacy.",0,original
Carpuat and Wu (2007) and Chan et al.,0,original
"Specifically, we explore the statistical term weighting features of the word generation model with Support Vector machine (SVM), faithfully reproducing previous work as closely as possible (Pang et al., 2002).",0,original
"We use binary Synchronous ContextFree Grammar (bSCFG), based on Inversion Transduction Grammar (ITG) (Wu, 1997; Chiang, 2005a), to define the set of eligible segmentations for an aligned sentence pair.",0,original
"The bidirectional word alignmentisusedtoobtainlexicalphrasetranslationpairs using heuristics presented in (Och & Ney, 2003) and (Koehn et al. , 2003).",0,original
"This tolerant search uses the well known concept of Levenshtein distance in order to obtain the most similar string for the given prefix (see (Och et al., 2003) for more details).",0,original
"The various extraction measures have been discussed in great detail in the literature (Manning and Schutze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002).",0,original
"Rules have the form X  e, f, where e and f are phrases containing terminal symbols (words) and possibly co-indexed instances of the nonterminal symbol X.2 Associated with each rule is a set of translation model features, i( f, e); for example, one intuitively natural feature of a rule is the phrase translation (log-)probability ( f, e) = log p(e| f) , directly analogous to the corresponding feature in non-hierarchical phrase-based models like Pharaoh (Koehn et al., 2003).",0,original
We have begun experimenting with log likelihood ratio (Dunning 1993) as a thresholding technique.,0,original
"It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes (Smith and Eisner, 2007; Koo et al., 2008; Wang et al., 2008).",0,original
"Dialogs Speakers Turns Words Fragments Distinct Words Distinct Words/POS Singleton Words Singleton Words/POS Intonational Phrases Speech Repairs 98 34 6163 58298 756 859 1101 252 350 10947 2396 Table 1: Size of the Trains Corpus 2.1 POS Annotations Our POS tagset is based on the Penn Treebank tagset (Marcus et al. , 1993), but modified to include tags for discourse markers and end-of-turns, and to provide richer syntactic information (Heeman, 1997).",0,original
k -~ P(A) P(E) (3) 1P(E) Carletta (1996) suggests that the units over which the kappa statistic is computed affects the outcome.,0,original
"2(Daume III and Marcu, 2005) also presents the method using the averaged perceptron (Collins, 2002a) 3For re-ranking problems, Shen and Joshi (2004) proposed a perceptron algorithm that also uses margins.",0,original
"5http://opennlp.sourceforge.net/ We use the standard four-reference NIST MTEval data sets for the years 2003, 2004 and 2005 (henceforth MT03, MT04 and MT05, respectively) for testing and the 2002 data set for tuning.6 BLEU4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and multiple-reference Word Error Rate scores are reported.",0,original
"This difference was highlighted in the 3http://w3.msi.vxu.se/jha/maltparser/ studyofMcDonaldandNivre(2007), whichshowed that the difference is reflected directly in the error distributions of the parsers.",0,original
"The reliability of the annotations was checked using the kappa statistic (Carletta, 1996).",0,original
"Models of this kind assume that an input word is generated by only one output word (Brown et al. , 1993).",0,original
"to the pair-wise TER alignment described in (Rosti et al., 2007).",0,original
"(1993), Johansson and Nugues (2007), Prokopidis et al.",0,original
2 Background The natural language generator used in our experiments is the WSJ-trained system described in Cahill and van Genabith (2006) and Hogan et al.,0,original
"Language models, such as N-gram class models (Brown et al. , 1992) and Ergodic Hidden Markov Models (Kuhn el, al. , 1994) were proposed and used in applications such as syntactic class (POS) tagging for English (Cutting et al. , 1992), clustering and scoring of recognizer sentence hypotheses.",0,original
"The agreement on identifying the boundaries of units, using the AK statistic discussed in (Carletta, 1996), was AK BP BMBL (for two annotators and 500 units); the agreement on features(2 annotators and at least 200 units) was follows: Attribute AK Value utype .76 verbed .9 finite .81 subject .86 NPs Our instructions for identifying NP markables derive from those proposed in the MATE project scheme for annotating anaphoric relations (Poesio et al. , 1999).",0,original
"Our strategy for choosing heads is similar to the one in (Collins, 1997).",0,original
"287 System Train +base Test +base 1 Baseline 87.89 87.89 2 Contrastive 88.70 0.82 88.45 0.56 (5 trials/fold) 3 Contrastive 88.82 0.93 88.55 0.66 (greedy selection) Table 1: Average F1 of 7-way cross-validation To generate the alignments, we used Model 4 (Brown et al., 1993), as implemented in GIZA++ (Och and Ney, 2003).",0,original
"This is confirmed by a comparison between our baseline result (F=1=55.4%) and some baseline results of English base-NP chunking task (e.g. precision=81.9%, recall=78.2%, F=1=80.0% (Ramshaw and Marcus, 1995)).",0,original
"(2004), Pang and Lee (2004), Wilson et al.",0,original
"For this reason, name classification has been studied in solving the named entity extraction task in the NLP and information extraction communities (see, for example, (Collins and Singer, 1999; Cucerzan and Yarowsky, 1999) and various approaches reported in the MUC conferences (MUC-6, 1995)).",0,original
"(Daille, 1996; Smadja, 1993)), less prior work exists for bilingual acquisition of domain-specific translations.",0,original
"Then the two models and a search module are used to decode the best translation (Brown et al., 1993; Koehn et al., 2003).",0,original
"The approach is in the spirit of Smadja (1993) on retrieving collocations from text corpora, but is more integrated with parsing.",0,original
This algorithm can thus be viewed as a large-margin version of the perceptron algorithm for structured outputs Collins (2002).,0,original
"Among these methods, CRFs is the most common technique used in NLP and has been successfully applied to Part-of-Speech Tagging (Lafferty et al. , 2001), Named-Entity Recognition (Collins, 2002) and shallow parsing (Sha and Pereira, 2003; McCallum, 2003).",0,original
"3.1 The traditional IBM alignment model IBM Model 4 (Brown et al. , 1993) learns a set of 4 probability tables to compute p(f|e) given a foreign sentence f and its target translation e via the following (greatly simplified) generative story: 361 NP-C NPB NPB NNP taiwan POS s NN surplus PP IN in NP-C NPB NN trade PP IN between NP-C NPB DT the CD two NNS shores FTD0 GR G4E7 DYBG EL DIDV TAIWAN IN TWO-SHORES TRADE MIDDLE SURPLUS R1: NP-C NPB x0:NPB x1:NN x2:PP x0 x2EL x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R2: NPB NNP taiwan POS s FTD0 R11: NPB x0:NNP POS s x0 R17: NPB NNP taiwan x0:POS x0 R12: NNP taiwan FTD0 R18: POS s FTD0 R3: PP x0:IN x1:NP-C x0 x1 R13: PP IN in x0:NP-C GR x0EL R19: PP IN in x0:NP-C x0 R4: IN in  GR R5: NP-C x0:NPB x1:PP  x1 x0 R5: NP-C x0:NPB x1:PP x1 x0 R20: NP-C x0:NPB PP x1:IN x2:NP-C x2 x0 x1 R6: PP IN between NP-C NPB DT the CD two NNS shores G4E7 R14: PP IN between x0:NP-C x0 R21: IN between EL R15: NP-C x0:NPB x0 R15: NP-C x0:NPB x0 R16: NPB DT the CD two NNS shores G4E7 R22: NPB x0:DT CD two x1:NNS x0 x1 R23: NNS shores G4E7 R24: DT the GR R7: NPB x0:NN x0 R7: NPB x0:NN x0 R7: NPB x0:NN x0 R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV Figure 2: A (English tree, Chinese string) pair and three different sets of multilevel tree-to-string rules that can explain it; the first set is obtained from bootstrap alignments, the second from this papers re-alignment procedure, and the third is a viable, if poor quality, alternative that is not learned.",0,original
"By introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e = argmaxe Pr(e | f) = argmaxe summationdisplay a Pr(e,a | f)  argmaxe,a Pr(e,a | f) Exploiting the maximum entropy (Berger et al. , 1996) framework, the conditional distribution Pr(e,a | f) can be determined through suitable real valued functions (called features) hr(e,f,a),r = 1R, and takes the parametric form: p(e,a | f)  exp Rsummationdisplay r=1 rhr(e,f,a)} The ITC-irst system (Chen et al. , 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al. , 1993) to phrases (Koehn et al. , 2003; Federico and Bertoldi, 2005).",0,original
"As described in Section 3 we retrieved neighbors using Lins (1998) similarity measure on a RASP parsed (Briscoe and Carroll, 2002) version of the BNC.",0,original
"The structure of the graphical model resembles IBM Model 1 (Brown et al., 1993) in which each target (record) word is assigned one or more source (text) words.",0,original
"Using an Maximum Entropy approach to POS tagging, Ratnaparkhi (1996) reports a tagging accuracy of 96.6% on the Wall Street Journal.",0,original
"2.2 Maximum Entropy Model The maximum entropy model (Berger et al. , 1996) estimates a probability distribution from training data.",0,original
"Since an existing study incorporates these relations ad hoc (Collins, 1997), they are apparently crucial in accurate disambiguation.",0,original
"Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT (Koehn et al., 2003), operating on characters rather than words.",0,original
"Networks (Toutanova et al. , 2003) 97.24 Perceptron (Collins, 2002) 97.11 SVM (Gimenez and Marquez, 2003) 97.05 HMM (Brants, 2000) 96.48 Easiest-first 97.10 Full Bidirectional 97.15 Table 3: POS tagging accuracy on the test set (Sections 22-24 of the WSJ, 5462 sentences).",0,original
Both Okanohara and Tsujii (2007) and Wagner et al.,0,original
4.4 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in Yarowsky (1995).,0,original
"They mention that the resulting shallow parse tags are somewhat different than those used by Ramshaw and Marcus (1995), but that they found no significant accuracy differences in training on either set.",0,original
"918 English For English we used the Wall Street Journal section of the Penn Treebank (Marcus et al. , 1993).",0,original
"Second, several tagging experiments on newspaper language, whether statistical (Ratnaparkhi, 1996; Brants, 2000) or rule-based (Brill, 1995), report that the tagging accuracy for unknown words is much lower than the overall accuracy.2 Thus, the lower percentage of unknown words in medical texts seems to be a sublanguage feature beneficial to POS taggers, whereas the higher proportion of unknown words in newspaper language seems to be a prominent source of tagging errors.",0,original
"3 Schone & Jurafsky's results indicate similar results for log-likelihood & T-score, and strong parallelism among information-theoretic measures such as ChiSquared, Selectional Association (Resnik 1996), Symmetric Conditional Probability (Ferreira and Pereira Lopes, 1999) and the Z-Score (Smadja 1993).",0,original
"In addition to portability experiments with the parsing model of (Collins, 1997), (Gildea, 2001) provided a comprehensive analysis of parser portability.",0,original
"Both were 5gram models with modified Kneser-Ney smoothing, lossily compressed using a perfect-hashing scheme similar to that of Talbot and Brants (2008) but using minimal perfect hashing (Botelho et al., 2005).",0,original
"To compare different clustering algorithms, results with the standard method of (Brown et al. , 1992) (SRILMs ngram-class) are also reported.",0,original
"1 Introduction Inversion transduction grammar (ITG) constraints (Wu, 1997) provide coherent structural constraints on the relationship between a sentence and its translation.",0,original
"Looking rst at learning times, it is obvious that learning time depends primarily on the number of training instances, which is why we can observe a difference of several orders of magnitude in learning time between the biggest training set (Czech) and the smallest training set (Slovene) 14 This is shown by Nivre and Scholz (2004) in comparison to the iterative, arc-standard algorithm of Yamada and Matsumoto (2003) and by McDonald and Nivre (2007) in comparison to the spanning tree algorithm of McDonald, Lerman, and Pereira (2006).",0,original
"For evaluation we have selected a set of 8 metric variants corresponding to seven different families: BLEU (n = 4) (Papineni et al. , 2001), NIST (n = 5) (Lin and Hovy, 2002), GTM F1-measure (e = 1,2) (Melamed et al. , 2003), 1-WER (Nieen et al. , 2000), 1-PER (Leusch et al. , 2003), ROUGE (ROUGE-S*) (Lin and Och, 2004) and METEOR3 (Banerjee and Lavie, 2005).",0,original
"This representation, being contiguous on both sides, successfully reduces the decoding complexity to a low polynomial and significantly improved the search quality (Zhang et al. , 2006).",0,original
"In this paper we use the so-called Model 4 from (Brown et al. , 1993).",0,original
"Mathematical details are fully described in (Brown et al. , 1993).",0,original
"The features used by the POS tagger, some of which are different to those from Collins (2002) and are specific to Chinese, are shown in Table 2.",0,original
"As far as we know, language modeling always improves with additional training data, so we add data from the North American News Text Corpus (NANC) (Graff, 1995) automatically parsed with the Charniak parser (McClosky et al. , 2006) to train our language model on up to 20 million additional words.",0,original
Agreement among annotators was measured using the K statistic (Siegel and Castellan 1988; Carletta 1996).,0,original
"In practice, 7-/ is very large and the model's expectation Efj cannot be computed directly, so the following approximation(Lau et al. , 1993) is used: n E fj,~ E15(hi)p(tilhi)fj(hi,ti) i=1 where fi(hi) is the observed probability of the history hi in the training set.",0,original
"In the tagging domain, Collins (2002) compared log-linear and perceptron training for HMM-style tagging based on dynamic programming.",0,original
"2 Perceptron Algorithm for Sequence Labeling Collins (2002a) proposed an extension of the perceptron algorithm (Rosenblatt, 1958) to sequence labeling.",0,original
"(1993) (as in Duygulu et al. , 2002), and extend it to structured shape descriptions of visual data.",0,original
(1993); Brown et al.,0,original
"As noted in Dolan (1994), it is possible to run a sense-clustering algorithm on several MRDs to build an integrated lexical database with more complete coverage of word senses.",0,original
"Snow etal (Snow et al., 2006) use known hypernym/hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns.",0,original
"For comparison purposes, we consider two different algorithms for our AnswerExtraction module: one that does not bridge the lexical chasm, based on N-gram cooccurrences between the question terms and the answer terms; and one that attempts to bridge the lexical chasm using Statistical Machine Translation inspired techniques (Brown et al. , 1993) in order to find the best answer for a given question.",0,original
"Indeed, the prominent approach for evaluating the quality of rule acquisition algorithms is by human judgment of the learned rules (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Pang et al. , 2003; Szpektor et al. , 2004; Sekine, 2005).",0,original
"We implemented this model within an ME modeling framework (Jaynes, 1957; Jaynes, 1979; Berger et al. , 1996).",0,original
"1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferfeira & McClure 1997, Gamsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell & Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993).",0,original
"Without specific knowledge of the target domains annotation standards, significant improvement can not be made(Dredze et al., 2007).",0,original
"Prominent among these properties is the semi-free Language Size LR LP Source English 40,000 87.4% 88.1% (Collins, 1997) Chinese 3,484 69.0% 74.8% (Bikel and Chiang, 2000) Czech 19,000 80.0% (Collins et al. , 1999) Table 1: Results for the Collins (1997) model for various languages (dependency precision for Czech) wordorder, i.e., German wordorder is fixed in some respects, but variable in others.",0,original
"6 Experiments 6.1 Data preparation Our experiments were conducted with data made available through the Penn Treebank annotation effort (Marcus et al. , 1993).",0,original
G-Theory and Agreement Indices Two well-known measures for capturing the quality of manual annotations are agreement percentages and the kappa statistic (Cohen 1960; Carletta 1996; Eugenio and Glass 2004).,0,original
"Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors.",0,original
"Although Phramer provides decoding functionality equivalent to Pharaohs, we preferred to use Pharaoh for this task because it is much faster than Phramer  between 2 and 15 times faster, depending on the configuration  and preliminary tests showed that there is no noticeable difference between the output of these two in terms of BLEU (Papineni et al. , 2002) score.",0,original
"For natural language engineers, the problem bears on information management systems like abstractive summarizers that must measure semantic overlap between sentences (Barzilay and Lee, 2003), question answering modules (Marsi and Krahmer, 2005) and machine translation (Callison-Burch et al., 2006).",0,original
"(2007), Rosti et al.",0,original
"Our aim is not only to determine the utility of citation texts for survey creation, but also to examine the quality distinctions between this form of input and others such as abstracts and full textscomparing the results to human-generated surveys using both automatic and nugget-based pyramid evaluation (Lin and Demner-Fushman, 2006; Nenkova and Passonneau, 2004; Lin, 2004).",0,original
1 The Baseline Maximum Entropy Model We started with a maximum entropy based tagger that uses features very similar to the ones proposed in Ratnaparkhi (1996).,0,original
"579 The MaxEnt algorithm associates a set of weights (ij)i=1nj=1m with the features, which are estimated during the training phase to maximize the likelihood of the data (Berger et al. , 1996).",0,original
"Two LUs close in the space are likely to be in a paradigmatic relation, i.e. to be close in a is-a hierarchy (Budanitsky and Hirst, 2006; Lin, 1998; Pado, 2007).",0,original
"Furthermore, early work on class-based language models was inconclusive (Brown et al. , 1992).",0,original
"264-285.</rawString> </citation> <citation valid=""true""> <authors> <author>T Fukushima</author> <author>M Okumura</author> </authors> <title>Text summarization challenge: text summarization in Japan</title> <date>2001</date> <booktitle>in Proceedings of NAACL 2001 Workshop Automatic Summarization</booktitle> <pages>51--59</pages> <contexts> <context>Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summarization Challenge (TSC) (Fukushima and Okumura, 2001), have attested the importance of this topic.",0,original
"1 Introduction Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation (Brown et al. 1993), and many other multi-lingual natural language processing applications.",0,original
"The model scaling factors M1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003).",0,original
"To determine the target distribution we classified 171 (approximately 5%) randomly selected utterances from the TownInfo data, that were used as a development set.2 In Table 1 we can see that 15.2 % of the trees in the artificial corpus will be NP NSUs.3 4 Data generation We constructed our artificial corpus from sections 2 to 21 of the Wall Street Journal (WSJ) section of the Penn Treebank corpus (Marcus et al., 1993) 2We discarded very short utterances (yes, no, and greetings) since they dont need parsing.",0,original
"The reason may be that shorter dependencies are often modifier of nouns such as determiners or adjectives or pronouns modifying their direct neighbors, while longer dependencies typically represent modifiers of the root or the main verb in a sentence(McDonald and Nivre, 2007).",0,original
"(4) can be used to motivate a novel class-based language model and a regularized version of minimum discrimination information (MDI) models (Della Pietra et al., 1992).",0,original
"The software also required GIZA++ word alignment tool(Och and Ney, 2003).",0,original
"In Englishto-German, this result produces results very comparable to a phrasal SMT system (Koehn et al. , 2003) trained on the same data.",0,original
"6 Comparison With Previous Work The two parsers which have previously reported the best accuracies on the Penn Treebank Wall St. Journal are the bigram parser described in (Collins, 1996) and the SPATTER parser described in (Jelinek et al. , 1994; Magerman, 1995).",0,original
"We say that wv and nq are semantically related if w~i and nq are semantically related and (wp, nq) and (w~i, nq) are semantically similar (Dagan et al. , 1993).",0,original
"Table 1 shows a summary of the results of our experiments with SVMpar and MBLpar, and also results obtained with the Charniak (2000) parser, the Bikel (2003) implementation of the Collins (1997) parser, and the Ratnaparkhi (1997) parser.",0,original
"Grefenstette (1993) studied two context delineation methods of English nouns: the window-based and the syntactic, whereby all the different types of syntactic dependencies of the nouns were used in the same feature space.",0,original
"We use the following features for our rules:  sourceand target-conditioned neg-log lexical weights as described in (Koehn et al. , 2003b)  neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned  Counters: n.o. rule applications, n.o. target words  Flags: IsPurelyLexical (i.e. , contains only terminals), IsPurelyAbstract (i.e. , contains only nonterminals), IsXRule (i.e. , non-syntactical span), IsGlueRule 139  Penalties: rareness penalty exp(1  RuleFrequency); unbalancedness penalty |MeanTargetSourceRatio  n.o. source words n.o. target words| 4 Parsing Our SynCFG rules are equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing.",0,original
"We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007), the SRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al., 2003) to obtain wordalignments, a translation model, language models, and the optimal weights for combining these models, respectively.",0,original
"The most commonly used MT evaluation metric in recent years has been IBM?s Bleu metric (Papineni et al. , 2002).",0,original
"For better probability estimation, the model was extended to work with (hidden) word classes (Brown et al. , 1992, Ward and Issar, 1996).",0,original
"(2) X1/X2    Y1:r1/Y2:r2 , [i1, j1, i2, j2], Y1/Y2   , [j1, k1, j2, k2] X1/X2   Y1:r1/Y2:r2  , [i1, k1, i2, k2] (3) X1/X2    Y1:r1/Y2:r2 , [i1, j1, j2, k2], Y1/Y2   , [j1, k1, i2, j2] X1/X2   Y1:r1/Y2:r2  , [i1, k1, i2, k2] Since each inference rule contains six free variables over string positions (i1, j1, k1, i2, j2, k2), we get a parsing complexity of order O(n6) for unlexicalized grammars (where n is the number of words in the longer of the two strings from language L1 and L2) (Wu, 1997; Melamed, 2003).",0,original
"More recently, phrase-based models (Och et al. , 1999; Marcu and Wong, 2002; Koehn et al. , 2003) have been proposed as a highly successful alternative to the IBM models.",0,original
"In the context of headline generation, simple statistical models are used for aligning documents and headlines (Banko, Mittal, and Witbrock 2000; Berger and Mittal 2000; Schwartz, Zajic, and Dorr 2002), based on IBM Model 1 (Brown et al. 1993).",0,original
"A more optimistic view can be found in (Leech and Eyes 1993, p. 39; Marcus et al. 1993, p. 328); they argue that a near-100% interjudge agreement is possible, provided the part-of-speech annotation is done carefully by experts.",0,original
"Chen & Martin (2007) introduced one of those similarity schemes, ?two-level SoftTFIDF??",0,original
"204 4.2.2 Correlation between TREC nuggets and non-text features Analyzing the features used could let us understand summarization better (Nenkova and Louis, 2008).",0,original
"One is a phrase-based translation in which a phrasal unit is employed for translation (Koehn et al. , 2003).",0,original
"While this approach exploits only syntactic and lexical information, Jing and McKeown (2000) also rely on cohesion information, derived from word distribution in a text: Phrases that are linked to a local context are retained, while phrases that have no such links are dropped.",0,original
"Marcu and Echihabi (2002) use a pattern-based approach in mining instances of RSRs such as Contrast and Elaboration from large, unannotated corpora.",0,original
"Indeed, the result of Collins (2002) that including low support features helps a voted perceptron model but harms a maximum entropy model is undone once the weights of the maximum entropy model are regularized.",0,original
"Also, PMI-IR is useful for calculating semantic orientation and rating reviews (Turney, 2002).",0,original
"Seen from Table 2, our result about SCL is in accord with that in (Blitzer et al., 2007) on the whole.",0,original
"have been proposed (Hindle, 1990; Brown et al. , 1992; Pereira et al. , 1993; Tokunaga et al. , 1995).",0,original
"Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al. , 1998), semi-supervised learning algorithms (Yarowsky, 1995), and unsupervised learning algorithms (Schutze, 1998).",0,original
"At each training-set size, a new copy of the network is trained under each of the following conditions: (1) using SULU, (2) using SULU but supplying only the labeled training examples to synthesize, (3) standard network training, (4) using a re-implementation of an algorithm proposed by Yarowsky (1995), and (5) using standard network training but with all training examples labeled to establish an upper bound.",0,original
"To circumvent these computational limitations, various pruning techniques are usually needed, e.g., (Huang and Chiang, 2007).",0,original
"2.1 EM parameter estimation We train using Expectation Maximisation (EM), optimising the log probability of the training setfe(s),f(s)gSs=1 (Brown et al., 1993).",0,original
"Such a coding procedure covers, for example, how segmentation of a corpus is performed, if multiple tagging is allowed and if so, is it unlimited or are there just certain combinations of tags not allowed, is look ahead permitted, etc For further information on coding procedures we want to refer to \[Dybkjmr et al.1998\] and for good examples of coding books see, for example, \[Carletta et al.1996\], \[Alexandersson et al.1998\], or \[Thym~-Gobbel and Levin1998\].",0,original
"Actually, it is defined similarly to the translation model in SMT (Koehn et al., 2003).",0,original
"Another technique used was to filter sentences of the out-of-domain corpus based on their similarity to the target domain, as predicted by a classifier (Dredze et al. , 2007).",0,original
"1999), OpenCCG (White, 2004) and XLE (Crouch et al., 2007), or created semi-automatically (Belz, 2007), or fully automatically extracted from annotated corpora, like the HPSG (Nakanishi et al., 2005), LFG (Cahill and van Genabith, 2006; Hogan et al., 2007) and CCG (White et al., 2007) resources derived from the Penn-II Treebank (PTB) (Marcus et al., 1993).",0,original
"A number of other re532 searchers (Berger et al. , 1996; Niessen and Ney, 2004; Xia and McCord, 2004) have described previous work on preprocessing methods.",0,original
"Next, we learn our polarity classifier using positive and negative reviews taken from two movie 611 review datasets, one assembled by Pang and Lee (2004) and the other by ourselves.",0,original
"a.2 Maximum-entropy method The maximum-entropy method is useful with sparse data conditions and has been used by many researchers (Berger et al. , 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick el; al. , 1998; Uchimoto et al. , 1999).",0,original
"The capitalization and punctuation is then removed from the text as in (Monroe et al. , 2006) and then the 1http://thomas.loc.gov 659 text stemmed using Porters Snowball II stemmer2.",0,original
"Additionally, automatic evaluation of content coverage using ROUGE (Lin, 2004) was explored in 2004.",0,original
"(~(e) = max ((fl ,f~) ~ e) (23) (11  Y~) Now, the problem of learning probabilistic subcategorization preference is stated as: for every verb-noun collocation e in C, estimating the probability distribution P((fl, 6Resnik (1993) applys the idea of the KL distance to measuring the association of a verb v and its object noun class c. Our definition of ekt corresponds to an extension of Resnik's association score, which considers dependencies of more than one case-markers in a subcategorization frame.",0,original
"In the past five years, important research on the automatic acquisition of word classes based on lexical distribution has been published (Church and Hanks, 1990; Hindle, 1990; Smadja, 1993; Grei~nstette, 1994; Grishman and Sterling, 1994).",0,original
"html 162 3.1.1 Penn Treebank 3 The Penn Treebank 3 corpus (Marcus et al., 1993) consists of hand-coded parses of the Wall Street Journal (test, development and training) and a small subset of the Brown corpus (W. N. Francis and H. Kucera, 1964) (test only).",0,original
"In order to create the necessary SMT language and translation models, they used:  Giza++ (Och & Ney, 2003);2  the CMU-Cambridge statistical toolkit;3  the ISI ReWrite Decoder.4 Translation was performed from EnglishFrench and FrenchEnglish, and the resulting translations were evaluated using a range of automatic metrics: BLEU (Papineni et al. , 2002), Precision and Recall 2http://www.isi.edu/och/Giza++.html 3http://mi.eng.cam.ac.uk/prc14/toolkit.html 4http://www.isi.edu/licensed-sw/rewrite-decoder/ 185 (Turian et al. , 2003), and Wordand Sentence Error Rates.",0,original
"html\] provided by Lynette Hirschman; syntactic structures in the style of the Penn TreeBank (Marcus et al. , 1993) provided by Ann Taylor; and an alternative annotation for the F0 aspects of prosody, known as Tilt (Taylor, 1998) and provided by its inventor, Paul Taylor.",0,original
"The flow using non-local features in two-stage architecture 2.4 Results We employ BIOE1 label scheme for the NER task because we found it performs better than IOB2 on Bakeoff 2006 (Levow, 2006) NER MSRA and CityU corpora.",0,original
"Thenthewordalignment is refined by performing grow-diag-final method (Koehn et al., 2003).",0,original
"In (Teevan et al., 1996) it was observed that a significant percent of the queries made by a user in a search engine are associated to a repeated search.",0,original
"Second, we discuss the work done by (Barzilay & Lee, 2003) who use clustering of paraphrases to induce rewriting rules.",0,original
"Instead of analyzing sentences directly, AUCONTRAIRE relies on the TEXTRUNNER Open Information Extraction system (Banko et al., 2007; Banko and Etzioni, 2008) to map each sentence to one or more tuples that represent the entities in the sentences and the relationships between them (e.g., was born in(Mozart,Salzburg)).",0,original
"5 Data Sets and Supervised Tagger 5.1 Source Domain: WSJ We used sections 02-21 of the Penn Treebank (Marcus et al. , 1993) for training.",0,original
"This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al.",0,original
"The starting point is the log likelihood ratio (log , Dunning 1993).",0,original
"Parallel bilingual corpora have been shown to provide a rich source of constraints for statistical analysis (Brown et al. 1990; Gale and Church 1991; Gale, Church, and Yarowsky 1992; Church 1993; Brown et al. 1993; Dagan, Church, and Gale 1993; Department of Computer Science, University of Science and Technology, Clear Water Bay, Hong Kong.",0,original
"When we run a phrase-based system, Pharaoh (Koehn et al. , 2003; Koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations: (4) [Aozhou] [shi] [yu] [Bei Han] [you] [bangjiao]1 [de shaoshu guojia zhiyi] [Australia] [is] [dipl.",0,original
"These rules can be handcrafted grammar rules, such as those of (LangkildeGeary, 2002; Carroll and Oepen, 2005), created semi-automatically (Belz, 2007) or, alternatively, extracted fully automatically from treebanks (Bangalore and Rambow, 2000; Nakanishi et al. , 2005; Cahill and van Genabith, 2006).",0,original
953 2 Bilexicalization of Inversion Transduction Grammar The Inversion Transduction Grammar of Wu (1997) models word alignment between a translation pair of sentences by assuming a binary synchronous tree on top of both sides.,0,original
"Recall that the log likelihood of our model is:  d parenleftBigg Lorig(Dd;d) i (d,i ,i)2 2 2d parenrightBigg  i (,i)2 2 2 We now introduce a new variable d = d , and plug it into the equation for log likelihood:  d parenleftBigg Lorig(Dd;d +) i (d,i)2 2 2d parenrightBigg  i (,i)2 2 2 The result is the model of (Daume III, 2007), where the d are the domain-specific feature weights, and d are the domain-independent feature weights.",0,original
Recent work emphasizes a corpus-based unsupervised approach [Dagon and Itai 1994; Yarowsky 1992; Yarowsky 1995] that avoids the need for costly truthed training data.,0,original
These tables were computed from a small fragment of the Canadian Hansards that has been used in a number of other studies: Church (1993) and Simard et al (1992).,0,original
"2 Incremental Parsing This section gives a description of Collins and Roarks incremental parser (Collins and Roark, 2004) and discusses its problem.",0,original
Model weights were also trained following Och (2003).,0,original
"However, with their system trained on the medical corpus and then tested on the Wall Street Journal corpus (Marcus et al., 1993), they achieve an overall prediction accuracy of only 54%.",0,original
"Phrase pairs are extracted up to a fixed maximum length, since very long phrases rarely have a tangible impact during translation (Koehn et al., 2003).",0,original
"The loglinear model weights are learned using Chiangs implementation of the maximum BLEU training algorithm (Och, 2003), both for the baseline, and the WSD-augmented system.",0,original
"[subjective] So far, none of the studies in sentiment detection (e.g. Wilson et al. , 2005; Pang et al. , 2002) or opinion extraction (e.g. Hu and Liu, 2004; Popescu and Etzioni, 2005) have specifically looked at the role of superlatives in these areas.",0,original
"(1999) proposed a summarization system based on the draft and revision. Jing and McKeown (2000) proposed a system based on extraction and cut-and-paste generation. Our abstractors performed the same cut-and-paste operations that Jing and McKeown noted in their work, and we think that our two-step model will be a reasonable starting point for our subsequent research.",0,original
"For subproblem (a), we have devised a new method, based on LPR, which has some good properties not shared by the methods proposed so far (Alshawi and Carter, 1995; Chang et al. , 1992; Collins and Brooks, 1995; Hindle and Rooth, 1991; Ratnaparkhi et al. , 1994; Resnik, 1993).",0,original
"When an S alignment exists, there will always also exist a P alignment such that P a65 S. The English sentences were parsed using a state-of-the-art statistical parser (Charniak, 2000) trained on the University of Pennsylvania Treebank (Marcus et al. , 1993).",0,original
"These alignments can be obtained from single-word models (Brown et al. , 1993) using the available public software GIZA++ (Och and Ney, 2003).",0,original
"In addition to this phrase translation probability feature, Hieros feature set includes the inverse phrase translation probability log p( f|e), lexical weights lexwt( f|e) and lexwt(e| f), which are estimates of translation quality based on word-level correspondences (Koehn et al., 2003), and a rule penalty allowing the model to learn a preference for longer or shorter derivations; see (Chiang, 2007) for details.",0,original
"Bilexical CFG is at the heart of most modern statistical parsers (Collins, 1997; Charniak, 1997), because the statistics associated with word-specific rules are more informative for disambiguation purposes.",0,original
"When evaluated against the state-of-the-art, phrase-based decoder Pharaoh (Koehn, 2004), using the same experimental conditions  translation table trained on the FBIS corpus (7.2M Chinese words and 9.2M English words of parallel text), trigram language model trained on 155M words of English newswire, interpolation weights a65 (Equation 2) trained using discriminative training (Och, 2003) (on the 2002 NIST MT evaluation set), probabilistic beam a90 set to 0.01, histogram beam a58 set to 10  and BLEU (Papineni et al. , 2002) as our metric, the WIDL-NGLM-Aa86 a129 algorithm produces translations that have a BLEU score of 0.2570, while Pharaoh translations have a BLEU score of 0.2635.",0,original
Wall-Street Journal (WSJ) Sections 15-18 and 20 were used by Ramshaw and Marcus (1995) as training and test data respectively for evaluating their base-NP chunker.,0,original
"We observe that AER is loosely correlated to BLEU ( = 0.81) though the relation is weak, as observed earlier by Fraser and Marcu (2006a).",0,original
"Feature selection methods have been proposed in the maximum-entropy literature by several authors (Ratnaparkhi, Roukos, and Ward 1994; Berger, Della Pietra, and Della Pietra 1996; Della Pietra, Della Pietra, and Lafferty 1997; Papineni, Roukos, and Ward 1997, 1998; McCallum 2003; Zhou et al. 2003; Riezler and Vasserman 2004).",0,original
"2 Baseline Coreference Resolution System Our baseline coreference system implements the standard machine learning approach to coreference resolution (see Ng and Cardie (2002b), Ponzetto and Strube (2006), Yang and Su (2007), for instance), which consists of probabilistic classification and clustering, as described below.",0,original
"The problem itself has started to get attention only recently (Roark and Bacchiani, 2003; Hara et al., 2005; Daume III and Marcu, 2006; Daume III, 2007; Blitzer et al., 2006; McClosky et al., 2006; Dredze et al., 2007).",0,original
"Foralllanguagepairs,weusedtheMosesdecoder (Koehnetal.,2007), whichfollowsthephrase-based statistical machine translation approach (Koehn et al., 2003), with default settings as a starting point.",0,original
"Thus, one conclusion from that line of work is that as soon as there is a reasonable (often even small) amount of labeled target data, it is often more fruitful to either just use that, or to apply simple adaptation techniques (Daume III, 2007; Plank and van Noord, 2008).",0,original
"More specifically, by using translation probabilities, we can rewrite equation (11) and (12) as follow: nullnullnullnullnull null nullnull null nullnullnull null null nullnullnullnull null nullnull null null nullnull null   nullnull null null | null null null null nullnull null nullnull null nullnull null null null null nullnull null nullnull null  null null 1nullnull null nullnull null null null nullnull|nullnull (13) nullnullnullnullnull null nullnull null nullnullnull null null nullnullnullnull null nullnull null null nullnull null   nullnull null null | null null null null nullnull null nullnull null nullnull null null null null nullnull null nullnull null  null null 1nullnull null nullnull null null null nullnull|nullnull  (14) where nullnullnullnull|null null null  denotes the probability that topic term null  is the translation of null null . In our experiments, to estimate the probability nullnullnullnull|null null null , we used the collections of question titles and question descriptions as the parallel corpus and the IBM model 1 (Brown et al., 1993) as the alignment model.",0,original
"Och showed thatsystemperformanceisbestwhenparametersare optimizedusingthesameobjectivefunctionthatwill be used for evaluation; BLEU (Papineni et al. , 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al. , 2006).",0,original
"Haghighi and Klein (2006) develop a prototype-driven approach, which requires just a few prototype examples for each POS tag and exploits these labeled words to constrain the labels of their distributionally similar words.",0,original
"When we have a junction tree for each document, we can efficiently perform belief propagation in order to compute argmax in Equation (1), or the marginal probabilities of cliques and labels, necessary for the parameter estimation of machine learning classifiers, including perceptrons (Collins, 2002), and maximum entropy models (Berger et al., 1996).",0,original
"In open-domain opinion extraction, some approaches use syntactic features obtained from parsed input sentences (Choi et al. , 2006; Kim and Hovy, 2006), as is commonly done in semantic role labeling.",0,original
"Word Senses Sample Size Feedback Size % Correct % Correct per Sense Total drug narcotic 65 100 92.3 90.5 medicine 83 65 89.1 sentence judgment 23 327 100.0 92.5 grammar 4 42 50.0 suit court 212 1,461 98.6 94.8 garment 21 81 55.0 player performer 48 230 87.5 92.3 participant 44 1,552 97.7 the feedback sets) consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods (Sch~itze 1992; Yarowsky 1995).",0,original
"Most SMT models (Brown et al. , 1993; Vogel et al. , 1996) try to model word-to-word corresl)ondences between source and target words using an alignment nmpl)ing from source l)osition j to target position i = aj.",0,original
"4 Related Work 4.1 Acquisition of Classes of Instances Although some researchers focus on re-organizing or extending classes of instances already available explicitly within manually-built resources such as Wikipedia (Ponzetto and Strube, 2007) or WordNet (Snow et al., 2006) or both (Suchanek et al., 2007), a large body of previous work focuses on compiling sets of instances, not necessarily labeled, from unstructured text.",0,original
"The results of these studies have important applications in lexicography, to detect lexicosyntactic regularities (Church and Hanks, 19901 (Calzolari and Bindi,1990), such as, for example~ support verbs (e.g. ""make-decision"") prepositional verbs (e.g. ""rely-upon"") idioms, semantic relations (e.g. ""part_of"") and fixed expressions (e.g. ""kick the bucket"").",0,original
"The analyser--and therefore the generator-includes exception lists derived from WordNet (version 1.5: Miller et al. , 1993).",0,original
"BLEU (Papineni et al., 2002), NIST (Doddington, 2002).",0,original
The most direct comparison is between our system and those presented in Cahill and van Genabith (2006) and Hogan et al.,0,original
"Methods for doing so, for stochastic parser output, are described by Johnson (2002) and Cahill et al (2004).",0,original
"Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency.",0,original
"For a given choice of q and f, the IIS algorithm (Berger et al. , 1996) can be used to find maximum likelihood values for the parameters ~.",0,original
"In addition, IC is stable even for relatively low frequency words, which can be contrasted with Fano's mutual information formula recently used by Church and Hanks (1990) to compute word cooccurrence patterns in a 44 million word corpus of Associated Press news stories.",0,original
"Collins (2002) adapted the perceptron learning algorithm to tagging tasks, via sentence-based global feedback.",0,original
"This task is closely related to both named entity recognition (NER), which traditionally assigns nouns to a small number of categories and word sense disambiguation (Agirre and 1http://class.inrialpes.fr/ Rigau, 1996; Yarowsky, 1995), where the sense for a word is chosen from a much larger inventory of word senses.",0,original
"Training of the phrase translation model builds on top of a standard statistical word alignment over the training corpus of parallel text (Brown et al. , 1993) for identifying corresponding word blocks, assuming no further linguistic analysis of the source or target language.",0,original
Forest reranking with a language model can be performed over this n-ary forest using the cube growing algorithm of Huang and Chiang (2007).,0,original
In this data set the 4-tuples of the test and training sets were extracted from Penn Treebank Wall Street Journal \[Marcus et al. 1993\].,0,original
"The data sets used are the standard data sets for this problem (Ramshaw and Maxcus, 1995; Argamon et al. , 1999; Mufioz et al. , 1999; Tjong Kim Sang and Veenstra, 1999) taken from the Wall Street Journal corpus in the Penn Treebank (Marcus et al. , 1993).",0,original
Table 6 contrasts our results with those from Collins (2002).,0,original
"First, we show how one can use an existing statistical translation model (Brown et al. , 1993) in order to automatically derive a statistical TMEM.",0,original
"Relative frequency ratio (RFR) of terms between two different corpora can also be used to discover domain-oriented multi-word terms that are characteristic of a corpus when compared with another (Damerau, 1993).",0,original
Dolan (1994) observed that sense division in MRD is frequently too free for the purpose of WSD.,0,original
"Finally, following Haghighi and Klein (2006) and Johnson (2007) we can instead insist that at most one HMM state can be mapped to any part-of-speech tag.",0,original
"However, the fact that the DGSSN uses a large-vocabulary tagger (Ratnaparkhi, 1996) as a preprocessing stage may compensate for its smaller vocabulary.",0,original
"We implement some global constraints and include unary constraints which were largely imported from the list of seed words used in (Haghighi and Klein, 2006).",0,original
"7 Discussion As we mentioned, there are some algorithms similar to ours (Collins and Roark, 2004; Daume III and Marcu, 2005; McDonald and Pereira, 2006; Liang et al. , 2006).",0,original
"Probability estimates of the RHS given the LHS are often smoothed by making a Markov assumption regarding the conditional independence of a category on those more than k categories away (Collins, 1997; Charniak, 2000): P(X  Y1Yn)= P(Y1|X) nY i=2 P(Yi|X,Y1 Yi1)  P(Y1|X) nY i=2 P(Yi|X,Yik Yi1).",0,original
"We chose this inverse direction since it can be integrated directly into the decoder and, thus, does not rely on a two-pass approach using reranking, as it is the case for (Hasan et al., 2008).",0,original
"We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy (Pedersen et al. , 2004).",0,original
"Above the phrase level, some models perform no reordering (Zens and Ney 2004; Kumar, Deng, and Byrne 2006), some have a simple distortion model that reorders phrases independently of their content (Koehn, Och, and Marcu 2003; Och and Ney 2004), and some, for example, the Alignment Template System (Och et al. 2004; Thayer et al. 2004), hereafter ATS, and the IBM phrase-based system (Tillmann 2004; Tillmann and Zhang 2005), have phrase-reordering models that add some lexical sensitivity.",0,original
"Our approach is based on earlier work on LFG semantic form extraction (van Genabith, Sadler, and Way 1999) and recent progress in automatically annotating the Penn-II and Penn-III Treebanks with LFG f-structures (Cahill et al. 2002; Cahill, McCarthy, et al. 2004).",0,original
"(2003), which is based on that of Och and Ney (2004).",0,original
"In this work, we use the GIZA++ implementation (Och and Ney, 2003) of IBM Model 5 (Brown et al. , 1993).",0,original
"Combining statistical and parsing methods has been done by (Hindle, 1990; Hindle and Rooths,1991) and (Smadja and McKewon, 1990; Smadja,1991).",0,original
Richman and Schone (2008) used a method similar to Nothman et al.,0,original
"This contrasts with alternative alignment models such as those of Melamed (1998) and Wu (1997), which impose a one-to-one constraint on alignments.",0,original
"Results are reported using lowercase BLEU (Papineni et al., 2002).",0,original
"For example, Barzilay and Lee (2003) applied multiple-sequence alignment (MSA) to parallel news sentences and induced paraphrasing patterns for generating new sentences.",0,original
"The tagger described in this paper is based on the standard Hidden Markov Model architecture (Charniak et al. , 1993; Brants, 2000).",0,original
"3 Candidates extraction on Suffix array Suffix array (also known as String PATarray)(Manber et al, 1993) is a compact data structure to handle arbitrary-length strings and performs much powerful on-line string search operations such as the ones supported by PAT-tree, but has less space overhead.",0,original
"We follow the approach of bootstrapping from a model with a narrower parameter space as is done in, e.g. Och and Ney (2000) and Fraser and Marcu (2006).",0,original
"Wehope the present work will, together with Talbot and Osborne (2007), establish the Bloom filter as a practical alternative to conventional associative data structures used in computational linguistics.",0,original
"This text was part-of-speech tagged using the Xerox HMM tagger (Cutting et al. , 1992).",0,original
"To accommodate multiple overlapping features on observations, some other approaches view the sequence labeling problem as a sequence of classification problems, including support vector machines (SVMs) (Kudo & Matsumoto 2001) and a variety of other classifiers (Punyakanok & Roth 2001; Abney et al. 1999; Ratnaparkhi 1996).",0,original
"1 Introduction In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [Black, 1992] [Briscoe, 1993] [Brown, 1991] [Charniak, 1997] [Collins, 1996] [Collins, 1997] [Magerman, 1991] [Magerman, 1992] [Magerman, 1995] [Eisner, 1996].",0,original
"Regardless of whether it takes the form of dictionaries (Lesk 1986; Guthrie et al. 1991; Dagan, Itai, and Schwall 1991; Karov and Edelman 1996), thesauri (Yarowsky 1992; Walker and Amsler 1986), bilingual corpora (Brown et al. 1991; Church and Gale 1991), or hand-labeled training sets (Hearst 1991; Leacock, Towell, and Voorhees 1993; Niwa and Nitta 1994; Bruce and Wiebe 1994), providing information for sense definitions can be a considerable burden.",0,original
"3 We then run Collins parser (1997), using just the sentence pairs where parsing succeeds with a negative log likelihood below 200.",0,original
"The normalization is visualized as a translation problem where messages in the SMS language are to be translated to normal English using a similar phrase-based statistical MT method (Koehn et al. , 2003).",0,original
"On the other hand, (Dagan et al. , 1993) proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences.",0,original
"The tree is produced by a state-of-the-art dependency parser (McDonald et al. , 2005) trained on the Wall Street Journal Penn Treebank (Marcus et al. , 1993).",0,original
"Appendix B gives a sketch of one such approach, which is based on results from Collins, Schapire, and Singer (2002).",0,original
The model of Haghighi and Klein (2007) incorporated a latent variable for named entity class.,0,original
"5.2 Impact on translation quality As reported in Table 3, small increases in METEOR (Banerjee and Lavie, 2005), BLEU (Papineni et al., 2002) and NIST scores (Doddington, 2002) suggest that SMT output matches the references better after postprocessing or decoding with the suggested lemma translations.",0,original
"(2004), Ponzetto and Strube (2006)).",0,original
"They are not used in LN, but they are known to be useful for WSD (Tanaka et al., 2007; Magnini et al., 2002).",0,original
"Moses used the development data for minimum error-rate training (Och, 2003) of its small number of parameters.",0,original
"We were given around 15K sentences of labeled text from the Wall Street Journal (WSJ) (Marcus et al. , 1993; Johansson and Nugues, 2007) as well as 200K unlabeled sentences.",0,original
"(Brown et al. , 1992)).",0,original
"The WordNet::Similarity package (Pedersen et al. , 2004) implements this distance measure and was used by the authors.",0,original
"There are good reasons for using such a hand-crafted, genre-specific verb lexicon instead of a general resource such as WordNet or Levins (1993) classes: Many verbs used in the domain of scientific argumentation have assumed a specialized meaning, which our lexicon readily encodes.",0,original
"In the rest of the paper we use the following notation, adapted from Collins (2002).",0,original
"(Luo et al., 2004; Ponzetto and Strube, 2006) for other approaches with an evaluation based on true mentions only).",0,original
"1 Introduction Word alignment is a critical component in training statistical machine translation systems and has received a significant amount of research, for example, (Brown et al., 1993; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2007), including work leveraging syntactic parse trees, e.g., (Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008).",0,original
"For instance, instead of representing the polarity of a term using a binary value, Mullen and Collier (2004) use Turneys (2002) method to assign a real value to represent term polarity and introduce a variety of numerical features that are aggregate measures of the polarity values of terms selected from the document under consideration.",0,original
"We extract a phrase table using the Moses pipeline, based on Model 4 word alignments generated from GIZA++ (Och and Ney, 2003).",0,original
"Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003).",0,original
"(1) Here, the candidate generator gen(s) enumerates candidates of destination (correct) strings, and the scorer P(t|s) denotes the conditional probability of the string t for the given s. The scorer was modeled by a noisy-channel model (Shannon, 1948; Brill and Moore, 2000; Ahmad and Kondrak, 2005) and maximum entropy framework (Berger et al., 1996; Li et al., 2006; Chen et al., 2007).",0,original
Standard data sets for machine learning approaches to this task were put forward by Ramshaw and Marcus (1995).,0,original
"In this paper we present MapReduce implementations of training algorithms for two kinds of models commonly used in statistical MT today: a phrasebased translation model (Koehn et al., 2003) and word alignment models based on pairwise lexical translation trained using expectation maximization (Dempster et al., 1977).",0,original
"In shift-reduce parsing, further mistakes are often caused by previous ones, so only the first mistake in each sentence (if there is one) is easily identifiable;7 this is also the argument for early update in applying perceptron learning to these incremental parsing algorithms (Collins and Roark, 2004) (see also Section 2).",0,original
Collins (2002) proposed a Perceptron like learning algorithm to solve sequence classification in the traditional left-to-right order.,0,original
"There bas recently been work in the detection of semantically related nouns via, for example, shared argument structures (Hindle 1990), and shared dictionary definition context (Wilks e al. 1990).",0,original
"While recent proposals for evaluation of MT systems have involved multi-parallel corpora (Thompson and Brew, 1996; Papineni et al. , 2002), statistical MT algorithms typically only use one-parallel data.",0,original
"However, the pb features yields no noticeable improvement unlike in prefect lexical choice scenario; this is similar to the findings in (Koehn et al. , 2003).",0,original
"W(S,T) = summationdisplay uS,vT w(u,v) Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice, using the maximum flow algorithm (Pang and Lee, 2004; Cormen et al., 2002).",0,original
"For a comparison, we also include the ROUGE-1 Fscores (Lin, 2004) of each system output against the human compressed sentences.",0,original
"As machine learners we used SVM-light1 (Joachims, 1998) and the MaxEnt decider from the Stanford Classifier2 (Manning and Klein, 2003).",0,original
"Smadja (1993) also detailed techniques for collocation extraction and developed a program called XTRACT, which is capable of computing flexible collocations based on elaborated statistical calculation.",0,original
"This improvement is close to that of one sense per discourse (Yarowsky, 1995) (improvement ranging from 1.3% to 1.7%), which seems to be a sensible upper bound of the proposed method.",0,original
"In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology (Cohen and Sarawagi, 2004; Collins and Singer, 1999; Haghighi and Klein, 2006; Thelen and Riloff, 2002).",0,original
"Formally, transformational rules ri presented in (Galley et al. , 2004) are equivalent to 1-state xRs transducers mapping a given pattern (subtree to match in pi) to a right hand side string.",0,original
"When the training text is adequate to estimate the tagger parameters, more efficient stochastic taggers (Dermatas and Kokkinakis 1994; Maltese and Mancini 1991; Weischedel et al. 1993) and training methods can be implemented (Merialdo 1994).",0,original
"Several approaches for learning from both labeled and unlabeled data have been proposed (Yarowsky, 1995; Blum and Mitchell, 1998; Collins and Singer, 1999) where the unlabeled data is utilised to boost the performance of the algorithm.",0,original
"For example, given that each semantic class exhibits a particular syntactic behaviour, information on the semantic class should improve POStagging for adjective-noun and adjective-participle ambiguities, probably the most difficult distinctions both for humans and computers (Marcus et al. , 1993; Brants, 2000).",0,original
"Solving this first methodological issue, has led to solutions dubbed hereafter as unlexicalized statistical parsing (Johnson, 1998; Klein and Manning, 2003a; Matsuzaki et al., 2005; Petrov et al., 2006).",0,original
"Several frameworks for finding translation equivalents or translation units in machine translation, such as \[Chang and Su 1993, Isabelle et al.1993\] and other example-based MT approaches, might be used to select the preferred mapping.",0,original
"The examples represent seven-word windows of words and their respective (predicted) part-of-speech tags, and each example is labeled with a class using the IOB type of segmentation coding as introduced by Ramshaw and Marcus (1995), marking whether the middle word is inside (I), outside (O), or at the beginning (B) of a chunk.",0,original
"In particular, Hockenmaier and Steedman (2001) report a generative model for CCG parsing roughly akin to the Collins parser (Collins, 1997) specific to CCG.",0,original
"SO can be used to classify reviews (e.g. , movie reviews) as positive or negative (Turney, 2002), and applied to subjectivity analysis such as recognizing hostile messages, classifying emails, mining reviews (Wiebe et al. , 2001).",0,original
"For this we aligned 170,863 pairs of Arabic/English newswire sentences from LDC, trained a state-of-the-art syntax-based statistical machine translation system (Galley et al., 2006) on these sentences and alignments, and measured BLEU scores (Papineni et al., 2002) on a separate set of 1298 newswire test sentences.",0,original
"Unlike previous annotations of sentiment or subjectivity (Wiebe et al. , 2005; Pang and Lee, 2004), which typically relied on binary 0/1 annotations, we decided to use a finer-grained scale, hence allowing the annotators to select different degrees of emotional load.",0,original
"1 Introduction In this paper, we study the use of so-called word trigger pairs (for short: word triggers) (Bahl et al. , 1984, Lau and Rosenfeld, 1993, Tillmann and Ney, 1996) to improve an existing language model, which is typically a trigram model in combination with a cache component (Ney and Essen, 1994).",0,original
"Treebank (Marcus et al., 1993), six of which are errors.",0,original
"To derive the joint counts c(?s,?t) from which p(?s|?t) and p(?t|?s) are estimated, we use the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993).",0,original
"In line with the reports in (Luo and Zitouni, 2005) we do observe the performance improvement against the baseline (NORM) for all the domains.",0,original
"4For justification for this kind of logical form for sentences with quantifiers and inteusional operators, see Hobbs(1983) and Hobbs (1985a).",0,original
"The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al. , 1993), annotated in the framework of Rhetorical Structure Theory.",0,original
"The lexical scores are computed as the (unnormalized) log probability of the Viterbi alignment for a phrase pair under IBM word-translation Model 1 (Brown et al. , 1993).",0,original
"Large treebanks are available for major languages, however these are often based on a speci c text type or genre, e.g. nancial newspaper text (the Penn-II Treebank (Marcus et al. , 1993)).",0,original
"Under the maximum entropy framework (Berger et al. , 1996), evidence from different features can be combined with no assumptions of feature independence.",0,original
"We use a simple, single parameter distribution, with  = 8.0 throughout P(K|m,e) = P(K|m,l)  K Word-to-Phrase Alignment Alignment is a Markov process that specifies the lengths of phrases and their alignment with source words P(aK1,hK1,K1 |K,m,e) = Kproductdisplay k=1 P(ak,hk,k|ak1,k1,e) = Kproductdisplay k=1 p(ak|ak1,hk;l)d(hk)n(k;eak) The actual word-to-phrase alignment (ak) is a firstorder Markov process, as in HMM-based word-toword alignment (Vogel et al. , 1996).",0,original
"Turney (Turney, 2001; Turney, 2002) reported that the NEAR operator outperformed simple page co-occurrence for his purposes; our early experiments informally showed the same for this work.",0,original
See Weeds and Weir (2005) for an overview of other measures.,0,original
"Statistic-based algorithms based on Belief Network(Murphy, 2001) such as Hidden-MarkovModel(HMM)(Cutting, 1992)(Thede, 1999), Lexicalized HMM(Lee, 2000) and Maximal-Entropy model(Ratnaparkhi, 1996) use the statistical information of a manually tagged corpus as background knowledge to tag new sentences.",0,original
"To model aspects of co-occurrence association that might be obscured by raw frequency, the log-likelihood ratio G2 (Dunning, 1993) was also used to transform the feature space.",0,original
"This differs from typical generative settings for IR and MT (Ponte and croft, 1998; Brown et al. , 1993), where all conditioned events are disjoint by construction.",0,original
"Consequently, the mainstream research in the literature has been focused on the modeling and utilization of local and sentential contexts, either linguistically in a rule-based framework or statistically in a searching and optimization set-up (Gan, Palmer and Lua 1996; Sproat, Shih, Gale and Chang 1996; Wu 1997; Gut 1997).",0,original
"5 Bidirectional Sequence Classification Bidirectional POS tagging (Shen et al., 2007), the current state of the art for English, has some properties that make it appropriate for Icelandic.",0,original
"The Logllkelihood Ratio, G 2, is a mathematically well-grounded and accurate method for calculating how ""surprising"" an event is (Dunning, 1993).",0,original
"1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention (Cong et al., 2008; Ding et al., 2008).",0,original
"This probability is computed using IBMs Model 1 (Brown et al., 1993): P(Q|A) = productdisplay qQ P(q|A) (3) P(q|A) = (1)Pml(q|A)+Pml(q|C) (4) Pml(q|A) = summationdisplay aA (T(q|a)Pml(a|A)) (5) where the probability that the question term q is generated from answer A, P(q|A), is smoothed using the prior probability that the term q is generated from the entire collection of answers C, Pml(q|C).",0,original
"It is therefore desirable to have dedicated servers to load parts of the LM3  an idea that has been exploited by (Zhang et al., 2006; Emami et al., 2007; Brants et al., 2007).",0,original
"We used the heuristic combination described in (Och and Ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (Koehn et al. , 2003).",0,original
"Second, the word alignment is refined by a grow-diag-final heuristic (Koehn et al. , 2003).",0,original
"This leads to a good amount of work in this area (Ratnaparkhi et al. , 1994; Berger et al. , 1996; Pietra et al, 1997; Zhou et al. , 2003; Riezler and Vasserman, 2004) In the most basic approach, such as Ratnaparkhi et al.",0,original
We compared our system with the concepts in WordNet and Fleischman et al.s instance/concept relations (Fleischman et al. 2003).,0,original
"It is an important and growing field of natural language processing with applications in areas such as transferbased machine translation (Riezler and Maxwell, 2006) and sentence condensation (Riezler et al. , 2003).",0,original
"1 Introduction Recent approaches to statistical machine translation (SMT) piggyback on the central concepts of phrasebased SMT (Och et al. , 1999; Koehn et al. , 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process.",0,original
"We build sentencespecific zero-cutoff stupid-backoff (Brants et al., 2007) 5-gram language models, estimated using 4.7B words of English newswire text, and apply them to rescore either 10000-best lists generated by HCP or word lattices generated by HiFST.",0,original
"1 Introduction Several approaches including statistical techniques (Gale and Church, 1991; Brown et al. , 1993), lexical techniques (Huang and Choi, 2000; Tiedemann, 2003) and hybrid techniques (Ahrenberg et al. , 2000), have been pursued to design schemes for word alignment which aims at establishing links between words of a source language and a target language in a parallel corpus.",0,original
"It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al. , 1999), (Tillmann and Xia, 2003), (Koehn et al. , 2003, sec.",0,original
"The other form of hybridization ??a statistical MT model that is based on a deeper analysis of the syntactic 33 structure of a sentence ??has also long been identified as a desirable objective in principle (consider (Wu, 1997; Yamada and Knight, 2001)).",0,original
"For example, the lexicalized grammars of Collins (1997) and Charniak (1997) and the statesplit grammars of Petrov et al.",0,original
"We use the Stanford parser (Klein and Manning, 2003) with its default Chinese grammar, the GIZA++ (Och and Ney, 2000) alignment package with its default settings, and the ME tool developed by (Zhang, 2004).",0,original
This therefore suggests that better parameters are likely to be learned in the 2Haghighi and Kleins (2007) generative coreference model mirrors this in the posterior distribution which it assigns to mention types given their salience (see their Table 1).,0,original
"Building on a recent proposal in this direction by Turney (2008), we propose a generic method of this sort, and we test it on a set of unrelated tasks, reporting good performance across the board with very little task-specific tweaking.",0,original
"503 Bikel Intricacies of Collins Parsing Model Table 4 Overall parsing results using only details found in Collins (1997, 1999).",0,original
"To do this, we first identify initial phrase pairs using the same criterion as previous systems (Och and Ney, 2004; Koehn et al. , 2003): Definition 1.",0,original
"2 Phrasal Inversion Transduction Grammar We use a phrasal extension of Inversion Transduction Grammar (Wu, 1997) as the generative framework.",0,original
"The model presented above is based on our previous work (Jiang and Zhai, 2007c), which bears the same spirit of some other recent work on multitask learning (Ando and Zhang, 2005; Evgeniou and Pontil, 2004; Daume III, 2007).",0,original
"3 The statistical model We use the Xerox part-of-speech tagger (Cutting et al. , 1992), a statistical tagger made at the Xerox Palo Alto Research Center.",0,original
Carletta (1996) and Ros6 (1995) point out the importance of taking into account the expected chance agreement among judges when computing whether or not judges agree significantly.,0,original
"The Penn Treebank annotation (Marcus et al. , 1993) was chosen to be the first among equals: it is the starting point for the merger and data from other annotations are attached at tree nodes.",0,original
"Attempts to alleviate this tagbottleneck i~lude tmotstr~ias (Te~ ot ill,, 1996; Hearst, 1991) and unsupervised algorith~ (Yarowsky, 199s) Dictionary-based approaches rely on linguistic knowledge sources such as ma~l~i,~e-readable dictionaries (Luk, 1995; Veronis and Ide, 1990) and WordNet (Agirre and Rigau, 1996; Resnik, 1995) and e0(ploit these for word sense disaznbiguation.",0,original
"2 Related Work Syntax-based translation models engaged with SCFG have been actively investigated in the literature (Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Galley et al., 2004; Satta and Peserico, 2005).",0,original
"Typically, a phrase-based SMT system includes a feature that scores phrase pairs using lexical weights (Koehn et al., 2003) which are computed for two directions: source to target and target to source.",0,original
"Lexical cues of differing complexities have been used, including single words and Ngrams (e.g. , (Mullen and Collier, 2004; Pang et al. , 2002; Turney, 2002; Yu and Hatzivassiloglou, 2003; Wiebe et al. , 2004)), as well as phrases and lexico-syntactic patterns (e.g, (Kim and Hovy, 2004; Hu and Liu, 2004; Popescu and Etzioni, 2005; Riloff and Wiebe, 2003; Whitelaw et al. , 2005)).",0,original
"(Yarowsky, 1995) also uses wide context, but incorporates the one-senseper-discourse and one-sense-per-collocation constraints, using an unsupervised learning technique.",0,original
Yarowsky (1995) has proposed a bootstrapping method for word sense disambiguation.,0,original
"The k-best list is also frequently used in discriminative learning to approximate the whole set of candidates which is usually exponentially large (Och, 2003; McDonald et al., 2005).",0,original
"The tagger from (Ratnaparkhi, 1996) first annotates sentences of raw text with a sequence of partof-speech tags.",0,original
"GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007).",0,original
"2.2.1 The evaluator The evaluator is a function p(t\[t', s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t' which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al. , 1993), but it diflhrs in one significant aspect: whereas the IBM model involves a ""noisy channel"" decomposition, we use a linear combination of separate predictions from a language model p(t\[t') and a translation model p(t\[s).",0,original
"Automatic measures like BLEU (PAPINENI et al. , 2001) or NIST (DODDINGTON, 2002) do so by counting sequences of words in such paraphrases.",0,original
"The simple model 1 (Brown et al. , 1993) for the translation of a SL sentence d = dldt in a TL sentence e = el em assumes that every TL word is generated independently as a mixture of the SL words: m l P(e\[d),,~ H ~ t(ej\[di) (2) j=l i=O In the equation above t(ej\[di) stands for the probability that ej is generated by di.",0,original
"Typically, the local context around the 215 word to be sense-tagged is used to disambiguate the sense (Yarowsky, 1993), and it is common for linguistic resources such as WordNet (Li et al. , 1995; Mihalcea and Moldovan, 1998; Ramakrishnan and Prithviraj, 2004), or bilingual data (Li and Li, 2002) to be employed as well as more longrange context.",0,original
"2.3 Feature Functions Our phrase-based model uses a standard pharaoh feature functions listed as follows (Koehn et al. , 2003):  Relative-count based phrase translation probabilities in both directions.",0,original
"Other methods include rule-based systems (Brill, 1995), maximum entropy models (Ratnaparkhi, 1996), and memory-based models (Daelemans et al. , 1996).",0,original
"3http://www.openoffice.org Another corpora based method due to Turney and Littman (2003) tries to measure the semantic orientation O(t) for a term t by O(t) = summationdisplay tiS+ PMI(t,ti) summationdisplay tjS PMI(t,tj) where S+ and S are minimal sets of polar terms that contain prototypical positive and negative terms respectively, and PMI(t,ti) is the pointwise mutual information (Lin, 1998b) between the terms t and ti.",0,original
"Actually, now that SMT has reached some maturity, we see several attempts to integrate more structure into these systems, ranging from simple hierarchical alignment models (Wu 1997, Chiang 2005) to syntax-based statistical systems (Yamada and Knight 2001, Zollmann and Venugopal 2006).",0,original
"However, feature/class functions are traditionally deflned as binary (Berger et al. , 1996); hence, explicitly incorporating frequencies would require difierent functions for each count (or count bin), making training impractical.",0,original
We use the version extracted and preprocessed by Daume III and Campbell (2007).,0,original
"Confusion network and re-decoding have been well studied in the combination of different MT systems (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b).",0,original
"Before parsing, POS tags are assigned to the input sentence using our reimplementation of the POStagger from Collins (2002).",0,original
"grow-diagfinal (Koehn et al., 2003)).",0,original
"We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and Hindles (1990) and Lins (1998) mutual information-based metrics.",0,original
The tagging scheme is a variant of the IOB scheme originally put forward by Ramshaw and Marcus (1995).,0,original
"While this heuristic estimator gives good empirical results, it does not seem to optimize any intuitively reasonable objective function of the (wordaligned) parallel corpus (see e.g., (DeNero et al., 2006)) The mounting number of efforts attacking this problem over the last few years (DeNero et al., 2006; Marcu and Wong, 2002; Birch et al., 2006; Moore and Quirk, 2007; Zhang et al., 2008) exhibits its difficulty.",0,original
"In the iNeast system (Leuski et al. , 2003), the identification of relevant terms is oriented towards multi-document summarization, and they use a likelihood ratio (Dunning, 1993) which favours terms which are representative of the set of documents as opposed to the full collection.",0,original
"W(S,T) = summationdisplay uS,vT w(u,v) Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice, using the maximum flow algorithm (Pang and Lee, 2004; Cormen et al., 2002).",0,original
"The algorithm is exactly the same as the one described in (Ratnaparkhi, 1996) to find the most probable part-of-speech sequence.",0,original
"Where Pantel and Lin use Lins (1998) measure, we use Wu and Palmers (1994) measure.",0,original
"While this is certainly a daunting task, it is possible that for annotation studies that do not require expert annotators and extensive annotator training, the newly available access to a large pool of inexpensive annotators, such as the Amazon Mechanical Turk scheme (Snow et al., 2008),4 or embedding the task in an online game played by volunteers (Poesio et al., 2008; von Ahn, 2006) could provide some solutions.",0,original
"We train IBM Model-4 using GIZA++ toolkit (Och and Ney, 2003) in two translation directions and perform different word alignment combination.",0,original
An alternative training criterion therefore directly optimizes translation quality as measured by an automatic evaluation criterion (Och 2003).,0,original
"(2006) and Chiang (2007), in terms of what alignments they induce, has been discussed in Wu (1997) and Wellington et al.",0,original
"Lin (1998a)s similar word list for eat misses these but includes sleep (ranked 6) and sit (ranked 14), because these have similar subjects to eat.",0,original
"The Attr cells summarize the performance of the 6 models on the wiki table that are based on attributional similarity only (Turney, 2006).",0,original
"K-best suffix arrays have been used in autocomplete applications (Church and Thiesson, 2005).",0,original
"Since most phrases appear only a few times in training data, a phrase pair translation is also evaluated by lexical weights (Koehn et al., 2003) or term weighting (Zhao et al., 2004) as additional features to avoid overestimation.",0,original
Dunning (1993) used a likelihood ratio to test word similarity under the assumption that the words in text have a binomial distribution.,0,original
"For the Brown corpus, we based our division on (Bacchiani et al. , 2006; McClosky et al. , 2006b).",0,original
"For a detailed introduction to IBM translation models, please see (Brown et al. , 1993).",0,original
"We evaluate the summaries using the automatic evaluation tool ROUGE (Lin, 2004) (described in Section 6) and the ROUGE value works as the feedback to our learning loop.",0,original
"Some of these methods make use of prior knowledge in the form of an existing thesaurus (Resnik 1993a, 1993b; Framis 1994; Almuallim et al. 1994; Tanaka 1996; Utsuro and Matsumoto 1997), while others do not rely on any prior knowledge (Pereira, Tishby, and Lee 1993; Grishman and Sterling 1994; Tanaka 1994).",0,original
"To find these pairs automatically, wetrainedanon-sequentiallog-linearmodel that achieves a .902 accuracy (Galley et al. , 2004).",0,original
"One solution would be to apply the maximum entropy estimation technique (MaxEnt (Berger et al. , 1996)) to all of the three components of the SLM, or at least to the CONSTRUCTOR.",0,original
"It can be applied to complicated models such IBM Model-4 (Brown et al. , 1993).",0,original
"is a WordNet based relatedness measure (Pedersen et al., 2004).",0,original
"The resulting model has an exponential form with free parameters a102 a91 a24a94a93 a8 a87 a24 a10a11a10a11a10 a24a46a95 . The parameter values which maximize the likelihood for a given training corpus can be computed with the socalled GIS algorithm (general iterative scaling) or its improved version IIS (Pietra et al. , 1997; Berger et al. , 1996).",0,original
"The first two phases are approached as straightforward classification in a maximum entropy framework (Berger et al. , 1996).",0,original
"In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007).",0,original
"Previous authors have used numerous HMM-based models (Banko and Moore, 2004; Collins, 2002; Lee et al. , 2000; Thede and Harper, 1999) and other types of networks including maximum entropy models (Ratnaparkhi, 1996), conditional Markov models (Klein and Manning, 2002; McCallum et al. , 2000), conditional random elds (CRF) (Lafferty et al. , 2001), and cyclic dependency networks (Toutanova et al. , 2003).",0,original
"The main reason behind this lies in the difference between the two corpora used: Penn Treebank (Marcus et al. , 1993) and EDR corpus (EDR, 1995).",0,original
"Similarlyto(Collins and Singer, 1999; Yarowsky, 1995), we define the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y, estimated using Laplace smoothing: strength(p,y) = count(p,y) + epsilon1count(p) + kepsilon1 (3) where count(p,y) is the number of documents labeled y containing pattern p, count(p) is the overall number of labeled documents containing p, and k is the number of domains.",0,original
"Two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (Koehn et al. , 2003; Tillmann and Xia, 2003).",0,original
"For (1), the morphemes and labels for our task are: (2) kita NEG tINC inE1S chabe VT -j SC laj PREP inA1S yol S -j SC iin PRON We also consider POS-tagging for Danish, Dutch, English, and Swedish; the English is from sections 00-05 (as training set) and 19-21 (as development set) of the Penn Treebank (Marcus et al., 1993), and the other languages are from the CoNLL-X dependency parsing shared task (Buchholz and Marsi, 2006).1 We split the original training data into training and development sets.",0,original
"The earliest work in this direction are those of (Hindle, 1990), (Lin, 1998), (Dagan et al., 1999), (Chen and Chen, 2000), (Geffet and Dagan, 2004) and (Weeds and Weir, 2005).",0,original
"We can use a linear-time algorithm (Zhang et al. , 2006) to detect non-ITG movement in our high-confidence links, and remove the offending sentence pairs from our training corpus.",0,original
"Turney (2008) is the first, to the best of our knowledge, to raise the issue of a unified approach.",0,original
"In order to overcome this, several methods are proposed, including minimally-supervised learning methods (e.g. , (Yarowsky, 1995; Blum and Mitchell, 1998)), and active learning methods (e.g. , (Thompson et al. , 1999; Sassano, 2002)).",0,original
"4 Methodology 4.1 Data In order to be able to compare our results with the results obtained by other researchers, we worked with the same data sets already used by (Ramshaw and Marcus, 1995; Argamon et al. , 1998) for NP and SV detection.",0,original
"(Hughes and Ramage, 2007) described the use of a biased PageRank over the WordNet graph to compute word pair semantic relatedness using the divergence of the probability values over the graph created by each word.",0,original
"Other commonly used measures include kappa (Carletta 1996) and relative utility (Radev, Jing, and Budzikowska 2000), both of which take into account the performance of a summarizer that randomly picks passages from the original document to produce an extract.",0,original
"We refer to a3a16a5a7 as the source language string and a10 a11a7 as the target language string in accordance with the noisy channel terminology used in the IBM models of (Brown et al. , 1993).",0,original
"SGD was recently used for NLP tasks including machine translation (Tillmann and Zhang, 2006) and syntactic parsing (Smith and Eisner, 2008; Finkel et al., 2008).",0,original
"We believe that other kinds of translationunit such as n-gram (Jos et al., 2006),factoredphrasaltranslation(Koehn and Hoang, 2007), or treelet (Quirk et al., 2005) can be used in this method.",0,original
(1997) and the English parser developed by Collins (1997).,0,original
"Tillmann and Zhang (2006), Liang et al.",0,original
"4 Dependency Parsing: Baseline 4.1 Learning Model and Features According to (McDonald and Nivre, 2007), all data-driven models for dependency parsing that have been proposed in recent years can be described as either graph-based or transition-based.",0,original
"A more recent bootstrapping approach is described in (Yarowsky, 1995).",0,original
"The second uses Lin dependency similarity, a syntacticdependency based distributional word similarity resource described in (Lin, 1998a)9.",0,original
"Reported and direct speech are certainly important in discourse (Prasad et al., 2006); we do not believe, however, that they enter discourse relations of the type that RST attempts to capture.",0,original
"a65 The rest of the factors denote distorsion probabilities (d), which capture the probability that words change their position when translated from one language into another; the probability of some French words being generated from an invisible English NULL element (pa6 ), etc. See (Brown et al. , 1993) or (Germann et al. , 2001) for a detailed discussion of this translation model and a description of its parameters.",0,original
"The machine translation literature is littered with various attempts to learn a phrase-based string transducer directly from aligned sentence pairs, doing away with the separate word alignment step (Marcu and Wong, 2002; Cherry and Lin, 2007; Zhang et al., 2008b; Blunsom et al., 2008).",0,original
"Inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (Mihalcea and Tarau, 2004), text summarization (Erkan and Radev, 2004; Mihalcea, 2004), word sense disambiguation (Mihalcea et al. , 2004; Mihalcea, 2005), sentiment analysis (Pang and Lee, 2004), and sentence retrieval for question answering (Otterbacher et al. , 2005).",0,original
"The statistical methods are based on distributional analysis (we defined a measure called mutual conditioned plausibility, a derivation of the well known mutual information), and cluster analysis (a COBWEB-like algorithm for word classification is presented in \[Basili et al, 1993,a\]).",0,original
"Several authors have used mutual information and similar statistics as an objective function for word clustering (Dagan et al. , 1993; Brown et al. , 1992; Pereira et al. , 1993; Wang et al. , 1996), for automatic determination of phonemic baseforms (Lucassen & Mercer, 1984), and for language modeling for speech recognition (Ries ct al. , 1996).",0,original
"As the strength of relevance between a target compound noun t and its co-occurring word r, the feature value of r, w(t;r) is deflned by the log likelihood ratio (Dunning, 1993) 1 as follows.",0,original
"The recent work of (Haghighi and Klein, 2006) and (Quirk et al., 2005) were also sources of inspiration.",0,original
Our technique of generating negative examples is similar to the approach of Okanohara and Tsujii (2007).,0,original
"In our experiments, the class assignment is performed by maximizing the mutual information between adjacent phrases, following the line described in (Brown 301 et al. , 1992), with only the modification that candidates to clustering are phrases instead of words.",0,original
"The decision rule here is: W 0 = argmax W {Pr(W|C)} = argmax W { M summationdisplay m=1  m h m (W, C)} (3) The parameters  M 1 of this model can be optimized by standard approaches, such as the Minimum Error Rate Training used in machine translation (Och, 2003).",0,original
"The co-occurrence relation can also be based on distance in a bitext space, which is a more general representations of bitext correspondence (Dagan et al. , 1993; Resnik & Melamed, 1997), or it can be restricted to words pairs that satisfy some matching predicate, which can be extrinsic to the model (Melamed, 1995; Melamed, 1997).",0,original
"We use ROUGE (Lin, 2004) to assess summary quality using common n-gram counts and longest common subsequence (LCS) measures.",0,original
"(Snow et al., 2006; Nakov & Hearst, 2008).",0,original
"Good partof-speech results can be obtained using only the preceding category (Weischedel et al. , 1993), which is what we will be using.",0,original
History-based models for predicting the next parser action (Black et al. 1992; Magerman 1995; Ratnaparkhi 1997; Collins 1999) 3.,0,original
"108 To follow related work and to focus on the effects of the language model, we present translation resultsunderaninversiontransductiongrammar(ITG) translation model (Wu, 1997) trained on the Europarl corpus (Koehn, 2005), described in detail in Section 3, and using a trigram language model.",0,original
"Word alignment is newer, found only in a few places (Gale and Church, 1991a; Brown et al. , 1993; Dagan et al. , 1993).",0,original
"For phrase-based translation model training, we used the GIZA++ toolkit (Och et al., 2003).",0,original
"These include scripts for creating alignments from a parallel corpus, creating phrase tables and language models, binarizing phrase tables, scripts for weight optimization using MERT (Och 2003), and testing scripts.",0,original
"The typical practice of preprocessing distributional data is to remove rare word co-occurrences, thus aiming to reduce noise from idiosyncratic word uses and linguistic processing errors and at the same time form more compact word representations (e.g. , Grefenstette, 1993; Ciaramita, 2002).",0,original
Lin (2004a; 2004b) and Lin and Och (2004) proposed an LCS-based automatic evaluation measure called ROUGE-L.,0,original
"We use MXPOST tagger (Adwait, 1996) for POS tagging, Charniak parser (Charniak, 2000) for extracting syntactic relations, SVMlight1 for SVM classifier and David Bleis version of LDA2 for LDA training and inference.",0,original
"We first determine lexical heads of nonterminal nodes by using Bikels implementation of Collins head detection algorithm9 (Bikel, 2004; Collins, 1997).",0,original
Smadja (Smadja 1993) proposed a statistical model by measuring the spread of the distribution of cooccurring pairs of words with higher strength.,0,original
"The approach is evaluated by cross-validation on the WSJ treebank corpus \[Marcus et al. , 1993\].",0,original
"(2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; and Lavie?s METEOR metric (Banerjee and Lavie, 2005) can be used with additionalknowledgesuchasWordNetinordertosupport inexact lexical matches.",0,original
"The novel algorithm differs computationally from earlier work in discriminative training algorithms for SMT (Och, 2003) as follows: a90 No computationally expensive a57 -best lists are generated during training: for each input sentence a single block sequence is generated on each iteration over the training data.",0,original
"Applications of word clustering include language modeling (Brown et al., 1992), text classification (Baker and McCallum, 1998), thesaurus construction (Lin, 1998) and so on.",0,original
"The form of the maximum entropy probability model is identical to the one used in (Berger et al. , 1996; Ratnaparkhi, 1998): k f$(wi,wi-1,wi-2,at~ri) YIj=I Otj p(wilwi-l, wi-2,attri) = Z(Wi-l, wi-2, attri) k to t j=l where wi ranges over V t3 .stop.",0,original
"2 RelatedWork 2.1 Sentiment Classification Most previous work on the problem of categorizing opinionated texts has focused on the binary classification of positive and negative sentiment (Turney, 2002; Pang et al., 2002; Dave at al., 2003).",0,original
"Empirical evaluations using two standard summarization metricsthe Pyramid method (Nenkova and Passonneau, 2004b) and ROUGE (Lin, 2004)show that the best performing system is a CRF incorporating both order-2 Markov dependencies and skip-chain dependencies, which achieves 91.3% of human performance in Pyramid score, and outperforms our best-performing non-sequential model by 3.9%.",0,original
"The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997).",0,original
"Previous attempts have used, for instance, the similarities between case frames (Lin and Pan57 tel, 2001), anchor words (Barzilay and Lee, 2003; Shinyama et al. , 2002; Szepektor et al. , 2004), and a web-based method(Szepektor et al. , 2004;Geffet and Dagan, 2005).",0,original
"First, as originally advocated by Hobbs (1985), we adopt an ONTOLOGICALLY PROMISCUOUS representation that includes a wide variety of types of entities.",0,original
"We also record for each token its derivational root, using the CELEX(Baayen et al. , 1993) database.",0,original
"1 Introduction The reranking approach is widely used in parsing (Collins and Koo, 2005; Koo and Collins, 2005; Henderson and Titov, 2005; Shen and Joshi, 2003) as well as in other structured classification problems.",0,original
"We tune all feature weights automatically (Och, 2003) to maximize the BLEU (Papineni et al., 2002) score on the dev set.",0,original
"As discussed in (Titov and Henderson, 2007), undirected graphical models do not seem to be suitable for history-based parsing models.",0,original
"Previous research has focused on classifying subjective-versus-objective expressions (Wiebe et al., 2004), and also on accurate sentiment polarity assignment (Turney, 2002; Yi et al., 2003; Pang and Lee, 2004; Sindhwani and Melville, 2008; Melville et al., 2009).",0,original
"As other researchers pursued efficient default unification (Bouma, 1990; Russell et al. , 1991; Copestake, 1993), we also propose another definition of default unification, which we call lenient default unification.",0,original
"Among all the language modeling approaches, ngram models have been most widely used in speech recognition (Jelinek 1990; Gale and Church 1990; Brown et al. 1992; Yang et al. 1996) and other applications.",0,original
"We use SUMMA (Saggion and Gaizauskas, 2005) to generate generic and query-based multi-document summaries and evaluate them using ROUGE evaluation metrics (Lin, 2004) relative to human generated summaries.",0,original
"For non-recursive NPs, Collins (1997) does not use the probability function in (5), but instead substitutes P r (and, by analogy, P l ) by: P r (R i ;t(R i );l(R i )jP;R i1 ;t(R i1 );l(R i1 );d(i))(8) Here the head H is substituted by the sister R i1 (and L i1 ).",0,original
"A description of the flat featurized dependency-style syntactic representation we use is available in (Langkilde-Geary and Betteridge, 2006), which describes how the entire Penn Treebank (Marcus et al., 1993) was converted to this representation.",0,original
"Domain adaptation deals with these feature distribution changes (Blitzer et al., 2007; Jiang and Zhai, 2007).",0,original
"The feature weights i are trained in concert with the LM weight via minimum error rate (MER) training (Och, 2003).",0,original
"Minor variants support voted perceptron (Collins, 2002) and MEMMs (McCallum et al. , 2000) with the same ef cient feature encoding.",0,original
3.1 NP Our NP chunks are very similar to the ones of Ramshaw and Marcus (1995).,0,original
"This resembles the re-ranking approach (Collins and Duffy, 2002; Collins, 2002b).",0,original
"But Koehn, Och, and Marcu (2003) find that phrases longer than three words improve performance little for training corpora of up to 20 million words, suggesting that the data may be too sparse to learn longer phrases.",0,original
"Most statistical parsing research, such as Collins (1997), has centered on training probabilistic context-free grammars using the Penn Treebank.",0,original
"Second, McDonald and Satta (2007) propose an O(n5) algorithm for computing the marginals, as opposed to the O(n3) matrix-inversion approach used by Smith and Smith (2007) and ourselves.",0,original
It has been claimed that content analysis researchers usually regard a > .8 to demonstrate good reliability and .67 < ~ < .8 alf16 lows tentative conclusions to be drawn (see Carletta (1996)).,0,original
"(2002), Turney (2002), Kim and Hovy (2004) and others), however, the research described in this paper uses the information retrieval (IR) paradigm which has also been used by some researchers.",0,original
Ratnaparkhi 1996).,0,original
"We have adopted the evaluation method of Snow et al (2006): compare the generated hypernyms with hypernyms present in a lexical resource, in our case the Dutch part of EuroWordNet (1998).",0,original
"To enable such techniques, we bring the cohesion constraint inside the ITG framework (Wu, 1997).",0,original
"Unlike with factored models (Koehn and Hoang, 2007) or additional translation lexicons (Schwenk et al., 2008), we do not generate the surface form back from the lemma translation, which means that tense, gender and number information are 151 news-dev2009a representation OOV % METEOR BLEU NIST baseline surface form only 2.24 49.05 20.45 6.135 decoding lemma backoff 2.13 49.12 20.44 6.143 word alignment lemma+POS for all 2.24 48.87 20.36 6.145 lemma+POS for adj 2.25 48.94 20.46 6.131 lemma+POS for verbs 2.21 49.05 20.47 6.137 decoding + alignment backoff + all 2.10 48.97 20.36 6.147 backoff + adj 2.12 49.05 20.48 6.140 backoff + verbs 2.08 49.15 20.50 6.148 news-dev2009b representation OOV % METEOR BLEU NIST baseline surface form only 2.52 49.60 21.10 6.211 decoding lemma backoff 2.43 49.66 21.02 6.210 word alignment lemma+POS for all 2.53 49.56 21.03 6.199 lemma+POS for adj 2.52 49.74 21.00 6.213 lemma+POS for verbs 2.47 49.73 21.10 6.217 decoding+alignment backoff + all 2.44 49.59 20.92 6.194 backoff + adj 2.43 49.80 21.03 6.217 backoff + verbs 2.39 49.80 21.03 6.217 Table 2: Evaluation of the decoding backoff strategy, the modified word alignment strategy and their combination Input Meme sil demissionnait, la situation ne changerait pas.",0,original
"(2005)), while exploring word-to-expression (inter-expression) relations has connections to techniques that employ more of a global-view of corpus statistics (e.g., Kanayama and Nasukawa (2006)).1 While most previousresearch exploits only one or the other type of relation, we propose a unified method that can exploit both types of semantic relation, while adapting a general purpose polarity lexicon into a domain specific one.",0,original
"We divided these case roles into four types by location in the article as in (Iida et al., 2006), i) the case role depends on the predicate or the predicate depends on the case role in the intra-sentence (dependency relations), ii) the case role does not depend on the predicate and the predicate does not depend on the case role in the intra-sentence (zeroanaphoric (intra-sentential)), iii) the case role is not in the sentence containing the predicate (zeroanaphoric (inter-sentential)), and iv) the case role and the predicate are in the same phrase (in same phrase).",0,original
"96 Research on DA classification initially focused on two-party conversational speech (Mast et al. , 1996; Stolcke et al. , 1998; Shriberg et al. , 1998) and, more recently, has extended to multi-party audio recordings like the ICSI corpus (Shriberg et al. , 2004).",0,original
"At the present time, given the key role of window size in determining the selection and apparent strength of associations under the conventional co-occurrence model highlighted here and in the works of Church et al (1991), Rapp (2002), Wang (2005), and Schulte im Walde & Melinger (2008) we would urge that this is an issue which window-driven studies continue to conscientiously address; at the very least, scale is a parameter which findings dependent on distributional phenomena must be qualified in light of.",0,original
"3.4 Feature Representation Ranking Models Following previous work on sentiment classi cation (Pang et al. , 2002), we represent each review as a vector of lexical features.",0,original
"For the evaluation of translation quality, we used the BLEU metric (Papineni et al. , 2002), which measures the n-gram overlap between the translated output and one or more reference translations.",0,original
"Successful approaches aimed at trying to overcome the sparse data limitation include backoff (Katz 1987), Turing-Good variants (Good 1953; Church and Gale 1991), interpolation (Jelinek 1985), deleted estimation (Jelinek 1985; Church and Gale 1991), similarity-based models (Dagan, Pereira, and Lee 1994; Essen and Steinbiss 1992), Pos-language models (Derouault and Merialdo 1986) and decision tree models (Bahl et al. 1989; Black, Garside, and Leech 1993; Magerman 1994).",0,original
"Under a phrase based translation model (Koehn et al. , 2003; Marcu and Wong, 2002), this distinction is important and will be discussed in more detail.",0,original
"The Kappa statistic (Carletta, 1996) is typically used to measure the human interrater agreement.",0,original
"5 Related Work There has not been much previous work on graphical models for full parsing, although recently several latent variable models for parsing have been proposed (Koo and Collins, 2005; Matsuzaki et al. , 2005; Riezler et al. , 2002).",0,original
"Parse selection constitutes an important part of many parsing systems (Johnson et al., 1999; Hara et al., 2005; van Noord and Malouf, 2005; McClosky et al., 2006).",0,original
"Due to its popularity for unsupervised POS induction research (e.g., Goldberg et al., 2008; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008) and its often-used tagset, for our initial research, we use the Wall Street Journal (WSJ) portion of the Penn Treebank (Marcus et al., 1993), with 36 tags (plus 9 punctuation tags), and we use sections 00-18, leaving held-out data for future experiments.4 Defining frequent frames as those occurring at 4Even if we wanted child-directed speech, the CHILDES database (MacWhinney, 2000) uses coarse POS tags.",0,original
"This set of words (rooted primarily in the verbs of the set) corresponds to the (Levin, 1993) Characterize (class 29.2), Declare (29.4), Admire (31.2), and Judgment verbs (33) and hence may have particular syntactic and semantic patterning.",0,original
"In a phrase-based statistical translation (Koehn et al. , 2003), a bilingual text is decomposed as K phrase translation pairs (e1, fa1), (e2, fa2 ),: The input foreign sentence is segmented into phrases f K1, 122 mapped into corresponding English eK1, then, reordered to form the output English sentence according to a phrase alignment index mapping a. In a hierarchical phrase-based translation (Chiang, 2005), translation is modeled after a weighted synchronous-CFG consisting of production rules whose right-hand side is paired (Aho and Ullman, 1969): X  ,, where X is a non-terminal,  and  are strings of terminals and non-terminals.",0,original
"Given a sentence-pair (f,e), the most likely (Viterbi) word alignment is found as (Brown et al. , 1993): a = argmaxa P(f,a|e).",0,original
But it is close to the paradigm described by Yarowsky (1995) and Turney (2002) as it also employs self-training based on a relatively small seed data set which is incrementally enlarged with unlabelled samples.,0,original
"Sentiment classification at the document level investigates ways to classify each evaluative document (e.g., product review) as positive or negative (Pang et al 2002; Turney 2002).",0,original
"They can be used for discriminative training of reordering models (Tillmann and Zhang, 2006).",0,original
"It is available in several formats, and in this paper, we use the Penn Treebank (Marcus et al. , 1993) format of NEGRA.",0,original
"The limited contexts used in this model are similar to the previous methods (Collins and Roark, 2004; Roark, 2001; Roark, 2004).",0,original
"We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a)).",0,original
(2002) and Turney (2002) classified sentiment polarity of reviews at the document level.,0,original
"Previous approaches to the problem (Collins, 1997; Johnson, 2002; Dienes and Dubey, 2003a,b; Higgins, 2003) have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of GovernmentBinding theory (Chomsky, 1981), since that theory underlies the annotation.",0,original
"EsEn 63.00.9 59.20.9 6.01.4 EnEs 63.80.9 60.51.0 5.21.6 DeEn 71.60.8 69.00.9 3.61.3 EnDe 75.90.8 73.50.9 3.21.2 FrEn 62.90.9 59.21.0 5.91.6 EnFr 63.40.9 60.00.9 5.41.4 bined in a log-linear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) procedure, optimising the BLEU (Papineni et al., 2002) score obtained on the development partition.",0,original
"Accordingly, in Ponzetto & Strube (2006) we used a machine learning based coreference resolution system to provide an extrinsic evaluation of the utility of WordNet and Wikipedia relatedness measures for NLP applications.",0,original
"Second, phrase translation pairs are extracted from the word aligned corpus (Koehn et al. , 2003).",0,original
"Yarowsky (1995) describes a 'semi-unsupervised' approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations.",0,original
"The system used for baseline experiments is two runs of IBM Model 4 (Brown et al. , 1993) in the GIZA++ (Och and Ney, 2003) implementation, which includes smoothing extensions to Model 4.",0,original
"(2003) from Sections 2-21 of the Wall Street Journal (WSJ) in the Penn Treebank (Marcus et al. , 1993) and its subsets.3 We then converted them into strongly equivalent HPSG-style grammars using the grammar conversion described in Section 2.1.",0,original
"6.4 Feature Selection Methods A number of previous papers (Berger, Della Pietra, and Della Pietra 1996; Ratnaparkhi 1998; Della Pietra, Della Pietra, and Lafferty 1997; McCallum 2003; Zhou et al. 2003; Riezler and Vasserman 2004) describe feature selection approaches for log-linear models applied to NLP problems.",0,original
"\[Marcus et al. , 1993\] Marcus, M. , Santorini, B. , and Malvinkiewicz, M.A.",0,original
a Hindle and Rooth (1991) and Church and Hanks (1990) used partial parses generated by Fidditch to study word ~urrt.nc patterns m syntactic contexts.,0,original
"1984), written discourse (Brown and WSJ from Penn Treebank Marcus et al. 1993), and conversational data (Switchboard Godfrey et al. 1992).",0,original
"From the above discussion, we can see that traditional tree sequence-based method uses single tree as translation input while the forestbased model uses single sub-tree as the basic translation unit that can only learn tree-to-string (Galley et al. 2004; Liu et al., 2006) rules.",0,original
"The TRIPS structure generally has more levels of structure (roughly corresponding to levels in X-bar theory) than the Penn Treebank analyses (Marcus et al. , 1993), in particular for base noun phrases.",0,original
"Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003).",0,original
"So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al. , 2004; Riloff et al. , 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al. , 2003), and discriminating between positive and negative language (Pang et al. , 2002; Morinaga et al. , 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al. , 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al. , 2005).",0,original
"1 Introduction Word alignmentdetection of corresponding words between two sentences that are translations of each otheris usually an intermediate step of statistical machine translation (MT) (Brown et al. , 1993; Och and Ney, 2003; Koehn et al. , 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval.",0,original
"3.2 Translation performance For the experiments reported in this section, we used feature weights trained with minimum error rate training (MERT; Och, 2003) . Because MERT ignores the denominator in Equation 1, it is invariant with respect to the scale of the weight vector   the Moses implementation simply normalises the weight vector it finds by its lscript1-norm.",0,original
"For example, the HMM aligner achieves an AER of 20.7 when using the competitive thresholding heuristic of DeNero and Klein (2007).",0,original
"The data contains words, their part-of-speech 1This Ramshaw and Marcus (1995) bascNP data set is availal)le via ffp://fti).cis.upe,m.edu/pub/chunker/ 857 (POS) tags as computed by the Brill tagger and their baseNP segmentation as derived from the %'eebank (with some modifications).",0,original
"In natural language processing, recent years have seen ME techniques used for sentence boundary detection, part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just a few applications (Abney, 1997; Berger et al. , 1996; Ratnaparkhi, 1998; Johnson et al. , 1999).",0,original
"Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition.",0,original
"The results of the comparison with ROUGE-N (Lin and Hovy, 2003; Lin, 2004a; Lin, 2004b), ROUGE-S(U) (Lin, 2004b; Lin and Och, 2004) and ROUGE-L (Lin, 2004a; Lin, 2004b) show that our method correlates more closely with human evaluations and is more robust.",0,original
"Model parameters are estimated using maximum entropy (Berger et al. , 1996).",0,original
"Expectation Evaluation is the soul of parameter estimation (Brown et al. , 1993), (Al-Onaizan et al. , 1999).",0,original
"For extrinsic evaluation of machine translation, we use the BLEU metric (Papineni et al. , 2002).",0,original
"Second, it can be applied to control the quality of parallel bilingual sentences mined from the Web, which are critical sources for a wide range of applications, such as statistical machine translation (Brown et al. , 1993) and cross-lingual information retrieval (Nie et al. , 1999).",0,original
"To support this claim, first, we used the  coefficient (Krippendorff, 1980; Carletta, 1996) to assess the agreement between the classification made by FLSA and the classification from the corpora  see Table 8.",0,original
"Furthermore, we use averaged weights (Collins, 2002; Freund and Schapire, 1999) in Algorithm 1.",0,original
"Lexical collocation functions, especially those determined statistically, have recently attracted considerable attention in computational linguistics (Calzolari and Bindi 1990; Church and Hanks 1990; Sekine et al. 1992; Hindle and Rooth 1993) mainly, though not exclusively, for use in disambiguation.",0,original
"The forest representation was obtained by adopting chart generation (Kay, 1996; Car93 roll et al. , 1999) where ambiguous candidates are packed into an equivalence class and mapping a chart into a forest in the same way as parsing.",0,original
"An example set of tags can be found in the Penn Treebank project (Marcus et al. , 1993).",0,original
"Feature function scaling factors m are optimized based on a maximum likelihood approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003).",0,original
"They are: ??Meteor (Banerjee and Lavie, 2005)?Meteor measures precision and recall of unigrams when comparing a hypothesis translation 142 Language Pair Test Set Adequacy Fluency Rank Constituent English-German Europarl 1,416 1,418 1,419 2,626 News Commentary 1,412 1,413 1,412 2,755 German-English Europarl 1,525 1,521 1,514 2,999 News Commentary 1,626 1,620 1,601 3,084 English-Spanish Europarl 1,000 1,003 1,064 1,001 News Commentary 1,272 1,272 1,238 1,595 Spanish-English Europarl 1,174 1,175 1,224 1,898 News Commentary 947 949 922 1,339 English-French Europarl 773 772 769 1,456 News Commentary 729 735 728 1,313 French-English Europarl 834 833 830 1,641 News Commentary 1,041 1,045 1,035 2,036 English-Czech News Commentary 2,303 2,304 2,331 3,968 Czech-English News Commentary 1,711 1,711 1,733 0 Totals 17,763 17,771 17,820 27,711 Table 2: The number of items that were judged for each task during the manual evaluation against a reference.",0,original
"2.1 Data and Semantic Role Annotation Proposition Bank (Palmer et al., 2005) adds Levins style predicate-argument annotation and indication of verbs alternations to the syntactic structures of the Penn Treebank (Marcus et al., 289 1993).",0,original
"The same probabilities are also included using 50 hard word classes derived from the parallel corpus using the GIZA++ mkcls utility (Och and Ney, 2003).",0,original
"Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging \[Jelinek, 1985; Church, 1988; Derose, 1988; DeMarcken, 1990; Cutting et al. , 1992; Kupiec, 1992; Charniak et al. , 1993; Weischedel et al. , 1993; Schutze and Singer, 1994; Lin et al. , 1994; Elworthy, 1994; Merialdo, 1995\].",0,original
"2.2 Automatic evaluation metric Since the official evaluation criterion for WMT09 is human sentence ranking, we chose to minimize a linear combination of two common evaluation metrics, BLEU and TER (Papineni et al., 2002; Snover et al., 2006), during system development and tuning: TERBLEU 2 Although we are not aware of any work demonstrating that this combination of metrics correlates better than either individually in sentence ranking, Yaser Al-Onaizan (personal communication) reports that it correlates well with the human evaluation metric HTER.",0,original
"Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called invertedtranslationmodels (Brown et al. 1990, 1993).",0,original
"6 Related works After the work of Ramshaw and Marcus (1995), many machine learning techniques have been applied to the basic chunking task, such as Support Vector Machines (Kudo and Matsumoto, 2001), Hidden Markov Model(Molina and Pla 2002), Memory Based Learning (Sang, 2002), Conditional Random Fields (Sha and Pereira, 2003), and so on.",0,original
"2.2.2 ENGLISH TRAINING DATA For training in the English experiments, we used WSJ (Marcus et al. , 1993).",0,original
"Itowever, Harris' methodology implies also to simplify and transform each parse tree 2, so as to obtain so-called ""elementary sentences"" exhibiting the main conceptual classes for the domain (Sager lIa'or instance, Hindle (Hindle, 1990) needs a six million word corpus in order to extract noun similarities from predicate-argunlent structures.",0,original
"Since the lexical translations and dependency paths are typically not labeled in the English corpus, a given pair must be counted fractionally according to its posterior probability of satisfying these conditions, given models of contextual translation and English parsing.3 3Similarly, Jansche (2005) imputes missing trees by using comparable corpora.",0,original
"We augment each labeled target instance xj with the label assigned by the source domain classifier (Florian et al. , 2004; Blitzer et al. , 2006).",0,original
"1 Introduction Many state-of-the-art machine translation (MT) systems over the past few years (Och and Ney, 2002; Koehn et al., 2003; Chiang, 2007; Koehn et al., 2007; Li et al., 2009) rely on several models to evaluate the goodness of a given candidate translation in the target language.",0,original
3TheData For our experiments we used a version of the British National Corpus parsed with the statistical parser of Collins (1997).,0,original
"Additionally, we present results of the tagger on the NEGRA corpus (Brants et al. , 1999) and the Penn Treebank (Marcus et al. , 1993).",0,original
Collins (2002) proposed the perceptron as an alternative to the CRF method for HMM-style taggers.,0,original
"2 Basic Approaches 2.1 Cross-Lingual Approach Our cross-lingual approach (called MLEV) is based on (Freeman et al. 2006), who used a modified Levenshtein string edit-distance algorithm to match Arabic script person names against their corresponding English versions.",0,original
"Reported work includes improved model variants (e.g., Jiao et al., 2006) and applications such as web data extraction (Pinto et al., 2003), scientific citation extraction (Peng and McCallum, 2004), word alignment (Blunsom and Cohn, 2006), and discourselevel chunking (Feng et al., 2007).",0,original
"We are encoding the knowledge as axioms in what is for the most part  first-order logic, described in Hobbs (1985a), although quantification over predicates is sometimes convenient.",0,original
"2 Disperp and Distortion Corpora 2.1 Defining Disperp The ultimate reason for choosing one SCM over another will be the performance of an MT system containing it, as measured by a metric like BLEU (Papineni et al. , 2002).",0,original
"1313 E2C C2E Union Heuristic w/ Big 13.37 12.66 14.55 14.28 w/o Big 13.20 12.62 14.53 14.21 Table 3: BLEU-4 scores (test set) of systems based on GIZA++ word alignments 5 6 7 8  BLEU-4 14.27 14.42 14.43 14.45 14.55 Table 4: BLEU-4 scores (test set) of the union alignment, using TTS templates up to a certain size, in terms of the number of leaves in their LHSs 4.1 Baseline Systems GHKM (Galley et al., 2004) is used to generate the baseline TTS templates based on the word alignments computed using GIZA++ and different combination methods, including union and the diagonal growing heuristic (Koehn et al., 2003).",0,original
"For example, extractive text summarization generates a summary by selecting a few good sentences from one or more articles on the same topic (Goldstein et al. , 2000).",0,original
Lopez (2008) explores whether lexical reordering or the phrase discontiguity inherent in hierarchical rules explains improvements over phrase-based systems.,0,original
"In this case it is possible to perform the correct selection if we used only statistics about the cooccurrences of 'corruption' with either 'investigator' or 'researcher', without looking for any syntactic relation (as in Church and Hanks (1990)).",0,original
"We trained and tested the parser on the Wall Street Journal corpus of the Penn Treebank (Marcus et al. , 1993) using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.",0,original
"P(d)  P L (d) (4) Statistical approaches to language modeling have been used in much NLP research, such as machine translation (Brown et al. , 1993) and speech recognition (Bahl et al. , 1983).",0,original
"The superiority of discriminative models has been shown on many tasks when the discriminative and generative models use exactly the same model structure (Klein and Manning, 2002).",0,original
"2.1 Synchronous derivations The derivations for syntactic dependency trees are the same as specified in (Titov and Henderson, 2007b), which are based on the shift-reduce style parser of (Nivre et al., 2006).",0,original
"In recent years, HMMs have enjoyed great success in many tagging applications, most notably part-of-speech (POS) tagging (Church 1988; Weischedel et al 1993; Merialdo 1994) and named entity recognition (Bikel et al 1999; Zhou et al 2002).",0,original
We collected training samples from the Brown Corpus distributed with the Penn Treebank (Marcus et al.1993 ).,0,original
"298 within LFG includes the XLE,3 Cahill and van Genabith (2006), Hogan et al.",0,original
"Their weights are optimized w.r.t. BLEU score using the algorithm described in (Och, 2003).",0,original
"(2007) are appealing, as they have rather simple structure, modeling only NP, VP and LCP via one-level sub-tree structure with two children, in the source parse-tree (a special case of ITG (Wu, 1997)).",0,original
"605 ROUGE-S (Lin, 2004) Skip-bigram is any pair of words in their sentence order, allowing for arbitrary gaps.",0,original
"(Koehn et al., 2003; Och and Ney, 2004)).",0,original
"(2002), Turney (2002)), a sentence (e.g. , Liu et al.",0,original
"We use discourse-level feature predicates in a maximum entropy classifier (Berger et al., 1996) with binary and n-class classification to select referring expressions from a list.",0,original
"Our decoder is a phrase-based multi-stack imple5 mentation of the log-linear model similar to Pharaoh (Koehn et al. , 2003).",0,original
"Furthermore, it is not possible to apply the powerful ""one sense per discourse"" property (Yarowsky, 1995) because there is no discourse in dictionaries.",0,original
"Results for chunking Penn Treebank data were previously presented by several authors (Ramshaw and Marcus, 1995; Argamon et al. , 1998; Veenstra, 1998; Cardie and Pierce, 1998).",0,original
"2.1 Conditional Maximum Entropy Model The goal of CME is to find the most uniform conditional distribution of y given observation x, ( )xyp, subject to constraints specified by a set of features ()yxf i,, where features typically take the value of either 0 or 1 (Berger et al. , 1996).",0,original
"According to Carletta (1996), K measures pairwise agreement among a set of coders making category judgments, correcting for expected chance agreement as follows: KP(A) -P(E) 1 -P(E) where P(A) is the proportion of times that the coders agree and P(E) is the proportion of times that they would be expected to agree by chance.",0,original
"Talbot and Brants (2008) show that Bloomier filters (Chazelle et al., 2004) can be used to create perfect hash functions for language models.",0,original
"lscript1-regularized log-linear models (lscript1-LLMs), on the other hand, provide sparse solutions, in which weights of irrelevant features are exactly zero, by assumingaLaplacianpriorontheweights(Tibshirani, 1996; Kazama and Tsujii, 2003; Goodman, 2004; Gao et al., 2007).",0,original
"For instance, the Penn Treebank policy (Marcus et al. , 1993; Marcus et al. , 1994) is to annotate the lowest node that is unfinished with an -UNF tag as in Figure 4(a).",0,original
"1 Introduction This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993).",0,original
"The target set is built using the 88-89 Wall Street Journal Corpus (WSJ) tagged using the (Ratnaparkhi, 1996) tagger and the (Bangalore & Joshi, 1999) SuperTagger; the feedback sets are built using WSJ sentences con330 Algorithm 1 KE-train: (Karov & Edelman, 1998) algorithm adapted to literal/nonliteral classification Require: S: the set of sentences containing the target word Require: L: the set of literal seed sentences Require: N: the set of nonliteral seed sentences Require: W: the set of words/features, w  s means w is in sentence s, s owner w means s contains w Require: epsilon1: threshold that determines the stopping condition 1: w-sim0(wx,wy) := 1 if wx = wy,0 otherwise 2: s-simI0(sx,sy) := 1, for all sx,sy  S S where sx = sy, 0 otherwise 3: i := 0 4: while (true) do 5: s-simLi+1(sx,sy) := summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S L 6: s-simNi+1(sx,sy) := summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S N 7: for wx,wy  W W do 8: w-simi+1(wx,wy) := braceleftBigg i = 0 summationtextsxownerwx p(wx,sx)maxsyownerwy s-simIi(sx,sy) else summationtextsxownerwx p(wx,sx)maxsyownerwys-simLi (sx,sy),s-simNi (sx,sy)} 9: end for 10: if wx,maxwyw-simi+1(wx,wy)w-simi(wx,wy)}  epsilon1 then 11: break # algorithm converges in 1epsilon1 steps.",0,original
"Far from full syntactic complexity, we suggest to go back to the simpler alignment methods first described by (Brown et al. , 1993).",0,original
"However, the aforementioned SDT techniques require word classes(Brown et al. , 1992) to help prevent data fragmentation, and a sophisticated smoothing algorithm to mitigate the effects of any fragmentation that occurs.",0,original
This hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation (Hindle 1990; Grefenstette 1994; Lin 1998a; Curran and Moens 2002; Kilgarriff 2003).,0,original
"Although the above statement was made about translation problems faced by human translators, recent research (Brown et al. 1993; Melamed 1996b) suggests that it also applies to problems in machine translation.",0,original
"Examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (Brill, 1995), memory based learning (Daelemans et al. , 1996), and maximum entropy models (Ratnaparkhi, 1996).",0,original
"Similarly, the sense disambiguation problem is typically attacked by comparing the distribution of the neighbors of a word's occurrence to prototypical distributions associated with each of the word's senses \[Gale et al. , 1992, Schtltze, 1992\].",0,original
"Yarowsky (1994 and 1995), Mihalcea and Moldovan (2000), and Mihalcea (2002) have made further research to obtain large corpus of higher quality from an initial seed corpus.",0,original
"accuracy Training data Turney (2002) 66% unsupervised Pang & Lee (2004) 87.15% supervised Aue & Gamon (2005) 91.4% supervised SO 73.95% unsupervised SM+SO to increase seed words, then SO 74.85% weakly supervised Table 7: Classification accuracy on the movie review domain Turney (2002) achieves 66% accuracy on the movie review domain using the PMI-IR algorithm to gather association scores from the web.",0,original
"The modify features involve the dependency parse tree for the sentence, obtained by first parsing the sentence (Collins, 1997) and then converting the tree into its dependency representation (Xia and Palmer, 2001).",0,original
"The probabilities of derivation decisions are modelled using the neural network approximation (Henderson, 2003) to a type of dynamic Bayesian Network called an Incremental Sigmoid Belief Network (ISBN) (Titov and Henderson, 2007).",0,original
"There are five different IBM translation models (Brown et al. , 1993).",0,original
"(2002) 94.17 Li and Roth (2001) 93.02 94.64 Table 2: Baseline results on three shallow parsing tasks: the NP-Chunking task (Ramshaw and Marcus, 1995); the CoNLL-2000 Chunking task (Sang and Buchholz, 2000); and the Li & Roth task (Li and Roth, 2001), which is the same as CoNLL-2000 but with more training data and a different test section.",0,original
"The concept of these alignments is similar to the ones introduced by (Brown et al. , 1993), but we will use another type of dependence in the probability distributions.",0,original
"Two major research topics in this field are Named Entity Recognition (NER) (N. Wacholder and Choi, 1997; Cucerzan and Yarowsky, 1999) and Word Sense Disambiguation (WSD) (Yarowsky, 1995; Wilks and Stevenson, 1999).",0,original
"All conditions were optimized using BLEU (Papineni et al., 2002) and evaluated using both BLEU and Translation Edit Rate (TER) (Snover et al., 2006).",0,original
"The unlabeled data for English we use is the union of the Penn Treebank tagged WSJ data (Marcus et al., 1993) and the BLLIP corpus.5 For the rest of the languages we use only the text of George Orwells novel 1984, which is provided in morphologically disambiguated form as part of MultextEast (but we dont use the annotations).",0,original
Hindle (1990) grouped nouns into thesaurus-like lists based on the similarity of their syntactic contexts.,0,original
"These constituent matching/violation counts are used as a feature in the decoders log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003).",0,original
"Sometimes, due to data sparseness and/or limitations in the machine learning paradigm used, we need to extract features from the available representation in a manner that profoundly changes the representation (as is done in bilexical parsing (Collins, 1997)).",0,original
"This problem will be solved by incorporating other resources such as thesaurus or a dictionary,orcombiningourmethodwithothermethods using external wider contexts (Suzuki et al. , 2006; Turney, 2002; Baron and Hirst, 2004).",0,original
"In this paper, we present Phramer, an open-source system that embeds a phrase-based decoder, a minimum error rate training (Och, 2003) module and various tools related to Machine Translation (MT).",0,original
"The corpus consists of sections 15-18 and section 20 of the Penn Treebank (Marcus et al. , 1993), and is pre-divided into a 8936-sentence (211727 tokens) training set and a 2012-sentence (47377 tokens) test set.",0,original
"Introduction Many applications that process natural language can be enhanced by incorporating information about the probabilities of word strings; that is, by using statistical language model information (Church et al. 1991; Church and Mercer 1993; Gale, Church, and Yarowsky 1992; Liddy and Paik 1992).",0,original
"1 Introduction Word alignmentdetection of corresponding words between two sentences that are translations of each otheris usually an intermediate step of statistical machine translation (MT) (Brown et al. , 1993; Och and Ney, 2003; Koehn et al. , 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval.",0,original
"We used sections 220 of the Penn Treebank 2 Wall Street Journal corpus (Marcus et al. , 1993) for training, section 22 as development set and section 23 for testing.",0,original
"We have developed a set of extensions to a probabilistic translation model (Brown et al. , 1993) that enable us to successfully merge oversegmented regions into coherent objects.",0,original
"4This was a straightforward task; two annotators annotated independently, with very high agreementkappa score of over 0.95 (Carletta, 1996).",0,original
"The unknown word tokens are with respect to Training I. Data set Sect'ns Token Unknown Training I 26-270, 600-931 213986 Training II 600-931, 500-527, 1001-1039 204701 Training III 001-270, 301-527, 590-593, 600-1039, 1043-1151 485321 Devset 23839 2849 XH 001-025 7844 381 HKSAR 500-527 8202 1168 SM 590-593, 1001-1002 7793 1300 Test set 23522 2957 XH 271-300 8008 358 HKSAR 528-554 7153 1020 SM 594-596, 1040-1042 8361 1579 5.2 The model Our model builds on research into loglinear models by Ng and Low (2004), Toutanova et al. , (2003) and Ratnaparkhi (1996).",0,original
"Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging \[Jelinek, 1985; Church, 1988; Derose, 1988; DeMarcken, 1990; Cutting et al. , 1992; Kupiec, 1992; Charniak et al. , 1993; Weischedel et al. , 1993; Schutze and Singer, 1994; Lin et al. , 1994; Elworthy, 1994; Merialdo, 1995\].",0,original
"For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004).",0,original
Citation texts have also been used to create summaries of single scientific articles in Qazvinian and Radev (2008) and Mei and Zhai (2008).,0,original
"Generative and discriminative models have been comparedanddiscussedagreatdeal(NgandJordan, 2002), including for NLP models (Johnson, 2001; Klein and Manning, 2002).",0,original
"In order to avoid this problem we implemented a simple bootstrapping procedure in which a seed data set of 100 instances of each of the eight categories was hand tagged and used to generate a decision list classifier using the C4.5 algorithm (Quinlan, 1993) with the word frequency and topic signature features described below.",0,original
"We used the Penn Treebank WSJ corpus (Marcus et al. , 1993) to perform the empirical evaluation of the considered approaches.",0,original
"Johnson (2007) evaluates both estimation techniques on the Bayesian bitag model; Goldwater and Griffiths (2007) emphasize the advantage in the MCMC approach of integrating out the HMM parameters in a tritag model, yielding a tagging supported by many different parameter settings.",0,original
"There has been an increased interest recently in employing Bayesian modeling for probabilistic grammars in different settings, ranging from putting priors over grammar probabilities (Johnson et al., 2007) to putting non-parametric priors over derivations (Johnson et al., 2006) to learning the set of states in a grammar (Finkel et al., 2007; Liang et al., 2007).",0,original
"For evaluation we use a state-of-the-art baseline system (Moses) (Hoang and Koehn, 2008) which works with a log-linear interpolation of feature functions optimized by MERT (Och, 2003).",0,original
"Post-editing of automatic annotation has been pursued in various projects (e.g. , Brants 2000, and Marcus et al. 1993).",0,original
"1 Introduction Motivation: Sharing basic intuitions and longterm goals with other tasks within the area of Webbased information extraction (Banko and Etzioni, 2008; Davidov and Rappoport, 2008), the task of acquiring class attributes relies on unstructured text available on the Web, as a data source for extracting generally-useful knowledge.",0,original
"In this paper we apply perceptron trained HMMs originally proposed in (Collins, 2002).",0,original
"In this paper, Stanford Named Entity Recognizer (Finkel et al. 2005) is used to classify noun phrases into four semantic categories: PERSON, LOCATION, ORGANIZARION and MISC.",0,original
"Algorithms such as co-training (Blum and Mitchell, 1998)(Collins and Singer, 1999)(Pierce and Cardie, 2001) and the Yarowsky algorithm (Yarowsky, 1995) make assumptions about the data that permit such an approach.",0,original
"MT output is evaluated using the standard MT evaluation metric BLEU (Papineni et al. , 2002).",0,original
"INTRODUCTION Class-based language models (Brown et al. , 1992)have been proposed for dealing with two problems confronted by the well-known word n-gram language models (1) data sparseness: the amount of training data is insufficient for estimating the huge number of parameters; and (2) domain robustness: the model is not adaptable to new application domains.",0,original
"While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved (Church and Hanks, 1989; Church and Hanks, 1991; Rapp, 2002) Measures based on distance between words in the text.",0,original
"Their weights are optimized w.r.t. BLEU score using the algorithm described in (Och, 2003).",0,original
"Parsers Precision(a4 ) Recall(a4 ) a5a7a6 (a4 ) a8KM00 a9 93.45 93.51 93.48 a8Hal00 a9 93.13 93.51 93.32 a8CSCL a9 * 93.41 92.64 93.02 a8TKS00 a9 94.04 91.00 92.50 a8ZST00 a9 91.99 92.25 92.12 a8Dej00 a9 91.87 91.31 92.09 a8Koe00 a9 92.08 91.86 91.97 a8Osb00 a9 91.65 92.23 91.94 a8VB00 a9 91.05 92.03 91.54 a8PMP00 a9 90.63 89.65 90.14 a8Joh00 a9 86.24 88.25 87.23 a8VD00 a9 88.82 82.91 85.76 Baseline 72.58 82.14 77.07 2.2 Data Training was done on the Penn Treebank (Marcus et al. , 1993) Wall Street Journal data, sections 02-21.",0,original
"So unlike some other studies (Zens and Ney, 2003; Zhang et al. , 2006), we used manually annotated alignments instead of automatically generated ones.",0,original
"Thus, some research has been focused on deriving different word-sense groupings to overcome the finegrained distinctions of WN (Hearst and Schutze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007).",0,original
"As in phrasebased translation model estimation, ? also contains two lexical weights (Koehn et al. , 2003), counters for number of target terminals generated.",0,original
"Previous studies (Abney, 1997; Johnson et al. , 1999; Riezler et al. , 2000; Miyao et al. , 2003; Malouf and van Noord, 2004; Kaplan et al. , 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars as a log-linear model or maximum entropy model (Berger et al. , 1996).",0,original
"To model p(fJle~;8,.T) we assume the existence of an alignment a J. We assume that every word fj is produced by the word e~j at position aj in the training corpus with the probability P(f~le,~i): J p(f lc ') = 1\] p(L Icon) j=l (7) The word alignment a J is trained automatically using statistical translation models as described in (Brown et al. , 1993; Vogel et al. , 1996).",0,original
"Method Source Spearman (Strube and Ponzetto, 2006) Wikipedia 0.190.48 (Jarmasz, 2003) WordNet 0.330.35 (Jarmasz, 2003) Rogets 0.55 (Hughes and Ramage, 2007) WordNet 0.55 (Finkelstein et al., 2002) Web corpus, WN 0.56 (Gabrilovich and Markovitch, 2007) ODP 0.65 (Gabrilovich and Markovitch, 2007) Wikipedia 0.75 SVM Web corpus, WN 0.78 Table 9: Comparison with previous work for WordSim353.",0,original
"The PropBank corpus adds a semantic layer to parse trees from the Wall Street Journal section of the Penn Treebank II corpus (Marcus et al., 1993).",0,original
"(Yates and Etzioni, 2007) 4.",0,original
"(Black et al. , 1992; Materman, 1995)), we treat the word identities as a further refinement of the POS tags; thus we build a word classification tree for each POS tag.",0,original
"c2009 Association for Computational Linguistics Improving Mid-Range Reordering using Templates of Factors Hieu Hoang School of Informatics University of Edinburgh h.hoang@sms.ed.ac.uk Philipp Koehn School of Informatics University of Edinburgh pkoehn@inf.ed.ac.uk Abstract We extend the factored translation model (Koehn and Hoang, 2007) to allow translations of longer phrases composed of factors such as POS and morphological tags to act as templates for the selection and reordering of surface phrase translation.",0,original
"Such transformations are typically denoted as paraphrases in the literature, where a wealth of methods for their automatic acquisition were proposed (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004).",0,original
"We optimized separately for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al. , 2002).",0,original
"Training Procedure Our algorithm is a modification of the perceptron ranking algorithm (Collins, 2002), which allows for joint learning across several ranking problems (Daume III and Marcu, 2005; Snyder and Barzilay, 2007).",0,original
"Instead of directly minimizing error as in earlier work (Och, 2003), we decompose the decoding process into a sequence of local decision steps based on Eq.",0,original
"3.2 The parsers The parsers that we chose to evaluate are the C&C CCG parser (Clark and Curran, 2007), the Enju HPSG parser (Miyao and Tsujii, 2005), the RASP parser (Briscoe et al., 2006), the Stanford parser (Klein and Manning, 2003), and the DCU postprocessor of PTB parsers (Cahill et al., 2004), based on LFG and applied to the output of the Charniak and Johnson reranking parser.",0,original
"4 Evaluation 4.1 Experimental Setup For evaluation, we use five sentiment classification datasets, including the widely-used movie review dataset [MOV] (Pang et al., 2002) as well as four datasets that contain reviews of four different types of product from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al., 2007).",0,original
"available): SCISSOR (Ge and Mooney, 2005), an integrated syntactic-semantic parser; KRISP (Kate and Mooney, 2006), an SVM-based parser using string kernels; WASP (Wong and Mooney, 2006; Wong and Mooney, 2007), a system based on synchronous grammars; Z&C (Zettlemoyer and Collins, 2007)3, a probabilistic parser based on relaxed CCG grammars; and LU (Lu et al., 2008), a generative model with discriminative reranking.",0,original
"Rapp (1999), Dunning (1993)) but using cosine rather than cityblock distance to measure profile similarity.",0,original
"The sets obtainedare then ranked usingthe loglikelihoodratiostest(Dunning,1993).",0,original
"The feature weights are learned by maximizing the BLEU score (Papineni et al. , 2002) on held-out data,usingminimum-error-ratetraining(Och,2003) as implemented by Koehn.",0,original
"As such, we quantify success based on ROUGE (Lin, 2004) scores.",0,original
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993).",0,original
"3.2 Domain Adaptation Track As mentioned previously, the source data is drawn from a corpus of news, specifically the Wall Street Journal section of the Penn Treebank (Marcus et al. , 1993).",0,original
"These problems include collocation discovery (Pearce, 2001), smoothing and estimation (Brown et al. , 1992; Clark and Weir, 2001) and question answering (Pasca and Harabagiu, 2001).",0,original
"Since we also adopt a linear scoring function in Equation (3), the feature weights of our combination model can also be tuned on a development data set to optimize the specified evaluation metrics using the standard Minimum Error Rate Training (MERT) algorithm (Och 2003).",0,original
The models were originally introduced in Collins (1997); the current article 1 gives considerably more detail about the models and discusses them in greater depth.,0,original
"Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al. , 2003).",0,original
"For instance, BLEU and ROUGE (Lin and Och, 2004) are based on n-gram precisions, METEOR (Banerjee and Lavie, 2005) and STM (Liu and Gildea, 2005) use word-class or structural information, Kauchak (2006) leverages on paraphrases, and TER (Snover et al., 2006) uses edit-distances.",0,original
"Then we compute the same ratio of machine translation sentence to source sentence, and take the output of p-norm function as a feature: ) __/__ ()( s csrcoflengthtoflenght Ptf norm  =      (7)   Features based on parse score The usual practice to model the wellformedness of a sentence is to employ the n-gram language model or compute the syntactic structure similarity (Liu and Gildea 2005).",0,original
We borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff (1999).,0,original
"Entropy, used in some part-of-speech tagging systems (Ratnaparkhi, 1996), is a measure of how much information is necessary to separate data.",0,original
"2 Our statistical engine 2.1 The statistical models In this study, we built an SMT engine designed to translate from French to English, following the noisy-channel paradigm flrst described by (Brown et al. , 1993b).",0,original
"2 We used the Collins parser (1997) to generate the constituency parse and a dependency converter (Hwa and Lopez, 2004) to obtain the dependency parse of English sentences.",0,original
Turney (2002) describes a method of sentiment classification using two human-selected seed words (the words poor and excellent) in conjunction with a very large text corpus; the semantic orientation of phrases is computed as their association with the seed words (as measured by pointwise mutual information).,0,original
"(Turney, 2002; Pang et al., 2002; Dave at al., 2003).",0,original
"Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al., 2006), and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string (Lin, 2004; Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006).",0,original
"4 Phrase-Based Translation In phrase-based translation, the translation process is modeled by splitting the source sentence into phrases (a contiguous string of words) and translating the phrases as a unit (Och et al., 1999; Koehn et al., 2003).",0,original
"This research has focused mostly on the development of statistical parsers trained on large annotated corpora, in particular the Penn Treebank WSJ corpus (Marcus et al. , 1993).",0,original
"We ran the decoder with its default settings and then used Moses implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set.",0,original
"The commonly used phrase extraction approach based on word alignment heuristics (referred as ViterbiExtract algorithm for comparison in this paper) as described in (Och, 2002; Koehn et al., 2003) is a special case of the algorithm, where candidate phrase pairs are restricted to those that respect word alignment boundaries.",0,original
"Comparison With Previous Work Most of the recent corpus-based POS taggers in the literature are either statistically based, and use Markov Model(Weischedel et al. , 1993, Merialdo, 1994) or Statistical Decision Tree(Jelinek et al. , 1994, Magerman, 1995)(SDT) techniques, or are primarily rule based, such as Drill's Transformation Based Learner(Drill, 1994)(TBL).",0,original
"Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003).",0,original
Pang and Lee (2004) proposed to eliminate objective sentences before the sentiment classification of documents.,0,original
"2.4 Comparison with Hybrid Model SSL based on a hybrid generative/discriminative approach proposed in (Suzuki et al., 2007) has been defined as a log-linear model that discriminatively combines several discriminative models, pDi , and generative models, pGj , such that: R(y|x;,,) = producttext i p Di (y|x;i)i producttext j p Gj (xj,y;j)j summationtext y producttext i p Di (y|x;i)i producttext j p Gj (xj,y;j)j , where ={i}Ii=1, and ={{i}Ii=1,{j}I+Jj=I+1}.",0,original
"Tuning is done for each experimental condition using Ochs Minimum Error Training (Och, 2003).",0,original
"This implementation is exactly the one proposed in (Yarowsky 1995), and we will denote it as MB-D hereafter.",0,original
"of the works of (Kuplec, Pedersen, and Chen, 1995) and (Brandow, Mltze, .and Ran, 1995), and advances summarmatlon technology by applynag corpus-based statistical NLP teehmques, robust information extraction, and readily avaalable on-hne resources Our prehxmnary experiments with combining different summarization features have been reported, and our current effort to learn to combine these features to produce the best summaries has been described The features derived by these robust NLP techmques were also utihzed m presentmg multiple summary.vtews to the user m a novel way References Advanced Research Projects Agency 1995 Proceed:rigs of S:zth Message Understanding Conference (MUC-6) Morgan Kanfmann Pubhshers Brandow, Ron, Karl Mltze, and Lisa Ran 1995 Automatic condensation of electromc pubhcatlous by sentence selection Information Processing and  Management, 31, forthcoming .Bull, Eric 1993 A Comps-based Approach to Language Learning Ph D thesm, Umverslty of Pennsylvania Church, Kenneth and Patrick Hanks 1990 Word  Aesoclatlon Norrns, Mutual Information, and Lexicography Computational Lmgmstscs, 16(1) Church, Kenneth W 1995 One term or two 9 In Proceedings of the 17th Annual International SIGIR Conference on Research and Development In Informatzon Retrzeral, pages 310-318 Edmundson, H P 1969 New methods m automatic abstracting Journal of the ACM, 16(2) 264-228 Fum, Dando, Glovanm Gmda, and Carlo Tasso 1985 Evalutatmg Importance A step towards text surnmarlzatlon In I3CAI85, pages 840-844IJCAi, AAAI Hahn, Udo 1990 Topic parsing Accounting for text macro structures m full-text analysm In format:on Processing and Management, 26(1)135170 Harman, Donna 1991 How effective is suttixang ~ Journal of the Amerlcan Sot:cry for Informatwn Sc:ence, 42(1) 7-15 Harman, Donna 1996 Overview of the fifth text retrieval conference (tree-5) In TREC-5 Conference Proceedings Jmg, Y and B Croft 1994 An Assoc:atwn Thesaurns for Informatzon Retrseval Umass Techmcal Report 94-I7 Center for Intelligent Information Retrieval, University of Massachusetts Johnson, F C, C D Prate, W J Black, and A P Neal 1993.",0,original
"For the constituent-based models, constituent information was obtained from the output of Collins parser (1997) for English and Dubeys parser (2004) for German.",0,original
"Originally introduced as a byproduct of training statistical translation models in (Brown et al. , 1993), word alignment has become the first step in training most statistical translation systems, and alignments are useful to a host of other tasks.",0,original
Pang and Lee (2004) report 87.15% accuracy using a unigram-based SVM classifier combined with subjectivity detection.,0,original
"However, after several advances in tasks such as automatic tagging of text with high level semantics such as parts-of-speech (Ratnaparkhi, 1996), named-entities (Bikel et al. , 1999), sentence-parsing (Charniak, 1997), etc. , there is increasing hope that one could leverage this information into IR techniques.",0,original
"4 Experiments Our experiments involve data from two treebanks: the Wall Street Journal Penn treebank (Marcus et al., 1993) and the Chinese treebank (Xue et al., 2004).",0,original
"6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly.",0,original
"Further, it has been shown (Weeds et al. 2005; Weeds and Weir 2005) that performance of Lins distributional similarity score decreases more significantly than other measures for low frequency nouns.",0,original
"They first extract English collocations using the Xtract systetn (Smadja, 1993), and theu look for French coutlterparts.",0,original
"The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal (Marcus et al. , 1993).",0,original
"In previous work (Church et al, 1993), we have reported some preliminary success in aligning the English and Japanese versions of the AWK manual (Aho, Kernighan, Weinberger (1980)), using charalign (Church, 1993), a method that looks for character sequences that are the same in both the source and target.",0,original
"5.1 Baseline System We trained Moses on all Spanish-English Europarl sentences up to length 20 (177k sentences) using GIZA++ Model 4 word alignments and the growdiag-final-and combination heuristic (Koehn et al., 2007; Och and Ney, 2003; Koehn, 2002), which performed better than any alternative combination heuristic.13 The baseline estimates (Heuristic) come fromextractingphrasesuptolength7fromtheword alignment.",0,original
"Meanwhile, some learning algorithms, like maximum likelihood for conditional log-linear models (Lafferty et al., 2001), unsupervised models (Pereira and Schabes, 1992), and models with hidden variables (Koo and Collins, 2005; Wang et al., 2007; Blunsom et al., 2008), require summing over the scores of many structures to calculate marginals.",0,original
"(Smadja, 1993), extracts uninterrupted as well as interrupted collocations (predicative relations, rigid noun phrases and phrasal templates).",0,original
"In cut-and-paste summarization (Jing and McKeown, 2000), sentence combination operations were implemented manually following the study of a set of professionally written abstracts; however the particular pasting operation presented here was not implemented.",0,original
"They give a probabilistic formation of paraphrasing which naturally falls out of the fact that they use techniques from phrase-based statistical machine translation: e2 = argmax e2:e2negationslash=e1 p(e2|e1) (1) where p(e2|e1) = summationdisplay f p(f|e1)p(e2|f,e1) (2)  summationdisplay f p(f|e1)p(e2|f) (3) Phrase translation probabilities p(f|e1) and p(e2|f) are commonly calculated using maximum likelihood estimation (Koehn et al., 2003): p(f|e) = count(e,f)summationtext f count(e,f) (4) where the counts are collected by enumerating all bilingual phrase pairs that are consistent with the 197 conseguido .opportunitiesequalcreatetofailedhasprojecteuropeanthe oportunidadesdeigualdadlahanoeuropeoproyectoel Figure 1: The interaction of the phrase extraction heuristic with unaligned English words means that the Spanish phrase la igualdad aligns with equal, create equal, and to create equal.",0,original
"(2008)]), and others identifying non-anaphoric definite descriptions (using rule-based techniques [e.g., Vieira and Poesio (2000)] and unsupervised techniques [e.g., Bean and Riloff (1999)]).",0,original
"Unlike (Titov and Henderson, 2007b), in the shared task we used only the simplest feed-forward approximation, which replicates the computation of a neural network of the type proposed in (Henderson, 2003).",0,original
"2.1 Minimum Error Rate Training The predominant approach to reconciling the mismatch between the MAP decision rule and the evaluation metric has been to train the parameters  of the exponential model to correlate the MAP choice with the maximum score as indicated by the evaluation metric on a development set with known references (Och, 2003).",0,original
"Past work has synchronously binarized such rules for efficiency (Zhang et al., 2006; Huang et al., 2008).",0,original
"The definitions of part-of-speech (POS) categories and syntactic labels follow those of the Treebank I style (Marcus et al. , 1993).",0,original
In particular we work with dependency paths that can reach beyond direct dependencies as opposed to Lin (1998) but in the line of Pado and Lapata (2007).,0,original
"Pr(pi,F,A) = summationdisplay i,c()=(pi,F,A) productdisplay rji p(rj) (4) In order to acquire the rules specific to our model and to induce their probabilities, we parse the English side of our corpus with an in-house implementation (Soricut, 2005) of Collins parsing models (Collins, 2003) and we word-align the parallel corpus with the Giza++2 implementation of the IBM models (Brown et al. , 1993).",0,original
"Table 3 compares precision, recall, and F scores for our system with CoNLL-2001 results training on sections 15-18 of the Penn Treebank and testing on section 21 (Marcus et al. , 1993).",0,original
"The table in Figure 9 shows a comparison of different systems for which tagging accuracies have been reported previously for the 17-tagset case (Goldberg et al., 2008).",0,original
"2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al. , 1993), the Chinese Penn Treebank (Xia et al. , 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000).",0,original
"Although some work has been done on syllabifying orthographic forms (Muller et al., 2000; Bouma, 2002; Marchand and Damper, 2007; Bartlett et al., 2008), syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes.",0,original
"L1 or Lasso regularization of linear models, introduced by Tibshirani (1996), embeds feature selection into regularization so that both an assessment of the reliability of a feature and the decision about whether to remove it are done in the same framework, and has generated a large amount of interest in the NLP community recently (e.g. , Goodman 2003; Riezler and Vasserman 2004).",0,original
"It is important to realize that the output of all mentioned processing steps is noisy and contains plenty of mistakes, since the data has huge variability in terms of quality, style, genres, domains etc., and domain adaptation for the NLP tasks involved is still an open problem (Dredze et al., 2007).",0,original
"Various machine learning strategies have been proposed to address this problem, including semi-supervised learning (Zhu, 2007), domain adaptation (Wu and Dietterich, 2004; Blitzer et al., 2006; Blitzer et al., 2007; Arnold et al., 2007; Chan and Ng, 2007; Daume, 2007; Jiang and Zhai, 2007; Reichart and Rappoport, 2007; Andreevskaia and Bergler, 2008), multi-task learning (Caruana, 1997; Reichart et al., 2008; Arnold et al., 2008), self-taught learning (Raina et al., 2007), etc. A commonality among these methods is that they all require the training data and test data to be in the same feature space.",0,original
"Based on IBM Model 1 lexical parameters(Brown et al. , 1993), providing a complementary probability for each tuple in the translation table.",0,original
"In addition, many more sophisticated parsing models are elaborations of such PCFG models, so understanding the properties of PCFGs is likely to be useful (Charniak, 1997; Collins, 1997).",0,original
"For instance, Pang and Lee (2004) train an independent subjectivity classifier to identify and remove objective sentences from a review prior to polarity classification.",0,original
"Instead of computing all intersections, Och (2003) only computes critical intersections where highest-score translations will change.",0,original
"Given a set of evidences E over all the relevant word pairs, in (Snow et al., 2006), the probabilistic taxonomy learning task is defined as the problem of finding the taxonomy hatwideT that maximizes the 67 probability of having the evidences E, i.e.: hatwideT = arg max T P(E|T) In (Snow et al., 2006), this maximization problem is solved with a local search.",0,original
"The translation problem can be statistically formulated as in (Brown et al., 1993).",0,original
(2004) use an information extraction engine to extract linguistic features from documents relevant to the target term.,0,original
"To cope with this problem we 898 use the concept of class proposed for a word n-gram model (Brown et al. , 1992).",0,original
"In all experiments that follow, each system configuration was independently optimized on the NIST 2003 Chinese-English test set (919 sentences) using minimum error rate training (Och, 2003) and tested on the NIST 2005 Chinese-English task (1082 sentences).",0,original
"A variety of methods are used to account for the re-ordering stage: word-based (Brown et al. , 1993), templatebased (Och et al. , 1999), and syntax-based (Yamada and Knight, 2001), to name just a few.",0,original
"Both Liang, et al (2006), and Tillmann and Zhang (2006) report on effective machine translation (MT) models involving large numbers of features with discriminatively trained weights.",0,original
"Since in these LVCs the complement is a predicative noun in stem form identical to a verb, we form development and test expressions by combining give or take with verbs from selected semantic classes of Levin (1993), taken from Stevenson et al.",0,original
"A similar approach is used here, including a collapsed version of the Treebank POS tag set (Marcus et al., 1993), with additions for specific words (e.g. personal pronouns and filled pause markers), compound punctuation (e.g. multiple exclamation marks), and a general emoticon tag, resulting in a total of 41 tags.",0,original
"In this work, model fit is reported in terms of the likelihood ratio statistic, G 2, and its significance (Read and Cressie, 1988; Dunning, 1993).",0,original
"It will also be relevant to apply advanced statistical models that can incorporate various useful information to this task, e.g., the maximum entropy model (Ratnaparkhi, 1996).",0,original
"CRF (baseline)] 97.18 97.21  Table 7: POS tagging results of the previous top systems for PTB III data evaluated by label accuracy system test additional resources JESS-CM (CRF/HMM) 95.15 1G-word unlabeled data 94.67 15M-word unlabeled data (Ando and Zhang, 2005) 94.39 15M-word unlabeled data (Suzuki et al., 2007) 94.36 17M-word unlabeled data (Zhang et al., 2002) 94.17 full parser output (Kudo and Matsumoto, 2001) 93.91  [supervised CRF (baseline)] 93.88  Table 8: Syntactic chunking results of the previous top systems for CoNLL00 shared task data (F=1 score) 30-31 Aug. 1996 and 6-7 Dec. 1996 Reuters news articles, respectively.",0,original
"MI is defined in general as follows: y) I ix y) = log2 P(x) P(y) We can use this definition to derive an estimate of the connectedness between words, in terms of collocations (Smadja, 1993), but also in terms of phrases and grammatical relations (Hindle, 1990).",0,original
"A la Ramshaw and Marcus (1995), they represent the words as a sequence of labeled words with IOB annotations, where the B marks a word at the beginning of a chunk, I marks a word inside a chunk, and O marks those words (and punctuation) that are outside chunks.",0,original
"More details about the re-ranking algorithm are presented in (Ji et al. , 2006).",0,original
See Yarowsky (1995) for details.,0,original
"(Lin, 2004; Lin and Och, 2004).",0,original
"POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al. , 1993).",0,original
"2 Previous Approaches Koehn, et al.?s (2003) method of estimating phrasetranslation probabilities is very simple.",0,original
"(Black et al. , 1992; Magerman, 1994)) and view the POS tags and word identities as two separate sources of information.",0,original
"We develop this intuition into a technique called synchronous binarization (Zhang et al. , 2006) which binarizes a synchronous production or treetranduction rule on both source and target sides simultaneously.",0,original
"Note that unlike the constructions in (Talbot and Osborne, 2007b) and (Church et al., 2007) no errors are possible for ngrams stored in the model.",0,original
"This method is described hereafter, while the subsequent steps, that use deeper (rulebased) levels of knowledge, are implemented into the ARIOSTO_LEX lexical learning system, described in (Basili et al. , 1993b, 1933c and 1996).",0,original
The patterns will be manually constructed following the approach of Hearst (1992) and Nakov and Hearst (2008).6 The example collection for each relation R will be passed to two independent annotators.,0,original
"3.1 Paraphrase Identification A few unsupervised metrics have been applied to automatic paraphrase identification and extraction (Barzilay & Lee, 2003; Dolan & Brockett, 2004).",0,original
"The labeled corpus is the Penn Wall Street Journal treebank (Marcus et al. , 1993).",0,original
"(Case-sensitive) BLEU-4 (Papineni et al. , 2002) is used as the evaluation metric.",0,original
"Our work builds upon Turneys work on semantic orientation (Turney, 2002) and synonym learning (Turney, 2001), in which he used a PMI-IR algorithm to measure the similarity of words and phrases based on Web queries.",0,original
"Our evaluation metric is BLEU (Papineni et al., 2002) with caseinsensitive matching from unigram to four-gram.",0,original
"Pharaoh also includes lexical weighting parameters that are derived from the alignments used to induce its phrase pairs (Koehn et al. , 2003).",0,original
The linear kernel derived from the L1 distance is the same as the difference-weighted token-based similarity measure of Weeds and Weir (2005).,0,original
"Different optimization techniques are available, like the Simplex algorithm or the special Minimum Error Training as described in (Och 2003).",0,original
"Detail of the Bakeoff data sets is in (Levow, 2006).",0,original
"The next two methods are heuristic (H) in (Och and Ney, 2003) and grow-diagonal (GD) proposed in (Koehn et al., 2003).",0,original
"This approach to minimally supervised classifier construction has been widely studied (Yarowsky 1995), especially in cases in which the features of interest are orthogonal in some sense (e.g. , Blum and Mitchell 1998; Abney 2002).",0,original
"We assign tags of part-of-speech (POS) to the words with MXPOST that adopts the Penn Treebank tag set (Ratnaparkhi, 1996).",0,original
"We use the maximum entropy tagging method described in (Kazama et al. , 2001) for the experiments, which is a variant of (Ratnaparkhi, 1996) modified to use HMM state features.",0,original
"We have achieved average results in the CoNLL domain adaptation track open submission (Marcus et al. , 1993; Johansson and Nugues, 2007; Kulick et al. , 2004; MacWhinney, 2000; Brown, 1973).",0,original
(2005) applied the distributional similarity proposed by Lin (1998) to coordination disambiguation.,0,original
"Strength of association between subject i and verb j is measured using mutual information (Church and Hanks 1990): )ln(),( ji ij tftf tfNjiMI  = . Here tfij is the maximum frequency of subject-verb pair ij in the Reuters corpus, tfi is the frequency of subject head noun i in the corpus, tfj is the frequency of verb j in the corpus, and N is the number of terms in the corpus.",0,original
"For the English experiments, we use the now-standard training and test sets that were introduced in (Marcus and Ramshaw, 1995)2.",0,original
"In particular, we use a feature augmentation technique recently introduced by Daume III (2007), and active learning (Lewis and Gale, 1994) to perform domain adaptation of WSD systems.",0,original
"We ran the trainer with its default settings (maximum phrase length 7), and then used Koehns implementation of minimumerror-rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on our development set, yielding the values shown in Table 2.",0,original
"For the MER training (Och, 2003), we modified Koehns MER trainer (Koehn, 2004) for our tree sequence-based system.",0,original
"Other linear time algorithms for rank reduction are found in the literature (Zhang et al., 2008), but they are restricted to the case of synchronous context-free grammars, a strict subclass of the LCFRS with f = 2.",0,original
Goodman (1997) and Johnson (1997) both suggest this strategy.,0,original
"4 Sub Translation Combining For sub translation combining, we mainly use the best-first expansion idea from cube pruning (Huang and Chiang, 2007) to combine subtranslations and generate the whole k-best translations.",0,original
"5 The Experimental Results We used the Penn Treebank WSJ corpus (Marcus et al. , 1993) to perform empirical experiments on the proposed parsing models.",0,original
"(Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL).",0,original
"In a different work, Banerjee and Lavie (2005) argued that the measured reliability of metrics can be due to averaging effects but might not be robust across translations.",0,original
"Top-Down Parsing and Language Modeling Statistically based heuristic best-first or beam-search strategies (Caraballo and Charniak 1998; Charniak, Goldwater, and Johnson 1998; Goodman 1997) have yielded an enormous improvement in the quality and speed of parsers, even without any guarantee that the parse returned is, in fact, that with the maximum likelihood for the probability model.",0,original
"40,000 sentences) and section 23 for testing (see Collins 1997, 1999; Charniak 1997, 2000; l~,atnalmrkhi 1999); we only tested on sentences _< 40 words (2245 sentences).",0,original
"A sinfilar approach has been chosen by (Da.gan et al. , 1993).",0,original
"Intuitively speaking, the gaps on the target-side will lead to exponential complexity in decoding with integrated language models (see Section 3), as well as synchronous parsing (Zhang et al. , 2006).",0,original
"In showing how DLTAG and an interpretative process on its derivations operate, we must, of necessity, gloss over how inference triggered by adjacency or associated with a structural connective provides the intended relation between adjacent discourse 578 Computational Linguistics Volume 29, Number 4 units: It may be a matter simply of statistical inference, as in Marcu and Echihabi (2002), or of more complex inference, as in Hobbs et al.",0,original
"In this method, each training sentence is decoded and weights are updated at every iteration (Liang et al. , 2006).",0,original
"For evaluation we use ROUGE (Lin, 2004) SU4 recall metric1, which was among the official automatic evaluation metrics for DUC.",0,original
Direct feedback loops that copy a predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by Ratnaparkhi (1996) and the memory-based tagger (MBT) proposed by Daelemans et al.,0,original
"Increasingly, parallel corpora are becoming available for many language pairs and SMT systems have been built for French-English, German-English, Arabic-English, Chinese-English, Hindi-English and other language pairs (Brown et al. , 1993), (AlOnaizan et al. , 1999), (Udupa, 2004).",0,original
"Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling.",0,original
"2 Related Work Recently, several studies have reported about dialog systems that are capable of classifying emotions in a human-computer dialog (Batliner et al., 2004; Ang et al., 2002; Litman and Forbes-Riley, 2004; Rotaru et al., 2005).",0,original
"In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007).",0,original
"We trained log linear models with theperceptronalgorithm(Collins,2002)usingfea746 Markov order Classification Task 0 1 2 S1 (no multi-word constituent start) 96.7 96.9 96.9 E1 (no multi-word constituent end) 97.3 97.3 97.3 Table 2: Classification accuracy on development set for binary classes S1 and E1, for various Markov orders.",0,original
"The value of fj is calculated by Mutual Information (Church and Hanks, 1990) between xi and fj.",0,original
"model reranking has also been established, both for synchronous binarization (Zhang et al., 2006) and for target-only binarization (Huang, 2007).",0,original
"The reliability for the two annotation tasks (-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively.",0,original
"In particular, ROUGE-2 is the recall in bigrams with a set of human-written abstractive summaries (Lin, 2004).",0,original
"Given a set of features and a training corpus, the MaxEnt estimation process produces a model in which every feature fi has a weight i. We can compute the conditional probability as (Berger et al., 1996): p(o|h) = 1Z(h) productdisplay i ifi(h,o) (1) Z(h) = summationdisplay o productdisplay i ifi(h,o) (2) The conditional probability of the outcome is the product of the weights of all active features, normalized over the products of all the features.",0,original
"There are other types of variations for phrases; for example, insertion, deletion or substitution of words, and permutation of words such as view point and point of view are such variations (Daille et al., 1996).",0,original
"Adaptations to the algorithms in the presence of ngram LMs are discussed in (Chiang, 2007; Venugopal et al., 2007; Huang and Chiang, 2007).",0,original
"Classes can be induced directly from the corpus using distributional clustering (Pereira, Tishby, and Lee 1993; Brown et al. 1992; Lee and Pereira 1999) or taken from a manually crafted taxonomy (Resnik 1993).",0,original
"Other classes, such as the ones below can be extracted using lexico-statistical tools, such as in (Smadja, 1993), and then checked by a human.",0,original
"We use a standard maximum entropy classifier (Berger et al. , 1996) implemented as part of MALLET (McCallum, 2002).",0,original
"Five chunk tag sets, IOB1, IOB2, IOE1, IOE2 (Ramshaw and Marcus, 1995) and SE (Uchimoto et al. , 2000), are commonly used.",0,original
"test additional resources JESS-CM (CRF/HMM) 97.35 97.40 1G-word unlabeled data (Shen et al., 2007) 97.28 97.33  (Toutanova et al., 2003) 97.15 97.24 crude company name detector [sup.",0,original
"Another current topic of machine translation is automatic evaluation of MT quality (Papineni et al. , 2002; Yasuda et al. , 2001; Akiba et al. , 2001).",0,original
"Machine learning methods should be interchangeable: Transformation-based learning (TBL) (Brill, 1993) and Memory-based learning (MBL) (Daelemans et al. , 2002) have been applied to many different problems, so a single interchangeable component should be used to represent each method.",0,original
"We use the same alignment data for the five language pairs Chinese/English, Romanian/English, Hindi/English, Spanish/English, and French/English (Wellington et al. , 2006).",0,original
"Similar to the work of Barzilay and Lee (2003), who have applied paraphrase generation techniques to comparable corpora consisting of different newspaper articles about the same event, we are currently attempting to solve the data sparseness problem by extending our approach to non-parallel corpora.",0,original
"This is referred to as an IOB representation (Ramshaw and Marcus, 1995).",0,original
"The hierarchical phrase translation pairs are extracted in a standard way (Chiang, 2005): First, the bilingual data are word alignment annotated by running GIZA++ (Och and Ney, 2003) in two directions.",0,original
"A simple example is shown in Figure 1, where the arc between a and hat indicates that hat is the head of a. Current statistical dependency parsers perform better if the dependency lengthes are shorter (McDonald and Nivre, 2007).",0,original
"We could also use the value of semantic similarity and relatedness measures (Pedersen et al., 2004) or the existence of hypernym or hyponym relations as features.",0,original
"This task is quite common in corpus linguistics and provides the starting point to many other algorithms, e.g., for computing statistics such as pointwise mutual information (Church and Hanks, 1990), for unsupervised sense clustering (Schutze, 1998), and more generally, a large body of work in lexical semantics based on distributional profiles, dating back to Firth (1957) and Harris (1968).",0,original
"Under the maximum entropy framework (Berger et al. , 1996), evidence from different features can be combined with no assumptions of feature independence.",0,original
"The modified version of the Roark parser, trained on the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), was used to parse the different narratives and produce the word by word measures.",0,original
"Algorithm 1 The RRM Decoding Algorithm foreacha26a29a27a67a42 foreacha68 a1a20a23a69a10a11a10a12a10a45 a60 a48a22a70a26a22a71 a1a73a72a2a25 a57a38a50 a7 a56 a48a54a57 a64a74a30 a57 a31a33a26a17a34 a5a11a75 a60a77a76a74a76 a31a78a26a35a34a66a79a81a80a83a82a38a84a69a85a86a80a24a87a88a48 a60 a48 a70a26a61a71 Somewhat similarly, the MaxEnt algorithm has an associated set of weights a31a33a89 a48a54a57 a34a48a90a50 a7a53a52a54a52a54a52a15 a57a38a50 a7a58a52a54a52a54a52 a25, which are estimated during the training phase so as to maximize the likelihood of the data (Berger et al. , 1996).",0,original
"These tasks include collocation discovery (Pearce, 2001), smoothing and model estimation (Brown et al. , 1992; Clark and Weir, 2001) and text classi cation (Baker and McCallum, 1998).",0,original
"Following (Collins, 2002), we do not distinguish rare words.",0,original
"However, (Koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between there is in English and es gibt (it gives) in German.",0,original
"Techniques that analyze n-gram precision such as BLEU score (Papineni et al., 2002) have been developed with the goal of comparing candidate translations against references provided by human experts in order to determine accuracy; although in our application the candidate translator is a student and not a machine, the principle is the same, and we wish to adapt their technique to our context.",0,original
Our work in sentence reformulation is different from cut-and-paste summarization (Jing and McKeown 2000) in many ways.,0,original
"(Snow et al., 2006; Nakov & Hearst, 2008).",0,original
"We do not use particular lexicosyntactic patterns, as previous attempts have (Hearst, 1992; Caraballo, 1999; Imasumi, 2001; Fleischman et al. , 2003; Morin and Jacquemin, 2003; Ando et al. , 2003).",0,original
"However more recent results have shown that it can indeed improve parser performance (Bacchiani et al., 2006; McClosky et al., 2006a; McClosky et al., 2006b).",0,original
"We computed precision, recall and error rate on the entire set for each data set.6 For an initial alignment, we used GIZA++ in both directions (E-to-F and F-to-E, where F is either Chinese (C) or Spanish (S)), and also two different combined alignments: intersection of E-to-F and F-to-E; and RA using a heuristic combination approach called grow-diag-final (Koehn et al. , 2003).",0,original
"The parameters of the refined productions Ax  By Cz, where Ax is a subcategory of A, By of B, and Cz of C, can then be estimated in various ways; past work has included both generative (Matsuzaki et al., 2005; Liang et al., 2007) and discriminative approaches (Petrov and Klein, 2008).",0,original
"In this paper, we use IBM model 1 (Brown et al., 1993) in order to get the probability P(Q|DA) as follows.",0,original
Marcu and Echihabi (2002) demonstrated that word pairs extracted from the respective text spans are a good signal of the discourse relation between arguments.,0,original
"4Following Carletta (1996), we measure agreement in Kappa, which follows the formula K = P(A)P(E)1P(E) where P(A) is observed, and P(E) expected agreement.",0,original
"3.1 Data and Experimental Setup The data set by Pang and Lee (2004) consists of 2000 movie reviews (1000-pos, 1000-neg) from the IMDb review archive.",0,original
"As in other work, we collapsed AI)VP and Pl?Jl"" to the same label when calculating these scores (see Collins 1997; I~,atnaparkhi 1999; Charniak 1997).",0,original
"We show translation results in terms of the automatic BLEU evaluation metric (Papineni et al. , 2002) on the MT03 Arabic-English DARPA evaluation test set consisting of a212a89a212a89a87 sentences with a98a89a212a161a213a89a214a89a215 Arabic words with a95 reference translations.",0,original
"accuracy Training data Turney (2002) 66% unsupervised Pang & Lee (2004) 87.15% supervised Aue & Gamon (2005) 91.4% supervised SO 73.95% unsupervised SM+SO to increase seed words, then SO 74.85% weakly supervised Table 7: Classification accuracy on the movie review domain Turney (2002) achieves 66% accuracy on the movie review domain using the PMI-IR algorithm to gather association scores from the web.",0,original
"After unioning the Viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion (Koehn et al., 2003).",0,original
"Binarizing the syntax trees for syntax-based machine translation is similar in spirit to generalizing parsing models via markovization (Collins, 1997; Charniak, 2000).",0,original
Hughes and Ramage (2007) present a lexical similarity model based on random walks on graphs derived from WordNet; Rao et al.,0,original
"For our POS tagging experiments, we use 561 MEDLINE sentences (9576 words) from the Penn BioIE project (PennBioIE, 2005), a test set previously used by Blitzer et al.(2006).",0,original
"The POS tagger uses the same contextual predicates as Ratnaparkhi (1996); the supertagger adds contextual predicates corresponding to POS tags and bigram combinations of POS tags (Curran and Clark, 2003).",0,original
"We just assign these rules a constant score trained using our implementation of Minimum Error Rate Training (Och, 2003b), which is 0.7 in our system.",0,original
"5http://cl.cs.okayama-u.ac.jp/rsc/ jacabit/ a4a6a5 which gathers the set of co-occurrence units a7 associated with the number of times that a7 and a2 occur together a8a6a9a10a9 a5 a11 . In order to identify speci c words in the lexical context and to reduce word-frequency effects, we normalize context vectors using an association score such as Mutual Information (Fano, 1961) or Log-likelihood (Dunning, 1993).",0,original
"In recent years, reranking techniques have been successfully applied to the so-called history-based models (Black et al. , 1993), especially to parsing (Collins, 2000; Collins and Duffy, 2002).",0,original
"(Kanayama and Nasukawa, 2006) reported that it was appropriate in 72.2% of cases.",0,original
"For example, aspects of a digital camera could include picture quality, battery life, size, color, value, etc. Finding such aspects is a challenging research problem that has been addressed in a number of ways (Hu and Liu, 2004b; Gamon et al., 2005; Carenini et al., 2005; Zhuang et al., 2006; Branavan et al., 2008; Blair-Goldensohn et al., 2008; Titov and McDonald, 2008b; Titov and McDonald, 2008a).",0,original
"Instead, researchers routinely use automatic metrics like Bleu (Papineni et al., 2002) as the sole evidence of improvement to translation quality.",0,original
"Responsiveness differs from other measures of summary content such as SEE coverage (Lin and Hovy, 2002) and Pyramid scores (Nenkova and Passonneau, 2004) in that it does not compare a peer summary against a set of known human summaries.",0,original
Wiebe (2000) uses Lin (1998a) style distributionally similar adjectives in a cluster-and-label process to generate sentiment lexicon of adjectives.,0,original
"Because treebank annotation for individual formalisms is prohibitively expensive, there have been a number of efforts to extract TAGs, LFGs, and, more recently, HPSGs, from the Penn Treebank (Xia 1999; Chen and Vijay-Shanker 2000; Xia, Palmer, and Joshi 2000; Xia 2001; Cahill et al. 2002; Miyao, Ninomiya, and Tsujii 2004; ODonovan et al. 2005; Shen and Joshi 2005; Chen, Bangalore, and Vijay-Shanker 2006).",0,original
"The toolkit also implements suffixarray grammar extraction (Callison-Burch et al., 2005; Lopez, 2007) and minimum error rate training (Och, 2003).",0,original
"Bilingual alignments have so far shown that they can play multiple roles in a wide range of linguistic applications, such as computer assisted translation (Isabelle et al. , 1993; Brown et al. , 1990), terminology (Dagan and Church, 1994) lexicography (Langlois, 1996; Klavans and Tzoukermann, 1995; Melamed, 1996), and cross-language information retrieval (Nie et al. , * This research was funded by the Canadian Department of Foreign Affairs and International Trade (http://~.dfait-maeci.gc.ca/), via the Agence de la francophonie (http://~.",0,original
"For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).",0,original
"Statistics on co-occurrence of words in a local context were used recently for monolingual word sense disambiguation (Gale, Church, and Yarowsky 1992b, 1993; Sch6tze 1992, 1993) (see Section 7 for more details and Church and Hanks 1990; Smadja 1993, for other applications of these statistics).",0,original
"The WSJNPVP set consists of part-of speech tagged Wall Street Journal material (Marcus, Santorini & Marcinkiewicz, 1993), supplemented with syntactic tags indicating noun phrase and verb phrase boundaries (Daelemans et al, 1999iii).",0,original
"on test BLEU BP BLEU BP pair-CI 95% BLEU BP 3 01  03 32.98 0.92 33.03 0.93 [ -0.23, +0.34] 33.60 0.93 4 01  04 33.44 0.93 33.46 0.93 [ -0.26, +0.29] 34.97 0.94 5 01  05 33.07 0.92 33.14 0.93 [ -0.29, +0.43] 34.33 0.93 6 01  06 32.86 0.92 33.53 0.93 [+0.26, +1.08] 34.43 0.93 7 01  07 33.08 0.93 33.51 0.93 [+0.04, +0.82] 34.49 0.93 8 01  08 33.12 0.93 33.47 0.93 [ -0.06, +0.75] 34.50 0.94 9 01  09 33.15 0.93 33.22 0.93 [ -0.35, +0.51] 34.68 0.93 10 01  10 33.01 0.93 33.59 0.94 [+0.18, +0.96] 34.79 0.94 11 01  11 32.84 0.94 33.40 0.94 [+0.13, +0.98] 34.76 0.94 12 01  12 32.73 0.93 33.49 0.94 [+0.34, +1.18] 34.83 0.94 13 01  13 32.71 0.93 33.54 0.94 [+0.39, +1.26] 34.91 0.94 14 01  14 32.66 0.93 33.69 0.94 [+0.58, +1.47] 34.97 0.94 15 01  15 32.47 0.93 33.57 0.94 [+0.63, +1.57] 34.99 0.94 16 01  16 32.51 0.93 33.62 0.94 [+0.62, +1.59] 35.00 0.94 3.2 Non-Uniform System Prior Weights As pointed out in Section 2.1, a useful property of the MBR-like system selection method is that system prior weights can easily be trained using the Minimum Error Rate Training (Och, 2003).",0,original
"(Ruge, 1992; Rapp, 2002)).",0,original
"EsEn 63.00.9 59.20.9 6.01.4 EnEs 63.80.9 60.51.0 5.21.6 DeEn 71.60.8 69.00.9 3.61.3 EnDe 75.90.8 73.50.9 3.21.2 FrEn 62.90.9 59.21.0 5.91.6 EnFr 63.40.9 60.00.9 5.41.4 bined in a log-linear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) procedure, optimising the BLEU (Papineni et al., 2002) score obtained on the development partition.",0,original
"So far, these techniques have focused on phrasebased models using contiguous phrases (Koehn et al. , 2003; Och and Ney, 2004).",0,original
"INTRODUCTION Word associations have been studied for some time in the fields of psycholinguistics (by testing human subjects on words), linguistics (where meaning is often based on how words co-occur with each other), and more recently, by researchers in natural language processing (Church and Hanks, 1990; Hindle and Rooth, 1990; Dagan, 1990; McDonald et al. , 1990; Wilks et al. , 1990) using statistical measures to identify sets of associated words for use in various natural language processing tasks.",0,original
"In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al. , 2000; Akiba et al. , 2001; Papineni et al. , 2002; NIST, 2002; Leusch et al. , 2003; Turian et al. , 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gimenez et al. , 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently.",0,original
"Finally, inducing lexical semantics from distributional data (e.g. , (Brown et al. , 1992; Church et al. , 1989)) is also a form of surface cueing.",0,original
"Indeed, in the II scenario, (Steedman et al. , 2003a; McClosky et al. , 2006a; Charniak, 1997) reported no improvement of the base parser for small (500 sentences, in the first paper) and large (40K sentences, in the last two papers) seed datasets respectively.",0,original
"(1994) uses the mutual information clustering algorithm described in (Brown et al. , 1992).",0,original
Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features.,0,original
"have been used in statistical machine translation (Brown et al. , 1990), terminology research and translation aids (Isabelle, 1992; Ogden and Gonzales, 1993; van der Eijk, 1993), bilingual lexicography (Klavans and Tzoukermann, 1990; Smadja, 1992), word-sense disambiguation (Brown et al. , 1991b; Gale et al. , 1992) and information retrieval in a multilingual environment (Landauer and Littman, 1990).",0,original
"We evaluated the translation quality using the BLEU metric (Papineni et al. , 2002), as calculated by mteval-v11b.pl with its default setting except that we used case-sensitive matching of n-grams.",0,original
Walker et al. \[forthcoming\] and Boguraev and Briscoe \[1988\]).,0,original
"1 Introduction The overall goal of the Penn Discourse Treebank (PDTB) is to annotate the million word WSJ corpus in the Penn TreeBank (Marcus et al. , 1993) with a layer of discourse annotations.",0,original
"5.3 Translation Results For the translation experiments on the BTEC task, we report the two accuracy measures BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) as well as the two error rates: word error rate (WER) and position-independent word error rate (PER).",0,original
"In the concept extension part of our algorithm we adapt our concept acquisition framework (Davidov and Rappoport, 2006; Davidov et al., 2007; Davidov and Rappoport, 2008a; Davidov and Rappoport, 2008b) to suit diverse languages, including ones without explicit word segmentation.",0,original
"4 Experiments We evaluated our classifier-based best-first parser on the Wall Street Journal corpus of the Penn Treebank (Marcus et al. , 1993) using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.",0,original
"Using GIZA++ model 4 alignments and Pharaoh (Koehn et al. , 2003), we achieved a BLEU score of 0.3035.",0,original
"The translation quality is evaluated by case-sensitive NIST (Doddington, 2002) and BLEU (Papineni et al. , 2002)2.",0,original
"For example, both Haghighi and Klein (2006) and Mann and McCallum (2008) have demonstrated results better than 66.1% on the apartments task described above using only a list of 33 highly discriminative features and the labels they indicate.",0,original
"Dependency Analyzer PP-Attachment Resolver Root-Node Finder Base NP Chunker (POS Tagger) = SVM, = Preference Learning Figure 2: Module layers in the system That is, we use Penn Treebanks Wall Street Journal data (Marcus et al. , 1993).",0,original
"2 WordNet-based semantic relatedness measures 2.1 Basic measures Two similarity/distance measures from the Perl package WordNet-Similarity written by (Pedersen et al. , 2004) are used.",0,original
"We perform minimum error rate training (Och, 2003) to tune the feature weights for the log-linear modeltomaximizethesystemssBLEUscoreonthe development set.",0,original
Method Number of frames Number of verbs Linguistic resources F-Score (evaluation based on a gold standard) Coverage on a corpus C. Manning (1993) 19 200 POS tagger + simple finite state parser 58 T. Briscoe & J. Carroll (1997) 161 14 Full parser 55 A. Sarkar & D. Zeman (2000) 137 914 Annotated treebank 88 D. Kawahara et al.,0,original
"2 Bilingual Bracketing In [Wu 1997], the Bilingual Bracketing PCFG was introduced, which can be simplified as the following production rules: A ! [AA] (1) A ! < AA > (2) A ! f=e (3) A ! f=null (4) A ! null=e (5) Where f and e are words in the target vocabulary Vf and source vocabulary Ve respectively.",0,original
"The first SMT systems were developed in the early nineties (Brown et al. 1990, 1993).",0,original
"??Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al. , 2003; Och and Ney, 2004).",0,original
"3.2 Translation quality Table 2 presents the impact of parse quality on a treelet translation system, measured using BLEU (Papineni et al. , 2002).",0,original
"Evidence have shown that by exploiting the constraint of so-called ""one sense per discourse,"" (Gale, Church and Yarowsky 1992b) and the strategy of bootstrapping (Yarowsky 1995), it is possible to boost coverage, while maintaining about the same level of precision.",0,original
"Schtze, 1993) is not suited to highly skewed distributions omni-present in natural language.",0,original
"In order to calculate a global score or probability for a transition sequence, two systems used a Markov chain approach (Duan et al. , 2007; Sagae and Tsujii, 2007).",0,original
"Instead of taking just the nal weight vector, the voted perceptron algorithm takes the average of the t. Collins (2002) reported and we con rmed that this averaging reduces overtting considerably.",0,original
"Phrase tables were learned from the training corpus using the diag-and method (Koehn et al. , 2003), and using IBM model 2 to produce initial word alignments (these authors found this worked as well as IBM4).",0,original
"Both systems are built around from the maximum-entropy technique (Berger et al. , 1996).",0,original
"2 The METEOR Metric 2.1 Weaknesses in BLEU Addressed in METEOR The main principle behind IBMs BLEU metric (Papineni et al, 2002) is the measurement of the 66 overlap in unigrams (single words) and higher order n-grams of words, between a translation being evaluated and a set of one or more reference translations.",0,original
"task (Church, 1988; Brill, 1993; Ratnaparkhi, 1996; Daelemans et al. , 1996), and reported errors in the range of 26% are common.",0,original
"For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997; Wang et al. , 2005), and yet they are not being used in current large margin training algorithms.",0,original
"The training and test set were derived by finding all instances of the confusable words in the Brown Corpus, using the Penn Treebank parts of speech and tokenization (Marcus, Santorini et al. 1993), and then dividing this set into 80% for training and 20% for testing.",0,original
"Hindle (1990) proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of ""similar"" events that have been seen.",0,original
"The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For (computational) linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank (Marcus et al. , 1993), or semantic annotations, such as the one underlying ACE (Doddington et al. , 2004), are increasingly being used in a quasi standard way.",0,original
"The features are similar to the ones used in phrasal systems, and their weights are trained using max-BLEU training (Och, 2003).",0,original
"Many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Koehn et al. , 2003).",0,original
"To address this, standard measures like precision and recall could be used, as in some previous research (Banerjee and Lavie, 2005; Melamed et al., 2003).",0,original
"This could, for example, aid machine-translation evaluation, where it has become common to evaluate systems by comparing their output against a bank of several reference translations for the same sentences (Papineni et al. , 2002).",0,original
"First, we considered single sentences as documents, and tokens as sentences (we define a token as a sequence of characters delimited by 1In our case, the score we seek to globally maximize by dynamic programming is not only taking into account the length criteria described in (Gale and Church, 1993) but also a cognate-based one similar to (Simard et al. , 1992).",0,original
"Correspondences between MALTUS and other tagsets (Klein and Soria, 1998) were also provided (Popescu-Belis, 2003).",0,original
"1 Introduction Sentiment analysis of text documents has received considerable attention recently (Shanahan et al. , 2005; Turney, 2002; Dave et al. , 2003; Hu and Liu, 2004; Chaovalit and Zhou, 2005).",0,original
"We report BLEU scores (Papineni et al., 2002) on untokenized, recapitalized output.",0,original
First as the configuration space we can use only the reference nodes (w) from the lattice which makes it similar to the method of Berger et al. 1996 described in section 2.1.,0,original
"The disambiguation model of this parser is based on a maximum entropy model (Berger et al. , 1996).",0,original
"As, from a linguistic perspective, it is the modifier 2We use a mechanism similar to (Collins, 1997) but adapted to Chinese data to find lexical heads in the treebank data.",0,original
"In batch mode, OpinionFinder parses the data again, this time to obtain constituency parse trees (Collins, 1997), which are then converted to dependency parse trees (Xia and Palmer, 2001).",0,original
 A natural fit to the existing statistical machine translation framework  A metric that ranks a good translation high in an nbest list could be easily integrated in a minimal error rate statistical machine translation training framework (Och 2003).,0,original
"The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar: it has a start symbol S, a single preterminal C, and two intermediate nonterminals A and B used to ensure that only one parse can generate any given word-level alignment, as discussed by Wu (1997) and Zens and Ney (2003).",0,original
"(2004) In this example, we can see that after compression the lead sentence reads 156 more like a headline.",0,original
"Suhm and Waibel (1994) and Eckert, Gallwitz, and Niemann (1996) each condition a recognizer LM on left-to-right DA predictions and are able to 366 Stolcke et al. Dialogue Act Modeling show reductions in word error rate of 1% on task-oriented corpora.",0,original
"An analysis of the alignments shows that smoothing the fertility probabilities significantly reduces the frequently occurring problem of rare words forming garbage collectors in that they tend to align with too many words in the other language (Brown, Della Pietra, Della Pietra, Goldsmith, et al. 1993).",0,original
"ROUGE-N (Lin, 2004) This measure compares n-grams of two summaries, and counts the number of matches.",0,original
"Pure statistical machine translation (Brown et al. , 1993) mltst in principle recover the most probable alignment out of all possible alignments between the input and a translation.",0,original
"The model parameters are trained using minimum error-rate training (Och, 2003).",0,original
"Consider the following example (Pang et al. , 2002): This film should be brilliant.",0,original
"4), it constitutes a bijection between source and target sentence positions, since the intersecting alignments are functions according to their definition in (Brown et al. , 1993) 3.",0,original
"(Och et al., 1999; Koehn et al., 2003; Liang et al., 2006).",0,original
"Note that it is straightforward to calculate these expected counts using a variant of the inside-outside algorithm (Baker, 1979) applied to the (Eisner, 1996) dependency-parsing data structures (Paskin, 2001) for projective dependency structures, or the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for nonprojective dependency structures.",0,original
"lscript1-regularized log-linear models (lscript1-LLMs), on the other hand, provide sparse solutions, in which weights of irrelevant features are exactly zero, by assumingaLaplacianpriorontheweights(Tibshirani, 1996; Kazama and Tsujii, 2003; Goodman, 2004; Gao et al., 2007).",0,original
Early work by Yarowsky (1995) falls within this framework.,0,original
"5 Related Research Ramshaw and Marcus (1995), Munoz et al.",0,original
"Finally, we are investigating several avenues for using this system output for Machine Translation (MT) including: (1) aiding word alignment for other MT system (Wang et al., 2007); and (2) aiding the creation various MT models involving analyzed text, e.g., (Gildea, 2004; Shen et al., 2008).",0,original
"An alternative to tercom, considered in this paper, is to use the Inversion Transduction Grammar (ITG) formalism (Wu, 1997) which allows one to view the problem of alignment as a problem of bilingual parsing.",0,original
"1 Introduction The Inversion Transduction Grammar or ITG formalism, which historically was developed in the context of translation and alignment, hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments (Wu, 1997).",0,original
"The relationship between Kneser-Ney smoothing to the Bayesian approach have been explored in (Goldwater et al., 2006; Teh, 2006) using Pitman-Yor processes.",0,original
"This paper continues a line of research on online discriminative training (Tillmann and Zhang, 2006; Liang et al., 2006; Arun and Koehn, 2007), extending that of Watanabe et al.",0,original
Pustejovsky confronted with the problem of automatic acquisition more extensively in \[Pustejovsky et al. 1993\].,0,original
"Performance is also measured by the BLEU score (Papineni et al. , 2002), which measures similarity to the reference translation taken from the English side of the parallel corpus.",0,original
"We then describe the two main paradigms for learning and inference, in this years shared task as well as in last years, which we call transition-based parsers (section 5.2) and graph-based parsers (section 5.3), adopting the terminology of McDonald and Nivre (2007).5 Finally, we give an overview of the domain adaptation methods that were used (section 5.4).",0,original
Based on the proofs in Collins (2002a) and Li et al.,0,original
"Unfortunately, as was shown by Fraser and Marcu (2007) AER can have weak correlation with translation performance as measured by BLEU score (Papineni et al., 2002), when the alignments are used to train a phrase-based translation system.",0,original
"While they train the parameters using a maximum a posteriori estimator, we extend the MERT algorithm (Och, 2003) to take the evaluation metric into account.",0,original
"One such approach is maximum entropy classification (Berger et al. , 1996), which we use in the form of a library implemented by Tsuruoka1 and used in his classifier-based parser (Tsuruoka and Tsujii, 2005).",0,original
"Much research has been carried out recently in this area (Hughes and Atwell 1994; Finch and Chater 1994; Redington, Chater, and Finch 1993; Brill et al. 1990; Kiss 1973; Pereira and Tishby 1992; Resnik 1993; Ney, Essen, and Kneser 1994; Matsukawa 1993).",0,original
"They are generated from the training corpus via the ?diag-and??method (Koehn et al. , 2003) and smoothed using Kneser-Ney smoothing (Foster et al. , 2006), ??one or several n-gram language model(s) trained with the SRILM toolkit (Stolcke, 2002); in the baseline experiments reported here, we used a trigram model, ??a distortion model which assigns a penalty based on the number of source words which are skipped when generating a new target phrase, ??a word penalty.",0,original
"Previous studies have shed light on the predictability of the next unix command that a user will enter (Motoda and Yoshida, 1997; Davison and Hirsch, 1998), the next keystrokes on a small input device such as a PDA (Darragh and Witten, 1992), and of the translation that a human translator will choose for a given foreign sentence (Nepveu et al. , 2004).",0,original
"(2002), Turney (2002), Dave et al.",0,original
"We also used the following resources: the Charniak parser (Charniak, 2000) to carry out the syntactic analysis; the wn::similaritypackage (Pedersen et al. , 2004) to compute the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) needed to implement the lexical similarity siml(T,H) as defined in (Corley and Mihalcea, 2005); SVM-lightTK (Moschitti, 2004) to encode the basic tree kernel function, KT, in SVM-light (Joachims, 1999).",0,original
"Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008).",0,original
"32-39 Proceedings of HLT-NAACL 2003 similar distribution patterns (Hindle, 1990; Peraira, et al. , 1993; Grefenstette, 1994).",0,original
"We then rank-order the P X|Y MI XY M Z Pr Z|Y MI ZY G092log [P X P Y P X P Y ] f Y [P XY P XY ] f XY [P XY P XY ] f XY M iG13X,X} jG13Y,Y} (f ij G09 ij ) 2 ij f XY G09 XY XY (1G09( XY /N)) f XY G09 XY f XY (1G09(f XY /N)) Table 1: Probabilistic Approaches METHOD FORMULA Frequency (Guiliano, 1964) f XY Pointwise Mutual Information (MI) (Fano, 1961; Church and Hanks, 1990) log (P / PP) 2XY XY Selectional Association (Resnik, 1996) Symmetric Conditional Probability (Ferreira and Pereira, 1999) P / PP XY X Y 2 Dice Formula (Dice, 1945) 2 f / (f +f ) XY X Y Log-likelihood (Dunning, 1993; (Daille, 1996).",0,original
"These estimates are usually heuristic and inconsistent (Koehn et al., 2003).",0,original
"3.2 Automatic ROUGE Evaluation ROUGE(Lin, 2004)measuresthen-grammatchbetween system generated summaries and human summaries.",0,original
"Manual processes, such as lexicon development could be automated in the future using standard contextbased, word distribution methods (Smadja, 1993), or other corpus-based techniques.",0,original
"Discriminative parsing has been investigated before, such as in Johnson (2001), Clark and Curran (2004), Henderson (2004), Koo and Collins (2005), Turian et al.",0,original
"Decomposing the translational equivalence relations in the training data into smaller units of knowledge can improve a models ability to generalize (Zhang et al. , 2006).",0,original
"Several representations to encode region information are proposed and examined (Ramshaw and Marcus, 1995; Uchimoto et al. , 2000; Kudo and Matsumoto, 2001).",0,original
"The training algorithm we used is the improved iterative scaling (IIS) described in (Berger et al, 1996)3.",0,original
"Finally, other approaches rely on reviews with numeric ratings from websites (Pang and Lee, 2002; Dave et al. , 2003; Pang and Lee, 2004; Cui et al. , 2006) and train (semi-)supervised learning algorithms to classify reviews as positive or negative, or in more fine-grained scales (Pang and Lee, 2005; Wilson et al. , 2006).",0,original
"(Downey et al., 2007) use HMM-based similarity for the same purpose.",0,original
"5 Related Work Automatically finding sentences with the same meaning has been extensively studied in the field of automatic paraphrasing using parallel corpora and corporawith multiple descriptionsof the same events (Barzilay and McKeown, 2001; Barzilay and Lee, 2003).",0,original
"1 Introduction Shallow parsing has received a reasonable amount of attention in the last few years (for example (Ramshaw and Marcus, 1995)).",0,original
"Many 649 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include Lee (1999), Curran (2003) and Weeds and Weir (2005).",0,original
"Setting the gradient to zero yields the usual maximum entropy constraints (Berger et al. , 1996), except that in this case the empirical values are themselves expectations (over all derivations leading to each gold standard dependency structure).",0,original
"5 Combining In-Domain and Out-of-Domain Data for Training In this section, we will first introduce the AUGMENT technique of Daume III (2007), before showing the performance of our WSD system with and without using this technique.",0,original
"1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews (Pang et al., 2002; Turney, 2002).",0,original
"Verbs and possible senses in our corpus Both corpora were lemmatized and part-of-speech (POS) tagged using Minipar (Lin, 1993) and Mxpost (Ratnaparkhi, 1996), respectivelly.",0,original
"AL has already been applied to several NLP tasks, such as document classification (Schohn and Cohn, 2000), POS tagging (Engelson and Dagan, 1996), chunking (Ngai and Yarowsky, 2000), statistical parsing (Thompson et al. , 1999; Hwa, 2000), and information extraction (Lewis and Catlett, 1994; Thompson et al. , 1999).",0,original
"The acquisition of clues is a key technology in these research efforts, as seen in learning methods for document-level SA (Hatzivassiloglou and McKeown, 1997; Turney, 2002) and for phraselevel SA (Wilson et al., 2005; Kanayama and Nasukawa, 2006).",0,original
"2.2 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics (Hindle 1990, Lin 1998).",0,original
"However, recent progress in machine translation and the continuous improvement on evaluation metrics such as BLEU (Papineni et al. , 2002) suggest that SMT systems are already very good at choosing correct word translations.",0,original
"A few researchers have focused on other aspects of summarization, including single sentence (Knight and Marcu, 2002), paragraph or short document (Daume III and Marcu, 2002), query-focused (Berger and Mittal, 2000), or speech (Hori et al. , 2003).",0,original
Carpuat and Wu (2007) approached the issue as a Word Sense Disambiguation problem.,0,original
"Here, it might be useful to relax the strict linear control regime by exploring beam search strategies, e.g. along the lines of Collins and Roark (2004).",0,original
"In order to generate a value for each target-side factor, we use a sequence of mapping steps similar to Koehn and Hoang (2007).",0,original
"These lists are rescored with the different models described above, a character penalty, and three different features based on IBM Models 1 and 2 (Brown et al. , 1993) calculated in both translation directions.",0,original
"(Cahill et al. , 2004b) provide four sets of annotation principles, one for non-coordinate configurations, one for coordinate configurations, one for traces (long distance dependencies) and a final catch all and clean up phase.",0,original
"5 Datasets For evaluation we selected two domain adaptation datasets: spam (Jiang and Zhai, 2007) and sentiment (Blitzer et al., 2007).",0,original
"The most common answer is component testing, where the component is compared against a standard of goodness, usually the Penn Treebank for English (Marcus et al. , 1993), allowing a numerical score of precision and recall (e.g. Collins, 1997).",0,original
"We discriminatively trained our parser in an on-line fashion using a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004; Crammer and Singer, 2003).",0,original
"WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997).",0,original
1 Church and Hanks (1990; Church et al. 1991) thus emphasize the importance of human judgment used in conjunction with these tools.,0,original
"Traditionally, maximum-likelihood estimation from relative frequencies is used to obtain conditional probabilities (Koehn et al. , 2003), eg, p(s|t) = c(s,t)/summationtexts c(s,t) (since the estimation problems for p(s|t) and p(t|s) are symmetrical, we will usually refer only to p(s|t) for brevity).",0,original
"3.1 Word Sequence Classification Similar to English text chunking (Ramshaw and Marcus, 1995; Lee and Wu, 2007), the word sequence classification model aims to classify each word via encoding its context features.",0,original
"When the data has distinct sub-structures, models that exploit hidden state variables are advantageous in learning (Matsuzaki et al. 2005; Petrov et al. 2007).",0,original
"Early examples of this work include (Alshawi, 1996; Wu, 1997); more recent models include (Yamada and Knight, 2001; Eisner, 2003; Melamed, 2004; Zhang and Gildea, 2005; Chiang, 2005; Quirk et al., 2005; Marcu et al., 2006; Zollmann and Venugopal, 2006; Nesson et al., 2006; Cherry, 2008; Mi et al., 2008; Shen et al., 2008).",0,original
"In Section 3, we will present a Perceptron like algorithm (Collins, 2002; Daume III and Marcu, 2005) to obtain the parameters.",0,original
"4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool (Och and Ney, 2003) and the grow-diag-final-and heuristics described in (Koehn et al., 2003) on 948,507 sentences of the French-English part of the Europarl corpus (Koehn, 2005) and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation.",0,original
"We adopted IOB (IOB2) labeling (Ramshaw and Marcus, 1995), where the rst word of an entity of class C is labeled B-C, the words in the entity are labeled I-C, and other words are labeled O.",0,original
"Shen et al., (2007) report an accuracy of 97.33% on the same data set using a perceptron-based bidirectional tagging model.",0,original
"Examples of this work include a system by Liu et al (1990), and experiments by Hindle and Rooth (1993), and Resnik and Hearst (1993).2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems.",0,original
"2 Related Work There has been extensive research in opinion mining at the document level, for example on product and movie reviews (Pang et al., 2002; Pang and Lee, 2004; Dave et al., 2003; Popescu and Etzioni, 2005).",0,original
"One option is what Johnson (2007) calls many-to-one (M-to-1) accuracy, in which each induced tag is labeled with its most frequent gold tag.",0,original
The algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm (Berger et al. 1996) to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs.,0,original
"Similarly, Kazama and Torisawa (2007) used Wikipedia, particularly the first sentence of each article, to create lists of entities.",0,original
"This paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs (Gallo et al. , 1993; Klein and Manning, 2001) (equivalently, and/or graphs or packed forests), which includes most parsers and parsing-based MT decoders.",0,original
"In this sense, instead of measuring only the categorial agreement between annotators with the kappa statistic (Carletta, 1996) or the performance of a system in terms of precision/recall, we could take into account the hierarchical organization of the categories or concepts by making use of measures considering the hierarchical distance between two concepts such as proposed by (Hahn and Schnattinger, 1998) or (Madche et al. , 2002).",0,original
Wu (1997) and Alshawi et al.,0,original
"On the other hand, other authors (e.g., (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2007)) do use the expression phrase-based models.",0,original
"For this present work, we use Dunnings log-likelihood ratio statistics (Dunning, 1993) defined as follows: sim = aloga+blogb+clogc+dlogd (a+b)log(a+b)(a+c)log(a+c) (b+d)log(b+d)(c+d)log(c+d) +(a+b+c+d)log(a+b+c+d) For each bilingual pattern EiJj, we compute its similarity score and qualify it as a bilingual sequence-to-sequence correspondence if no equally strong or stronger association for monolingual constituent is found.",0,original
"The Brill tagger comes with an English default version also trained on general-purpose language corpora like the PENN TREEBANK (Marcus et al. , 1993).",0,original
"This negation handling is similar to that used in (Das and Chen, 2001; Pang et al. , 2002).",0,original
"1313 E2C C2E Union Heuristic w/ Big 13.37 12.66 14.55 14.28 w/o Big 13.20 12.62 14.53 14.21 Table 3: BLEU-4 scores (test set) of systems based on GIZA++ word alignments 5 6 7 8  BLEU-4 14.27 14.42 14.43 14.45 14.55 Table 4: BLEU-4 scores (test set) of the union alignment, using TTS templates up to a certain size, in terms of the number of leaves in their LHSs 4.1 Baseline Systems GHKM (Galley et al., 2004) is used to generate the baseline TTS templates based on the word alignments computed using GIZA++ and different combination methods, including union and the diagonal growing heuristic (Koehn et al., 2003).",0,original
"Hidden Markov models (Rabiner, 1989) are one of the earliest structured learning algorithms, which have recently been followedbydiscriminativelearningapproachessuch as conditional random fields (CRFs) (Lafferty et al. , 2001; Sutton and McCallum, 2006), the structured perceptron (Collins, 2002) and its large-margin variants (Taskar et al. , 2003; Tsochantaridis et al. , 2004; McDonald et al. , 2005; Daume III et al. , 2006).",0,original
"Other scores for the word arc are set as in (Rosti et al., 2007).",0,original
"(Yamada and Knight, 2001) follow (Brown et al., 1993) in using the noisy channel model, by decomposing the translation decisions modeled by the translation model into different types, and inducing probability distributions via maximum likelihood estimation over each decision type.",0,original
"Related Work 2.1 Translation with Non-parallel Corpora A straightforward approach to word or phrase translation is to perform the task by using parallel bilingual corpora (e.g. , Brown et al, 1993).",0,original
"Some o1' l;his research has treated the sentenees as unstructured word sequences to be aligned; this work has primarily involved the acquisition of bilingual lexical correspondences (Chen, 1993), although there has also been a,n attempt to create a full MT system based on such trcat, ment (Brown et al. , 1993).",0,original
"In his analysis of Yarowsky (1995), Abney (2004) formulates several variants of bootstrapping.",0,original
"The loglinear model feature weights were learned using minimum error rate training (MERT) (Och, 2003) with BLEU score (Papineni et al., 2002) as the objective function.",0,original
"Och showed thatsystemperformanceisbestwhenparametersare optimizedusingthesameobjectivefunctionthatwill be used for evaluation; BLEU (Papineni et al. , 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al. , 2006).",0,original
"2 Literature Survey The task of sentiment analysis has evolved from document level analysis (e.g., (Turney., 2002); (Pang and Lee, 2004)) to sentence level analysis (e.g., (Hu and Liu., 2004); (Kim and Hovy., 2004); (Yu and Hatzivassiloglou, 2003)).",0,original
"3 Results and Analysis Hall (2007) shows that the oracle parsing accuracy of a k-best edge-factored MST parser is considerably higher than the one-best score of the same parser, even when k is small.",0,original
"so they conform to the Penn Treebank corpus (Marcus et al. , 1993) annotation style, and then do experiments using models built with Treebank data.",0,original
"Experimental results are reported in Table 2: here cased BLEU results are reported on MT03 Arabic-English test set (Papineni et al. , 2002).",0,original
"In (Matusov et al. , 2006), different word orderings are taken into account by training alignment models by considering all hypothesis pairs as a parallel corpus using GIZA++ (Och and Ney, 2003).",0,original
We also experimented with a method suggested by Brent (1993) which applies the binomial test on frame frequency data.,0,original
"1 Introduction Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach (Brown et al. , 1993).",0,original
"This can either be semi-supervised parsing, using both annotated and unannotated data (McClosky et al. , 2006) or unsupervised parsing, training entirely on unannotated text.",0,original
"3 Margin Perceptron Algorithm for Sequence Labeling Weextendedaperceptronwithamargin(Krauthand Mezard, 1987) to sequence labeling in this study, as Collins (2002a) extended the perceptron algorithm to sequence labeling.",0,original
"4.3 Corpora The evaluations of the different models were carried out on the Penn Wall Street Journal corpus (Marcus et al., 1993) for English, and the Tiger treebank (Brants et al., 2002) for German.",0,original
"In contrast, semi-supervised domain adaptation (Blitzer et al., 2006; McClosky et al., 2006; Dredze et al., 2007) is the scenario in which, in addition to the labeled source data, we only have unlabeled and no labeled target domain data.",0,original
"In fact, the largest source of English dependency trees is automatically generated from the Penn Treebank (Marcus et al. , 1993) and is by convention exclusively projective.",0,original
"The generator used in our experiments is an instance of the second type, using a probability model defined over Lexical Functional Grammar c-structure and f-structure annotations (Cahill and van Genabith, 2006; Hogan et al., 2007).",0,original
"Interestingly, the interannotator agreement on SWITCHBOARD (a0a2a1 a3a5a4a7a6a9a8a9a6 ) is higher than on the lecture corpus (0.372) and higher than the a0 -score reported by Galley (2006) for the ICSI meeting data used by Murray et al.",0,original
"Following Ponzetto and Strube (2006), we consider an anaphoric reference, NPi, correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition.",0,original
"With the availability of large natural language corpora annotated for syntactic structure, the treebanks, e.g., (Marcus et al. , 1993), automatic grammar extraction became possible (Chen and VijayShanker, 2000; Xia, 1999).",0,original
"Daume allows an extra degree of freedom among the features of his domains, implicitly creating a two-level feature hierarchy with one branch for general features, and another for domain specific ones, but does not extend his hierarchy further (Daume III, 2007)).",0,original
"2 Word Alignment Framework A statistical translation model (Brown et al. , 1993; Och and Ney, 2003) describes the relationship between a pair of sentences in the source and target languages (f = fJ1,e = eI1) using a translation probability P(f|e).",0,original
"Since Odds = P/(1  P), we multiply both sides of Definition 3 by (1P(U|E))1 to obtain, P(U|E) 1P(U|E) = P(E|U)P(U) P(E)(1P(U|E)) (7) By substituting Equation 6 in Equation 7 and later, applying the multiplication rule P(U|E)P(E) = P(E|U)P(U) to it, we will obtain: P(U|E) P(U|E) = P(E|U)P(U) P(E|U)P(U) (8) We proceed to take the log of the odds in Equation 8 (i.e. logit) to get: log P(E|U)P(E|U) = log P(U|E)P(U|E) log P(U)P(U) (9) While it is obvious that certain words tend to cooccur more frequently than others (i.e. idioms and collocations), such phenomena are largely arbitrary (Smadja, 1993).",0,original
"We implement this algorithm using the perceptron framework, as it can be easily modified for structured prediction while preserving convergence guarantees (Daume III and Marcu, 2005; Snyder and Barzilay, 2007).",0,original
"The phrases in the translations were located using standard phrase extraction techniques (Koehn et al., 2003).",0,original
"Berger et al. 1996 presented a way of computing conditional maximum entropy models directly by modifying equation 6 as follows (now instead of w we will explicitly use (x, y) ): i ~Cx~) = ~ f~(~, y) * ~(~, y) ~ ~ .~(~, y) * ~(~) * pCy I ~) = p(xk) (9) x6X yEY xEX yEY where ~(x, y) is an empirical probability of a joint configuration (w) of certain instantiated factor I variables with certain instantiated behavior variables.",0,original
"Hierarchical rules were extracted from a subset which has about 35M/41M words5, and the rest of the training data were used to extract phrasal rules as in (Och, 2003; Chiang, 2005).",0,original
"We trained the parser on the Penn Treebank (Marcus et al. , 1993).",0,original
"The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns (Church, 1988; Ramshaw and Marcus, 1995; Argamon et al. , 1998; Cardie and Pierce, 1998).",0,original
"A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al. , 2003; Zens and Ney, 2003; Tillman, 2004).",0,original
"It is based on Incremental Sigmoid Belief Networks (ISBNs), a class of directed graphical model for structure prediction problems recently proposed in (Titov and Henderson, 2007), where they were demonstrated to achieve competitive results on the constituent parsing task.",0,original
"The pchemtb-closed shared task (Marcus et al. , 1993; Johansson and Nugues, 2007; Kulick et al. , 2004) is used to illustrate our models.",0,original
"The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al. , 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances.",0,original
"\[Francis and Kucera, 1982; Marcus et al. , 1993\]), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy \[Weischedel et al. , 1993\].",0,original
"Many methods for calculating the similarity have been proposed (Niessen et al. , 2000; Akiba et al. , 2001; Papineni et al. , 2002; NIST, 2002; Leusch et al. , 2003; Turian et al. , 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gimenez et al. , 2005).",0,original
"Syntax based statistical MT approaches began with (Wu 1997), who introduced a polynomial-time solution for the alignment problem based on synchronous binary trees.",0,original
"There are however other similarity metrics (e.g. BLEU (Papineni et al., 2002)) which could be used equally well.",0,original
"ROUGE (Lin, 2004), a recall-oriented evaluation package for automatic summarization.",0,original
"Probabilistic generative models like IBM 1-5 (Brown et al., 1993), HMM (Vogel et al., 1996), ITG (Wu, 1997), and LEAF (Fraser and Marcu, 2007) define formulas for P(f | e) or P(e, f), with ok-voon ororok sprok at-voon bichat dat erok sprok izok hihok ghirok totat dat arrat vat hilat ok-drubel ok-voon anok plok sprok at-drubel at-voon pippat rrat dat ok-voon anok drok brok jok at-voon krat pippat sat lat wiwok farok izok stok totat jjat quat cat lalok sprok izok jok stok wat dat krat quat cat lalok farok ororok lalok sprok izok enemok wat jjat bichat wat dat vat eneat lalok brok anok plok nok iat lat pippat rrat nnat wiwok nok izok kantok ok-yurp totat nnat quat oloat at-yurp lalok mok nok yorok ghirok clok wat nnat gat mat bat hilat lalok nok crrrok hihok yorok zanzanok wat nnat arrat mat zanzanat lalok rarok nok izok hihok mok wat nnat forat arrat vat gat Figure 1: Word alignment exercise (Knight, 1997).",0,original
"In this paper, we implement the SDB model in a state-of-the-art phrase-based system which adapts a binary bracketing transduction grammar (BTG) (Wu, 1997) to phrase translation and reordering, described in (Xiong et al., 2006).",0,original
"In WASP, GIZA++ (Och and Ney, 2003) is used to obtain the best alignments from the training examples.",0,original
"A token can be a word or a punctuation symbol, and each of these neighboring tokens must be in the same sentence as a2 . We use a sentence segmentation program (Reynar and Ratnaparkhi, 1997) and a POS tagger (Ratnaparkhi, 1996) to segment the tokens surrounding a2 into sentences and assign POS tags to these tokens.",0,original
An alternative to linear models is the log-linear models suggested by Och (2003).,0,original
"There are many choices for modeling co-occurrence data (Brown et al. , 1992; Pereira et al. , 1993; Blei et al. , 2003).",0,original
"Furthermore, recent studies revealed that word clustering is useful for semi-supervised learning in NLP (Miller et al., 2004; Li and McCallum, 2005; Kazama and Torisawa, 2008; Koo et al., 2008).",0,original
"4.2 Word alignment We have used IBM models proposed by Brown (Brown et al. , 1993) for word aligning the parallel corpus.",0,original
"2 We illustrate the rule extraction with an example from the tree-to-tree translation model based on tree sequence alignment (Zhang et al, 2008a) without losing of generality to most syntactic tree based models.",0,original
"Beyond WordNet (Fellbaum, 1998), a wide range of resources has been developed and utilized, including extensions to WordNet (Moldovan and Rus, 2001; Snow et al., 2006) and resources based on automatic distributional similarity methods (Lin, 1998; Pantel and Lin, 2002).",0,original
"However, much recent work in machine learning and statistics has turned away from maximum-likelihood in favor of Bayesian methods, and there is increasing interest in Bayesian methods in computational linguistics as well (Finkel et al. , 2006).",0,original
"First, we trained a finitestate shallow parser on base phrases extracted from the Penn Wall St. Journal (WSJ) Treebank (Marcus et al. , 1993).",0,original
"The Xerox tagger (Cutting et al. 1992) comes with a set of rules that assign an unknown word a set of possible pos-tags (i.e. , POS-class) on the basis of its ending segment.",0,original
"In comparison, (Yarowsky, 1995) achieved 48 Table 1: A summary of the experimental results on four polysemous words.",0,original
"Training Set (Labeled English Reviews): There are many labeled English corpora available on the Web and we used the corpus constructed for multi-domain sentiment classification (Blitzer et al., 2007) 9 , because the corpus was large-scale and it was within similar domains as the test set.",0,original
"In our experiments, we used the full parse output from Collins parser (Collins, 1997), in which every non-terminal node is already annotated with head information.",0,original
"They are most commonly used for parsing and linguistic analysis (Charniak and Johnson, 2005; Collins, 2003), but are now commonly seen in applications like machine translation (Wu, 1997) and question answering (Wang et al., 2007).",0,original
"Furthermore, techniques such as iterative minimum errorrate training (Och et al., 2003) as well as web-based MT services require the decoder to translate a large number of source-language sentences per unit time.",0,original
"In our context, bootstrapping has a similar motivation to the annealing approach of Smith and Eisner (2006), which also tries to alter the space of hidden outputs in the E-step over time to facilitate learning in the M-step, though of course the use of bootstrapping in general is quite widespread (Yarowsky, 1995).",0,original
"Existing automatic evaluation measures such as BLEU (Papineni et al. , 2002) and ROUGE (Lin 2The collections are available from http://www.csail.",0,original
"One of the first large scale hand tagging efforts is reported in (Miller et al. , 1993), where a subset of the Brown corpus was tagged with WordNet July 2002, pp.",0,original
"More recently, Ramshaw & Marcus (In press) apply transformation-based learning (Brill, 1995) to the problem.",0,original
"Since manual word alignment is an ambiguous task, we also explicitly allow for ambiguous alignments, i.e. the links are marked as sure (S) or possible (P) (Och and Ney, 2003).",0,original
Our study is also different from these previous ones in that measuring the agreement among annotators became an issue (Carletta 1996).,0,original
"In our search procedure, we use a mixture-based alignment model that slightly differs from the model introduced as Model 2 in (Brown et al. , 1993).",0,original
"Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase (Magerman, 1995; Collins, 1996; Collins, 1997; Johnson, 1998; Charniak, 2000; Henderson, 2003; Klein and Manning, 2003; Matsuzaki et al. , 2005) (and others).",0,original
"By contrast, Liu and Gildea (2005) present three metrics that use syntactic and unlabelled dependency information.",0,original
"5 Evaluation 5.1 Datasets We used two datasets, customer reviews 1 (Hu and Liu, 2004) and movie reviews 2 (Pang and Lee, 2005) to evaluate sentiment classification of sentences.",0,original
"4 Experiments Our experiments were conducted on CoNLL-2007 shared task domain adaptation track (Nivre et al. , 2007) using treebanks (Marcus et al. , 1993; Johansson and Nugues, 2007; Kulick et al. , 2004).",0,original
"(2006) and Daume III (2007) (and see below for discussions), so in this paper we focus on the less studied, but equally important problem of annotationstyle adaptation.",0,original
"Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation (Hindle 1990; Dagan, Pereira, and Lee 1994) and to develop lexical resources from corpora (Lin 1998; Riloff and Jones 1999).",0,original
"Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)).",0,original
"Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007).",0,original
"The measures2  Mutual Information (a0a2a1 ) (Church and Hanks, 1989), the log-likelihood ratio test (Dunning, 1993), two statistical tests: t-test and a3a5a4 -test, and co-occurrence frequency  are applied to two sets of data: adjective-noun (AdjN) pairs and preposition-noun-verb (PNV) triples, where the AMs are applied to (PN,V) pairs.",0,original
"Inspired by (Cahill et al. , 2004)s methodology which was originally designed for English and Penn-II treebank, our approach to Chinese non-local dependency recovery is based on Lexical-Functional Grammar (LFG), a formalism that involves both phrase structure trees and predicate-argument structures.",0,original
"andw2 iscomputedusinganassociationscorebased on pointwise mutual information, asdefinedbyFano (1961) and used for a similar purpose in Church and Hanks (1990), as well as in many other studies in corpus linguistics.",0,original
"Given the parallel corpus, we tagged the English words with a publicly available maximum entropy tagger (Ratnaparkhi, 1996), and we used an implementation of the IBM translation model (AlOnaizan et al. , 1999) to align the words.",0,original
"(Suzuki et al. , 2006) 88.02 (+0.82) + unlabeled data (17M  27M words) 88.41 (+0.39) + supplied gazetters 88.90 (+0.49) + add dev.",0,original
"First, the graph-based models have better precision than the transition-based models when predicting long arcs, which is compatible with the results of McDonald and Nivre (2007).",0,original
"Such methods were presented in (Hoblm et al. , 1993) and ~flensky, 1978).",0,original
"4 Experiments 4.1 Experiment Settings A series of experiments were run to compare the performance of the three SWD models against the baseline, which is the standard phrase-based approach to SMT as elaborated in (Koehn et al., 2003).",0,original
"More recently, Clarke and Lapata (2007) use Centering Theory (Grosz et al., 1995) and Lexical Chains (Morris and Hirst, 1991) to identify which information to prune.",0,original
"For each training direction, we run GIZA++ (Och and Ney, 2003), specifying 5 iterations of Model 1, 4 iterations of the HMM model (Vogel et al. , 1996), and 4 iterations of Model 4.",0,original
"5 External Knowledge Sources 5.1 Lexical Dependencies Features derived from n-grams of words and tags in the immediate vicinity of the word being tagged have underpinned the world of POS tagging for many years (Kupiec, 1992; Merialdo, 1994; Ratnaparkhi, 1996), and have proven to be useful features in WSD (Yarowsky, 1993).",0,original
"This can be done in a supervised (Yarowsky, 1994), a semi-supervised (Yarowsky, 1995) or a fully unsupervised way (Pantel & Lin, 2002).",0,original
"Before training the classifiers, we perform feature ablation by imposing a count cutoff of 10, and by limiting the number of features to the top 75K features in terms of log likelihood ratio (Dunning 1993).",0,original
"For example, Church and Hanks (1990) describe the use of the mutual information index for this purpose (cf.",0,original
"1 Introduction A ""pain in the neck"" (Sag et al. , 2002) for NLP in languages of the Indo-Aryan family (e.g. Hindi-Urdu, Bangla and Kashmiri) is the fact that most verbs (nearly half of all instances in Hindi) occur as complex predicates multi-word complexes which function as a single verbal unit in terms of argument and event structure (Hook, 1993; Butt and Geuder, 2003; Raina and Mukerjee, 2005).",0,original
"Other authors have applied this approach to language modeling (Rosenfeld, 1996; Martin et al. , 1999; Peters and Klakow, 1999).",0,original
"summarization (Knight and Marcu, 2002), paraphrasing (Pang, Knight, and Marcu, 2003), natural language generation (Langkilde and Knight, 1998; Bangalore and Rambow, 2000; Corston-Oliver et al. , 2002), and language modeling (Baker, 1979; Lari and Young, 1990; Collins, 1997; Chelba and Jelinek, 2000; Charniak, 2001; Klein and Manning, 2003).",0,original
"This sort of problem can be solved in principle by conditional variants of the Expectation-Maximization algorithm (Baum et al. , 1970; Dempster et al. , 1977; Meng and Rubin, 1993; Jebara and Pentland, 1999).",0,original
"These constraints tie words in such a way that the space of alignments cannot be enumerated as in IBM models 1 and 2 (Brown et al. , 1993).",0,original
"The performance of cross-language information retrieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often (Buckley 1993).",0,original
"We briefly describe the tagger (see (Ciaramita & Altun, 2006) for more details), a Hidden Markov Model trained with the perceptron algorithm introduced in (Collins, 2002).",0,original
"2.2 The Crossing Constraint According to (Wu, 1997), crossing constraint can be defined in the following.",0,original
"Document level sentiment classification is mostly applied to reviews, where systems assign a positive or negative sentiment for a whole review document (Pang et al. , 2002; Turney, 2002).",0,original
"Moreover, the overall BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) scores, as well as numbers of exact string matches (as measured against to the original sentences in the CCGbank) are higher for the hypertagger-seeded realizer than for the preexisting realizer.",0,original
"4 Experiments and Results We use the standard corpus for this task, the Penn Treebank (Marcus et al. , 1993).",0,original
"Given the motivations for performing a linguistically-informedextraction whichwere also put forth, among others, by Church and Hanks(1990,25), Smadja(1993,151) and Heid (1994)  and given the recent developmentof linguisticanalysistools,itseemsplausiblethatthe linguisticstructurewill be more and more taken intoaccountbycollocationextractionsystems.",0,original
"The implementation of the algorithm is one that has a core of code that can run on either the Penn Treebank (Marcus et al. , 1993) or on the Chinese Treebank.",0,original
"This approach gave an improvement of 2.7 in BLEU (Papineni et al. , 2002) score on the IWSLT05 Japanese to English evaluation corpus (improving the score from 52.4 to 55.1).",0,original
"Intuitively, if we are able to find good correspondences through linking pivots, then the augmented source data should transfer better to a target domain (Blitzer et al., 2006).",0,original
"models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible (Berger et al. , 1996).",0,original
"The mutual information clustering algorithm(Brown et al. , 1992) were used for this.",0,original
"3 Synchronous Binarization Optimization by Cost Reduction As discussed in Section 1, binarizing an SCFG in a fixed (left-heavy) way (Zhang et al., 2006) may lead to a large number of competing edges and consequently high risk of making search errors.",0,original
"In this paper, we investigate the effectiveness of structural correspondence learning (SCL) (Blitzer et al. , 2006) in the domain adaptation task given by the CoNLL 2007.",0,original
"The likelihood ratio is obtained by treating word and Ic as a bigram and computed with the formula in (Dunning, 1993).",0,original
"Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.",0,original
"Because Daume III (2007) views the adaptation as merely augmenting the feature space, each of his features has the same prior mean and variance, regardless of whether it is domain specific or independent.",0,original
"4 Comparison to Related Work Previous work has compared generative and discriminative models having the same structure, such as the Naive Bayes and Logistic regression models (Ng and Jordan, 2002; Klein and Manning, 2002) and other models (Klein and Manning, 2002; Johnson, 2001).",0,original
"The progress in parsing technology are noteworthy, and in particular, various statistical dependency models have been proposed(Collins, 1997),, (Ratnaparkhi, 1997), (Charniak, 2000).",0,original
"2 Extracting paraphrases Much previous work on extracting paraphrases (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al. , 2003) has focused on finding identifying contexts within aligned monolingual sentences from which divergent text can be extracted, and treated as paraphrases.",0,original
"We used GIZA++ (Och and Ney, 2003) to align approximately 751,000 sentences from the German-English portion of the Europarl corpus (Koehn, 2005), in both the German-to-English and English-to-German directions.",0,original
"To deal with the difficulties in parse-to-parse matching, Wu (1997) utilizes inversion transduction grammar (ITG) for bilingual parsing.",0,original
"These tools are important in that the strongest collocational associations often represent different word senses, and thus 'they provide a powerful set of suggestions to the lexicographer for what needs to be accounted for in choosing a set of semantic tags' (Church and Hanks 1990, p. 28).",0,original
"Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic (Barzilay and Lee, 2003; Ibrahim et al., 2003).",0,original
There are several other approaches such as Ji and Ploux (2003) and the already mentioned Rapp (2002).,0,original
"6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006).",0,original
"It is worth noting, however, that even in Turney (2002) the choice of seed words is explicitly motivated by domain properties of movie reviews.",0,original
"Precursors to this work include (Pereira et al, 1993), (Brown et al. 1992), (Brill & Kapur, 1993), (Jelinek, 1990), and (Brill et al, 1990) and, as applied to child language acquisition, (Finch & Chater, 1992).",0,original
"We use a program to label syntactic arguments with the roles they are playing (Blaheta and Charniak, 2000), and the rules for complement/adjunct distinction given by (Collins, 1997) to never allow deletion of the complement.",0,original
"Construct a parse chart with a CKY parser simultaneously constrained on the foreign string and English tree, similar to the bilingual parsing of Wu (1997) 1.",0,original
"All topic models utilize Gibbs sampling for inference (Griffiths, 2002; Blei et al., 2004).",0,original
"In the BB.N model, as with Model 2 of (Collins, 1997), modifying nonterminals are generated conditioning both on the parent P and its head child H. Unlike Model 2 of (Collins, 1997), they are also generated conditioning on the previously generated modifying nonterminal, L/-1 or Pq-1, and there is no subcat frame or distance feature.",0,original
"6 The Experimental Results We used the Penn Treebank (Marcus et al. , 1993) to perform empirical experiments on this parsing model.",0,original
Our method was applied to 23 million words of the WSJ that were automatically tagged with Ratnaparkhi's maximum entropy tagger (Ratnaparkhi 1996) and chunked with the partial parser CASS (Abney 1996).,0,original
"(2006) propose a MaxEnt-based reordering model for BTG (Wu, 1997) while Setiawan et al.",0,original
"The named-entity features are generated by the freely available Stanford NER tagger (Finkel et al., 2005).",0,original
"These techniques included unweighted FS morphology, conditional random fields (Lafferty et al. , 2001), synchronous parsers (Wu, 1997; Melamed, 2003), lexicalized parsers (Eisner and Satta, 1999),22 partially supervised training `a la (Pereira and Schabes, 1992),23 and grammar induction (Klein and Manning, 2002).",0,original
"This can also be interpreted as a generalization of standard class-based models (Brown et al. , 1992).",0,original
"Daume III (Daume III, 2007) divided features into three classes: domainindependent features, source-domain features and target-domain features.",0,original
"This alignment system is powered by the IBM translation models (Brown et al. , 1993), in which one sentence generates the other.",0,original
Haghighi and Klein (2006) propose constraining the mapping from hidden states to POS tags so that at most one hidden state maps to any POS tag.,0,original
"Feature comparison measures: to convert two feature sets into a scalar value, several measures have been proposed, such as cosine, Lins measure (Lin, 1998), Kullback-Leibler (KL) divergence and its variants.",0,original
"determining document orientation (or polarity), as in deciding if a given Subjective text expresses a Positive or a Negative opinion on its subject matter (Pang and Lee, 2004; Turney, 2002); 3.",0,original
3.3 Grid Line Search Our implementation of a grid search is a modified version of that proposed in (Och 2003).,0,original
"The other main difference is the apparently nonlocal nature of the problem, which motivates our choice of a Maximum Entropy (ME) model for the tagging task (Berger et al. , 1996).",0,original
"The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003).",0,original
"The model consists of a set of word-pair parameters p(t\[s) and position parameters p(j\[i,/); in model 1 (IBM1) the latter are fixed at 1/(1 + 1), as each position, including the empty position 0, is considered equally likely to contain a translation for w. Maximum likelihood estimates for these parameters can be obtained with the EM algorithm over a bilingual training corpus, as described in (Brown et al. , 1993).",0,original
"As in (Collins, 1997), the parameter C8 D0 B4C4 CX B4D0D8 CX BND0DB CX B5CYC8BNC0BNDBBND8BNA1BNC4BVB5 is further smoothed as follows: C8 D0BD B4C4 CX CYC8BNC0BNDBBND8BNA1BNC4BVB5 A2 C8 D0BE B4D0D8 CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B5A2 C8 D0BF B4D0DB CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B4D0D8 CX B5B5 Note this smoothing is different from the syntactic counterpart.",0,original
"We use the distributed training and application infrastructure described in (Brants et al., 2007) with modifications to allow the training of predictive class-based models and their application in the decoder of the machine translation system.",0,original
"For example, incremental CFG parsing algorithms can be used with the CFGs produced by this transform, as can the Inside-Outside estimation algorithm (Lari and Young, 1990) and more exotic methods such as estimating adjoined hidden states (Matsuzaki et al. , 2005; Petrov et al. , 2006).",0,original
"(2005), Ponzetto and Strube (2006)) and the exploitation of advanced techniques that involve joint learning (e.g., Daume III and Marcu (2005)) and joint inference (e.g., Denis and Baldridge (2007)) for coreference resolution and a related extraction task.",0,original
"1 Introduction Summarizing spoken documents has been extensively studied over the past several years (Penn and Zhu, 2008; Maskey and Hirschberg, 2005; Murray et al., 2005; Christensen et al., 2004; Zechner, 2001).",0,original
"Transformation-based error-driven learning has been applied to a number of natural language problems, including part of speech tagging, prepositional phrase attachment disambiguation, speech generation and syntactic parsing \[Brill, 1992; Brill, 1994; Ramshaw and Marcus, 1994; Roche and Schabes, 1995; Brill and Resnik, 1994; Huang et al. , 1994; Brill, 1993a; Brill, 1993b\].",0,original
"2 Related Work This method is similar to block-orientation modeling (Tillmann and Zhang 2005) and maximum entropy based phrase reordering model (Xiong et al. 2006), in which local orientations (left/right) of phrase pairs (blocks) are learned via MaxEnt classifiers.",0,original
"For instance, word alignment models are often trained using the GIZA++ toolkit (Och and Ney, 2003); error minimizing training criteria such as the Minimum Error Rate Training (Och, 2003) are employed in order to learn feature function weights for log-linear models; and translation candidates are produced using phrase-based decoders (Koehn et al. , 2003) in combination with n-gram language models (Brants et al. , 2007).",0,original
"Among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation (Katz 1987; Jelinek 1989; Gale and Church 1990; Brown et al. 1992; Yang et al. 1996; Bai et al 1998; Zhou et al 1999; Rosenfeld 2000; Gao et al 2002).",0,original
"(ii) Apply some statistical tests such as the Binomial Hypothesis Test (Brent, 1993) and loglikelihood ratio score (Dunning, 1993) to SCCs to filter out false SCCs on the basis of their reliability and likelihood.",0,original
"There is evidence that this leads to better performance on some part-of-speech induction metrics (Johnson, 2007; Goldwater and Griffiths, 2007).",0,original
"As shown by McDonald and Nivre (2007), the Single Malt parser tends to suffer from two problems: error propagation due to the deterministic parsing strategy, typicallyaffectinglongdependenciesmorethan short ones, and low precision on dependencies originating in the artificial root node due to fragmented parses.9 The question is which of these problems is alleviatedbythemultipleviewsgivenbythecomponent parsers in the Blended system.",0,original
"In general the training set is the parsed Wall Street Journal (Marcus et al, 1993), with few exceptions, and the size of the training samples is around 10-20,000 test cases.",0,original
"#Reference: If our player 2, 3, 7 or 5 has the ball and the ball is close to our goal line  PHARAOH++: If player 3 has the ball is in 2 5 the ball is in the area near our goal line  WASP1++: If players 2, 3, 7 and 5 has the ball and the ball is near our goal line  Figure 4: Sample partial system output in the ROBOCUP domain ROBOCUP GEOQUERY BLEU NIST BLEU NIST PHARAOH 0.3247 5.0263 0.2070 3.1478 WASP1 0.4357 5.4486 0.4582 5.9900 PHARAOH++ 0.4336 5.9185 0.5354 6.3637 WASP1++ 0.6022 6.8976 0.5370 6.4808 Table 1: Results of automatic evaluation; bold type indicates the best performing system (or systems) for a given domain-metric pair (p < 0.05) 5.1 Automatic Evaluation Weperformed4runsof10-foldcrossvalidation,and measured the performance of the learned generators using the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002).",0,original
"The clusters were found automatically by attempting to minimize perplexity (Brown et al. , 1992).",0,original
"Indeed, as Sinopalnikova and Pavel (2004) note, Deese (1965) was the first to conduct linguistic analyses of word association norms, such as measurements of semantic similarity based on his convictions that similar words evoke similar word association responsesan approach that is somewhat reminiscent of Church and Hanks (1990) notion of mutual information.",0,original
"The Ino<lel 1) 3,,SI;e,l;ina (1.998) was {,rai\]md tm SemCor that was merged with a flfll senl;ential parse tree, the determination of which is considered a difficult l)rolflem of its own (Collins, 1997).",0,original
"(2002), Turney (2002), Dave et al.",0,original
"For example, consider a case of observation bias (Klein and Manning, 2002) for a first-order left-toright CMM.",0,original
"Wu (1997)s Inversion Transduction Grammar, as well as tree-transformation models of translation such as Yamada and Knight (2001), Galley et al.",0,original
"We prepare the corpus by passing it through Adwait Ratnaparkhis part-of-speech tagger (Ratnaparkhi, 1996) (trained on the Penn Treebank WSJ corpus) and then running Steve Abneys chunker (Abney, 1997) over the entire text.",0,original
"3.1 A simple solution Wu (1997) suggests that in order to have an ITG take advantage of a known partial structure, one can simply stop the parser from using any spans that would violate the structure.",0,original
"These include cube pruning (Chiang, 2007), cube growing (Huang and Chiang, 2007), early pruning (Moore and Quirk, 2007), closing spans (Roark and Hollingshead, 2008; Roark and Hollingshead, 2009), coarse-to-fine methods (Petrov et al., 2008), pervasive laziness (Pust and Knight, 2009), and many more.",0,original
"5.2.1 Generate English Annotated Corpus from Wikipedia Wikipedia provides a variety of data resources for NER and other NLP research (Richman and Schone, 2008).",0,original
"Previous research has focused on classifying subjective-versus-objective expressions (Wiebe et al., 2004), and also on accurate sentiment polarity assignment (Turney, 2002; Yi et al., 2003; Pang and Lee, 2004; Sindhwani and Melville, 2008; Melville et al., 2009).",0,original
"Each model can represent an important feature for the translation, such as phrase-based, language, or lexical models (Koehn et al., 2003).",0,original
"Given sentence-aligned bi-lingual training data, we first use GIZA++ (Och and Ney, 2003) to generate word level alignment.",0,original
"In (Hindle, 1990), a small set of sample results are presented.",0,original
"Smadja,Frank.(1993).",0,original
"Examples of such early work include (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005).",0,original
"Much of the recent work in word alignment has focussed on improving the word alignment quality through better modeling (Och and Ney, 2003; Deng and Byrne, 2005; Martin et al. , 2005) or alternative approaches to training (Fraser and Marcu, 2006b; Moore, 2005; Ittycheriah and Roukos, 2005).",0,original
"s e, the window to consider when extracting words related to word w, should span from postttuon w-5 to w+5 Maarek also defines the resolwng power of a parr m a document d as P = ~'Pd log Pc where Pd is the observed probabshty of appearance of the pan"" m document d, Pc the observed probabdny of the pmr recorpus, and -log Pc the quantity of mformauon assocmted to the pmr It Is easdy seen that p wall be h|gher, the higher the frequency of the pmr m the document and the lower sts frequency m the corpus, which agrees wlth the sdea presented at the begmnmg of this sectton Church and Hanks (1990) propose the apphcatlon of the concept of mutual mformatton e(x,y) ~,(x.y) = hog2 ecx)e(y) 51 to the retrieval, ro a corpus, of pairs of lextcally related words They alsoconslder a word span of :e5 words and observe that ""roterestrog"" pmr, s generally present a mutual mformatxon above 3 Salton and.Allan (1995) foc~as on paragraph level Each paragraph Is represented by a weighed vector, where each element is a term (typically.",0,original
"Finally, the parameters  i of the log-linear model (18) are learned by minimumerror-rate training (Och 2003), which tries to set the parameters so as to maximize the BLEU score (Papineni et al. 2002) of a development set.",0,original
"3 Incremental Parsing Method Based on Adjoining Operation In order to avoid the problem of infinite local ambiguity, the previous works have adopted the following approaches: (1) a beam search strategy (Collins and Roark, 2004; Roark, 2001; Roark, 2004), (2) limiting the allowable chains to those actually observed in the treebank (Collins and Roark, 2004), and (3) transforming the parse trees with a selective left-corner transformation (Johnson and Roark, 2000) before inducing the allowable chains and allowable triples (Collins and Roark, 2004).",0,original
"We symmetrized bidirectional alignments using the growdiag-final heuristic (Koehn et al. , 2003).",0,original
"1 To train their system, R&M used a 200k-word chunk of the Penn Treebank Parsed Wall Street Journal (Marcus et al. , 1993) tagged using a transformation-based tagger (Brill, 1995) and extracted base noun phrases from its parses by selecting noun phrases that contained no nested noun phrases and further processing the data with some heuristics (like treating the possessive marker as the first word of a new base noun phrase) to flatten the recursive structure of the parse.",0,original
As a basis mapping function  we used a generalisation of the one used by Grefenstette (1994) and Lin (1998).,0,original
"Previous research in this area includes several models which incorporate hidden variables (Matsuzaki et al., 2005; Koo and Collins, 2005; Petrov et al., 2006; Titov and Henderson, 2007).",0,original
"The final model V uses the weight vector w = summationtextk j=1(cjwj) Tn (Collins, 2002).",0,original
5 Effectiveness Comparison 5.1 English-Chinese ATIS Models Both the transfer and transducer systems were trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus (Hirschman et al. 1993).,0,original
"73 ment and phrase-extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003), a trigram language model with KneserNey smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data, and Moses (Koehn et al., 2007) to decode.",0,original
"1 Introduction Most recent approaches in SMT, eg (Koehn et al., 2003; Chiang, 2005), use a log-linear model to combine probabilistic features.",0,original
"2.2 Implementation of GIZA++ GIZA++ is an implementation of ML estimators for several statistical alignment models, including IBM Model 1 through 5 (Brown et al., 1993), HMM (Vogel et al., 1996) and Model 6 (Och and Ney, 2003).",0,original
"3 Analysis Results 3.1 Kappa Statistic Kappa coefficient (Carletta, 1996) is commonly used as a standard to reflect inter-annotator agreement.",0,original
"RIDF is like MI, but different References Church, K. and P. Hanks (1990)Word association norms, mutual information, and lexicography Computational Linguistics, 16:1, pp.",0,original
"Various machine learning strategies have been proposed to address this problem, including semi-supervised learning (Zhu, 2007), domain adaptation (Wu and Dietterich, 2004; Blitzer et al., 2006; Blitzer et al., 2007; Arnold et al., 2007; Chan and Ng, 2007; Daume, 2007; Jiang and Zhai, 2007; Reichart and Rappoport, 2007; Andreevskaia and Bergler, 2008), multi-task learning (Caruana, 1997; Reichart et al., 2008; Arnold et al., 2008), self-taught learning (Raina et al., 2007), etc. A commonality among these methods is that they all require the training data and test data to be in the same feature space.",0,original
"Inversion Transduction Grammar (ITG) is the model of Wu (1997), Tree-to-String is the model of Yamada and Knight (2001), and Tree-to-String, Clone allows the node cloning operation described above.",0,original
"Except where noted, each system was trained on 27 million words of newswire data, aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003).",0,original
"We thus introduce a multiplier  to form the actual objective function that we minimize with respect to :4 summationdisplay iL logp,i(yi ) +  Nsummationdisplay inegationslashL H(p,i) (4) One may regard  as a Lagrange multiplier that is used to constrain the classifiers uncertainty H to be low, as presented in the work on entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006).",0,original
"The intercoder reliability is a constant concern of everyone working with corpora to test linguistic hypotheses (Carletta, 1996), and the more so when one is coding for semanto-pragmatic interpretations, as in the case of the analysis of connectives.",0,original
"On the base of the chunk scheme proposed by Abney (1991) and the BIO tagging system proposed in Ramshaw and Marcus(1995), many machine learning techniques are used to deal with the problem.",0,original
"Previous work aligns a group of sentences into a compact word lattice (Barzilay and Lee, 2003), a finite state automaton representation that can be used to identify commonality or variability among comparable texts and generate paraphrases.",0,original
"4 Corpus Annotation For our corpus, we selected 1,000 sentences containing at least one comma from the Penn Treebank (Marcus et al., 1993) WSJ section 00, and manually annotated them with comma information3.",0,original
One such model is the IBM Model 1 (Brown et al. 1993).,0,original
"82 2 Aggregate Markov models In this section we consider how to construct classbased bigram models (Brown et al. , 1992).",0,original
The tag propagation/elimination scheme is adopted from [Yarowsky 1995].,0,original
"Concrete similarity measures compare a pair of weighted context feature vectors that characterize two words (Church and Hanks, 1990; Ruge, 1992; Pereira et al. , 1993; Grefenstette, 1994; Lee, 1997; Lin, 1998; Pantel and Lin, 2002; Weeds and Weir, 2003).",0,original
"More importantly, the ratio of binarizability, as expected, decreases on freer word-order languages (Wellington et al. , 2006).",0,original
"Also, we chose to average each individual perceptron (Collins, 2002) prior to Bayesian averaging.",0,original
"We perform named entity tagging using the Stanford four-class named entity tagger (Finkel et al., 2005).",0,original
"In that table, TBL stands for Brill's transformation-based error-driven tagget (Brill, 1995), ME stands for a tagger based on the maimum entropy modelling (Ratnaparkhi, 1996), SPATTER stands for a statistical parser based on decision trees (Magerman, 1996), IGTREE stands for the memory-based tagger by Daelemans et al.",0,original
"2 Previous Work It is helpful to compare this approach with recent efforts in statistical MT. Phrase-based models (Koehn et al. , 2003; Och and Ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order.",0,original
(2008a) propose a tree sequence-based tree to tree translation model and Zhang et al.,0,original
"With IOB2 representation (Ramshaw and Marcus, 1995), the problem of Chinese chunking can be regarded as a sequence labeling task.",0,original
"Pivots are features occurring frequently and behaving similarly in both domains (Blitzer et al., 2006).",0,original
"The learning algorithm used is the IB1 algorithm (Aha et al. , 1991) with k = 5, i.e. classification based on 5 nearest neighbors.4 Distances are measured using the modified value difference metric (MVDM) (Stanfill and Waltz, 1986; Cost and Salzberg, 1993) for instances with a frequency of at least 3 (and the simple overlap metric otherwise), and classification is based on distance weighted class voting with inverse distance weighting (Dudani, 1976).",0,original
"For example, in John saw Mary yesterday at the station, only John and Mary are required arguments while the other constituents are optional (adjuncts).3 The problem of SF identification using statistical methods has had a rich discussion in the literature (Ushioda et al. , 1993; Manning, 1993; Briscoe and Carroll, 1997; Brent, 1994) (also see the refences cited in (Sarkar and Zeman, 2000)).",0,original
"The alignment a J 1 that has the highest probability (under a certain model) is also called the Viterbi alignment (of that model): a J 1 = argmax a J 1 p   (f J 1, a J 1 | e I 1 ) (8) A detailed comparison of the quality of these Viterbi alignments for various statistical alignment models compared to human-made word alignments can be found in Och and Ney (2003).",0,original
"Most of the phrase-based translation models have adopted the noisy-channel based IBM style models (Brown et al. , 1993): CMCT C1 BD BP CPD6CVD1CPDC CT C1 BD C8D6B4CU C2 BD CYCT C1 BD B5C8D6B4CT C1 BD B5 (1) In these model, we have two types of knowledge: translation model, C8D6B4CU C2 BD CYCT C1 BD B5 and language model, C8D6B4CT C1 BD B5.",0,original
"1 Introduction A recent development in data-driven parsing is the use of discriminative training methods (Riezler et al. , 2002; Taskar et al. , 2004; Collins and Roark, 2004; Turian and Melamed, 2006).",0,original
"The upper envelope is a convex hull and can be inscribed with a convex polygon whose edges are the segments of a piecewise linear function in  (Papineni, 1999; Och, 2003): EnvD4fD5 AG max eC8C AWa D4e,fD5 A0  A4 bD4e,fD5 :  C8 RB4 (6) 726 Score  Error count  0 0 e1 e2 e5 e6 e8 e1e 2 e3 e4 e5e6e 7 e8 Figure 1: The upper envelope (bold, red curve) for a set of lines is the convex hull which consists of the topmost line segments.",0,original
"4 Semi-Supervised Training for Word Alignments Intuitively, in approximate EM training for Model 4 (Brown et al. , 1993), the E-step corresponds to calculating the probability of all alignments according to the current model estimate, while the M-step is the creation of a new model estimate given a probability distribution over alignments (calculated in the E-step).",0,original
"However, while discriminative models promise much, they have not been shown to deliver significant gains 1We class approaches using minimum error rate training (Och, 2003) frequency count based as these systems re-scale a handful of generative features estimated from frequency counts and do not support large sets of non-independent features.",0,original
"This paper extends the IBM Machine Translation Group's concept of fertility (Brown et al. , 1993) to the generation of clumps for natural language understanding.",0,original
"Monotone Nonmonotone Target B A Positions C D Source Positions Figure 1: Two Types of Alignment The IBM model 1 (IBM-1) (Brown et al. , 1993) assumes that all alignments have the same probability by using a uniform distribution: p(fJ1 |eI1) = 1IJ  Jproductdisplay j=1 Isummationdisplay i=1 p(fj|ei) (2) We use the IBM-1 to train the lexicon parameters p(f|e), the training software is GIZA++ (Och and Ney, 2003).",0,original
"Collins (2002b) gives convergence proofs for the methods; Collins (2002a) directly compares the boosting and perceptron approaches on a named entity task; and Collins and Duffy (2001, 2002) use a reranking approach with kernels, which allow representations of parse trees or labeled sequences in very-high-dimensional spaces.",0,original
"ROUGE-S ROUGE-S is an extension of ROUGE-2 defined as follows (Lin, 2004b): ROUGE-Sa59a61a146a31a62a98a147a49a65a68a67 a59a68a101a161a128a104a162 a2 a65a161a163 a157 a134a61a135a93a245a246 a2 a59a61a146a31a62a98a147a49a65a161a163 a145 a134a61a135a89a245a246 a2 a59a61a146a31a62a164a147a49a65 a157 a134a136a135a93a245a246 a2 a59a61a146a31a62a90a147a49a65a51a128a104a162 a2 a145 a134a61a135a89a245a246 a2 a59a61a146a31a62a98a147a49a65 (11) Where a166a168a169a78a170a248a247a250a249 a26 and a171a138a169a90a170a158a247a250a249 a26 are defined as follows: a251 a134a61a135a89a245a246 a2 a59a61a146a31a62a90a147a49a65a68a67 a252a248a253a85a254a255 a1 a59a61a146a31a62a90a147a49a65 # of skip bigram a2a23a147 (12) a3 a134a136a135a93a245a246 a2 a59a61a146a31a62a90a147a49a65a68a67 a252a83a253a118a254a255 a1 a59a61a146a31a62a90a147a49a65 # of skip bigram a2 a146 (13) Here, function Skip2 returns the number of skipbi-grams that are common to a141 and a139 . ROUGE-SU ROUGE-SU is an extension of ROUGE-S, which includes unigrams as a feature defined as follows (Lin, 2004b): ROUGE-SUa59a61a146a31a62a90a147a49a65a68a67 a59a68a101a161a128a49a162 a2 a65a117a163 a157 a134a5a4 a59a61a146a31a62a98a147a49a65a71a163 a145 a134a6a4 a59a61a146a31a62a98a147a49a65 a157 a134a5a4 a59a61a146a31a62a90a147a49a65a47a128a49a162 a2 a145 a134a5a4 a59a61a146a31a62a164a147a49a65 (14) Where a166 a169a8a7 and a171 a169a8a7 are defined as follows: a251 a134a5a4 a59a61a146a31a62a98a147a49a65a68a67 a252 a9 a59a61a146a31a62a90a147a49a65 (# of skip bigrams + # of unigrams) a2 a147 (15) a3 a134a5a4 a59a61a146a31a62a90a147a49a65a68a67 a252 a9 a59a61a146a31a62a90a147a49a65 (# of skip bigrams + # of unigrams) a2 a146 (16) Here, function SU returns the number of skip-bigrams and unigrams that are common to a141 and a139 . ROUGE-L ROUGE-L is an LCS-based evaluation measure defined as follows (Lin, 2004b): ROUGE-La59a61a146a31a62a90a147a49a65a68a67 a59a68a101a161a128a49a162 a2 a65a161a163 a157a11a10 a225a90a134 a59a61a146a31a62a90a147a49a65a161a163 a145a12a10 a225a90a134 a59a61a146a31a62a98a147a49a65 a157a11a10 a225a90a134 a59a61a146a31a62a90a147a49a65a47a128a49a162 a2 a145a12a10 a225a98a134 a59a61a146a31a62a90a147a49a65 (17) where a166a14a13a250a241a132a169 and a171a15a13a250a241a130a169 are defined as follows: a157a11a10 a225a98a134 a59a61a146a31a62a98a147a49a65a68a67 a101 a91 a16 a75 a77a29a216 LCSa17a244a59a61a156 a88 a62a90a146a21a65 (18) a145a18a10 a225a98a134 a59a61a146a31a62a98a147a49a65a68a67 a101 a95 a16 a75a78a77a83a216 LCSa17 a59a61a156a34a88a78a62a98a146a21a65 (19) Here, LCSa19a244a28a78a144a183a114a93a32a93a139a102a36 is the LCS score of the union longest common subsequence between reference sentences a144a25a114 and a139 . a115 and a122 are the number of words contained in a141, and a139, respectively.",0,original
"The model scaling factors M1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003).",0,original
Jing and McKeown (1999; 2000) found that human summarization can be traced back to six cut-andpaste operations of a text and proposed a revision method consisting of sentence reduction and combination modules with a sentence extraction part.,0,original
"(2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005).",0,original
"For each cell in the contingency table, the expected counts are: mi j = ni+n+ jn++ . The measures are calculated as (Pedersen, 1996): 2 = i;j (ni j mi j) 2 mi j LL = 2 i;j log2 n 2i j mi j Log-likelihood ratios (Dunning, 1993) are more appropriate for sparse data than chi-square.",0,original
"Proceedings of EACL '99 Determinants of Adjective-Noun Plausibility Maria Lapata and Scott McDonald and Frank Keller School of Cognitive Science Division of Informatics, University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW, UK {mlap, scottm, keller} @cogsci.ed.ac.uk Abstract This paper explores the determinants of adjective-noun plausibility by using correlation analysis to compare judgements elicited from human subjects with five corpus-based variables: co-occurrence frequency of the adjective-noun pair, noun frequency, conditional probability of the noun given the adjective, the log-likelihood ratio, and Resnik's (1993) selectional association measure.",0,original
"There has of course been a large amount of work on the more general problem of word-sense disambiguation, e.g., (Yarowsky 1995) (Kilgarriff and Edmonds 2002).",0,original
"The results so far mainly come from studies where a parser originally developed for English,such as the Collins parser (Collins 1997,1999), is applied to a new language,which often leads to a signicant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004).",0,original
(McArthur 1992; Mei et al. 1993) Classification allows a word to align with a target word using the collective translation tendency of words in the same class.,0,original
"Many traditional clustering techniques [Brown et al. , 1992] attempt to maximize the average mutual information of adjacent clusters  = 21, 2 12 2121 )( )|( log)(),( WW WP WWP WWPWWI, (2) where the same clusters are used for both predicted and conditional words.",0,original
"3.4) 3.1 Probabilistic model In the probabilistic formulation (Snow et al., 2006), the task of learning taxonomies from a corpus is seen as a probability maximization problem.",0,original
"The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 (Collins, 1997).",0,original
"Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. \[1993b, Equation 26\]).",0,original
"Inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (Mihalcea and Tarau, 2004), text summarization (Erkan and Radev, 2004; Mihalcea, 2004), word sense disambiguation (Mihalcea et al. , 2004; Mihalcea, 2005), sentiment analysis (Pang and Lee, 2004), and sentence retrieval for question answering (Otterbacher et al. , 2005).",0,original
"The  statistic (Carletta, 1996) is recast as: (fs,w)(sys,sys) = agr(fs,w)(sys,sys) P agr(fs,)(sys,sys) N  P agr(fs,)(sys,sys) N In this modified form, (fs,w) represents the divergence in relative agreement wrt f s for target noun w, relative to the mean relative agreement wrt f s over all words.",0,original
"3 Hebrew Simple NP Chunks The standard definition of English base-NPs is any noun phrase that does not contain another noun phrase, with possessives treated as a special case, viewing the possessive marker as the first word of a new base-NP (Ramshaw and Marcus, 1995).",0,original
"A path in a translation hypergraph induces a translation hypothesis E along with its sequence of SCFG rules D = r1,r2,,rK which, if applied to the start symbol, derives E. The sequence of SCFG rules induced by a path is also called a derivation tree for E. 3 Minimum Error Rate Training Given a set of source sentences FS1 with corresponding reference translations RS1, the objective of MERT is to find a parameter set M1 which minimizes an automated evaluation criterion under a linear model: M1 = argmin M1  SX s=1 Err`Rs, E(Fs; M1 ) ff E(Fs; M1 ) = argmax E  SX s=1 mhm(E, Fs) ff . In the context of statistical machine translation, the optimization procedure was first described in Och (2003) for N-best lists and later extended to phrase-lattices in Macherey et al.",0,original
3 Feature selection Berger et al (1996) proposed an iterative procedure of adding news features to feature set driven by data.,0,original
"Thus, we can compute the source dependency LM score in the same way we compute the target side score, using a procedure described in (Shen et al., 2008).",0,original
Results This algorithm was applied to a fragment of the Canadian Hansards that has been used in a number of other studies: Church (1993) and Simard et al (1992).,0,original
"For this paper, we use an exact inference (exhaustive search) CYK parser, using a simple probabilistic context-free grammar (PCFG) induced from the Penn WSJ Treebank (Marcus et al., 1993).",0,original
"Note that it is straightforward to calculate these expected counts using a variant of the inside-outside algorithm (Baker, 1979) applied to the (Eisner, 1996) dependency-parsing data structures (Paskin, 2001) for projective dependency structures, or the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for nonprojective dependency structures.",0,original
"The scores were then weighted by the inverse of their height in the tree and then summed together, similarly to the procedure in (Resnik, 1993).",0,original
"Our baseline is the phrase-based MT system of (Koehn et al. , 2003).",0,original
Turney (2002) and Wiebe (2000) focused on learning adjectives and adjectival phrases and Wiebe et al.,0,original
"Given that semantically similar words can be identified automatically on the basis of distributional properties and linguistic cues (Brown et al. , 1992; Pereira et al. , 1993; Hatzivassiloglou and McKeown, 1993), identifying the semantic orientation of words would allow a system to further refine the retrieved semantic similarity relationships, extracting antonyms.",0,original
"Specifically, three features are used to instantiate the templates:  POS tags on both sides: We assign POS tags using the MXPOST tagger (Ratnaparkhi, 1996) for English and Chinese, and Connexor for Spanish.",0,original
"For this study, the Levenshtein edit-distance score (where a perfect match scores zero) is  Roman Chinese (Pinyin) Alignment Score LEV ashburton ashenbodu |   a   s   h   b   u   r   t   o   n   | |   a   s   h   e   n   b  o  d    u   | 0.67 MLEV ashburton ashenbodu |  a   s   h       b   u   r    t   o   n  | |  a   s   h   e   n   b   o     d   u    | 0.72 MALINE asVburton aseCnpotu |   a   sV    b   <   u   r   t   o   |   n |   a   s   eC  n   p   o     t   u   |   0.48 3 normalized to a similarity score as in (Freeman et al. 2006), where the score ranges from 0 to 1, with 1 being a perfect match.",0,original
"To this end, the translational correspondence is described within a translation rule, i.e., (Galley et al. , 2004) (or a synchronous production), rather than a translational phrase pair; and the training data will be derivation forests, instead of the phrase-aligned bilingual corpus.",0,original
"2 Maximum Entropy In this bakeoff, our basic model is based on the framework described in the work of Ratnaparkhi (1996) which was applied for English POS tagging.",0,original
"The results evaluated by BLEU score (Papineni et al., 2002) is shown in Table 2.",0,original
"In this paper we will compare and evaluate several aspects of these techniques, focusing on Minimum Error Rate (MER) training (Och, 2003) and Minimum Bayes Risk (MBR) decision rules, within a novel training environment that isolates the impact of each component of these methods.",0,original
"While we can only compare class models with word models on the largest training set, for this training set model M outperforms the baseline Katzsmoothed word trigram model by 1.9% absolute.6 4 Domain Adaptation In this section, we introduce another heuristic for improving exponential models and show how this heuristic can be used to motivate a regularized version of minimum discrimination information (MDI) models (Della Pietra et al., 1992).",0,original
"Firstly, they classify all the GHKM2 rules (Galley et al., 2004; Galley et al., 2006) into two categories: lexical rules and non-lexical rules.",0,original
"For automatic evaluation, we employed BLEU (Papineni et al., 2002) by following (Unno et al., 2006).",0,original
"It is an implementation of Models 1-4 of Brown et al. \[1993\], where each of these models produces a Viterbi alignment.",0,original
"We proposed a Perceptron like learning algorithm (Collins and Roark, 2004; Daume III and Marcu, 2005) for guided learning.",0,original
"The feature templates in Ratnaparkhi (1996) that were left out were the ones that look at the previous word, the word two positions before the current, and the word two positions after the current.",0,original
"(Donaway et al. , 2000, Hirao et al. , 2005, Lin et al. , 2003, Lin, 2004, Hori et al. , 2003) and manual methods",0,original
"Recent computational work either focuses on sentence subjectivity (Wiebe et al. 2002; Riloff et al. 2003), concentrates just on explicit statements of evaluation, such as of films (Turney 2002; Pang et al. 2002), or focuses on just one aspect of opinion, e.g., (Hatzivassiloglou and McKeown 1997) on adjectives.",0,original
"Following (Ratnaparkhi, 1996; Collins, 2002; Toutanova et al. , 2003; Tsuruoka and Tsujii, 2005), 765 Feature Sets Templates Error% A Ratnaparkhis 3.05 B A + [t0,t1],[t0,t1,t1],[t0,t1,t2] 2.92 C B + [t0,t2],[t0,t2],[t0,t2,w0],[t0,t1,w0],[t0,t1,w0], [t0,t2,w0], [t0,t2,t1,w0],[t0,t1,t1,w0],[t0,t1,t2,w0] 2.84 D C + [t0,w1,w0],[t0,w1,w0] 2.78 E D + [t0,X = prefix or suffix of w0],4 < |X|  9 2.72 Table 2: Experiments on the development data with beam width of 3 we cut the PTB into the training, development and test sets as shown in Table 1.",0,original
"One of the theoretical problems with phrase based SMT models is that they can not effectively model the discontiguous translations and numerous attempts have been made on this issue (Simard et al., 2005; Quirk and Menezes, 2006; Wellington et al., 2006; Bod, 2007; Zhang et al., 2007).",0,original
"Finally, we use as a feature the mappings produced in (Navigli, 2006) of WordNet senses to Oxford English Dictionary senses.",0,original
"While Kazama and Torisawa used a chunker, we parsed the definition sentence using Minipar (Lin, 1998b).",0,original
Both Agichtein and Ganti (2004) and Canisius and Sporleder (2007) train a language model for each database column.,0,original
"Generally, WSD methods use the context of a word for its sense disambiguation, and the context information can come from either annotated/unannotated text or other knowledge resources, such as WordNet (Fellbaum, 1998), SemCor (SemCor, 2008), Open Mind Word Expert (Chklovski and Mihalcea, 2002), eXtended WordNet (Moldovan and Rus, 2001), Wikipedia (Mihalcea, 2007), parallel corpora (Ng, Wang, and Chan, 2003).",0,original
"Second, we will discuss the work done by (Barzilay & Lee, 2003) who use clustering of paraphrases to induce rewriting rules.",0,original
"We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in (Koehn et al. , 2003) to obtain a single many-to-many word alignment for each sentence pair.",0,original
"Amazon Reviews: The dataset contains product reviews taken from Amazon.com from 4 product types: Kitchen, Books, DVDs, and Electronics (Blitzer et al., 2007).",0,original
"SRILM (Stolcke, 2002) can produce classes to maximize the mutual information between the classes I(C(wt);C(wt 1)), as described in (Brown et al. , 1992).",0,original
"The third column reports the BLEU score (Papineni et al. , 2002) along with 95% confidence interval.",0,original
"Independently, in artificial intelligence an effort arose to encode large amounts of commonsense knowledge (Hayes, 1979; Hobbs and Moore, 1985; Hobbs et al. 1985).",0,original
"To generate the n-best lists, a phrase based SMT (Koehn et al., 2003) was used.",0,original
"See (Luo and Zitouni, 2005) and (Daume III and Marcu, 2005).",0,original
"A variety of other measures of semantic relatedness have been proposed, including distributional similarity measures based on co-occurrence in a body of text see (Weeds and Weir, 2005) for a survey.",0,original
"Here, we use the hidden Markov model (HMM) alignment model (Vogel, Ney, and Tillmann 1996) and Model 4 of Brown et al.",0,original
"Minimum error rate training (MERT) with respect to BLEU score was used to tune the decoders parameters, and performed using the technique proposed in (Och, 2003).",0,original
"(1993), sometimes augmented by an HMM-based model or Och and Neys Model 6 (Och and Ney, 2003).",0,original
"4.1 Training The training procedure is identical to the factored phrase-based training described in (Koehn and Hoang, 2007).",0,original
"Using the values computed above: p1 = k1n 1 p2 = k2n 2 p = k1+k2n 1+n2 Taking these probabilities to be binomially distributed, the log likelihood statistic (Dunning, 1993) is given by: 2 log = 2[log L(p1;k1;n1)+log L(p2;k2;n2) log L(p;k1;n2) log L(p;k2;n2)] where, log L(p;n;k)=k log p+(n k) log(1 p) According to this statistic, the greater the value of 2 log for a particular pair of observed frame and verb, the more likely that frame is to be valid SF of the verb.",0,original
"We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank (Marcus et al., 1993) and Prague Dependency Treebank (Hajic, 1998; Hajic et al., 2001) (see Sections 4.1 and 4.3).",0,original
Pang and Lee (2004) applied two different classifiers to perform sentiment annotation in two sequential steps: the first classifier separated subjective (sentiment-laden) texts from objective (neutral) ones and then they used the second classifier to classify the subjective texts into positive and negative.,0,original
"The f-structures are created automatically by annotating nodes in the gold standard WSJ trees with LFG functional equations and then passing these equations through a constraint solver (Cahill et al., 2004).",0,original
"Using these patterns, we introduced verb form errors into AQUAINT, then re-parsed the corpus (Collins, 1997), and compiled the changes in the disturbed trees into a catalog.",0,original
"For the log-linear model training, we take minimum-error-rate training method as described in (Och, 2003).",0,original
"Essentially, we follow Hobbs (1985) in using a rich ontology and a representation scheme that makes explicit all the individuals and abstract objects (i.e. , propositions, facts/beliefs, and eventualities) (Asher 1993) involved in the LF interpretation of an utterance.",0,original
"With hand-labeled data, {m} can be learnt via generalized iterative scaling algorithm (GIS) (Darroch and Ratcliff, 1972) or improved iterative scaling (IIS) (Berger 367 et al. , 1996).",0,original
The formally syntax-based model for SMT was first advocated by Wu (1997).,0,original
"Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003).",0,original
"6.3 Unsupervised sentiment classification Turney proposed the unsupervised method for sentiment classification (Turney, 2002), and similar method is utilized by many other researchers (Yu and Hatzivassiloglou, 2003).",0,original
"(Marcus, et al. 1993; Santorini 1990) The syntactic annotation task consists of marking constituent boundaries, inserting empty categories (traces of movement, PRO, pro), showing the relationships between constituents (argument/adjunct structures), and specifying a particular subset of adverbial roles.",0,original
"Many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms (Leacock et al. , 1998; Towel and Voorheest, 1998), weakly supervised learning algorithms (Dagan and Itai, 1994; Li and Li, 2004; Mihalcea, 2004; Niu et al. , 2005; Park et al. , 2000; Yarowsky, 1995), unsupervised learning algorithms (or word sense discrimination) (Pedersen and Bruce, 1997; Schutze, 1998), and knowledge based algorithms (Lesk, 1986; McCarthy et al. , 2004).",0,original
"To evaluate sentence automatically generated with taking consideration word concatenation into by using references varied among humans, various metrics using n-gram precision and word accuracy have been proposed: word string precision (Hori and Furui, 2000b) for summarization through word extraction, ROUGE (Lin and Hovy, 2003) for abstracts, and BLEU (Papineni et al. , 2002) for machine translation.",0,original
"Decoding Conditions For tuning of the decoder's parameters, minimum error training (Och 2003) with respect to the BLEU score using was conducted using the respective development corpus.",0,original
"This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries.",0,original
"One such technique is bootstrapping, which was recently presented in (Riloff and Jones 1999), (Jones et a1.1999) as an ideal framework for text learning tasks that have knowledge seeds.",0,original
"Any encoding scheme, such as the packed representation of Talbot and Brants (2008), is viable here.",0,original
"12 As such, we resort to an approximation: Voted Perceptron training (Collins, 2002).",0,original
"For our studies here, the parser employed was that of Collins (1997) applied to the sentences of the British National Corpus (BNC Consortium, 2001).",0,original
"However, at the short term, the incorporation of these type of features will force us to either build a new decoder or extend an existing one, or to move to a new MT architecture, for instance, in the fashion of the architectures suggested by Tillmann and Zhang (2006) or Liang et al.",0,original
"When different decoder settings are applied to the same model, MERT weights (Och, 2003) from the unprojected single pass setup are used and are kept constant across runs.",0,original
"Aside from purely linguistic interest, bracket structure has been empirically shown to be highly effective at constraining subsequent training of, for example, stochastic context-free grammars (Pereira & ~ 1992; Black et al. 1993).",0,original
"Given phrase p1 and its paraphrase p2, we compute Score3(p1,p2) by relative frequency (Koehn et al., 2003): Score3(p1,p2) = p(p2|p1) = count(p2,p1)P pprime count(pprime,p1) (7) People may wonder why we do not use the same method on the monolingual parallel and comparable corpora.",0,original
"The underlying formalisms used has been quite broad and include simple formalisms such as ITGs (Wu, 1997), hierarchicalsynchronousrules(Chiang, 2005), string to tree models by (Galley et al., 2004) and (Galley et al., 2006), synchronous CFG models such (Xia and McCord, 2004) (Yamada and Knight, 2001), synchronous Lexical Functional Grammar inspired approaches (Probst et al., 2002) and others.",0,original
"The relationship between the translation model and the alignment model is given by: Pr(fJ1 jeI1) = X aJ1 Pr(fJ1 ;aJ1jeI1) (3) In this paper, we use the models IBM-1, IBM4 from (Brown et al. , 1993) and the HiddenMarkovalignmentmodel(HMM)from(Vogelet al. , 1996).",0,original
"The need for some way to model aspects of syntactic behavior, such as the tendency of constituents to move together as a unit, is widely recognizedthe role of syntactic units is well attested in recent systematic studies of translation (Fox, 2002; Hwa et al. , 2002; Koehn and Knight, 2003), and their absence in phrase-based models is quite evident when looking at MT system output.",0,original
"The supervised methods are based on Maximum Entropy (ME) (Lau et al. , 1993; Berger et al. , 1996; Ratnaparkhi, 1998), neural network using the Learning Vector Quantization algorithm (Kohonen, 1995) and Specialized Hidden Markov Models (Pla, 2000).",0,original
"There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (Ge et al. , 1998), or contextual role-knowledge (Bean and Riloff, 2004).",0,original
(2004) and Barzilay and Lee (2003) used comparable news articles to obtain sentence level paraphrases.,0,original
"In this paper we present results on using a recent phrase-based SMT system, PHARAOH (Koehn et al. , 2003), for NLG.1 Although moderately effec1We also tried IBM Model 4/REWRITE (Germann, 2003), a word-based SMT system, but it gave much worse results.",0,original
"We preferred the log-likelihood ratio to other statistical scores, such as the association ratio (Church and Hanks, 1990) or ;(2, since it adequately takes into account the frequency of the co-occurring words and is less sensitive to rare events and corpussize (Dunning, 1993; Daille, 1996).",0,original
"(Pedersen et al. , 1996) and (Zipf, 1935)).",0,original
"The translation table is obtained as described in (Koehn et al. , 2003), i.e. the alignment tool GIZA++ is run over the training data in both translation directions, and the two alignTest Setting BLEU B1 standard phrase-based SMT 29.22 B2 (B1) + clause splitting 29.13 Table 2: Experiment Baseline Test Setting BLEU BLEU 2-ary 2,3-ary 1 rule 29.77 30.31 2 ME (phrase label) 29.93 30.49 3 ME (left,right) 30.10 30.53 4 ME ((3)+head) 30.24 30.71 5 ME ((3)+phrase label) 30.12 30.30 6 ME ((4)+context) 30.24 30.76 Table 3: Tests on Various Reordering Models The 3rd column comprises the BLEU scores obtained by reordering binary nodes only, the 4th column the scores by reordering both binary and 3-ary nodes.",0,original
"Probability Based Commensurability Charniak and Goldman (1988) started out with a model very similar to Hobbs et al. , but became concerned with 227 the lack of theoretical grounding for Ihe number, in rules, much as we we.re.",0,original
"3 Surface Realisation from f-Structures Cahill and van Genabith (2006) present a probabilistic surface generation model for LFG (Kaplan, 1995).",0,original
"The tags sets we shall examine are the set used in the Penn Tree Bank (PTB) (Marcus et al. , 1993) and the C5 tag-set used by the CLAWS part-of-speech tagger (Garside, 1996).",0,original
"Then, h(s)  h(s) + Lmax, s  S. This epsilon1-admissible heuristic (Ghallab and Allard, 1982) bounds our search error by Lmax.3 3 Bitext Parsing In bitext parsing, one jointly infers a synchronous phrase structure tree over a sentence ws and its translation wt (Melamed et al. , 2004; Wu, 1997).",0,original
"This statistic is given by -2 log A = 2(log L(p1, kl, hi) log L(p2, k2, n2)-log L(p, kl, R1)--log L(p, k2, n2)), where log LCo, k, n) = k logp + (n k)log(1 -p), and Pl = ~, P2 = ~, P =,~',~; (For a detailed description of the statistic used, see (Dunning, 1993)).",0,original
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 45 50 55 60 65 70 75 80 85Correlation Coefficient with Human Judgement (R) Human-Likeness Classifier Accuracy (%) Figure 1: This scatter plot compares classifiers accuracy with their corresponding metrics correlations with human assessments been previously observed by Liu and Gildea (2005).,0,original
"Supervision for simple features has been explored in the literature (Raghavan et al., 2006; Druck et al., 2008; Haghighi and Klein, 2006).",0,original
"In their presentation of the factored SMT models, Koehn and Hoang (2007) describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags.",0,original
"To determine headwords of the semantic roles, the corpus was parsed using the Collins (1997) parser.",0,original
Word association norms based on co-occurrence information have been proposed by (Church and Hanks 1990).,0,original
"Since this transform takes a probabilistic grammar as input, it can also easily accommodate horizontal and vertical Markovisation (annotating grammar symbols with parent and sibling categories) as described by Collins (1997) and subsequently.",0,original
"This is applied to maximize coverage, which is similar as the final in (Koehn et al., 2003).",0,original
"PMI (Church and Hanks, 1990) between two phrases is de ned as: log2 prob(ph1 is near ph2)prob(ph 1)  prob(ph2) PMI is positive when two phrases tend to co-occur and negative when they tend to be in a complementary distribution.",0,original
"At one extreme are those, exemplified by that of Wu (1997), that have no dependence on syntactic theory beyond the idea that natural language is hierarchical.",0,original
"Conditional probability, the log-likelihood ratio, and Resnik's (1993) selectional association measure were also significantly correlated with plausibility ratings.",0,original
"Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function.",0,original
"Following this idea, there have been introduced a parameter estimation approach for non-generative approaches that can effectively incorporate unlabeled data (Suzuki et al., 2007).",0,original
"Once we obtain the augmented phrase table, we should run the minimum-error-rate training (Och, 2003) with the augmented phrase table such that the model parameters are properly adjusted.",0,original
"The modifications are made to deal with the efficiency issue due to the fact that there is a very large number of features and training samples in our task, compared to only 8 features used in (Och 2003).",0,original
MSR thus adopts the method proposed by Och (2003).,0,original
"Heuristic approaches obtain word alignments by using various similarity functions between the types of the two languages (Smadja et al. , 1996; Ker and Chang, 1997; Melamed, 2000).",0,original
Okanohara and Tsujii (2007) generate ill-formed sentences by sampling a probabilistic language model and end up with pseudo-negative examples which resemble machine translation output more than they do learner texts.,0,original
"Though several algorithms (Brown et al. , 1992; Pereira, Tishby, and Lee, 1993) have been proposed 100( 9o( 80( 4O( 20( 1000 goo 80~ 41111 2@ 5 10 15 20 25 30 5 10 15 20 25 30 iteration of EM iteration of EM (a) (b) Figure 1: Plots of (a) training and (b) test perplexity versus number of iterations of the EM algorithm, for the aggregate Markov model with C = 32 classes.",0,original
"(Collins parser (Collins, 1997) always predicts a flat NP for such configurations).",0,original
"One of our goals was to use for our study only information that could be annotated reliably (Passonneau and Litman, 1993; Carletta, 1996), as we believe this will make our results easier to replicate.",0,original
Cahill and van Genabith (2006) note that conditioning f-structure annotated generation rules on local features (Eqn.,0,original
"h1(eI1,fJ1 ) = log Kproductdisplay k=1 N(z)(T(z), Tk) N(T(z)) h2(eI1,fJ1 ) = log Kproductdisplay k=1 N(z)(T(z), Tk) N(S(z)) h3(eI1,fJ1 ) = log Kproductdisplay k=1 lex(T(z)|S(z))(T(z), Tk) h4(eI1,fJ1 ) = log Kproductdisplay k=1 lex(S(z)|T(z))(T(z), Tk) h5(eI1,fJ1 ) = K h6(eI1,fJ1 ) = log Iproductdisplay i=1 p(ei|ei2,ei1) h7(eI1,fJ1 ) = I 4When computing lexical weighting features (Koehn et al. , 2003), we take only terminals into account.",0,original
"The techniques used to solve this problem can be roughly classified into two main categories: those relying on pre-existing knowledge resources (thesauri, semantic networks, taxonomies or encyclopedias) (Alvarez and Lim, 2007; Yang and Powers, 2005; Hughes and Ramage, 2007) and those inducing distributional properties of words from corpora (Sahami and Heilman, 2006; Chen et al., 2006; Bollegala et al., 2007).",0,original
"(Collins 2002b) describes how the voted perceptron can be used to train maximum-entropy style taggers, and also gives a more thorough discussion of the theory behind the perceptron algorithm applied to ranking tasks.",0,original
See Collins (2002) for more details on this approach.,0,original
"Maximum Entropy models have been used to express the interactions among multiple feature variables (e.g. , (Berger et al. , 1996)), but within this framework no systematic study of interactions has been proposed.",0,original
Proposals have recently been made for protocols for the collection of human discourse segmentation data (Nakatani et al. 1995) and for how to evaluate the validity of judgments so obtained (Carletta 1996; Isard and Carletta 1995; Ros6 1995; Passonneau and Litman 1993; Litman and Passonneau 1995).,0,original
"2 Data 2.1 The US Congressional Speech Corpus The text used in the experiments is from the United States Congressional Speech corpus (Monroe et al. , 2006), which is an XML formatted version of the electronic United States Congressional Record from the Library of Congress1.",0,original
"One is distortion model (Och and Ney, 2004; Koehn et al. , 2003) which penalizes translations according to their jump distance instead of their content.",0,original
" The piecewise linearity observation made in (Papineni et al. , 2002) is no longer applicable since we cannot move the log operation into the expected value.",0,original
"They can be seen as extensions of the simpler IBM models 1 and 2 (Brown et al. , 1993).",0,original
"For instance, one might be interested in frequencies of co-occurences of a word with other words and phrases (collocations) (Smadja, 1993), or one might be interested in inducing wordclasses from the text by collecting frequencies of the left and right context words for a word in focus (Finch&Chater, 1993).",0,original
"It has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model training, can significantly improve word alignment F-measure and translation performance (Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006).",0,original
"The algorithm is slightly different from other online training algorithms (Tillmann and Zhang, 2006; Liang et al. , 2006) in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, i.e. BLEU (Papineni et al. , 2002).",0,original
"Intuitively, if we allow any Source words to be aligned to any Target words, the best alignment that we can come up with is the one in Figure 1.c. Sentence pair (S2, T2) offers strong evidence that b c in language S means the same thing as x in language T. On the basis of this evidence, we expect the system to also learn from sentence pair (S1, T1) that a in language S means the same thing as y in language T. Unfortunately, if one works with translation models that do not allow Target words to be aligned to more than one Source word  as it is the case in the IBM models (Brown et al. , 1993)  it is impossible to learn that the phrase b c in language S means the same thing as word x in language T. The IBM Model 4 (Brown et al. , 1993), for example, converges to the word alignments shown in Figure 1.b and learns the translation probabilities shown in Figure 1.a.2 Since in the IBM model one cannot link a Target word to more than a Source word, the training procedure 2To train the IBM-4 model, we used Giza (Al-Onaizan et al. , 1999).",0,original
"4.1.3 Alternative Paraphrasing Techniques To investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: Latent Semantic Analysis (LSA), and Brown clustering (Brown et al. , 1992).",0,original
"As Carletta (1996) notes, many tasks in computational linguistics are simply more difficult than the content analysis classifications addressed by Krippendorff, and according to Fleiss (1981), kappa values between .4 and .75 indicate fair to good agreement anyhow.",0,original
"There has been some previous work on accuracy-driven training techniques for SMT, such as MERT (Och, 2003) and the Simplex Armijo Downhill method (Zhao and Chen, 2009), which tune the parameters in a linear combination of various phrase scores according to a held-out tuning set.",0,original
"The straight-forward way is to first generate the best BTG tree for each sentence pair using the way of (Wu, 1997), then annotate each BTG node with linguistic elements by projecting source-side syntax tree to BTG tree, and finally extract rules from these annotated BTG trees.",0,original
"To avoid this problem we use the concept of class proposed for a word n-gram model (Brown et al. , 1992).",0,original
"METEOR uses the Porter stemmer and synonymmatching via WordNet to calculate recall and precision more accurately (Banerjee and Lavie, 2005).",0,original
"Standard MET (Och, 2003) iterative parameter estimation under IBM BLEU (Papineni et al., 2001) is performed on the corresponding development set.",0,original
"To avoid this problem, we sample from a space of probable alignments, as is done in IBM models 3 and above (Brown et al. , 1993), and weight counts based on the likelihood of each alignment sampled under the current probability model.",0,original
"The standard solution is to approximate the maximum probability translation using a single derivation (Koehn et al., 2003).",0,original
"Pooling the sets to form two large CE and AE test sets, the AE system improvements are significant at a 95% level (Och, 2003); the CE systems are only equivalent.",0,original
"Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (Pang et al. , 2002) or positive and negative words (Turney, 2002; Mullen and Collier, 2004); classifying sentences in a document as either subjective or objective (Riloff and Wiebe, 2003; Pang and Lee, 2004); identifying or classifying appraisal targets (Nigam and Hurst, 2004); identifying the source of an opinion in a text (Choi et al. , 2005), whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (Gamon et al. , 2005; Popescu and Etzioni, 2005).",0,original
Our approach is related to those of Collins and Roark (2004) and Taskar et al.,0,original
"The last row shows the results for the feature augmentation algorithm (Daume III, 2007).",0,original
"Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success.",0,original
"Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn  et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008).",0,original
"Following Lin (1998), we use syntactic dependencies between words to model their semantic properties.",0,original
"Of the several slightly different definitions of a base NP in the literature we use for the purposes of this work the definition presented in (Ramshaw and Marcus, 1995) and used also by (Argamon et al. , 1998)and others.",0,original
"Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)).",0,original
"3 The data 3.1 The supervised data For English, we use the same data division of Penn Treebank (PTB) parsed section (Marcus et al., 1994) as all of (Collins, 2002), (Toutanova et al., 2003), (Gimenez and M`arquez, 2004) and (Shen et al., 2007) do; for details, see Table 1.",0,original
"Our chunks and functions are based on the annotations in the third release of the Penn Treebank (Marcus et al. , 1993).",0,original
"1 Introduction Word compositions have long been a concern in lexicography(Benson et al. 1986; Miller et al. 1995), and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, e.g., parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etc.(e.g. , Abney 1989, 1990; Benson et al. 1986; Yarowsky 1995; Church and Hanks 1989; Church, Gale, Hans, and Hindle 1989).",0,original
"However, since we are interested in the word counts that correlate to w, we adopt the concept of the translation model proposed by Brown et al (1993).",0,original
"The experiment used all 578 sentences in the ATIS corpus with a parse tree, in the Penn Treebank (Marcus et al. 1993).",0,original
"By using 8-bit floating point quantization 1 , N-gram language models are compressed into 10 GB, which is comparable to a lossy representation (Talbot and Brants, 2008).",0,original
"The first one makes use of the advances in the parsing technology or on the availability of large parsed corpora (e.g. Trcebank (Marcus et al.1993)) to produce algorithms inspired by Hobbs' baseline method (Hobbs, 1978).",0,original
"where mk is one mention in entity e, and the basic model building block PL(L = 1je, mk, m) is an exponential or maximum entropy model (Berger et al. , 1996).",0,original
The prevalent use of this criterion despite repeated advice that it is unlikely to be suitable for all studies (Carletta 1996; Di Eugenio and Glass 2004; Krippendorff 2004a) is probably due to a desire for a simple system that can be easily applied to a scheme.,0,original
"157 ena or the linguist's abstraction capabilities (e.g. knowledge about what is relevant in the context), they tend to reach a 95-97% accuracy in the analysis of several languages, in particular English (Marshall 1983; Black et aL 1992; Church 1988; Cutting et al. 1992; de Marcken 1990; DeRose 1988; Hindle 1989; Merialdo 1994; Weischedel et al. 1993; Brill 1992; Samuelsson 1994; Eineborg and Gamb~ick 1994, etc.).",0,original
"For example, the sentence My father is *work in the laboratory is parsed (Collins, 1997) as: (S (NP My father) (VP is (NP work)) (PP in the laboratory)) 2The abbreviations s (is or has) and d (would or had) compound the ambiguities.",0,original
"For instance, the to-PP frame is poorly' represented in the syntactically annotated version of the Penn Treebank (Marcus et al. , 1993).",0,original
Some of the alignment sets also have links which are not Sure links but are Possible links (Och and Ney 2003).,0,original
"Because of its central role in building machine translation systems and because of the complexity of the task, sub-sentential alignment of parallel corpora continues to be an active area of research (e.g. , Moore et al. , 2006; Fraser and Marcu, 2006), and this implies a continuing demand for manually created or human-verified gold standard alignments for development and evaluation purposes.",0,original
"Our experience suggests that disjunctive LFs are an important capability, especially as one seeks to make grammars reusable across applications, and to employ domain-specific, sentence-level paraphrases (Barzilay and Lee, 2003).",0,original
"Instead of assigning HEAD and DEPREL in a single step, some systems use a two-stage approach for attaching and labeling dependencies (Chen et al. , 2007; Dredze et al. , 2007).",0,original
"1 Introduction Early works, (Gale and Church, 1993; Brown et al. , 1993), and to a certain extent (Kay and R6scheisen, 1993), presented methods to ex~.:'~.ct bi'_.'i~gua!",0,original
"Others proposed distributional similarity measures between words (Hindle, 1990; Lin, 1998; Lee, 1999; Weeds et al., 2004).",0,original
"The common types of features include contextual (Lin, 1998), co-occurrence (Yang and Callan, 2008), and syntactic dependency (Pantel and Lin, 2002; Pantel and Ravichandran, 2004).",0,original
"METRIC FORMULA Frequency (Guiliano, 1964) x yf Pointwise Mutual Information [PMI] (Church & Hanks, 1990) ( )xy x y2log /P P P True Mutual Information [TMI] (Manning, 1999) ( )xy 2 xy x ylog /P P P P Chi-Squared ( 2 ) (Church and Gale, 1991) { }{ },, 2( ) i X X Y Y i j i j i j j f     T-Score (Church & Hanks, 1990) 1 2 2 2 1 2 1 2 x x s s n n  + C-Values4 (Frantzi, Anadiou & Mima 2000) 2 is not nested 2 log ( ) log ( ) 1 ( ) ( ) a a b T a f f f b P T         where is the candidate string f( ) is its frequency in the corpus T is the set of candidate terms that contain P(T ) is the number of these candidate terms 609 1,700 of the three-word phrases are attested in the Lexile corpus.",0,original
"The third exploits automatic subjectivity analysis in applications such as review classification (e.g. , (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g. , (Yi et al. , 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g. , (Kim and Hovy, 2004)), information extraction (e.g. , (Riloff et al. , 2005)), 1Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation.",0,original
"A simpler, related idea of penalizing distortion from some ideal matching pattern can be found in the statistical translation (Brown et al. 1990; Brown et al. 1993) and word alignment (Dagan et al. 1993; Dagan & Church 1994) models.",0,original
This normal form allows simpler algorithm descriptions than the normal forms used by Wu (1997) and Melamed (2003).,0,original
"We use the Europarl corpus (Koehn, 2002), and the statistical word alignment was performed with the GIZA++ toolkit (Al-Onaizan et al. , 1999; Och and Ney, 2003).1 For the current experiments we assume no preexisting parser for any of the languages, contrary to the information projection scenario.",0,original
"In (Hindle,1990; Zernik, 1989; Webster el Marcus, 1989) cooccurrence analyses augmented with syntactic parsing is used for the purpose of word classification.",0,original
"6 Phrase Recognition with a Maximum Entropy Classifier For the candidates which are not filtered out in the above two phases, we perform classification with maximum entropy classifiers (Berger et al. , 1996).",0,original
"or cooking, which agrees with the knowledge presented in previous work (Ostler and Atkins, 1991).",0,original
"Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn  et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008).",0,original
"There are more sophisticated surface generation packages, such as FUF/SURGE (Elhadad and Robin, 1996), KPML (Bateman, 1996), MUMBLE (Meteer et al. , 1987), and RealPro (Lavoie and Rambow, 1997), which produce natural language text from an abstract semantic representation.",0,original
The other approach selected was Yarowsky's unsupervised algorithm (1995).,0,original
"For all performance metrics, we show the 70% confidence interval with respect to the MAP baseline computed using bootstrap resampling (Press et al. , 2002; Och, 2003).",0,original
"First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Och and Ney, 2004).",0,original
"In (Calzolari and Bindi, 1990), (Church and Hanks, 1990) the significance of an association (x,y) is measured by the mutual information I(x,y), i.e. the probability of observing x and y together, compared with the probability of observing x and y independently.",0,original
"One option would be to leverage unannotated text (McClosky et al., 2006; Smith and Eisner, 2007).",0,original
"of ACL 1990 (Smadja, 1993), F. Smadja, Retrieving collocations fi'cma text: XTRACT, (1993).",0,original
"Dependency models have recently gained considerable interest in many NLP applications, including machine translation (Ding and Palmer, 2005; Quirk et al., 2005; Shen et al., 2008).",0,original
"6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006).",0,original
"Bayesian approaches can also improve performance (Goldwater and Griffiths, 2007; Johnson, 2007; Kurihara and Sato, 2006).",0,original
"There are two tasks(Daume III, 2007) for the domain adaptation problem.",0,original
"Following initial work by (Sparck Jones, 1964) and (Grefenstette, 1994), an early, online distributional thesaurus presented in (Lin, 1998) has been widely used and cited, and numerous authors since have explored thesaurus properties and parameters: see survey component of (Weeds and Weir, 2005).",0,original
"With the exception of (Hindle and Rooth, 1993), most unsupervised work on PP attachment is based on superficial analysis of the unlabeled corpus without the use of partial parsing (Volk, 2001; Calvo et al. , 2005).",0,original
"by diag-and symmetrization (Koehn et al., 2003).",0,original
"The data was segmented into baseNP parts and nonbaseNP parts in a similar fashion as the data used by (Ramshaw and Marcus, 1995).",0,original
"At the end we ran our models once on TEST to get final numbers.2 4 Models Our experiments used phrase-based models (Koehn et al. , 2003), which require a translation table and language model for decoding and feature computation.",0,original
"80 8.0% Positive child education Positive cost Negative SUBJECT increase Figure 3: An example of a word-polarity lattice Various methods have already been proposed for sentiment polarity classification, ranging from the use of co-occurrence with typical positive and negative words (Turney, 2002) to bag of words (Pang et al., 2002) and dependency structure (Kudo and Matsumoto, 2004).",0,original
"To reduce it we exploit the one sense per collocation property (Yarowsky, 1995).",0,original
"N-grams have been used extensively for this purpose (Collins 1996, 1997; Eisner, 1996).",0,original
"The phrase translation table is learnt in the following manner: The parallel corpus is word-aligned bidirectionally, and using various heuristics (see (Koehn et al., 2003) for details) phrase correspondences are established.",0,original
"TB TBR JJ, JJR, JJS JJ RB,RBR,RBS RB CD, LS CD CC CC DT, WDT, PDT DT FW FW MD, VB, VBD, VBG, VBN, VBP, VBZ, VH, VHD, VHG, VHN, VHP, VHZ MD NN, NNS, NP, NPS NN PP, WP, PP$, WP$, EX, WRB PP IN, TO IN POS PO RP RP SYM SY UH UH VV, VVD, VVG, VVN, VVP, VVZ VB (Marcus et al. , 1993).",0,original
"Such linguistic-preprocessing techniques could 1Various models have been constructed by the IBM team (Brown et al. , 1993).",0,original
"5http://opennlp.sourceforge.net/ We use the standard four-reference NIST MTEval data sets for the years 2003, 2004 and 2005 (henceforth MT03, MT04 and MT05, respectively) for testing and the 2002 data set for tuning.6 BLEU4 (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and multiple-reference Word Error Rate scores are reported.",0,original
"(Wang and Hirschberg, 1992; Wightman and Ostendorf, 1994; Stolcke and Shriberg, 1996a; Kompe et al. , 1994; Mast et al. , 1996)) and on speech repair detection and correction (e.g.",0,original
"7 In the models described in Collins (1997), there was a third question concerning punctuation: (3) Does the string contain 0, 1, 2 or more than 2 commas?",0,original
"These domains have been commonly used in prior work on summarization (Weischedel et al., 2004; Zhou et al., 2004; Filatova and Prager, 2005; DemnerFushman and Lin, 2007; Biadsy et al., 2008).",0,original
"They constructed word clusters by using HMMs or Browns clustering algorithm (Brown et al., 1992), which utilize only information from neighboring words.",0,original
"3.5 The Experiments We have ran LexTract on the one-millionword English Penn Treebank (Marcus et al. , 1993) and got two Treebank grammars.",0,original
"The model presented above is based on our previous work (Jiang and Zhai, 2007c), which bears the same spirit of some other recent work on multitask learning (Ando and Zhang, 2005; Evgeniou and Pontil, 2004; Daume III, 2007).",0,original
"Also, the aspect of generalizing features across different products is closely related to fully supervised domain adaptation (Daume III, 2007), and we plan to combine our approach with the idea from Daume III (2007) to gain insights into whether the composite back-off features exhibit different behavior in domain-general versus domain-specific feature sub-spaces.",0,original
"In order to create the necessary SMT language and translation models, they used:  Giza++ (Och & Ney, 2003);2  the CMU-Cambridge statistical toolkit;3  the ISI ReWrite Decoder.4 Translation was performed from EnglishFrench and FrenchEnglish, and the resulting translations were evaluated using a range of automatic metrics: BLEU (Papineni et al. , 2002), Precision and Recall 2http://www.isi.edu/och/Giza++.html 3http://mi.eng.cam.ac.uk/prc14/toolkit.html 4http://www.isi.edu/licensed-sw/rewrite-decoder/ 185 (Turian et al. , 2003), and Wordand Sentence Error Rates.",0,original
"They have used the (Ramshaw and Marcus, 1995) representation as well (IOB1).",0,original
"We are currently investigating more challenging problems like multiple category classification using the Reuters-21578 data set (Lewis, 1992) and subjective sentiment classification (Turney, 2002).",0,original
"From this LFG annotated treebank, large-scale unification grammar resources were automatically extracted and used in parsing (Cahill and al., 2008) and generation (Cahill and van Genabith, 2006).",0,original
"(Charniak et al. , 1993)) simplify these probability distributions, as given in Equations 9 and 10.",0,original
"This is contrastive to the one dimensional models used by Collinss perceptronbased sequence method (Collins, 2002) which our algorithms are based upon, and by the linear-chain CRFs.",0,original
"We use the same set of binary features as in previous work on this dataset (Pang et al., 2002; Pang and Lee, 2004; Zaidan et al., 2007).",0,original
"Barzilay & Lee (2003) employ Multiple Sequence Alignment (MSA, e.g., Durbin et al. , 1998) to align strings extracted from closely related news articles.",0,original
"Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear modelparametersrelativetoameasureoftranslation quality.",0,original
"(General grammars with infinite numbers of nonterminals were studied by (Liang et al., 2007b)).",0,original
"These methods have reported performance in the range of 95-99% ""correct"" by word (DeRose 1988; Cutting et al. 1992; Jelinek, Mercer, and Roukos 1992; Kupiec 1992).",0,original
"This simplified version does not take word classes into account as described in (Brown et al. , 1993).",0,original
"The parser expresses distinctions that are especially important for a predicate-argument based deep syntactic representation, as far as they are expressed in the training data generated from the Penn Treebank (Marcus et al., 1993).",0,original
"(1) 1We follow the notations in (Brown et al. , 1993) for English-French, i.e., e  f, although our models are tested, in this paper, for English-Chinese.",0,original
"These methods often involve using a statistic such as 2 (Gale and Church, 1991) or the log likelihood ratio (Dunning, 1993) to create a score to measure the strength of correlation between source and target words.",0,original
"Examples are the Penn Treebank (Marcus et al. , 1993) for American English annotated at the University of Pennsylvania, the French treebank (Abeille and Clement, 1999) developed in Paris, the TIGER Corpus (Brants et al. , 2002) for German annotated at the Universities of Saarbrcurrency1ucken and This research was funded by a German Science Foundation grant (DFG SFB441-6).",0,original
"3 Previous Work on Subjectivity Tagging In previous work (Wiebe et al., 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus et al., 1993) was manually anno- tated with subjectivity classifications by multiple judges.",0,original
"(~ 1998 Association for Computational Linguistics Computational Linguistics Volume 24, Number 1 1995), (3) thesaurus categories (Yarowsky 1992; Chen and Chang 1994), (4) translation in another language (Gale, Church, and Yarowsky 1992; Dagan, Itai, and Schwall 1991; Dagan and Itai 1994), (5) automatically induced clusters with sublexical representation (Schiitze 1992), and (6) hand-crafted lexicons (McRoy 1992).",0,original
3.1 Background Smith and Eisner (2006) introduced the quasisynchronous grammar formalism.,0,original
"Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g. , Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994).",0,original
"We use BLEU scores (Papineni et al. , 2002) to measure translation accuracy.",0,original
"We obtained word alignments of training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diag-final-and (Koehn et al., 2003).",0,original
"Similarly, Murdock and Croft (2005) adopted a simple translation model from IBM model 1 (Brown et al. , 1990; Brown et al. , 1993) and applied it to QA.",0,original
"For example, in this work we use loglikelihood ratio (Dunning, 1993) to determine the SoA between a word sense and co-occurring words, and cosine to determine the distance between two DPWSs log likelihood vectors (McDonald, 2000).",0,original
"Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars (SCFG) (Wu, 1997) and synchronous treesubstitutiongrammars(STSG)(YamadaandKnight, 2001).",0,original
"Others, such as Turney (2002), Pang and Vaithyanathan (2002), have examined the positive or negative polarity, rather than presence or absence, of affective content in text.",0,original
"Most recently, Yarowsky used an unsupervised learning procedure to perform WSD (Yarowsky, 1995), although this is only tested on disambiguating words into binary, coarse sense distinction.",0,original
"Our evaluation metric is BLEU-4 (Papineni et al. , 2002), as calculated by the script mteval-v11b.pl with its default setting except that we used case-sensitive matching of n-grams.",0,original
"We set all weights by optimizing Bleu (Papineni et al., 2002) using minimum error rate training (MERT) (Och, 2003) on a separate development set of 2,000 sentences (Indonesian or Spanish), and we used them in a beam search decoder (Koehn et al., 2007) to translate 2,000 test sentences (Indonesian or Spanish) into English.",0,original
"When we trained external Chinese models, we used the same unlabeled data set as DeNero and Klein (2007), including the bilingual dictionary.",0,original
"The reliability of the annotations was checked using the kappa statistic (Carletta, 1996).",0,original
Kim and Hovy (2007) predict the results of an election by analyzing forums discussing the elections.,0,original
Paraphrases can also be automatically acquired using statistical methods as shown by Barzilay and Lee (2003).,0,original
"(Smith and Smith, 2007)).",0,original
"138 2 Rule Generation We start with phrase translations on the parallel training data using the techniques and implementation described in (Koehn et al. , 2003a).",0,original
"Language modeling (Chen and Goodman, 1996), noun-clustering (Ravichandran et al., 2005), constructing syntactic rules for SMT (Galley et al., 2004), and finding analogies (Turney, 2008) are examples of some of the problems where we need to compute relative frequencies.",0,original
"A related method is multi-category perceptron, which explicitly finds a weight vector that separates correct labels from the incorrect ones in a mistake driven fashion (Collins, 2002).",0,original
"Recently, methods for training binary classifiers to maximize the F 1 -score have been proposed for SVM (Joachims, 2005) and LRM (Jansche, 2005).",0,original
"We report that our parsing framework achieved high accuracy (88.6%) in dependency analysis of Japanese with a combination of an underspecified HPSG-based Japanese grammar, SLUNG (Mitsuishi et al. , 1998) and the maximum entropy method (Berger et al. , 1996).",0,original
"1 word w 2 word bigram w1w2 3 single-character word w 4 a word of length l with starting character c 5 a word of length l with ending character c 6 space-separated characters c1 and c2 7 character bigram c1c2 in any word 8 the first / last characters c1 / c2 of any word 9 word w immediately before character c 10 character c immediately before word w 11 the starting characters c1 and c2 of two consecutive words 12 the ending characters c1 and c2 of two consecutive words 13 a word of length l with previous word w 14 a word of length l with next word w Table 1: Feature templates for the baseline segmentor 2 The Baseline System We built a two-stage baseline system, using the perceptron segmentation model from our previous work (Zhang and Clark, 2007) and the perceptron POS tagging model from Collins (2002).",0,original
"(Koehn et al., 2003).",0,original
"The way a decoder constructs translation hypotheses is directly related to the weights for different model features in a SMT system, which are usually optimized for a given set of models with minimum error rate training (MERT) (Och, 2003) to achieve better translation performance.",0,original
"Our MT baseline system is based on Moses decoder (Koehn et al., 2007) with word alignment obtained from GIZA++ (Och et al., 2003).",0,original
"For the named entity features, we used a fairly standard feature set, similar to those described in (Finkel et al., 2005).",0,original
"For comparison, we use the MT training program, GIZA++ (Och and Ney, 2003), the phrase-base decoder, Pharaoh (Koehn et al. , 2003), and the wordbased decoder, Rewrite (Germann, 2003).",0,original
"Finally, we would like to investigate the incorporation of unsupervised methods for WSD, such as the heuristically-based methods of (Stetina and Nagao, 1997) and (Stetina et al. , 1998), and the theoretically purer bootstrapping method of (Yarowsky, 1995).",0,original
"Then the initial precision is 1(Yarowsky, 1995), citing (Yarowsky, 1994), actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting.",0,original
"4.3 Relaxing Length Restrictions Increasing the maximum phrase length in standard phrase-based translation does not improve BLEU (Koehn et al., 2003; Zens and Ney, 2007).",0,original
"In the SMT research community, the second step has been well studied and many methods have been proposed to speed up the decoding process, such as node-based or span-based beam search with different pruning strategies (Liu et al., 2006; Zhang et al., 2008a, 2008b) and cube pruning (Huang and Chiang, 2007; Mi et al., 2008).",0,original
"3 Implementation 3.1 Feature Structure To implement the twin model, we adopt the log linear or maximum entropy (MaxEnt) model (Berger et al. , 1996) for its flexibility of combining diverse sources of information.",0,original
"Giza++ is a freely available implementation of IBM Models 1-5 (Brown et al. 1993) and the HMM alignment (Vogel et al. 1996), along with various improvements and modifications motivated by experimentation by Och & Ney (2000).",0,original
"2 Related Work There has been extensive research in opinion mining at the document level, for example on product and movie reviews (Pang et al., 2002; Pang and Lee, 2004; Dave et al., 2003; Popescu and Etzioni, 2005).",0,original
"The syntactic parser is the version that is selftrained using 2,500,000 sentences from NANC, and where the starting version is trained only on WSJ data (McClosky et al. , 2006b).",0,original
"To search for the most probable parse, we use the heuristic search algorithm described in (Titov and Henderson, 2007b), which is a form of beam search.",0,original
"7 For the most frequent 184 expressions, on the average, the agreement rate between two human annotators is 0.93 and the Kappa value is 0.73, which means allowing tentative conclusions to be drawn (Carletta, 1996; Ng et al. , 1999).",0,original
"The Collins parser (Collins, 1997) does use dynamic programming in its search.",0,original
"1 Introduction Recent work in machine translation has evolved from the traditional word (Brown et al. , 1993) and phrase based (Koehn et al. , 2003a) models to include hierarchical phrase models (Chiang, 2005) and bilingual synchronous grammars (Melamed, 2004).",0,original
"Furthermore, our model is not necessarily nativist; these biases may be innate, but they may also be the product of some other earlier learning algorithm, as the results of Ellison (1992) and Brown et al.",0,original
"Prior to running the parsers, we trained the POS tagger described in (Collins, 2002).",0,original
"The decoding process is very similar to those described in (Koehn et al. , 2003): It starts from an initial empty hypothesis.",0,original
"GIZA++ (Och and Ney, 2003) and the heuristics grow-diag-final-and are used to generate m-ton word alignments.",0,original
"In previous work (Bean and Riloff, 1999), we developed an unsupervised learning algorithm that automatically recognizes definite NPs that are existential without syntactic modification because their meaning is universally understood.",0,original
"There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald.",0,original
"For example, the constrained optimization method of (Mozer et al. , 2001) relies on approximations of sensitivity (which they call CA) and specificity2 (their CR); related techniques (Gao et al. , 2006; Jansche, 2005) rely on approximations of true positives, false positives, and false negatives, and, indirectly, recall and precision.",0,original
"The results are consistent with the idea in (Gale and Church, 1994; Shfitze, 1992; Yarowsky, 1995).",0,original
A very impor232 Author Best Hindle and Rooth (1993) 80.0 % Resnik and Hearst (1993) 83.9 % WN Resnik and Hearst (1993) 75.0 % Ratnaparkhi et al.,0,original
"In our SRL system, we select maximum entropy (Berger et al. , 1996) as a classi er to implement the semantic role labeling system.",0,original
"The true segmentation can now be compared with the N-best list in order to train an averaged perceptron algorithm (Collins, 2002a).",0,original
"2.4 Maximum Entropy Classifier Maximum Entropy Models (Berger et al., 1996) seek to maximise the conditional probability of classes, given certain observations (features).",0,original
"On the other end of the spectrum, character-based bitext mapping algorithms (Church, 1993; Davis et al. , 1995) are limited to language pairs where cognates are common; in addition, they may easily be misled by superficial differences in formatting and page layout and must sacrifice precision to be computationally tractable.",0,original
"Recently several latent variable models for constituent parsing have been proposed (Koo and Collins, 2005; Matsuzaki et al. , 2005; Prescher, 2005; Riezler et al. , 2002).",0,original
"BLEU (Papineni et al, 2002) was devised to provide automatic evaluation of MT output.",0,original
"(Cahill et al., 2004) managed to extract LFG subcategorisation frames and paths linking long distance dependencies reentrancies from f-structures generated automatically for the PennII treebank trees and used them in an long distance dependency resolution algorithm to parse new text.",0,original
"The model weights are trained using the standard ranking perceptron (Collins, 2002).",0,original
"predict correctly the label of a test instance xN+1 is bounded by 2N+1EN+1bracketleftbigd+D bracketrightbig2 where D = D(w,,) = radicalBigsummationtext N i=12i . This result is used to explain the convergence of weighted or voted perceptron algorithms (Collins, 2002a).",0,original
"2.2 Weight optimization A common criterion to optimize the coefficients of the log-linear combination of feature functions is to maximize the BLEU score (Papineni et al. , 2002) on a development set (Och and Ney, 2002).",0,original
"The orientation model is related to the distortion model in (Brown et al. , 1993), but we do not compute a block alignment during training.",0,original
"Once an acceptable rate of interjudge agreement was verified on the first nine clusters (Kappa (Carletta, 1996) of 0.68), the remaining 11 clusters were annotated by one judge each.",0,original
"The final SMT system performance is evaluated on a uncased test set of 3071 sentences using the BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) scores.",0,original
"Supervised methods include hidden Markov model (HMM), maximum entropy, conditional random fields (CRF), and support vector machines (SVM) (Galley, 2006; Buist et al., 2005; Xie et al., 2008; Maskey and Hirschberg, 2006).",0,original
"Candidate term Segment result of GPWS for one sentence, in which term appears   / / / / /  /   / / / / / /  / /   / / / / / / /  / / / / / /   / / / / / / Table 2: Examples of candidates eliminated by GPWS 5 Relative frequency ratio against background corpus Relative frequency ratio (RFR) is a useful method to be used to discover characteristic linguistic phenomena of a corpus when compared with another (Damerau, 1993).",0,original
"For example, (Brown et al., 1993) suggested two different methods: using only the alignment with the maximum probability, the so-called Viterbi alignment, or generating a set of alignments by starting from the Viterbi alignment and making changes, which keep the alignment probability high.",0,original
"Taking SIGHAN Bakeoff 2006 (Levow, 2006) as an example, the recall is lower about 5% than the precision for each submitted system on MSRA and CityU closed track.",0,original
"1 minority report 2 box office 3 scooby doo 4 sixth sense 5 national guard 6 bourne identity 7 air national guard 8 united states 9 phantom menace 10 special effects 11 hotel room 12 comic book 13 blair witch project 14 short story 15 real life 16 jude law 17 iron giant 18 bin laden 19 black people 20 opening weekend 21 bad guy 22 country bears 23 mans man 24 long time 25 spoiler space 26 empire strikes back 27 top ten 28 politically correct 29 white people 30 tv show 31 bad guys 32 freddie prinze jr 33 monsters ball 34 good thing 35 evil minions 36 big screen 37 political correctness 38 martial arts 39 supreme court 40 beautiful mind Figure 7: Result of re-ranking output from the phrase extension module 6.4 Revisiting unigram informativeness An alternative approach to calculate informativeness from the foreground LM and the background LM is just to take the ratio of likelihood scores, a11 fga9a54a86 a15 a23 a11 bga9a54a86 a15 . This is a smoothed version of relative frequency ratio which is commonly used to find subject-specific terms (Damerau, 1993).",0,original
"This is possible because of the availability of statistical parsers, which can be trained on human-annotated treebanks (Marcus et al. , 1993; Xia et al. , 2000; Maamouri and Bies, 2004) for multiple languages; (2) The binding theory is used as a guideline and syntactic structures are encoded as features in a maximum entropy coreference system; (3) The syntactic features are evaluated on three languages: Arabic, Chinese and English (one goal is to see if features motivated by the English language can help coreference resolution in other languages).",0,original
"Following previous work in statistical MT (Brown et al., 1993), we envision a noisy-channel model in which a language model generates English, and then a translation model transforms English trees into Chinese.",0,original
"Dynamic programming is applied to bilingual sentence alignment in most of previous works (Brown et al. , 1991; Gate and Church, 1993; Chen, 1993).",0,original
"The first, Powells method, was advocated by Och (2003) when MERT was first introduced for statistical machine translation.",0,original
"Perhaps this was not observed earlier since (Ramshaw and Marcus, 1995) studied only base NPs, most of which are short.",0,original
"Words surrounding the current word have been occasionally used in taggers, such as (Ratnaparkhi, 1996), Brills transformation based tagger (Brill, 1995), and the HMM model of Lee et al.",0,original
"However, they use the (Ramshaw and Marcus, 1995) data set in a different training-test division (10-fold cross validation) which makes it (tifficult to compare their results with others.",0,original
"However, searching the space of all possible alignments is intractable for EM, so in practice the procedure is bootstrapped by models with narrower search space such as IBM Model 1 (Brown et al. , 1993) or Aachen HMM (Vogel et al. , 1996).",0,original
"F (Cahill et al. , 2004) overall 95.98 57.86 72.20 73.00 40.28 51.91 90.16 54.35 67.82 65.54 36.16 46.61 args only 98.64 42.03 58.94 82.69 30.54 44.60 86.36 36.80 51.61 66.08 24.40 35.64 Basic Model overall 92.44 91.28 91.85 63.87 62.15 63.00 63.12 62.33 62.72 42.69 41.54 42.10 args only 89.42 92.95 91.15 60.89 63.45 62.15 47.92 49.81 48.84 31.41 32.73 32.06 Basic Model with Subject Path Constraint overall 92.16 91.36 91.76 63.72 62.20 62.95 75.96 75.30 75.63 50.82 49.61 50.21 args only 89.04 93.08 91.02 60.69 63.52 62.07 66.15 69.15 67.62 42.77 44.76 44.76 Table 7: Evaluation of trace insertion and antecedent recovery for C04 algorithm, our basic algorithm and basic algorithm with the subject path constraint.",0,original
"The results were evaluated using the character/pinyin-based 4-gram BLEU score (Papineni et al., 2002), word error rate (WER), position independent word error rate (PER), and exact match (EMatch).",0,original
"1 Introduction and Motivation Parse selection constitutes an important part of many parsing systems (Hara et al., 2005; van Noord and Malouf, 2005; McClosky et al., 2006).",0,original
"We used the preprocessed data to train the phrase-based translation model by using GIZA++ (Och and Ney, 2003) and the Pharaoh tool kit (Koehn et al., 2003).",0,original
Yarowsky (1995) studied a method for word sense disambiguation using unlabeled data.,0,original
"From this data, we use the the GHKM minimal-rule extraction algorithm of (Galley et al., 2004) to yield rules like: NP-C(x0:NPB PP(IN(of x1:NPB))$x1 de x0 Though this rule can be used in either direction, here we use it right-to-left (Chinese to English).",0,original
"(2007), Rosti et al.",0,original
(1993) and Och and Ney (2003).,0,original
"Of the methods we compare against, only the WordNet-based similarity measures, (Mihalcea and Moldovan, 2001), and (Navigli, 2006) provide a method for predicting verb similarities; our learned measure widely outperforms these methods, achieving a 13.6% F-score improvement over the LESK similarity measure.",0,original
(2005) 86.6 86.7 1.19 61.1 Collins (1999) 88.7 88.5 0.92 66.7 Charniak and Johnson (2005) 90.1 90.1 0.74 70.1 This Paper 90.3 90.0 0.78 68.5 all sentences LP LR CB 0CB Klein and Manning (2003) 86.3 85.1 1.31 57.2 Matsuzaki et al.,0,original
"It has been shown that both Nave Bayes and SVMs perform with similar accuracy on different sentiment tagging tasks (Pang and Lee, 2004).",0,original
"For mention detection we use approaches based on Maximum Entropy (MaxEnt henceforth) (Berger et al. , 1996) and Robust Risk Minimization (RRM henceforth) 1For a description of the ACE program see http://www.nist.gov/speech/tests/ace/.",0,original
"Liang (2005) uses the discriminative perceptron algorithm (Collins, 2002) to score whole character tag sequences, finding the best candidate by the global score.",0,original
"6.2 Experimental Settings We utilize a maximum entropy (ME) model (Berger et al., 1996) to design the basic classifier for WSD and TC tasks.",0,original
"In this study we have concentrated on the NPs??term extraction, which comprises the focus of interest in several studies (Jacquemin, 2001; Justeson & Katz, 1995; Voutanen, 1993).",0,original
"The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and 4-gram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit.",0,original
"3.2.1 Factored Treelet Translation Labels of nodes at the t-layer are not atomic but consist of more than 20 attributes representing various linguistic features.3 We can consider the attributes as individual factors (Koehn and Hoang, 2007).",0,original
"Rulesize and lexicalization affect parsing complexity whether the grammar is binarized explicitly (Zhang et al., 2006) or implicitly binarized using Early-style intermediate symbols (Zollmann et al., 2006).",0,original
"WLCS(w,d) =summationtextmi=0 f(ki) We then compute the following quantities, where || is word length, and f1 is the inverse of f. P(w,d) = f1(WLCS(w,d)f(|w|) ) R(w,d) = f1(WLCS(w,d)f(|d|) ) F(w,d) = (1+2)R(w,d)P(w,d)R(w,d)+2P(w,d) In effect, P(w,d) examines how close the longest common substring is to w and R(w,d) how close it is to d. Following Lin (2004), we use  = 8, assigninggreaterimportancetoR(w,d).",0,original
"(Cahill et al. , 2004b) measure annotation quality in terms of precision and recall against manually constructed, gold-standard f-structures for 105 randomly selected trees from section 23 of the WSJ section of Penn-II.",0,original
"The traditional method of evaluating similarity in a semantic network by measuring the path length between two nodes (Lee et al. , 1993; Rada et al. , 1989) also captures this, albeit indirectly, when the semantic network is just an IS-A hierarchy: if the minimal path of IS-A links between two nodes is long, that means it is necessary to go high in the taxonomy, to more abstract concepts, in order to find their least upper bound.",0,original
"For experiment on English, we used the English Penn Treebank (PTB) (Marcus et al., 1993) and the constituency structures were converted to dependency trees using the same rules as (Yamada and Matsumoto, 2003).",0,original
"(2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis.",0,original
"We follow the method used by Kazama and Torisawa (2007), which encodes the matching with a gazetteer entity using IOB tags, with the modication for Japanese.",0,original
"Carletta (1996) also states that in the behavioral sciences, K > .8 signals good replicability, and .67 < K < .8 allows tentative conclusions to be drawn.",0,original
"Stage 2 processing is then free to assign to the compound any bracketing for which it 3The design of this level of Lucy is influenced by Hobbs (1985), which advocates a level of ""surfaey"" logical form with predicates close to actual English words and a structure similar to the syntactic structure of the sentence.",0,original
"We finally move on to present more complex models which attempt to model coreference as a global discourse phenomenon (Yang et al., 2003; Luo et al., 2004; Daume III & Marcu, 2005, inter alia).",0,original
"We therefore ran the dependency model on a test corpus tagged with the POS-tagger of Ratnaparkhi (1996), which is trained on the original Penn Treebank (see HWDep (+ tagger) in Table 3).",0,original
That some model structures work better than others at real NLP tasks was discussed by Johnson (2001) and Klein and Manning (2002).,0,original
One approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus (Hindle 1990; Lin 1998).,0,original
McDonald and Nivre (2007) showed that the MSTParser and MaltParser produce different errors.,0,original
"We also compared the cluster gazetteers with the Wikipedia gazetteer constructed by following the method of (Kazama and Torisawa, 2007).",0,original
"The goal of integrating syntactic information into the translation model has prompted many researchers to pursue tree-based transfer models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Melamed, 2004; Menezes and Quirk, 2005; Galley et al. , 2006), with increasingly encouraging results.",0,original
"The first work in SMT, done at IBM (Brown et al. , 1993), developed a noisy-channel model, factoring the translation process into two portions: the translation model and the language model.",0,original
(2007) and Luo and Zitouni (2005).,0,original
"In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K. We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006).",0,original
"Numerous approaches have been explored for exploiting situations where some amount of annotated data is available and a much larger amount of data exists unannotated, e.g. Marialdo's HMM part-of-speech tagger training (1994), Charniak's parser retraining experiment (1996), Yarowsky's seeds for word sense disambiguation (1995) and Nigam et al's (1998) topic classifier learned in part from unlabelled documents.",0,original
"Predicate argument structures, which consist of complements (case filler nouns and case markers) and verbs, have also been used in the task of noun classification (Hindle 1990).",0,original
"As discussed in (Och, 2003), the direct translation model represents the probability of target sentence English e = e1eI being the translation for a source sentence French f = f1 fJ through an exponential, or log-linear model p(e|f) = exp( summationtextm k=1 k  hk(e,f))summationtext eprimeE exp( summationtextm k=1 k  hk(eprime,f)) (1) where e is a single candidate translation for f from the set of all English translations E,  is the parameter vector for the model, and each hk is a feature function of e and f. In practice, we restrict E to the set Gen(f) which is a set of highly likely translations discovered by a decoder (Vogel et al. , 2003).",0,original
"We provide results using a range of automatic evaluation metrics: BLEU (Papineni et al. , 2002), Precision and Recall (Turian et al. , 2003), and Wordand Sentence Error Rates.",0,original
"For example, Wu (1997) used an English-Chinese bilingual parser based on stochastic transduction grammars to identify terms, including multiword expressions.",0,original
"Uses for k-best lists include minimum Bayes risk decoding (Goodman, 1998; Kumar and Byrne, 2004), discriminative reranking (Collins, 2000; Charniak and Johnson, 2005), and discriminative training (Och, 2003; McClosky et al., 2006).",0,original
"In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al. , 2003).",0,original
"If the bound is too tight to allow the correct parse of some sentence, we would still like to allow an accurate partial parse: a sequence of accurate parse fragments (Hindle, 1990; Abney, 1991; Appelt et al. , 1993; Chen, 1995; Grefenstette, 1996).",0,original
"This decomposition applies both to discriminative linear models and to generative models such as HMMs and CRFs, in which case the linear sum corresponds to log likelihood assigned to the input/output pair by the model (for details see (Roth, 1999) for the classi cation case and (Collins, 2002) for the structured case).",0,original
"We contrast our work with (Galley et al. , 2004), highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.",0,original
"The f are trained using a held-out corpus using maximum BLEU training (Och, 2003).",0,original
"Like Collins (2002), the decoder is the same for both the perceptron and the log-linear parsing models; the only change is the method for setting the weights.",0,original
Brown et al. 1993).,0,original
"(1996), Warnke et al.",0,original
"We tuned our system on the development set devtest2006 for the EuroParl tasks and on nc-test2007 for CzechEnglish, using minimum error-rate training (Och, 2003) to optimise BLEU score.",0,original
"(2005) and compare with results reported by HK06 (Haghighi and Klein, 2006) and CRR07 (Chang et al., 2007).",0,original
"We measure translation performance by the BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005) scores with multiple translation references.",0,original
"Document level sentiment classification is mostly applied to reviews, where systems assign a positive or negative sentiment for a whole review document (Pang et al. , 2002; Turney, 2002).",0,original
"3.3 Language Model We estimate P(s) using n-gram LMs trained on data from the Web, using Stupid Backoff (Brants et al., 2007).",0,original
"(Ramshaw and Marcus, 1995) To reduce the inference time, following (McCallum et al, 2003), we collapsed the 45 different POS labels contained in the original data.",0,original
"First, hierarchical word clusters are derived from unlabeled data using the Brown et al. clustering algorithm (Brown et al., 1992).",0,original
"For instance, for Maximum Entropy, I picked (Berger et al., 1996; Ratnaparkhi, 1997) for the basic theory, (Ratnaparkhi, 1996) for an application (POS tagging in this case), and (Klein and Manning, 2003) for more advanced topics such as optimization and smoothing.",0,original
"1 Introduction Corpus-derived distributional semantic spaces have proved valuable in tackling a variety of tasks, ranging from concept categorization to relation extraction to many others (Sahlgren, 2006; Turney, 2006; Pado and Lapata, 2007).",0,original
"We tune all feature weights automatically (Och, 2003) to maximize the BLEU (Papineni et al., 2002) score on the dev set.",0,original
"The general label sequence ln1 has the highest probability of occuring for the word sequence W n1 among all possible label sequences, that is Ln1 = argmax {Pr (Ln1 | W n1 ) } 3.2 Tagging Scheme We followed the IOB tagging scheme (Ramshaw and Marcus, 1995) for all the three languages (English, Hindi and Telugu).",0,original
"According to the statistical machine translation formalism (Brown et al. , 1993), the translation process is to search for the best sentence bE such that bE = arg max E P(EjJ) = arg maxE P(JjE)P(E) where P(JjE) is a translation model characterizing the correspondence between E and J; P(E), the English language model probability.",0,original
"In order to get a better understanding of these matters, we replicate parts of the error analysis presented by McDonald and Nivre (2007), where parsing errors are related to different structural properties of sentences and their dependency graphs.",0,original
"For a second set of parsing experiments, we used the WSJ portion of the Penn Tree Bank (Marcus et al. , 1993) and Helmut Schmids enrichment program tmod (Schmid, 2006).",0,original
"are the labeled parsing recall and precision, respectively, as defined in (Collins, 1997) (slightly different from (Black et al. , 1991)).",0,original
"1 Introduction Viewed at a very high level, statistical machine translationinvolvesfourphases: languageandtranslation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al. , 2003).",0,original
"One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007).",0,original
"We propose a probabilistic quasi-synchronous grammar, inspired by one proposed for machine translation (D. Smith and Eisner, 2006), and parameterized by mixtures of a robust nonlexical syntax/alignment model with a(n optional)lexical-semantics-drivenlog-linear model.",0,original
"4 Experiment Our baseline system is a popular phrase-based SMT system, Moses (Koehn et al., 2007), with 5-gram SRILM language model (Stolcke, 2002), tuned with Minimum Error Training (Och, 2003).",0,original
"Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al. , 2003).",0,original
"Cohen's Kappa ~ (Bakeman and Gottman, 1986; Carletta, 1996).",0,original
"Methods such as (Wu, 1997), (Alshawi et al. , 2000) and (Lopez et al. , 2002) employ a synchronous parsing procedure to constrain a statistical alignment.",0,original
"Evaluation 8.1 Effects of Unpublished Details In this section we present the results of effectively doing a clean-room implementation of Collins parsing model, that is, using only information available in (Collins 1997, 1999), as shown in Table 4.",0,original
"3 Stochastic Inversion Transduction Grammars Stochastic Inversion Transduction Grammars (SITGs) (Wu, 1997) can be viewed as a restricted subset of Stochastic Syntax-Directed Transduction Grammars.",0,original
"From this aligned training corpus, we extract the phrase pairs according to the heuristics in (Koehn et al., 2003).",0,original
"There are multiple studies (Wu and Fung, 1994; Sproat et al. , 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper a15 a12a14a7 to lower a0a4a12a14a7.",0,original
"This technique is called system combination (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b).",0,original
"The surface heuristic can define consistency according to any word alignment; but most often, the alignment is provided by GIZA++ (Och and Ney, 2003).",0,original
"It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes (Smith and Eisner, 2007; Koo et al., 2008; Wang et al., 2008).",0,original
"We are already using the extracted semantic forms in parsing new text with robust, wide-coverage PCFG-based LFG grammar approximations automatically acquired from the f-structure annotated Penn-II treebank (Cahill et al. , 2004a).",0,original
We follow (Yang et al. 2006; Iida et al. 2006) in using a tree kernel to represent structural information using the subtree that covers a pronoun and its antecedent candidate.,0,original
"As a model learning method, we adopt the maximum entropy model learning method (Della Pietra et al. , 1997; Berger et al. , 1996).",0,original
"In a factored translation model other factors than surface form can be used, such as lemma or part-of-speech (Koehn and Hoang, 2007).",0,original
"Ramshaw and Marcus (Ramshaw and Marcus, 1995) views chunking as a tagging problem.",0,original
"For instance, Church and Hanks (1990) calculated SA in terms of mutual information between two words wl and w2: N * f(wl,w2) I(wl, w2) = log2 (1) f(wl)f(w2) here N is the size of the corpus used in the estimation, f(Wl, w2) is the frequency of the cooccurrence, f(wl) and f(w2) that of each word.",0,original
"Note that generative hybrids are the norm in SMT, where translation scores are provided by a discriminative combination of generative models (Och, 2003).",0,original
Daume III (2007) proposed a simple feature augmentation method to achieve domain adaptation.,0,original
"Alignment, whether for training a translation model using EM or for nding the Viterbi alignment of test data, is O(n6) (Wu, 1997), while translation (decoding) is O(n7) using a bigram language model, and O(n11) with trigrams.",0,original
"The system is tested on base noun-phrase (NP) chunking using the Wall Street Journal corpus (Marcus et al. , 1993).",0,original
"We removed all but the first two characters of each POS tag, resulting in a set of 57 tags which more closely resembles that of the Penn TreeBank (Marcus et al., 1993).",0,original
"85 Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006).",0,original
"Moses uses standard external tools for some of these tasks, such as GIZA++ (Och and Ney, 2003) for word alignments and SRILM (Stolcke, 2002) for language modeling.",0,original
"We use the likelihood ratio for a binomial distribution (Dunning 1993), which tests the hypothesis whether the term occurs independently in texts of biographical nature given a large corpus of biographical and non-biographical texts.",0,original
"6 Conclusion Traditional approaches for devising parsing models, smoothing techniques and evaluation metrics are not well suited for MH, as they presuppose 13The lack of head marking, for instance, precludes the use of lexicalized models a la (Collins, 1997).",0,original
"This is important when LARGE CUT-OFF 0 5 100 NAIVE 541,721 184,493 35,617 SASH 10,599 8,796 6,231 INDEX 5,844 13,187 32,663 Table 4: Average number of comparisons per term considering that different tasks may require different weights and measures (Weeds and Weir, 2005).",0,original
"Running words 1,864 14,437 Vocabulary size 569 1,081 Table 2: ChineseEnglish corpus statistics (Och, 2003) using Phramer (Olteanu et al. , 2006), a 3-gram language model with Kneser-Ney smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data and Pharaoh (Koehn, 2004) with default settings to decode.",0,original
"First, for each verb occurrence subjects and objects were extracted from a parsed corpus (Collins 1997).",0,original
"The co-occurrence relation can also be based on distance in a bitext space, which is a more general representations of bitext correspondence (Dagan et al. , 1993; Resnik & Melamed, 1997), or it can be restricted to words pairs that satisfy some matching predicate, which can be extrinsic to the model (Melamed, 1995; Melamed, 1997).",0,original
"Carletta (1996) cites the convention from the domain of content analysis indicating that .67 K K < .8 indicates marginal agreement, while K > .8 is an indication of good agreement.",0,original
"Finally, it would be nice to merge some of the approaches by (Toutanova et al., 2003) and (Shen et al., 2007) with the ideas of semi-supervised learning introduced here, since they seem orthogonal in at least some aspects (e.g., to replace the rudimentary lookahead features with full bidirectionality).",0,original
"ROUGE-N ROUGE-N is an N-gram-based evaluation measure defined as follows (Lin, 2004b): ROUGE-Na59a61a146a31a62a90a147a49a65a68a67 a215 a77a83a216 a209a68a217a61a173 a172a27a218 a77 a215 a219a27a220a158a221a183a222a85a223 a172 a173a78a224a76a225a164a226 a59a136a227a158a228 a152a130a150a104a229 a65 a215 a77a29a216 a209a68a217a76a173 a172 a218 a77 a215 a219a27a220a159a221a183a222a85a223 a59a136a227a158a228 a152a130a150 a229 a65 (10) Here, a230a66a231a37a232a21a233a27a234a118a28a78a235a37a236a25a237a37a238a11a239a168a36 is the number of an N-gram and a230a66a231a37a232a21a233a27a234 a196 a197a29a240a98a241a243a242a244a28a78a235a37a236a25a237a37a238a49a239a168a36 denotes the number of ngram co-occurrences in a system output and the reference.",0,original
"(Wellington et al. , 2006) argue that these restrictions reduce our ability to model translation equivalence effectively.",0,original
"To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007).",0,original
"Many studies on collocation extraction are carried out based on co-occurring frequencies of the word pairs in texts (Choueka et al., 1983; Church and Hanks, 1990; Smadja, 1993; Dunning, 1993; Pearce, 2002; Evert, 2004).",0,original
"These sentences were parsed with the Collins parser (Collins, 1997).",0,original
"using Spearmans rank correlation coefficient and Pearsons rank correlation coefficient (Lin et al. , 2003, Lin, 2004, Hirao et al. , 2005).",0,original
"(1998) present a probabilistic model for pronoun resolution trained on a small subset of the Penn Treebank Wall Street Journal corpus (Marcus et al. , 1993).",0,original
"3.2 Classifying speech segments in isolation In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5 Following standard practice in sentiment analysis (Pang et al. , 2002), the input to SVMlight consisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.",0,original
"In previous alignment methods, some researchers modeled the alignments with different statistical models (Wu, 1997; Och and Ney, 2000; Cherry and Lin, 2003).",0,original
"Several researchers (e.g., (Palmer et al., 2004; Navigli, 2006; Snow et al., 2007; Hovy et al., 2006)) work on reducing the granularity of sense inventories for WSD.",0,original
"They use a conditional model, based on Collins (1996), which, as the authors acknowledge, has a number of theoretical deficiencies; thus the results of Clark et al. provide a useful baseline for the new models presented here.",0,original
We apply the log likelihood principle (Dunning 1993) to compute this score.,0,original
"In the probabilistic LR model, probabilities are assigned to tree 696 Precision Recall F-score Time (min) Best-First Classifier-Based (this paper) 88.1 87.8 87.9 17 Deterministic (MaxEnt) (this paper) 85.4 84.8 85.1 < 1 Charniak & Johnson (2005) 91.3 90.6 91.0 Unk Bod (2003) 90.8 90.7 90.7 145* Charniak (2000) 89.5 89.6 89.5 23 Collins (1999) 88.3 88.1 88.2 39 Ratnaparkhi (1997) 87.5 86.3 86.9 Unk Tsuruoka & Tsujii (2005): deterministic 86.5 81.2 83.8 < 1* Tsuruoka & Tsujii (2005): search 86.8 85.0 85.9 2* Sagae & Lavie (2005) 86.0 86.1 86.0 11* Table 1: Summary of results on labeled precision and recall of constituents, and time required to parse the test set.",0,original
"2 RelatedWork 2.1 Sentiment Classification Most previous work on the problem of categorizing opinionated texts has focused on the binary classification of positive and negative sentiment (Turney, 2002; Pang et al., 2002; Dave at al., 2003).",0,original
"6.1.1 Nugget-Based Pyramid Evaluation For our first approach we used a nugget-based evaluation methodology (Lin and Demner-Fushman, 2006; Nenkova and Passonneau, 2004; Hildebrandt et al., 2004; Voorhees, 2003).",0,original
"High values of  fall into the minimal entropy trap, while low values ofhave no effect on the model (see (Jiao et al., 2006) for an example).",0,original
"In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus (Yarowsky, 1995).",0,original
"For comparison, we also implemented a different N-best phrase alignment method, where _ _ _ _ the_light_was_red _ _ _ the_light was_red _ _ the_light was red (1) (2) (3) Figure 4: N-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (Koehn et al. , 2003).",0,original
"Although the BLEU (Papineni et al. , 2002) score from Finnish to English is 21.8, the score in the reverse direction is reported as 13.0 which is one of the lowest scores in 11 European languages scores (Koehn, 2005).",0,original
"3.5 Regularization We apply lscript1 regularization (Ng, 2004; Gao et al., 2007) to make learning more robust to noise and control the effective dimensionality of the feature spacebysubtractingaweightedsumofabsolutevalues of parameter weights from the log-likelihood of the training data w = argmaxw LL(w) summationdisplay i Ci|wi| (6) We optimize the objective using a variant of the orthant-wise limited-memory quasi-Newton algorithm proposed by Andrew & Gao (2007).3 All values Ci are set to 1 in most of the experiments below, although we apply stronger regularization (Ci = 3) to reordering features.",0,original
"One such relational reasoning task is the problem of compound noun interpretation, which has received a great deal of attention in recent years (Girju et al., 2005; Turney, 2006; Butnariu and Veale, 2008).",0,original
"Annotation was highly reliable with a kappa (Carletta, 1996) of 3https://www.cia.gov/cia/publications/ factbook/index.html 4Given that the task is not about standard Named Entity Recognition, we assume that the general semantic class of the name is already known.",0,original
"Most importantly, whereas the one-sense-per-discourse assumption (Yarowsky, 1995) also applies to discriminating images, there is no guarantee of a local collocational or co-occurrence context around the target image.",0,original
"Previous SMT systems (e.g., Brown et al., 1993) used a word-based translation model which assumes that a sentence can be translated into other languages by translating each word into one or more words in the target language.",0,original
"We use the GIZA++ implementation of IBM Model 4 (Brown et al., 1993; Och and Ney, 2003) coupled with the phrase extraction heuristics of Koehn et al.",0,original
"We performed feature selection by incrementally growing a log-linear model with order0 features f(x,yt) using a forward feature selection procedure similar to (Berger et al. , 1996).",0,original
"1 Introduction Over the past five years progress in machine translation, and to a lesser extent progress in natural language generation tasks such as summarization, has been driven by optimizing against n-grambased evaluation metrics such as Bleu (Papineni et al. , 2002).",0,original
"The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English sentence.",0,original
"2 Word Alignment algorithm We use IBM Model 4 (Brown et al. , 1993) as a basis for our word alignment system.",0,original
"Each element of the resulting vector was replaced with its log-likelihood value (see Definition 10 in Section 2.3) which can be considered as an estimate of how surprising or distinctive a co-occurrence pair is (Dunning, 1993).",0,original
"Smadja, 1993): 1.",0,original
"These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al. , 2004; Luo and Zitouni, 2005).",0,original
"One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007).",0,original
"(Farach et al. , 1995; Wyner, in press) describe a novel algorithm for entropy estimation for which they claim very fast convergence time; using no more than about five pages of text, they can achieve nearly the same accuracy as (Brown et al. , 1992).",0,original
"For example, the sentence I went to California last May would be marked for base NPs as: I went to California last May I 0 0 I B I indicating that the NPs are I, California and last May. This approach has been studied in (Ramshaw and Marcus, 1995).",0,original
"??queries: The queries of Turney (2002) are made up of a pair of adjectives, and in our approach the query contains the content words of the headline and an emotion.",0,original
But it is close to the paradigm described by Yarowsky (1995) and Turney (2002) as it also employs self-training based on a relatively small seed data set which is incrementally enlarged with unlabelled samples.,0,original
"In the field of parsing, McDonald and Nivre (2007) compared parsing errors between graphbased and transition-based parsers.",0,original
"(Jiampojamarn et al., 2008) and (Bartlett et al., 2008) do worse on the English test data than they do on German, Dutch, or French.",0,original
"The parsing algorithm was CKY-style parsing with beam thresholding, which was similar to ones used in (Collins, 1996; Clark et al. , 2002).",0,original
"Movie-domainSubjectivityDataSet(Movie): Pang and Lee (2004) used a collection of labeled subjective and objective sentences in their work on review classification.5 The data set contains 5000 subjective sentences, extracted from movie reviews collected from the Rotten Tomatoes web formed best.",0,original
"5.2 Adding lexical information Gildea (2001) shows that removing the lexical dependencies in Model 1 of Collins (1997) (that is, not conditioning on w h when generating w s )decreases labeled precision and recall by only 0.5%.",0,original
"The real-valued features include the following: a block translation score derived from phrase occurrence statistics a4a9a113a77a11, a trigram language model to predict target words a4a179a112a229 a78a204a11, a lexical weighting score for the block internal words a4a127a202a204a11, a distortion model a4a0a207a229 a218a147a11 as well as the negative target phrase length a4a60a36a87a11 . The transition cost is computed as a19 a4a20a6 a23 a6 a39 a11a224a15 a27 a28 a30a89a32 a4a7a6 a83 a6a20a39a34a11, where a27 a199a230a227 a228 is a weight vector that sums up to a113a89a35a116 : a228 a13a26a17 a10 a27 a13a217a15a231a113a25a35a116 . The weights are trained using a procedure similar to (Och, 2003) on held-out test data.",0,original
"The simplest (Wu, 1997) uses constit(np,3,5,np,4,8) to denote a NP spanning positions 35 in the English string that is aligned with an NP spanning positions 48 in the Chinese string.",0,original
3.4 Related work and issues for future research Smadja (1992) and van der Eijk (1993) describe term translation methods that use bilingual texts that were aligned at the sentence level.,0,original
"4 Method-2: Simple Chunk-based Extraction To overcome the shortcomings of the Brill tagger in identifying particles, we next look to full chunk 2Note, this is the same as the maximum span length of 5 used by Smadja (1993), and above the maximum attested NP length of 3 from our corpus study (see Section 2.2).",0,original
"In the early statistical translation model work at IBM, these representations were called cepts, short for concepts (Brown et al., 1993).",0,original
"In many applications, it has been shown that sentences with subjective meanings are paid more attention than factual ones(Pang and Lee, 2004)(Esuli and Sebastiani, 2006).",0,original
"The problem is that with such a definition of collocations, even when improved, one identifies not only collocations but freecombining pairs frequently appearing together such as lawyer-client; doctor-hospital, as pointed out by Smadja (1993).",0,original
"4.1 Translation Modeling We can test our models utility for translation by transforming its parameters into a phrase table for the phrasal decoder Pharaoh (Koehn et al. , 2003).",0,original
"The results are comparable to other results reported using the Inside/Outside method (Ramshaw and Marcus, 1995) (see Table 7.",0,original
"Since so many concepts used in discourse are graindependent, a theory of granularity is also fundamental (see Hobbs 1985b).",0,original
"A CHECK move requests the partner to confirm information that the speaker has some reason to believe, but is not entirely sure about \[Carletta et al.1996\].",0,original
"For now, we consider it to be one where:  Every foreign word is aligned exactly once (Brown et al., 1993).",0,original
"This system uses all featuresof conventionalphrase-basedSMT as in (Koehn et al., 2003).",0,original
"A popular statistical machine translation paradigms is the phrase-based model (Koehn et al., 2003; Och and Ney, 2004).",0,original
"Kanayama and Nasukawa used both intraand inter-sentential co-occurrence to learn polarity of words and phrases (Kanayama and Nasukawa, 2006).",0,original
"This kind of smoothing has also been used in the generative parser of (Collins, 1997) and has been shown to have a relatively good performance for language modeling (Goodman, 2001).",0,original
"Systems based on word-to-word lexicons, such as the IBM systems (Brown et al. , 1990; Brown et al. , 1993), incorporate further devices that allow reordering of words (a distortion model) and ranking of alternatives (a monolingual language model).",0,original
"(Turney (2002) makes a similar point, noting that for reviews, \the whole is not necessarily the sum of the parts"").",0,original
"ROUGE (Lin, 2004) is an evaluation metric designed to evaluate automatically generated summaries.",0,original
"3 Tagging 3.1 Corpus To facilitate comparison with previous results, we used the UPenn Treebank corpus (Marcus et al. , 1993).",0,original
"Extensions to Hiero Several authors describe extensions to Hiero, to incorporate additional syntactic information (Zollmann and Venugopal, 2006; Zhang and Gildea, 2006; Shen et al., 2008; Marton and Resnik, 2008), or to combine it with discriminative latent models (Blunsom et al., 2008).",0,original
"          = = = = )(),( InverseM1 )(),( DirectM1 )(),( InverseMLE )(),( DirectMLE )|(),,( )|(),,( )(*, ),(),,(,*)( ),(),,( Atreelets s t Atreelets t s Atreelets Atreelets tspATSf stpATSf c cATSf c cATSf             We use word probability tables p(t | s) and p(s | t) estimated by IBM Model 1 (Brown et al. 1993).",0,original
"Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT.",0,original
"(2003), and component weights are adjusted by minimum error rate training (Och, 2003).",0,original
"Table 1 shows the impact of increasing reordering window length (Koehn et al. , 2003) on translation quality for the ?dev06??data.2 Increasing the reordering window past 2 has minimal impact on translation quality, implying that most of the reordering effects across Spanish and English are well modeled at the local or phrase level.",0,original
"The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009).",0,original
"We examine Structural Correspondence Learning (SCL) (Blitzer et al., 2006) for this task, and compare it to several variants of Self-training (Abney, 2007; McClosky et al., 2006).",0,original
"Following the broad shift in the field from finite state transducers to grammar transducers (Chiang, 2007), recent approaches to phrase-based alignment have used synchronous grammar formalisms permitting polynomial time inference (Wu, 1997; 783 Cherry and Lin, 2007; Zhang et al., 2008b; Blunsom et al., 2008).",0,original
These are most directly presented in Ostler and Atkins (1991).,0,original
"2 Related Work Sentiment Classi cation Traditionally, categorization of opinion texts has been cast as a binary classication task (Pang et al. , 2002; Turney, 2002; Yu and Hatzivassiloglou, 2003; Dave et al. , 2003).",0,original
"Word alignment was carried out by running Giza++ implementation of IBM Model 4 initialized with 5 iterations of Model 1, 5 of the HMM aligner, and 3 iterations of Model 4 (Och and Ney, 2003) in both directions and then symmetrizing using the grow-diag-final-and heuristic (Koehn et al., 2003).",0,original
"One aspect of VPCs that makes them dicult to extract (cited in, e.g., Smadja (1993)) is that the verb and particle can be non-contiguous, e.g. hand the paper in and battle right on.",0,original
"Let a183a49a48a50 a69 a188 a50 a51a181a51a181a51a212a188 a50a7a51a24a52 a48a54a53 a185a56a55 be a substring of a183 from the word a188 a50 with length a57 . Note this notation is different from (Brown et al. , 1993).",0,original
"For example, in IBM Model 1 the lexicon probability of source word f given target word e is calculated as (Och and Ney, 2003): p(f|e) = summationtext k c(f|e;e k,fk) summationtext k,f c(f|e;e k,fk) (1) c(f|e;ek,fk) = summationdisplay ek,fk P(ek,fk)summationdisplay a P(a|ek,fk) (2) summationdisplay j (f,fkj )(e,ekaj) Therefore, the distribution of P(ek,fk) will affect the alignment results.",0,original
"As a sanity check, we duplicated Pang et al.s (2002) baseline in which all unigrams that appear four or more times in the training documents are used as features.",0,original
"(levelopment of cor1)ora with morl)ho-synta(:ti(: and syntacti(: mmotation (Marcus et al. , 1993), (Sampson, 1995).",0,original
"4 Semantic Class Induction from Wikipedia Wikipedia has recently been used as a knowledge source for various language processing tasks, including taxonomy construction (Ponzetto and Strube, 2007a), coreference resolution (Ponzetto and Strube, 2007b), and English NER (e.g., Bunescu and Pasca (2006), Cucerzan (2007), Kazama and Torisawa (2007), Watanabe et al.",0,original
"Additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential CRF; in contrast, approaches like Gibbs Sampling that model the dependencies directly can increase inference time by a factor of 30 (Finkel et al. , 2005).",0,original
" Our evaluation metrics are BLEU (Papineni et al., 2002) and NIST, which are to perform caseinsensitive matching of n-grams up to n = 4.",0,original
"Having a single, canonical tree structure for each possible alignment can help when flattening binary trees, as it indicates arbitrary binarization decisions (Wu, 1997).",0,original
"Parameters were tuned with minimum error-rate training (Och, 2003) on the NIST evaluation set of 2006 (MT06) for both C-E and A-E.",0,original
"The learning algorithm, which is illustrated in Collins (2002a), proceeds as follows.",0,original
"The system combination weights  one for each system, LM weight, and word and NULL insertion penalties  were tuned to maximize the BLEU (Papineni et al., 2002) score on the tuning set (newssyscomb2009).",0,original
"toilet/bathroom Since the word ""facility"" is the subject of ""employ"" and is modified by ""new"" in (3), we retrieve other words that appeared in the same contexts and obtain the following two groups of selectors (the log A column shows the likelihood ratios (Dunning, 1993) of these words in the local contexts):  Subjects of ""employ"" with top-20 highest likelihood ratios: word freq, Iog,k word freq ORG"" 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 537 *ORG includes all proper names recognized as organizations 18  Modifiees of ""new"" with top-20 highest likelihood ratios: word freq log,k post 432 952.9 issue 805 902.8 product 675 888.6 rule 459 875.8 law 356 541.5 technology 237 382.7 generation 150 323.2 model 207 319.3 job 260 269.2 system 318 251.8 word freq log )~ bonds 223 245.4 capital 178 241.8 order 228 236.5 version 158 223.7 position 236 207.3 high 152 201.2 contract 279 198.1 bill 208 194.9 venture 123 193.7 program 283 183.8 Since the similarity between Sense 1 of ""facility"" and the selectors is greater than that of other senses, the word ""facility"" in (3) is tagged ""Sense The key innovation of our algorithm is that a polysemous word is disambiguated with past usages of other words.",0,original
"Hockenmaier et al (Hockenmaier et al. , 2000), although to some extent following the approach of Xia (Xia, 1999) where LTAGs are extracted, have pursued an alternative by extracting Combinatory Categorial Grammar (CCG) (Steedman, 1993; Wood, 1993) lexicons from the Penn Treebank.",0,original
"Klein and Manning (2002) argue that these results show a pattern where discriminative probability models are inferior to generative probability models, but that improvements can be achieved by keeping a generative probability model and training according to a discriminative optimization criteria.",0,original
However morphosyntactic features alone cannot verify the terminological status of the units extracted since they can also select non terms (see Smadja 1993).,0,original
"The data consist of sections of the Wall Street Journal (WSJ) part of the Penn TreeBank (Marcus et al. , 1993), with information on predicate-argument structures extracted from the PropBank corpus (Palmer et al. , 2005).",0,original
"Language modeling (Chen and Goodman, 1996), noun-clustering (Ravichandran et al., 2005), constructing syntactic rules for SMT (Galley et al., 2004), and finding analogies (Turney, 2008) are examples of some of the problems where we need to compute relative frequencies.",0,original
"3 Evaluation We trained our model parameters on a subset of the provided dev2006 development set, optimizing for case-insensitive IBM-style BLEU (Papineni et al., 2002) with several iterations of minimum error rate training on n-best lists.",0,original
"3.2 ROUGE Version 1.5.5 of the ROUGE scoring algorithm (Lin, 2004) is also used for evaluating results.",0,original
"154 2 Translation Models 2.1 Standard Phrase-based Model Most phrase-based translation models (Och, 2003; Koehn et al. , 2003; Vogel et al. , 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters.",0,original
"We made use of the same data set as introduced in (Cong et al., 2008; Ding et al., 2008).",0,original
"As a result, the string translation probability can be decomposed into a lexicon probability and an alignment probability (Brown et al. 1993).",0,original
"3.3 Tree Transducer Grammars Syntactic machine translation (Galley et al., 2004) uses tree transducer grammars to translate sentences.",0,original
"As argued in Carletta (1996), Kappa values of 0.8 or higher are desirable for detecting associations between several coded variables; we were thus satisfied with the level of agreement achieved.",0,original
"Given a wordq, its set of featuresFq and feature weightswq(f) for f Fq, a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u,v) = summationtext fFuFv[wu(f)+wv(f)]summationtext fFu wu(f)+ summationtext fFv wv(f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: wq(f) =log[Pr(f|q)Pr(f) ].",0,original
"(Yarowsky, 1995) and (Mihalcea and Moldovan, 2001) utilized bootstrapping for word sense disambiguation.",0,original
"There has thus been a trend recently towards robust wide-coverage semantic construction (e.g., (Bos et al., 2004; Zettlemoyer and Collins, 2007)).",0,original
"Although a large number of studies have been made on learning paraphrases, for example (Barzilay and Lee, 2003), there are only a few studies which address the connotational difference of paraphrases.",0,original
"For example, in machine translation, BLEU score (Papineni et al., 2002) is developed to assess the quality of machine translated sentences.",0,original
"This is similar to results in the literature (Ramshaw and Marcus, 1995).",0,original
"4.3 Baselines 4.3.1 Word Alignment We used the GIZA++ implementation of IBM word alignment model 4 (Brown et al., 1993; Och and Ney, 2003) for word alignment, and the heuristics described in (Och and Ney, 2003) to derive the intersection and refined alignment.",0,original
"This is the same complexity as the ITG alignment algorithm used by Wu (1997) and others, meaning complete Viterbi decoding is possible without pruning for realistic-length sentences.",0,original
Eguchi & Lavrenko (2006) propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevancy.,0,original
"Methods such as (Wu, 1997), (Alshawi et al. , 2000) and (Lopez et al. , 2002) employ a synchronous parsing procedure to constrain a statistical alignment.",0,original
"In constrast with many previous approaches (Brown et al. , 1993; Och et al. , 1999; Yamada and Knight, 2001), our model does not try to capture how Source sentences can be mapped into Target sentences, but rather how Source and Target sentences can be generated simultaneously.",0,original
Curran (2002) and Lin (1998) use syntactic features in the vector definition.,0,original
"2.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy (Berger et al. , 1996) model.",0,original
We propose a method similar to Yarowsky (1995) to generalize beyond the training set.,0,original
The translation probability can also be discriminatively trained such as in Tillmann and Zhang (2006).,0,original
"We have used the Improved Iterative Scaling algorithm (IIS) (Berger et al. , 1996).",0,original
"There is potential of developing Sense Definition Model to identify and represent semantic and stylistic differentiation reflected in the MRD glosses pointed out in DiMarco, Hirst and Stede (1993).",0,original
"Our approach was to identify a parallel corpus of manually and automatically transcribed documents, the TDT2 corpus, and then use a statistical approach (Dunning, 1993) to identify tokens with significantly Table 5: Impact of recall and precision enhancing devices.",0,original
"Table 1 shows theresultsalongwithB andthethreemetricsthat achieved higher correlations than B: semantic role overlap (Gimenez and Marquez, 2007), ParaEval recall (Zhou et al., 2006), and METEOR (Banerjee and Lavie, 2005).",0,original
"There has been a sizable amount of research on structure induction ranging fromlinearsegmentation(Hearst, 1994)tocontent modeling (Barzilay and Lee, 2004).",0,original
"Similarly, prototype-driven learning (PDL) (Haghighi and Klein, 2006) optimizes the joint marginal likelihood of data labeled with prototype input features for each label.",0,original
"In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores (Dunning, 1993) are above a threshold.",0,original
"The features we use are shown in Table 2, which are based on the features used by Ratnaparkhi (1996) and Uchimoto et al.",0,original
"In this work, we employ a syntax-based model that applies a series of tree/string (xRS) rules (Galley et al. , 2004; Graehl and Knight, 2004) to a source language string to produce a target language phrase structure tree.",0,original
"This algorithm and its many variants are widely used in the computational linguistics community (Collins, 2002a; Collins and Duffy, 2002; Collins, 2002b; Collins and Roark, 2004; Henderson and Titov, 2005; Viola and Narasimhan, 2005; Cohen et al., 2004; Carreras et al., 2005; Shen and Joshi, 2005; Ciaramita and Johnson, 2003).",0,original
"5.2 Assigning complex ambiguity tags In the tagging literature (e.g. , Cutting et al (1992)) an ambiguity class is often composed of the set of every possible tag for a word.",0,original
"This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied (Abney, 2004).",0,original
"In Table 6 we report our results, together with the state-of-the-art from the ACL wiki5 and the scores of Turney (2008) (PairClass) and from Amac Herdagdelens PairSpace system, that was trained on ukWaC.",0,original
(2006) and Blitzer et al.,0,original
"The node mapping function f for the entire tree thus has a different role from the alignment function in the IBM statistical translation model (Brown et al. 1990, 1993); the role of the latter includes the linear ordering of words in the target string.",0,original
"Breidt(1993) alsopointedouta coupleof problemsthatmakes extractionfor Germanmoredifficultthanfor English: the stronginflectionfor verbs,the variable word-order,andthepositionalambiguityofthearguments.Sheshowsthatevendistinguishingsubjectsfromobjectsisverydifficultwithoutparsing.",0,original
"For tuning of the decoders parameters, including the language model weight, minimum error training (Och 2003) with respect to the BLEU score using was conducted using the development corpus.",0,original
"The importance of including single nonheadwords is now also uncontroversial (e.g. Collins 1997, 1999; Charniak 2000), and the current paper has shown the importance of including two and more nonheadwords.",0,original
"Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (Pang et al. , 2002) or positive and negative words (Turney, 2002; Mullen and Collier, 2004); classifying sentences in a document as either subjective or objective (Riloff and Wiebe, 2003; Pang and Lee, 2004); identifying or classifying appraisal targets (Nigam and Hurst, 2004); identifying the source of an opinion in a text (Choi et al. , 2005), whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (Gamon et al. , 2005; Popescu and Etzioni, 2005).",0,original
"(Koehn et al. , 2003) used the following distortion model, which simply penalizes nonmonotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter a71, a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 a10 a71a26a72a73a25a74 a45a62a75 a74a77a76a24a78 a45 a32 a72 (3) a79a17a80a82a81a84a83a85a15a86a88a87a70a89a91a90 languageis a means communication of MG RA RA b1 b2 b3 b4 Figure 1: Phrase alignment and reordering bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei source target target source target target source source d=MA d=MG d=RA d=RG Figure 2: Four types of reordering patterns 3 The Global Phrase Reordering Model Figure 1 shows an example of Japanese-English phrase alignment that consists of four phrase pairs.",0,original
"2.2 Brown clustering algorithm In order to provide word clusters for our experiments, we used the Brown clustering algorithm (Brown et al., 1992).",0,original
"Performance of Alternative Models 157 5 Related Work Previous parsing models (e.g. , Collins, 1997; Charniak, 2000) maximize the joint probability P(S, T) of a sentence S and its parse tree T. We maximize the conditional probability P(T | S).",0,original
"We use these tuples to calculate a balanced f-score against the gold alignment tuples.4 Method Dict size f-score Gold 28 100.0 Monotone 39 68.9 IBM-1 (Brown et al., 1993) 30 80.3 IBM-4 (Brown et al., 1993) 29 86.9 IP 28 95.9 The last line shows an average f-score over the 8 tied IP solutions.",0,original
"For testing purposes, we used the Wall Street Journal part of the Penn Treebank corpus (Marcus et al., 1993).",0,original
"Aggregate models based on higher-order n-grams (Brown et al. , 1992) might be able to capture multi-word structures such as noun phrases.",0,original
Johnson (2007) and Gao & Johnson (2008) assume that words are generated by a hidden Markov model and find that the resulting states strongly correlate with POS tags.,0,original
"(Brown et aL, 1993) The heuristics in Section 6 are designed specifically to find the interesting features in that featureless desert.",0,original
"While in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types (Davidov et al., 2007; Davidov and Rappoport, 2008a; Davidov and Rappoport, 2008b).",0,original
"For the former we made use Decision Lists similar to Yarowskys method for Word Sense Disambiguation (WSD) (Yarowsky, 1995).",0,original
"The third exploits automatic subjectivity analysis in applications such as review classification (e.g. , (Turney, 2002; Pang and Lee, 2004)), mining texts for product reviews (e.g. , (Yi et al. , 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005)), summarization (e.g. , (Kim and Hovy, 2004)), information extraction (e.g. , (Riloff et al. , 2005)), 1Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation.",0,original
"Such a similarity is calculated by using the WordNet::Similarity tool (Pedersen et al. , 2004), and, concretely, the Wu-Palmer measure, as defined in Equation1 (Wu and Palmer, 1994).",0,original
"Table 2 shows the total space and number of bytes required per n-gram to encode the model under different schemes: LDC gzipd is the size of the files as delivered by LDC; Trie uses a compact trie representation (e.g., (Clarkson et al., 1997; Church et al., 2007)) with 3 byte word ids, 1 byte values, and 3 byte indices; Block encoding is the encoding used in (Brants et al., 2007); and randomized uses our novel randomized scheme with 12 error bits.",0,original
"This is known as cost-based abduction (Hobbs et al. , 1988).",0,original
"Reference-based metrics such as BLEU (Papineni et al. , 2002) have rephrased this subjective task as a somewhat more objective question: how closely does the translation resemble sentences that are known to be good translations for the same source?",0,original
"We use the discriminative perceptron learning algorithm (Collins, 2002; McDonald et al., 2005) to train the values of vectorw.",0,original
Turney (2002) and Turney and Littman (2002) exploit the first two generalizations for unsupervised sentiment classification of movie reviews.,0,original
"The other approach is to estimate a single score or likelihood of a translation with rich features, for example, with the maximum entropy (MaxEnt) method as in (Carpuat and Wu, 2007; Ittycheriah and Roukos, 2007; He et al., 2008).",0,original
"In this paper we present a novel PCFG-based architecture for probabilistic generation based on wide-coverage, robust Lexical Functional Grammar (LFG) approximations automatically extracted from treebanks (Cahill et al. , 2004).",0,original
"We combine different parametrization of (smoothed) BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and TER (Snover et al., 2006), to give a total of roughly 100 features.",0,original
"For each feature function, there is a model parameter  i . The best word segmentation W * is determined by the decision rule as  = == M i ii W M W WSfWSScoreW 0 0 * ),(maxarg),,(maxarg  (2) Below we describe how to optimize  s. Our method is a discriminative approach inspired by the Minimum Error Rate Training method proposed in Och (2003).",0,original
"Experimental Comparison 4.1 Experiments on the ATIS corpus For our first comparison, we used I0 splits from the Penn ATIS corpus (Marcus et al. 1993) into training sets of 675 sentences and test sets of 75 sentences.",0,original
"The different approaches (e.g. Brent, !991, 1993; Ushioda et al. , 1993; Briscoe and Carroll, 1997; Manning, 1993; Carroll and Rooth, 1998; Gahl, 1998; Lapata, 1999; Sarkar and Zeman, 2000) vary largely according to the methods used and the number of SCFS being extracted.",0,original
"4 The Experiments For the experiments, we used PropBank (www.cis.upenn.edu/ace) along with PennTreeBank5 2 (www.cis.upenn.edu/treebank) (Marcus et al. , 1993).",0,original
"a0 subsequence S1 S2 a0 subsequence S1 S2 a0 subsequence S1 S2 Becoming 1 1 Becoming-is a1 a2 a1 a2 astronaut-DREAM 0 a1 a2 DREAM 1 1 Becoming-my a1a4a3a5a1a4a3 astronaut-ambition 0 a1 a2 SPACEMAN 1 1 SPACEMAN-DREAM a1a4a3a5a1 a2 astronaut-is 0 1 a 1 0 SPACEMAN-ambition 0 a1 a2 astronaut-my 0 a1 ambition 0 1 SPACEMAN-dream a1 a3 0 cosmonaut-DREAM a1 a3 0 1 an 0 1 SPACEMAN-great a1 a2 0 cosmonaut-dream a1 a3 0 astronaut 0 1 SPACEMAN-is 1 1 cosmonaut-great a1 a2 0 cosmonaut 1 0 SPACEMAN-my a1a6a1 cosmonaut-is 1 0 dream 1 0 a-DREAM a1 a7 0 cosmonaut-my a1 0great 1 0 a-SPACEMAN 1 0 great-DREAM 1 0 is 1 1 2 a-cosmonaut 1 0 2 great-dream 1 0 my 1 1 a-dream a1 a7 0 is-DREAM a1 a2 a1 Becoming-DREAM a1a4a8a5a1 a7 a-great a1 a3 0 is-ambition 0 a1 Becoming-SPACEMAN a1a6a1 a-is a1 0 is-dream a1 a2 0 Becoming-a 1 0 a-my a1 a2 0 is-great a1 0 Becoming-ambition 0 a1 a7 an-DREAM 0 a1 a3 is-my 1 1 2 Becoming-an 0 1 an-SPACEMAN 0 1 my-DREAM a1 1 Becoming-astronaut 0 a1 an-ambition 0 a1 a3 my-ambition 0 1 Becoming-cosmonaut a1 0 an-astronaut 0 1 my-dream a1 0 Becoming-dream a1a4a8 0 an-is 0 a1 my-great 1 0 Becoming-great a1 a7 0 an-my 0 a1 a2 2002; Lin and Hovy, 2003; Lin, 2004a; Lin, 2004b; Soricut and Brill, 2004).",0,original
"While earlier approaches for text compression were based on symbolic reduction rules (Grefenstette 1998; Mani, Gates, and Bloedorn 1999), more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced (Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003).",0,original
"In (Daume III and Marcu, 2005), as well as other similar works (Collins, 2002; Collins and Roark, 2004; Shen and Joshi, 2005), only left-toright search was employed.",0,original
"Normally,   :8 is considered a good agreement (Carletta, 1996).",0,original
"The main data set consist of four sections (15-18) of the Wall Street Journal (WSJ) part of the Penn Treebank (Marcus et al. , 1993) as training material and one section (20) as test material 1.",0,original
"Decoding weights are optimized using Ochs algorithm (Och, 2003) to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature.",0,original
"2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al. , 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002).",0,original
"The details of the algorithm can be found in the literature for statistical translation models, such as (Brown et al., 1993).",0,original
"The published F score for voted perceptron is 93.53% with a different feature set (Collins, 2002).",0,original
"For example, if the lexicon contains an adjective excellent, it matches every adjective phrase that includes excellent such as view-excellent etc. As a baseline, we built lexicon similarly by using polarity value of (Turney, 2002).",0,original
"In the literature on the kappa statistic, most authors address only category data; some can handle more general data, such as data in interval scales or ratio scales (Krippendorff, 1980; Carletta, 1996).",0,original
"Koehn and Hoang (2007) propose factored translation models that combine feature functions to handle syntactic, morphological, and other linguistic information in a log-linear model.",0,original
"3.2 (m,n)-cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts (Hindle, 1990).",0,original
"By introducing the hidden word alignment variable a  (Brown et al., 1993), the optimal translation can be searched for based on the following criterion: * 1 , arg max( ( , , )) M mm m ea eh = = efa             (1) where  is a string of phrases in the target language, e f  fa    is the source language string of phrases,  he  are feature functions, weights (, , ) m m  are typically optimized to maximize the scoring function (Och, 2003).",0,original
"5 Conclusions and Future Work The paper compares Structural Correspondence Learning (Blitzer et al., 2006) with (various instances of) self-training (Abney, 2007; McClosky et al., 2006) for the adaptation of a parse selection model to Wikipedia domains.",0,original
"The dependency trees induced when each rewrite rule in an i-th order LCFRS distinguish a unique head can similarly be characterized by being of gap-degree i, so that i is the maximum number of gaps that may appear between contiguous substrings of any subtree in the dependency tree (Kuhlmann and Mohl, 2007).",0,original
"Starting from an initial point M1 , computing the most probable sentence hypothesis out of a set of K candidate translations Cs AG D8e1,,eKD9 along the line M1 A0  A4 dM1 results in the following optimization problem (Och, 2003): e D4fs;D5 AG argmax eC8Cs AX D4 M 1 A0  A4 d M 1 D5 C2 A4 hM1 D4e,fsD5 B5 AG argmax eC8Cs AY F4 m mhmD4e,fsD5 D0D3D3D3D3D3D3D3D3D1D3D3D3D3D3D3D3D3D2 AGaD4e,fsD5 A0 A4 F4 m dmhmD4e,fsD5 D0D3D3D3D3D3D3D3D3D1D3D3D3D3D3D3D3D3D2 AGbD4e,fsD5 B6 AG argmax eC8Cs AWa D4e,fsD5 A0  A4 bD4e,fsD5 D0D3D3D3D3D3D3D3D3D3D3D3D1D3D3D3D3D3D3D3D3D3D3D3D2 D4A6D5 B4 (5) Hence, the total score D4A6D5 for any candidate translation corresponds to a line in the plane with  as the independent variable.",0,original
"4 Global Transliteration Modeling In global transliteration modeling, we directly model the agreement function between f and e. We follow (Collins 2002) and consider the global feature representation : F * E *  R d . 613 Each global feature corresponds to a condition on the pair of strings.",0,original
"tile data put tbrward by ll,amshaw and Marcus (1995).",0,original
"The decoder uses a binarized representation of the rules, which is obtained via a syncronous binarization procedure (Zhang et al. , 2006).",0,original
"We used a non-projective model, trained using an application of the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for the first-order Czech models, and projective parsers for all other models.",0,original
Tag test data using the POS-tagger described in Ratnaparkhi (1996).,0,original
"2 Related Work The issue of MWE processing has attracted much attention from the Natural Language Processing (NLP) community, including Smadja, 1993; Dagan and Church, 1994; Daille, 1995; 1995; McEnery et al. , 1997; Wu, 1997; Michiels and Dufour, 1998; Maynard and Ananiadou, 2000; Merkel and Andersson, 2000; Piao and McEnery, 2001; Sag et al. , 2001; Tanaka and Baldwin, 2003; Dias, 2003; Baldwin et al. , 2003; Nivre and Nilsson, 2004 Pereira et al,.",0,original
"(Wu, 1997) was an implicit or selforganizing syntax model as it did not use a Treebank.",0,original
"Our test set is 3718 sentences from the English Penn treebank (Marcus et al., 1993) which were translated into German.",0,original
"A few studies (Carpuat and Wu, 2007; Ittycheriah and Roukos, 2007; He et al., 2008; Hasan et al., 2008) addressed this defect by selecting the appropriate translation rules for an input span based on its context in the input sentence.",0,original
"5 Reliability of Annotations 5.1 The Kappa Statistic To measure the reliability of annotations we used the Kappa statistic (Carletta, 1996).",0,original
Koehn and Hoang (2007) present Factored Translation Models as an extension to phrase-based statistical machine translation models.,0,original
"IBM constraints (Berger et al., 1996), the lexical word reordering model (Tillmann, 2004), and inversion transduction grammar (ITG) constraints (Wu, 1995; Wu, 1997) belong to this type of approach.",0,original
"Word features are introduced primarily to help with unknown words, as in (Weischedel et al. 1993).",0,original
"Yarowsky (1995) tested the claim on about 37,000 examples and found that when a polysemous word appeared more than once in a discourse, they took on the majority sense for the discourse 99.8% of the time on average.",0,original
"Many methods exist for clustering, e.g., (Brown et al. , 1990; Cutting et al. , 1992; Pereira et al. , 1993; Karypis et al. , 1999).",0,original
"6.1 Hiero Results Using the MT 2002 test set, we ran the minimumerror rate training (MERT) (Och, 2003) with the decoder to tune the weights for each feature.",0,original
"Recent lexicalized stochastic parsers such as Collins (1999), Charniak (1997), and others add additional features to each constituent, the most important being the head word of the parse constituent.",0,original
"Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment (Pang et al. , 2002) andsubjectivityanalysis(Wiebeetal.",0,original
"While Liu and Gildea (2005) calculate n-gram matches on non-labelled head-modifier sequences derived by head-extraction rules from syntactic trees, we automatically evaluate the quality of translation by calculating an f-score on labelled dependency structures produced by a LexicalFunctional Grammar (LFG) parser.",0,original
"Self-training (Yarowsky, 1995) is a form of semi-supervised learning.",0,original
"2 Summary of approaches Given a source language sentence f, statistical machine translation defines the translation task as selecting the most likely target translation e under a model P(e|f), i.e.: e(f) = argmax e P(e|f) = argmax e msummationdisplay i=1 hi(e,f)i where the argmax operation denotes a search through a structured space of translation ouputs in the target language, hi(e,f) are bilingual features of e and f and monolingual features of e, and weights i are trained discriminitively to maximize translation quality (based on automatic metrics) on held out data (Och, 2003).",0,original
"Every sentence was part-of-speech tagged using a maximum entropy tagger (Ratnaparkhi, 1996) and parsed using a state-of-the-art wide coverage phrase structure parser (Collins, 1999).",0,original
"In this form, the distinction between our two models is sometimes referred to as \joint versus conditional"" (Johnson, 2001; Klein and Manning, 2002) rather than \generative versus discriminative"" (Ng and Jordan, 2002).",0,original
"Thus, Collins (2002a) also proposed an averaged perceptron, where the nal weight vector is 1Collins(2002a)alsoprovidedproofthatguaranteedgood learning for the non-separable case.",0,original
"(Collins 2002a) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels.",0,original
"A second example of subtle language dependence comes from Dasgupta and Ng (2007), who present an unsupervised morphological segmentation algorithm meant to be language-independent.",0,original
"c2006 Association for Computational Linguistics Robust PCFG-Based Generation using Automatically Acquired LFG Approximations Aoife Cahill1 and Josef van Genabith1,2 1 National Centre for Language Technology (NCLT) School of Computing, Dublin City University, Dublin 9, Ireland 2 Center for Advanced Studies, IBM Dublin, Ireland {acahill,josef}@computing.dcu.ie Abstract We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al. , 2004) automatically extracted from treebanks, maximising the probability of a tree given an f-structure.",0,original
"We use the IBM Model 1 (Brown et al. , 1993) (uniform distribution) and the Hidden Markov Model (HMM, first-order dependency, (Vogel et al. , 1996)) to estimate the alignment model.",0,original
"One could use the estimated co-occurrences from a small sample to compute the test statistics, most commonly Pearsons chi-squared test, the likelihood ratio test, Fishers exact test, cosine similarity, or resemblance (Jaccard coefficient) (Dunning 1993; Manning and Schutze 1999; Agresti 2002; Moore 2004).",0,original
"There is a vast literature on language modeling; see, e.g., (Rosenfeld, 2000; Chen and Goodman, 1999; Brants et al., 2007; Roark et al., 2007).",0,original
"It is often argued that the ability to translate discontiguous phrases is important to modeling translation (Chiang, 2007; Simard et al., 2005; Quirk and Menezes, 2006), and it may be that this explains the results.",0,original
"3 MaltParser MaltParser (Nivre et al., 2007b) is a languageindependent system for data-driven dependency parsing, based on a transition-based parsing model (McDonald and Nivre, 2007).",0,original
"3 Online Learning Again following (McDonald et al. , 2005), we have used the single best MIRA (Crammer and Singer, 2003), which is a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004) for structured prediction.",0,original
"The traditional framework presented in (Brown et al. , 1993) assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence.",0,original
"For example, the topics Sport and Education are important cues for differentiating mentions of Michael Jordan, which may refer to a basketball player, a computer science professor, etc. Second, as noted in the top WePS run (Chen and Martin, 2007), feature development is important in achieving good coreference performance.",0,original
"Comparing the LFG-based evaluation method with other popular metrics: BLEU, NIST, General Text Matcher (GTM) (Turian et al. , 2003), Translation Error Rate (TER) (Snover et al. , 2006)1, and METEOR (Banerjee and Lavie, 2005), we show that combining dependency representations with paraphrases leads to a more accurate evaluation that correlates better with human judgment.",0,original
"We used a non-projective model, trained using an application of the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for the first-order Czech models, and projective parsers for all other models.",0,original
"3 Implementation 3.1 Pronoun resolution model We built a machine learning based pronoun resolution engine using a Maximum Entropy ranker model (Berger et al., 1996), similar with Denis and Baldridges model (Denis and Baldridge, 2007).",0,original
"Some works \[Woods et al, 1972\], \[Boguraev, 1979\], \[Marcus et al. 1993\] suggested several strategies that based their 231 decision-making on the relationships existing between predicates and argumentswhat \[Katz and Fodor, 1963\] called selectional restrictions.",0,original
"When evaluated against the state-of-the-art, phrase-based decoder Pharaoh (Koehn, 2004), using the same experimental conditions  translation table trained on the FBIS corpus (7.2M Chinese words and 9.2M English words of parallel text), trigram language model trained on 155M words of English newswire, interpolation weights a65 (Equation 2) trained using discriminative training (Och, 2003) (on the 2002 NIST MT evaluation set), probabilistic beam a90 set to 0.01, histogram beam a58 set to 10  and BLEU (Papineni et al. , 2002) as our metric, the WIDL-NGLM-Aa86 a129 algorithm produces translations that have a BLEU score of 0.2570, while Pharaoh translations have a BLEU score of 0.2635.",0,original
"2 Related work Our work is closest in spirit to the two papers that inspired us (Barzilay and Lee, 2003) and (Pang et al. , 2003).",0,original
"Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003).",0,original
"For instance, the frequency collected from the data can be used to bias initial transition and emission probabilities in an HMM model; the tagged words in IGT can be used to label the resulting clusters produced by the word clustering approach; the frequent and unambiguous words in the target lines can serve as prototype examples in the prototype-driven approach (Haghighi and Klein, 2006).",0,original
"For example, in the WSJ corpus, part of the Penn Treebank 3 release (Marcus et al. , 1993), the string in (1) is a variation 12-gram since off is a variation nucleus that in one corpus occurrence is tagged as a preposition (IN), while in another it is tagged as a particle (RP).",0,original
"Unlike a full blown machine translation task (Carpuat and Wu, 2007), annotators and systems will not be required to translate the whole context but just the target word.",0,original
"Dubey et al. proposed an unlexicalized PCFG parser that modied PCFG probabilities to condition the existence of syntactic parallelism (Dubey et al. , 2006).",0,original
"On the machine-learning side, it would be interesting to generalize the ideas of large-margin classi cation to sequence models, strengthening the results of Collins (2002) and leading to new optimal training algorithms with stronger guarantees against over tting.",0,original
"3 Previous Work on Subjectivity Tagging In previous work (Wiebe et al. , 1999;; Bruce and Wiebe, 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus et al. , 1993) was manually annotated with subjectivity classi cations bymultiplejudges.",0,original
"In other words, (4b) can be used in substitution of (4a), whereas (5b) cannot, so easily 41n (Carletta, 1996), a value of K between .8 and I indicates good agreement; a value between .6 and .8 indicates some agreement.",0,original
"In Section 3 we then describe the probabilistic taxonomy learning model introduced by (Snow et al., 2006).",0,original
"It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b).",0,original
"Transformation-based learning has also been successfully applied to text chunking (Ramshaw and Marcus, 1995), morphological disambiguation (Oflazer and Tur, 1996), and phrase parsing (Vilain and Day, 1996).",0,original
"For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees.",0,original
"Coling 2008: Companion volume  Posters and Demonstrations, pages 103106 Manchester, August 2008 Range concatenation grammars for translation Anders Sgaard University of Potsdam soegaard@ling.uni-potsdam.de Abstract Positive and bottom-up non-erasing binary range concatenation grammars (Boullier, 1998) with at most binary predicates ((2,2)-BRCGs) is a O(|G|n6) time strict extension of inversion transduction grammars (Wu, 1997) (ITGs).",0,original
"The huge increase in computational and storage cost of including longer phrases does not provide a signi cant improvement in quality (Koehn et al. , 2003) as the probability of reappearance of larger phrases decreases.",0,original
"For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) with the aim of selecting the shortest paraphrase.",0,original
"Following (Ratnaparkhi 1996), we only include features which occur 5 times or more in training data.",0,original
1 Introduction The Inversion Transduction Grammar (ITG) of Wu (1997) is a syntactically motivated algorithm for producing word-level alignments of pairs of translationally equivalent sentences in two languages.,0,original
"First, two maximum entropy classifiers (Berger et al. , 1996) are applied, where the first predicts clause start labels and the second predicts clause end labels.",0,original
"4 Pattern switching The compositional translation presents problems which have been reported by (Baldwin and Tanaka, 2004; Brown et al., 1993): Fertility SWTs and MWTs are not translated by a term of a same length.",0,original
"On the one hand using 1 human reference with uniform results is essential for our methodology, since it means that there is no more trouble with Recall (Papineni et al. , 2002:314)  a systems ability to avoid under-generation of N-grams can now be reliably measured.",0,original
"Our MT system was evaluated using the n-gram based Bleu (Papineni et al. , 2002) and NIST machine translation evaluation software.",0,original
"A variety of unsupervised WSD methods, which use a machinereadable dictionary or thesaurus in addition to a corpus, have also been proposed (Yarowsky 1992; Yarowsky 1995; Karov and Edelman 1998).",0,original
"Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi (2002) in two important ways.",0,original
"We used treebank grammars induced directly from the local trees of the entire WSJ section of the Penn Treebank (Marcus et al. , 1993) (release 3).",0,original
"The average senior high school student achieves 57% correct (Turney, 2006).",0,original
"Second, phrase translation pairs are extracted from the word alignment corpus (Koehn et al. , 2003).",0,original
"(Yarowsky, 1995) used bootstrapping to train decision list classifiers to disambiguate between two senses of a word, achieving impressive classification accuracy.",0,original
"Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al., 2008).",0,original
"The de-facto answer came during the 1990s from the research community on Statistical Machine Translation, who made use of statistical tools based on a noisy channel model originally developed for speech recognition (Brown et al., 1994; Och and Weber, 1998; R.Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003).",0,original
"Many studies on collocation extraction are carried out based on co-occurring frequencies of the word pairs in texts (Choueka et al., 1983; Church and Hanks, 1990; Smadja, 1993; Dunning, 1993; Pearce, 2002; Evert, 2004).",0,original
"For the efficiency of minimum-error-rate training (Och, 2003), we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data.",0,original
"State-of-the-art statistical parsers trained on the Penn Treebank (PTB) (Marcus et al. , 1993) proS a8a8 a8a8a8 a72a72 a72a72a72 NP-SBJ a16a16a16 a80a80a80the authority VP a16a16a16 a16a16a16a16 a0 a0a0 a64 a64a64 a80a80a80 a80a80a80a80 VBD dropped PP-TMP a8a8 a72a72IN at NP NN midnight NP-TMP NNP Tuesday PP-DIR a8a8 a72a72TO to NP QP a16a16a16 a80a80a80$ 2.80 trillion Figure 1: A sample syntactic structure with function labels.",0,original
"Then, we build a classier learned by training data, using a maximum entropy model (Berger et al., 1996) and the features related to spelling variations in Table 3.",0,original
"The second alternative used BerkeleyAligner (Liang et al., 2006; DeNero and Klein, 2007), which shares information between the two alignment directions to improve alignment quality.",0,original
"Previous studies called the class of algorithms illustrated in Figure 2 cautious or sequential because in each iteration they acquire 1 or a small set of rules (Abney, 2004; Collins and Singer, 1999).",0,original
"We used the Maximum Entropy approach5 (Berger et al. , 1996) as a machine learner for this task.",0,original
"A third of the corpus is syntactically parsed as part of the Penn Treebank (Marcus et al. , 1993) 2This type corresponds to Princes (1981; 1992) inferrables.",0,original
"edu Abstract This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993).",0,original
"In most cases, supervised learning methods can perform well (Pang et al., 2002).",0,original
"These models can be tuned using minimum error rate training (Och, 2003).",0,original
"4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework (Koehn et al. , 2003; Och and Ney, 2004).",0,original
"2.1 The Evaluator The evaluator is a function p(t\[t', s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t' which precede t in the current translation of s. 1 Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al. , 1993), but it differs in one significant aspect: whereas the IBM model involves a ""noisy channel"" decomposition, we use a linear combination of separate predictions from a language model p(tlt ~) and a translation model p(tls ).",0,original
"We use the same featuresas (Koehnet al., 2003).",0,original
6.1 Reader Judgments There is a growing concern surrounding issues of intercoder reliability when using human judgments to evaluate discourse-processing algorithms (Carletta 1996; Condon and Cech 1995).,0,original
"However, as discussed in prior arts (Galley et al., 2004) and this paper, linguistically-informed SCFG is an inadequate model for parallel corpora due to its nature that only allowing child-node reorderings.",0,original
"1 Introduction The field of sentiment classification has received considerable attention from researchers in recent years (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002, Wiebe et al. 2001, Bai et al. 2004, Yu and Hatzivassiloglou 2003 and many others).",0,original
"And indeed, the agreement figures went up from K = 0.63 to K = 0.68 (ignoring doubts) when we did so, i.e., within the ""tentative"" margins of agreement according to Carletta (1996) (0.68 <_ x < 0.8).",0,original
"Second, we follow Snow et al.s work (2006) on taxonomy induction in incorporating transitive closure constraints in our probability calculations, as explained below.",0,original
"PP-model WecollectedthePPparametersbysimply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (Koehn et al. , 2003).",0,original
"Researchers extracted opinions from words, sentences, and documents, and both rule-based and statistical models are investigated (Wiebe et al. , 2002; Pang et al. , 2002).",0,original
"There are many different similarity measures, which variously use taxonomic lexical hierarchies or lexical-semantic networks, large text corpora, word definitions in machine-readable dictionaries or other semantic formalisms, or a combination of these (Dagan, Marcus, and Markovitch 1993; Kozima and Furugori 1993; Pereira, Tishby, and Lee 1993; Church et al. 1994; Grefenstette 1994; Resnik 1995; McMahon and Smith 1996; Jiang and Conrath 1997; Sch utze 1998; Lin 1998; Resnik and Diab 2000; Budanitsky 1999; Budanitsky and Hirst 2001, 2002).",0,original
"Some regarded Wikipedia as the corpora and applied hand-crafted or machine-learned rules to acquire semantic relations (Herbelot and Copestake, 2006; Kazama and Torisawa, 2007; Ruiz-casado et al., 2005; Nastase and Strube, 2008; Sumida et al., 2008; Suchanek et al., 2007).",0,original
"Collins (1997)s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al. , 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikels web page, Arabic.",0,original
"This leads to 49 methods that use semi-supervised techniques on a treebank-infered grammar backbone, such as (Matsuzaki et al., 2005; Petrov et al., 2006).",0,original
"1 Introduction In phrase-based statistical machine translation (Koehn et al., 2003) phrases extracted from word-aligned parallel data are the fundamental unit of translation.",0,original
"Measurement of B.eliability The Kappa Statistic Following Jean Carletta (1996), we use the kappa statistic (Sidney Siegel and N. John Castellan Jr. , 1988) to measure degree of agreement among subjects.",0,original
"Table 2 shows results in lowercase BLEU (Papineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and held151 out evaluation sets.",0,original
"We used MXPOST (Ratnaparkhi, 1996), and in order to discover more general patterns, we map the tag set down after tagging, e.g. NN, NNP, NNPS and NNS all map to NN.",0,original
Many other projects have used statistics in a way that summarizes facts about the text but does not draw any explicit conclusions from them (Finch and Chater 1992; Hindle 1990).,0,original
"Not only many combinations are found in the corpus, many of them have very similar mutual information values to that of 318 Table 2: economic impact verb economic financial political social budgetary ecological economic economic economic economic economic economic economic economic economic object impact impact impact impact impact impact effect implication consequence significance fallout repercussion potential ramification risk mutual freq info 171 1.85 127 1.72 46 0.50 15 0.94 8 3.20 4 2.59 84 0.70 17 0.80 59 1.88 10 0.84 7 1.66 7 1.84 27 1.24 8 2.19 17 -0.33 nomial distribution can be accurately approximated by a normal distribution (Dunning, 1993).",0,original
"We use Minimal Error Rate Training (Och, 2003) to maximize BLEU on the complete development data.",0,original
"Like the models of Goodman (1997), the additional features in our model are generated probabilistically, whereas in the parser of Collins (1997) distance measures are assumed to be a function of the already generated structure and are not generated explicitly.",0,original
"However, (Fraser and Marcu, 2007a) show that, in phrase-based translation, improvements in AER or f-measure do not necessarily correlate with improvements in BLEU score.",0,original
"While it was initially believed that lexicalization of PCFG parsers (Collins, 1997; Charniak, 2000) is crucial for obtaining good parsing results, Gildea (2001) demonstrated that the lexicalized Model-1 parser of Collins (1997) does not benefit from bilexical information when tested on a new text domain, and only marginally benefits from such information when tested on the same text domain as the training corpora.",0,original
"The model is defined mathematically (Koehn and Hoang, 2007) as following: p(f|e) = 1Zexp nsummationdisplay i=1 ihi(f,e) (1) where i is a vector of weights determined during a tuning process, and hi is the feature function.",0,original
"The word alignment models implemented in GIZA++, the so-called IBM (Brown et al., 1993) and HMM alignment models (Vogel et al., 1996) are typical implementation of the EM algorithm (Dempster et al., 1977).",0,original
"3.2 ITG Constraints In this section, we describe the ITG constraints (Wu, 1995; Wu, 1997).",0,original
"Secondly, we used the Kappa coefficient (Carletta, 1996), which has become the standard evaluation metric and the score obtained was 0.905.",0,original
"Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by (Wu, 1997) concerning parse-parse-match procedures.",0,original
"We then piped the text through a maximum entropy sentence boundary detector (Ratnaparkhi, 1996) and performed text normalization using NSW tools (Sproat et al, 2001).",0,original
"For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by Lin (1998).",0,original
"One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007).",0,original
"Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words (Yarowsky, 1992; Resnik, 1993).",0,original
"8 Conclusions In this paper, we developed probability models for the multi-level transfer rules presented in (Galley et al. , 2004), showed how to acquire larger rules that crucially condition on more syntactic context, and how to pack multiple derivations, including interpretations of unaligned words, into derivation forests.",0,original
"Zens and Ney (2003) explore the re-orderings allowed by ITGs, and provide a formulation for the number of structures that can be built for a sentence pair of size n. ITGs explore almost all of permutation space when n is small, but their coverage of permutation space falls off quickly for n > 5 (Wu, 1997).",0,original
"We present a new implication of Wus (1997) Inversion Transduction Grammar (ITG) Hypothesis, on the problem of retrieving truly parallel sentence translations from large collections of highly non-parallel documents.",0,original
"5.5 Applying F-score Optimization Technique In addition, we can simply apply the F-score optimization technique for the sequence labeling tasks proposed in (Suzuki et al. , 2006) to boost the HySOL performance since the base discriminative models pD(y|x) and discriminative combination, namely Equation (3), in our hybrid model basically uses the same optimization procedure as CRFs.",0,original
"For example, syntactic features (Ng and Cardie, 2002b; Luo and Zitouni, 2005) can be computed this way and are used in our system.",0,original
"To tune all lambda weights above, we perform minimum error rate training (Och, 2003) on the development set described in Section 7.",0,original
"Recent work has applied Bayesian non-parametric models to anaphora resolution (Haghighi and Klein, 2007), lexical acquisition (Goldwater, 2007) and language modeling (Teh, 2006) with good results.",0,original
"2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al. , 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text.",0,original
2 The Inversion Transduction Grammar The Inversion Transduction Grammar of Wu (1997) can be thought as a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar productions.,0,original
"Many of the current approaches of domain modeling collapse together different instances and make the decision on what information is important for a domain based on this generalized corpus (Collier, 1998; Barzilay and Lee, 2003; Sudo et al. , 2003).",0,original
"We used a maximummatching algorithm and a dictionary compiled from the CTB (Sproat et al. , 1996; Xue, 2001) to do segmentation, and trained a maximum entropy part-ofspeech tagger (Ratnaparkhi, 1998) and TAG-based parser (Bikel and Chiang, 2000) on the CTB to do tagging and parsing.4 Then the same feature extraction and model-training was done for the PDN corpus as for the CTB.",0,original
"This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.'s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994).",0,original
"Thus, as a powerful sequence tagging model, CRF became the dominant method in the Bakeoff 2006 (Levow, 2006).",0,original
"the syntax-based system, we ran a reimplementation of the Collins parser (Collins, 1997) on the English half of the bitext to produce parse trees, then restructured and relabeled them as described in Section 3.2.",0,original
"One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity (e.g. Riloff and Shepherd, 1997; Lin, 1998; Caraballo, 1999; Thelen and Riloff, 2002; You and Chen, 2006).",0,original
"(Chen et al. , 1993; Gale et al. , 1993) proposed sentence alignment techniques based on dynamic programming, using sentence length and lexical mapping information.",0,original
"2 Recap of BLEU, ROUGE-W and METEOR The most commonly used automatic evaluation metrics, BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002), are based on the assumption that The closer a machine translation is to a promt1: Life is like one nice chocolate in box ref: Life is just like a box of tasty chocolate ref: Life is just like a box of tasty chocolate mt2: Life is of one nice chocolate in box Figure 1: Alignment Example for ROUGE-W fessional human translation, the better it is (Papineni et al. , 2002).",0,original
"To tune the decoder parameters, we conducted minimum error rate training (Och, 2003) with respect to the word BLEU score (Papineni et al., 2002) using 2.0K development sentence pairs.",0,original
"It differs from the many approaches where (1) is defined by a stochastic synchronous grammar (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001; Eisner, 2003; Gildea, 2003; Melamed, 2004) and from transfer-based systems defined by context-free grammars (Lavie et al. , 2003).",0,original
"We can stipulate the time line to be linearly ordered (although it is not in approaches that build ignorance of relative times into the representation of time (e.g. , Hobbs, 1974) nor in approaches using branching futures (e.g. , McDermott, 1985)), and we can stipulate it to be dense (although it is not in the situation calculus).",0,original
"Fortunately, using distributional characteristics of term contexts, it is feasible to induce part-of-speech categories directly from a corpus of suf cient size, as several papers have made clear (Brown et al. , 1992; Schcurrency1utze, 1993; Clark, 2000).",0,original
"They train from the Penn Treebank (Marcus et al. , 1993); a collection of 40,000 sentences that are labeled with corrected parse trees (approximately a million word tokens).",0,original
"The second approach (Sekine et al. 1992; Chang, Luo, and Su 1992; Resnik 1993a; Grishman and Sterling 1994; Alshawi and Carter 1994) takes triples (verb, prep, noun2) and (nounl, prep, noun2), like those in Table 10, as training data for acquiring semantic knowledge and performs PP-attachment disambiguation on quadruples.",0,original
"Collins head words finder rules have been modified to extract semantic head word (Klein and Manning, 2003).",0,original
"11 However, modeling word order under translation is notoriously difficult (Brown et al. , 1993), and it is unclear how much improvement in accuracy a good model of word order would provide.",0,original
"2.3 Online Learning Again following (McDonald et al. , 2005), we have used the single best MIRA (Crammer and Singer, 2003), which is a margin aware variant of perceptron (Collins, 2002; Collins and Roark, 2004) for structured prediction.",0,original
"4.1 Data We used Penn-Treebank (Marcus et al. , 1993) data, presented in Table 1.",0,original
"4.2 Impact of Paraphrases on Machine Translation Evaluation The standard way to analyze the performance of an evaluation metric in machine translation is to compute the Pearson correlation between the automatic metric and human scores (Papineni et al. , 2002; Koehn, 2004; Lin and Och, 2004; Stent et al. , 2005).",0,original
"If the language model Pr(eI1) = p (eI1) depends on parameters and the translation model Pr(fJ1 jeI1) = p (fJ1 jeI1) depends on parameters, then the optimal parameter values are obtained by maximizing the likelihood on a parallel training corpus fS1;eS1 (Brown et al. , 1993):  = argmax SY s=1 p (fsjes) (3)  = argmax SY s=1 p (es) (4) Computational Linguistics (ACL), Philadelphia, July 2002, pp.",0,original
"In practice, texts contain an enormous number of word sequences (Brown et al. , 1992), only a tiny fraction of which are NCCs, and it takes considerable computational effort to induce each translation model.",0,original
"Following previous work on using global features of candidate structures to learn a ranking model (Collins, 2002), the global (i.e. , partition-based) features we consider here are simple functions of the local features that capture the relationship between NP pairs.",0,original
"The algorithms were trained and tested using version 3 of the Penn Treebank, using the training, development, and test split described in Collins (2002) and also employed by Toutanova et al.",0,original
"We guess it is an acronym for the authors of (Galley et al., 2004): Michel Galley, Mark Hopkins, Kevin Knight and Daniel Marcu.",0,original
"By introducing the hidden word alignment variable a  (Brown et al., 1993), the optimal translation can be searched for based on the following criterion: * 1 , arg max( ( , , )) M mm m ea eh = = efa             (1) where  is a string of phrases in the target language, e f  fa    is the source language string of phrases,  he  are feature functions, weights (, , ) m m  are typically optimized to maximize the scoring function (Och, 2003).",0,original
"By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (Koehn et al., 2003).",0,original
"pointwise mutual information (Church and Hanks, 1990), 3.",0,original
"(Berger et al. , 1996)), 1We are overloading the word state to mean Arabic word position.",0,original
"len.: median length of sequences of co-specifying referring expressions with Cohen's n (Cohen, 1960; Carletta, 1996).",0,original
"Decoding is carried-out using the Moses decoder (Koehn and Hoang, 2007).",0,original
"Approaches include word substitution systems (Brown et al. , 1993), phrase substitution systems (Koehn et al. , 2003; Och and Ney, 2004), and synchronous context-free grammar systems (Wu and Wong, 1998; Chiang, 2005), all of which train on string pairs and seek to establish connections between source and target strings.",0,original
"section 20 Majority voting (Mufioz et al. , 1999) (Tjong Kim Sang and Veenstra~ 1999) (Ramshaw and Marcus, 1995) (Argarnon et al. , 1998) accuracy precision O:98.10% C:98.29% 93.63% O:98.1% C:98.2% 93.1% 97.58% 92.50% 97.37% 91.80% 91.6% recall FZ=I 92.89% 93.26 92.4% 92.8 92.25% 92.37 92.27% 92.03 91.6% 91.6 section 00 accuracy precision Majority voting 0:98.59% C:98.65% 95.04% r (Tjong Kim Sang and Veenstra, 1999) 98.04% 93.71% (Ramshaw and Marcus, 1995) 97.8% 93.1% recall FB=I 94.75% 94.90 93.90% 93.81 93.5% 93.3 Table 3: The results of majority voting of different data representations applied to the two standard data sets put forward by (Ramshaw and Marcus, 1995) compared with earlier work.",0,original
"Word association norms, mutual information, and lexicography, Computational Linguistics, 16(1): 22-29 Marcus, M. et al. 1993.",0,original
"Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style.",0,original
"(Smadja, 1993:p.168) Kita & al.",0,original
"Motivation There have been quite a number of recent papers on parallel text: Brown et al (1990, 1991, 1993), Chen (1993), Church (1993), Church et al (1993), Dagan et al (1993), Gale and Church (1991, 1993), Isabelle (1992), Kay and Rgsenschein (1993), Klavans and Tzoukermann (1990), Kupiec (1993), Matsumoto (1991), Ogden and Gonzales (1993), Shemtov (1993), Simard et al (1992), WarwickArmstrong and Russell (1990), Wu (to appear).",0,original
"Inter-annotator agreement was assessed mainly using f-score and percentage agreement as well as 11 Table 1: Annotation examples of superlative adjectives example sup span det num car mod comp set The third-largest thrift institution in Puerto Rico also [] 22 def sg no ord 37 The Agriculture Department reported that feedlots in the 13 biggest ranch states held [] 910 def pl yes no 1112 The failed takeover would have given UAL employees 75 % voting control of the nation s second-largest airline [] 1717 pos sg no ord 1418 the kappa statistics (K), where applicable (Carletta, 1996).",0,original
"Two error rates: the sentence error rate (SER) and the word error rate (WER) that we seek to minimize, and BLEU (Papineni et al. , 2002), that we seek to maximize.",0,original
"We use the adaptation of this algorithm to structure prediction, first proposed by (Collins, 2002).",0,original
"4 Structural Correspondence Learning SCL (Structural Correspondence Learning) (Blitzer et al., 2006; Blitzer et al., 2007; Blitzer, 2008) is a recently proposed domain adaptation technique which uses unlabeled data from both source and target domain to learn correspondences between features from different domains.",0,original
"Equation (2) is rewritten as: )|()|()|( )|()|()|()|( 2211 21 ce colecolcolcolcol rrpcepcep crpcepcepcep = = (3) It is equal to a word translation model if we take the relation type in the collocations as an element like a word, which is similar to Model 1 in (Brown et al. , 1993).",0,original
"A variety of methods have been applied, ranging from simple frequency (Justeson & Katz 1995), modified frequency measures such as c-values (Frantzi, Anadiou & Mima 2000, Maynard & Anadiou 2000) and standard statistical significance tests such as the t-test, the chi-squared test, and loglikelihood (Church and Hanks 1990, Dunning 1993), and information-based methods, e.g. pointwise mutual information (Church & Hanks 1990).",0,original
"In this paper, translation quality is evaluated according to (1) the BLEU metrics which calculates the geometric mean of ngram precision by the system output with respect to reference translations (Papineni et al., 2002), and (2) the METEOR metrics that calculates unigram overlaps between translations (Banerjee and Lavie, 2005).",0,original
"NULL) Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus(1995), structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represnts each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence.",0,original
"4 Features For our experiments we use the features proposed, motivated and described in detail by (Nenkova and Louis, 2008).",0,original
"2.3 Online Learning Again following (McDonald et al. , 2005), we have used the single best MIRA (Crammer and Singer, 2003), which is a margin aware variant of perceptron (Collins, 2002; Collins and Roark, 2004) for structured prediction.",0,original
"Assuming that the corpusbased error count for some translations eS1 is additively decomposable into the error counts of the individual sentences, i.e., ED4rS1 ,eS1D5 AG EWSs AG1 ED4rs,esD5,the MERT criterion is given as: M1 AG argmin M1 AZ S F4 sAG1 EA0rs,eD4fs;M1 D5A8 B7 (3) AG argmin M1 AZ S F4 sAG1 K F4 kAG1 ED4rs,es,kD5A0eD4fs;M1 D5,es,kA8 B7 with e D4fs;M1 D5 AG argmaxe AZ M F4 mAG1 mhmD4e,fsD5 B7 (4) In (Och, 2003), it was shown that linear models can effectively be trained under the MERT criterion using a special line optimization algorithm.",0,original
"2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al. , 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002).",0,original
"3 Inversion Transduction Grammars While our approach applies in principle to a variety of machine translation systems (phrase-based or syntactic), we will use the inversion transduction grammar (ITG) approach of Wu (1997) to facilitate comparison with previous work (Zens and Ney, 2003;ZhangandGildea,2008)aswellastofocuson language model complexity.",0,original
"The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance.",0,original
"Following previous work (Ratnaparkhi, 1996), we assume that the tag of a word is independent of the tags of all preceding words given the tags of the previous two words (i.e. ,  =2 in the equation above).",0,original
The problem is due to the assumption of normality in naive frequency based statistics according to Dunning (1993).,0,original
"We discriminatively trained our parser in an on-line fashion using a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004; Crammer and Singer, 2003).",0,original
"5 Related Work Although there have been many studies on collocation extraction and mining using only statistical approaches (Church and Hanks, 1990; Ikehara et al. , 1996), there has been much less work on collocation acquisition which takes into account the linguistic properties typically associated with collocations.",0,original
Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach.,0,original
"This view is supported by Lin (2004a), who concludes that correlations to human judgments were increased by using multiple references but using single reference summary with enough number of samples was a valid alternative.",0,original
"A Broad-Coverage Word Sense Tagger Dekang Lin Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada R3T 2N2 lindek@cs.umanitoba.ca Previous corpus-based Word Sense Disambiguation (WSD) algorithms (Hearst, 1991; Bruce and Wiebe, 1994; Leacock et al. , 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1995) determine the meanings of polysemous words by exploiting their local contexts.",0,original
re-ranking 1 uses the score of the rst model as a feature in addition to the non-local features as in Collins (2002b).,0,original
"6 Conclusions and Future Directions In previous work, statistical NLP computation over large corpora has been a slow, of ine process, as in KNOWITALL (Etzioni et al. , 2005) and also in PMI-IR applications such as sentiment classi cation (Turney, 2002).",0,original
But we did not use any LM estimate to achieve early stopping as suggested by Huang and Chiang (2007).,0,original
"The method thereby retains the full set of lexical entries of phrase-based systems (e.g., (Koehn et al., 2003)).1  The model allows a straightforward integration of lexicalized syntactic language modelsfor example the models of (Charniak, 2001)in addition to a surface language model.",0,original
"It is also related to loglinear models for machine translation (Och, 2003).",0,original
"Perhaps the most related is 86 learning as search optimization (LASO) (Daume III and Marcu, 2005b; Daume III and Marcu, 2005a).",0,original
"Using the values computed above: Pl -7tl k2 P2 --= -77, 2 kl +k2 p -7z 1 .-\]'It 2 Taking these probabilities to be binomially distributed, the log likelihood statistic (Dunning, 1993) is given by: 2 log A = 2\[log L(pt, k:l, rtl) @ log L(p2, k2, rl,2) -log L(p, kl, n2) log L(p, k2, n2)\] where, log L(p, n, k) = k logp + (,z -k)log(1 p) According to this statistic, tile greater the value of -2 log A for a particular pair of observed frame and verb, the more likely that frame is to be valid SF of the verb.",0,original
"We utilize a maximum entropy (ME) model (Berger et al. , 1996) to design the basic classifier used in active learning for WSD.",0,original
"Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in (Hobbs, 1985).",0,original
"Among these methods, SVM is shown to perform better than other methods (Yang and Pedersen, 1997; Pang et al.,  1 http://people.csail.mit.edu/~jrennie/20Newsgroups/ 2 http://www.cs.cornell.edu/People/pabo/movie-review-data/ 3 http://www.seas.upenn.edu/~mdredze/datasets/sentiment/  2002).",0,original
"For example, (Spertus, 1997) developed a system to identify inflammatory texts and (Turney, 2002; Pang et al. , 2002) developed methods for classifying reviews as positive or negative.",0,original
"We compare TERp with BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006).",0,original
"(2007): The committee consists of k = 3 Maximum Entropy (ME) classifiers (Berger et al., 1996).",0,original
"(Ramshaw and Marcus, 1995) represent chunking as tagging problem and the CoNLL2000 shared task (Kim Sang and Buchholz, 2000) is now the standard evaluation task for chunking English.",0,original
"(1980), Walker (1978), Fink and Biermann (1986), Mudler and Paulus (1988), Carbonell and Pierrel (1988), Young (1990), and Young et al.",0,original
"A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training (Och, 2003).",0,original
"Exact Decoding is the original decoding problem as defined in (Brown et al. , 1993) and Relaxed Decoding is the relaxation of the decoding problem typically used in practice.",0,original
"Thus the alignment set is denoted as }&],1[|),{( ialiaiA ii = . We adapt the bilingual word alignment model, IBM Model 3 (Brown et al., 1993), to monolingual word alignment.",0,original
"(2004)), better language-specific preprocessing (Koehn and Knight, 2003) and restructuring (Collins et al. , 2005), additional feature functions such as word class language models, and minimum error rate training (Och, 2003) to optimize parameters.",0,original
"Unfortunately, as shown in (Okanohara and Tsujii, 2007), with the represetation of sentences that we use, linear classifiers cannot discriminate real sentences from sentences sampled from a trigram, which is the model we use as a baseline, so here we resort to a non-linear large-margin classifier (see section 3 for details).",0,original
"First, we can let the number of nonterminals grow unboundedly, as in the Infinite PCFG, where the nonterminals of the grammar can be indefinitely refined versions of a base PCFG (Liang et al., 2007).",0,original
"Their weights are calculated by deleted interpolation (Brown et al. , 1992).",0,original
"4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis (Marcu and Echihabi, 2002; Lapata, 2003; Elsner et al. , 2007).",0,original
"2.2 Global Linear Models We follow the framework of Collins (2002; 2004), recently applied to language modeling in Roark et al.",0,original
"what does student want to write your Figure 3: A derivation tree of lexicalized parse trees, such as the distinction of arguments/modifiers and unbounded dependencies (Collins, 1997), are elegantly represented in derivation trees.",0,original
"The sequential classi cation approach can handle many correlated features, as demonstrated in work on maximum-entropy (McCallum et al. , 2000; Ratnaparkhi, 1996) and a variety of other linear classi ers, including winnow (Punyakanok and Roth, 2001), AdaBoost (Abney et al. , 1999), and support-vector machines (Kudo and Matsumoto, 2001).",0,original
"To perform code generalization, Li adopted to Smadjas work (Smadja, 1993) and defined the code strength using a code frequency and a standard deviation in each level of the concept hierarchy.",0,original
"These distributions are modeled using a maximum entropy formulation (Berger et al. , 1996), using training data which consists of human judgments of question answer pairs.",0,original
"The first work in SMT, done at IBM (Brown et al. , 1993), developed a noisy-channel model, factoring the translation process into two portions: the translation model and the language model.",0,original
"Figure 1 exhibits this scenario with a typical IE system such as SRI's FASTUS system (Hobbs et al. , 1996).",0,original
"Syntactic criteria are relevant, but clearly not decisive, as can be observed in (Marcu and Echihabi, 2002).",0,original
"2.5 Evaluation Minnen and Carroll (Under review) report an evaluation of the accuracy of the morphological generator with respect to the CELEX lexical database (version 2.5; Baayen et al. , 1993).",0,original
Online discriminative training has already been studied by Tillmann and Zhang (2006) and Liang et al.,0,original
"We use a hand-written competence grammar, combined with performance-driven disambiguation obtained from the Penn Treebank (Marcus et al. , 1993).",0,original
"We attribute the difference in M3/4 scores to the fact we use a Viterbi-like training procedure (i.e. , we consider a single configuration of the hidden variables in EM training) while GIZA uses pegging (Brown et al. , 1993) to sum over a set of likely hidden variable configurations in EM.",0,original
"We should note, however, that most other stochastic parsers do include counts of single nonheadwords: they appear in the backed-off statistics of these parsers (see Collins 1997, 1999; Charniak 1997; Goodman 1998).",0,original
"234 ADV Non-specific adverbial BNF Benefemtive CLF It-cleft CLR 'Closely related' DIR Direction DTV Dative EXT Extent HLN Headline LGS Logical subject L0C Location MNI~ Manner N0M Nominal PRD Predicate PRP Purpose PUT Locative complement of 'put' SBJ Subject TMP Temporal TPC Topic TTL Title V0C Vocative Grammatical DTV 0.48% LGS 3.0% PRD 18.% PUT 0.26% SBJ 78.% v0c 0.025% Figure 1: Penn treebank function tags 53.% Form/Function 37.% Topicalisation 2.2% 0.25% NOM 6.8% 2.5% TPC 100% 2.2% 1.5% ADV 11.% 4.2% 9.3% BN'F 0.072% 0.026% 0.13% DIR 8.3% 3.0% 41.% EXT 3.2% 1.2% 0.013% LOC 25.% 9.2% MNR 6.2% 2.3% PI~ 5.2% 1.9% 33.% 12.% Miscellaneous 9.5% CLR 94.% 8.8% CLF 0.34% 0.03% HLN 2.6% 0.25% TTL 3.1% 0.29% Figure 2: Categories of function tags and their relative frequencies one project that used them at all: (Collins, 1997) defines certain constituents as complements based on a combination of label and function tag information.",0,original
"Several techniques and results have been reported on learning subcategorization frames (SFs) from text corpora (Webster and Marcus, 1989; Brent, 1991; Brent, 1993; Brent, 1994; Ushioda et al. , 1993; Manning, 1993; Ersan and Charniak, 1996; Briscoe and Carroll, 1997; Carroll and Minnen, 1998; Carroll and Rooth, 1998).",0,original
"In parsing, the most relevant previous work is due to Collins (1997), who considered three binary features of the intervening material: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons?",0,original
"5.3 Analysis of BF-LM framework We refer to (Talbot and Osborne, 2007) for empirical results establishing the performance of the logfrequency BF-LM: overestimation errors occur with 474 0.01 0.025 0.05 0.1 0.25 0.5 0.03 0.02 0.01 0.005 0.0025 0.001 Mean squared error of log probabilites Memory in GB MSE between WB 3-gram SRILM and BF-LMs Base 3 Base 1.5 Base 1.1 Figure 5: MSE between SRILM and BF-LMs 22 23 24 25 26 27 28 29 30 0.01 0.1 1 BLEU Score Mean squared error WB-smoothed BF-LM 3-gram model BF-LM base 1.1 BF-LM base 1.5 BF-LM base 3 Figure 6: MSE vs. BLEU for WB 3-gram BF-LMs a probability that decays exponentially in the size of the overestimation error.",0,original
"Successful discriminative parsers have relied on generative models to reduce training time and raise accuracy above generative baselines (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004).",0,original
"3 Method 3.1 Standard text classication approach We take our starting point from topic-based text classication (Dumais et al., 1998; Joachims, 1998) and sentiment classication (Turney, 2002; Pang and Lee, 2008).",0,original
"For the multilingual dependency parsing track, which was the other track of the shared task, Nilsson et al. achieved the best performance using an ensemble method (Hall et al., 2007).",0,original
"Our evaluation metric is BLEU (Papineni et al., 2002).",0,original
"The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al. , 1993; Ney et al. , 2000).",0,original
"Klein and Manning (2002) argue for CL on grounds of accuracy, but see also Johnson (2001).",0,original
"In none of these cases did we repeat minimum-error-rate training; all these systems were trained using max-B. The metrics we tested were:  METEOR (Banerjee and Lavie, 2005), version 0.6,usingtheexact,Porter-stemmer,andWordNet synonmy stages, and the optimized parameters  = 0.81,  = 0.83,  = 0.28 as reported in (Lavie and Agarwal, 2007).",0,original
"Decoding time of our experiments (h means hours)  language model for rescoring (Huang and Chiang, 2007).",0,original
"6 Related Work A description of the IBM models for statistical machine translation can be found in (Brown et al. , 1993).",0,original
"291 3.1 Level of Analysis Research on sentiment annotation is usually conducted at the text (Aue and Gamon, 2005; Pang et al., 2002; Pang and Lee, 2004; Riloff et al., 2006; Turney, 2002; Turney and Littman, 2003) or at the sentence levels (Gamon and Aue, 2005; Hu and Liu, 2004; Kim and Hovy, 2005; Riloff et al., 2006).",0,original
"This set of 800 sentences was used for Minimum Error Rate Training (Och, 2003) to tune the weights of our system with respect to BLEU score.",0,original
"3.2 Maximum Entropy ME models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible (Berger et al. , 1996).",0,original
"(2003), bilingual sentences are trained by GIZA++ (Och and Ney 2003) in two directions (from source to target and target to source).",0,original
"For example, both papers propose minimum-risk decoding, and McDonald and Satta (2007) discuss unsupervised learning and language modeling, while Smith and Smith (2007) define hiddenvariable models based on spanning trees.",0,original
Method Correlation Edge-counting 0.664 Jiang & Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al.,0,original
"2.4 GermanEnglish For GermanEnglish, we additionally incorporated rule-based reordering  We parse the input using the Collins parser (Collins, 1997) and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order (Collins et al., 2005).",0,original
"3The usefulness of position varies significantly in different genres (Penn and Zhu, 2008).",0,original
"Reranking methods have also been proposed as a method for using syntactic information (Koehn and Knight, 2003; Och et al. , 2004; Shen et al. , 2004).",0,original
"6 Results We trained on the standard Penn Treebank WSJ corpus (Marcus et al., 1993).",0,original
"1 A cept is defined as the set of target words connected to a source word (Brown et al. , 1993).",0,original
"If the alignments are not available, they can be automatically generated; e.g., using GIZA++ (Och and Ney, 2003).",0,original
"Although some early systems for web-page analysis induce rules at character-level (e.g., such as WIEN (Kushmerick et al., 1997) and DIPRE (Brin, 1998)), most recent approaches for set expansion have used either tokenized and/or parsed free-text (Carlson et al., 2009; Talukdar et al., 2006; Snow et al., 2006; Pantel and Pennacchiotti, 2006), or have incorporated heuristics for exploiting HTML structures that are likely to encode lists and tables (Nadeau et al., 2006; Etzioni et al., 2005).",0,original
"Salience Feature Pronoun Name Nominal TOP 0.75 0.17 0.08 HIGH 0.55 0.28 0.17 MID 0.39 0.40 0.21 LOW 0.20 0.45 0.35 NONE 0.00 0.88 0.12 Table 2: Posterior distribution of mention type given salience (taken from Haghighi and Klein (2007)) 3.3 Modifications to the H&K Model Next, we discuss the potential weaknesses of H&Ks model and propose three modifications to it.",0,original
"Let w be a target word and Nw = fn1,n2nkg be the ordered set of the top scoring k neighbours of w from the thesaurus with associated distributional similarity scores fdss(w,n1),dss(w,n2),dss(w,nk)g using (Lin, 1998).",0,original
"MT output was evaluated using the standard evaluation metric BLEU (Papineni et al. , 2002).2 The parameters of the MT System were optimized for BLEU metric on NIST MTEval2002 test sets using minimum error rate training (Och, 2003), and the systems were tested on NIST MTEval2003 test sets for both languages.",0,original
"Table 2: Corpora and Modalities CORPUS MODALITY ACE asserted, or other TIMEML must, may, should, would, or could Prasad et al., 2006 assertion, belief, facts or eventualities Saur et al., 2007 certain, probable, possible, or other Inui et al., 2008 affirm, infer, doubt, hear, intend, ask, recommend, hypothesize, or other THIS STUDY S/O, necessity, hope, possible, recommend, intend   Table 3: Markup Scheme (Tags and Definitions) Tag Definition (Examples) R Remedy, Medical operation (e.g. radiotherapy) T Medical test, Medical examination (e.g., CT, MRI) D Deasese, Symptom (e.g., Endometrial cancer, headache) M Medication, administration of a drug (e.g., Levofloxacin, Flexeril) A patient action (e.g., admitted to a hospital) V Other verb (e.g., cancer spread to )   2 Related Works 2.1 Previous Markup Schemes In the NLP field, fact identification has not been studied well to date.",0,original
"However, developing the PDTB may help facilitate the production of more such corpora, through an initial pass of automatic annotation, followed by manual correction, much as was done in developing the PTB (Marcus et al. , 1993).)",0,original
"Not unlike (Yarowsky, 1995) we use confidence of our classifier on unannotated data to enrich itself; that is, by adding confidently-classified instances to the memory.",0,original
"In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections.",0,original
"The training samples are respectively used to create the models PT^G, PCHUNK, PBUILD, and PCMECK, all of which have the form: k p(a, b) = II _ij(o,b ~j (1) j----1 where a is some action, b is some context, ~"" is a nor4 Model Categories Description Templates Used TAG See (Ratnaparkhi, 1996) CHUNK chunkandpostag(n)* BUILD CHECK chunkandpostag(m, n)* cons(n) cons(re, n)* cons(m, n,p) T punctuation checkcons(n)* checkcons(m,n)* production surround(n)* The word, POS tag, and chunk tag of nth leaf.",0,original
"2 Automatic Annotation Schemes Using ROUGE Similarity Measures ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is an automatic tool to determine the quality of a summary using a collection of measures ROUGE-N (N=1,2,3,4), ROUGE-L, ROUGE-W and ROUGE-S which count the number of overlapping units such as n-gram, word-sequences, and word-pairs between the extract and the abstract summaries (Lin, 2004).",0,original
"We retrained the parser on lowercased Penn Treebank II (Marcus et al. , 1993), to match the lowercased output of the MT decoder.",0,original
We borrow this useful term from the Core Language Engine project (Alshawi et al. 1988; 1989).,0,original
"The trigger-based lexicon model used in this work follows the training procedure introduced in (Hasan et al., 2008) and is integrated directly in the decoder instead of being applied in n-best list reranking.",0,original
"As our approach for incorporating unlabeled data, we basically follow the idea proposed in (Suzuki et al., 2007).",0,original
Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis.,0,original
"2 Phrase-based Statistical MT Our baseline is a standard phrase-based SMT system (Koehn et al. , 2003).",0,original
"1 Introduction Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al. , 2003).",0,original
"Online baselines include Top-1 Perceptron (Collins, 2002), Top-1 Passive-Aggressive (PA), and k-best PA (Crammer & Singer, 2003; McDonald et al., 2004).",0,original
"Also, on WS-353, our hybrid sense-filtered variants and word-cos-ll obtained a correlation score higher than published results using WordNet-based measures (Jarmasz and Szpakowicz, 2003) (.33 to .35) and Wikipediabased methods (Ponzetto and Strube, 2006) (.19 to .48); and very close to the results obtained by thesaurus-based (Jarmasz and Szpakowicz, 2003) (.55) and LSA-based methods (Finkelstein et al., 2002) (.56).",0,original
"1 Introduction Word alignment, which can be defined as an object for indicating the corresponding words in a parallel text, was first introduced as an intermediate result of statistical translation models (Brown et al. , 1993).",0,original
"According to the document, it is the output of Ratnaparkhis tagger (Ratnaparkhi, 1996).",0,original
"The POS data set and the CTS data set have previously been used for testing other adaptation methods (Daume III and Marcu, 2006; Blitzer et al. , 2006), though the setup there is different from ours.",0,original
"To evaluate the performance of a parser, NP chunks can usefully be evaluated by a gold standard; many systems (e.g. , Ramshaw and Marcus 1995 and Cardie and Pierce 1988) use the Penn Treebank for this type of evaluation.",0,original
"(See also Kaplan et al. , 1988, on the latter point).",0,original
"Other methods that have been proposed are one based on using the gain (Berger et al. , 1996) and an approximate method for selecting informative features (Shirai et al. , 1998a), and several criteria for feature selection were proposed and compared with other criteria (Berger and Printz, 1998).",0,original
Our method uses assumptions similar to Berger et al. 1996 but is naturally suitable for distributed parallel computations.,0,original
We used the same 58 feature types as Ratnaparkhi (1996).,0,original
"Parse selection constitutes an important part of many parsing systems (Johnson et al., 1999; Hara et al., 2005; van Noord and Malouf, 2005; McClosky et al., 2006).",0,original
"In his analysis of Yarowsky (1995), Abney (2004) formulates several variants of bootstrapping.",0,original
"To optimize the parameters of the decoder, we performed minimum error rate training on IWSLT04 optimizing for the IBM-BLEU metric (Papineni et al., 2002).",0,original
"Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models (HMMs) (Bikel et al. , 1997), the dictionary HMM model (Kou et al. , 2005) and Maximum Entropy Markov Models (MEMMs) (Finkel et al. , 2004).",0,original
"Several authors (for example, Krovetz and Croft \[1989\], Guthrie et al. \[1991\], Slator \[1992\], Cowie, Guthrie, and Guthrie \[1992\], Janssen \[1992\], Braden-Harder \[1993\], Liddy and Paik \[1993\]) have attempted to improve results by using supplementary fields of information in the electronic version of the Longman Dictionary of Contemporary English (LDOCE), in particular, the box codes and subject codes provided for each sense.",0,original
"The Maximum Entropy model (Berger et al., 1996; Ratnaparkhi, 1997; Abney, 1997) is a conditional model that assigns a probability to every possible parse  for a given sentence s. The model consists of a set of m feature functions fj() that describe properties of parses, together with their associated weights j. The denominator is a normalization term where Y (s) is the set of parses with yield s: p(|s;) = exp( summationtextm j=1 jfj())summationtext yY (s) exp( summationtextm j=1 jfj(y))) (1) The parameters (weights) j can be estimated efficiently by maximizing the regularized conditional likelihood of a training corpus (Johnson et al., 1999; van Noord and Malouf, 2005):  = argmax  logL()  summationtextm j=1  2j 22 (2) where L() is the likelihood of the training data.",0,original
"While this technique has been sttccessfully applied to parsing lhe ATIS portion in the Penn Treebank (Marcus et al. 1993), it is extremely time consuming.",0,original
"Translation rules can:  look like phrase pairs with syntax decoration: NPB(NNP(prime) NNP(minister) NNP(keizo) NNP(obuchi)) BUFDFKEUBWAZ  carry extra contextual constraints: VP(VBD(said) x0:SBAR-C) DKx0 (according to this rule, DK can translate to said only if some Chinese sequence to the right ofDK is translated into an SBAR-C)  be non-constituent phrases: VP(VBD(said) SBAR-C(IN(that) x0:S-C)) DKx0 VP(VBD(pointed) PRT(RP(out)) x0:SBAR-C) DXGPx0  contain non-contiguous phrases, effectively phrases with holes: PP(IN(on) NP-C(NPB(DT(the) x0:NNP)) NN(issue)))) GRx0 EVABG6 PP(IN(on) NP-C(NPB(DT(the) NN(issue)) x0:PP)) GRx0 EVEVABABG6  be purely structural (no words): S(x0:NP-C x1:VP)x0 x1  re-order their children: NP-C(NPB(DT(the) x0:NN) PP(IN(of) x1:NP-C)) x1 DFx0 Decoding with this model produces a tree in the target language, bottom-up, by parsing the foreign string using a CYK parser and a binarized rule set (Zhang et al. , 2006).",0,original
"Several authors have used mutual information and similar statistics as an objective function for word clustering (Dagan et al. , 1993; Brown et al. , 1992; Pereira et al. , 1993; Wang et al. , 1996), for automatic determination of phonemic baseforms (Lucassen & Mercer, 1984), and for language modeling for speech recognition (Ries ct al. , 1996).",0,original
"The annotation scheme (Skut et al. , 1997) is modeled to a certain extent on that of the Penn Treebank (Marcus et al. , 1993), with crucial differences.",0,original
"Similarly to (Galley et al. , 2004), the tree-to-string alignment templates discussed in this paper are actually transformation rules.",0,original
Ramshaw and Marcus (1995) approached chunking by using a machine learning method.,0,original
"(1990, 1993), these models have non-uniform linguistically motivated structure, at present coded by hand.",0,original
"To compute the degree of interaction between two proteins D4 BD and D4 BE, we use the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and Schutze, 1999), which is computed based on the following quantities: 1.",0,original
"This is similar to work by several other groups which aims to induce semantic classes through syntactic co-occurrence analysis (Riloff and Jones, 1999; Pereira et al. , 1993; Dagan et al. , 1993; Hirschman et al. , 1975), although in .our case the contexts are limited to selected patterns, relevant to the scenario.",0,original
"2 Detecting Discourse-New Definite Descriptions 2.1 Vieira and Poesio Poesio and Vieira (1998) carried out corpus studies indicating that in corpora like the Wall Street Journal portion of the Penn Treebank (Marcus et al. , 1993), around 52% of DDs are discourse-new (Prince, 1992), and another 15% or so are bridging references, for a total of about 66-67% firstmention.",0,original
"This contrasts with alternative alignment models such as those of Melamed (1998) and Wu (1997), which impose a one-to-one constraint on alignments.",0,original
"To tackle this problem, we defined 2The best results of Collins and Roark (2004) (LR=88.4%, LP=89.1% and F=88.8%) are achieved when the parser utilizes the information about the final punctuation and the look-ahead.",0,original
"In particular, we adopt the approach of phrase-based statistical machine translation (Koehn et al., 2003; Koehn and Hoang, 2007).",0,original
"More recently, other approaches have investigated the use of machine learning to nd patterns in documents(Strzalkowski et al. , 1998) and the utility of parameterized modules so as to deal with dierent genres or corpora(Goldstein et al. , 2000).",0,original
"Similarly, Smadja (1993) uses a six content word window to extract significant collocations.",0,original
"An especially well-founded framework for doing this is maximum entropy (Berger et al. , 1996).",0,original
"Several non-linear objective functions, such as F-score for text classification (Gao et al. , 2003), and BLEU-score and some other evaluation measures for statistical machine translation (Och, 2003), have been introduced with reference to the framework of MCE criterion training.",0,original
"Because their joint distributions have such closed-form expressions, the parameters can be estimated directly from the training data without the need for an iterative fitting procedure (as is required, for example, to estimate the parameters of maximum entropy models; (Berger et al. , 1996)).",0,original
"And third, 1This (Ramshaw and Marcus, 1995) baseNP data set is available via ftp://ftp.cis.upenn.edu/pub/chunker/ 2Software for generating the data is available from http://lcg-www.uia.ac.be/conl199/npb/ 50 with the FZ=I rate which is equal to (2*precision*recall)/(precision+recall).",0,original
"It is true that various term extraction systems have been developed, such as Xtract (Smadja 1993), Termight (Dagan & Church 1994), and TERMS (Justeson & Katz 1995) among others (cf.",0,original
"This new model leads to significant improvements in MT quality as measured by BLEU (Papineni et al. , 2002).",0,original
"Following (Langkilde, 2002) and other work on general-purpose generators, we adopt BLEU score (Papineni et al., 2002), average simple string accuracy (SSA) and percentage of exactly matched sentences for accuracy evaluation.6 For coverage evaluation, we measure the percentage of input fstructures that generate a sentence.",0,original
"This is in line with earlier work on consistent estimation for similar models (Zollmann and Simaan, 2006), and agrees with the most up-to-date work that employs Bayesian priors over the estimates (Zhang et al., 2008).",0,original
"When evaluated against the state-of-the-art, phrase-based decoder Pharaoh (Koehn, 2004), using the same experimental conditions  translation table trained on the FBIS corpus (7.2M Chinese words and 9.2M English words of parallel text), trigram language model trained on 155M words of English newswire, interpolation weights a65 (Equation 2) trained using discriminative training (Och, 2003) (on the 2002 NIST MT evaluation set), probabilistic beam a90 set to 0.01, histogram beam a58 set to 10  and BLEU (Papineni et al. , 2002) as our metric, the WIDL-NGLM-Aa86 a129 algorithm produces translations that have a BLEU score of 0.2570, while Pharaoh translations have a BLEU score of 0.2635.",0,original
"The data consists of 2,544 main clauses from the Wall Street Journal Treebank corpus (Marcus et al. , 1993).",0,original
"We finally also include as alignment candidates those word pairs that are transliterations of each other to cover rare proper names (Hermjakob et al., 2008), which is important for language pairs that dont share the same alphabet such as Arabic and English.",0,original
"Various approaches to word sense division have been proposed in the literature on WSD, including (1) sense numbers in every-day dictionaries (Lesk 1986; Cowie, Guthrie, and Guthrie 1992), (2) automatic or hand-crafted clusters of dictionary senses (Dolan 1994; Bruce and Wiebe 1995; Luk * Department of Computer Science, National Tsing Hua University, Hsinchu 30043, Taiwan, ROC.",0,original
"Church and Hanks 1990; Klavans, Chodorow, and Wacholder 1990; Wilks et al. 1993; Smadja 1991a, 1991b; Calzolari and Bindi 1990).",0,original
Our approach thus provides an even more extreme version of automatic con rmation generation than that used byChu-Carroll and Carpenter (1999) where only a small eort is required by the developer.,0,original
"As we noted in Section 5, we are able to significantly outperform basic structural correspondence learning (Blitzer et al. , 2006).",0,original
"We used four different system summaries for each of the 6 meetings: one based on the MMR method in MEAD (Carbonell and Goldstein, 1998; et al., 2003), the other three are the system output from (Galley, 2006; Murray et al., 2005; Xie and Liu, 2008).",0,original
"It combines online Peceptron learning (Collins, 2002) with a parsing model based on the Eisner algorithm (Eisner, 1996), extended so as to jointly assign syntactic and semantic labels.",0,original
"This approach is similar to that of seed words (e.g., (Hearst, 1998)) or hook words (e.g., (Davidov and Rappoport, 2008)) in previous work.",0,original
"We present two approaches to SMT-based query expansion, both of which are implemented in the framework of phrase-based SMT (Och and Ney, 2004; Koehn et al. , 2003).",0,original
"Finally, methods in the literature more focused on a specific disambiguation task include statistical methods for the attachment of hyponyms under the most likely hypernym in the WordNet taxonomy (Snow et al., 2006), structural approaches based on semantic clusters and distance metrics (Pennacchiotti and Pantel, 2006), supervised machine learning methods for the disambiguation of meronymy relations (Girju et al., 2003), etc. 6 Conclusions In this paper we presented a novel approach to disambiguate the glosses of computational lexicons and machine-readable dictionaries, with the aim of alleviating the knowledge acquisition bottleneck.",0,original
"Nevertheless, EM sometimes fails to find good parameter values.2 The reason is that EM tries to assign roughly the same number of word tokens to each of the hidden states (Johnson, 2007).",0,original
"a22 a14 is the sufficient statistic of a16 a14 . Then, we can rewrite a2a24a3 a10a27 a42a7 a25 as: a5a7a6a9a8a11a10 a23 a3 a10 a7 a15 a27 a25a18a17a26a25 a12a28a27 a5a7a6a29a8a30a10 a23 a3 a10 a7 a15 a27 a25a18a17 . 3 Loss Functions for Label Sequences Given the theoretical advantages of discriminative models over generative models and the empirical support by (Klein and Manning, 2002), and that CRFs are the state-of-the-art among discriminative models for label sequences, we chose CRFs as our model, and trained by optimizing various objective functions a31 a3 a10a36 a25 with respect to the corpus a36 . The application of these models to the label sequence problems vary widely.",0,original
"The grammars were induced from sections 2-21 of the Penn Wall St. Journal Treebank (Marcus et al. , 1993), and tested on section 23.",0,original
"For the evaluation of translation quality, we applied standard automatic evaluation metrics, i.e., BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005).",0,original
"Here, we train word alignments in both directions with GIZA++ (Och and Ney, 2003).",0,original
"Note that using stems and their synonyms as used in METEOR (Banerjee and Lavie, 2005) could also be considered for word similarity.",0,original
"1 Introduction Sentiment detection and classification has received considerable attention recently (Pang et al. , 2002; Turney, 2002; Goldberg and Zhu, 2004).",0,original
"Identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. Sentiment detection is the task of determining positive or negative sentiment of words (Hatzivassiloglou and McKeown, 1997; Turney, 2002; Esuli and Sebastiani, 2005), phrases and sentences (Kim and Hovy, 2004; Wilson et al. , 2005), or documents (Pang et al. , 2002; Turney, 2002).",0,original
"First, researchers are divided between a general method (that attempts to apply WSD to all the content words of texts, the option taken in this paper) and one that is applied only to a small trial selection of texts words (for example (Schiitze, 1992) (Yarowsky, 1995)).",0,original
"In information retrieval, word similarity can be used to identify terms for pseudo-relevance feedback (Harman, 1992; Buckley et al. , 1995; Xu and Croft, 2000; Vechtomova and Robertson, 2000).",0,original
"594 2.3 Viterbi Approximation To approximate the intractable decoding problem of (2), most MT systems (Koehn et al., 2003; Chiang, 2007) use a simple Viterbi approximation, y = argmax yT(x) pViterbi(y|x) (4) = argmax yT(x) max dD(x,y) p(y,d|x) (5) = Y parenleftBigg argmax dD(x) p(y,d|x) parenrightBigg (6) Clearly, (5) replaces the sum in (2) with a max.",0,original
"From multilingual texts, translation lexica can be generated (Gale and Church 1991; Kupiec 1993; Kumano and Hirakawa 1994; Boutsis, Piperidis, and Demiros 1999; Grefenstette 1999).",0,original
"This includes the automatic generation of sense-tagged data using monosemous relatives (Leacock et al. , 1998; Mihalcea and Moldovan, 1999; Agirre and Martinez, 2004), automatically bootstrapped disambiguation patterns (Yarowsky, 1995; Mihalcea, 2002), parallel texts as a way to point out word senses bearing different translations in a second language (Diab and Resnik, 2002; Ng et al. , 2003; Diab, 2004), and the use of volunteer contributions over the Web (Chklovski and Mihalcea, 2002).",0,original
"The more recent set of techniques includes mult iplicative weightupdate algorithms (Golding and Roth, 1998), latent semantic analysis (Jones and Martin, 1997), transformation-based learning (Mangu and Brill, 1997), differential grammars (Powers, 1997), decision lists (Yarowsky, 1994), and a variety of Bayesian classifiers (Gale et al. , 1993, Golding, 1995, Golding and Schabes, 1996).",0,original
"These results confirm the observed figures in the previous subsection and reinforce the sight that clustering is a worthless effort for automatic paraphrase corpora construction, contrarily to what (Barzilay & Lee, 2003) suggest.",0,original
"Its applications range from sentence boundary disambiguation (Reynar and Ratnaparkhi, 1997) to part-of-speech tagging (Ratnaparkhi, 1996), parsing (Ratnaparkhi, 1997) and machine translation (Berger et al. , 1996).",0,original
"For an HMM with a set of states T and a set of output symbols V : t  T t  Dir(1,|T|) (1) t  T t  Dir(1,|V |) (2) ti|ti1, ti1  Multi(ti1) (3) wi|ti, ti  Multi(ti) (4) One advantage of the Bayesian approach is that the prior allows us to bias learning toward sparser structures, by setting the Dirichlet hyperparameters , to a value less than one (Johnson, 2007; Goldwater and Griffiths, 2007).",0,original
"Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al. , 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source.",0,original
"The dataset is available only in English and has been widely used in previous semantic relatedness evaluations (e.g., (Resnik, 1995; Hughes and Ramage, 2007; Zesch et al., 2008)).",0,original
Minimum-error-rate training was done using Koehns implementation of Ochs (2003) minimum-error-rate model.,0,original
"This is analogous, and in a certain sense equivalent, to empirical risk minimization, which has been used successfully in related areas, such as speech recognition (Rahim and Lee, 1997), language modeling (Paciorek and Rosenfeld, 2000), and machine translation (Och, 2003).",0,original
"MTTK provides implementations of various alignment, models including IBM Model-1, Model-2 (Brown et al. , 1993), HMM-based word-to-word alignment model (Vogel et al. , 1996; Och and Ney, 2003) and HMM-based word-to-phrase alignment model (Deng and Byrne, 2005).",0,original
"Obtained percent agreement of 0.988 and  coefficient (Carletta, 1996) of 0.975 suggest high convergence of both annotations.",0,original
"Since part of the chunking errors could be caused by POS errors, we also compared the same baseNP chunker on the santo corpus tagged with i) the Brill tagger as used in \[Ramshaw and Marcus, 1995\], ii) the Memory-Based Tagger (MBT) as described in \[Daelemans et al. , 1996\].",0,original
"Bikel and Chiang (2000) in fact contains two parsers: one is a lexicalized probabilistic contextfree grammar (PCFG) similar to (Collins, 1997); the other is based on statistical TAG (Chiang, 2000).",0,original
"Since a handmade thesaurus is not slfitahle for machine use, and expensive to compile, automatical construction of~a thesaurus has been attempted using corpora (Hindle, 1990).",0,original
2 Machine Translation using Inversion Transduction Grammar The Inversion Transduction Grammar (ITG) of Wu (1997) is a type of context-free grammar (CFG) for generating two languages synchronously.,0,original
"The evaluation metric is casesensitive BLEU-4 (Papineni et al., 2002).",0,original
"Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals (Groves et al. , 2004; Chiang, 2005), or, given a constraining parse tree, to flatten it (Fox, 2002; Zens and Ney, 2003; Galley et al. , 2004).",0,original
"A superset of the parallel data was word aligned by GIZA union (Och and Ney, 2003) and EMD (Fraser and Marcu, 2006).",0,original
Our intuition comes from an observation by Yarowsky (1995) regarding multiple tokens of words in documents.,0,original
"As to analysis of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences (Collins and Roark, 2004; McDonald et al., 2005), and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available.",0,original
"This merging of contexts is different than clustering words (e.g., Clark, 2000; Brown et al., 1992), but is applicable, as word clustering relies on knowing which contexts identify the same category.",0,original
"Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993).",0,original
"To obtain these distances, Ratnaparkhis partof-speech (POS) tagger (Ratnaparkhi, 1996) and Collins parser (Collins, 1999) were used to obtain parse trees for the English side of the test corpus.",0,original
"Chu-Carroll and Carpenter (1999) describe a method of disambiguation, where disambiguation questions are dynamically constructed on the basis of an analysis of the differences among the closest routing destination vectors.",0,original
Wu (1997) introduced constraints on alignments using a probabilistic synchronous context-free grammar restricted to Chomskynormal form.,0,original
"In (Tillmann and Zhang, 2006) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU.",0,original
"Their transliteration probability is: P(t|s)  PE(s|t)max[PT(t),PL(t)] (1) Inspired by the linear models used in SMT (Och, 2003), we can discriminatively weight the components of this generative model, producing: wE logPE(s|t)+wT logPT(t)+wL logPL(t) with weights w learned by perceptron training.",0,original
"415-458, Wu, Dekai (1997) Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.",0,original
"Since we need knowledge-poor Daille, 1996) induction, we cannot use human-suggested filtering Chi-squared (G24 ) 2 (Church and Gale, 1991) Z-Score (Smadja, 1993; Fontenelle, et al. , 1994) Students t-Score (Church and Hanks, 1990) n-gram list in accordance to each probabilistic algorithm.",0,original
"In this framework, the source language, let-s say English, is assumed to be generated by a noisy probabilistic source.1 Most of the current statistical MT systems treat this source as a sequence of words (Brown et al. , 1993).",0,original
Tillmann and Zhang (2006) and Liang et al.,0,original
"(Papineni et al. , 2002).",0,original
"Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al. , 2006; Dolan et al. , 2004; Ibrahim et al. , 2003; Lin and Pantel, 2001; Pang et al. , 2003; Quirk et al. , 2004; Shinyama et al. , 2002).",0,original
"BLEU (Papineni et al. , 2002) is a canonical example: in matching n-grams in a candidate translation text with those in a reference text, the metric measures faithfulness by counting the matches, and fluency by implicitly using the reference n-grams as a language model.",0,original
"Introduction Verb subcategorizafion probabilities play an important role in both computational linguistic applications (e.g. Carroll, Minnen, and Briscoe 1998, Charniak 1997, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Tmeswell 1997, Stolcke et al. 1997) and psycholinguisfic models of language processing (e.g. Boland 1997, Clifton et al. 1984, Ferreira & McClure 1997, Fodor 1978, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell & Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993).",0,original
This implementation is exactly the one proposed in Yarowsky (1995).,0,original
"c 2009 Association for Computational Linguistics Reverse Revision and Linear Tree Combination for Dependency Parsing Giuseppe Attardi Dipartimento di Informatica Universit`a di Pisa Pisa, Italy attardi@di.unipi.it Felice DellOrletta Dipartimento di Informatica Universit`a di Pisa Pisa, Italy felice.dellorletta@di.unipi.it 1 Introduction Deterministic transition-based Shift/Reduce dependency parsers make often mistakes in the analysis of long span dependencies (McDonald & Nivre, 2007).",0,original
"Substituting the probabilities in the PMI formula with the previously introduced Web statistics, we obtain: a15a17a16a25a18a26a11a22a21 Qspa49a6a50a22a51a6a52 Aspa24 a15a17a16a25a18a26a11a22a21 Qspa24a56a55a57a15a33a16a19a18a26a11a6a21 Aspa24 a55 a38 a1a6a39a17a34a40a1a8a41a45a43a46a11 Maximal Likelihood Ratio (MLHR) is also used for word co-occurrence mining (Dunning, 1993).",0,original
"Similar to bidirectional labelling in (Shen et al., 2007), there are two learning tasking in this model.",0,original
"In some recent grammar induction and MT work (Haghighi and Klein, 2006; Quirk et al., 2005) it has been shown that even a small amount of knowledge about a language, in the form of grammar fragments, treelets or prototypes, can go a long way in helping with the induction of a grammar from raw text or with alignment of parallel corpora.",0,original
(Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Nave Bayes classifiers trained on a huge corpus.,0,original
"Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English.",0,original
"The syntactic parameters are the same as in Section 5.1 and are smoothed as in (Collins, 1997).",0,original
"The system described in (Bean and Riloff, 1999) also makes use of syntactic heuristics.",0,original
"For the WMT 2009 Workshop, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimization criterion,  := argmax{(2BLEU)TER}, based on previous experience (Mauser et al., 2008).",0,original
"We viewed the seed word as a classified sentence, following a similar proposal in Yarowsky (1995).",0,original
"There have been many studies of zero-pronoun identification (Walker et al., 1994) (Nakaiwa, 1997) (Iida et al., 2006).",0,original
"Hence, either the best translation hypothesis is directly extracted from the word graph and output, or an N-best list of translations is computed (Tran et al. , 1996).",0,original
"These are identical to prior work (Smith and Eisner, 2006; Wang et al., 2007), except that we add a root configuration that aligns the target parent-child pair to null and the head word of the source sentence, respectively.",0,original
"Adapting a vectorbased approach reported by Chu-Carroll and Carpenter (1999), the Task ID Frame Agent is domain-independent and automatically trained.",0,original
"We parsed the TimeEval data using MSTParser v0.2 (McDonald and Pereira, 2006), which is trained with all Penn Treebank (Marcus et al. , 1993) without dependency label.",0,original
glish nouns first appeared in Hindle (1990).,0,original
"One sees this clear trend in the supervised NLP literature examples include the Perceptron algorithm for tagging (Collins, 2002), MIRA for dependency parsing (McDonald et al., 2005), exponentiated gradient algorithms (Collins et al., 2008), stochastic gradient for constituency parsing (Finkel et al., 2008), just to name a few.",0,original
"5.3 Evaluation Metric This paper focuses on the BLEU metric as presented in (Papineni et al. , 2002).",0,original
"6.2 Translation Results For the translation experiments, we report the two accuracy measures BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) as well as the two error rates word error rate (WER) and positionindependent word error rate (PER).",0,original
"1 Introduction Sentiment detection and classification has received considerable attention recently (Pang et al. , 2002; Turney, 2002; Goldberg and Zhu, 2004).",0,original
"distance (MSD) and the maximum swap segment size (MSSS) ranging from 0 to 10 and evaluated the translations with the BLEU7 metric (Papineni et al. , 2002).",0,original
"5 Analysis Over the last few years, several automatic metrics for machine translation evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle (Lin and Och, 2004; Melamed et al. , 2003; Papineni et al. , 2002).",0,original
"5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank (Marcus et al. , 1993); i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation.",0,original
"(Haghighi and Klein, 2006) also worked on one of our data sets.",0,original
"Similar ideas were explored in (He et al., 2008).",0,original
"In designing LEAF, we were also inspired by dependency-based alignment models (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001; Cherry and Lin, 2003; Zhang and Gildea, 2004).",0,original
"Our appoach is based on Maximum Entropy (MaxEnt henceforth) technique (Berger et al. , 1996).",0,original
"Words are encoded through an automatic clustering algorithm (Brown et al. , 1992) while tags, labels and extensions are normally encoded using diagonal bits.",0,original
"2.3 Previous Randomized LMs Recent work (Talbot and Osborne, 2007b) has used lossy encodings based on Bloom filters (Bloom, 1970) to represent logarithmically quantized corpus statistics for language modeling.",0,original
"A similar soft projection of dependencies was used in supervised machine translation by Smith and Eisner (2006), who used a source sentences dependency paths to bias the generation of its translation.",0,original
"Both for the training and for the testing of our algorithm, we used the syntactically analysed sentences of the Brown Corpus (Marcus, 1993), which have been manually semantically tagged (Miller et al. , 1993) into semantic concordance files (SemCor).",0,original
"Existing statistical NLG (i) uses corpus statistics to inform heuristic decisions in what is otherwise symbolic generation (Varges and Mellish, 2001; White, 2004; Paiva and Evans, 2005); (ii) applies n-gram models to select the overall most likely realisation after generation (HALOGEN family); or (iii) reuses an existing parsing grammar or treebank for surface realisation (Velldal et al. , 2004; Cahill and van Genabith, 2006).",0,original
"It generates a vector of 5 numeric values for each phrase pair:  phrase translation probability: ( f|e) = count( f, e) count(e),(e| f) = count( f, e) count( f) 2http://www.phramer.org/  Java-based open-source phrase based SMT system 3http://www.isi.edu/licensed-sw/carmel/ 4http://www.speech.sri.com/projects/srilm/ 5http://www.iccs.inf.ed.ac.uk/pkoehn/training.tgz 150  lexical weighting (Koehn et al. , 2003): lex( f|e,a) = nproductdisplay i=1 1 |{j|(i, j)  a}| summationdisplay (i,j)a w(fi|ej) lex(e|f,a) = mproductdisplay j=1 1 |{i|(i, j)  a}| summationdisplay (i,j)a w(ej|fi)  phrase penalty: ( f|e) = e; log(( f|e)) = 1 2.2 Decoding We used the Pharaoh decoder for both the Minimum Error Rate Training (Och, 2003) and test dataset decoding.",0,original
"For comparison, Haghighi and Klein (2006) report an unsupervised baseline of 41.3%, and a best result of 80.5% from using hand-labeled prototypes and distributional similarity.",0,original
"2 Bidirectional Dependency Networks When building probabilistic models for tag sequences, we often decompose the global probability of sequences using a directed graphical model (e.g. , an HMM (Brants, 2000) or a conditional Markov model (CMM) (Ratnaparkhi, 1996)).",0,original
"To perform minimum error rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on development set, we used optimizeV5IBMBLEU.m (Venugopal and Vogel, 2005).",0,original
"MT output was evaluated using the standard evaluation metric BLEU (Papineni et al. , 2002).2 The parameters of the MT System were optimized for BLEU metric on NIST MTEval2002 test sets using minimum error rate training (Och, 2003), and the systems were tested on NIST MTEval2003 test sets for both languages.",0,original
"(2006)), or by using linguistic evidence, mostly lexical similarity (METEOR, Banerjee and Lavie (2005); MaxSim, Chan and Ng (2008)), or syntactic overlap (Owczarzak et al.",0,original
"(2005a).5 6.2 Results We performed experiments using three training algorithms: the averaged perceptron (Collins, 2002), log-linear training (via conjugate gradient descent), and max-margin training (via the EG algorithm).",0,original
"7 For a more detailed discussion, see Berger, Della Pietra, and Della Pietra (1996) and Ratnaparkhi (1996).",0,original
"The following four metrics were used speci cally in this study: BLEU (Papineni et al. , 2002): A weighted geometric mean of the n-gram matches between test and reference sentences multiplied by a brevity penalty that penalizes short translation sentences.",0,original
"Word alignment models were first introduced in statistical machine translation (Brown et al. , 1993).",0,original
"They may rely only on this information (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003)), or they may combine it with additional information as well (e.g., (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Wilson et al., 2005a)).",0,original
"(Collins (1997) discusses the recovery of one kind of empty node, viz.",0,original
"Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, e.g., (Craven and Kumlien 1999) (Hull and Gomez 1993), or require human-annotated training data with relation information for each domain (Craven et al. 1998).",0,original
"5.1 The Prague Dependency Tree Bank (PDT in the sequel), which has been inspired by the build-up of the Penn Treebank (Marcus, Santorini & Marcinkiewicz 1993; Marcus, Kim, Marcinkiewicz et al. 1994), is aimed at a complex annotation of (a part of) the Czech National Corpus (CNC in the sequel), the creation of which is under progress at the Department of Czech National Corpus at the Faculty of Philosophy, Charles University (the corpus currently comprises about 100 million tokens of word forms).",0,original
"corpora and corpus query tools has been particularly significant in the area of compiling and developing lexicographic materials (Kilgarriff and Rundell, 2002) and in the area of creating various kinds of lexical resources, such as WordNet (Fellbaum, 1998) and FrameNet (Atkins et al., 2003; Fillmore et al., 2003).",0,original
"The model scaling factors are optimized using minimum error rate training (Och, 2003).",0,original
"In comparison, most corpus-based algorithms employ substantially larger corpora (e.g. , 1 million words (de Marcken, 1990), 2.5 million words (Brent, 1991), 6 million words (Hindle, 1990), 13 million words (Hindle, & Rooth, 1991)).",0,original
"Therefore, we determine the maximal translation probability of the target word e over the source sentence words: p ibm1 (e|f J 1 ) = max j=0,,J p(e|f j ) (18) where f 0 is the empty source word (Brown et al. 1993).",0,original
"This was done for supervised parsing in different ways by Collins (1997), Klein and Manning (2003), and McDonald et al.",0,original
"The subsequent construction of translation table was done in exactly the same way as explained 4 in (Koehn et al., 2003).",0,original
"Three kinds of metrics have been defined: 1http://www.lsi.upc.edu/nlp/IQMT 2http://svn.ask.it.usyd.edu.au/trac/ candc DR-STM-l (Semantic Tree Matching) These metrics are similar to the Syntactic Tree Matching metric defined by Liu and Gildea (2005), in this case applied to DRSs instead of constituency trees.",0,original
"Unfortunately, determining the optimal segmentation is challenging, typically requiring extensive experimentation (Koehn and Knight, 2003; Habash and Sadat, 2006; Chang et al., 2008).",0,original
"The most obvious comparison takes on the form of a keyword analysis, which looks for the words that are significantly more frequent in the one corpus as compared to the other (Dunning, 1993; Scott, 1997; Rayson et al., 2004).",0,original
"We computed precision, recall and error rate on the entire set of sentence pairs for each data set.5 To evaluate NeurAlign, we used GIZA++ in both directions (E-to-F and F-to-E, where F is either Chinese (C) or Spanish (S)) as input and a refined alignment approach (Och and Ney, 2000) that uses a heuristic combination method called grow-diagfinal (Koehn et al. , 2003) for comparison.",0,original
"Statistical approaches, which depend on a set of unknown parameters that are learned from training data, try to describe the relationship between a bilingual sentence pair (Brown et al. , 1993; Vogel and Ney, 1996).",0,original
"These heuristics are extensions of those developed for phrase-based models (Koehn et al., 2003), and involve symmetrising two directional word alignments followed by a projection step which uses the alignments to find a mapping between source words and nodes in the target parse trees (Galley et al., 2004).",0,original
"Due to the positive results in Ando (2006), Blitzer et al.",0,original
"It is difficult to compare these with previous work, but Haghighi and Klein (2006) report that in a completely unsupervised setting, their MRF model, which uses a large set of additional features and a more complex estimation procedure, achieves an average 1-to-1 accuracy of 41.3%.",0,original
"Automatic identification of subjective content often relies on word indicators, such as unigrams (Pang et al., 2002) or predetermined sentiment lexica (Wilson et al., 2005).",0,original
"We have: )|(),|(),|( )|,,()|( 21 21 trictrictric trictritri erpercpercp ecrcpecp = = (6) Assumption 2: For an English triple tri e, assume that i c only depends on {1,2}) (i  i e, and c r only depends on e r . Equation (6) is rewritten as: )|()|()|( )|(),|(),|()|( 2211 21 ec trietrictrictritri rrpecpecp erpercpercpecp = = (7) Notice that )|( 11 ecp and )|( 22 ecp are translation probabilities within triples, they are different from the unrestricted probabilities such as the ones in IBM models (Brown et al. , 1993).",0,original
2 Related Work One of the first works that use statistical methods to detect implicit discourse relations is that of Marcu and Echihabi (2002).,0,original
"1 Introduction In a classical statistical machine translation, a foreign language sentence f J1 = f1, f2, fJ is translated into another language, i.e. English, eI1 = e1, e2,, eI by seeking a maximum likely solution of: eI1 = argmax eI1 Pr(eI1|f J1 ) (1) = argmax eI1 Pr( f J1|eI1)Pr(eI1) (2) The source channel approach in Equation 2 independently decomposes translation knowledge into a translation model and a language model, respectively (Brown et al. , 1993).",0,original
"Note that there are some similarities between our two-stage semi-supervised learning approach and the semi-supervised learning method introduced by (Blitzer et al., 2006), which is an extension of the method described by (Ando and Zhang, 558 2005).",0,original
"For instance, for Maximum Entropy, I picked (Berger et al., 1996; Ratnaparkhi, 1997) for the basic theory, (Ratnaparkhi, 1996) for an application (POS tagging in this case), and (Klein and Manning, 2003) for more advanced topics such as optimization and smoothing.",0,original
"Unsupervised approaches are attractive due to the the availability of large quantities of unlabeled text, and unsupervised morphological segmentation has been extensively studied for a number of languages (Brent et al., 1995; Goldsmith, 2001; Dasgupta and Ng, 2007; Creutz and Lagus, 2007).",0,original
"A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (e.g. , (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002)).",0,original
"Recent work has explored two-stage decoding, which explicitly decouples decoding into a source parsing stage and a target language model integration stage (Huang and Chiang, 2007).",0,original
"Thus, a lot of alignment techniques have been suggested at; the sentence (Gale et al. , 1993), phrase (Shin et al. , 1996), nomt t)hrase (Kupiec, 1993), word (Brown et al. , 1993; Berger et al. , 1996; Melamed, 1997), collocation (Smadja et al. , 1996) and terminology level.",0,original
"For example, sentence alignment of bilingual texts are performed just by measuring sentence lengths in words or in characters (Brown et al. , 1991; Gale and Church, 1993), or by statistically estimating word level correspondences (Chen, 1993; Kay and RSscheisen, 1993).",0,original
"So far, most previous work on domain adaptation for parsing has focused on data-driven systems (Gildea, 2001; Roark and Bacchiani, 2003; McClosky et al., 2006; Shimizu and Nakagawa, 2007), i.e. systems employing (constituent or dependency based) treebank grammars (Charniak, 1996).",0,original
"Sentiment classification is a well studied problem (Wiebe, 2000; Pang et al., 2002; Turney, 2002) and in many domains users explicitly 1We use the term aspect to denote properties of an object that can be rated by a user as in Snyder and Barzilay (2007).",0,original
"The probability distributions of these binary classifiers are learnt using maximum entropy model (Berger et al. , 1996; Haffner, 2006).",0,original
"Our human word alignments do not distinguish between Sure and Probable links (Och and Ney, 2003).",0,original
Toward a Task-based Gold Standard for Evaluation of NP Chunks and Technical Terms Nina Wacholder Rutgers University nina@scils.rutgers.edu Peng Song Rutgers University psong@paul.rutgers.edu Abstract We propose a gold standard for evaluating two types of information extraction output -noun phrase (NP) chunks (Abney 1991; Ramshaw and Marcus 1995) and technical terms (Justeson and Katz 1995; Daille 2000; Jacquemin 2002).,0,original
"2.1 Training the model As with (Minnen et al. , 2000), we train the language model on the Penn Treebank (Marcus et al. , 1993).",0,original
"1 Introduction The field of sentiment classification has received considerable attention from researchers in recent years (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002, Wiebe et al. 2001, Bai et al. 2004, Yu and Hatzivassiloglou 2003 and many others).",0,original
"More recently, the integration of information sources, and the modeling of more complex language processing tasks in the statistical framework has increased the interest in smoothing methods (Collins ~z Brooks, 1995; Ratnaparkhi, 1996; Magerman, 1994; Ng & Lee, 1996; Collins, 1996).",0,original
"(Marcus et al. 1993, 316).",0,original
21418 examples of structures of the kind 'VB N1 PREP N2' were extracted from the Penn-TreeBank Wall Street Journal (Marcus et al. 1993).,0,original
"Both systems rely on the OpenNlp maximum-entropy part-of-speech tagger and chunker (Ratnaparkhi, 1996), but KNOWITALL applies them to pages downloaded from the Web based on the results of Google queries, whereas KNOWITNOW applies them once to crawled and indexed pages.6 Overall, each of the above elements of KNOWITALL and KNOWITNOW are the same to allow for controlled experiments.",0,original
"In the second experiment, the basic learning model is Collinss (1997) Model 2 parser, which uses a history-based learning algorithm that takes statistics directly over the treebank.",0,original
"2 Word-to-Word Bitext Alignment We will study the problem of aligning an English sentence to a French sentence and we will use the word alignment of the IBM statistical translation models (Brown et al. , 1993).",0,original
"As the third test set we selected all tokens of the Brown corpus part of the Penn Treebank (Marcus et al. , 1993), a selected portion of the original one-million word Brown corpus (Kucera and Francis, 1967), a collection of samples of American English in many different genres, from sources printed in 1961; we refer to this test set as BROWN.",0,original
"Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet (Miller et al. , 1993) and Chinese HowNet (Dong and Dong, 2001).",0,original
".1 is a set of assumptions sufficient to support the inI,'rl)n'lation  given S and R. In other words, this is h,~crl)rctal, ion as abduction' (Itobbs et al. 1988), since ~!)(i,('lion, not deduction, is needed to arrive at the :~>.'d H II I~tiOIIS,4.",0,original
"Translation accuracy is measured in terms of the BLEU score (Papineni et al. 2002), which is computed here for translations generated by using the tuple n-gram model alone, in the case of Table 2, and by using the tuple n-gram model along with the additional four feature functions described in Section 3.2, in the case of Table 3.",0,original
"More recently, EM has been used to learn hidden variables in parse trees; these can be head-childannotations(ChiangandBikel, 2002), latent head features (Matsuzaki et al. , 2005; Prescher, 2005; Dreyer and Eisner, 2006), or hierarchicallysplit nonterminal states (Petrov et al. , 2006).",0,original
"On the other hand, works done by (Snow et al., 2005; Snow et al., 2006; Sang and Hofmann, 2007; Bollegala et al., 2007) have proposed methodologies to automatically acquire these patterns mostly based on supervised learning to leverage manual work.",0,original
"3.1 Agreement for Emotion Classes The kappa coefficient of agreement is a statistic adopted by the Computational Linguistics community as a standard measure for this purpose (Carletta, 1996).",0,original
"Although there is a modest cost associated with annotating data, we show that a reduction of 40% relative in alignment error (AER) is possible over the GIZA++ aligner (Och and Ney, 2003).",0,original
"The data consists of sections of the Wall Street Journal part of the Penn TreeBank (Marcus et al. , 1993), with information on predicate-argument structures extracted from the PropBank corpus (Palmer et al. , 2005).",0,original
"Any linguistic annotation required during the extraction process, therefore, is produced through automatic means, and it is only for reasons of accessibility and comparability with other research that we choose to work over the Wall Street Journal section of the Penn Treebank (Marcus et al. , 1993).",0,original
"(1) a. I expected \[nv the man who smoked NP\] to eat ice-cream h. I doubted \[NP the man who liked to eat ice-cream NP\] Current high-coverage parsers tend to use either custom, hand-generated lists of subcategorization frames (e.g. , Hindle, 1983), or published, handgenerated lists like the Ozford Advanced Learner's Dictionary of Contemporary English, Hornby and Covey (1973) (e.g. , DeMarcken, 1990).",0,original
"Like Haghighi and Klein (2007), we give our model information about the basic types of pronouns in English.",0,original
"To simulate real world scenario, we use n-best lists from ISIs state-of-the-art statistical machine translation system, AlTemp (Och 2003), and the 2002 NIST Chinese-English evaluation corpus as the test corpus.",0,original
"(Wu, 1997)).",0,original
"To overcome the knowledge acquisition bottleneck problem suffered by supervised methods, these methods make use of a small annotated corpus as seed data in a bootstrapping process (Hearst, 1991) (Yarowsky, 1995).",0,original
Talbot and Brants (2008) used a Bloomier filter to encode a LM.,0,original
"146 2.3 Approximating ISBNs (Titov and Henderson, 2007) proposes two approximations for inference in ISBNs, both based on variational methods.",0,original
"Collocation Dictionary of Modern Chinese Lexical Words, Business Publisher, China Yuan Liu, et al. 1993.",0,original
"Note that it is straightforward to calculate these expected counts using a variant of the inside-outside algorithm (Baker, 1979) applied to the (Eisner, 1996) dependency-parsing data structures (Paskin, 2001) for projective dependency structures, or the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for nonprojective dependency structures.",0,original
"Since so many concepts used in discourse are $q'aindependent, a theory of granularity is also fundamental (see Hobbs 1985b).",0,original
"Drawing on Abneys (2004) analysis of the Yarowsky algorithm, we perform bootstrapping by entropy regularization: we maximize a linear combination of conditional likelihood on labeled data and confidence (negative Renyi entropy) on unlabeled data.",0,original
", i.e.: (ll) Lj = ~ maz(zi(j, u)) i=I where xi(j,u)E Qi and max(xi(j,u)) is the highest score in the line of the matrix Qi which corresponds to the head word sense j. n is the number of modifiers of the head word h at the current tree level, and k i Lj = j~l Lj where k is the number of senses of the head word h. The reason why gj (I0) is calculated as a sum of the best scores (ll), rather than by using the traditional maximum likelihood estimate (Berger et al. , 1996)(Gah eta\[.",0,original
"Our system is actually designed as a hybrid of the classic phrase-based SMT model (Koehn et al., 2003) and the kernel regression model as follows: First, for each source sentence a small relevant set of sentence pairs are retrieved from the large-scale parallel corpus.",0,original
"eBonsai first performs syntactic analysis of a sentence using a parser based on GLR algorithm (MSLR parser) (Tanaka et al. , 1993), and provides candidates of its syntactic structure.",0,original
1Mihalcea (2007) shows that Wikipedia can indeed be used as a sense inventory for sense disambiguation.,0,original
"a larger number of labeled documents, its performance on this corpus is comparable to that of Support Vector Machines and Maximum Entropy models (Pang et al. , 2002).",0,original
"He then goes on to adapt the conventional noisy channel MT model of [Brown et al 1993] to NLU, where extracting a semantic representation from an input text corresponds to finding: argmax(Sem) {p(Input|Sem) p(Sem)}, where p(Sem) is a model for generating semantic representations, and p(Input|Sem) is a model for the relation between semantic representations and corresponding texts.",0,original
"Previous workthe generative models described in Collins (1996) and the earlier version of these models described in Collins (1997)conditioned on punctuation as surface features of the string, treating it quite differently from lexical items.",0,original
"1 Introduction Empty categories (also called null elements) are used in the annotation of the PENN treebank (Marcus et al. , 1993) in order to represent syntactic phenomena like constituent movement (e.g. whextraction), discontinuous constituents, and missing elements (PRO elements, empty complementizers and relative pronouns).",0,original
"The first is to align the words using a standard word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences.",0,original
"Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al. , 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al. , 2005), as well as the speaker level in debates (Thomas et al. , 2006).",0,original
"The classifier consists of two components based on the averaged multiclass perceptron (Collins, 2002; Crammer and Singer, 2003).",0,original
"(1999) and Lee (1999)) can be generally divided into three types: discounting (Katz, 1987), class-based smoothing (Resnik, 1993; Brown et al. , 1992; Pereira et al. , 1993), and distance-weighted averaging (Grishman and Sterling, 1994; Dagan et al. , 1999).",0,original
"Moreover, our approach integrates the abbreviation translation component into the baseline system in a natural way, and thus is able to make use of the minimum-error-rate training (Och, 2003) to automatically adjust the model parameters to reflect the change of the integrated system over the baseline system.",0,original
"While early head-lexicalized grammars restricted the fragments to the locality of headwords (e.g. Collins 1996; Eisner 1996), later models showed the importance of including context from higher nodes in the tree (Charniak 1997; Johnson 1998).",0,original
"(Carpenter, 1992), (Copestake, 1999), (DSrre and Dorna, 1993), (D6I're et al. , 1996), (Emele and Zajac, 1990), (H6ht~ld and Smolka, 1988)), and to pick those ingredients which are known to be con~i)utationally 'tractable' in some sense.",0,original
"2 Related Work The most commonly used similarity measures are based on the WordNet lexical database (eg Budanitsky and Hirst 2006, Hughes and Ramage 2007) and a number of such measures have been made publicly available (Pedersen et-al 2004).",0,original
"It has been lately incorporated into computational lexicography in (Atkins, 1991), (Ostler and Atkins, 1992), (Briscoe and Copestake, 1991), (Copestake and Briscoe, 1992), (Briscoe et al. , 1993)).",0,original
", Yarowsky 1995) after using an ensemble of NBCs.",0,original
"3 Maximum Entropy Taggers The taggers are based on Maximum Entropy tagging methods (Ratnaparkhi, 1996), and can all be trained on new annotated data, using either GIS or BFGS training code.",0,original
"Word-aligned corpora have been found to be an excellent source for translation-related knowledge, not only for phrase-based models (Och and Ney, 2004; Koehn et al., 2003), but also for syntax-based models (e.g., (Chiang, 2007; Galley et al., 2006; Shen et al., 2008; Liu et al., 2006)).",0,original
"Illustrative clusterings of this type can also be found in Pereira, Tishby, and Lee (1993), Brown, Della Pietra, Mercer, Della Pietra, and Lai (1992), Kneser and Ney (1993), and Brill et al.",0,original
The lexicalized model proposed by Collins (1997) (henceforth Collins model) was re-implemented by one of the authors.,0,original
"(Berger et al. , 1996) describe an approach that targets translation of French phrases of the form NOUN de NOUN (e.g. , conflit dinteret).",0,original
"Consequently, we abstract away from specifying a distribution by allowing the user to assign labels to features (c.f. Haghighi and Klein (2006) , Druck et al.",0,original
"Most of the annotation approaches tackling these issues, however, are aimed at performing classifications at either the document level (Pang et al. , 2002; Turney, 2002), or the sentence or word level (Wiebe et al. , 2004; Yu and Hatzivassiloglou, 2003).",0,original
"Related to this issue, we note that the head rules, which were nearly identical to those used in (Collins, 1997), have not been tuned at all to this task.",0,original
(DeRose 1988; Cutting et al 1992; Merialdo 1994).,0,original
"For a detailed description of each algorithm, readers are referred to Collins (2000) for the boosting algorithm, Collins (2002) for perceptron learning, and Gao et al.",0,original
"These measures have, in fact, been used previously in measuring term recognition (Smadja, 1993; Bourigault, 1994; Lauriston, 1994).",0,original
"SMT has evolved from the original word-based approach (Brown et al. , 1993) into phrase-based approaches (Koehn et al. , 2003; Och and Ney, 2004) and syntax-based approaches (Wu, 1997; Alshawi et al. , 2000; Yamada and Knignt, 2001; Chiang, 2005).",0,original
"There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald.",0,original
"A systematic exploration of a set of such features for proteinprotein interaction extraction was recently provided by Jiang and Zhai (2007), who also used features derived from the Collins parser.",0,original
"(Collins 2002) showed how to use the Voted Perceptron algorithm for learning W, and we use it for learning the global transliteration model.",0,original
"consistency among raters who may have different levels of fluency in the source language, raters are not shown the original French or Spanish sentence (for similar methodologies, see Ringger et al. , 2001; White et al. , 1993).",0,original
"1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data (Magerman, 1995; Collins, 1999; Charniak, 1997; Ratnaparkhi, 1999; Charniak, 2000; Wang et al. , 2005; McDonald et al. , 2005).",0,original
"Firstly, there is also H(RB) A(ADVP) declined H(VBD) H(VP) the dollar A(DT) H(NN) C(NP-SBJ) H(VP) H(S) Figure 2: A tree with constituents marked the top-down method, which is a version of the algorithm described by Hockenmaier et al (Hockenmaier et al. , 2000), but used for translating into simple (AB) CG rather than the Steedmans Combinatory Categorial Grammar (CCG) (Steedman, 1993).",0,original
"Some of these have been previously employed for various tasks by Gabrilovich and Markovitch, (2006); Overell and Ruger (2006), Cucerzan (2007), and Suchanek et al.",0,original
"303 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures (Church and Hanks, 1990), we are able to identify higher-precision collocations by including placeholders for unique words (i.e. , the ugen-n-grams).",0,original
"context-free rules Charniak (1996) Collins (1996), Eisner (1996) context-free rules, headwords Charniak (1997) context-free rules, headwords, grandparent nodes Collins (2000) context-free rules, headwords, grandparent nodes/rules, bigrams, two-level rules, two-level bigrams, nonheadwords Bod (1992) all fragments within parse trees Scope of Statistical Dependencies Model Figure 4.",0,original
"The principle of our approach is more similar to (Yarowsky, 1995).",0,original
"Turney (2002) showed that it is possible to use only a few of those semantically oriented words (namely, excellent and poor) to label other phrases co-occuring with them as positive or negative.",0,original
"However, they make different types of errors, which can be seen as a reflection of their theoretical differences (McDonald and Nivre, 2007).",0,original
"Forced decoding arises in online discriminative training, where model updates are made toward the most likely derivation of a gold translation (Liang et al., 2006).",0,original
"(2006), modified from (Koehn et al. , 2003), which is an average of pairwise word translation probabilities.",0,original
"Following (Lin, 2004), we computed the skip bi-gram score using both the sentence pool and the query pool.",0,original
4 are equivalent to a maximum entropy variant of the phrase sense disambiguation approach studied by Carpuat & Wu (2007b).,0,original
"Recent research in open information extraction (Banko and Etzioni, 2008; Davidov and Rappaport, 2008) has shown that we can extract large amounts of relational data from open-domain text with high accuracy.",0,original
"6 Related Work Other work combining supervised and unsupervised learning for parsing includes (Charniak, 1997), (Johnson and Riezler, 2000), and (Schmid, 2002).",0,original
"In this paper, we propose an alignment algorithm between English and Korean conceptual units (or between English and Korean term constituents) in English-Korean technical term pairs based on IBM Model (Brown et al. , 1993).",0,original
"The probabilities are ordered according to, at least my, intuition with pronoun being the most likely (0.094), followed by proper nouns (0.057), followed by common nouns (0.032), a fact also noted by (Haghighi and Klein, 2007).",0,original
(2007) and Nivre and McDonald (2008) can be seen as methods to combine separately defined models.,0,original
"Cutting et al. 1992), local rules (e.g. Hindle 1989) and neural networks (e.g. Schmid 1994).",0,original
"Introduction Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural language processing tasks, such as part-of-speech tagging \[Brill, 1995\], PPattachment disambiguation \[Brill and Resnik, 1994\], text chunking \[Ramshaw and Marcus, 1995\], spelling correction \[Mangu and Brill, 1997\], dialogue act tagging \[Samuel et al. , 1998\] and ellipsis resolution \[Hardt, 1998\].",0,original
"Six features from (Och, 2003) were used as baseline features.",0,original
"For handling word identities, one could follow the approach used for handling the POS tags (e.g. , Black et al. 1992; Magerman 1994) and view the POS tags and word identities as two separate sources of information.",0,original
"In previous work (Foster, 2000), I described a Maximum Entropy/Minimum Divergence (MEMD) model (Berger et al. , 1996) for p(w\[hi, s) which incorporates a trigram language model and a translation component which is an analog of the well-known IBM translation model 1 (Brown et al. , 1993).",0,original
"It consists of sections 15-18 of the Wall Street Journal part of the Penn Treebank II (Marcus et al. , 1993) as training data (211727 tokens) and section 20 as test data (47377 tokens).",0,original
"A variety of synset similarity measures based on properties of WordNet itself have been proposed; nine such measures are discussed in (Pedersen et al. , 2004), including gloss-based heuristics (Lesk, 1986; Banerjee and Pedersen, 2003), information-content based measures (Resnik, 1995; Lin, 1998; Jiang and Conrath, 1997), and others.",0,original
Discovering orientations of context dependent opinion comparative words is related to identifying domain opinion words (Hatzivassiloglou and McKeown 1997; Kanayama and Nasukawa 2006).,0,original
"Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008).",0,original
"The feature weights were tuned on a heldout development set so as to maximize an equally weighted linear combination of BLEU and 1-TER (Papineni et al., 2002; Snover et al., 2006) using the minimum error training algorithm on a packed forest representation of the decoders hypothesis space (Macherey et al., 2008).",0,original
"As has been pointed out by Dunning (1993), the calculation of log  assumes a binomial distribution.",0,original
"One heuristic approach is to adapt the self-training algorithm (Yarowsky, 1995) to our model.",0,original
"(2007), it is much higher than the 2.6% unknown word rate in the test set for Ratnaparkhis (1996) English POS tagging experiments.",0,original
"1 Introduction In the past few years, there has been an increasing interest in mining opinions from product reviews (Pang, et al, 2002; Liu, et al, 2004; Popescu and Etzioni, 2005).",0,original
"1 Introduction Most of the current work in statistical machine translation builds on word replacement models developed at IBM in the early 1990s (Brown et al. , 1990, 1993; Berger et al. , 1994, 1996).",0,original
"One other published model for grouping semantically related words (Brown et al. , 1992), is based on a statistical model of bigrams and trigrams and produces word groups using no linguistic knowledge, but no evaluation of the results is reported.",0,original
"7However, the algorithms shares many common points with iterative algorithm that are known to converge and that have been proposed to find maximum entropy probability distributions under a set of constraints (Berger et al. , 1996).",0,original
"Polarity orientation identification has many useful applications, including opinion summarization (Ku et al., 2006) and sentiment retrieval (Eguchi and Lavrenko, 2006).",0,original
"The feature combinations play an essential role in obtaining a classifier with state-of-the-art accuracy for several NLP tasks; recent examples include dependency parsing (Koo et al., 2008), parse re-ranking (McClosky et al., 2006), pronoun resolution (Nguyen and Kim, 2008), and semantic role labeling (Liu and Sarkar, 2007).",0,original
"Since the texts in the RST Treebank are taken from the syntactically annotated Penn Treebank (Marcus et al. , 1993), it is natural to ask what the relation is between the discourse structures in the RST Treebank and the syntactic structures of the Penn Treebank.",0,original
"(Haruno et al. , 1996; Kay et al. , 1993) applied iterative refinement algorithms to sentence level alignment tasks.",0,original
"Averaging has been shown to help reduce overfitting (McDonald et al. , 2005a; Collins, 2002).",0,original
"1 Introduction In this paper, we present an approach for extracting the named entities (NE) of natural language inputs which uses the maximum entropy (ME) framework (Berger et al. , 1996).",0,original
"Section 4 concludes the paper with a critical assessment of the proposed approach and a discussion of the prospects for application in the construction of corpora comparable in size and quality to existing treebanks (such as, for example, the Penn Treebank for English (Marcus et al. , 1993) or the TIGER Treebank for German (Brants et al. , 2002)).",0,original
"The minimum error training (Och, 2003) was used on the development data for parameter estimation.",0,original
"2.4 METEOR Given a pair of strings to compare (a system translation and a reference translation), METEOR (Banerjee and Lavie, 2005) first creates a word alignment between the two strings.",0,original
", 1993; Graham et al. , 1980) where K is the number of distinct nonternfinal symbols in the gramma.r G. We ca.n expect a. very etfide.nt pa.rser tbr our pa.tterns, r The input string ca.n a.lso be scanned to reduce the number of relewmt gramma.r rules before pa.rsing, e The combined process is a.lso known as offlineparsing in LTAC,.",0,original
"Our baseline uses Giza++ alignments (Och and Ney, 2003) symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003).",0,original
"(Blitzer et al., 2006; Jiang and Zhai, 2007; Daume III, 2007; Finkel and Manning, 2009), or [S+T-], where no labeled target domain data is available, e.g.",0,original
"Some work has been done on adding new terms and relations to WordNet (Snow et al., 2006) and FACTOTUM (OHara and Wiebe, 2003).",0,original
"Corpus Time Period Size Articles Words New Indian Express (English) 2007.01.01 to 2007.08.31 2,359 347,050 Dinamani (Tamil) 2007.01.01 to 2007.08.31 2,359 256,456 Table 1: Statistics on Comparable Corpora  From the above corpora, we first extracted all the NEs from the English side, using the Stanford NER tool [Finkel et al, 2005].",0,original
In (Zernik 1990; Calzolari and Bindi 1990; Smadja 1989; Church and Hanks 1990) associations are detected in a 5 window.,0,original
"Thus, an orthogonal line of research can involve inducing classes for words which are more general than single categories, i.e., something akin to ambiguity classes (see, e.g., the discussion of ambiguity class guessers in Goldberg et al., 2008).",0,original
"We then rank-order the P X|Y MI XY M Z Pr Z|Y MI ZY G092log [P X P Y P X P Y ] f Y [P XY P XY ] f XY [P XY P XY ] f XY M iG13X,X} jG13Y,Y} (f ij G09 ij ) 2 ij f XY G09 XY XY (1G09( XY /N)) f XY G09 XY f XY (1G09(f XY /N)) Table 1: Probabilistic Approaches METHOD FORMULA Frequency (Guiliano, 1964) f XY Pointwise Mutual Information (MI) (Fano, 1961; Church and Hanks, 1990) log (P / PP) 2XY XY Selectional Association (Resnik, 1996) Symmetric Conditional Probability (Ferreira and Pereira, 1999) P / PP XY X Y 2 Dice Formula (Dice, 1945) 2 f / (f +f ) XY X Y Log-likelihood (Dunning, 1993; (Daille, 1996).",0,original
"The IBM translation models (Brown et al. , 1993) describe word reordering via a distortion model defined over word positions within sentence pairs.",0,original
"It forms a baseline for performance evaluations, but is prone to sparse data problems (Dunning, 1993).",0,original
"Given a source sentence f, the preferred translation output is determined by computing the lowest-cost derivation (combination of hierarchical and glue rules) yielding f as its source side, where the cost of a derivation R1 Rn with respective feature vectors v1,,vn  Rm is given by msummationdisplay i=1 i nsummationdisplay j=1 (vj)i. Here, 1,,m are the parameters of the loglinear model, which we optimize on a held-out portion of the training set (2005 development data) using minimum-error-rate training (Och, 2003).",0,original
"1 Introduction Conditional Maximum Entropy (maxent) models have been widely used for a variety of tasks, including language modeling (Rosenfeld, 1994), part-of-speech tagging, prepositional phrase attachment, and parsing (Ratnaparkhi, 1998), word selection for machine translation (Berger et al. , 1996), and finding sentence boundaries (Reynar and Ratnaparkhi, 1997).",0,original
"al. 2006), we are interested in applying alternative metrics such a Meteor (Banerjee and Lavie 2005).",0,original
Our statistical tagging model is modified from the standard bigrams (Cutting et al. 1992) using Viterbi search plus onthe-fly extra computing of lexical probabilities for unknown morphemes.,0,original
"Our story makes use of a weighted formalism known as quasi-synchronous grammar (hereafter, QG), originally developed by D. Smith and Eisner (2006) for machine translation.",0,original
"Statistical Model In SIFTs statistical model, augmented parse trees are generated according to a process similar to that described in Collins (1996, 1997).",0,original
"The IBM models, together with a Hidden Markov Model (HMM), form a class of generative models that are based on a lexical translation model P(fj|ei) where each word fj in the foreign sentence fm1 is generated by precisely one word ei in the sentence el1, independently of the other translation decisions (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2000).",0,original
"For instance, for Maximum Entropy, I picked (Berger et al., 1996; Ratnaparkhi, 1997) for the basic theory, (Ratnaparkhi, 1996) for an application (POS tagging in this case), and (Klein and Manning, 2003) for more advanced topics such as optimization and smoothing.",0,original
"At last, the dependency parser presented in (Collins, 1997) is used to generate the full parse.",0,original
"(2007a), and Rosti et al.",0,original
"Unsupervised Learning: Results To test the effectiveness of the above unsupervised learning algorithm, we ran a number of experiments using two different corpora and part of speech tag sets: the Penn Treebank Wall Street Journal Corpus \[Marcus et al. , 1993\] and the original Brown Corpus \[Francis and Kucera, 1982\].",0,original
"Some researchers (Fujii and Ishikawa, 2006) targeted nouns, noun phrases and verb phrases.",0,original
"In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003).",0,original
"The POS disambiguation has usually been performed by statistical approaches mainly using hidden markov model (HMM) (Cutting et al. , 1992; Kupiec.",0,original
"Training Data Our source for syntactically annotated training data was the Penn Treebank (Marcus et al. , 1993).",0,original
"The a0 coefficient is computed as follows: a0 a47 a1a32a2 a9 a1 a30 a68 a9 a1a32a30 Carletta (1996) reports that content analysis researchers generally think of a0a34a33 a49a36a35a37 as good reliability, with a49a36a35a38a40a39a37a41 a0 a41a25a49a36a35a37 allowing tentative conclusions to be drawn. All that remains is to define the chance agreement probability a1 a30 . Let a1a32a41 a1 a30 a7 and a1a32a42 a1 a30 a7 be the fraction of utterances that begin or end one or more segments in segmentation a30 respectively.",0,original
"The second approximation proposed in (Titov and Henderson, 2007) takes into consideration the fact that, after each decision is made, all the preceding latent variables should have their means i updated.",0,original
"We build sentencespecific zero-cutoff stupid-backoff (Brants et al., 2007) 5-gram language models, estimated using 4.7B words of English newswire text, and apply them to rescore each 10000-best list.",0,original
"This approach to term clustering is closely related to others from the literature (Brown et al. , 1992; Clark, 2000).2 Recall that the mutual information between random variables a0 and a1 can be written: a2a4a3a6a5a8a7a10a9a11a13a12a15a14a17a16a19a18a21a20a23a22a25a24a27a26a29a28 a14a17a16a19a18a21a20a23a22a25a24 a14a17a16a19a18a30a24a31a14a17a16a19a22a32a24 (1) Here, a0 and a1 correspond to term and context clusters, respectively, each event a18 and a22 the observation of some term and contextual term in the corpus.",0,original
"(2001) and Ponzetto and Strube (2006)), we generate training instances as follows: a positive instance is created for each anaphoric NP, NPj, and its closest antecedent, NPi; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+1, NPi+2, . . ., NPj1.",0,original
"Test and training materials were derived from the Brown corpus of American English, all of which has been parsed and manually verified by the Penn T~eebank project (Marcus et al. , 1993) and parts of which have been manually sense-tagged by the WordNet group (Miller et al. , 1993).",0,original
"2 Background Several graph-based learning techniques have recently been developed and applied to NLP problems: minimum cuts (Pang and Lee, 2004), random walks (Mihalcea, 2005; Otterbacher et al. , 2005), graph matching (Haghighi et al. , 2005), and label propagation (Niu et al. , 2005).",0,original
"We use the GIZA++ implementation of IBM Model 4 (Brown et al., 1993; Och and Ney, 2003) coupled with the phrase extraction heuristics of Koehn et al.",0,original
"1.2 Evaluation In this paper we report results using the BLEU metric (Papineni et al., 2002), however as the evaluation criterion in GALE is HTER (Snover et al., 2006), we also report in TER (Snover et al., 2005).",0,original
"Many systems (e.g. , the KERNEL system \[Palmer et al. , 1993\]) use these relationships as an intermediate, form when determining the semantics of syntactically parsed text.",0,original
"Since these morphological generalizations are based on the initial categorization provided by the algorithm of (Brown et al., 1992), we hope that they will foster speedy convergence of HNN training.",0,original
"The weights of feature functions are optimized to maximize the scoring measure (Och, 2003).",0,original
"Inspired by previous work on syntax-driven semantic parsing (Gildea and Jurafsky, 2002; Fleischman et al. , 2003), and syntax-based machine translation (Wu, 1997; Cuerzan and Yarowsky, 2002), we postulate that syntactically similar sentences with the same predicate also share similar semantic roles.",0,original
"In (Knight and A1-Onaizan, 1998), finite-state machine translation is based on (Brown et al. , 1993) and is used for decoding the target language string.",0,original
"It assumes that the distance of the positions relative to the diagonal of the (j, i) plane is the dominating factor: r(i _j I) p(ilj, J, I) = (7), Ei,=l r(i' j ) As described in (Brown et al. , 1993), the EM algorithm can be used to estimate the parameters of the model.",0,original
"5 The SemCor collection (Miller et al., 1993) is a subset of the Brown Corpus and consists of 352 news articles distributed into three sets in which the nouns, verbs, adverbs, and adjectives have been manually tagged with their corresponding WordNet senses and part-of-speech tags using Brills tagger (1995).",0,original
"There has been recent work on discovering allomorphic phenomena automatically (Dasgupta and Ng, 2007; Demberg, 2007).",0,original
3.1 The gender/animaticity statistics After we have identified the correct antecedents it is a simple counting procedure to compute P(p\[wa) where wa is in the correct antecedent for the pronoun p (Note the pronouns are grouped by their gender): \[ wain the antecedent for p \[ P(pl o) = When there are multiple relevant words in the antecedent we apply the likelihood test designed by Dunning (1993) on all the words in the candidate NP.,0,original
"Like the data used by Ramshaw and Marcus (1995), this data was retagged by the Brill tagger in order to obtain realistic part-of speech (POS) tags 5.",0,original
"Some approaches have used syntax at the core (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001; Gildea, 2003; Eisner, 2003; Hearne and Way, 2003; Melamed, 2004) while others have integrated syntax into existing phrase-based frameworks (Xia and McCord, 2004; Chiang, 2005; Collins et al. , 2005; Quirk et al. , 2005).",0,original
"2 Related Work There has been a large and diverse body of research in opinion mining, with most research at the text (Pang et al., 2002; Pang and Lee, 2004; Popescu and Etzioni, 2005; Ounis et al., 2006), sentence (Kim and Hovy, 2005; Kudo and Matsumoto, 2004; Riloff et al., 2003; Yu and Hatzivassiloglou, 2003) or word (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kim and Hovy, 2004; Takamura et al., 2005; Andreevskaia and Bergler, 2006; Kaji and Kitsuregawa, 2007) level.",0,original
"tactic parser (Collins, 1997).",0,original
This is the scenario considered by Haghighi and Klein (2006) for POS tagging: how to construct an accurate tagger given a set of tags and a few example words for each of those tags.,0,original
Yarowsky (1995) dealt with this problem largely by producing an unsupervised learning algorithm that generates probabilistic decision list models of word senses from seed collocates.,0,original
"Some of the early statistical terminology translation methods are (Brown et al. , 1993; Wu and Xia, 1994; Dagan and Church, 1994; Gale and Church, 1991; Kupiec, 1993; Smadja et al. , 1996; Kay and RSscheisen, 1993; Fung and Church, 1994; Fung, 1995b).",0,original
"When tested on f-structures for all sentences from Section 23 of the Penn Wall Street Journal (WSJ) treebank (Mar267 cus et al. , 1993), the techniques described in this paper improve BLEU score from 66.52 to 68.82.",0,original
"22 Table 5: Comparison with previous best results: (Top : POS tagging, Bottom: Text Chunking ) POS tagging F=1 Perceptron (Collins, 2002) 97.11 Dep.",0,original
"Assuming that the parameters P(etk|fsk) are known, the most likely alignment is computed by a simple dynamic-programming algorithm.1 Instead of using an Expectation-Maximization algorithm to estimate these parameters, as commonly done when performing word alignment (Brown et al., 1993; Och and Ney, 2003), we directly compute these parameters by relying on the information contained within the chunks.",0,original
"Syntactic context information is used (Hindle, 1990; Ruge, 1992; Lin, 1998) to compute term similarities, based on which similar words to a particular word can directly be returned.",0,original
"In related work (Chaovalit, 2005; Turney, 2002), both supervised and unsupervised approaches have been shown to have their pros and cons.",0,original
"The progression in the probabilistic parsing literature has been to start with lexical head-head dependencies (Collins, 1997) and then add non-lexical sis2 This result generalizes to Ss, which are also flat in Negra (see Section 2.2).",0,original
"2 F 1 -score Maximization Training of LRM We first review the F 1 -score maximization training method for linear models using a logistic function described in (Jansche, 2005).",0,original
"A comparison of the two approaches can be found in Koehn, Och, and Marcu (2003).",0,original
"5.2 A data recovery task In the second evaluation, the estimation method had to distinguish between members of two sets of 8It should be emphasized that the TWS method uses only a monolingual target corpus, and not a bilingual corpus as in other methods ((Brown et al. , 1991; Gale et al. , 1992)).",0,original
(2007) looked at Golomb Coding and Brants et al.,0,original
"We use Viterbi training (Brown et al. , 1993) but neighborhood estimation (Al-Onaizan et al. , 1999; Och and Ney, 2003) or pegging (Brown et al. , 1993) could also be used.",0,original
"The intuition is that the produced clusters will be less sense-conflating than those produced by other graph-based approaches, since collocations provide strong and consistent clues to the senses of a target word (Yarowsky, 1995).",0,original
"Some studies have been done for acquiring collocation translations using parallel corpora (Smadja et al, 1996; Kupiec, 1993; Echizen-ya et al. , 2003).",0,original
"Parameters  used to calculate P(D) are trained using MER training (Och, 2003) on development data.",0,original
Pang & Lee (2004) propose the use of language models for sentiment analysis task and subjectivity extraction.,0,original
"2 Related Work The issue of MWE processing has attracted much attention from the Natural Language Processing (NLP) community, including Smadja, 1993; Dagan and Church, 1994; Daille, 1995; 1995; McEnery et al. , 1997; Wu, 1997; Michiels and Dufour, 1998; Maynard and Ananiadou, 2000; Merkel and Andersson, 2000; Piao and McEnery, 2001; Sag et al. , 2001; Tanaka and Baldwin, 2003; Dias, 2003; Baldwin et al. , 2003; Nivre and Nilsson, 2004 Pereira et al,.",0,original
The tag propagation/elimination scheme is adopted from (Yarowsky 1995).,0,original
"Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT) (Hermjakob et al., 2008; Klementiev and Roth, 2006a; Meng et al., 2001; Knight and Graehl, 1998).",0,original
"3 The M&E Framework We model two RSRs, Cause and Contrast, adopting the de nitions of Marcu and Echihabi (2002) (henceforth M&E) for their Cause-ExplanationEvidence and Contrast relations, respectively.",0,original
"The idea of topic signature terms was introduced by Lin and Hovy (Lin and Hovy, 2000) in the context of single document summarization, and was later used in several multi-document summarization systems (Conroy et al., 2006; Lacatusu et al., 2004; Gupta et al., 2007).",0,original
"The second type has clear interpretation as a probability model, but no criteria to determine the number of clusters (Brown et al. , 1992; Kneser and Ney, 1993).",0,original
"3.1 Learning Chunk-based Translation We learn chunk alignments from a corpus that has been word-aligned by a training toolkit for wordbased translation models: the Giza++ (Och and Ney, 2000) toolkit for the IBM models (Brown et al. , 1993).",0,original
"However, they can be usefully employed during system development, for example, for quickly assessing modeling ideas or for comparing across different system configurations (Papineni et al. 2002; Bangalore, Rambow, and Whittaker 2000).",0,original
"(2002), who retrain the Ratnaparkhi (1996) tagger and reach accuracies of 93% using CTB-I.",0,original
"6 Experiments We evaluated the translation quality of the system using the BLEU metric (Papineni et al. , 2002).",0,original
"Our MT experiments use a re-implementation of Moses (Koehn et al., 2003) called Phrasal, which provides an easier API for adding features.",0,original
"Recently, Wikipedia is emerging as a source for extracting semantic relationships (Suchanek et al., 2007; Kazama and Torisawa, 2007).",0,original
"For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning (Brill, 1995), decision trees (Black et al. , 1992), markov model (Cutting et al. 1992), maximum entropy methods (Ratnaparkhi, 1996) etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS (Garside and Smith, 1997).",0,original
"Until now, translation models have been evaluated either subjectively (e.g. White and O'Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b).",0,original
Researchers have mostly looked at representing words by their surrounding words (Lund and Burgess 1996) and by their syntactical contexts (Hindle 1990; Lin 1998).,0,original
"To compare the performance of different taggers learned by different mechanisms, one can measure the precision, recall and F-measure, given by precision = # correct predictions# predicted gene mentions recall = # correct predictions# true gene mentions F-measure = a96a15a14 precision a14 recallprecision a44 recall In our evaluation, we compared the proposed semi-supervised learning approach to the state of the art supervised CRF of McDonald and Pereira (2005), and also to self-training (Celeux and Govaert 1992; Yarowsky 1995), using the same feature set as (McDonald and Pereira 2005).",0,original
", 1998; Traupman and Wilensky, 2003; Yarowsky, 1995).",0,original
"3.2.2 Features We used eight features (Och and Ney, 2003; Koehn et al., 2003) and their weights for the translations.",0,original
"As the most concise definition we take the first sentence of each article, following (Kazama and Torisawa, 2007).",0,original
"2005; Choi et al., 2006; Ku et al., 2006; Titov and McDonald, 2008).",0,original
"Recently there have been some works on using multiple treebanks for domain adaptation of parsers, where these treebanks have the same grammar formalism (McClosky et al., 2006b; Roark and Bacchiani, 2003).",0,original
"This program differs from earlier work in its almost complete lack of hand-crafting, relying instead on a very small corpus of Penn Wall Street Journal Tree-bank text (Marcus et al. , 1993) that has been marked with co-reference information.",0,original
"Nevertheless, the generated rules are strictly required to be derived from the contiguous translational equivalences (Galley et al, 2006; Marcu et al, 2006; Zhang et al, 2007, 2008a, 2008b; Liu et al, 2006, 2007).",0,original
"The other utilizes a sort of parallel texts, such as multiple translation of the same text (Barzilay and McKeown, 2001; Pang et al., 2003), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Dolan et al., 2004), and bilingual corpus (Wu and Zhou, 2003; Bannard and Callison-Burch, 2005).",0,original
Note in passing that the ratio 1.04-1.08/99.7% compares very favourably with other systems; c.f. 3.0/99.3% by POST (Weischedel et al. 1993) and 1.04/97.6% or 1.09/98.6% by de Marcken (1990).,0,original
Like the work of Jing and McKeown (2000) and Mani et al.,0,original
"The learning algorithm follows the global strategy introduced in (Collins, 2002) and adapted in (Carreras and M`arquez, 2004b) for partial parsing tasks.",0,original
"5.1 Pharaoh The baseline system we used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004), a freely available decoder for phrase-based translation models: p(e|f) = p(f|e) pLM(e)LM  pD(e,f)D length(e)W(e) (10) We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in (Koehn et al. , 2003) to obtain a single many-to-many word alignment for each sentence pair.",0,original
"(2005), Ponzetto and Strube (2006)) and the exploitation of advanced techniques that involve joint learning (e.g., Daume III and Marcu (2005)) and joint inference (e.g., Denis and Baldridge (2007)) for coreference resolution and a related extraction task.",0,original
"Another alternative for future work is to compare the dynamic programming approach taken here with the beam-search approach of Collins and Roark (2004), which allows more global features.",0,original
"The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al. , 2003; Al-Onaizan et al. , 2004), which includes some heuristic filtering to mal statement here.",0,original
"Neural networks have been used in NLP in the past, e.g. for machine translation (Asuncion Castano et al., 1997) and constituent parsing (Titov and Henderson, 2007).",0,original
"We implemented an N-gram indexer/estimator using MPI inspired by the MapReduce implementation of N-gram language model indexing/estimation pipeline (Brants et al., 2007).",0,original
"1 Introduction Hyponymy relations can play a crucial role in various NLP systems, and there have been many attempts to develop automatic methods to acquire hyponymy relations from text corpora (Hearst, 1992; Caraballo, 1999; Imasumi, 2001; Fleischman et al. , 2003; Morin and Jacquemin, 2003; Ando et al. , 2003).",0,original
"Non-anaphoric definite descriptions have been detected using heuristics (e.g., Vieira and Poesio (2000)) and unsupervised methods (e.g., Bean and Riloff (1999)).",0,original
"Many strategies have been proposed to integrate morphology information in SMT, including factored translation models (Koehn and Hoang, 2007), adding a translation dictionary containing inflected forms to the training data (Schwenk et al., 2008), entirely replacing surface forms by representations built on lemmas and POS tags (Popovic and Ney, 2004), morphemes learned in an unsupervised manner (Virpojia et al., 2007), and using Porter stems and even 4-letter prefixes for word alignment (Watanabe et al., 2006).",0,original
"We use the same feature processing as Haghighi and Klein (2006), with the addition of context features in a window of3.",0,original
"This approach is similar to conventional techniques for automatic thesaurus construction (Lin, 1998).",0,original
"We will employ the structural correspondence learning (SCL) domain adaption algorithm used in (Blitzer et al., 2007) for linking the translated text and the natural text.",0,original
"(Koehn et al., 2003; Och and Ney, 2004)).",0,original
"1 Introduction Word alignment is a critical component in training statistical machine translation systems and has received a significant amount of research, for example, (Brown et al., 1993; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2007), including work leveraging syntactic parse trees, e.g., (Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008).",0,original
"Dunning (1993) also used windows of size 2, which corresponds to word bigrams.",0,original
"Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al. , 2003), or not at all (Zens and Ney, 2004; Kumar et al. , 2005).",0,original
"We can, however, produce a useful surrogate: a pair of monolingual WCFGs with structures projected by G and weights that, when combined, underestimate the costs of G. Parsing optimally relative to a synchronous grammar using a dynamic program requires time O(n6) in the length of the sentence (Wu, 1997).",0,original
"We observe that the tagging method exploits the one sense per collocation property (Yarowsky, 1995), which means that WSD based on collocations is probably finer than WSD based on simple words, since ambiguity is reduced (Klapaftis and Manandhar, 2008).",0,original
"However, the maximum entropy (Jaynes, 1978) was found to yield higher accuracy than nave Bayes in a subsequent comparison by Klein and Manning (2002), who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data.",0,original
"For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g. , see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al. , 2004; Xia and McCord, 2004)).",0,original
"In (Wu, 1997), these forbidden subsequences are called inside-out transpositions.",0,original
"In order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using a maximum entropy tagger (Ratnaparkhi, 1998) and parsed using the Collins parser (Collins, 1997).",0,original
"These tasks are generally treated as sequential labeling problems incorporating the IOB tagging scheme (Ramshaw and Marcus, 1995).",0,original
"The X 2 statistic is performing at least as well as G 2, and the results show that the average level of generalization is slightly higher for G 2 than X 2 . This suggests a possible explanation for the results presented here and those in Dunning (1993): that the X 2 statistic provides a less conservative test when counts in the contingency table are low.",0,original
"It ewduato.s the pairwise agreement mnong a set; of coders making category.iudgment, correcting tbr expected chance agreement (Carletta, 1996).",0,original
"There are many choices for modeling co-occurrence data (Brown et al. , 1992; Pereira et al. , 1993; Blei et al. , 2003).",0,original
"We evaluate translation output using case-insensitive BLEU (Papineni et al., 2001), as provided by NIST, and METEOR (Banerjee and Lavie, 2005), version 0.6, with Porter stemming and WordNet synonym matching.",0,original
(2002) and Turney (2002).,0,original
"Collins and Roark (2004) used the averaged perceptron (Collins, 2002a).",0,original
"In general, previous work in opinion mining includes document level sentiment classification using supervised (Chaovalit and Zhou, 2005) and unsupervised methods (Turney, 2002), machine learning techniques and sentiment classification considering rating scales (Pang, Lee and Vaithyanathan, 2002), and scoring of features (Dave, Lawrence and Pennock, 2003).",0,original
Its distribution is asymptotic to a  2 distribution and can hence be used as a test statistic (Dunning 1993).,0,original
"They developed a simple heuristic function for Model 2 from (Brown et al. , 1993) which was non admissible.",0,original
"The Xerox experiments (Cutting et al. , 1992) correspond to something between D1 and D2, and between TO and T1, in that there is some initial biasing of the probabilities.",0,original
"(Dolan, 1994) and (Krovetz and Croft, 1992) claim that fine-grained semantic distinctions are unlikely to be of practical value for many applications.",0,original
"In the following, we summarize the optimization algorithm for the unsmoothed error counts presented in (Och, 2003) and the implementation detailed in (Venugopal and Vogel, 2005).",0,original
"(McClosky et al., 2006) uses selftraining to perform this step) (2) smoothing, usually this is performed using a markovization procedure (Collins, 1999; Klein and Manning, 2003a) and (3) make the data more coarse (i.e. clustering).",0,original
The SENSEVAL '~tan(lard is clearly beaten by the earlier results of Yarowsky (1995) (96.5 % precision) and Schiitze (1992) (92 % precision).,0,original
"In the future, we plan to explore our discriminative framework on a full distortion model (Koehn et al. , 2003) or even a hierarchical model (Chiang, 2005).",0,original
"Previous workonsentimentanalysishascoveredawiderange of tasks, including polarity classification (Pang et al. , 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al. , 2005; Choi et al. , 2006).",0,original
"Alternatively, order is modelled in terms of movement of automatically induced hierarchical structure of sentences (Chiang, 2005; Wu, 1997).",0,original
"The system used for baseline experiments is two runs of IBM Model 4 (Brown et al. , 1993) in the GIZA++ (Och and Ney, 2003) implementation, which includes smoothing extensions to Model 4.",0,original
"We run the decoder with its default settings and then use Koehn's implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set.",0,original
"To use the data from NANC, we use self-training (McClosky et al. , 2006).",0,original
"Statistical and information theoretic approaches (Hindle and Rooth, 1993), (Ratnaparkhi et al. , 1994),(Collins and Brooks, 1995), (Franz, 1996) Using lexical collocations to determine PPA with statistical techniques was first proposed by (Hindle and Rooth, 1993).",0,original
"Algorithms for the computation of first-order associations have been used in lexicography for the extraction of collocations (Smadja, 1993) and in cognitive psychology for the simulation of associative learning (Wettler & Rapp, 1993).",0,original
"5 Experiments For all experiments, we trained and tested on the Penn treebank (PTB) (Marcus et al., 1993).",0,original
"Until now, translation models have been evaluated either subjectively (e.g. White and O'Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b).",0,original
"272 Similarity-based estimation was first used for language modeling in the cooccurrence smoothing method of Essen and Steinbiss (1992), derived from work on acoustic model smoothing by Sugawara et al.",0,original
(2004) we use k = 50 and obtain our thesaurus using the distributional similarity metric described by Lin (1998).,0,original
"The simplest version, called Dependency Model with Valence (DMV), has been used in isolation and in combination with other models (Klein and Manning, 2004; Smith and Eisner, 2006b).",0,original
"Please note that our approach is very different from other approaches to context dependent rule selection such as (Ittycheriah and Roukos, 2007) and (He et al., 2008).",0,original
"We evaluate this method over the part of speech tagged portion of the Penn Treebank corpus (Marcus et al. , 1993).",0,original
"Rather than learning how strings in one language map to strings in another, however, translation now involves learning how systematic patterns of errors in ESL learners English map to corresponding patterns in native English 2.2 A Noisy Channel Model of ESL Errors If ESL error correction is seen as a translation task, the task can be treated as an SMT problem using the noisy channel model of (Brown et al. , 1993): here the L2 sentence produced by the learner can be regarded as having been corrupted by noise in the form of interference from his or her L1 model and incomplete language models internalized during language learning.",0,original
"Chiang (2005) distinguishes statistical MT approaches that are  syntactic in a formal sense, going beyond the  nite-state underpinnings of phrasebased models, from approaches that are syntactic in a linguistic sense, i.e. taking advantage of a priori language knowledge in the form of annotations derived from human linguistic analysis or treebanking.1 The two forms of syntactic modeling are doubly dissociable: current research frameworks include systems that are  nite state but informed by linguistic annotation prior to training (e.g., (Koehn and Hoang, 2007; Birch et al., 2007; Hassan et al., 2007)), and also include systems employing contextfree models trained on parallel text without bene t of any prior linguistic analysis (e.g.",0,original
"It is sometimes assumed that estimates of entropy (e.g. , Shannon's estimate that English is 75% redundant, Brown et al's (1992) upper bound of 1.75 bits per character for printed English) are directly 3There are some cases where words are deliberately misspelled in order to get better output from the synthesizer, such as coyote spelled kiote.",0,original
"This framework is 211 commonly used in generation and summarization applications where the selection process is driven by multiple constraints (Marciniak and Strube, 2005; Clarke and Lapata, 2007).",0,original
"We used the implementation of MaxEnt classifier described in (Manning and Klein, 2003).",0,original
"(2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005a; Read, 2005).",0,original
"For example, in the WSJ corpus, part of the Penn Treebank 3 release (Marcus et al., 1993), the string in (1) is a variation 12-gram since off is a variation nucleus that is tagged preposition (IN) in one corpus occurrence and particle (RP) in another.1 Dickinson (2005) shows that examining those cases with identical local contextin this case, lookingat ward off aresultsinanestimated error detection precision of 92.5%.",0,original
"For more detail, see Chen & Martin (2007).",0,original
"Unlike (Le Nguyen & Ho, 2004), one interesting idea proposed by (Barzilay & Lee, 2003) is to cluster similar pairs of paraphrases to apply multiplesequence alignment.",0,original
"5.1 The baseline System used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004), which uses a beam search algorithm for decoding.",0,original
"A monotonic segmentation copes with monotonic alignments, that is, j < k ??aj < ak following the notation of (Brown et al. , 1993).",0,original
"In order to prove this induction step, we use the concept of order annotations (Kuhlmann, 2007; Kuhlmann and Mohl, 2007), which are strings that lexicalise the precedence relation between the nodes of a dependency tree.",0,original
"In additioil, (Yarowsky, 1995), (Gale, Church &; Yarowsky, 1992) point ou; that there is a st, rent tenden(:y for words 1;O occur in (}Ile sense within any given dis:ourse (""one sense pe, r dis:ourse"").",0,original
"First, the Wikipedia gazetteer improved the accuracy as expected, i.e., it reproduced the result of Kazama and Torisawa (2007) for Japanese NER.",0,original
"Such measures as mutual information (Turney 2001), latent semantic analysis (Landauer et al. , 1998), log-likelihood ratio (Dunning, 1993) have been proposed to evaluate word semantic similarity based on the co-occurrence information on a large corpus.",0,original
There have been many approaches to compute the similarity between words based on their distribution in a corpus (Hindle 1990; Landauer and Dumais 1997; Lin 1998).,0,original
"Ontologies are formal specifications of a conceptualization (Gruber, 1993) so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat (Handschuh et al. , 2001) for the purpose of linguistic annotation.",0,original
"In the original work (Brown et al. , 1993) the posterior probability p(eI1|fJ1 ) is decomposed following a noisy-channel approach, but current stateof-the-art systems model the translation probability directly using a log-linear model(Och and Ney, 2002): p(eI1|fJ1 ) = exp parenleftBigsummationtextM m=1 mhm(e I1,fJ1 ) parenrightBig summationdisplay ?eI1 exp parenleftBigsummationtextM m=1 mhm(?eI1,fJ1 ) parenrightBig, (2) with hm different models, m scaling factors and the denominator a normalization factor that can be ignored in the maximization process.",0,original
"We chose to train maximum entropy models (Berger et al., 1996).",0,original
"The MBT POS tagger (Daelemans et al. , 1996) is used to provide POS information.",0,original
"Several automatic sentence alignment approaches have been proposed based on sentence length (Brown et al., 1991) and lexical information (Kay and Roscheisen, 1993).",0,original
"3 Network Evaluation We present an evaluation which has been carried out on an initial set of annotations of English articles from The Wall Street Journal (covering those annotated at the syntactic level in the Penn Treebank (Marcus et al., 1993)).",0,original
"For instance, we may find metrics which compute similarities over shallow syntactic structures/sequences (Gimenez and M`arquez, 2007; Popovic and Ney, 2007), constituency trees (Liu and Gildea, 2005) and dependency trees (Liu and Gildea, 2005; Amigo et al., 2006; Mehay and Brew, 2007; Owczarzak et al., 2007).",0,original
"Sentiment classification is a well studied problem (Wiebe, 2000; Pang et al., 2002; Turney, 2002) and in many domains users explicitly 1We use the term aspect to denote properties of an object that can be rated by a user as in Snyder and Barzilay (2007).",0,original
"The statistical machine translation approach is based on the noisy channel paradigm and the Maximum-A-Posteriori decoding algorithm (Brown et al. , 1993).",0,original
"The basic model uses the following features, analogous to Pharaohs default feature set:  P( | ) and P( | )  the lexical weights Pw( | ) and Pw( | ) (Koehn et al. , 2003);1  a phrase penalty exp(1);  a word penalty exp(l), where l is the number of terminals in .",0,original
"3.2 Conversion to Dependencies 3.2.1 Syntactic Dependencies There exists no large-scale dependency treebank for English, and we thus had to construct a dependency-annotated corpus automatically from the Penn Treebank (Marcus et al., 1993).",0,original
"The text was split at the sentence level, tokenized and PoS tagged, in the style of the Wall Street Journal Penn TreeBank (Marcus et al., 1993).",0,original
"First, it recognizes non-recursive Base Noun Phrase (BNP) (our specifications for BNP resemble those in Ramshaw and Marcus 1995).",0,original
"Within this class would fall the Lexical Implication Rules (LIRs) of Ostler and Atkins (1991), the lexical rules of Copestake and Briscoe (1991), the Generative Lexicon of Pustejovsky (1995), and the ellipsis recovery procedUres of Viegas and Nirenburg (1995).",0,original
"In fact, a limitation of the experiments described in this paper is that the loglinear weights for the glass-box techniques were optimized for BLEU using Ochs algorithm (Och, 2003), while the linear weights for 55 black-box techniques were set heuristically.",0,original
"The translation models and lexical scores were estimated on the training corpus whichwasautomaticallyalignedusingGiza++(Och et al. , 1999) in both directions between source and target and symmetrised using the growing heuristic (Koehn et al. , 2003).",0,original
"3.3 Voted Perceptron Unlike other methods discussed so far, voted perceptron training (Collins, 2002) attempts to minimize the difference between the global feature vector for a training instance and the same feature vector for the best-scoring labeling of that instance according to the current model.",0,original
"From this point of view, some of the measures used in the evaluation of Machine Translation systems, such as BLEU (Papineni et al. , 2002), have been imported into the summarization task.",0,original
"Expectation Maximization does surprisingly well on larger data sets and is competitive with the Bayesian estimators at least in terms of cross-validation accuracy, confirming the results reported by Johnson (2007).",0,original
"1.2 Recent work A few publications, so far, deal with POS-tagging of Northern Sotho; most prominently, de Schryver and de Pauw (2007) have presented the MaxTag method, a tagger based on Maximum Entropy 38 Learning (Berger et al., 1996) as implemented in the machine learning package Maxent (Le, 2004).",0,original
"(Chiang, 2005; Chiang, 2007; Wu, 1997)).",0,original
"determining document orientation (or polarity), as in deciding if a given Subjective text expresses a Positive or a Negative opinion on its subject matter (Pang and Lee, 2004; Turney, 2002); 3.",0,original
"These feature vectors and the associated parser actions are used to train maximum entropy models (Berger et al., 1996).",0,original
"3.1 Generation using PHARAOH PHARAOH (Koehn et al. , 2003) is an SMT system that uses phrases as basic translation units.",0,original
"Note that the results of MB-D here cannot be directly compared with those in Yarowsky (1995), because the data used are different.",0,original
"While close attention has been paid to multi-document summarization technologies (Barzilay et al. 2002, Goldstein et al 2000), the inherent properties of humanwritten multi-document summaries have not yet been quantified.",0,original
"The current release of PDTB2.0 contains the annotations of 1,808 Wall Street Journal articles (~1 million words) from the Penn TreeBank (Marcus et al. 1993) II distribution and a total of 40,600 discourse connective tokens (Prasad et al. 2008b).",0,original
"Thus, GCNF is a more restrictive normal form than those used by Wu (1997) and Melamed (2003).",0,original
"One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques (Brown et al., 1993) to mine new translations.",0,original
"The token precision is higher than 90% in all of the corpora, including the movie domain, which is considered to be difficult for SA (Turney, 2002).",0,original
"To train the model, we use the averaged perceptron algorithm described by Collins (2002).",0,original
"We were already using a generative statistical model for part-of-speech tagging (Weischedel et al. 1993), and more recently, had begun using a generative statistical model for name finding (Bikel et al. 1997).",0,original
"When an S alignment exists, there will always also exist a P alignment such that P a65 S. The English sentences were parsed using a state-of-the-art statistical parser (Charniak, 2000) trained on the University of Pennsylvania Treebank (Marcus et al. , 1993).",0,original
"My guess is that the features used in e.g., the Collins (2003) or Charniak (2000) parsers are probably close to optimal for English Penn Treebank parsing (Marcus et al., 1993), but that other features might improve parsing of other languages or even other English genres.",0,original
"In particular, we use a randomly-selected corpus the first five columns as information-like. consisting of a 6.7 million word subset of the TREC Similarly, since the last four columns share databases (DARPA, 1993-1997).",0,original
"Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training (Pereira and Schabes, 1992; Klein and Manning, 2004; Smith and Eisner, 2004; Smith and Eisner, 2005) over bootstrapping approaches like selftraining (McClosky et al., 2006) to feature-based enhancements of discriminative reranking models (Koo et al., 2008) and the application of semisupervised SVMs (Wang et al., 2008).",0,original
"To find the optimal coefficients  for a loglinear combination of these experts, we use separate development data, using the following procedure due to Och (2003): 1.",0,original
"1 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al. , 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003).",0,original
"(2003), or in more recent implementation, the MOSES MT system1 (Koehn et al., 2007).",0,original
"Our system attempts to recognize these syntactic patterus; in addition, it considers as unfamiliar some definites occurring in 4This list was developed by hand; more recently, Bean and Riloff (1999) proposed methods for autolnatically extracting fl'om a corpus such special predicates, i.e., heads that correlate well with discourse novelty.",0,original
"This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999).",0,original
"(Termbased versions of this premise have motivated much sentiment-analysis work for over a decade (Das and Chen, 2001; Tong, 2001; Turney, 2002)).",0,original
"In the usual case considered by Dunning (1993) and discussed by Manning and Sch utze (1999), the right-hand side of the equation is larger than the left-hand side.",0,original
"The similarities become moreapparentwhenweconsiderthecanonical-form binary-bracketing ITG (Wu, 1997) shown here: S  A | B | C A  [AB] | [BB] | [CB] | [AC] | [BC] | [CC] B  AA | BA | CA | AC | BC | CC C  e/ f (3) (3) is employed in place of (2) to reduce redundant alignments and clean up EM expectations.1 More importantly for our purposes, it introduces a preterminal C, which generates all phrase pairs or cepts.",0,original
"We use a bidirectional search strategy (Woods, 1976; Satta and Stock, 1994), and our algorithm is based on Perceptron learning (Collins, 2002).",0,original
"There are similarities with dependency grammars here because such constraint graphs are also produced by dependency grammars (Covington, 1990) (Kashket, 1986).",0,original
"This kind of synchronizer stands in contrast to more ad-hoc approaches (e.g. , Matsumoto, 1993; Meyers, 1996; Wu, 1998; Hwa et al. , 2002).",0,original
"We report precision, recall and balanced F-measure (Och and Ney, 2003).",0,original
"In particular, previous work (Ratnaparkhi, Roukos, and Ward 1994; Abney 1997; Della Pietra, Della Pietra, and Lafferty 1997; Johnson et al. 1999; Riezler et al. 2002) has investigated the use of Markov random fields (MRFs) or log-linear models as probabilistic models with global features for parsing and other NLP tasks.",0,original
"We use five sentiment classification datasets, including the widely-used movie review dataset [MOV] (Pang et al., 2002) as well as four datasets containing reviews of four different types of products from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al., 2007).",0,original
Yarowsky (1995) used this method for word sense disambiguation.,0,original
"To extract such word clusters we used suffix arrays proposed in Yamamoto and Church (2001) and the pointwise mutual information measure, see Church and Hanks (1990).",0,original
"1 Introduction The field of sentiment classification has received considerable attention from researchers in recent years (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002, Wiebe et al. 2001, Bai et al. 2004, Yu and Hatzivassiloglou 2003 and many others).",0,original
"More specifically, the latter system uses the IBM-1 lexical parameters (Brown et al. 1993) for computing the translation probabilities of two possible new tuples: the one resulting when the null-aligned-word is attached to Table 6 Evaluation results for experiments on n-gram size incidence.",0,original
The reader is referred to Schmid (2000) and Collins (1997) for details.,0,original
"The first stage parser is a best-first PCFG parser trained on sections 2 through 22, and 24 of the Penn WSJ treebank (Marcus et al. , 1993).",0,original
"Wu (1997) demonstrated that for pairs of sentences that are less than 16 words, the ITG alignment space has a good coverage over all possibilities.",0,original
"Again, we find the clearest patterns in the graphs for precision, where Malt has very low precision near the root but improves with increasing depth, while MST shows the opposite trend (McDonald and Nivre, 2007).",0,original
"It was also included in the DUC 2004 evaluation plan where summary quality was automatically judged using a set of n-gram word overlap metrics called ROUGE (Lin and Hovy, 2003).",0,original
"Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. \[1993b, Equation 26\]).",0,original
"We show that the method of (Daume III, 2007), which was presented as a simple preprocessing step, is actually equivalent, except our representation explicitly separates hyperparameters which were tied in his work.",0,original
"In addition to their use in machine translation (Sato & Nagao, 1990; Brown et al. , 1993; Melamed, 1997), translation models can be applied to machineassisted translation (Sato, 1992; Foster et al. , 1996), cross-lingual information retrieval (SIGIR, 1996), and gisting of World Wide Web pages (Resnik, 1997).",0,original
"They may rely only on this information (e.g., (Turney, 2002; Whitelaw et al., 2005; Riloff and Wiebe, 2003)), or they may combine it with additional information as well (e.g., (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Bloom et al., 2007; Wilson et al., 2005a)).",0,original
"Wordalignment, however, isalmost exclusively done using statistics (Brown et al. , 1993; Hiemstra, 1996; Vogel et al. , 1999; Toutanova et al. , 2002).",0,original
"For classi cation, we use a maximum entropy model (Berger et al., 1996), from the logistic regression package in Weka (Witten and Frank, 2005), with all default parameter settings.",0,original
"General purpose text annotations, such as part-of-speech tags and noun-phrase bracketing, are costly to obtain but have wide applicability and have been used successfully to develop statistical NLP systems (e.g. , \[Church, 1989; Weischedel et al. , 1993\]).",0,original
"sister head tag X Table 4: Linguistic features in the current model compared to the models of Carroll and Rooth (1998), Collins (1997), and Charniak (2000) Negra, based on Collinss (1997) model for nonrecursive NPs in the Penn Treebank (which are also flat).",0,original
The data set that has become standard for evaluation machine learning approaches is the one first used by Ramshaw and Marcus (1995).,0,original
"One obvious first approach would be to run a simpler model for the first iteration (for example, Model 1 from machine translation (Brown et al. 1993), which tends to be very recall oriented) and use this to see subsequent iterations of the more complex model.",0,original
"The feature functions are combined under a log-linear framework, andtheweights aretuned bytheminimum-error-rate training (Och, 2003) using BLEU (Papineni et al., 2002) as the optimization metric.",0,original
"10Our experiments have shown that using averaging helps tremendously, confirming both the theoretical and practical results of (Collins, 2002).",0,original
"Without removing them, extracted rules cannot be triggered until when completely the same strings appear in a text.4 6 Performance Evaluation We measured the performance of our robust parsing algorithm by measuring coverage and degree of overgeneration for the Wall Street Journal in the Penn Treebank (Marcus et al. , 1993).",0,original
"   = ==              = = m aj j m j aj l i i l i ii m j j mlajdeft en pp m ap 0:1 11 1 2 0 0 0 ),( ),,|()|( ! )|( )|,Pr()|,( 00       eef (3) 1 A cept is defined as the set of target words connected to a source word (Brown et al. , 1993).",0,original
"Despite the above differences, since the theorems of convergence and their proof (Collins, 2002) are only dependent on the feature vectors, and not on the source of the feature definitions, the perceptron algorithm is applicable to the training of our CWS model.",0,original
"We selected 580 short sentences of length at most 50 characters from the 2002 NIST MT Evaluation test set as our development corpus and used it to tune s by maximizing the BLEU score (Och, 2003), and used the 2005 NIST MT Evaluation test set as our test corpus.",0,original
"Our named entity recognizer used a maximum entropy model, built with Adwait Ratnaparkhi's tools (Ratnaparkhi, 1996) to label word sequences as either person, place, company or none of the above based on local cues including the surrounding words and whether honorifics (e.g. Mrs. or Gen).",0,original
"The idea caught on very quickly: Suhm and Waibel (1994), Mast et aL (1996), Warnke et al.",0,original
"It is believed that improvement can be achieved by training the generative model based on a discriminative optimization criteria (Klein and Manning, 2002) in which the training procedure is designed to maximize the conditional probability of the parses given the sentences in the training corpus.",0,original
"This is an instance of the ITG alignment algorithm (Wu, 1997).",0,original
"We used a bottom-up, CKY-style decoder that works with binary xRs rules obtained via a synchronous binarization procedure (Zhang et al. , 2006).",0,original
"The last two counts (CAUS and ANIM) were performed on a 29-million word parsed corpus (\gall Street Journal 1988, provided by Michael Collins (Collins, 1997)).",0,original
Kappa coefficient is given in (1) (Carletta 1996) (1) )(1 )()( EP EPAP Kappa   = where P(A) is the proportion of times the annotators actually agree and P(E) is the proportion of times the annotators are expected to agree due to chance 3.,0,original
"This obviously does not preclude using the audio-based system together with other features such as utterance position, length, speakers roles, and most others used in the literature (Penn and Zhu, 2008).",0,original
"To obtain their corresponding weights, we adapted the minimum-error-rate training algorithm (Och, 2003) to train the outside-layer model.",0,original
"The two annotators agreed on the annotations of 385/453 turns, achieving 84.99% agreement (Kappa = 0.68 (Carletta, 1996)).",0,original
"The most commonly used MT evaluation metric in recent years has been IBMs Bleu metric (Papineni et al., 2002).",0,original
"Using our WSD model to constrain the translation candidates given to the decoder hurts translation quality, as measured by the automated BLEU metric (Papineni et al. , 2002).",0,original
"Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by Riezler and Maxwell (2006).",0,original
"We used *TH*=3 following ""a very rough rule of thumb"" used for word-based mutual information in (Church and Hanks, 1990).",0,original
"By habit, most systems for automatic role-semantic analysis have used Pennstyle constituents (Marcus et al., 1993) produced by Collins (1997) or Charniaks (2000) parsers.",0,original
"3 Maximum Entropy Classifier For local classifiers, we used a maximum entropy model which is a common choice for incorporating various types of features for classification problems in natural language processing (Berger et al. , 1996).",0,original
"The first of these nonstructural problems with Model 1, as standardly trained, is that rare words in the source language tend to act as garbage collectors (Brown et al. , 1993b; Och and Ney, 2004), aligning to too many words in the target language.",0,original
"Alignment spaces can emerge from generative stories (Brown et al. , 1993), from syntactic notions (Wu, 1997), or they can be imposed to create competition between links (Melamed, 2000).",0,original
"5 Experimental Data The sense-tagged text and feature set used in these experiments are the same as in (Bruce et al. , 1996).",0,original
"The phrasebased machine translation (Koehn et al., 2003) uses the grow-diag-final heuristic to extend the word alignment to phrase alignment by using the intersection result.",0,original
"In our VB experiments we set i = j = 0.1,i  {1,,|T|},j  {1,,|V |}, which yielded the best performance on most reported metrics in Johnson (2007).",0,original
"Our approach to statistical machine translation differs from the model proposed in (Brown et al. , 1993) in that:  We compute the joint model P(Ws, WT) from the bilanguage corpus to account for the direct mapping of the source sentence Ws into the target sentence I?VT that is ordered according to the  source language word order.",0,original
"To make sense tagging more precise, it is advisable to place constraint on the translation counterpart c of w. SWAT considers only those translations c that has been linked with w based the Competitive Linking Algorithm (Melamed 1997) and logarithmic likelihood ratio (Dunning 1993).",0,original
"In (Post and Gildea, 2008; Shen et al., 2008), target trees were employed to improve the scoring of translation theories.",0,original
"The number of weights wi is 3 plus the number of source languages, and they are trained using minimum error-rate training (MERT) to maximize the BLEU score (Och, 2003) on a development set.",0,original
"Beam-search parsing using an unnormalized discriminative model, as in Collins and Roark (2004), requires a slightly different search strategy than the original generative model described in Roark (2001; 2004).",0,original
"They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al. , 2002), and inducing statistical machine translation models (Koehn et al. , 2003).",0,original
"(Shfitze, 1992; Yarowsky, 1995) all use multiple context words as discriminating features.",0,original
"To this extent, we cast the supersense tagging problem as a sequence labeling task and train a discriminative Hidden Markov Model (HMM), based on that of Collins (2002), on the manually annotated Semcor corpus (Miller et al. , 1993).",0,original
"3 GM Representation of IBM MT Models In this section we present a GM representation for IBM model 3 (Brown et al. , 1993) in fig.",0,original
"For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems (e.g. , see (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Och et al. , 2004; Xia and McCord, 2004)).",0,original
"The first one is a hypotheses testing approach (Gale and Church, 1991; Melamed, 2001; Tufi 2002) while the second one is closer to a model estimating approach (Brown et al. , 1993; Och and Ney, 2000).",0,original
"We use a bootstrap approach in which we first extract 1-to-n word alignments using an existing word aligner, and then estimate the confidence of those alignments to decide whether or not the n words have to be grouped; if so, this group is conwould thus be completely driven by the bilingual alignment process (see also (Wu, 1997; Tiedemann, 2003) for related considerations).",0,original
"In particular, we used this method with WordNet (Miller et al. , 1993) and using the same training data.",0,original
"For word alignment accuracy, F-measure is reported, i.e., the harmonic mean of precision and recall against a gold-standard reference set; for translation quality, Bleu (Papineni et al. , 2002) and its variation of NIST scores are reported.",0,original
"The feature weights i in the log-linear model are determined using a minimum error rate training method, typically Powells method (Och, 2003).",0,original
"In Section 3 we review (Cahill et al. , 2004)s method for recovering English NLDs in treebank-based LFG approximations.",0,original
"Evaluations are typically carried out on newspaper texts, i.e. on section 23 of the Penn Treebank (PTB) (Marcus et al., 1993).",0,original
"Until now, we have defined BestLossk, a to be the minimum of the loss given that the kth feature is updated an optimal amount: BestLossk, amin d LogLossUpda,k,d In this section we sketch a different approach, based on results from Collins, Schapire, and Singer (2002), which leads to an algorithm very similar to that for ExpLoss in Figures 3 and 4.",0,original
"Translation qualities are measured by uncased BLEU (Papineni et al. 2002) with 4 reference translations, sysids: ahb, ahc, ahd, ahe.",0,original
McClosky et al. 2006).,0,original
"Thus, a lot of alignment techniques have been suggested at; the sentence (Gale et al. , 1993), phrase (Shin et al. , 1996), nomt t)hrase (Kupiec, 1993), word (Brown et al. , 1993; Berger et al. , 1996; Melamed, 1997), collocation (Smadja et al. , 1996) and terminology level.",0,original
"In Hirschberg and Nakatani (1996), average reliability (measured using the kappa coefficient discussed in Carletta \[1996\]) of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is.8 or above for both read and spontaneous speech; values of at least .8 are typically viewed as representing high reliability (see Section 3.2).",0,original
"Model 4 of (Brown et al. , 1993) is also a first-order alignment model (along the source positions) like the HMM, trot includes also fertilities.",0,original
"1 Introduction Robust statistical syntactic parsers, made possible by new statistical techniques (Collins, 1999; Charniak, 2000; Bikel, 2004) and by the availability of large, hand-annotated training corpora such as WSJ (Marcus et al. , 1993) and Switchboard (Godefrey et al. , 1992), have had a major impact on the field of natural language processing.",0,original
"2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003).",0,original
"The translations are evaluated in terms of BLEU score (Papineni et al., 2002).",0,original
"Alignment is often used in training both generative and discriminative models (Brown et al., 1993; Blunsom et al., 2008; Liang et al., 2006).",0,original
"The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al. , 1991; Dagan and Itai, 1994), or sense-tagged seed examples (Yarowsky, 1995).",0,original
"However, most of them do not build a NEs resource but exploit external gazetteers (Bunescu and Pasca, 2006), (Cucerzan, 2007).",0,original
"unlabeled R 100% 20/08/199605/08/1997 (351 days) 50% 20/08/199617/02/1997 (182 days) 10% 20/08/199624/09/1996 (36 days) labeled WSJ 50% sections 0012 (23412 sentences) 25% lines 1  292960 (11637 sentences) 5% lines 1  58284 (2304 sentences) 1% lines 1  11720 (500 sentences) 0.05% lines 1  611 (23 sentences) Table 1: Corpora used for the experiments: unlabeled Reuters (R) corpus for attachment statistics, labeled Penn treebank (WSJ) for training the Collins parser.",0,original
Clarke and Lapata (2007) included discourse level features in their framework to leverage context for enhancing coherence.,0,original
"In contrast, globally optimized clustering decisions were reported in (Luo et al. , 2004) and (DaumeIII and Marcu, 2005a), where all clustering possibilities are considered by searching on a Bell tree representation or by using the Learning as Search Optimization (LaSO) framework (DaumeIII and Marcu, 2005b) respectively, but the first search is partial and driven by heuristics and the second one only looks back in text.",0,original
"Similar to Goldwater and Griffiths (2007) and Johnson (2007), Toutanova and Johnson (2007) also use Bayesian inference for POS tagging.",0,original
"On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al. , 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al. , 1996) or neural networks (Schmid, 1994).",0,original
"It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) instead of the original word-based approach.",0,original
"We rerank derivations with cube growing, a lazy beam search algorithm (Huang and Chiang, 2007).",0,original
"Alternatively, one can view (2) as inducing an alignment between terms in the h to the terms in the t, somewhat similar to alignment models in statistical MT (Brown et al. , 1993).",0,original
"Reranking approaches (Charniak and Johnson, 2005; Chen et al. , 2002; Collins and Koo, 2005; Ji et al. , 2006; Roark et al. , 2006) have been successfully applied to many NLP applications, including parsing, named entity recognition, sentence boundary detection, etc. To the best of our knowledge, reranking approaches have not been used for POS tagging, possibly due to the already high levels of accuracy for English, which leave little room for further improvement.",0,original
"Generative word alignment models, initially developed at IBM (Brown et al., 1993), and then augmented by an HMM-based model (Vogel et al., 1996), have provided powerful modeling capability for word alignment.",0,original
"Second, the automatic approach, in which the model is automatically obtained from corpora (either raw or annotated) 1, and consists of n-grams (Garside et al. , 1987; Cutting et ah, 1992), rules (Hindle, 1989) or neural nets (Schmid, 1994).",0,original
"Step Description mean stddev % 1.5 Sample 1.5s 0.07s 0.7% 1.6 Extraction 38.2s 0.13s 18.6% 1.7 Build tree 127.6s 27.60s 62.3% 1.8 Percolation 31.4s 4.91s 15.3% 1.911 Leaf updates 6.2s 1.75s 3.0% 1.511 Total 204.9s 32.6s 100.0% 2004),10 the only one that we were able to train and test under exactly the same experimental conditions (including the use of POS tags from Ratnaparkhi (1996)).",0,original
"Work in this area includes that of Lin and Hovy (2003) and Pastra and Saggion (2003), both of whom inspect the use of Bleu-like metrics (Papineni et al. , 2002) in summarization.",0,original
"The disambiguation algorithms also require that the semantic relatedness measures WordNet::Similarity (Pedersen et al. , 2004) be installed.",0,original
"3For decoding, loc is averaged over the training iterations as in Collins and Roark (2004).",0,original
"Networks (Toutanova et al., 2003) 97.24 SVM (Gimenez and M`arquez, 2003) 97.05 ME based a bidirectional inference (Tsuruoka and Tsujii, 2005) 97.15 Guided learning for bidirectional sequence classification (Shen et al., 2007) 97.33 AdaBoost.SDF with candidate features (=2,=1,=100, W-dist) 97.32 AdaBoost.SDF with candidate features (=2,=10,=10, F-dist) 97.32 SVM with candidate features (C=0.1, d=2) 97.32 Text Chunking F=1 Regularized Winnow + full parser output (Zhang et al., 2001) 94.17 SVM-voting (Kudo and Matsumoto, 2001) 93.91 ASO + unlabeled data (Ando and Zhang, 2005) 94.39 CRF+Reranking(Kudo et al., 2005) 94.12 ME based a bidirectional inference (Tsuruoka and Tsujii, 2005) 93.70 LaSo (Approximate Large Margin Update) (Daume III and Marcu, 2005) 94.4 HySOL (Suzuki et al., 2007) 94.36 AdaBoost.SDF with candidate featuers (=2,=1,=, W-dist) 94.32 AdaBoost.SDF with candidate featuers (=2,=10,=10,W-dist) 94.30 SVM with candidate features (C=1, d=2) 94.31 One of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.",0,original
"Yarowsky proposed the unsupervised learning method for WSD(Yarowsky, 1995).",0,original
"1 Introduction Over the last few years, several automatic metrics for machine translation (MT) evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle (Papineni et al. , 2002; Melamed et al. , 2003).",0,original
"The models are trained using the Margin Infused Relaxed Algorithm or MIRA (Crammer et al., 2006) instead of the standard minimum-error-rate training or MERT algorithm (Och, 2003).",0,original
"There are many POS taggers developed using different techniques for many major languages such as transformation-based error-driven learning (Brill, 1995), decision trees (Black et al., 1992), Markov model (Cutting et al., 1992), maximum entropy methods (Ratnaparkhi, 1996) etc for English.",0,original
The work most similar in spirit to ours that of Turney (2002).,0,original
"Section 4 describes the online training procedure and compares it to the well known perceptron training algorithm (Collins, 2002).",0,original
"Then, we used the refinement technique grow-diag-final-and (Koehn et al., 2003) to all 50  50 bidirectional alignment pairs.",0,original
"Examples of such affinities include synonyms (Terra and Clarke, 2003), verb similarities (Resnik and Diab, 2000) and word associations (Rapp, 2002).",0,original
"(Carpuat and Wu, 2007) and (He et al., 2008), the specific technique we used by means of a context language model is rather different.",0,original
"Second, movie reviews are apparently harder to classify than reviews of other products (Turney, 2002; Dave, Lawrence, and Pennock, 2003).",0,original
(2005) 86.6 86.7 1.19 Klein and Manning (2003) 86.9 85.7 86.3 30.9 1.10 Charniak (1997) 87.4 87.5 1.00 Collins (1997) 88.6 88.1 0.91 Table 3: Comparison with other parsers (sentences of length  40) as head information.,0,original
"Movie and product reviews have been the main focus of many of the recent studies in this area (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002).",0,original
"Even for relatively general texts, such as the Wall Street Journal (Marcus et al. , 1993) or terrorism articles (MUC4 Proceedings, 1992), Roark and Charniak (Roark and Charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in WordNet.",0,original
"Previously published approaches to reducing the rule set include: enforcing a minimum span of two words per non-terminal (Lopez, 2008), which would reduce our set to 115M rules; or a minimum count (mincount) threshold (Zollmann et al., 2008), which would reduce our set to 78M (mincount=2) or 57M (mincount=3) rules.",0,original
"The Stanford parser is representative of a large number of PTB parsers, exemplified by Collins (1997) and Charniak (2000).",0,original
Tillmann and Zhang (2006) trained their feature set using an online discriminative algorithm.,0,original
"Traditionally, generative word alignment models have been trained on massive parallel corpora (Brown et al., 1993).",0,original
"Algorithm 1 SCL (Blitzer et al., 2006) 1: Select m pivot features.",0,original
"After building the chunker, students were asked to 4 choose a verb and then analyze verb-argument structure (they were provided with two relevant papers (Church and Hanks, 1990; Chklovski and Pantel, 2004)).",0,original
The Tagger Support cutoff Accuracy Collins (2002) 0 96.60% 5 96.72% Model 3W+TAGS variant 1 96.97% 5 96.93% Table 6: Effect of changing common word feature cutoffs (features with support  cutoff are excluded from the model).,0,original
"When efficient techniques have been proposed (Brown et al. , 1993; Och and Ney, 2003), they have been mostly evaluated on safe pairs of languages where the notion of word is rather clear.",0,original
"Extensions to Hiero Several authors describe extensions to Hiero, to incorporate additional syntactic information (Zollmann and Venugopal, 2006; Zhang and Gildea, 2006; Shen et al., 2008; Marton and Resnik, 2008), or to combine it with discriminative latent models (Blunsom et al., 2008).",0,original
"In the English all-words task of the previous SENSEVAL evaluations (SENSEVAL-2, SENSEVAL3, SemEval-2007), the best performing English all-words task systems with the highest WSD accuracy were trained on SEMCOR (Mihalcea and Moldovan, 2001; Decadt et al., 2004; Chan et al., 2007b).",0,original
Daume III (2007) further augments the feature space on the instances of both domains.,0,original
Collins (1997) Model 3 integrates the detection and resolution of WH-traces in relative clauses into a lexicalized PCFG.,0,original
"Co-selection measures include precision and recall of co-selected sentences, relative utility (Radev et al. , 2000), and Kappa (Siegel and Castellan, 1988; Carletta, 1996).",0,original
"In one experiment, it has to be performed on the basis of the gold-standard, assumed-perfect POS taken directly from the training data, the Penn Treebank (Marcus et al. , 1993), so as to abstract from a particular POS tagger and to provide an upper bound.",0,original
"The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries (Barzilay and Lee, 2002) and sentence-level paraphrasing (Barzilay and Lee, 2003).",0,original
"The model scaling factors  1 ,, 5 and the word and phrase penalties are optimized with respect to some evaluation criterion (Och 2003) such as BLEU score.",0,original
"Recently, specific probabilistic tree-based models have been proposed not only for machine translation (Wu, 1997; Alshawi, Bangalore, and Douglas, 2000; Yamada and Knight, 2001; Gildea, 2003; Eisner, 2003), but also for This work was supported by DARPA contract F49620-001-0337 and ARDA contract MDA904-02-C-0450.",0,original
"The focus of much of the automatic sentiment analysis research is on identifying the affect bearing words (words with emotional content) and on measurement approaches for sentiment (Turney & Littman, 2003; Pang & Lee, 2004; Wilson et al. , 2005).",0,original
"The other is the self-training (McClosky et al. 2006) which first parses and reranks the NANC corpus, and then use them as additional training data to retrain the model.",0,original
"The data set consisting of 249,994 TFSs was generated by parsing the Figure 3: The size of Dpi; for the size of the data set 800 bracketed sentences in the Wall Street Journal corpus (the first 800 sentences in Wall Street Journal 00) in the Penn Treebank (Marcus et al. , 1993) with the XHPSG grammar (Tateisi et al. , 1998).",0,original
"Four teams had approaches that relied (to varying degrees) on an IBM model of statistical machine translation (Brown et al. , 1993).",0,original
"Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modi ed SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks.",0,original
"A richer set of features besides n-grams should be checked, and we should not ignore the potential effectiveness of unigrams in this task (Pang et al. , 2002).",0,original
"In our decoder, we incorporate two pruning techniques described by (Chiang, 2007; Huang and Chiang, 2007).",0,original
"Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (Johnson, 2002; Jijkoun and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al. , 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005).",0,original
"It compares favorably 505 with conventional phrase-based translation (Koehn et al., 2003) on Chinese-English news translation (Chiang, 2007).",0,original
"In this paper we focus on the second issue, constraining the grammar to the binary-branching Inversion Transduction Grammar of Wu (1997).",0,original
"In fact, in (Titov and Henderson, 2007a) it was shown that this neural network can be viewed as a coarse approximation to the corresponding ISBN model.",0,original
"This approach will generally take advantage of language-specific (e.g. in (Freeman et al., 2006)) and domain-specific knowledge, of any external resources (e.g. database, names dictionaries, etc.), and of any information about the entities to process, e.g. their type (person name, organization, etc.), or internal structure (e.g. in (Prager et al., 2007)).",0,original
"7.3 EM algorithm The only other application of the EM algorithm to word-sense disambiguation is described in (Gale, Church, and Yarowsky, 1995).",0,original
"The prime public domain examples of such implementations include the TrigramsnTags tagger (Brandts 2000), Xerox tagger (Cutting et al. 1992) and LT POS tagger (Mikheev 1997).",0,original
"They are based on the sourcechannel approach to statistical machine translation (Brown et al. , 1993).",0,original
Turney (2006) later addressed the same problem using 8000 automatically generated patterns.,0,original
"Of particular relevance is other work on parsing the Penn WSJ Treebank (Jelinek et al. 1994; Magerman 1995; Eisner 1996a, 1996b; Collins 1996; Charniak 1997; Goodman 1997; Ratnaparkhi 1997; Chelba and Jelinek 1998; Roark 2001).",0,original
"In the area of statistical machine translation (SMT), recently a combination of the BLEU evaluation metric (Papineni et al. , 2001) and the bootstrap method for statistical significance testing (Efron and Tibshirani, 1993) has become popular (Och, 2003; Kumar and Byrne, 2004; Koehn, 2004b; Zhang et al. , 2004).",0,original
"Parameter tuning is done with Minimum Error Rate Training (MERT) (Och, 2003).",0,original
" As multiple derivations are used for finding optimal translations, we extend the minimum error rate training (MERT) algorithm (Och, 2003) to tune feature weights with respect to BLEU score for max-translation decoding (Section 4).",0,original
"The translation models and lexical scores were estimated on the training corpus whichwasautomaticallyalignedusingGiza++(Och et al. , 1999) in both directions between source and target and symmetrised using the growing heuristic (Koehn et al. , 2003).",0,original
"In this paper we use a non-projective dependency tree CRF (Smith and Smith, 2007).",0,original
"The idea is that the translation of a sentence x into a sentence y can be performed in the following steps1: (a) If x is small enough, IBMs model 1 (Brown et al. , 1993) is employed for the translation.",0,original
"For instance, the most relaxed IBM Model-1, which assumes that any source word can be generated by any target word equally regardless of distance, can be improved by demanding a Markov process of alignments as in HMM-based models (Vogel et al. , 1996), or implementing a distribution of number of target words linked to a source word as in IBM fertility-based models (Brown et al. , 1993).",0,original
"We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM (Haghighi and Klein, 2006) and HMMs trained with soft constraints (Chang et al., 2007).",0,original
"In an evaluation on the PENN treebank (Marcus et al. , 1993), the parser outperformed other unlexicalized PCFG parsers in terms of labeled bracketing fscore.",0,original
"The largest corpus that Goldwater and Griffiths (2007) studied contained 96,000 words, while Johnson (2007) used all of the 1,173,766 words in the full Penn WSJ treebank.",0,original
"(DaumeIII and Marcu, 2005a) use the Learning as Search Optimization framework to take into account the non-locality behavior of the coreference features.",0,original
"Both taggers used the Penn Treebank tagset and were trained on the Wall Street Journal corpus (Marcus et al. , 1993).",0,original
"When updating model parameters, we employ a memorizationvariant of a local updating strategy (Liang et al. , 2006) in which parameters are optimized toward a set of good translations found in the k-best list across iterations.",0,original
"Example of such algorithms are (Pereira et al., 1993) and (Lin, 1998) that use syntactic features in the vector definition.",0,original
"The learning methods using in discriminative parsing are Perceptron (Collins, 2002) and online large-margin learning (MIRA) (Crammer and Singer, 2003).",0,original
"In order to extract the linguistic features necessary for the models, all sentences containing the target word were automatically part-of-speech-tagged using a maximum entropy tagger (Ratnaparkhi, 1998) and parsed using the Collins parser (Collins, 1997).",0,original
"By core phrases, we mean the kind of nonrecursive simplifications of the NP and VP that in the literature go by names such as noun/verb groups (Appelt et al. , 1993) or chunks, and base NPs (Ramshaw and Marcus, 1995).",0,original
"For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc. Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990), (Pereira et al. 1993), (Grefenstette 1994) and (Lin 1998).",0,original
"For comparison to previous results, table 2 lists the results on the testing set for our best model (TOP-Efficient-Freq20) and several other statistical parsers (Collins, 1999; Collins and Duffy, 2002; Collins and Roark, 2004; Henderson, 2003; Charniak, 2000; Collins, 2000; Shen and Joshi, 2004; Shen et al. , 2003; Henderson, 2004; Bod, 2003).",0,original
"In (Daume III and Marcu, 2005), as well as other similar works (Collins, 2002; Collins and Roark, 2004; Shen and Joshi, 2005), only left-toright search was employed.",0,original
"See (Luo and Zitouni, 2005) and (Daume III and Marcu, 2005).",0,original
CollinsandRoark(2004)proposedanapproximate incremental method for parsing.,0,original
"There have been many statistical measures which estimate co-occurrence and the degree of association in previous researches, such as mutual information (Church 1990, Sporat 1990), t-score (Church 1991), dice matrix (Smadja 1993, 1996).",0,original
"2.3 Experiment The training set for these experiments was sections 01-21 of the Penn Treebank (Marcus et al. , 1993).",0,original
"Other models (Wu (1997), Xiong et al.",0,original
"5.2 NP Chunking The goal of this task (Marcus and Ramshaw, 1995) is the identification of non-recursive NPs.",0,original
"4.2 Cast3LB Function Tagging For the task of Cast3LB function tag assignment we experimented with three generic machine learning algorithms: a memory-based learner (Daelemans and van den Bosch, 2005), a maximum entropy classifier (Berger et al. , 1996) and a Support Vector Machine classifier (Vapnik, 1998).",0,original
Bilingual Bracketing [Wu 1997] is one of the bilingual shallow parsing approaches studied for Chinese-English word alignment.,0,original
"Default parameters were used for all experiments except for the numberofiterationsforGIZA++(OchandNey, 2003).",0,original
"Moreover, an F-score optimization method for logistic regression has also been proposed (Jansche, 2005).",0,original
"Since the introduction of BLEU (Papineni et al. , 2002) the basic n-gram precision idea has been augmented in a number of ways.",0,original
"(1996) show that this model is a member of an exponential family with one parameter for each constraint, specifically a model of the form 1 ~ I~ (x,~) p(yl ) = E' in which z(x) = eZ, Y The parameters A1,  , An are Lagrange multipliers that impose the constraints corresponding to the chosen features fl, -,fnThe term Z(x) normalizes the probabilities by summing over all possible outcomes y. Berger et al.",0,original
"Perhaps the most well-known method is maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), as well as cross-sentence informational subsumption (Radev, 2000), mixture models (Zhang et al. , 2002), subtopic diversity (Zhai et al. , 2003), diversity penalty (Zhang et al. , 2005), and others.",0,original
"The first adaptation includes theswap-operation(WagnerandLowrance,1975), whilethesecondadaptationincludesphoneticsegment distances, which are generated by applying an iterative pointwise mutual information (PMI) procedure(Churchand Hanks, 1990).",0,original
"We generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (Koehn et al. , 2003) (both directions) and phrase penalty (constant value).",0,original
"GIZA++ consists of a set of statistical translation models of different complexity, namely the IBM ones (Brown et al. , 1993).",0,original
"The term global feature vector is used by Collins (2002) to distinguish between feature count vectors for whole sequences and the local feature vectors in ME tagging models, which are Boolean valued vectors containing the indicator features for one element in the sequence.",0,original
"Probabilistic models where probabilities are assigned to the CFG backbone of the unification-based grammar have been developed (Kasper et al. , 1996; Briscoe and Carroll, 1993; Kiefer et al. , 2002), and the most probable parse is found by PCFG parsing.",0,original
"The weights of the different knowledge sources in the log-linear model used by our system are trained using Maximum BLEU (Och 2003), which we run for 25 iterations individually for each system.",0,original
"Using the ME principle, we can combine information from a variety of sources into the same language model (Berger et al. , 1996; Rosenfeld, 1996).",0,original
"For each word in LDV, three existing thesauri are consulted: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998).",0,original
"Due to advances in statistical syntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences.",0,original
"Nakagawa (2007) and Hall (2007) also showed the effectiveness of global features in improving the accuracy of graph-based parsing, using the approximate Gibbs sampling method and a reranking approach, respectively.",0,original
"To set the weights, m, we performed minimum error rate training (Och, 2003) on the development set using Bleu (Papineni et al. , 2002) as the objective function.",0,original
"POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al. , 1993).",0,original
"To measure interannotator agreement, we compute Cohens Kappa (Carletta, 1996) from the two sets of annotations, obtaining a Kappa value of only 0.43.",0,original
"the parse trees of the simple grammar in (Wu, 1997).",0,original
"Note that the predicate language representation utilized by Carmel-Tools is in the style of Davidsonian event based semantics (Hobbs, 1985).",0,original
"Therefore, we determine the maximal translation probability of the target word e over the source sentence words: pIBM1(e|fJ1 ) = maxj=0,,J p(e|fj), (9) where f0 is the empty source word (Brown et al. , 1993).",0,original
"There have been a lot of prol)OS~fls for statistical analysis, in ninny languages, in particular in English and Japanese (Magerman, 1995) (Sekine and Grishman, 1995) (Collins, 1997) (I/atnal)arkhi, 1997) (K.Shirai et.al, 1998) (Fujio and Matsnlnoto, 1998) (Itaruno ct.al, 1997)(Ehara, 1998).",0,original
"Collocations were extracted according to the method described in (Church and Hanks, 1990) by moving a window on texts.",0,original
"5 Datasets and Evaluation We train our models with verb instances extracted from three parsed corpora: (1) the Wall Street Journal section of the Penn Treebank (PTB), which was parsed by human annotators (Marcus et al. , 1993), (2) the Brown Laboratory for Linguistic Information Processing corpus of Wall Street Journal text (BLLIP), which was parsed automatically by the Charniak parser (Charniak, 2000), and (3) the Gigaword corpus of raw newswire text (GW), which we parsed ourselves with the Stanford parser.",0,original
"'\['here are three main approaches in tagging problem: rule-based approach (Klein and Simmons 1%3; Brodda 1982; Paulussen and Martin 1992; Brill et al. 1990), statistical approach (Church :1988; Merialdo 1994; Foster 1991; Weischedel et al. 1993; Kupiec 1992) and connectionist approach (Benello et al. 1989; Nakanmra et al. 1989).",0,original
"Examples of such techniques are Markov Random Fields (Ratnaparkhi et al. , 1994; Abney, 1997; Della Pietra et al. , 1997; Johnson et al. , 1999), and boosting or perceptron approaches to reranking (Freund et al. , 1998; Collins, 2000; Collins and Duffy, 2002).",0,original
This upper bound is consistent with the upper limit of 50% found by Daume III and Marcu (2005) which takes into account stemming differences.,0,original
"We performed experiments with two statistical classifiers: the decision tree induction system C4.5 (Quinlan, 1993) and the Tilburg Memory-Based Learner (TiMBL) (Daelemans et al. , 2002).",0,original
"4.2 Adaptation to Chinese (Cahill et al. , 2004)s algorithm (Section 3.2) only resolves certain NLDs with known types of antecedents (TOPIC, TOPIC REL and FOCUS) at fstructures.",0,original
"If POS denotes the POS of the English word, we can define the word-to-word distance measure (Equation 4) as POS POS (15) Ratnaparkhis POS tagger (Ratnaparkhi, 1996) was used to obtain POS tags for each word in the English sentence.",0,original
"The precision of the extracted information can be improved significantly by using machine learning methods to filter out noise (Fleischman et al. , 2003).",0,original
The idea of synchronous SSMT can be traced back to Wu (1997)s Stochastic Inversion Transduction Grammars.,0,original
":~ The difl'erent kinds of noun chunks covered by our grmnmar are listed below and illustrated with exmnples:  a combination of a non-obligatory deternfiner, optional adjectives or cardinals and the noun 1Other types of lexicalised PCFGs have been (h!scrib('.d in (Charniak, 1997), (Collins, 1997), (G'oodman, 1997), (Chcll)a and .lelinek, 1998) mid (Eisner and Sat:a, 1999).",0,original
"EMD training (Fraser and Marcu, 2006) combines generative and discriminative elements.",0,original
"This set of context vectors is then clustered into a predetermined number of coherent clusters or context groups using Buckshot (Cutting et al. 1992), a combination of the EM algorithm and agglomerative clustering.",0,original
"The former extracts collocations within a fixed window (Church and Hanks 1990; Smadja, 1993).",0,original
"(Banerjee and Lavie, 2005) calculated the scores by matching the unigrams on the surface forms, stemmed forms and senses.",0,original
"Open-domain opinion extraction is another trend of research on opinion extraction, which aims to extract a wider range of opinions from such texts as newspaper articles (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Wiebe et al. , 2005; Choi et al. , 2006).",0,original
"Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005).",0,original
"Much like kappa statistics proposed by Carletta (1996), existing employments of majority class baselines assume an equal set of identical potential mark-ups, i.e. attributes and their values, for all markables.",0,original
"Unlabeled dependencies can be readily obtained by processing constituent trees, such as those in the Penn Treebank (Marcus et al. , 1993), with a set of rules to determine the lexical heads of constituents.",0,original
"For this work, an off-the-shelf maximum entropy tagger 10 (Ratnaparkhi, 1996) was used.",0,original
"It is possible that there is a better automated method for finding such phrases, such as the methods in (Kanayama and Nasukawa, 2006; Breck, Choi and Cardie, 2007).",0,original
"(Church & Hanks, 1990:p.24) Merkel, Nilsson, & Ahrenberg (1994) have constructed a system that uses frequency of recurrent segments to determine long phrases.",0,original
"In the proposed method, the statistical machine translation (SMT) (Brown et al., 1993) is deeply incorporated into the question answering process, instead of using the SMT as the preprocessing before the mono-lingual QA process as in the previous work.",0,original
"Albeit simple, the algorithm has proven to be very efficient and accurate for the task of parse selection (Collins and Roark, 2004; Collins, 2004; Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007).",0,original
"These rules can be learned from a parallel corpus using English parsetrees, Chinese strings, and word alignment (Galley et al. , 2004).",0,original
"There also have been prior work on maintaining approximate counts for higher-order language models (LMs) ((Talbot and Osborne, 2007a; Talbot and Osborne, 2007b; Talbot and Brants, 2008)) operates under the model that the goal is to store a compressed representation of a disk-resident table of counts and use this compressed representation to answer count queries approximately.",0,original
"2 Related Work Sentiment Classi cation Traditionally, categorization of opinion texts has been cast as a binary classication task (Pang et al. , 2002; Turney, 2002; Yu and Hatzivassiloglou, 2003; Dave et al. , 2003).",0,original
"(2008) who employ clusters of related words constructed by the Brown clustering algorithm (Brown et al., 1992) for syntactic processing of texts.",0,original
"CFGs extracted from such structures were then annotated with hidden variables encoding the constraints described in the previous section and trained until convergence by means of the Inside-Outside algorithm defined in (Pereira and Schabes, 1992) and applied in (Matsuzaki et al., 2005).",0,original
Church and Hanks 1990; Smadja and McKeown 1990).,0,original
"This information can be annotated reliably (a1a3a2a5a4a7a6a9a8 a10a12a11a14a13a16a15 and a1a17a2a5a4a19a18a20a8 a10a12a11a14a13a16a21 ).4 4Following (Carletta, 1996), we use the a22 statistic to estimate reliability of annotation.",0,original
"However there has recently been much work drawing connections between the two methods (Friedman, Hastie, and Tibshirani 2000; Lafferty 1999; Duffy and Helmbold 1999; Mason, Bartlett, and Baxter 1999; Lebanon and Lafferty 2001; Collins, Schapire, and Singer 2002); in this section we review this work.",0,original
"Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks.",0,original
CP-STM(i)-l This metric corresponds to the STM metric presented by Liu and Gildea (2005).,0,original
"3 Methodology Similar to (Rapp, 2002; Baroni et al., 2008, among others), we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures.",0,original
"We use two state-of-the-art POS taggersa maximum entropy based English POS tagger (Ratnaparkhi, 1996), and an HMM based Chinese POS tagger.",0,original
"1.2.2 SPECIFIC SYNTACTIC AND SEMANTIC ASSUMPTIONS The basic scheme, or some not too distant relative, is the one used in many large-scale implemented systems; as examples, we can quote TEAM (Grosz et al. 1987), PUNDIT (Dahl et al. 1987), TACITUS (Hobbs et al. 1988), MODL (McCord 1987), CLE (Alshawi et al. 1989), and SNACK-85 (Rayner and Banks 1986).",0,original
"(Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al. , 2006).",0,original
"Congress of the Italian Association for Artificial Intelligence, Palermo, 1991 B. Boguraev, Building a Lexicon: the Contribution of Computers, IBM Report, T.J. Watson Research Center, 1991 M. Brent, Automatic Aquisition of Subcategorization frames from Untagged Texts, in (ACL, 1991) N. Calzolari, R. Bindi, Acquisition of Lexical Information from Corpus, in (COLING 1990) K. W. Church, P. Hanks, Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, vol.",0,original
"2 Background Default unification has been investigated by many researchers (Bouma, 1990; Russell et al. , 1991; Copestake, 1993; Carpenter, 1993; Lascarides and Copestake, 1999) in the context of developing lexical semantics.",0,original
"Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (McKeown, 1985; Marcu and Echihabi, 2002).",0,original
"As in tile HMM we easily can extend the dependencies in the alignment model of Model 4 easily using the word class of the previous English word E = G(ci,), or the word class of the French word F = G(Ij) (Brown et al. , 1993).",0,original
"This combination of the perceptron algorithm with beam-search is similar to that described by Collins and Roark (2004).5 The perceptron algorithm is a convenient choice because it converges quickly  usually taking only a few iterations over the training set (Collins, 2002; Collins and Roark, 2004).",0,original
"Therefore, the Viterbi alignment is comlmted only approximately using the method described in (Brown et al. , 1993).",0,original
"Self-training is a commonly used technique for semi-supervised learning that has been ap532 plied to several natural language processing tasks (Yarowsky, 1995; Charniak, 1997; Steedman et al., 2003).",0,original
"4 Evaluation As our algorithm works in open domains, we were able to perform a corpus-based evaluation using the Penn WSJ Treebank (Marcus et al. , 1993).",0,original
"Due to its popularity for unsupervised POS induction research (e.g., Goldberg et al., 2008; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008) and its often-used tagset, for our initial research, we use the Wall Street Journal (WSJ) portion of the Penn Treebank (Marcus et al., 1993), with 36 tags (plus 9 punctuation tags), and we use sections 00-18, leaving held-out data for future experiments.4 Defining frequent frames as those occurring at 4Even if we wanted child-directed speech, the CHILDES database (MacWhinney, 2000) uses coarse POS tags.",0,original
Freund and Schapire (1999) originally proposed the averaged parameter method; it was shown to give substantial improvements in accuracy for tagging tasks in Collins (2002).,0,original
"We present results in the form of search error analysis and translation quality as measured by the BLEU score (Papineni et al. , 2002) on the IWSLT 06 text translation task (Eck and Hori, 2005)1, comparing Cube Pruning with our two-pass approach.",0,original
"Starting from the parallel training corpus, provided with direct and inverted alignments, the socalled union alignment (Och and Ney, 2003) is computed.",0,original
"759 For all models used in our experiments, both wordand class-based, the smoothing method used was Stupid Backoff (Brants et al., 2007).",0,original
"3 Bilingual Task: An Application for Word Alignment 3.1 Sentence and word alignment Bilingual alignment methods (Warwick et al. , 1990; Brown et al. , 1991a; Brown et al. , 1993; Gale and Church, 1991b; Gale and Church, 1991a; Kay and Roscheisen, 1993; Simard et al. , 1992; Church, 1993; Kupiec, 1993a; Matsumoto et al. , 1993; Dagan et al. , 1993).",0,original
"This dependency graph is partitioned into treelets; like (Koehn et al. , 2003), we assume a uniform probability distribution over all partitions.",0,original
They are a subset of the features used in Ratnaparkhi (1996).,0,original
"In this paper we use the phrase-based system of (Koehn et al. , 2003) as our underlying model.",0,original
"Parameter tuning is done with Minimum Error Rate Training (MERT) (Och, 2003).",0,original
"So the sequence with a fork, which corresponds to only one nucleus is treated as a three word sequence in model C. Apart from this difference, model C directly relies on a combination of equations (10) and (12), namely conditioning by a80a7a81a49a82a9a12, a74a61a8a65a75a57a12 and a74a61a8a65a75a57a14a61a86, both the probability of generating a74a61a8a65a75 a47 and the one of generating a80a7a81a49a82 a47 . Thus, model C uses a reduced version of equation (12) and an extended version of 2Other models, as (Collins and Brooks, 1995; Merlo et al. , 1998) for PP-attachment resolution, or (Collins, 1997; Samuelsson, 2000) for probabilistic parsing, are somewhat related, but their supervised nature makes any direct comparison impossible.",0,original
"In general, Agold / Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight i as follows: i = i + hAoraclei hA1-besti .9 Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights.",0,original
"Inter-annotator agreement is typically measured by the kappa statistic (Carletta, 1996), dekappa frequency 0.0 0.2 0.4 0.6 0.8 1.0 0 2 4 6 8 Figure 2: Distribution of  (inter-annotator agreement) across the 54 ICSI meetings tagged by two annotators.",0,original
"Set Test Set ENGLISH-WSJ Sections Section 22 Section 23 (Marcus et al., 1993) 2-21 ENGLISH-BROWN see 10% of 10% of the (Francis et al. 2002) ENGLISH-WSJ the data6 the data6 FRENCH7 Sentences Sentences Sentences (Abeille et al., 2000) 1-18,609 18,610-19,609 19,609-20,610 GERMAN Sentences Sentences Sentences (Skut et al., 1997) 1-18,602 18,603-19,602 19,603-20,602 Table 1: Corpora and standard experimental setups.",0,original
Ratnaparkhi (1996) estimates a POS tagging error rate of 3% in the Treebank.,0,original
"Regressive FLM (rFLM) h(FLM(e,j)) = w1 FLM(e,j)+b Regressive ALM (rALM) h(ALM(e,j)) = w1 ALM(e,j)+b Notice that h() here is supposed to relate FLM or ALM to some independent evaluation metric such as BLEU (Papineni et al. , 2002), not the log likelihood of a translation.",0,original
"4.1.3 Letter Lexical Transliteration Similar to IBM Model-1 (Brown et al. , 1993), we use a bag-of-letter generative model within a block to approximate the lexical transliteration equivalence: P(fj+lj |ei+ki )= j+lproductdisplay jprime=j i+ksummationdisplay iprime=i P(fjprime|eiprime)P(eiprime|ei+ki ), (10) where P(eiprime|ei+ki ) similarequal 1/(k+1) is approximated by a bagof-word unigram.",0,original
"This definition is similar to that of minimal translation units as described in Quirk and Menezes (2006), although they allow null words on either side.",0,original
"This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004).",0,original
"(1) a) ~ x e' ~ y ?read(e' x y) & book(y) b) ~ x 3 e e' y past(e) & enjoy(e x e') & ?read(e' x y) & book(y) c) 3 e e' y past(e) & enjoy(e j e') & ?read(e' j y) & book(y) We follow Hobbs (1985), Alshawi et al.",0,original
"These later inductive phases may rely on some level of a priori knowledge, like for example the naive case relations used in the ARIOSTO_LEX system (Basili et al, 1993c, 1996).",0,original
"Output sequence optimization Rather than basing classifications only on model parameters estimated from co-occurrences between input and output symbols employed for maximizing the likelihood of point-wise single-label predictions at the output level, classifier output may be augmented by an optimization over the output sequence as a whole using optimization techniques such as beam searching in the space of a conditional markov models output (Ratnaparkhi, 1996) or hidden markov models (Skut and Brants, 1998).",0,original
"The per-state models in this paper are log-linear models, building upon the models in (Ratnaparkhi, 1996) and (Toutanova and Manning, 2000), though some models are in fact strictly simpler.",0,original
"Many researchers (Banerjee and Lavie, 2005; Liu and Gildea, 2006), have observed consistent gains by using more flexible matching criteria.",0,original
"(Fleischman et al. , 2003; Jijkoun et al. , 2003).",0,original
"Statistical approaches, which depend on a set of unknown parameters that are learned from training data, try to describe the relationship between a bilingual sentence pair (Brown et al. , 1993; Vogel and Ney, 1996).",0,original
Our intuition is that we cannot apply our binarization to Collins (1997).,0,original
"We will provide a more detailed and systematic comparison between MAXIMUM ENTROPY MODELING (aatnaparkhi, 1996) and MEMORY BASED LEARNING (Daelemans et al. , 1996) for morpho-syntactic disambiguation and we investigate whether earlier observed differences in tagging accuracy can be attributed to algorithm bias, information source issues or both.",0,original
"Many probabilistic evaluation models have been published inspired by one or more of these feature types [Black, 1992] [Briscoe, 1993] [Charniak, 1997] [Collins, 1996] [Collins, 1997] [Magerman, 1995] [Eisner, 1996], but discrepancies between training sets, algorithms, and hardware environments make it difficult, if not impossible, to compare the models objectively.",0,original
"For comparing the sentence generator sample to the English sample, we compute log-likelihood statistics (Dunning, 1993) on neighboring words that at least co-occur twice.",0,original
"number of words in target string These statistics are combined into a log-linear model whose parameters are adjusted by minimum error rate training (Och, 2003).",0,original
"On the same dataset as that of (Chen et al. , 1999), our new supertagger achieves an accuracy of a2a4a3a6a5a8a7a10a9a12a11 . Compared with the supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of a22a23a5a26a9a12a11 . We repeat Ramshaw and Marcus Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset.",0,original
"1 Introduction Word alignments were first introduced as an intermediate result of statistical machine translation systems (Brown et al. , 1993).",0,original
"3see http://www.statmt.org/moses/ 194 4 Implementation Details 4.1 Alignment of MT output The input text and the output text of the MT systems was aligned by means of GIZA++ (Och and Ney, 2003), a tool with which statistical models for alignment of parallel texts can be trained.",0,original
"Different methods have been proposed to reduce error propagation between pipelined tasks, both in general (Sutton et al., 2004; Daume III and Marcu, 2005; Finkel et al., 2006) and for specific problems such as language modeling and utterance classification (Saraclar and Roark, 2005) and labeling and chunking (Shimizu and Haas, 2006).",0,original
"These joint counts are estimated using the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993).",0,original
"Sentiment summarization has been well studied in the past decade (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004a, 2004b; Carenini et al., 2006; Liu et al., 2007).",0,original
"In both cases there 1Alternatively, decisions from the sentence classifier can guide which input is seen by the document level classifier (Pang and Lee, 2004).",0,original
"Thus, the Penn Treebank of American English (Marcus et al. , 1993) has been used to train and evaluate the best available parsers of unrestricted English text (Collins, 1999; Charniak, 2000).",0,original
"In the nal step, we score our translations with 4-gram BLEU (Papineni et al. , 2002).",0,original
"302 (Marcus et al. , 1993) was nlanually annotated with subjeciivity chlssifications.",0,original
"2.1 The Standard Machine Learning Approach We use maximum entropy (MaxEnt) classification (Berger et al., 1996) in conjunction with the 33 features described in Ng (2007) to acquire a model, PC, for determining the probability that two mentions, mi and mj, are coreferent.",0,original
"(Wu, 1997) also includes a brief discussion of crossing constraints that can be derived from phrase structure correspondences.",0,original
"For all non-LEAF systems, we take the best performing of the union, refined and intersection symmetrization heuristics (Och and Ney, 2003) to combine the 1-to-N and M-to-1 directions resulting in a M-to-N alignment.",0,original
"2 Experimental System and Data HMIHY is a spoken dialogue system based on the notion of call routing (Gorin et al. , 1997; Chu-Carroll and Carpenter, 1999).",0,original
",.~.eqmvalent ot duty in a parallel French text, the correct sense of the Enghsh word is identified These studies exploit th~s lnformatmn m order to gather co-occurrence data for the different senses, which ts then used to dtsamb~guate new texts In related work, Dywk (1998) used patterns of translational relatmns in an EnghshNorwegian paralle ! corpus (ENPC, Oslo Umverslty) to define semantic propemes such as synonymy, ambtgmty, vagueness, and semantic helds and suggested a derivation otsemantic representations for signs (eg, lexemes), captunng semantm relatmnshlps such as hyponymy etc, fiom such translatmnal relatmns Recently, Resnlk and Yarowsky (1997) suggested that fol the purposes ot WSD, the different senses of a wo~d could be detelmlned by considering only sense d~stmctmns that are lextcahzed cross-hngmstlcally In particular, they propose that some set of target languages be ~dent~fied, and that the sense d~stmctmns to be considered for language processing appllcatmns and evaluatmn be restricted to those that are reahzed lexlcally in some minimum subset of those languages This idea would seem to p~ovtde an answer, at least m part, to the problem of determining different senses of a word mtumvely, one assumes that ff another language lexlcahzes a word m two or more ways, there must be a conceptual monvatmn If we look at enough languages, we would be likely to fred the s~gmficant lexlcal differences that dehmtt different senses of a word However, th~s suggestmn raises several questions Fo~ instance, ~t ~s well known that many amb~gumes are preserved across languages (for example, the French tntdrYt and the Enghsh interest), especmlly languages that are relatively closely related Assuming this problem can be overcome, should differences found m closely related languages be given lesser (or greater) weight than those found m more distantly related languages 9 More generally, which languages should be considered for this exermse 9 All languages 9 Closely related languages9 Languages from different language famlhes '~ A mixture of the two 9 How many languages, and of which types, would be ""enough"" to provide adequate lnfotmanon tot this purpose~ There ts also the questmn ot the crlterm that would be used to estabhsh that a sense distinction is ""lexlcahzed cross-hngu~stmally"" How consistent must the d~stlnCtlOn be 9 Does it mean that two concepts are expressed by mutually non-lntetchangeable lexmal items in some slgmficant number ot other languages, or need tt only be the case that the option ot a different lexlcahzatlon exists m a certain percentage of cases 9 Another conslderatmn ts where the cross-hngual mformatlon to answer these questmns would come from Using bdmgual dictionaries would be extremely tedmus and error-prone, g~ven the substantial d~vergence among d~ctlonanes in terms of the kinds and degree of sense dlstmctmns they make Resmk and Yalowsky (1997) suggest EutoWordNet (Vossen, 1998) as a possible somce of mformatmn, but, given that EuroWordNet ts pttmatdy a lexmon and not a corpus, ~t is subject to many of the same objections as for bl-hngual dictionaries An alternative would be to gather the reformation from parallel, ahgned corpma Unlike bilingual and muttt-hngual dictionaries, translatmn eqmvalents xn parallel texts a~e determined by experienced translatols, who evaluate each instance ot a word's use m context rather than as a part of the meta-hngmst~c actlvlty of classifying senses for mclusmn in a dictionary However, at present very few parallel ahgned corpora exist The vast majority ot these are bl-texts, mvolwng only two languages, one of which is very often English Ideally, a serious 53 evaluation of Resnik and Yarowsky's proposal would include parallel texts m languages from several different language families, and, to maximally ensure that the word m question is used in the exact same sense across languages, ~t would be preferable that the same text were used over all languages in the study The only currently avadable parallel corpora for more than two languages are Olwell's Nmeteen Eighty-Four (Erjavec and Ide, 1998), Plato's Repubhc (Erjavec, et al, 1998), the MULTEXT Journal .o/ the Commt.~ston corpus (Ide and V6roms, 1994), and the Bible (Resnlk, et al, m press) It is likely that these corpora do not provide enough appropriate data to reliably determine sense distinctions Also, ~t Is not clear how the lexlcahzatlon of sense distractions across languages Is affected by genre, domain, style, etc Thls paper attempts to provide some prehmlnary answers to the questions outhned above, In order to eventually determine the degree to which the use of parallel data ts vmble to determine sense distinctions, and, ff so, the ways in which th~s reformation might be used Given the lack of lalge parallel texts across multiple languages, the study is necessarily hmlted, however, close exammanon of a small sample of parallel data can, as a first step, provide the basis and dlrectmn for more extensive studies 1 Methodology I have conducted a small study using parallel, aligned versmns ot George Orwell's Nineteen Etghtv-Fo,lr (Euavec and Ide, 1998)m five languages Enghsh, Slovene, Estonian, Romanlan, and Czech I The study therefole Involves languages from four language families The O~well parallel corpus also includes vers|ons o) Ntneteen-E~gho Four m Hungarian, Bulgarmn, Latwan, Llthuaman, Se~bmn, and Russmn (Germanic, Slavic, Fmno-Ugrec, and Romance), two languages from the same family (Czech and Slovene), as well as one non-Indo-European language (Estoman) Nmeteen Eighty-Four Is a text of about 100,000 words, translated directly from the original English m each of the other languages The parallel versions of the text are sentence-aligned to the English and tagged for part of speech Although Nineteen Eighty-Four is a work of fiction, Orwell's prose IS not highly stylized and, as such, it provides a reasonable sample ot modern, ordinary language that ~s not tied to a given topic or sub-domain (such as newspapers, technical reports, etc ) Furthermore, the translations of the text seem to be relatively faithful to the original for instance, over 95% ot the sentence alignments in the full pmallel corpus of seven languages are one-to-one (Prlest-Dorman, et al, 1997) Nine ambiguous English words were considered hard, head, country, hne, promise, shght, seize, scrap, float The first four were chosen because they have been used in other dlsamb~guatlon studies, the latter five were chosen from among the words used m the Senseval dlsamblguatlon exercise (Kllgamff and Palmer, forthcoming) In all cases, the study was necessarily hmlted to words that occurred frequently enough in the Orwell text to warrant consideration F~ve hundred forty-two sentences conta|nmg an occurrence or occurrences (Including morphological variants) of each of the nine words were extracted from the Enghsh text, together w~th the parallel sentences m which they occur m the texts ot the four comparison languages (Czech, Estonian, Romantan, Slovene) As Walks and Stevenson (1998) have pointed out, pa~t-of-speech tagging accomplishes a good portion of the work ot semantic dlsamb~guatmn, therefore occmrences of wolds that appemed in the data in more than 54 one part of speech were grouped separately 2 The Enghsh occurrences were then grouped usmg the sense distinctions m WordNet, (version 1 6) \[Miller et al, 1990, Fellbaum, 1998\]) The sense categonzatmn was performed by the author and two student assistants, results from the three were compared and a final, mutually agreeable set of sense assignments was estabhshed For each of the four comparison languages, the corpus of sense-grouped parallel sentences were sent to a llngmst and natl,ve speaker of the comparison language The hngmsts were asked to provide the lexlcal item m each parallel sentence that corresponds to the ambiguous Enghsh word If inflected, they were asked to provide both the inflected form and the root form In addttmn, the lmgmsts were asked to indicate the type of translatmn, according to the dtstmctmns given m Table 1 For over 85% of the Enghsh word occurrences (corresponding to types 1 and 2 m Table 1), a specific lexlcal item or items could be identified as the translation equivalent for the corresponding Enghsh word For comparison purposes, each translanon equivalent was represented by ~ts lemma (or the lemma of the toot form in the case of derivatives) and associated w~th the WordNet sense to which it corresponds In order to determine the degree to which the assigned sense dlstlncttons correspond to translation eqmvalents, a coherence index ( Cl) was computed that measures how often each pmr of senses is translated usmg the same word as well as the consistency with which a g~ven se,ls,z ~s translated with the same word ~ Note that the z The adJective and adverb senses of hard are consadeied together because the distinction is not consistent across the translations used m the study Note that the CI ~s similar to semanuc entropy (Melamed, 1997) However, Melamed computes CIs do not determine whether or not a sense dtstmctton can be lextcahzed in the target language, but only the degree to whmh they are lexicahzed differently m the translated text However, tt can be assumed that the CIs provide a measure of the tendency to lex~cahze different WordNet senses differently, which can m turn be seen as an mdtcatmn of the degree to which the distraction ts vahd For each ambiguous word, the CI Is computed for each pair of senses, as follows S<q t> Cl(sqS, ) = '=1 m rnrt where @ n ~s the number of comparison languages under consideration, nl~q and m,, are the nt~mber of occurrences olsense sqand sense s~ m the Enghsh corpus, respectively, including occurrences that have no idenufiable translation, s<~ ~>m ts the number of times that senses q and r are translated by the same lex~cal Item m language t, i e, x=y t ~tJan ~( q ), r~oan~( r ) The CI ts a value between 0 and 1, computed by examining clusters of occurrences translated by the same word In the othel languages If sense and sense ) are consistently translated w~th the same wo~d in each comparison language, then Cl(s, s~) = 1, if they are translated with a different word m every occurrence, Cl(s, ~) = 0 In general, the CI for pans of different senses provides an index of thmr relatedness, t e, the greater the value of Cl(s, sj), the more frequently occurrences of-sense t and sense j are translated with the same lextcal item When t = j, we entropy tOl wold types, lather than word senses 55 obtain a measure of the coherence of a ~lven sense Type Meaning 1 A slngle lexlcal Item is used to translate the En@izsh equivalent (possibly a 2 The English word is translated by a phrase of two or more words or a compound, meaning as the slngle English word 3 The En@izsh word is not lexzcalized in the translation 4 A pronoun is substituted for the English word In the translation An English phrase contalnmng the ambiguous word Is translated by a single language which has a broader or more specific meanlng, or by a phrase in whl corresponding to the English word Is not explicltl~ lexlcallzed Table 1 Translation types and their trequencles % dizen whl%h h 6% 6% 6% of s p same Word # Description hard 1 1 difficult 2 head i i i 1 Table 2 1 2 _meta~horlcally hard _\] 3 not yielding to pressure, 1 4 very strong or ~lgorous, ar 2 I wlth force or vigor (adv) 3 earnestly, intently (adv) i_ ~art of the body  3 intellect 4 _r~le_!r, ch,%ef 7 front, front part WoldNet senses ot hard and head CIs were also computed for each language individually as well as for different language groupings Romaman, Czech, and Estonian (three different language families) Czech and Slovene (same family), Romaman, Czech, Slovene (Indo-European, and Estonian (nonIndo-European) To better visualize the relationship between senses, a hierarchical clustering algorithm was applied to the CI data to generate trees reflecting sense proximity 4 Finally, in order to determine the degree to which the linguistic relaUon between languages may affect coherence, a correlation was run among CIs for all pairs of the four target languages Fol example, Table 2 gives the senses of hard and head that occurred in the data s The CI data .s 'sobS' hard and head are given in Tables 3 and 4 ~uous CIs measuring the aff, mty of a sense with itself--that is, the tendency for all occurrences of that sense to be translated wlth the same word--show that all of the s,x senses of ha,d have greatel internal consistency tfian athmty with other senses, with senses 1 1 (""dlff|cult"" CI = 56) and 13 (,'not soft,, ci = 63) registenng the h,ghest internal consistency 6 The same holds true for three of the four senses of head, while the CI for senses 1 3 (""Intellect"") and 1 1 (""part of the body"") is higher than the CI for 1 3/1 3 WordNet Sense 2 1 2 3 1 4 1 3 1 1 1 2 21 23 1 4 13 0 50 o 13 i ool 0 O0 0 25 i O0 0 04 0 50 0 17 0 56 0 19 0 00 0 00 0 00 0 00 0 00 0 25 0 21 Table 3 CIs for hard I i 12 0,,63 0 00 0 50 2 Results Although the data sample is small, It gives some insight into ways m which a larger sample might contribute to sense discrimination 4 Developed by Andleas Stolcke Results tor all words m the study are avadable at http//www cs vassar edu/~~de/wsd/cross-hng html 6 Senses 2 3 and 1 4 have CIs ot 1 because each ot these senses exists m a single occurrence m the corpus, and have theretote been dlscarded horn consideration ot CIs to~ individual senses We a~e currently mvesugatmg the use oI the Kappa staUst~c (Carletta, 1996) to normahze these sparse data 56 WordNet Sense 1 1 1 3 1 4 1 7 1 1 0 69 1 3 0 53 0 45 1 4 0 12 0 07, 0 50 1 7 0 40 0 001 0 00 1 00 Table 4 CIs for head Figure 2 shows the sense clusters for hard generated from the CI data 7 The senses fall into two mare clusters, w~th the two most internally consistent senses (1 1 and 1 3) at the deepest level of each ot the respecuve groups The two adverbml forms 8 are placed in separate groups, leflectmg thmr semantic proximity to the different adjecuval meanings of hard The clusters for head (Figure 2) stmdarly show two dlstmct groupings, each anchored in the two senses with the h~ghest internal consistency and the lowest mutual CI (""part of the body"" (1 1) and ""ruler, chief"" (1 4)) The h~erarchtes apparent m the cluster graphs make intuitive sense Structured hke dictmnary enmes, the clusters for hard and head might appeal as m F~gure 1 This ts not dissimilar to actual dlctLonary entries for hard and head, for example, the enmes for hard in four differently constructed dlctmnanes ( Colhns Enghsh (CED), Longman's (LDOCE), OxJotd Advanced Learner's (OALD), and COBUILD) all hst the ""'d~fficult"" and ""not soft"" senses first and second, whmh, since most dictionaries hst the most common Ol frequently used senses hrst, reflects the gross dlwslon apparent m the clusters Beyond this, ~t ~s difficult to assess the 7 Foi the purposes ot the cluster analys~s, CIs of l 00 resulting from a single occurrrence were normahzed to 5 8 Because ~oot to, ms were used m the analysis, no dzstlncUon m UanslaUon eqmvalents was made tor part ot speech correspondence between the senses In the dictionary entries and the clusters The remamlng WordNet senses are scattered at various places within the entries or, m some cases, split across various senses The h~erarchlcal relatmns apparent m the clusters are not reflected m the d~cttonary enmes, smce the senses are for the most part presented in flat, hnear hsts However, It is interesting to note that the first five senses of hard In the COBUILD d~cuonary, which is the only d~cttonary in the group constructed on the bas~s of colpus examples 9 and presents senses m ruder of frequency, correspond to hve of the six WordNet senses in thls study WordNet's ""metaphorically hard"" is spread over multiple senses in the COB UILD, as it.is In the other d~ctlonarles HARD HEAD I 1 dlfflcult 2 vlgorously II 1 a not soft b strong 2 a earnestly b metaphorlcally hard I 1 a part of the body b zntellect 2 front, front part II ruler, chlef Flgme 1 Clusteis tol hard and head suuctured as dlcuonary entt ~es The results tor dlftment language groupings show that the tendency to lextcahze senses differently is not aftected by language d~stance (Table 5) In fact, the mean CI fol Estonian, the only non-Indo-European language m the study, ~s lower than that for any other group, mdmatmg that WordNet sense dtstmctmns are slightly less hkely to be lexlcahzed differently m Estonian 9 Edmons ot the LDOCE (1987 vexsmn) and OALD (1985 version) dictlonalles consulted m this study ple-date edmons ol those same d~ctlonanes based on colpus evidence 57 Correlations of CIs for each language pair (Table 5) also show no relationship between the degree to which sense d~stmcuons are lexlcahzed differently and language distance This is contrary to results obtained by Resmk and Yarowsky (subm,tted), who, using a memc slmdar to the one used in this study, found that that non-Indo-European languages tended to lexlcallze English sense d~stmctlons more than Indo-European languages, especially at finergrained levels However, their translation data was generated by native speakers presented with Isolated sentences in English, who were asked to provide the translation for a given word In the sentence It is not clear how this data compares to translations generated by trained translators working with full context Lanquaqe qroup Averaqe CI ALL 0 27 RO/ES/SL 0 28 SL/CS 0 28 RO/SL/CS 0 27 ES 0 26 Table 5 Average CI values Lanqs Hard Country Llne Head Ave ES/CS 0 86 0 72 0 68 0 69 0 74 RO/SL 0 73 0 78 0 68 1 00 0 80 RO/CS 0 83 0 66 0 67 0 72 0 72 SL/CS 0 88 0 51 0 72 0 71 0 71 RO/ES 0 97 0 26 0 70 0 98 0 73 ES/SL 0 73 0 59 0 90 0 99 0 80 Table 6 CI correlauon tor the tour target languages I -I I  I I m~nlmum dlstance = 0 249399 m~nlmum d~stance = 0 434856 mlnlmum dlstance = 0 555158 mlnlmum dlstance = 0 602972 m~nlmum dlstance = 0 761327 I  >21 I  >ii I  >23 l  >13 l  >14 I  >12 (13) (23) (12) (1,4) (ii) (21) (1412) (2313) ( 2 3 1 3 1 4 1 2 ) ( 2 111 ) Figure 2 Cluster tree and distance measures tor the sm senses of hard I  >14 -i I  > i i I--- 1 J  > i 3 I  >17 mlnlmum dlstance = 0 441022 mlnlmum dlstance = 0 619052 mln~mum dlstance = 0 723157 (13) (ll) (17) (1113) (111317) (14) F,gure 3 Cluster tree and dmtance measures tot the tout senses ot head 58 Conclusion The small sample m this study suggests that cross-hngual lexlcahzat~on can be used to define and structure sense d~stmct~ons The cluster graphs above provide mformat~on about relations among WordNet senses that could be used, for example, to determine the granularity of sense differences, whtch m turn could be used in tasks such as machine translatton, mtormaUon retrieval, etc For example, it is hkely that as sense dtstmcttons become finer, the degree of error ~s less severe Resmk and Yarowsky (1997) suggest that confusing freer-grained sense dtstmctlons should be penahzed less severely than confusing grosser d~stmct~ons when evaluatmg the performance of sense dtsambtguatt0n systems The clusters also provide insight into the lexlcallzatlon of sense dtstmcttons related by various semantic relations (metonymy, meronymy, etc ) across languages, for instance, the ""part of the body"" and ""intellect"" senses of head are lex~cahzed with the same ~tem a s~gnlficant portion of the t~me across all languages, reformation that could be used m machine translatton In addtt~on, cluster data such as that presented here could be used m lexicography, to determine a mole detaded hierarchy of relations among senses in dtct~onary entries It is less clear how cross-hngual reformation can be used to determine sense d~st~nctlons independent of a pre-deflned set, such as the WordNet senses used here In an effort to explore how thts mlght be done, I have used the small sample from thts study to create word groupmgs from ""back translations"" (l e, additional translations m the original language ot the translations m the target language) and developed a metric that uses th~s mformatton to determine relatedness between occurrences, whtch ~s m turn used to cluster occurrences into sense groups I have also compared sets of back translations for words representing the various WordNet senses, which provtde word groups s~mdar to WordNet synsets Interestingly, there ts virtually no overlap between the WordNet synsets and word groups generated from back translations The results show, however, that sense dlstmctlons useful for natural language processing tasks such as machme translanon could potentsally be determined, ot at least influenced, by constdeHng this mformatton The automatically generated synsets themselves may also be useful m the same apphcatlons; where WordNet synsets (and ontologtes) have been used tn the past More work needs to be done on the topic of cross-hngual sense determination, utthzmg substantially larger parallel corpora that include a variety ot language types as well as texts fiom several genres This small study explores a possible methodology to apply when such resources become avatlable Acknowledgements The author would hke to gratefully acknowledge the contrtbut~on of those who provided the translatton mfotmat~on Tomaz Eua~ec (Slovene), Kadrt Muxschnek (Estonian), Vladtmlr Petkevtc (Czech), and Dan Tubs (Romanlan), as well as Dana Fleut and Darnel Khne, who helped to transcrtbe and evaluate the data Special thanks to Dan Melamed and Hlnrtch Schutze for their helpful comments 59 \[\] \[\] in \[\] in i i Hg nn i an i am References Ca~letta, Jean (1996) Assessing Agreement on Classthcatton Tasks The Kappa Stat~st~t. Computational Lmgulstlcs, 22(2), 249-254 Dagan, Ido and Ita~, Alon (1994) Wo~d sense dlsambxguat~on using a second language monohngual corpus Computattonal Ltngmsttcs, 20(4), 563-596 Dagan, Ido, Ital, Alon, and Schwall, Ulnke (1991) Two languages a~e more mformattve than one Proceedings of the 29th Annual Meettng of the Assoctatton for Computattonal Ltngutsttcs, 18-21 June 1991, Berkeley, Cahfornm, 130-137 Dyvtk, Helge (1998) Translations as Semantic Mirrors Proceedmgs of Workshop W13 Multzlmguahty in the Lextcon II, The 13th Biennial European Conference on Arttftctal lntelhgence (ECA198), Brighton, UK, 24-44 Eqavec, Tomaz and Ide, Nancy (1998) The MULTEXT-EAST Corpus Proceedlng~ of the Fltst International Conference on Language Resources and Evaluatton, 27-30 May 1998, Granada, 971-74 Erjavec, Tomaz, Lawson, Ann, and Romary, Laurent (1998) East meets West Producing Multflmgual Resources m a European Context Pioceedtngs of the Ftrst Internattonal Conference on Language Resources and Evaluation, 27-30 May 1998, Gtanada, 981-86 Fellbaum, Chttstmne (ed) (1998) WordNet An Electrontc Lexlcal Database MIT Press, Cambridge, Massachusetts Gale, Wdham A, Church, Kenneth W and Yatowsky, Davtd (1993) A method tor dlsamblguatmg word senses m a large cmpus Computers and the Humamtles, 26, 415-439, Hearst, M'attl A (1991) Noun homograph  ' dlsamblguatlon using local:'~.'0ntext m large corpora Proceedtngs of the 7th Annual Conference of the Umver~lt~ of Waterloo Centre for the New OED and Text ReaeaJch, Oxford, Umted Kingdom, 1-19 Ide, Nancy and V61oms, Jean (1998) Word sense d~samb~guat~on The state of the alt Computational Lmgut~ttc~, 24 1, 1-40 Kdgar~ttt, Adam and Palmer, Ma~tha, Eds (forthcoming) Proceedmgs ot the Senseval Word Sense D~samb~guatlon Workshop, Specml double ~ssue otComputer~ and the Humamttes, 33 4-5 Leacock, Claudia, Towell, Geoffrey and Voorhees, Ellen (1993) Corpus-based stattstlcal sense resolution Proceedtng~ of the ARPA Human Language Technology Worsl~shop, San Francisco, Morgan Kautman Melamed, I Dan (1997) Measuring Semantic Entropy ACL-SIGLEX Workshop Taggmg Tert wtth Lextcal Semanttcs Why, What, and How ~ April 4-5, 1997, Washington, D C, 41-46 Mtllet, George A, Beckwlth, Richard T Fellbaum.",0,original
"The Bloomier filter LM (Talbot and Brants, 2008) has a precomputed matching of keys shared between a constant number of cells in the filter array.",0,original
"Following (Brown et al. , 1993) and the other literature in TM, this paper only focuses the details of TM.",0,original
"The GIZA++ aligner is based on IBM Model 4 (Brown et al., 1993).",0,original
"The second voting model is a maximum entropy model (Jaynes, 1978), since Klein and Manning (2002) found that this model yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance.",0,original
"McClosky et al (2006a) use sections 2-21 of the WSJ PennTreebank as seed data and between 50K to 2,500K unlabeled NANC corpus sentences as self-training data.",0,original
"2 Statistical Translation Engine A word-based translation engine is used based on the so-called IBM-4 model (Brown et al. , 1993).",0,original
"We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al. , 2003), and our treelet system.",0,original
"4 Maxilnum Entropy The model used here for sentence-boundary detection is based on the maximum entropy model used for POS tagging in (Ratnaparkhi, 1996).",0,original
"Sang used the IOB tagging method proposed by Ramshow(Ramshaw and Marcus, 1995) and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the Penn Treebank corpus.",0,original
"1 Motivation A major component in phrase-based statistical Machine translation (PBSMT) (Zens et al., 2002; Koehn et al., 2003) is the table of conditional probabilities of phrase translation pairs.",0,original
"Most of researchers focus on how to extract useful textual features (lexical, syntactic, punctuation, etc.) for determining the semantic orientation of the sentences using machine learning algorithm (Bo et al. 2002; Kim and Hovy, 2004; Bo et al. 2005, Hu et al. 2004; Alina et al 2008; Alistair et al 2006).",0,original
"Finally, the loglikelihood ratios test (henceforth LLR) (Dunning, 1993) is applied on each set of pairs.",0,original
"We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank (Brants et al. 2002) and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar 361 Computational Linguistics Volume 31, Number 3 approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004).",0,original
"(levelopment of cor1)ora with morl)ho-synta(:ti(: and syntacti(: mmotation (Marcus et al. , 1993), (Sampson, 1995).",0,original
"For English, we used the Penn Treebank (Marcus et al., 1993) in our experiments and the tool Penn2Malt7 to convert the data into dependency structures using a standard set of head rules (Yamada and Matsumoto, 2003).",0,original
"Some methods use sentence alignment and additional statistics to find candidate translations of terms (Smadja, 1992; van der Eijk, 1993).",0,original
"For extracting simple noun phrases we first used Ramshaw and Marcuss base NP chunker (Ramshaw and Marcus, 1995).",0,original
"In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al. , 1996; Ahrenberg et al. , 1998; Tufis and Barbu, 2002) to build alignment links.",0,original
These include the bootstrapping approach [Yarowsky 1995] and the context clustering approach [Schutze 1998].,0,original
"Meanwhile, translation grammars have grown in complexity from simple inversion transduction grammars (Wu, 1997) to general tree-to-string transducers (Galley et al., 2004) and have increased in size by including more synchronous tree fragments (Galley et al., 2006; Marcuetal.,2006; DeNeefeetal.,2007).",0,original
"Mihalcea (2007) demonstrates that manual mappings can be created for a small number of words with relative ease, but for a very large number of words the e ort involved in mapping would approach presented involves no be considerable.",0,original
"This procedure uses the head finding rules of (Collins, 1997).",0,original
"This algorithm adjusts the log-linear weights so that BLEU (Papineni et al. , 2002) is maximized over a given development set.",0,original
"We obtain aligned parallel sentences and the phrase table after the training of Moses, which includes running GIZA++ (Och and Ney, 2003), grow-diagonal-final symmetrization and phrase extraction (Koehn et al., 2005).",0,original
"The corresponding unlabeled figures are 73.3 and 33.4.3 This confirms the results of previous studies showing that the pseudo-projective parsing technique used by MaltParser tends to give high precision  given that non-projective dependencies are among the most difficult to parse correctly  but rather low recall (McDonald and Nivre, 2007).",0,original
"1 Introduction A recent theme in parsing research has been the application of statistical methods to linguistically motivated grammars, for example LFG (Kaplan et al. , 2004; Cahill et al. , 2004), HPSG (Toutanova et al. , 2002; Malouf and van Noord, 2004), TAG (Sarkar and Joshi, 2003) and CCG (Hockenmaier andSteedman,2002; ClarkandCurran,2004b).",0,original
"In particular, mutual information (Church and Hanks, 1990; Wu and Su, 1993) and other statistical methods such as (Smadja, 1993) and frequency-based methods such as (Justeson and Katz, 1993) exclude infrequent phrases because they tend to introduce too much noise.",0,original
"task, originally introduced in Ramshaw and Marcus (1995) and also described in (Collins, 2002; Sha and Pereira, 2003), brackets just base NP constituents5.",0,original
"(2002) and Pang and Lee (2004) in merely using binary unigram features, corresponding to the 17,744 unstemmed word or punctuation types with count  4 in the full 2000-document corpus.",0,original
"We use the by now standard a0 statistic (Di Eugenio and Glass, 2004; Carletta, 1996; Marcu et al. , 1999; Webber and Byron, 2004) to quantify the degree of above-chance agreement between multiple annotators, and the a1 statistic for analysis of sources of unreliability (Krippendorff, 1980).",0,original
"Recently, many works combined a MRD and a corpus for word sense disambiguation(Karov, 1998; Luk, 1995; Ng, 1996; Yarowsky,1995).",0,original
"To set the weights, m, we carried out minimum error rate training (Och, 2003) using BLEU (Papineni et al. , 2002) as the objective function.",0,original
"Our method is based on the Extended String Subsequence Kernel (ESK) (Hirao et al. , 2004b) which is a kind of convolution kernel (Collins and Duffy, 2001).",0,original
"The features we use are shown in Table 2, which are based on the features used by Ratnaparkhi (1996) and Uchimoto et al.",0,original
"We obtained word alignments of the training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diagfinal-and (Koehn et al., 2003).",0,original
"lscript1-regularized log-linear models (lscript1-LLMs), on the other hand, provide sparse solutions, in which weights of irrelevant features are exactly zero, by assumingaLaplacianpriorontheweights(Tibshirani, 1996; Kazama and Tsujii, 2003; Goodman, 2004; Gao et al., 2007).",0,original
"(Chanod and Tapanainen, 1995) compare two tagging frameworks for tagging French, one that is statistical, built upon the Xerox tagger (Cutting et al. , 1992), and another based on linguistic constraints only.",0,original
"For the combined set (ALL), we also show the 95% BLEU confidence interval computed using bootstrap resampling (Och, 2003).",0,original
"Stochastic taggers use both contextual and morphological information, and the model parameters are usually defined or updated automatically from tagged texts (Cerf-Danon and E1-Beze 1991; Church 1988; Cutting et al. 1992; Dermatas and Kokkinakis 1988, 1990, 1993, 1994; Garside, Leech, and Sampson 1987; Kupiec 1992; Maltese * Department of Electrical Engineering, Wire Communications Laboratory (WCL), University of Patras, 265 00 Patras, Greece.",0,original
"One possible strategy is to exploit a widecoverage realizer that aims for applicability in multiple application domains (White et al., 2007; Cahill and van Genabith, 2006; Zhong and Stent, 2005; Langkilde-Geary, 2002; Langkilde and Knight, 1998; Elhadad, 1991).",0,original
"2.2.1 BLEU Evaluation The BLEU score (Papineni et al. , 2002) was defined to measure overlap between a hypothesized translation and a set of human references.",0,original
"The feature weights were optimized against the BLEU scores (Och, 2003).",0,original
"Evaluation We evaluate translation output using three automatic evaluation measures: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Banerjee and Lavie, 2005, version 0.6).5 All measures used were the case-sensitive, corpuslevel versions.",0,original
"4.2 Smoothing: Gaussian Priors Since NLP maximum entropy models usually have lots of features and lots of sparseness (e.g. features seen in testing not occurring in training), smoothing is essential as a way to optimize the feature weights (Chen and Rosenfeld, 2000; Klein and Manning, 2003).",0,original
"Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005).",0,original
"They are also used for inducing alignments (Wu, 1997; Zhang and Gildea, 2004).",0,original
The output of GIZA++ is then post-processed using the three symmetrization heuristics described in Och and Ney (2003).,0,original
This model is very similar to the markovized rule models in Collins (1997).,0,original
"It was later applied by (Dunning, 1993) as a way to determine if a sequence of N words (Ngram) came from an independently distributed sample.",0,original
"Previous uses of this model include language modeling(Lau et al. , 1993), machine translation(Berger et al. , 1996), prepositional phrase attachment(Ratnaparkhi et al. , 1994), and word morphology(Della Pietra et al. , 1995).",0,original
"Towards a Meaning-Full Comparison of Lexieal Resources Kenneth C Lltkowska CL Research 9208 Gue Road Damascus, MD 20872 ken@clres corn http//www tires tom Abstract The mapping from WordNet to Hector senses m Senseval provides a ""gold standard"" against wluch to judge our ability to compare lexlcal resources The ""gold standard"" is provided through a word overlap analysis (with and without a stop list) for flus mapping, achieving at most a 36 percent correct mapping (inflated by 9 percent from ""empty"" assignments) An alternaUve componenttal analysis of the defimtaons, using syntacUc, collocatmnal, and semantac component and relation identification (through the use ofdefimng patterns integrated seamlessly mto the parsing thclaonary), provides an almost 41 percent correct mapping, with an additaonal 4 percent by recogmzmg semantic components not used in the Senseval mapping Defimtion sets of the Senseval words from three pubhshed thclaonanes and Dorr's lextcal knowledge base were added to WordNet and the Hector database to exanune the nature of the mapping process between defimtton sets of more and less sco\[~e The tecbauques described here consUtute only an maaal implementation of the componenUal analysis approach and suggests that considerable further improvements can be aclueved Introduction The difficulty of companng lemcal resources, long a s~gnfficant challenge in computauonal hnguistlcs (Atlans, 1991), came to the fore in the recent Senseval competatton (IOlgarnff, 1998), when some systems that relied heavily on the WordNet (Miller, et al, 1990) sense inventory were faced with the necessity of using another sense inventory (Hecto0 A hasty solutaon to the problem was the "" development of a map between the two inventories, but some part~cipants expressed concerns that use of flus map may have degraded their performance to an unknown degree Although there were disclaimers about the WordNet-Hector map, it nonetheless stands as a usable gold standard for efforts to compare lexical resources Moreover, we have a usable baseline (a word overlap method suggested m (Lesk, 1986)) against which to compare whether we are able to make improvements m the mapping (since flus method has been shown to perform not as well as expected (Krovetz, 1992)) We first describe the lextcal resources used m the study (Hector, WordNet, other dicUonanes, and a lex~cal knowledge base), first characterizing them in terms ofpolysemy and the types of leracal mformaUon each contmns (syntacUc properties and features, semantac components and relaUons, and collocaUonal properties) We then present results of perfornung the word overlap analysis of the 18 verbs used m Senseval, analyzing the definitions m WordNet and Hector We then expand our analysis to include other dictionaries We describe our methods of analysis, particularly the methods of parsing defimtaons and identff)qng semantic relations (semrels) based on defimng patterns, essentially takang first steps m Implementing the program described by Atkms and focusmg on the use of""meamng"" full mformataon rather than statistical mformaUon We identify the results that have been achieved thus far and outline further steps that may add more ""meanmg"" to the analysis IAll analyses described m this paper were performed automatically using functlonahty incorporated m DIMAP (Dictionary Maintenance Programs) (available for immediate download at (CL Research, 1999a)) This includes automatac extracuon of WordNet reformation for the selected words (mtegrated m DIMAP) Hector defimtlons were uploaded into DIMAP dicUonanes after use of a conversmn program Defimtlons for other 30 The Lexical Resources Tlus analysis focuses on the mmn verb senses used In Senseval (not ichoms and phrases), specifically the followmg AMAZE, BAND, BET, BOTHER, BURY, CALCULATE, CONSUME, DERIVE, FLOAT, HURDLE, INVADE, PROMISE, SACK, SANCTION, SCRAP, SEIZE, SHAKE, SLIGHT The Hector database used In Senseval consists of a tree of senses, each of which contains defimttons, syntactic properties, example usages, and ""clues"" (collocational information about the syntactic and semantic enwronment in wluch a word appears in the spectfic sense) The WordNet database contmns synonyms (synsets), perhaps a defimtton or example usages (gloss), some syntactic mformaUon (verb frames), hypernyms, hyponyms, and some other semrels (ENTAILS, CAUSES) To extend our analysis In order to look at other issues of lexacal resource comparison, we have included the defirauons or leracal information from the following additional sources  Webster's 3 ra New International Dictionary (W3)  Oxford Advanced l.earners D~ctlonary (OALD)  American Hentage DlcUonary (AI-ID)  Dorr's Lexacal Knowledge Base (Dorr) We used only the defimuons from W3, OALD, and AHD (which also contmn sample usages and some collocattonal information m the form of usage notes, not used at the present tame) Dorr's database contains thematic grids wluch characterize the thematic roles of obligatory and optional semanuc components, frequently identifying accompanying preposmons (Olsen, et al, 1998) The following table identities the number of senses and average overall polysemy for each of these resources dictionaries were entered by hand Word amaze band bet bother bury calculate consume denve float hurdle invade pronuse sack sanction scrap seize shake shght Average Polysemy o o o 1 2 4 2 3 1 II 4 4 2 5 5 7 6 9 7 12 6 14 5 5 5 10 9 6 6 8 8 6 5 15 5 16 4 41 14 2 1 4 3 6 2 10 5 5 4 7 4 4 4 6 3 2 2 5 2 3 1 3 3 11 6 21 13 8 8 37 17 1 1 6 3 O 1 2 2 4 1 3 4 4 8 1 3 1 3 1 3 2 10 5 1 0 3 1 3 2 2 0 1 1 1 0 7 1 7 12 I 0 57 37 120 62 34 22 Word Overlap Analysis We first estabhsh a baseline for automatic replication of the lexicographer's mappmg from WordNet 1 6 to Hector, using a s~mple word overlap analysis smular to (Lesk, 1986) The lextcographer mapped the 66 WordNet senses (each synset m which a test occurred) Into 102 Hector senses A total of 86 assignments were made, 9 WordNet senses were gwen no assignments, 40 recewed exactly one, and 17 senses received 2 or 3 asssgnments The WordNet senses contained 348 words (about half of wluch were common words appeanng on our stop list, which contained 165 words, mostly preposmons, pronouns, and conjunctions) The Hector senses selected m the word overlap analysis contained about 960 words (all Hector senses contained 1878 words) We performed a strict word overlap analysts (with and wsthout a stop hst) between tile definlUons in WordNet and the Hector senses, that is, we did not attempt to ldenttfy root forms of Inflected words We took each word m a WordNet sense and determined whether ~t appeared in a Hector sense, we selected a Hector sense based on the highest percentage of words over all Hector senses An 31 empty selection was made ff all the words in the WordNet sense did not appear in any Hector sense, only content words were considered when the stop hst was used For example, for bet, WordNet sense 2 (stake (money) on the outcome of an issue) mapped into Hector sense 4 ((of a person) to risk (a sum of money or property) m thts way) In this case, there was an overlap on two words (money, 039 in the Hector defimtlon (0 13 of its 15 words) without the stop list When the stop list was invoked, there was an overlap of only one word (money, 0 07 of the Hector defimtion) In this case, the lexicographer had made three assignments (Hector senses 2, 3, and 4), our scoring method treated flus as only 1 out of 3 correct (not using the relaxed method employed in Senseval of treating flus as completely correct) Without the stop hst, our selections matched the lexicographer's in 28 of 86 cases (32 6%), using the stop list, we were successful in 31 of 86 cases (36 1%) The improvement arising when the stop list was used is deceptive, where 8 cases were due to empty assignments (so that only 23 cases, 26 7%, were due to matching content words) Overall, only 41 content words were involved in these 23 successes when the stop list was used, an average of I 8 content words To summanze the word overlap analysis (1) despite a ncher set of defimtions in Hector, 9 of 66 WordNet senses (13 6%) could not be assigned, (2) despite the greater detail in Hector senses compared to WordNet senses (2 8 times as many words), only 1 8 content words participated in the assignments, and (3) therefore, the defimng vocabulary between these two definition sets seems to be somewhat divergent Although it might appear as if the word overlap analysis does not perform well, this is not the case The analysis provides a broad overview of the defimuon companson process between two definmon sets and frames a deeper analysis of the differences Moreover, it appears that the accuracy of a ""gold standard"" mapping is not crucially important The quality of the mapping may help frame the subsequent analysis more precisely, but it seems sufficient that any reasonable mapping will suffice This will be discussed further after presenting the results of the componentlal analysis of the defimtlons 32 Meaning-Full Analysis of Definitions The deeper analysis of the mapping between two defimtion sets relies primarily on two major steps (1) parsing definitions and using defimng patterns to identify semrels present m the definitions and (2) relaxing values to these relations by allowing ""synonymic"" substitution (using WordNet) Thus, for example, ffwe identify hypernyms or instruments from parsing a defimtion, we would say that the defimtions are ""equal"" not just ffthe hypernym or instrument is the same word, but also Lf the hypernyms or instruments are members of the same synset This approach is based on the finding (Litkowski, 1978) that a dictionary induces a semantic network where nodes represent ""concepts"" that may be lexicahzed and verbalized in more than one way This finding implies, in general, the absence of true synonyms, and instead the kind of ""concept"" embodied in WordNet synsets (with several lexical items and phraseologles) A slmdar approach, parsing defimtlons and relaxing semrel values, was followed in (Dolan, 1994) for clnstenng related senses w~thin a single dictionary The ideal toward which this approach strives is a complete identification of the meamng components included in a defimtion The meaning components can include syntactic features and charactenstlcs (including subcategonzation patterns), semantm components (realized through identification of semrels), selectional restrictions, and coUocational specifications The first stage of the analysis parses the definitions (CL Research, 1999b, Litkowski, to appear) and uses the parse results to extract (via defining patterns) semrels Since definitions have many idiosyncrasies (that do not follow ordinary text), an important first step in this stage is preprocessmg the definition text to put it into a sentence frame that facilitates the extraction of semrels 2 2Note that the stop hst is not applicable to the definition parsing The parser is a full-scale sentence parser, where prepositmns and other words on the stop list are necessary for successful parsing Moreover, inclusion of the prepositions is cmcml to the method, since they are the bearers of much semrel information The extractmn of semrels examines the parse results, a e, a tree whose mtermedaate nodes represent non-ternunals and whose leaves represent the lextcal atems that compnse the defimuons, where any node may also include annotations such as characterizations of number and tense For all noun or verb defimttons, flus includes Identification of the head noun (with recogmtton of""empty"" heads) or verb, for verbs, we signal whether the defimtaon contmned any selecttonal restnctmus (that as, pamcular parenthesazed expressaons) for the subject and object We then exanune preposattonal phrases In the defimUon and deterrmne whether we have a ""defining pattern"" for the preposaUon whach we can use as mdacaUve of a partacular semrel We also identify adverbs m the parse tree and look these up in WordNet to adentffy an adjecuve synset from wluch they are derived (if one is gwen) The defimng pattems are actually part of the dictionary used by the parser That is, we do not have to develop specafic routines to look for specLfic patterns A defimng pattern ~s a regular expressaon that arlaculates a syntactac pattern to be matched Thus, to recograze a ""manner"" semrel, we have the foUowmg entry for ""m"" m(dpat((~ rep0 l(det(0)) adj manner(0) st(manner)))) This allows us to recognize ""m"" as possibly gwmg rise to a ""manner"" component, where we recogmze ""m"" (the tdde, which allows us to specify partacular elements before the ""m"" as well), vath a noun phrase that consasts of 0 or 1 determiner, an adjectwe, and the lateral ""manner"" The '0  after the detenmner and the hteral mdacate that these words are not copied into the value for a ""manner"" role, so that the value to the ""manner"" semrel becomes only the adjectwe that as recogmzed The second stage of the analysis uses the populated lexacal database to compare senses and make the selectaons This process follows the general methodology used m Senseval (Lltkowska, to appear) Specifically, m the defimtaon comparison, we first exanune exclusaon cntena to rule out specific mappings These criteria include syntacUc properUes (e g, a verb sense that Is only transluve cannot map into one that Is only mtransRave) and collocataonal propertaes (e g, a sense that is used with a parUcle cannot map into one that uses a different particle) At the present tune, these are used only rmmmally 33 We next score each viable sense based on rots semrels We increment the score ff the senses have a common hypernym or If a sense's hypernyms belong  to the same synset as the other sense's hypernyms If a parUcular sense con~ns a large number of synonyms (that as, no differentiae on the hypernym) and they overlap consaderably m the synsets they evoke, the score can be increased substanUally Currently, we add 5 points for each match 3 We increment the score based on common semrels In tins amtml tmplementaUon, we have defimng patterns (usually qmte nummal) for recogmzmg Instrument, means, location, purpose, source, manner, has-constituents, has-members, is-part-of, locale, and goal 4 We Increment the score by 2 points when we have a common semrel and then by another 5 points when the value Is ~dentacal or m the same synset After all possable increments to the scores have been made, we then select the sense(s) w~th the lughest score Finally, we compare our selecuon with that of the gold standard to assess our mapping over all senses Another way an wluch our methodology follows the Senseval process as that at proceeds incrementally Thus, ~t ms not necessary to have a ""final"" perfect parse and mapping rouUne We can make conUnual refinements at any stage of the process and exarmne the overall effect As m Senseval, we may make changes to deal wath a particular phenomenon with the result that overall performance dechnes, but w~th a sounder basis for making subsequent amprovements Results of Componential Analysis The ""gold standard"" analysis Involves mapping 66 WordNet senses with 348 words into 102 Hector senses with 1878 words Using the method described above, we obtained 35 out of 86 correct 3At the present tame, we use WordNet to adentffy semreis We envaslon usmg the full semanlac network created by parsing all a dlcUonary's defimtaons Thas would include a richer set of semrels than currently included m WordNet 4The defimng patterns are developed by hand We have onlyJust begun this effort, so the current set ms somewhat Impoverished mappmgs (407%), a shght improvement over the 31 correct assignments usmg the stop-last word overlap techmque However, as mentioned above, the stophst techmque had aclueved 8 of its successes by matclung null assignments Consadered on tlus basins, ~t seems that the componentaal analysis techmque provides substantial ~mprovement In addition, our technique ""erred"" on 4 cases by malang assagnments where none were made by the leracographer We suggest that these cases do con~n some common elements of meaning and may conceivably not be construed as errors The mapping from WordNet to Hector had relatavely few empty mappings, senses for wtuch It was not possable to make an assignment These are the cases where at appears that the chetmnanes do not overlap and thus prowde a tentative mdacataon of where two dictionaries may have different coverage The cases of multiple assignments mchcate the degree ofamblgmty m the mapping The average m both darecUons between Hector and WordNet were donunated by the mabdaty to obtain good dascnnunatton for the word ""semze"" Thus, tlus method identifies individual words where the &scnnunatwe ablhty needs to be further refined  Perhaps more importantly, the componentml analysis method exploits consaderably more WordNet Hector  mformauon than the word overlap methods Whereas the stop-hst word overlap mapping was  based on only 41 content words, the componenual ~ approach (In the selected mappings) had 228 hits in ~.~  developing ats scores, with only a small number of ~ .~ ~ defining patterns Comparison of Dictionaries tel O ~3 0'3 We next exanuned the nature of the mterrelalaons between parrs of chctaonanes w~thout use of a ""gold standard"" to assess the process of mapping For t/us purpose, we mapped m both &recttons between the paars {WordNet, Hector}, {W3, OALD}, and {W3, AHD We exanune Dorr's lexacal knowledge base for the amphcatlons It may have m the mapping process Neither WordNet nor Hector are properly v~ewed as chcuonanes, since there was no mtenuon to pubhsh them as such WordNet ""glosses"" are generally smaller (53 words per sense) compared to Hector (184 words per sense), whach contains many words specff3nng selectmnal restnct~ons on the subject and object of the verbs Hector was used primarily for a large-scale sense tagging project The three formal d~ctmnanes were subject to rigorous pubhslung and style standards The average number of words per sense were 87 (OALD), 7 1 (AHD), and 9 9 (W3), w~th an average of 3 4, 62, and 120 senses per word Each table shows the average number of senses being mapped, the average number of assignments m the target dlCtmnary, the average number of senses for which no assagnment could be made, the average number of mulUple assignments per word, and the average score of the assignments that were made WN-Hector 37 47 06 17 119 Hector-WN 57 64 14 22 113 These points are further emphasized m the mapping between W3 and OALD, where the disparity between the empty and mulUple assagnments indicate that we are mapping between dictionaries qmte disparate This tends to be the case not only for the enUre set of words, but also is evident for individual words where there is a considerable d~spanty m the number of senses, wtuch then dominate the overall dlspanty Thus, for example, W3 has 41 defimUons for ""float"", while OALD has 10 We tend to be unable to find the specific sense m going from W3 to OALD, because at is likely that we have many more specific defimtlons that are not present In the other direction, we are hkely to have considerable ambiguity and multiple assignments W3-OALD OALD-W3 W3 OALD 120 78 60 18 99 34 60 07 32 86 34 A Between W3 and AHD, there ss less overall daspanty between the defimtaon sets, although since W3 Is tmabndged, we stall have a relatavely lugh number of senses m W3 that do not appear to be present m AHD Finally, It should be noted that the scores for the published dictaonanes tend to be a little lower than for WordNet and Hector Tlus reflects the hkehhood that we have not extracted as much mformataon as we dad m parsing and analyzmg the defimtaon sets used m Senseval W3 AHD oJ  'q O W3-AHD 120 115 40 36 90 AHD-W3 6 2 9 1 1 2 4 1 9 1 We next considered Dorr's lexacal database We first transformed her theta grids to syntactic spectflcataons (transttave or lntransmttve) and identtficataon of semreis (e g, where she Identified an instr component, we added such a semrel to the DIMAP sense) We were able to identify a mappmg from WordNet to her senses for two words (""float"" and ""shake"") for wluch Dorr has several entries However, smce she has considerably more semanuc components than we are currently able to recogmze, we dad not pursue this avenue any further at flus time More important than just mappmg between two words, Dorr's data mdacates the posstbday of further exploitation of a richer set of semanUc components Spectfically, as reported m (Olsen, et al, 1998), m descnbmg procedures for automatically acqumng thematic grids for Mandann Chinese, ~t was noted that ""verbs that incorporate themaUc elements m their meamng would not allow that element to appear m the complement structure"" Thus, by usmg Dorr's thematic grids when verb are parsed m defimtaons, it ~s possible to ~dentffy where partacular semantac components are lexicahzed and which others are transnutted through to the themaUc grid (complement or subcategonzataon pattern) for the defimendum The transmiss~on of semantic components to the thematic gnd ~s also reflected overtly m many defimtlons For example, shake has one definition, ""to bnng to a specified condatton by or as ffby repeated qmck jerky movements"" We would thus expect that the thematac grid for this defimtaon should include a ""goal"" And, deed, Dorr's database has two senses whch reqmre a ""goal"" as part of their thematic grid Smularly, for many defimtaons m the sample set, we ~dentLfied a source defimng pattern based on the word ""from,"" frequently, the object of the preposmon was the word ""source"" ttseff, mdacatmg that the subcategonzaUon, properties of the defimendum should elude a source component Discussion Wlule the improvement m mapping by using the componentaal analysis techmque (over the word overlap methods) is modest, we consider these results qmte slgmficant m wew of the very small number of defimng patterns we have Implemented Most of the improvement stems from the word substatuUon pnnclple described earlier (as ewdenced by the preponderance of 5 point scores) This techmque also provides a mechamsm for bnngmg back the stop words, wz, the preposmons, wluch are the careers of mformatmn about semrels (the 2 point scores) The more general conclusion (from the word subsutuuon) is that the success arises from no longer considenng a defimtmn m ~solation The proper context for a word and its defimtions consists not .lUSt of the words that make up the definition, but also the total semantac network represented by the dictaonary We have aclueved our results by explomng only a small part of that network We have moved only a few steps to that network beyond the mdawdual words and their definitions We would expect that further expansmn, first by the addon of further and ~mproved semrel defining patterns, and second, through the identaficataon of more pnmmve semanuc components, will add considerably to our abflay to map between lexacal resources We also expect ~mprovements from consideration of other techniques, such as attempts at ontology ahgnment (Hovy, 1998) Although tile definition analysis provlded here was performed on definmons with a stogie language, the vanous meamng components m m m m m m m m 35 correspond to those used in an Interhngua The use of the exUncuon method (developed m order to charactenze verbs m another language, Clunese) can frmtfully be applied here as well Two further observaUons about tlus process can be made The first is that rchance on a wellestablished semantic network such as WordNet,s not necessary The componenUal analysis method rehes on the local neighborhood of words m the defimUons, not on the completeness of the network Indeed, the network ~tsel can be bootstrapped based on the parsing results The method can work vath any semanUc network or ontology and may be used to refine or flesh out the network or ontology The second observation is that it is not necessary to have a well-estabhshed ""gold standard"" Any mapping vail do All that Is necessary is for any mvesugator (lemcographer or not) to create a judgmental mappmg The methods employed here can then quanufy ttus mapping based on a word overlap analysis and then further examine tt based on the componenaal analysis The componenUal analysis method can then be used to exanune underlying subtleUes and nuances tn the defimUous, wluch a lemcographer or analyst can then examine m further detail to assess the mapping Future Work Tlus work has marked the first ume that all the necessary mfrastructure has been combmed tn a rudimentary form Because of its rudimentary status, the opportumUes for improvement are quite extensive In addlUon, there are many opportumUes for using the techmques descnbed here m further NLP apphcatlons First, the techmques described here have immediate apphcabtllty as part of a lexicographer's workstaUon When defimUons are parsed and semrels are zdenttfied, the resulUng data structures can be apphed against a corpus of instances for parUcular words (as m Senseval) for improving word-sense disamblguaUon The techmques will also permit comparing an entry vath Itself to deternune the mterrelattonshtps among ~ts defimUons and of companng the defimUons of two ""synonyms"" to deternune the amount of overlap between them on a defimtlon by defimUon bas~s Although the analys,s here has focused on the parsing of defimUous, the development of defimng patterns clearly extends to generalized text parsing since the defimng patterns have been incorporated mto the same chcttonary used for parsing free text, the patterns can be used threctly to identify the presence of parUcular semrels among sentenual consUtuents We are working to integrate th~s funcUonahty into our word-sense &sambiguaUon techruques (both the defimng patterns and the semrels) Even further, mt seems that matclung defimng patterns in free text can be used for lextcal acquisition Textual matenal that contains these patterns could concewably be flagged as providing defimUonal matenal which can then be compared to emstmg defimUons to assess whether their use ts cous,stent vath these defimUons, and ff not, at least to flag the inconsistency The tecluuques descnbed here can be apphed directly to the fields of ontology development and analysis of ternunologlcal databases For ontoiogles, vath or w~thout defimuons, the methods employed can be used to compare entries m dai'erent ontologles based pnmanly on the relattous m the ontology, both luerarclucal and other For ternunologlcal databases, the methods descnbed here can be used to exanune the set of conceptual relaUons lmphed by the defimtmus The defimuon parsing wall facd~tate the development of the termmolog~ca I network tn the pamcular field covered by the database The componenUal analysts methods result m a richer semantic network that can be used m other apphcattous Thus, for example, ~t ts possible to extend the leracal chatmng methods described m (Green, 1997), which are based on the semrels used m WordNet The semrels developed with the componenttal analysis method would provide additional detad available for apphcauon of lexlcal cohesion methods In particular, addtUonal relattous would penmt some structunng wmthm the individual leracal chams, rather than just consldenng each cham as an amorphous set (Green, 1999) Finally, we are currently investigating the use of the componenUal analysts techmque for mformauon extracUon The techmque identifies (from defimtlous) slots that can be used as slots or fields m template generataon Once these slots are identified, we wall be attemptmg to extract slot values from Items m large catalog databases (mdhons of items) 36 In conclusion, it would seem that, instead of a paucity of tnformation allovang us to compare lexmal resources, by bnngmg m the full semantic network of the lexicon, we are overwhelmed with a plethora of data Acknowledgments I would like to thank Bonnie Dorr, Chnstiane Fellbaum, Steve Green, Ed Hovy, Ramesh Knshnamurthy, Bob Krovetz, Thomas Potter, Lucy Vanderwende, and an anonymous reviewer for their comments on an earlier draft of this paper References Atlans, B T S (1991) Bmldmga lexicon The contribution of lexicography lnternattonal Journal of Lextcography, 4(3), 167-204 CL Research (1999a) CL Research Demos http//www clres com/Demo html CL Research (1999b) Dmtlonary Parsing Project http//www clres com/dpp html Dolan, W B (1994, 5-9 Aug) Word Sense Amblguation Chistenng Related Senses COLING-94, The 15th International Conference on Computational Linguistics Kyoto, Japan Green, S J (1997) Automatically generating hypertext by computing semantic smulanty \[Dlss\], Toronto, Canada Umverstty of Toronto Green, S J (Sjgreen@mn mq edu au) (1999, 1 June) (Rich semantic networks) Hovy, E (1998, May) Combining and Standardizing Large-Scale, Practical Ontologms for Machine Translation and Other Uses Language Resources and Evaluation Conference Granada, Spam Kalgarnff, A (1998) SENSEVAL Home Page http//www itn bton ac uk/events/senseval/ Krovetz, R (1992, June) Sense-Linking m a Machine Readable Dictionary 30th Annual Meeting of the Association for Computational Lmgu~stics Newark, Delaware Association for Computational Lmgtustics Lesk, M (1986) Automatic Sense Dlsamblguation Using Machine Readable Dmttonanes How to Tell a Pine Cone from an Ice Cream Cone Proceechngs of SIGDOC Lttkowski, K C (1978) Models of the semantic structure of dictionaries American Journal of Computattonal Lmgutsttcs, Atf 81, 25-74 Lttkowskl, K C (to appear) SENSEVAL The CL Research Expenence Computers and the Humamttes Mtller, G A, Beckwlth, R, Fellbaum, C, Gross, D, & Miller, K J (1990) Introduction to WordNet An on-hne lexical database lnternatwnal Journal of Lexicography, 3(4), 235-244 Olsen, M B, Dorr, B J, & Thomas, S C (1998, 28-31 October) Enhancmg Automatic Acqulsmon of Thematic Structure in a Large-Scale Lexacon for Mandann Chinese Tlurd Conference of the Association for Machine Translation m the Americas, AMTA-98 Langhorne, PA",0,original
"Results in terms of word-error-rate (WER) and BLEU score (Papineni et al. , 2002) are reported in Table 4 for those sentences that contain at least one unknown word.",0,original
"1 Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000).",0,original
"The parser is trained on dependencies extracted from the English Penn Treebank version 3.0 (Marcus et al. , 1993) by using the head-percolation rules of (Yamada and Matsumoto, 2003).",0,original
"Modulo more minor differences, these notions are close to the ideas of interpretation as abduction (Hobbs et al \[1988\]) and generation as abduction (ltobbs et al \[1990:26-28\]), where we take abduction, in the former case for instance, to be a process returning a temporal-causal structure which can explain the utterance in context.",0,original
"Mutual information MI(x,y) is defined as following (Church and Hanks, 1990): )()( ),( log )()( ),( log),( 22 yfxf yxfN ypxp yxp yxMI  == (4) where f(x) and f(y) are frequency of term x and term y, respectively.",0,original
"Proceedings of the Conference on Empirical Methods in Natural 2 Automatic Thesaurus Extraction The development of large thesauri and semantic resources, such as WordNet (Fellbaum, 1998), has allowed lexical semantic information to be leveraged to solve NLP tasks, including collocation discovery (Pearce, 2001), model estimation (Brown et al. , 1992; Clark and Weir, 2001) and text classi cation (Baker and McCallum, 1998).",0,original
"1 Introduction Over the past decade, researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation (Brown et al. , 1988; Brown et al. , 1990; Brown et al. , 1993a).",0,original
Carletta (1996) says that 0.67 a10a14a11a15a10 0.8 allows just tentative conclusions to be drawn.,0,original
"A new automatic metric METEOR (Banerjee and Lavie, 2005) uses stems and synonyms of the words.",0,original
"The disambiguation model of Enju is based on a feature forest model (Miyao and Tsujii, 2002), which is a log-linear model (Berger et al. , 1996) on packed forest structure.",0,original
"The differences between a k-best and a beam-search parser (not to mention the use of dynamic programming) make a running time difference unsur17 Our score of 85.8 average labeled precision and recall for sentences less than or equal to 100 on Section 23 compares to: 86.7 in Charniak (1997), 86.9 in Ratnaparkhi (1997), 88.2 in Collins (1999), 89.6 in Charniak (2000), and 89.75 in Collins (2000).",0,original
"Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (Pang et al. , 2002) or positive and negative words (Turney, 2002; Mullen and Collier, 2004); classifying sentences in a document as either subjective or objective (Riloff and Wiebe, 2003; Pang and Lee, 2004); identifying or classifying appraisal targets (Nigam and Hurst, 2004); identifying the source of an opinion in a text (Choi et al. , 2005), whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (Gamon et al. , 2005; Popescu and Etzioni, 2005).",0,original
"In particular, since we treat each individual speech within a debate as a single document, we are considering a version of document-level sentiment-polarity classification, namely, automatically distinguishing between positive and negative documents (Das and Chen, 2001; Pang et al. , 2002; Turney, 2002; Dave et al. , 2003).",0,original
"In contrast to the opinion extracts produced by Pang and Lee (2004), our summaries are not text extracts, but rather explicitly identify and 337 characterize the relations between opinions and their sources.",0,original
"No artificial glue-rules or rule span limits were employed.7 The parameters of the translation system were trained to maximize BLEU on the MT02 test set (Och, 2003).",0,original
"Section 3 describes previous work (Friedman, Hastie, and Tibshirani 2000; Duffy and Helmbold 1999; Mason, Bartlett, and Baxter 1999; Lebanon and Lafferty 2001; Collins, Schapire, and Singer 2002) that derives connections between boosting and maximum-entropy models for the simpler case of classification problems; this work forms the basis for the reranking methods.",0,original
"The tensor has been adapted with a straightforward extension of pointwise mutual information (Church and Hanks, 1990) for three-way cooccurrences, following equation 4.",0,original
Navigli (2006) has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource.,0,original
"3.1 Selecting Coreference Systems A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set 2Examples of such scoring functions include the DempsterShafer rule (see Kehler (1997) and Bean and Riloff (2004)) and its variants (see Harabagiu et al.",0,original
"For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system (Och, 2003).",0,original
"WordNet sense information has been criticized to be too fine grained (Agirre and Lopez de Lacalle Lekuona, 2003; Navigli, 2006).",0,original
"2 The Data Our experiments on joint syntactic and semantic parsing use data that is produced automatically by merging the Penn Treebank (PTB) with PropBank (PRBK) (Marcus et al., 1993; Palmer et al., 2005), as shown in Figure 1.",0,original
"Other work aims to do truly unsupervised learning of taggers, such as Goldwater and Griffiths (2007) and Johnson (2007).",0,original
"Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts (e.g. , Brown et al. 1992, Yarowsky 1992), as well as in similar predicateargument structure contexts (e.g. , Grishman and Sterling 1994).",0,original
"Extensions to Hiero Several authors describe extensions to Hiero, to incorporate additional syntactic information (Zollmann and Venugopal, 2006; Zhang and Gildea, 2006; Shen et al., 2008; Marton and Resnik, 2008), or to combine it with discriminative latent models (Blunsom et al., 2008).",0,original
"Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method.",0,original
"As our basic data source, we use 500 000 sentences from the Wikipedia XML corpus (Denoyer and Gallinari, 2006); this is the corpus used by Akhmatova and Dras (2007), and related to one used in one set of experiments by Snow et al.",0,original
"Morphologicaltoolssuch as lemmatizers andPOStaggersarebeingcommonlyusedin extractionsystems;they areemployedbothfordealingwithtext variationandfor validatingthe candidatepairs: combinationsof functionwordsare typicallyruledout (Justesonand Katz, 1995),as are the ungrammaticalcombinationsin the systemsthatmake useofparsers(ChurchandHanks, 1990;Smadja,1993;Basilietal.",0,original
"For ROUGE-S and ROUGE-SU, we use three variations following (Lin, 2004b): the maximum skip distances are 4, 9 and infinity 7.",0,original
"We set all feature weights by optimizing Bleu (Papineni et al., 2002) directly using minimum error rate training (MERT) (Och, 2003) on the tuning part of the development set (dev-test2009a).",0,original
"Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition (Jelinek, 1990), language generation (Smadja and McKeown, 1990), lexicography (Church and Hanks, 1990), machine translation (Brown et al. , ; Sadler, 1989), information retrieval (Maarek and Smadja, 1989) and various disambiguation tasks (Dagan et al. , 1991; Hindle and Rooth, 1991; Grishman et al. , 1986; Dagan and Itai, 1990).",0,original
"(Smadja, 1993) proposed a method to retrieve collocations by combining bigrams whose cooccurrences are greater than a given threshold 3.",0,original
"1 Introduction Conditional Maximum Entropy (CME) modeling has received a great amount of attention within natural language processing community for the past decade (e.g. , Berger et al. , 1996; Reynar and Ratnaparkhi, 1997; Koeling, 2000; Malouf, 2002; Zhou et al. , 2003; Riezler and Vasserman, 2004).",0,original
"Similarity-based smoothing (Hindle 1990; Brown et al. 1992; Dagan, Marcus, and Markovitch 1993; Pereira, Tishby, and Lee 1993; Dagan, Lee, and Pereira 1999) provides an intuitively appealing approach to language modeling.",0,original
(2006) and McClosky et al.,0,original
"1 Introduction During the last few years, SMT systems have evolved from the original word-based approach (Brown et al. , 1993) to phrase-based translation systems (Koehn et al. , 2003).",0,original
"(HICSS-35</booktitle> <contexts> <context>documents, genres also work on an intra-document, or page segment level because a single document can contain instances of multiple genres, e.g., contact information, list of publications, C.V., see (Rehm, 2002; Rehm, 2007; Mehler et al., 2007).",0,original
"Various clustering techniques have been proposed (Brown et al. , 1992; Jardino and Adda, 1993; Martin et al. , 1998) which perform automatic word clustering optimizing a maximum-likelihood criterion with iterative clustering algorithms.",0,original
"Our system is a re-implementation of the phrase-based system described in Koehn (2003), and uses publicly available components for word alignment (Och and Ney, 2003)1, decoding (Koehn, 2004a)2, language modeling (Stolcke, 2002)3 and finite-state processing (Knight and Al-Onaizan, 1999)4.",0,original
"It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation (MT) system (Koehn et al., 2003), or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework.",0,original
Barzilay & Lee (2003) and Quirk et al.,0,original
"Some researchers (Hindle, 1990; Grefenstette, 1994; Lin, 1998) classify terms by similarities based on their distributional syntactic patterns.",0,original
"145 2 The Latent Variable Architecture In this section we will begin by briefly introducing the class of graphical models we will be using, Incremental Sigmoid Belief Networks (Titov and Henderson, 2007).",0,original
"(2004) describe how to learn hundreds of millions of treetransformation rules from a parsed, aligned Chinese/English corpus, and Galley et al.",0,original
"However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods (Koehn et al., 2003).",0,original
"Sentiment classification at the document level investigates ways to classify each evaluative document (e.g., product review) as positive or negative (Pang et al 2002; Turney 2002).",0,original
"The performance of tl,e presented tagger is measured and compared to that of two other taggers (Cutting et al. , 1992; Kempe, 1993).",0,original
"Since Chinese text is not orthographically separated into words, the standard methodology is to first preproce~ input texts through a segmentation module (Chiang et al. 1992; Linet al. 1992; Chang & Chert 1993; Linet al. 1993; Wu & Tseng 1993; Sproat et al. 1994).",0,original
"2 Related Work Starting with the IBM models (Brown et al. , 1993), researchers have developed various statistical word alignment systems based on different models, such as hidden Markov models (HMM) (Vogel et al. , 1996), log-linear models (Och and Ney, 2003), and similarity-based heuristic methods (Melamed, 2000).",0,original
"The simplest ""period-space-capital_letter"" approach works well for simple texts but is rather unreliable for texts with many proper names and abbreviations at the end of sentence as, for instance, the Wall Street Journal (WSJ) corpus ( (Marcus et al. , 1993) ).",0,original
"(Brants et al., 2007; Emami et al., 2007) built 5-gram LMs over web using distributed cluster of machines and queried them via network requests.",0,original
Brown et al (1992) put forward and discussed n-gram models based on classes of words.,0,original
"These probabilities are estimated with IBM model 1 (Brown et al., 1993) on parallel corpora.",0,original
"5.1 Relationship to ""supervised"" training To illustrate the relationship between the above symbolic training method for preference scoring and corpus-based methods, perhaps the easiest way is to compare it to an adaptation (Collins and Roark, 2004) of the perceptron training method to the problem of obtaining a best parse (either directly, or for parse reranking), because the two methods are analogous in a number of ways.",0,original
"Research in the first category aims to identify specific types of nonanaphoric phrases, with some identifying pleonastic it (using heuristics [e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)], supervised approaches [e.g., Evans (2001), Muller (2006), Versley et al.",0,original
"The query tions, the syntax, semantics, and abstract knowledge representation have type declarations (Crouch and King, 2008) which help to detect malformed representations.",0,original
"We measure semantic similarity using the shortest path length in WordNet (Fellbaum, 1998) as implemented in the WordNet Similarity package (Pedersen et al., 2004).",0,original
"Since there is no well-agreed to definition of what an utterance is, we instead focus on intonational phrases (Silverman et al. , 1992), which end with an acoustically signaled boundary lone.",0,original
"Secondly, while all taggers use lexical information, and, indeed, it is well-known that lexical probabilities are much more revealing than tag sequence probabilities (Charniak et al. , 1993), most taggers make quite limited use of lexical probabilities (compared with, for example, the bilexical probabilities commonly used in current statistical parsers).",0,original
"Our evaluation metric is case-insensitive BLEU-4 (Papineni et al. 2002), as defined by NIST, that is, using the shortest (as opposed to closest) reference sentence length for the brevity penalty.",0,original
"4 Maximum Entropy To explain our method, we l)riefly des(:ribe the con(:ept of maximum entrol)y. Recently, many al)lnoaches l)ased on the maximum entroi)y lnodel have t)een applied to natural language processing (Berger eL al. , \]994; Berger et al. , 1996; Pietra et al. , 1997).",0,original
"It is appreciated that multi-sense words appearing in the same document tend to be tagged with the same word sense if they belong to the same common domain in the semantic hierarchy (Yarowsky, 1995).",0,original
"IBM constraints (Berger et al., 1996), the lexical word reordering model (Tillmann, 2004), and inversion transduction grammar (ITG) constraints (Wu, 1995; Wu, 1997) belong to this type of approach.",0,original
"An exception is the use of similarity for alleviating the sparse data problem in language modeling (Essen & Steinbiss, 1992; Brown et al. , 1992; Dagan et al. , 1994).",0,original
"The data set is same as in Section 5.1, except that we also parsed the English-side using a variant of the Collins (1997) parser, and then extracted 24.7M tree-to-string rules using the algorithm of (Galley et al. , 2006).",0,original
"We examine Structural Correspondence Learning (SCL) (Blitzer et al., 2006) for this task, and compare it to several variants of Self-training (Abney, 2007; McClosky et al., 2006).",0,original
"Researchers have focused on learning adjectives or adjectival phrases (Turney, 2002; Hatzivassiloglou and McKeown, 1997; Wiebe, 2000) and verbs (Wiebe et al. , 2001), but no previous work has focused on learning nouns.",0,original
"This can be seen as a simplified version of (Rosti et al., 2007b).",0,original
"For process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (Dave et al. , 2003; Beineke et al. , 2004; Hu and Liu, 2004; Pang and Lee, 2004) or multipoint scale categories (Kim and Hovy, 2004; Pang and Lee, 2005).",0,original
"2.4 Formalization of (Daume III, 2007) As mentioned earlier, our model is equivalent to that presented in (Daume III, 2007), and can be viewed as a formal version of his model.2 In his presentation, the adapation is done through feature augmentation.",0,original
"It is possible to prove that, provided the training set (xi,zi) is separable with margin > 0, the algorithm is assured to converge after a finite number of iterations to a model with zero training errors (Collins and Roark, 2004).",0,original
"2.2 Statistical Approaches with a grmnnmr There have been nlally l)rOl)osals tbr statistical t'rameworks particularly designed tbr 1)arsers with hand-crafted grmnmars (Schal)es, 1992; Briscoe and Carroll, 1993; Abney, 1996; Inui et al. , 1!)97).",0,original
"Our approach to inducing syntactic clusters is closely related to that described in Brown, et al, (1992) which is one of the earliest papers on the subject.",0,original
"We use the perceptron algorithm for sequence tagging (Collins, 2002).",0,original
"For the statistics-based approaches, Bean and Riloff (1999) developed a statistics-based method for automatically identifying existential definite NPs which are non-anaphoric.",0,original
"In this article, we used the algorithm of (Brown et al., 1992) to initialize the model.",0,original
"We adopt an approach, similar to (Ciaramella, 1993; Boros et al. , 1996), in which the meaning representation, in our case XML, is transformed into a sorted flat list of attribute-value pairs indicating the core contentful concepts of each command.",0,original
"If human-aligned data is available, the EMD algorithm provides higher baseline alignments than GIZA++ that have led to better MT performance (Fraser and Marcu, 2006).",0,original
We set our space usage to match the 3.08 bytes per n-gram reported in Talbot and Brants (2008) and held out just over 1M unseen n-grams to test the error rates of our models.,0,original
"84 5.2 Machine translation on Europarl corpus We further tested our WDHMM on a phrase-based machine translation system to see whether our improvement on word alignment can also improve MT accuracy measured by BLEU score (Papineni et al. , 2002).",0,original
"Wu (1997) demonstrates the case of binary SCFG parsing, where six string boundary variables, three for each language as in monolingual CFG parsing, interact with each other, yielding an O(N6) dynamic programming algorithm, where N is the string length, assuming the two paired strings are comparable in length.",0,original
"2 Related Work There has been a large and diverse body of research in opinion mining, with most research at the text (Pang et al., 2002; Pang and Lee, 2004; Popescu and Etzioni, 2005; Ounis et al., 2006), sentence (Kim and Hovy, 2005; Kudo and Matsumoto, 2004; Riloff et al., 2003; Yu and Hatzivassiloglou, 2003) or word (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kim and Hovy, 2004; Takamura et al., 2005; Andreevskaia and Bergler, 2006; Kaji and Kitsuregawa, 2007) level.",0,original
"NeATS computes the likelihood ratio (Dunning, 1993) to identify key concepts in unigrams, bigrams, and trigrams and clusters these concepts in order to identify major subtopics within the main topic.",0,original
"However, instead of estimating the probabilities for the production rules via EM as described in [Wu 1997], we assign the probabilities to the rules using the Model-1 statistical translation lexicon [Brown et al. 1993].",0,original
"Precision and recall rates were 92.4% on the same data used in (Ramshaw and Marcus, 1995).",0,original
"The idea of threading EEs to their antecedents in a stochastic parser was proposed by Collins (1997), following the GPSG tradition (Gazdar et al. , 1985).",0,original
The algorithm we implemented is inspired by the work of Yarowsky (1995) on word sense disambiguation.,0,original
"Then, those structurally matched parallel sentences are used as a source for acquiring lexical knowledge snch as verbal case frames (Utsuro et al. , 1992; Utsuro et al. , 1993).",0,original
"Techniques for weakening the independence assumptions made by the IBM models 1 and 2 have been proposed in recent work (Brown et al. , 1993; Berger et al. , 1996; Och and Weber, 98; Wang and Waibel, 98; Wu and Wong, 98).",0,original
"(Johnson [1997] notes that this structure has a higher probability than the correct, flat structure, given counts taken from the treebank for a standard PCFG).",0,original
"4.1 Experimental Setup We use the whole Penn Treebank corpus (Marcus et al. , 1993) as our data set.",0,original
"We compute log-likelihood significance between features and target nouns (as in (Dunning, 1993)) and keep only the most significant 200 features per target word.",0,original
"Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese.",0,original
"At any rate, regularized conditional loglinear models have not previously been applied to the problem of producing a high quality part-of-speech tagger: Ratnaparkhi (1996), Toutanova and Manning (2000), and Collins (2002) all present unregularized models.",0,original
"The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004).",0,original
"4 Evaluation The evaluation is conducted with all four corpora from Bakeoff-3 (Levow, 2006), as summarized in Table 1 with corpus size in number of characters.",0,original
"The reliability for the two annotation tasks (-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively.",0,original
"The XEROX tagger comes with a list of built-in ending guessing rules (Cutting et al. ,1992).",0,original
"291 3.1 Level of Analysis Research on sentiment annotation is usually conducted at the text (Aue and Gamon, 2005; Pang et al., 2002; Pang and Lee, 2004; Riloff et al., 2006; Turney, 2002; Turney and Littman, 2003) or at the sentence levels (Gamon and Aue, 2005; Hu and Liu, 2004; Kim and Hovy, 2005; Riloff et al., 2006).",0,original
"Typically, frequency information for rare words in the training data is used to estimate parameters for unknown words (and when these rare or unknown words are encountered during parsing, additional information may be obtained from a POS-tagger (Collins 1997)).",0,original
"3 A Categorization of Block Styles In (Brown et al. , 1993), multi-word cepts (which are realized in our block concept) are discussed and the authors state that when a target sequence is sufficiently different from a word by word translation, only then should the target sequence should be promoted to a cept.",0,original
"One is the longest common subsequence (LCS) based approach (Hori et al. , 2003; Lin, 2004a; Lin, 2004b; Lin and Och, 2004).",0,original
"4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework (Koehn et al. , 2003; Och and Ney, 2004).",0,original
"(2007), we introduced the Movie Review Polarity Dataset Enriched with Annotator Rationales.8 It is based on the dataset of Pang and Lee (2004),9 which consists of 1000 positive and 1000 negative movie reviews, tokenized and divided into 10 folds (F0F9).",0,original
"6 Smaller Tagset and Incomplete Dictionaries Previously, researchers working on this task have also reported results for unsupervised tagging with a smaller tagset (Smith and Eisner, 2005; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008; Goldberg et al., 2008).",0,original
"In these experiments we used the MXPOST tagger (Ratnaparkhi, 1996) combined withCollinsparser(Collins,1996)toassignparse trees to the corpus.",0,original
"Chunking For NP chunking, \[Argamon et al. , 1998\] used data extracted from section 15-18 of the WS.J as a fixed train set and section 20 as a fixed test set, the same data as \[Ramshaw and Marcus, 1995\].",0,original
"The results we obtained on the CoNLL03 test set were consistent with what was reported in (Finkel et al., 2005).",0,original
"For instance, several studies have shown that BLEU correlates with human ratings on machine translation quality (Papineni et al. 2002; Doddington 2002; Coughlin 2003).",0,original
"have been used in statistical machine translation (Brown et al. , 1990), terminology research and translation aids (Isabelle, 1992; Ogden and Gonzales, 1993; van der Eijk, 1993), bilingual lexicography (Klavans and Tzoukermann, 1990; Smadja, 1992), word-sense disambiguation (Brown et al. , 1991b; Gale et al. , 1992) and information retrieval in a multilingual environment (Landauer and Littman, 1990).",0,original
"The translation models were pharse-based (Zen et al. , 2002) created using the GIZA++ toolkit (Och et al. , 2003).",0,original
"Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used cooccurrence statistics in local context to discover sibling relations.",0,original
"In practice, we used MMR in our experiments, since the original MEAD considers also sentence positions 3 , which can always been added later as in (Penn and Zhu, 2008).",0,original
"6 Discussion Lack of interannotator agreement presents a significant problem in annotation efforts (see, e.g., Marcus et al. 1993).",0,original
"Eisner (1996), Charniak (1997), Collins (1997), and many subsequent researchers1 annotated every node with lexical features passed up from its head child, in order to more precisely reflect the nodes inside contents.",0,original
"5 Experiments We compare the performance of our forest reranker against n-best reranking on the Penn English Treebank (Marcus et al., 1993).",0,original
"For the chunk part of the code, we adopt the Inside, Outside, and Between (IOB) encoding originating from (Ramshaw and Marcus, 1995).",0,original
Each queue Hi stores the only N-best 43 Table 1: Parsing results LR(%) LP(%) F(%) Roark (2004) 86.4 86.8 86.6 Collins and Roark (2004) 86.5 86.8 86.7 No adjoining 86.3 86.8 86.6 Non-monotonic adjoining 86.1 87.1 86.6 Monotonic adjoining 87.2 87.7 87.4 partial parse trees.,0,original
"REALM uses an HMM trained on a large corpus to help determine whether the arguments of a candidate relation are of the appropriate type (Downey et al., 2007).",0,original
"The relatedness between two word senses is computed using a measure of semantic relatedness defined in the WordNet::Similarity software package (Pedersen et al. , 2004), which is a suite of Perl modules implementing a number WordNet-based measures of semantic relatedness.",0,original
"Note that, since the FrameNet data does not include deep syntactic tree annotation, we processed the FrameNet data with Collins parser (Collins, 1997), consequently, the experiments on FrameNet relate to automatic syntactic parse trees.",0,original
"1 Introduction Previous corpus-based sense disambiguation methods require substantial amounts of sense-tagged training data (Kelly and Stone, 1975; Black, 1988 and Hearst, 1991) or aligned bilingual corpora (Brown et al. , 1991; Dagan, 1991 and Gale et al. 1992).",0,original
"1 Introduction Most empirical work in translation analyzes models and algorithms using BLEU (Papineni et al., 2002) and related metrics.",0,original
"It achieves 90.1% average precision/recall for sentences with maximum length 40 and 89.5% for sentences with maximum length 100 when trained and tested on the standard sections of the Wall Street Journal Treebank (Marcus et al. , 1993).",0,original
"In this paper, we make a direct comparison of a syntactically unsupervised alignment model, based on Wu (1997), with a syntactically supervised model, based on Yamada and Knight (2001).",0,original
"We can sum over all non-projective spanning trees by taking the determinant of the Kirchhoff matrix of the graph defined above, minus the row and column corresponding to the root node (Smith and Smith, 2007).",0,original
"For the first two tasks, all heuristics of the Pharaoh-Toolkit (Koehn et al., 2003) as well as the refined heuristic (Och and Ney, 2003) to combine both IBM4-alignments were tested and the best ones are shown in the tables.",0,original
"In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation(Brown et al. , 1993; Brown et al. , 1991; Gale and Church, 1993; Church, 1993; Simard et al. , 1992), large amount of human effort and time has been invested in collecting parallel corpora of translated texts.",0,original
"Otherwise they are generated along with the words using the same approach as in (Collins, 1997).",0,original
"We have used a state-of-the-art Chinese handwriting recognizer (Li et al. , 1992) developed by ATC, CCL, ITRI, Taiwan as the basis of our experiments.",0,original
"Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate (MER) (Och, 2003) training, proposes directions to search for a better weight-vector  to combine feature functions.",0,original
"We show that link 1For a complete discussion of alignment symmetrization heuristics, including union, intersection, and refined, refer to (Och and Ney, 2003).",0,original
"Thus we rank each sense wsi WSw using Prevalence Score wsi = (11)  njNw dssnj  wnss(wsi,nj) wsiWSw wnss(wsi,nj) where the WordNet similarity score (wnss) is defined as: wnss(wsi,nj)= max nsxNSnj (wnss(wsi,nsx)) 2.2 Building the Thesaurus The thesaurus was acquired using the method described by Lin (1998).",0,original
"Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005).",0,original
Words in test data that have not been seen in training are deterministically assigned the POS tag that is assigned by the tagger described in Ratnaparkhi (1996).,0,original
"To support a more rigorous analysis, however, wc have followed Carletta's suggestion (1996) of using the K coettMcnt (Siegel and Castellan, 1988) as a measure of coder agreement.",0,original
"Hw6: Implement beam search and reduplicate the POS tagger described in (Ratnaparkhi, 1996).",0,original
"1 Introduction Word alignment is an important step of most modern approaches to statistical machine translation (Koehn et al. , 2003).",0,original
"In a second top-down pass similar to Huang and Chiang (2007), we can recalculate psyn(d) for alternative derivations in the hypergraph; potentially correcting search errors made in the first pass.",0,original
"To address this drawback, we proposed a new method3 to compute a more reliable and smoothed score in the undefined case, based on the IBM model 1 (Brown et al., 1993).",0,original
"The methodology used (Brown et al. , 1993) is based on the definition of a function Pr(tI1|sJ1) that returns the probability that tI1 is a 835 source Transferir documentos explorados a otro directorio interaction-0 Move documents scanned to other directory interaction-1 Move s canned documents to other directory interaction-2 Move scanned documents to a nother directory interaction-3 Move scanned documents to another f older acceptance Move scanned documents to another folder Figure 1: Example of CAT system interactions to translate the Spanish source sentence into English.",0,original
"In order to determine interannotator agreement for step 2 of the coding procedure for the database of annotated texts, we calculated kappa statistics (Carletta 1996).",0,original
"It is an extension of Pharaoh (Koehn et al. , 2003), and supports factor training and decoding.",0,original
"Recently, it has gained renewed attention as empirical methods in parsing have emphasized the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly, but context-free phrase-structure grammars do not.",0,original
"Also, even the two-category version of the rating-inference problem for movie reviews has proven quite challenging for many automated classi cation techniques (Pang, Lee, and Vaithyanathan, 2002; Turney, 2002).",0,original
"Distortion models were first proposed by (Brown et al. , 1993) in the so-called IBM Models.",0,original
"5 Discussion and Future Work The work in this paper substantially differs from previous work in SMT based on the noisy channel approach presented in (Brown et al. , 1993).",0,original
"Cucerzan (2007), by contrast to the above, used Wikipedia primarily for Named Entity Disambiguation, following the path of Bunescu and Paca (2006).",0,original
"For example, the coding manual for the Switchboard DAMSL dialogue act annotation scheme (Jurafsky, Shriberg, and Biasca 1997, page 2) states that kappa is used to assess labelling accuracy, and Di Eugenio and Glass (2004) relate reliability to the objectivity of decisions, whereas Carletta (1996) regards reliability as the degree to which we understand the judgments that annotators are asked to make.",0,original
"Two disjoint corpora are used in steps 2 and 5, both consisting of complete articles taken from the Wall Street Journal Treebank Corpus (Marcus et al. , 1993).",0,original
"In our Machine %'anslation system, transfer rules are generated automatically from parsed parallel text along the lines of (Matsulnoto el; al,, 1993; Meyers et al. , 1996; Meyers et al. , 1998b).",0,original
"A major issue in MaxEnt training is how to select proper features and determine the feature targets (Berger et al. , 1996; Jebara and Jaakkola, 2000).",0,original
"As referring dataset, we used the PropBank corpora available at www.cis.upenn.edu/ace, along with the Penn TreeBank 2 (www.cis.upenn.edu/treebank) (Marcus et al. , 1993).",0,original
"The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9 The Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajic, 1998; Hajic et al., 2001), which is directly annotated with dependency structures.",0,original
"By analyzing rhetorical discourse structure of aim, background, solution, etc. or citation context, we can obtain appropriate abstracts and the most influential contents from scientific articles (Teufel and Moens, 2002; Mei and Zhai, 2008).",0,original
"The association relationship between two words can be indicated by their mutual information, which can be further used to discover phrases \[Church :& Hanks (1990)\].",0,original
"3.3 Syntax based approach An alternative to the Window and Document-oriented approach is to use syntactical information (Grefenstette, 1993).",0,original
"While theoretically sound, this approach is computationally challenging both in practice (DeNero et al., 2008) and in theory (DeNero and Klein, 2008), may suffer from reference reachability problems (DeNero et al., 2006), and in the end may lead to inferior translation quality (Koehn et al., 2003).",0,original
"The most relevant to our work are Kazama and Torisawa (2007), Toral and Muoz (2006), and Cucerzan (2007).",0,original
"Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools (Hindle, 1990), (Zernik, 1990), (Resnik, 1993), or for automatic thesaurus generation (Grefenstette, 1994).",0,original
"Methods 4.1 Experiment 1: Held out data To examine the generalizability of classifiers trained on the automatically generated data, a C4.5 decision tree classifier (Quinlan, 1993) was trained and tested on the held out test set described above.",0,original
"Dunning (1993) argues for the use of G 2 rather than X 2, based on the claim that the sampling distribution of G 2 approaches the true chi-square distribution quicker than the sampling distribution of X 2 . However, Agresti (1996, page 34) makes the opposite claim: The sampling distributions of X 2 and G 2 get closer to chi-squared as the sample size n increasesThe convergence is quicker for X 2 than G 2 . In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic.",0,original
"We took part the Multilingual Track of all ten languages provided by the CoNLL-2007 shared task organizers(Hajic et al. , 2004; Aduriz et al. , 2003; Mart et al. , 2007; Chen et al. , 2003; Bohmova et al. , 2003; Marcus et al. , 1993; Johansson and Nugues, 2007; Prokopidis et al. , 2005; Csendes et al. , 2005; Montemagni et al. , 2003; Oflazer et al. , 2003).",0,original
"To prune away those pairs, we used the log-likelihood-ratio algorithm (Dunning, 1993) to compute the degree of association between the verb and the noun in each pair.",0,original
"The key difference is that, instead of using the delta rule of Equation (8) (as shown in line 5 of Figure 4), Collins (2002) updates parameters using the rule:  t+1 d   t d + f d (w R i )  f d (w i ).",0,original
"To measure the translation quality, we use the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002).",0,original
"Research prototypes exist for applications such as personal email and calendars, travel and restaurant information, and personal banking (Baggia et al. , 1998; Walker et al. , 1998; Seneff et al. , 1995; Sanderman et al. , 1998; Chu-Carroll and Carpenter, 1999) inter alia.",0,original
"We report case-insensitive scores on version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006).",0,original
"For the final ranking, we chose the log likelihood statistic outlined in Dunning (1993), which is based upon the co-occurrence counts of all nouns (see Dunning for details).",0,original
"4.1 Corpora set-up The above kernels were experimented over two corpora: PropBank (www.cis.upenn.edu/ ace) along with Penn TreeBank5 2 (Marcus et al. , 1993) and FrameNet.",0,original
"We used the preprocessed data to train the phrase-based translation model by using GIZA++ (Och and Ney, 2003) and the Pharaoh tool kit (Koehn et al., 2003).",0,original
"Obviously, these productions are not in the normal form of an ITG, but with the method described in (Wu, 1997), they can be normalized.",0,original
"This strategy is commonly used in multi-document summarization (Barzilay et al., 1999; Goldstein et al., 2000; Radev et al., 2000), where the combination step eliminates the redundancy across selected excerpts.",0,original
"In (Koo and Collins, 2005), an undirected graphical model is used for parse reranking.",0,original
"For example, researchers (Turney 2002; Yu and Hatzivassiloglou 2003) have identified semantic correlation between words and views: positive words tend to appear more frequently in positive movie and product reviews and newswire article sentences that have a positive semantic orientation and vice versa for negative reviews or sentences with a negative semantic orientation.",0,original
"On one hand, as (Barzilay & Lee, 2003) evidence, clusters of paraphrases can lead to better learning of text-totext rewriting rules compared to just pairs of paraphrases.",0,original
"Our proposal is a first order linear model that relies on an online averaged Perceptron for learning (Collins, 2002) and an extended Eisner algorithm for the joint parsing inference.",0,original
This model is related to the averaged perceptron algorithm of Collins (2002).,0,original
"The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method.",0,original
"Because it is not feasible here to have humans judge the quality of many sets of translated data, we rely on an array of well known automatic evaluation measures to estimate translation quality :  BLEU (Papineni et al. 2002) is the geometric mean of the n-gram precisions in the output with respect to a set of reference translations.",0,original
"The second model is a maximum entropy model (Jaynes, 1978), since Klein and Manning (Klein and Manning, 2002) found that this model yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance.",0,original
"One of the applications is in automatic summarization in order to compress sentences extracted for the summary (Lin, 2003; Jing and McKeown, 2000).",0,original
"After the parser produces a semantic feature structure representation of the sentence, predicate mapping rules then match against that representation in order to produce a predicate language representation in the style of Davidsonian event based semantics (Davidson, 1967; Hobbs, 1985), as mentioned above.",0,original
"The self-training protocol is the same as in (Charniak, 1997; McClosky et al., 2006; Reichart and Rappoport, 2007): we parse the entire unlabeled corpus in one iteration.",0,original
"The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks, 1990; Zernik and Jacobs, 1990; Hindle, 1990).",0,original
"The quality of the translation output is mainly evaluated using BLEU, with NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) as complementary metrics.",0,original
"In order increase the likelihood that 909 only true paraphrases were considered as phraselevel alternations for an example, extracted sentences were clustered using complete-link clustering using a technique proposed in (Barzilay and Lee, 2003).",0,original
"for their models (Brown et al. , 1993b).",0,original
"LW was originally used to validate the quality of a phrase translation pair in MT (Koehn et al., 2003).",0,original
"2 Phrase-based statistical machine translation Phrase-based SMT uses a framework of log-linear models (Och, 2003) to integrate multiple features.",0,original
"Day 1 Day 2 No ASR adaptation 29.39 27.41 Unsupervised ASR adaptation 31.55 27.66 Supervised ASR adaptation 32.19 27.65 Table 2: Impact of ASR adaptation to SMT Table 2 shows the impact of ASR adaptation on the performance of the translation system in BLEU (Papineni et al., 2002).",0,original
"More recent papers Hindle (1990), Pereira and Tishby (1992) proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts.",0,original
"The sequential classi cation approach can handle many correlated features, as demonstrated in work on maximum-entropy (McCallum et al. , 2000; Ratnaparkhi, 1996) and a variety of other linear classi ers, including winnow (Punyakanok and Roth, 2001), AdaBoost (Abney et al. , 1999), and support-vector machines (Kudo and Matsumoto, 2001).",0,original
"3.2 Probability structure of the original model We use p to denote the unlexicalized nonterminal corresponding to P, and similarly for li, ri and h. We now present the top-level generation probabilities, along with examples from 4The inclusion of the word feature in the BBN model was due to the work described in (Weischedel et al. , 1993), where word features helped reduce part of speech ambiguity for unknown words.",0,original
"We have implemented a parallel version of our GIS code using the MPICH library (Gropp et al. , 1996), an open-source implementation of the Message Passing Interface (MPI) standard.",0,original
"The second attempts to instill knowledge of collocations in the data; we use the technique described by (Dunning, 1993) to compute multi-word expressions and then mark words that are commonly used as such with a feature that expresses this fact.",0,original
"Besides the the case-sensitive BLEU-4 (Papineni et al., 2002) used in the two experiments, we design another evaluation metrics Reordering Accuracy (RAcc) for forced decoding evaluation.",0,original
"These feature functions fi were used to train a maximum entropy classifier (Berger et al., 1996) (Le, 2004)thatassignsaprobabilitytoaREregiven context cx as follows: p(re| cx) = Z(cx)exp nsummationdisplay i=1 ifi(cx,re) where Z(cx) is a normalizing sum and the i are the parameters (feature weights) learned.",0,original
"Importantly, this Bayesian approach facilitates the incorporation of sparse priors that result in a more practical distribution of tokens to lexical categories (Johnson, 2007).",0,original
"(1992), Yarowsky (1995), and Karol & Edelman (1996) where strong reliance on statistical techniques for the calculation of word and context similarity commands large source corpora.",0,original
"A standard solution is to use a weighted linear mixture of N-gram models, 1  n  N, (Brown et al. , 1992).",0,original
"Many recent approaches in natural language processing (Yarowsky, 1995; Collins and Singer, 1999; Riloff and Jones, 1999; Nigam et al. , 2000; Wiebe and Riloff, 2005) have recognized the need to use unannotated data to improve performance.",0,original
"(Fraser and Marcu, 2006a) established that it is important to tune  (the trade-off between Precision and Recall) to maximize performance.",0,original
"It has been shown that the methods can be ported to other languages and treebanks (Burke et al. , 2004; Cahill et al. , 2003), including Cast3LB (ODonovan et al. , 2005).",0,original
"Also, adding a constituent size/distance effect, as described by Schubert (1986) and as used by some researchers in parsing (e.g. Lesmo and Torasso (1985) and Collins (1997)) would almost certainly improve parsing.",0,original
"Both models are based on IBM translation model 2 (Brown et al. , 1993) which has the 49 property that it generates tokens independently.",0,original
"Specifically, stochastic translation lexicons estimated using the IBM method (Brown et al. , 1993) from a fairly large sentence-aligned Chinese-English parallel corpus are used in their approach  a considerable demand for a resourcedeficient language.",0,original
"5.3 Related works and discussion Our two-step model essentially belongs to the same category as the works of (Mani et al. , 1999) and (Jing and McKeown, 2000).",0,original
"For comparison purposes, we also computed the value of R 2 for fluency using the BLEU score formula given in (Papineni et al. , 2002), for the 7 systems using the same one reference, and we obtained a similar value, 78.52%; computing the value of R 2 for fluency using the BLEU scores computed with all 4 references available yielded a lower value for R 2, 64.96%, although BLEU scores obtained with multiple references are usually considered more reliable.",0,original
"1http://chasen.org/ taku/software/yamcha/ 2http://chasen.org/ taku/software/TinySVM/ 197 a0 Bracketed representation of roles was converted into IOB2 representation (Ramhsaw and Marcus, 1995) (Sang and Veenstra, 1999).",0,original
"Their weights are optimized w.r.t. BLEU score using the algorithm described in (Och, 2003).",0,original
"(Kuhlmann and Mohl, 2007; McDonald and Nivre, 2007; Nivre et al., 2007) Hindi is a verb final, flexible word order language and therefore, has frequent occurrences of non-projectivity in its dependency structures.",0,original
"Other metrics assess the impact of alignments externally, e.g., different alignments are tested by comparing the corresponding MT outputs using automated evaluation metrics (e.g. , BLEU (Papineni et al. , 2002) or METEOR (Banerjee and Lavie, 2005)).",0,original
Wu (1996) and Berger et al.,0,original
"Our experimental results display that our SDB model achieves a substantial improvement over the baseline and significantly outperforms XP+ according to the BLEU metric (Papineni et al., 2002).",0,original
"Recent work by Koehn and Hoang (2007) pro514 poses factored translation models that combine feature functions to handle syntactic, morphological, and other linguistic information in a log-linear model.",0,original
"Baseline We use the Moses MT system (Koehn et al., 2007) as a baseline and closely follow the example training procedure given for the WMT-07 and WMT-08 shared tasks.4 In particular, we perform word alignment in each direction using GIZA++ (Och and Ney, 2003), apply the grow-diag-finaland heuristic for symmetrization and use a maximum phrase length of 7.",0,original
"For our experiments, we used the binary-only distribution of the tagger (Ratnaparkhi, 1996).",0,original
"Also the use of lossy data structures based on Bloom filters has been demonstrated to be effective for LMs (Talbot and Osborne, 2007a; Talbot and Osborne, 2007b).",0,original
"3 The Framework 3.1 The Algorithm Our transductive learning algorithm, Algorithm 1, is inspired by the Yarowsky algorithm (Yarowsky, 1995; Abney, 2004).",0,original
"It generates a vector of 5 numeric values for each phrase pair:  phrase translation probability: ( f|e) = count( f, e) count(e),(e| f) = count( f, e) count( f) 2http://www.phramer.org/  Java-based open-source phrase based SMT system 3http://www.isi.edu/licensed-sw/carmel/ 4http://www.speech.sri.com/projects/srilm/ 5http://www.iccs.inf.ed.ac.uk/pkoehn/training.tgz 150  lexical weighting (Koehn et al. , 2003): lex( f|e,a) = nproductdisplay i=1 1 |{j|(i, j)  a}| summationdisplay (i,j)a w(fi|ej) lex(e|f,a) = mproductdisplay j=1 1 |{i|(i, j)  a}| summationdisplay (i,j)a w(ej|fi)  phrase penalty: ( f|e) = e; log(( f|e)) = 1 2.2 Decoding We used the Pharaoh decoder for both the Minimum Error Rate Training (Och, 2003) and test dataset decoding.",0,original
"2 Related Research Several researchers (Melamed et al. , 2004; Zhang et al. , 2006) have already proposed methods for binarizing synchronous grammars in the context of machine translation.",0,original
"The grow-diag-final (GDF) combination heuristic (Koehn et al. , 2003) adds links so that each new link connects a previously unlinked token.",0,original
"We also employ the voted perceptron algorithm (Freund and Schapire, 1999) and the early update technique as in (Collins and Roark, 2004).",0,original
"We ran each estimator with the eight different combinations of values for the hyperparameters  and prime listed below, which include the optimal values for the hyperparameters found by Johnson (2007), and report results for the best combination for each estimator below 1.",0,original
"1 Introduction Parsers have been developed for a variety of grammar formalisms, for example HPSG (Toutanova et al. , 2002; Malouf and van Noord, 2004), LFG (Kaplan et al. , 2004; Cahill et al. , 2004), TAG (Sarkar and Joshi, 2003), CCG (Hockenmaier and Steedman, 2002; Clark and Curran, 2004b), and variants of phrase-structure grammar (Briscoe et al. , 2006), including the phrase-structure grammar implicit in the Penn Treebank (Collins, 2003; Charniak, 2000).",0,original
0.9595 0.9590 0.9611 0.9085 0.9134 0.9152 Table 8: Comparison of F1 results of our baseline model with Nakagawa and Uchimoto (2007) and Zhang and Clark (2008) on CTB 3.0.,0,original
"For the Penn Treebank, our research and the work of others (Xia 1999; Chen and Vijay-Shanker 2004; Chiang 2000; Cahill et al. 2002) have shown that such a correspondence exists in most cases.",0,original
"We ran the baseline semisupervised system for two iterations (line 2), and in contrast with (Fraser and Marcu, 2006b) we found that the best symmetrization heuristic for this system was union, which is most likely due to our use of fully linked alignments which was discussed at the end of Section 3.",0,original
"For the give source text, S, it finds the most probable alignment set, A, and target text, T.   = Aa SaTpSTp )|,()|( (1) Brown (Brown et al. , 1993) proposed five alignment models, called IBM Model, for an English-French alignment task based on equa68 tion (1).",0,original
"In terms of relative performance, Naive Bayes tends to do the worst and SVMs tend to do the best, although the 12http://www.english.bham.ac.uk/stafi/oliver/software/tagger/index.htm 13Turneys (2002) unsupervised algorithm uses bigrams containing an adjective or an adverb.",0,original
"To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007).",0,original
"In comparison we introduce 28 several metrics coefficients reported in Albrecht and Hwa (2007) including smoothed BLEU (Lin and Och, 2004), METEOR (Banerjee and Lavie, 2005), HWCM (Liu and Gildea 2005), and the metric proposed in Albrecht and Hwa (2007) using the full feature set.",0,original
Similarities are captured from different viewpoints: DP-HWC(i)-l This metric corresponds to the HWC metric presented by Liu and Gildea (2005).,0,original
" Most work has looked to model non-local dependencies only within a document (Finkel 1125 et al. , 2005; Chieu and Ng, 2002; Sutton and McCallum, 2004; Bunescu and Mooney, 2004).",0,original
"This characteristic of our corpus is similar to problems with noisy and comparable corpora (Veronis, 2000), and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as (Brown et al. , 1993).",0,original
"The significance of G 2 based on the exact conditional distribution does not rely on an asymptotic approximation and is accurate for sparse and skewed data samples (Pedersen et al. , 1996) 4.2 Information criteria The family of model evaluation criteria known as information criteria have the following expression: IC,~ = G 2 ~ x dof (3) where G ~ and dof are defined above.",0,original
"So far, this approach has been taken by a lot of researchers (Pang et al. , 2002; Dave et al. , 2003; Wilson et al. , 2005).",0,original
"Ramshaw and Marcus (1995) state that a baseNP aims to identify essentially the initial portions of nonrecursive noun phrases up to the head, including determiners but not including postmodifying prepositional phrases or clauses . However, work on baseNPs has essentially always proceeded via algorithmic extraction from fully parsed corpora such as the Penn Treebank.",0,original
"An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 proposed in (Banerjee and Lavie, 2005).",0,original
"2.1.2 Research on Syntax-Based SMT A number of researchers (Alshawi, 1996; Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al. , 2004) have proposed models where the translation process involves syntactic representations of the source and/or target languages.",0,original
"Since there is no practical way of determining the classification a0 which maximizes this quantity for a given corpus, (Brown et al., 1992) use a greedy algorithm which proceeds from the initial classification, performing the merge which results in the least loss in mutual information at each stage.",0,original
"The natural next step in sentence alignment is to account for word ordering in the translation model, e.g., the models described in (Brown et al. , 1993) could be used.",0,original
"For example, alignments can be used to learn translation lexicons (Melamed, 1996), transfer rules (Carbonell et al. , 2002; Menezes and Richardson, 2001), and classifiers to find safe sentence segmentation points (Berger et al. , 1996).",0,original
"Following the setup in Johnson (2007), we initialize the transition and emission distributions to be uniform with a small amount of noise, and run EM and VB for 1000 iterations.",0,original
"Research on the automatic classification of movie or product reviews as positive or negative (e.g. , (Pang et al. , 2002; Morinaga et al. , 2002; Turney and Littman, 2003; Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al. , 2004; Hu and Liu, 2004)) is perhaps the most similar to our work.",0,original
"Recent work (Johnson, 2007; Goldwater and Griffiths, 2007; Gao and Johnson, 2008) explored the task of part-of-speech tagging (PoS) using unsupervised Hidden Markov Models (HMMs) with encouraging results.",0,original
"All our experiments used the standard BIO encoding (Ramshaw and Marcus, 1995) with different feature sets and learning procedures.",0,original
"Another body of related work is the literature on word clustering in computational linguistics (Brown et al. 1992; Finch 1993; Pereira, Tishby, and Lee 1993; Grefenstette 1994a) and document clustering in information retrieval (van Rijsbergen 1979; Willett 1988; Sparck-Jones 1991; Cutting et al. 1992).",0,original
"First, we need to determine whether or not the positive effect of SVD feature selection is preserved in more complex feature spaces such as syntactic feature spaces as those used in (Snow et al., 2006).",0,original
"Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007).",0,original
"The publicly available Moses4 decoder is used for training and decoding (Koehn and Hoang, 2007).",0,original
"But it makes obvious that (Ratnaparkhi et al. , 1994) were tackling a problem different from (Hindle and Rooth, 1993) given the fact that their baseline was at 59% guessing noun attachment (rather than 67% in the Hindle and Rooth experiments).3 Of course, the baseline is not a direct indicator of the difficulty of the disambiguation task.",0,original
"On the other hand, the thesaurus-based method of Yarowsky (1992) may suffer from loss of information (since it is semi-class-based) as well as data sparseness (since H Classes used in Resnik (1992) are based on the WordNet taxonomy while classes of Brown et al.",0,original
Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994).,0,original
"SEP/epsilon a/A# epsilon/# a/epsilon a/epsilon b/epsilon b/B UNK/epsilon c/C b/epsilon c/BC e/+E epsilon/+ d/epsilon d/epsilon epsilon/epsilon b/AB# b/A#B# e/+DE c/epsilon d/BCD e/+D+E Figure 1: Illustration of dictionary based segmentation finite state transducer 3.1 Bootstrapping In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al. , 1996).",0,original
"Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER (Leusch et al. , 2006), which employs a version of edit distance for word substitution and reordering; or METEOR (Banerjee and Lavie, 2005), which uses stemming and WordNet synonymy.",0,original
"Language models, such as N-gram class models (Brown et al. , 1992) and Ergodic Hidden Markov Models (Kuhn el, al. , 1994) were proposed and used in applications such as syntactic class (POS) tagging for English (Cutting et al. , 1992), clustering and scoring of recognizer sentence hypotheses.",0,original
"5 Related work Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters (Cutting et al. , 1992) . Schmid used tile equivaleuce classes for smoothing.",0,original
"In order to determine inter-annotator agreement for the database of annotated texts, we computed kappa statistics (Carletta, 1996).",0,original
"First, the addition of each modification improves the F-score for both true and system mentions 9The H&K results shown here are not directly comparable with those reported in Haghighi and Klein (2007), since H&K evaluated their system on the ACE 2004 coreference corpus.",0,original
"Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems (Collins, 1997; Bikel, 2004).",0,original
"Although the training algorithm can handle realvalued features as used in (Och, 2003; Tillmann and Zhang, 2005) the current paper intentionally excludes them.",0,original
Additional evidence for this distinction is given in Pustejovsky and Anick (1988) and Briscoe et al.,0,original
"2.1 Baseline: IBM Model-1 The translation process can be viewed as operations of word substitutions, permutations, and insertions/deletions (Brown et al. , 1993) in noisychannel modeling scheme at parallel sentence-pair level.",0,original
"1 Introduction on measures for inter-rater reliability (Carletta, 1996), on frameworks for evaluating spoken dialogue agents (Walker et al. , 1998) and on the use of different corpora in the development of a particular system (The Carnegie-Mellon Communicator, Eskenazi et al.",0,original
"In particular, we adopt the approach of phrase-based statistical machine translation (Koehn et al., 2003; Koehn and Hoang, 2007).",0,original
"Giving the increasing sophistication of probabilistic linguistic models (for example, Collins (1997) has a statistical approach to learning gap-threading rules) a probabilistic extension of our work is attractive--it will be interesting to see how far an integration of 'logical' and statistical can go.",0,original
Carpuat and Wu (2007b) and Chan et al.,0,original
"Volume 17, Number 1 March 1991 References Lakoff, George and Johnson, Mark Metaphors We Live 8y University of Chicago Press 1980 MADCOW Committee (Hirschman, Lynette et al) Multi-Site Data Collection for a Spoken Language Corpus in Proceedings Speech and Natural Language Workshop February 1992 Grice, H. P. Logic and Conversation in P. Cole and J. L. Morgan, Speech Acts, New York: Academic Press, 1975 Pustejovsky, James The Generative Lexicon Computational Linguistics Volume 17, Number 4 December 1991 Hobbs, Jerry R. and Stickel, Mark Interpretation as Abduction in Proceedings of the 26th ACL June 1988 Bobrow, R. , Ingria, R. and Stallard, D. The Mapping Unit Approach to Subcategorization in Proceedings Speech and Natural Language Workshop February 1991 Hobbs, Jerry R. , and Martin, Paul Local Pragmatics in Proceedings, 10th International Joint Conference on Artificial Intelligence (IJCAI-87).",0,original
"A structured perceptron (Collins, 2002) learns weights for our transliteration features, which are drawn from two broad classes: indicator and hybrid generative features.",0,original
"Recentworkconsidersadamagedtagdictionary by assuming that tags are known only for words that occur more than once or twice (Toutanova and Johnson, 2007).",0,original
"S BNP VP PP VP Mr./g1820g10995 Wu/g2568 plays/g6183 basketball/g12738g10711 on/e Sunday/g7155g7411g3837 S ./g452 Figure 1 Inversion transduction Grammar parsing Any ITG can be converted to a normal form, where all productions are either lexical productions or binary-fanout nonterminal productions(Wu 1997).",0,original
"However, as (Barzilay & Lee, 2003) do not propose any evaluation of which clustering algorithm should be used, we experiment a set of clustering algorithms and present the comparative results.",0,original
"3 Online Learning Again following (McDonald et al. , 2005), we have used the single best MIRA (Crammer and Singer, 2003), which is a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004) for structured prediction.",0,original
"Using this alignment strategy, we follow (Och and Ney 2003) and compute one alignment for each translation direction ( f  e and e  f ), and then combine them.",0,original
"The COlllillOil poini;s regarding collocations appear to be, as (Smadja, 1993) suggestsl: they are m'bil;rary (it is nol; clear why to ""Bill through"" means to ""fail""), th('y are domain-dependent (""interest rate"", ""stock market""), t;hey are recurrenl; and cohesive lo~xical clusters: the presence of one of the.",0,original
"The method uses a translation model based on IBM Model 1 (Brown et al., 1993), in which translation candidates of a phrase are generated by combining translations and transliterations of the phrase components, and matching the result against a large corpus.",0,original
"6.3 Comparison with re-ranking approach Finally, we compared our algorithm with the reranking approach (Collins and Duffy, 2002; Collins, 2002b), where we rst generate the n-best candidates using a model with only local features (the rst model) and then re-rank the candidates using a model with non-local features (the second model).",0,original
"Such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the British 3 linguist J.R. Firth: You shall know a word by the company it keeps. (Firth, 1957, p. 11) Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks (1990) and by Dunning (1993), of identifying word senses, e.g. by Yarowski (1995) and by Schutze (1998), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al.",0,original
"Specifically, we will consider a system which was developed for the ACE (Automatic Content Extraction) task 3 and includes the following stages: name structure parsing, coreference, semantic relation extraction and event extraction (Ji et al. , 2006).",0,original
"This is a particularly exciting area in computational linguistics as evidenced by the large number of contributions in these special issues: Biber (1993), Brent (1993), Hindle and Rooth (this issue), Pustejovsky et al.",0,original
Wu (1997) and Alshawi (1996) describe early work on formalisms that make use of transductive grammars; Graehl and Knight (2004) describe methods for training tree transducers.,0,original
"(Och and Ney, 2003) invented heuristic symmetriza57 FRENCH/ENGLISH ARABIC/ENGLISH SYSTEM F-MEASURE ( = 0.4) BLEU F-MEASURE ( = 0.1) BLEU GIZA++ 73.5 30.63 75.8 51.55 (FRASER AND MARCU, 2006B) 74.1 31.40 79.1 52.89 LEAF UNSUPERVISED 74.5 72.3 LEAF SEMI-SUPERVISED 76.3 31.86 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in (Koehn et al. , 2003).",0,original
"Inversion Transduction Grammar (ITG) (Wu, 1997) and Syntax-Directed Translation Schema (SDTS) (Aho and Ullman, 1969) lack both of these properties.",0,original
"5 Related Work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (Riloff et al., 2003; Pang and Lee, 2004)) and adjacency pair information has been used to predict congressional votes (Thomas et al., 2006).",0,original
"Decoding is carried-out using the Moses decoder (Koehn and Hoang, 2007).",0,original
"As the taskisanimportantprecursortomanynaturallanguage processing systems, it receives a lot of attentions in the literature for the past decade (Wu and Tseng, 1993; Sproat et al. , 1996).",0,original
"However, at the short term, the incorporation of these type of features will force us to either build a new decoder or extend an existing one, or to move to a new MT architecture, for instance, in the fashion of the architectures suggested by Tillmann and Zhang (2006) or Liang et al.",0,original
"As well as the sentiment expressions leading to evaluations, there are many semantic aspects to be extracted from documents which contain writers opinions, such as subjectivity (Wiebe and Mihalcea, 2006), comparative sentences (Jindal and Liu, 2006), or predictive expressions (Kim and Hovy, 2007).",0,original
"Besides precision, recall and (balanced) F-measure, we also include an F-measure variant strongly biased towards recall (#0B=0.1), which (Fraser and Marcu, 2007) found to be best to tune their LEAF aligner for maximum MT accuracy.",0,original
"These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu.",0,original
"The syntactic and part-of-speech informations were obtained from the part of the corpus processed in the Penn Treebank project (Marcus et al. , 1993).",0,original
"In tabh; 2, the accuracy rate of the Net-Tagger is cOrolLated to that of a trigram l)msed tagger (Kempe, 1993) and a lIidden Markov Model tagger (Cutting et al. , 1992) which were.",0,original
"Previous uses of this model include language modeling(Lau et al. , 1993), machine translation(Berger et al. , 1996), prepositional phrase attachment(Ratnaparkhi et al. , 1994), and word morphology(Della Pietra et al. , 1995).",0,original
"For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997; Wang et al. , 2005), and yet they are not being used in current large margin training algorithms.",0,original
"The usual recall and precision metrics (e.g. , how many of the interesting bits of information were detected, and how many of the found bits were actually correct) require either a test corpus previously annotated with the required information, or manual evaluation (Fleischman et al. , 2003).",0,original
"Estimation of the parameters has been described elsewhere (Brown et al. , 1993).",0,original
"Metrics in the Rouge family allow for skip n-grams (Lin and Och, 2004a); Kauchak and Barzilay (2006) take paraphrasing into account; metrics such as METEOR (Banerjee and Lavie, 2005) and GTM (Melamed et al. , 2003) calculate both recall and precision; METEOR is also similar to SIA (Liu and Gildea, 2006) in that word class information is used.",0,original
"Agreement is sometimes measured as percentage of the cases on which the annotators agree, but more often expected agreement is taken into account in using the kappa statistic (Cohen, 1960; Carletta, 1996), which is given by:  = po  pe1  p e (1) where po is the observed proportion of agreement and pe is the proportion of agreement expected by chance.",0,original
"It has been further observed that simply compressing sentences individually and concatenating the results leads to suboptimal summaries (Daume III and Marcu, 2002).",0,original
"For every class the weights of the active features are combined and the best scoring class is chosen (Berger et al. , 1996).",0,original
"1 Introduction In latent variable approaches to parsing (Matsuzaki et al., 2005; Petrov et al., 2006), one models an observed treebank of coarse parse trees using a grammar over more refined, but unobserved, derivation trees.",0,original
"Previous research in this area includes several models which incorporate hidden variables (Matsuzaki et al., 2005; Koo and Collins, 2005; Petrov et al., 2006; Titov and Henderson, 2007).",0,original
"Theyalsoappliedself-training to domain adaptation of a constituency parser (McClosky et al., 2006b).",0,original
"Most current SMT systems (Och and Ney, 2004; Koehn et al. , 2003) use a generative model for word alignment such as the freely available GIZA++ (Och and Ney, 2003), an implementation of the IBM alignment models (Brown et al. , 1993).",0,original
"4 The Experiment For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text (Marcus et al. , 1993), with section 22 reserved for testing.",0,original
"Previous studies (Abney, 1997; Johnson et al. , 1999; Riezler et al. , 2000; Malouf and van Noord, 2004; Kaplan et al. , 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al. , 1996).",0,original
"We tune using Ochs algorithm (Och, 2003) to optimize weights for the distortion model, language model, phrase translation model and word penalty over the BLEU metric (Papineni et al., 2001).",0,original
"Models that support non-monotonic decoding generally include a distortion cost, such as|aibi11|where ai is the starting position of the foreign phrasefi andbi1 is the ending position of phrase fi1 (Koehn et al., 2003).",0,original
"We consider three class models, models S, M, and L, defined as pS(cj|c1cj1,w1wj1)=png(cj|cj2cj1) pS(wj|c1cj,w1wj1)=png(wj|cj) pM(cj|c1cj1,w1wj1)=png(cj|cj2cj1,wj2wj1) pM(wj|c1cj,w1wj1)=png(wj|wj2wj1cj) pL(cj|c1cj1,w1wj1)=png(cj|wj2cj2wj1cj1) pL(wj|c1cj,w1wj1)=png(wj|wj2cj2wj1cj1cj) Model S is an exponential version of the class-based n-gram model from (Brown et al., 1992); model M is a novel model introduced in (Chen, 2009); and model L is an exponential version of the model indexpredict from (Goodman, 2001).",0,original
"More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment (Hindle and Rooth 1991) and pronoun references (Dagan and Itai 1990, 1991).",0,original
"The class labeling system in our experiment is IOB2 (Sang, 2000), which is a variation of IOB (Ramshaw and Marcus, 1995).",0,original
"Similar observations have been made in the context of tagging problems using maximum-entropy models (Lafferty, McCallum, and Pereira 2001; Klein and Manning 2002).",0,original
"Liu and Gildea (2005) also pointed out that due to the limited references for every MT output, using the overlapping ratio of n-grams longer than 2 did not improve sentence level evaluation performance of BLEU.",0,original
"Item Form: a32 a2 a49a51 a15 a52 a49 a51a16a33 Goal: a32a35a34 a49 a51 a15 a23a4a3 a12 a0a36a5 a24 a49 a51a37a33 Inference Rules Scan component d, a10a38a8 a7 a8 a0 : a39a41a40a43a42a44 a44a45 a23a25a24 a49 a5a47a46 a49 a2 a23a25a24 a5a49a48 a49 a51 a50 a23a25a24 a49 a5a47a46 a49 a20a43a5 a3a22 a23a25a24 a5a49a48 a49 a51 a51a14a52 a52 a53 a54a55 a55 a56 a23a25a24 a49 a5a47a46 a49 a2 a23a25a24 a5a49a48 a49 a51 a50 a23a25a24 a49 a5a47a46 a49a23 a19a57a24 a10a13a12 a19 a24 a23a25a24 a5a49a48 a49 a51 a58a59 a59 a60 Compose: a61a63a62a65a64 a66a68a67a69 a64 a66a71a70 a61a35a72a37a64 a66a68a67a73 a64 a66a71a70a36a74a76a75 a32a78a77 a64 a66a76a67a69 a64 a66a80a79a81a73 a64 a66 a14 a62a82a64 a66 a14 a72a37a64 a66 a33 a10 a77 a64 a66 a67a69 a64 a66a37a83 a73 a64 a66 a18 Figure 3: Logic C (C for CKY) These constraints are enforced by the d-span operators a84 and a85 . Parser C is conceptually simpler than the synchronous parsers of Wu (1997), Alshawi et al.",0,original
"All the TB-LMs and O-RLMs were unpruned 5gram models and used Stupid-backoff smoothing (Brants et al., 2007) 2 with the backoff parameter set to 0.4 as suggested.",0,original
"This corpus contains annotations of semantic PASs superimposed on the Penn Treebank (PTB) (Marcus et al. , 1993; Marcus et al. , 1994).",0,original
"Other systems (Morinaga et al. , 2002; Kushal et al. , 2003) also look at Web product reviews but they do not extract 345 opinions about particular product features.",0,original
"These parameters 1 8 are tuned by minimum error rate training (Och, 2003) on the dev sets.",0,original
"Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and McDonald, 2008).",0,original
"The translation quality is evaluated by BLEU metric (Papineni et al. , 2002), as calculated by mteval-v11b.pl 6 with case-sensitive matching of n-grams.",0,original
"1 Introduction Since their appearance, string-based evaluation metrics such as BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) have been the standard tools used for evaluating MT quality.",0,original
"Thus, conventional methods had to introduce some kinds of restrictions such as the limitation of the kind of chains or the length of chains to be extracted (Smadja 1993, Shinnou and Isahara 1995).",0,original
(2008); Liu and Gildea (2005)).,0,original
"5.4 Domain Adaptation 5.4.1 Feature-Based Approaches Onewayofadaptingalearnertoanewdomainwithout using any unlabeled data is to only include features that are expected to transfer well (Dredze et al. , 2007).",0,original
"In the Link Grammar framework (Lagerty et al. , 1992; Della Pietra et al. , 1994), strictly local contexts are naturally combined with long-distance information coming from long-range trigrams.",0,original
"2 Statistical Word Alignment According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in Equation (1).",0,original
"Because of these kinds of results, the vast majority of statistical parsing work has focused on parsing as a supervised learning problem (Collins, 1997; Charniak, 2000).",0,original
"Then, the method of Smith and Smith (2007) can be used to compute the probability of every possible edge conditioned on the presence of ki, p(yiprime =kprime|yi = k,x), using K1ki. Multiplying this probability by p(yi=k|x) yields the desired two edge marginal.",0,original
"(Cutting et al. , 1992; Feldweg, 1995)), the tagger for grammatical functions works with lexical (1) Selbst besucht ADV VVPP himself visited hat Peter Sabine VAFIN NE NE has Peter Sabine 'Peter never visited Sabine himself' l hie ADV never Figure 2: Example sentence and contextual probability measures PO.(') depending on the category of a mother node (Q).",0,original
"Applying the projection WTx (where x is a training instance) would give us m new features, however, for both computational and statistical reasons (Blitzer et al., 2006; Ando and Zhang, 2005) a low-dimensional approximation of the original feature space is computed by applying Singular Value Decomposition (SVD) on W (step 4).",0,original
"For example, it has been observed that texts often contain multiple opinions on different topics (Turney, 2002; Wiebe et al., 2001), which makes assignment of the overall sentiment to the whole document problematic.",0,original
"For example, non-local features such as same phrases in a document do not have different entity classes were shown to be useful in named entity recognition (Sutton and McCallum, 2004; Bunescu and Mooney, 2004; Finkel et al. , 2005; Krishnan and Manning, 2006).",0,original
"The table also shows the -score, which is another commonly used measure for inter-annotator agreement [Carletta, 1996].",0,original
"We extracted 181,250 case frames from the WSJ (Wall Street Journal) bracketed corpus of the Penn Tree Bank (Marcus et al. , 1993).",0,original
"We parsed a 125-million word newspaper corpus with Minipar, 1 a descendent of Principar (Lin, 1993; Lin, 1994), and extracted dependency relationships from the parsed corpus.",0,original
"1 Introduction Previous work on sentiment categorization makes an implicit assumption that a single score can express the polarity of an opinion text (Pang et al. , 2002; Turney, 2002; Yu and Hatzivassiloglou, 2003).",0,original
"Within NLP, applications include sentiment-analysis problems (Pang and Lee, 2004; Agarwal and Bhattacharyya, 2005; Thomas et al., 2006) and content selection for text generation (Barzilay and Lapata, 2005).",0,original
We adopted the stop condition suggested in Berger et al. 1996 the maximization of the likelihood on a cross-validation set of samples which is unseen at the parameter esti~_tion.,0,original
"Whereas until recently the focus of research had been on sense disambiguation, papers like Pantel & Lin (2002), Neill (2002), and Rapp (2003) give evidence that sense induction now also attracts attention.",0,original
"The discrepancy between DEV performance and TEST performance is due to temporal distance from TRAIN and high variance in BLEU score.11 We also compared our model with Pharaoh (Koehn et al. , 2003).",0,original
"Furthermore, I plan to apply my parsers in other domains (e.g. , biomedical data) (Blitzer et al. , 2006) besides treebank data, to investigate the effectiveness and generality of my approaches.",0,original
"We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al. , 1996).",0,original
"2 Background 2.1 Phrase Table Extraction Phrasal decoders require a phrase table (Koehn et al. , 2003), which contains bilingual phrase pairs and 17 scores indicating their utility.",0,original
"We use a statistical POS tagging system built on Arabic Treebank data with MaxEnt framework (Ratnaparkhi, 1996).",0,original
"have been proposed (Hindle, 1990; Brown et al. , 1992; Pereira et al. , 1993; Tokunaga et al. , 1995).",0,original
"(~) 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 2 and Mancini 1991; Meteer, Schwartz, and Weischedel 1991; Merialdo 1991; Pelillo, Moro, and Refice 1992; Weischedel et al. 1993; Wothke et al. 1993).",0,original
"The latter approach has become increasingly popular (e.g. Schabes et al. , 1993; Weischedel et al. , 1993; Briscoe, 1994; Magerman, 1995; Collins, 1996).",0,original
"Our experiments created translation modules for two evaluation corpora: written news stories from the Penn Treebank corpus (Marcus et al. , 1993) and spoken task-oriented dialogues from the TRAINS93 corpus (Heeman and Allen, 1995).",0,original
"These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following (Ramshaw and Marcus, 1995).",0,original
"The up-arrows and down-arrows are shorthand for (M(ni)) = (ni) where ni is the c-structure node annotated with the equation.2 Treebest := argmaxTreeP(Tree|F-Str) (1) P(Tree|F-Str) := productdisplay X  Y in Tree Feats = {ai|vj((X))ai = vj} P(X  Y |X, Feats) (2) The generation model of (Cahill and van Genabith, 2006) maximises the probability of a tree given an f-structure (Eqn.",0,original
"We then train IBM models (Brown et al. , 1993) using the GIZA++ package (Och and Ney, 2000).",0,original
"We then built separate English-to-Spanish and Spanish-to-English directed word alignments using IBM model 4 (Brown et al., 1993), combined them using the intersect+grow heuristic (Och and Ney, 2003), and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach (Och and Ney, 2004).",0,original
"(Berger et al. , 1996).",0,original
"Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSPcooc on the verb join,3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch (subj) 1.18, work at 1.14 give a better SIMS(join) for Equation (1) than the top similarities returned by (Lin, 1998a): participate 0.164, lead 0.150, return to 0.148, say 0.143, rejoin 0.142, sign 0.142, meet 0.142, include 0.141, leave 0.140, work 0.137 Other features are also weighted intuitively.",0,original
Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis.,0,original
"As an alternative, Huang and Chiang (2007) describes a forest-based reranking algorithm called cube growing, which also employs beam search, but focuses computation only where necessary in a top-down pass through a parse forest.",0,original
"Even robust parsers using linguistically sophisticated formalisms, such as TAG (Chiang, 2000), CCG (Clark and Curran, 2004b; Hockenmaier, 2003), HPSG (Miyao et al. , 2004) and LFG (Riezler et al. , 2002; Cahill et al. , 2004), often use training data derived from the Penn Treebank.",0,original
"Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance.",0,original
"It has been used for diverse problems such as machine translation and sense disambiguation \[Gale et al. , 1992, Schiltze, 1992\].",0,original
"The measures are: word overlap, length difference (in words), BLEU (Papineni et al., 2002), dependency relation overlap (i.e., R1 and R2 but not FR1,R2), and dependency tree edit distance.",0,original
"For more information on these models, please refer to Brown et al. [1993].",0,original
"The small differences from their work are: (1) We used characters as the unit as we described above, (2) While Kazama and Torisawa (2007) checked only the word sequences that start with a capitalized word and thus exploitedthecharacteristicsofEnglishlanguage, we checked the matching at every character, (3) We used a TRIE to make the look-up efcient.",0,original
"The reader is referred to (Ushioda 1996) and (Brown et al. 1992) for details of MI clustering, but we will first briefly summarize the MI clustering and then describe our hierarchical clustering algorithm.",0,original
"in their treatment of chunk-initial and chunk-final \[ + \] words: IOB1 IOB2 IOE1 IOE2 The first word inside a baseNP immediately following another baseNP receives a B tag (Ramshaw and Marcus, 1995).",0,original
"So far, most previous work on domain adaptation for parsing has focused on data-driven systems (Gildea, 2001; Roark and Bacchiani, 2003; McClosky et al., 2006; Shimizu and Nakagawa, 2007), i.e. systems employing (constituent or dependency based) treebank grammars (Charniak, 1996).",0,original
"3.1 Results for English We used sections 0 to 12 of the WSJ part of the Penn Treebank (Marcus et al. , 1993) with a total of 24,618 sentences for our experiments.",0,original
"In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al. , 2000; Akiba et al. , 2001; Papineni et al. , 2002; NIST, 2002; Leusch et al. , 2003; Turian et al. , 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gimenez et al. , 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently.",0,original
"Occasionally, in 59 sentences out of 2416 on section 23 of the Wall Street Journal Penn Treebank (Marcus et al. , 1993), the shift-reduce parser fails to attach a node to a head, producing a disconnected graph.",0,original
"Then the two models and a search module are used to decode the best translation (Brown et al., 1993; Koehn et al., 2003).",0,original
"This corpus-based information typically concerns sequences of 1-3 tags or words (with some well-known exceptions, e.g. Cutting et al. 1992).",0,original
"The difference between MWA and bilingual word alignment (Brown et al., 1993) is that the MWA method works on monolingual parallel corpus instead of bilingual corpus used by bilingual word alignment.",0,original
"In contrast, generative models are trained to maximize the joint probability of the training data, which is 1Ramshaw and Marcus (1995) used transformation-based learning (Brill, 1995), which for the present purposes can be tought of as a classi cation-based method.",0,original
The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks 1990; Zernik and Jacobs 1990; Hindle 1990; Smadja 1993).,0,original
"4.2 String-Based Evaluation We evaluate the output of our generation system against the raw strings of Section 23 using the Simple String Accuracy and BLEU (Papineni et al. , 2002) evaluation metrics.",0,original
"We are given a source (Chinese) sentence f = fJ1 = f1,,fj,,fJ, which is to be translated into a target (English) sentence e = eI1 = e1,,ei,,eI Among all possible target sentences, we will choose the sentence with the highest probability: eI1 = argmax eI1 {Pr(eI1|fJ1 )} (1) As an alternative to the often used source-channel approach (Brown et al. , 1993), we directly model the posterior probability Pr(eI1|fJ1 ) (Och and Ney, 2002) using a log-linear combination of feature functions.",0,original
"5.2 Translation experiments with a bigram language model In this section we consider two real translation tasks, namely, translation from English to French, trained on Europarl (Koehn et al., 2003) and translation from German to Spanish training on the NewsCommentary corpus.",0,original
"Context extraction begins with a Maximum Entropy POS tagger and chunker (Ratnaparkhi, 1996).",0,original
"First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases (NPs) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization (Grishman, 1995; Appelt et al. , 1993).",0,original
"1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al. , 1993).",0,original
"The task originally emerged as an intermediate result of training the IBM translation models (Brown et al. , 1993).",0,original
"A problem mentioned in (Talbot and Brants, 2008) is that the algorithm that computes the compressed representation might need to retain the entire database in memory; in their paper, they design strategies to work around this problem.",0,original
"Previous studies (Abney, 1997; Johnson et al. , 1999; Riezler et al. , 2000; Malouf and van Noord, 2004; Kaplan et al. , 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al. , 1996).",0,original
"As (Church and Hanks, 1990), we adopted an evaluation of mutual information as a cohesion measure of each cooccurrence.",0,original
"Following (Collins, 2002), we used sections 0-18 of the Wall Street Journal (WSJ) corpus for training, sections 19-21 for development, and sections 22-24 for final evaluation.",0,original
"The difficulty of this task is that the standard method for converting NER to a sequence tagging problem with BIOencoding (Ramshaw and Marcus, 1995), where each 1http://www.nist.gov/speech/tests/ace/ index.htm token is assigned a tag to indicate whether it is at the beginning (B), inside (I), or outside (O) of an entity, is not directly applicable when tokens belong to more than one entity.",0,original
"We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted.",0,original
"The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).",0,original
"Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gimenez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008).",0,original
"For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning (Brill, 1995), decision trees (Black et al. , 1992), markov model (Cutting et al. 1992), maximum entropy methods (Ratnaparkhi, 1996) etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS (Garside and Smith, 1997).",0,original
"3 Formulation Following Klein and Manning (2001), we use weighted directed hypergraphs (Gallo et al. , 1993) as an abstraction of the probabilistic parsing problem.",0,original
"In prior research, ILP was used as a postprocessing step to remove redundancy and make other global decisions about parameters (McDonald, 2007; Marciniak and Strube, 2005; Clarke and Lapata, 2007).",0,original
"POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993).",0,original
"Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and namedentity identification (Collins and Singer, 1999).",0,original
"Table 2: Three types of class-based MSLMs on Switchboard-I (swbd) and ICSI Meeting (mr) corpora # of swbd mr classes BROWN MMI MCMI BROWN MMI MCMI 100 68.9 0.3 68.4 0.3 68.2 0.3 78.9 3.0 77.3 2.8 76.8 2.8 500 68.9 0.3 68.3 0.3 67.9 0.3 78.7 3.1 77.1 2.8 76.7 2.8 1000 68.9 0.3 68.2 0.3 67.9 0.3 79.0 3.1 77.2 2.7 76.9 2.8 1500 69.0 0.3 68.2 0.3 68.0 0.3 79.6 3.1 77.4 2.7 77.4 2.7 2000 69.0 0.3 68.3 0.3 68.0 0.3 80.1 3.1 77.6 2.7 77.9 2.7 jV j 68.5 0.3 78.3 2.7 Table 3: Class-based MSLM on Switchboard Eval-2003 size 100 500 1000 1500 2000 jV j 3-gram 4-gram ppl 65.8 65.5 65.6 65.7 66.1 67.9 72.1 76.3 % reduction 8.6 8.9 8.8 8.7 8.3 5.8 0 -5.8 Class-based language models (Brown et al. , 1992; Whittaker and Woodland, 2003) yield great bene ts when data sparseness abounds.",0,original
"3.5 Domain adaptation in Machine Translation Within MT there has been a variety of approaches dealing with domain adaption (for example (Wu et al., 2008; Koehn and Schroeder, 2007).",0,original
"Unknown words were not identified in (McClosky et al. , 2006a) as a useful predictor for the benefit of self-training.",0,original
McCarthy et al. use a distributional similarity thesaurus acquired from corpus data using the method of Lin (1998) for nding the predominant sense of a word where the senses are dened by WordNet.,0,original
"Moreover, as stated in (Hobbs, 1985), we assume that the alleged predicate is existentially opaque in its second argument.",0,original
"Minimum error-rate (MER) training (Och, 2003) was applied to obtain weights (m in Equation 2) for these features.",0,original
"In particular, most of the work on parsing with kernel methods has focussed on kernels over parse trees (Collins and Duffy, 2002; Shen and Joshi, 2003; Shen et al. , 2003; Collins and Roark, 2004).",0,original
Online discriminative training has already been studied by Tillmann and Zhang (2006) and Liang et al.,0,original
"1510 5 Related Work In recent years, many research has been done on extracting relations from free text (e.g., (Pantel and Pennacchiotti, 2006; Agichtein and Gravano, 2000; Snow et al., 2006)); however, almost all of them require some language-dependent parsers or taggers for English, which restrict the language of their extractions to English only (or languages that have these parsers).",0,original
"We implemented these models within an maximum entropy framework (Berger et al. , 1996; Ristad, 1997; Ristad, 1998).",0,original
"Carletta suggests that content analysis researchers consider K >.8 as good reliability, with.67< /~"" <.8 allowing tentative conclusions to be drawn (Carletta, 1996).",0,original
"Our approach is based on earlier work on LFG semantic form extraction (van Genabith et al. , 1999) and recent progress in automatically annotating the Penn-II treebank with LFG f-structures (Cahill et al. , 2004b).",0,original
"For the MER training (Och, 2003), Koehns MER trainer (Koehn, 2007) is modified for our system.",0,original
"The IBM models (Brown et al. , 1993) benefit from a one-tomany constraint, where each target word has ex105 the tax causes unrest l' impt cause le malaise Figure 1: A cohesion constraint violation.",0,original
"We shall take HMM-based word alignment model (Vogel et al. , 1996) as an example and follow the notation of (Brown et al. , 1993).",0,original
"This is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted Carletta (1996) to recommend chance-corrected measures.",0,original
"Ramshaw and Marcus(1995) used transformation-based learning, an error-driven learning technique introduced by Eric Bn11(1993), to locate chunks in the tagged corpus.",0,original
"They used the Bleu evaluation metric (Papineni et al. , 2002), but capped the n-gram precision at 4-grams.",0,original
"To tune feature weights minimum error rate training is used (Och, 2003), optimized against the Neva metric (Forsbom, 2003).",0,original
"We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al. , 2000), using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al. , 1993) into HPSG-style.",0,original
"(2002), Turney (2002), Dave et al.",0,original
"5 Analysis Over the last few years, several automatic metrics for machine translation evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle (Lin and Och, 2004; Melamed et al. , 2003; Papineni et al. , 2002).",0,original
"Table 2 shows the dependency accuracy, root accuracy and complete match scores for our best parser (Model 2 with label set B) in comparison with Collins (1997) (Model 3), Charniak (2000), and Yamada and Matsumoto (2003).5 It is clear that, with respect to unlabeled accuracy, our parser does not quite reach state-of-the-art performance, even if we limit the competition to deterministic methods such as that of Yamada and Matsumoto (2003).",0,original
"EnglishChinese (Wellington et al., 2006) and EnglishSpanish (Lepage and Denoual, 2005).",0,original
Kim and Hovy (2006) integrated verb information from FrameNet and incorporated it into semantic role labeling.,0,original
"This is comparable to the accuracy of 96.29% reported by (Daume III, 2007) on the newswire domain.",0,original
"The models in the comparative study by Klein and Manning (2002) did not include such features, and so, again for consistency of comparison, we experimentally verified that our maximum entropy model (a) consistently yielded higher scores than when the features were not used, and (b) consistently yielded higher scores than nave Bayes using the same features, in agreement with Klein and Manning (2002).",0,original
"Statistical parsers trained on the Penn Treebank (PTB) (Marcus et al. , 1993) produce trees annotated with bare phrase structure labels (Collins, 1999; Charniak, 2000).",0,original
"Thus, the WSJ+NANC model has better oracle rates than the WSJ model (McClosky et al. , 2006) for both the WSJ and BROWN domains.",0,original
"A large corpus is vahmble as a source of such nouns (Church and Hanks, 1990; Brown et al. , 1992).",0,original
"A few unsupervised metrics have been applied to automatic paraphrase identification and extraction (Barzilay & Lee, 2003; Dolan et al., 2004).",0,original
"The training methods of LRM-F and SVM-F were useful to improve the F M -scores of LRM and SVM, as reported in (Jansche, 2005; Joachims, 2005).",0,original
"The polarity value proposed by (Turney, 2002) is as follows.",0,original
"In each case the input to the network is a sequence of tag-word pairs.5 5We used a publicly available tagger (Ratnaparkhi, 1996) to provide the tags.",0,original
"These rules are learned using a word alignment model, which finds an optimal mapping from words to MR predicates given a set of training sentences and their correct MRs. Word alignment models have been widely used for lexical acquisition in SMT (Brown et al. , 1993; Koehn et al. , 2003).",0,original
"For this experiment, we used sections 02 21 of the Penn Treebank (PTB) (Marcus et al. , 1993) as the training data and section 23 (2416 sentences) for evaluation, as is now standard.",0,original
"The first LR model for each language uses maximum entropy classification (Berger et al. , 1996) to determine possible parser actions and their probabilities4.",0,original
"16In fact, we have experimented with other tagger combinations and configurations as wellwith the TnT (Brants, 2000), MaxEnt (Ratnaparkhi, 1996) and TreeTagger (Schmid, 1994), with or without the Morce tagger in the pack; see below for the winning combination.",0,original
"Grammar rules were induced with the syntaxbased SMT system SAMT described in (Zollmann and Venugopal, 2006), which requires initial phrase alignments that we generated with GIZA++ (Koehn et al. , 2003), and syntactic parse trees of the target training sentences, generated by the Stanford Parser (D. Klein, 2003) pre-trained on the Penn Treebank.",0,original
"Once the set of features functions are selected, algorithm such as improved iterative scaling (Berger et al. , 1996) or sequential conditional generalized iterative scaling (Goodman, 2002) can be used to find the optimal parameter values of fkg and fig.",0,original
"2.3 Probabilistic models for generation with HPSG Some existing studies on probabilistic models for HPSG parsing (Malouf and van Noord, 2004; Miyao and Tsujii, 2005) adopted log-linear models (Berger et al. , 1996).",0,original
"The SemEval-2010 task we present here builds on thework ofNakov (Nakovand Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions.",0,original
"Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition.",0,original
"The component features are weighted to minimize a translation error criterion on a development set (Och, 2003).",0,original
5.2 Results on the Newsblaster data We measured how well the models trained on DUC data perform with current news labeled using human 4http://newsblaster.cs.columbia.edu 5a20 (kappa) is a measure of inter-annotator agreement over and above what might be expected by pure chance (See Carletta (1996) for discussion of its use in NLP).a20a22a21a24a23 if there is perfect agreement between annotators anda20a25a21a27a26 if the annotators agree only as much as you would expect by chance.,0,original
"Moreover, rather than predicting an intrinsic metric such as the PARSEVAL Fscore, the metric that the predictor learns to predict can be chosen to better fit the final metric on which an end-to-end system is measured, in the style of (Och, 2003).",0,original
"It us widely acknowledged that word sense d~samblguatmn (WSD) us a central problem m natural language processing In order for computers to be able to understand and process natural language beyond simple keyword matching, the problem of d~samblguatmg word sense, or dlscermng the meamng of a word m context, must be effectively dealt with Advances in WSD v, ill have slgmficant Impact on apphcatlons hke information retrieval and machine translation For natural language subtasks hke part-of-speech tagging or s)ntactm parsing, there are relatlvely well defined and agreed-upon cnterm of what it means to have the ""correct"" part of speech or syntactic structure assigned to a word or sentence For instance, the Penn Treebank corpus (Marcus et al, 1993) pro~ide~,t large repo.~tory of texts annotated w~th partof-speech and s}ntactm structure mformatlon Tv.o independent human annotators can achieve a high rate of agreement on assigning part-of-speech tags to words m a g~ven sentence Unfortunately, th~s us not the case for word sense assignment F~rstly, it is rarely the case that any two dictionaries will have the same set of sense defimtmns for a g~ven word Different d~ctlonanes tend to carve up the ""semantic space"" m a different way, so to speak Secondly, the hst of senses for a word m a typical dmtmnar~ tend to be rather refined and comprehensive This is especmlly so for the commonly used words which have a large number of senses The sense dustmctmn between the different senses for a commonly used word m a d~ctmnary hke WoRDNET (Miller, 1990) tend to be rather fine Hence, two human annotators may genuinely dusagree m their sense assignment to a word m context The agreement rate between human annotators on word sense assignment us an Important concern for the evaluatmn of WSD algorithms One would prefer to define a dusamblguatlon task for which there us reasonably hlgh agreement between human annotators The agreement rate between human annotators will then form the upper ceiling against whmh to compare the performance of WSD algorithms For instance, the SENSEVAL exerclse has performed a detaded study to find out the raterannotator agreement among ~ts lexicographers taggrog the word senses (Kllgamff, 1998c, Kllgarnff, 1998a, Kflgarrlff, 1998b) 2 A Case Study In this-paper, we examine the ~ssue of raterannotator agreement by comparing the agreement rate of human annotators on a large sense-tagged corpus of more than 30,000 instances of the most frequently occurring nouns and verbs of Enghsh This corpus is the intersection of the WORDNET Semcor corpus (Miller et al, 1993) and the DSO corpus (Ng and Lee, 1996, Ng, 1997), which has been independently tagged wlth the refined senses of WORDNET by two separate groups of human annotators The Semcor corpus us a subset of the Brown corpus tagged with ~VoRDNET senses, and consists of more than 670,000 words from 352 text files Sense taggmg was done on the content words (nouns, ~erbs, adjectives and adverbs) m this subset The DSO corpus consists of sentences drawn from the Brown corpus and the Wall Street Journal For each word w from a hst of 191 frequently occurring words of Enghsh (121 nouns and 70 verbs), sentences containing w (m singular or plural form, and m its various reflectional verb form) are selected and each word occurrence w ~s tagged w~th a sense from WoRDNET There ~s a total of about 192,800 sentences in the DSO corpus m which one word occurrence has been sense-tagged m each sentence The intersection of the Semcor corpus and the DSO corpus thus consists of Brown corpus sentences m which a word occurrence w is sense-tagged m each sentence, where w Is one of.the 191 frequently oc-,currmg English nouns or verbs Since this common pomon has been sense-tagged by two independent groups of human annotators, ~t serves as our data set for investigating inter-annotator agreement in this paper 3 Sentence Matching To determine the extent of inter-annotator agreement, the first step ~s to match each sentence m Semcor to its corresponding counterpart In the DSO corpus This step ~s comphcated by the following factors 1 Although the intersected portion of both corpora came from Brown corpus, they adopted different tokemzatmn convention, and segmentartan into sentences differed sometimes 2 The latest versmn of Semcor makes use of the senses from WORDNET 1 6, whereas the senses used m the DSO corpus were from WoRDNET 15 1 To match the sentences, we first converted the senses m the DSO corpus to those of WORDNET 1 6 We ignored all sentences m the DSO corpus m which a word is tagged with sense 0 or -1 (A word is tagged with sense 0 or -1 ff none of the given senses m WoRDNFT applies ) 4, sentence from Semcor is considered to match one from the DSO corpus ff both sentences are exactl) ldent~cal or ff the~ differ only m the pre~ence or absence of the characters "" (permd) or -' (hyphen) For each remaining Semcor sentence, taking into account word ordering, ff 75% or more of the words m the sentence match those in a DSO corpus sentence, then a potential match ~s recorded These i -kctua\[ly, the WORD~q'ET senses used m the DSO corpus were from a shght variant of the official WORDNE'I 1 5 release Th~s ssas brought to our attention after the pubhc release of the DSO corpus potential matches are then manually verffied to ensure that they are true matches and to ~eed out any false matches Using this method of matching, a total of 13,188 sentence-palrs contasnmg nouns and 17,127 sentence-pa~rs containing verbs are found to match from both corpora, ymldmg 30,315 sentences which form the intersected corpus used m our present study 4 The Kappa Statistic Suppose there are N sentences m our corpus where each sentence contains the word w Assume that w has M senses Let 4 be the number of sentences which are assigned identical sense b~ two human annotators Then a simple measure to quantify the agreement rate between two human annotators Is Pc, where Pc, = A/N The drawback of this simple measure is that it does not take into account chance agreement between two annotators The Kappa statistic a (Cohen, 1960) is a better measure of rater-annotator agreement which takes into account the effect of chance agreement It has been used recently w~thm computatmnal hngu~stlcs to measure raterannotator agreement (Bruce and Wmbe, 1998, Carletta, 1996, Veroms, 1998) Let Cj be the sum of the number of sentences which have been assigned sense 3 by annotator 1 and the number of sentences whmh have been assigned sense 3 by annotator 2 Then P~-P~ 1-P~ where M j=l and Pe measures the chance agreement between two annotators A Kappa ~alue of 0 indicates that the agreement is purely due to chance agreement, whereas a Kappa ~alue of 1 indicates perfect agreement A Kappa ~alue of 0 8 and above is considered as mdmatmg good agreement (Carletta, 1996) Table 1 summarizes the inter-annotator agreement on the mtersected corpus The first (becond) row denotes agreement on the nouns (xerbs), wh~le the lass row denotes agreement on all words combined The a~erage ~ reported m the table is a s~mpie average of the individual ~ value of each word The agreement rate on the 30,315 sentences as measured by P= is 57% This tallies with the figure reported ~n our earlier paper (Ng and Lee, 1996) where we performed a quick test on a subset of 5,317 sentences,n the intersection of both the Semcor corpus and the DSO corpus 10 \[\] mm m m m m m mm m m m m mm m m m Type Num of v, ords A N \[ P~ Avg Nouns 121 7,676 13,188 I 0 582 0 300 Verbs 70 9,520 17,127 I 0 555 0 347 All I 191 I 17,196 30,315 I 056T 0317 Table 1 Raw inter-annotator agreement 5 Algorithm Since the rater-annotator agreement on the intersected corpus is not high, we would like to find out how the agreement rate would be affected if different sense classes were in use In this section, we present a greedy search algorithm that can automatmalb derive coarser sense classes based on the sense tags assigned by two human annotators The resulting derived coarse sense classes achmve a higher agreement rate but we still maintain as many of the original sense classes as possible The algorithm is given m Figure 1 The algorithm operates on a set of sentences where each sentence contains an occurrence of the word w whmh has been sense-tagged by two human annotators At each Iteration of the algorithm, tt finds the pair of sense classes Ct and Cj such that merging these two sense classes results in the highest t~ value for the resulting merged group of sense classes It then proceeds to merge Cz and C~ Thin process Is repeated until the ~ value reaches a satisfactory value ~,~t,~, which we set as 0 8 Note that this algorithm is also applicable to deriving any coarser set of classes from a refined set for any NLP tasks in which prior human agreement rate may not be high enough Such NLP tasks could be discourse tagging, speech-act categorization, etc 6 Results For each word w from the list of 121 nouns and 70 verbs, ~e applied the greedy search algorithm to each set of sentences in the intersected corpus contaming w For a subset of 95 words (53 nouns and 42 verbs), the algorithm was able to derive a coarser set of 2 or more senses for each of these 95 words such that the resulting Kappa ~alue reaches 0 8 or higher For the other 96 words, m order for the Kappa value to reach 0 8 or higher, the algorithm collapses all senses of the ~ord to a single (trivial) class Table 2 and 3 summarizes the results for the set of 53 nouns and 42 ~erbs, respectively Table 2 md~cates that before the collapse of sense classes, these 53 nouns have an average of 7 6 senses per noun There is a total of 5,339 sentences in the intersected corpus containing these nouns, of which 3,387 sentences were assigned the same sense by the two groups of human annotators The average Kappa statistic (computed as a simple average of the Kappa statistic of ~he mdlwdual nouns) is 0 463 After the collapse of sense classes by the greedy search algorithm, the average number of senses per noun for these 53 nouns drops to 40 Howe~er, the number of sentences which have been asmgned the same coarse sense by the annotators increases to 5,033 That is, about 94 3% of the sentences have been assigned the same coarse sense, and that the average Kappa statistic has improved to 0 862, mgmfymg high rater-annotator agreement on the derived coarse senses Table3 gl~es the analogous figures for the 42 verbs, agmn mdmatmg that high agreement is achieved on the coarse sense classes den~ed for verbs 7 Discussion Our findings on rater-annotator agreement for word sense tagging indicate that for average language users, it is quite dl~cult to achieve high agreement when they are asked to assign refned sense tags (such as those found in WORDNET) given only the scanty definition entries m the WORDNET dlctionary and a few or no example sentences for the usage of each word sense Thin observation agrees wlth that obtmned m a recent study done by (Veroms, 1998), where the agreement on sense-tagging by naive users was also not hlgh Thus It appears that an average language user is able to process language wlthout needing to perform the task of dlsamblguatmg word sense to a very fine-grained resolutmn as formulated m a tradltlonal dmtlonary In contrast, expert lexicographers tagged the ~ ord sense in the sentences used m the SENSEVAL exerclse, where high rater-annotator agreement was reported There are also fuller dlctlonary entries m the HECTOR dlctlonary used and more e<amples showing the usage of each word sense m HECTOR These factors are likely to have contributed to the difference in rater-annotator agreement observed m the three studies conducted We also examined the coarse sense classes derived by the greedy search algorithm Vv'e found some interesting groupings of coarse senses for nouns which ~e hst in Table 4 From Table 4, it is apparent that the greedy search algorithm can derive interesting groupings of word senses that correspond to human mtmtwe judgment of sense graz}.ulanty It Is clear that some of the disagreement between the two groups of human annotators can be attributed solely to the overly refined senses of WoRDNET As an example, there is a total Ii loop: let Ct,, C M denote the current M sense classes ~* +--oo for all z,3 such that 1 <, < 3 < M let C\[,,C~w_ 1 denote the resulting M 1 sense classes by mergmg C, and C 3 compute ~(C\[,, C~/_t) ff ~(C,, C~4_x) > ~* then ~"" +~(C~,,C~_t), z* +~, ~* +end for merge the sense class C,.",0,original
"6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008).",0,original
"A number of knowledge-rich \[Jacobs and Rau, 1990, Calzolari and Bindi, 1990, Mauldin, 1991\] and knowledge-poor \[Brown et al. , 1992, Hindle, 1990, Ruge, 1991, Grefenstette, 1992\] methods have been proposed for recognizing when words are similar.",0,original
"The definition of 2(x, h, m, c) is:  dir  cpos(xh)  cpos(xm)  cpos(xc)  dir  cpos(xh)  cpos(xc)  dir  cpos(xm)  cpos(xc)  dir  form(xh)  form(xc)  dir  form(xm)  form(xc)  dir  cpos(xh)  form(xc)  dir  cpos(xm)  form(xc)  dir  form(xh)  cpos(xc)  dir  form(xm)  cpos(xc) 3 Experiments and Results We report experiments with higher-order models for the ten languages in the multilingual track of the CoNLL-2007 shared task (Nivre et al. , 2007).1 In all experiments, we trained our models using the averaged perceptron (Freund and Schapire, 1999), following the extension of Collins (2002) for structured prediction problems.",0,original
"The separation of these two requirements 7 A more precise account of what it means to be able to identify an object is beyond the scope of this paper; for further details, see the discussions by Hobbs (1985), Appelt (1985), Kronfeld (1986, 1990), and Morgenstern (1988).",0,original
(2007) and Smith and Smith (2007) showed that the MatrixTree Theorem can be used to train edge-factored log-linearmodelsofdependencyparsing.,0,original
"For instance, the resulting word graph can be used in the prediction engine of a CAT system (Och et al. , 2003).",0,original
recent advances in parsing technology are due to the explicit stochastic modeling of dependency information (Collins 1997).,0,original
"For example, the entry about the Microsoft in Wikipedia has the following categories: Companies listed on NASDAQ; Cloud computing vendors; etc. Both (Toral and Munoz, 2006) and (Kazama and Torisawa, 2007a) used the free-text description of the Wikipedia entity to reason about the entity type.",0,original
"The Duluth Word Alignment System is a Perl implementation of IBM Model 2 (Brown et al. , 1993).",0,original
"For example, the feature 1 On the ATR English Grammar, see below; for a detailed description of a precursor to the Gr-r~raar, see (Black et al. , 1993a).",0,original
"A statistical language model  a lexicalized PCFG (similar to that of Collins, 1997)  is derived from the analysis grammar by processing a corpus using the same grammar with no statistical model and recording frequencies of substructures built by each rule.",0,original
"They have been successfully applied in several tasks, such as information retrieval (Salton et al., 1975) and harvesting thesauri (Lin, 1998).",0,original
"Experiments are presented in table 1, using BLEU (Papineni et al., 2001) and METEOR5 (Banerjee and Lavie, 2005), and we also show the length ratio (ratio of hypothesized tokens to reference tokens).",0,original
"Online learning algorithms have been shown to be robust even with approximate rather than exact inference in problems such as word alignment (Moore, 2005), sequence analysis (Daume and Marcu, 2005; McDonald et al. , 2005a) and phrase-structure parsing (Collins and Roark, 2004).",0,original
"This results in two forbidden alignment structures, shown in Figure 1, called inside-out transpositions in (Wu, 1997).",0,original
"Speaker ranking accuracy Table 2 summarizes the accuracy of our statistical ranker on the test data with different feature sets: the performance is 89.39% when using all feature sets, and reaches 90.2% after applying Gaussian smoothing and using incremental feature selection as described in (Berger et al. , 1996) and implemented in the yasmetFS package.6 Note that restricting ourselves to only backward looking features decreases the performance significantly, as we can see in Table 2.",0,original
"Joint parsing with a simplest synchronous context-free grammar (Wu, 1997) is O(n6) as opposed to the monolingual O(n3) time.",0,original
External information such as the discourse or domain dependency of each word sense (Guthrie et al. 1991; Nasukawa 1993; Yarowsky 1995) is expected to lead to system improvement.,0,original
"test additional resources JESS-CM (CRF/HMM) 94.48 89.92 1G-word unlabeled data 93.66 89.36 37M-word unlabeled data (Ando and Zhang, 2005) 93.15 89.31 27M-word unlabeled data (Florian et al., 2003) 93.87 88.76 own large gazetteers, 2M-word labeled data (Suzuki et al., 2007) N/A 88.41 27M-word unlabeled data [sup.",0,original
"As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et aL, 1993).",0,original
"Oncetraininghastakenplace,minimumerrorrate training (Och, 2003) is used to tune the parameters i. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores (Chiang, 2007).",0,original
"For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words (Hindle, 1990; Pereira et al. , 1993; Grefenstette, 1994; Lin, 1998).",0,original
"3.2 Results and Discussion The BLEU scores (Papineni et al. , 2002) for 10 direct translations and 4 sets of heuristic selections 4Admittedly, in typical instances of such chains, English would appear earlier.",0,original
"No pretagged text is necessary for Hidden Markov Models (Jelinek, 1985; Cutting et al. , 1991; Kupiec, 1992).",0,original
"al. 2003b) 147 is (B)eginning, (I)nside or (O)utside of a chunk (Ramshaw & Marcus, 1995).",0,original
3.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus's base NP chunker [Ramshaw and Marcus (1995)].,0,original
"So fitr, we have implemented the following,: sentence ~dignment btLsed-on word correspondence information, word correspondence estimation by cooccnl'rence-ffequency-based methods in GMe mid Church (19.~H) and Kay and R6scheisen (1993), structured Imttehlng of parallel sentences (Matsumoto et a l. , 1993), and case Dame acquisition of Japanese verbs (Utsuro et al. , 1993).",0,original
"(b) MEDLINE DT JJ VBN NNS IN DT NN NNS VBP The oncogenic mutated forms of the ras proteins are RB JJ CC VBP IN JJ NN NN . constitutively active and interfere with normal signal transduction . Figure 1: Part of speech-tagged sentences from both corpora we investigate its use in part of speech (PoS) tagging (Ratnaparkhi, 1996; Toutanova et al. , 2003).",0,original
"Rule-based taggers (Brill 1992; Elenius 1990; Jacobs and Zernik 1988; Karlsson 1990; Karlsson et al. 1991; Voutilainen, Heikkila, and Antitila 1992; Voutilainen and Tapanainen 1993) use POS-dependent constraints defined by experienced linguists.",0,original
"of Linguistics University of Potsdam kuhn@ling.uni-potsdam.de Abstract The empirical adequacy of synchronous context-free grammars of rank two (2-SCFGs) (Satta and Peserico, 2005), used in syntaxbased machine translation systems such as Wu (1997), Zhang et al.",0,original
"Word-aligned corpora have been found to be an excellent source for translation-related knowledge, not only for phrase-based models (Och and Ney, 2004; Koehn et al., 2003), but also for syntax-based models (e.g., (Chiang, 2007; Galley et al., 2006; Shen et al., 2008; Liu et al., 2006)).",0,original
"The judges had an acceptable 0.74 mean  agreement (Carletta, 1996) for the assignment of the primary class, but a meaningless 0.21 for the secondary class (they did not even agree on which lemmata were polysemous).",0,original
"As a result, we can use collocation measures like point-wise mutual information (Church and Hanks, 1989) or the log-likelihood ratio (Dunning, 1993) to predict the strong association for a given cue.",0,original
"One such relational reasoning task is the problem of compound noun interpretation, which has received a great deal of attention in recent years (Girju et al., 2005; Turney, 2006; Butnariu and Veale, 2008).",0,original
"We calculated the translation quality using Bleus modified n-gram precision metric (Papineni et al. , 2002) for n-grams of up to length four.",0,original
"Class-based n-gram models have also been shown to benefit from their reduced number of parameters when scaling to higher-order n-grams (Goodman and Gao, 2000), and even despite the increasing size and decreasing sparsity of language model training corpora (Brants et al., 2007), class-based n-gram models might lead to improvements when increasing the n-gram order.",0,original
In the LFG-based generation algorithm presented by Cahill and van Genabith (2006) complex named entities (i.e. those consisting of more than one word token) and other multi-word units can be fragmented in the surface realization.,0,original
"Probabilistic generative models like IBM 1-5 (Brown et al., 1993), HMM (Vogel et al., 1996), ITG (Wu, 1997), and LEAF (Fraser and Marcu, 2007) define formulas for P(f | e) or P(e, f), with ok-voon ororok sprok at-voon bichat dat erok sprok izok hihok ghirok totat dat arrat vat hilat ok-drubel ok-voon anok plok sprok at-drubel at-voon pippat rrat dat ok-voon anok drok brok jok at-voon krat pippat sat lat wiwok farok izok stok totat jjat quat cat lalok sprok izok jok stok wat dat krat quat cat lalok farok ororok lalok sprok izok enemok wat jjat bichat wat dat vat eneat lalok brok anok plok nok iat lat pippat rrat nnat wiwok nok izok kantok ok-yurp totat nnat quat oloat at-yurp lalok mok nok yorok ghirok clok wat nnat gat mat bat hilat lalok nok crrrok hihok yorok zanzanok wat nnat arrat mat zanzanat lalok rarok nok izok hihok mok wat nnat forat arrat vat gat Figure 1: Word alignment exercise (Knight, 1997).",0,original
"The L1 or L2 norm is commonly used in statistical natural language processing (Gao et al., 2007).",0,original
"In (Thomas et al. , 2006), the authors use the transcripts of debates from the US Congress to automatically classify speeches as supporting or opposing a given topic by taking advantage of the voting records of the speakers.",0,original
"Wu (1997) modeled the reordering process with binary branching trees, where each production could be either in the same or in reverse order going from source to target language.",0,original
"177 Proceedings of EACL '99 IOB1 IOB2 IOE1 IOE2 \[+\] \[+ IO IO +\] (Ramshaw and Marcus, 1995) (Veenstra, 1998) (Argamon et al. , 1998) (Cardie and Pierce, 1998) accuracy 97.58% 96.50% 97.58% 96.77% 97.37% 97.2% precision 92.50% 91.24% 92.41% 91.93% 93.66% 91.47% 91.25% 91.80% 89.0% 91.6 % 90.7% recall F~=I 92.25% 92.37 92.32% 91.78 92.04% 92.23 92.46% 92.20 90.81% 92.22 92.61% 92.04 92.54% 91.89 92.27% 92.03 94.3% 91.6 91.6% 91.6 91.1% 90.9 Table 6: The F~=I scores for the (Ramshaw and Marcus, 1995) test set after training with their training data set.",0,original
"ca (2006) and Cucerzan (2007), in mining relationships between named entities, or in extracting useful facet terms from news articles (e.g., Dakka and Ipeirotis, 2008).",0,original
"c2005 Association for Computational Linguistics Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars Dekai Wu1 Human Language Technology Center HKUST Department of Computer Science University of Science and Technology, Clear Water Bay, Hong Kong dekai@cs.ust.hk Abstract We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wus (1995, 1997) Inversion Transduction Grammar (ITG) hypothesis.",0,original
