Citation_Text,Sentiment,Source
Several recent real-world parsers have improved state-of-the-art parsing accuracy by relying on probabilistic or weighted versions of bilexical grammars  .,1,original
"In a later study, Och and Ney   present a loglinear combination of the HMM and IBM Model 4 that produces better alignments than either of those.",1,original
"In related work  , both supervised and unsupervised approaches have been shown to have their pros and cons.",1,original
"Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging  , spelling correction  , word-sense disambiguation  , message understanding  , discourse tagging  , accent restoration  , prepositional-phrase attachment   and base noun phrase identification  .",1,original
"Inversion transduction grammar  , or ITG, is a wellstudied synchronous grammar formalism.",1,original
The only trainable approaches   to surface generation are the purely statistical machine translation   systems such as   and the corpus-based generation system described in  .,1,original
We report results using the well-known automatic evaluation metrics Bleu  .,1,original
"Statistical techniques developed for lexicalized grammars  , readily apply to CCG to improve the average parsing performance in large-scale practical applications  .",1,original
"For example, polymer based nanoparticles may be prepared by the well-known solvent evaporation method, in which the droplets of a nanoemulsion are composed of a volatile organic solvent in which the polymer is solubilized  .",1,original
We also show that integrating our case prediction model improves the quality of translation according to BLEU  g2 and human evaluation.,1,original
"Thus, as a powerful sequence tagging model, CRF became the dominant method in the Bakeoff 2006  .",1,original
"Emerging results in the field continue to suggest that trimeric, functional forms of recombinant Env might generate more broadly-reactive, neutralizing antibody responses against HIV  .",1,original
"Assuming the well-known Kronecker correlation structure   we can decompose H as H = R 1 2HwS 1 2   where R and S are the receive and transmit correlation matrices respectively, satisfying tr   = Nr and tr   = Nt, and the elements of Hw are i.",1,original
"We decided to use the class of maximum entropy models, which are probabilistically sound, can make use of possibly many overlapping features, and can be trained efficiently  .",1,original
"Discriminative models do not only have theoretical advantages over generative models, as we discuss in Section 2, but they are also shown to be empirically favorable over generative models when features and objective functions are fixed  .",1,original
"2 Related Work Recently, several successful attempts have been made at using supervised machine learning for word alignment  .",1,original
Phrase-based decoding   is a dominant formalism in statistical machine translation.,1,original
"Among these measures, the most important are Wu & Palmers  , Resniks   and Lins  .",1,original
"The maximum entropy model   provides us with a well-founded framework for this purpose, which has been extensively used in natural lan guage processing tasks ranging from part-ofspeech tagging to machine translation.",1,original
"As expected, human multiple sclerosis incidence does correlate with low serum 25-OH-D, the most reliable index of vitamin D status  .",1,original
"For instance, changing the training procedure for word alignment models turned out to be most beneficial; for details see  .",1,original
"Its also worth noting that Collins and Roark   saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.",1,original
"It is the most widely reported metric in MT research, and has been shown to correlate well with human judgment  .",1,original
"3 Parsing Exact inference in ISBN models is not tractable, but effective approximations were proposed in  .",1,original
"First, such a system makes use of lexical information when modeling reordering  , which has previously been shown to be useful in German-to-English translation  .",1,original
"Variants of this method have been successfully used in many NLP tasks, like shallow processing  , parsing   and word alignment  .",1,original
The subjects’ usual diet before diagnosis for cases or hospital admission for controls was estimated through a satisfactorily reproducible   food frequency questionnaire  .,1,original
3.1 A History-Based Model The history-based   approach which incorporates more context information has worked well in parsing  .,1,original
"The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years  .",1,original
"2.2 Statistical Parsers Pioneered by the IBM natural language group   and later pursued by, for example, Schabes, Roth, and Osborne  , Jelinek et al.",1,original
"Eigenvector centrality in particular has been successfully applied to many different types of networks, including hyperlinked web pages  , lexical networks  , and semantic networks  .",1,original
"A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation  .",1,original
As the Arabidopsis leaf Xavonoids are mainly composed of kaempferol and quercetin derivatives   this approach proved suYcient to,1,original
"LSTMs are able to capture past signal behavior and they have shown success in many audio processing applications, such as speech recognition and computational paralinguistics  .",1,original
Many recent approaches in natural language processing   have recognized the need to use unannotated data to improve performance.,1,original
"In order to activate reporter gene expression, we first treated the cells with H2O2/vanadate  , which causes rapid and efficient STAT92E phosphorylation     and is more efficient than transient transfection of hop in activating STAT.",1,original
"‚Ä¶automatically generates layout information encoding node and reaction centroid coordinates using the FruchtermanReingold   algorithm, which has been shown to be robust in the face of variegated graph topologies and faithfully reproduces the underlying symmetry  .",1,original
"The most common advantages expressed in the six most-cited publications are that the flipped classroom approach focusses student-centred and collaborative, problem-based learning activities, thus enabling teachers to spend more time identifying student problems and knowledge gaps  .",1,original
We use a recently proposed dependency parser  1 which has demonstrated state-of-theart performance on a selection of languages from the 1The ISBN parser will be soon made downloadable from the authors web-page.,1,original
4 Extended Minimum Error Rate Training Minimum error rate training   is widely used to optimize feature weights for a linear model  .,1,original
"We train an event model with a binary SVM classifier after the features are selected, and   The state-of-the-art event detection methods.",1,original
"One of the best efforts to quantify the performance of a term-recognition system   does so only for one processing stage, leaving unassessed the text-to-output performance of the system.",1,original
"3 Perceptron Reranking As Collins   observes, perceptron training involves a simple, on-line algorithm, with few iterations typically required to achieve good performance.",1,original
Averaging has been shown to reduce overfitting   as well as reliance on the order of the examples during training.,1,original
Ramshaw and Marcus   successflflly applied Eric Brill's transformation-based learning method to the chunking problem.,1,original
"By default, the log-likelihood ratio measure   is proposed, since it was shown to be particularly suited to language data  .",1,original
"In contrast to existing approaches  , the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment.",1,original
"4.4.1 N-gram Co-Occurrence Statistics for Answer Extraction N-gram co-occurrence statistics have been successfully used in automatic evaluation  , and more recently as training criteria in statistical machine translation  .",1,original
"The conceptually simplest approach to this latter problem is probably Turneys  , who has obtained interesting results on Task 2 by considering the algebraic sum of the orientations of terms as representative of the orientation of the document they belong to; but more sophisticated approaches arealsopossible  .",1,original
"In order to overcome this, some unsupervised learning methods and minimally-supervised methods, e.g.,  , have been proposed.",1,original
"Because of its high spatial resolution and applicability to air-filled structures, CT is a good alternative for guiding RFA, which cannot be adequately guided by US  .",1,original
"The former term P  is called a language model, representing the likelihood of E. The latter term P  is called a translation model, representing the generation probability from E into J. As an implementation of P , the word alignment based statistical translation   has been successfully applied to similar language pairs, such as FrenchEnglish and German English, but not to drastically dierent ones, such as JapaneseEnglish.",1,original
"Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score  , using a phrase-based system   which has been shown in the past to be a highly competitive SMT system.",1,original
"Recently, 3D-CNNs have been widely used for various 3D data analysis tasks such as 3D detection or classification  .",1,original
"1 Introduction Since 1995, a few statistical parsing algorithms   demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard.",1,original
"ROUGE-L, ROUGE-W, and ROUGE-S have also been applied in automatic evaluation of summarization and achieved very promising results  .",1,original
This algorithm is referred to as GHKM   and is widely used in SSMT systems  .,1,original
"The NLST trial was conducted among high-risk individuals of old age and heavy smokers, and demonstrated positive results  .",1,original
urneys   work is perhaps one of the most notable examples of unsupervised polarity classification,1,original
"3.2 Evaluation Criteria Well-established objective evaluation measures like the word error rate  , positionindependent word error rate  , and the BLEU score   were used to assess the translation quality.",1,original
"The approach has been shown to give improvements over the MAP classifier in many areas of natural language processing including automatic speech recognition  , machine translation  , bilingual word alignment  , andparsing .",1,original
"By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences  .",1,original
The most commonly used MT evaluation metric in recent years has been IBMs Bleu metric  .,1,original
"This is possible because the generation time is shorter, the genetic material can be manipulated easily and the cultural conditions can be optimized easily  .",1,original
East Asian H. pylori strains possess a D motif within CagA in place of the western C motif and this has been shown to be a potent inducer of SHP-2 phosphatase  .,1,original
mith and Smith   describe a more efficient algorithm that can compute all edge expectations in O  time using the inverse of the Kirchoff matrix K1,1,original
"Recently, sentiment classification has become popular because of its wide applications  .",1,original
"In machine translation, confusion-network based combination techniques  ) have achieved the state-of-theart performance in MT evaluations.",1,original
"In particular, the use of SVMs in   initially sparked interest in using machine learning methods for sentiment classi cation.",1,original
"  showed that, for this choice of joint feature vector, loss-augmented inference can be performed optimally using an efficient greedy algorithm.",1,original
"As discussed in  , computing the conditional probabilities which we need for parsing is in general intractable with ISBNs, but they can be approximated efficiently in several ways.",1,original
The fluency models hold promise for actual improvements in machine translation output quality  .,1,original
Every sentence was part-of-speech tagged using a maximum entropy tagger   and parsed using a state-of-the-art wide coverage phrase structure parser  .,1,original
"A recent study in northern Vietnam, in which researchers used participatory methods when introducing an educational programme for community health leaders, demonstrated promising results in learning capacity, and the health leaders expressed enthusiasm for this mode of gaining knowledge  .",1,original
"As has been previously observed and exploited in the NLP literature  , the above optimization function, unlike many others that have been proposed for graph or set partitioning, can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs.",1,original
The recent development of HLA class II   and CD1d tetramers   makes the additional monitoring of CD4+ and NKT cells feasible.,1,original
"Collins   improves the F1 score from 88.2% to 89.7%, while Charniak and Johnson   improve from 90.3% to 91.4%.",1,original
"Recently, we can see an important development in natural language processing and computational linguistics towards the use of empirical learning methods  ).",1,original
1 Motivation A major component in phrase-based statistical Machine translation     is the table of conditional probabilities of phrase translation pairs.,1,original
"In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations   because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently.",1,original
The validated Malay version of GAD-7 which was found to have good sensitivity and specificity was used in this study  .,1,original
"5 External Knowledge Sources 5.1 Lexical Dependencies Features derived from n-grams of words and tags in the immediate vicinity of the word being tagged have underpinned the world of POS tagging for many years  , and have proven to be useful features in WSD  .",1,original
"Currently, machine learning methods   and combinations of classifiers   have been popular.",1,original
"tems in  , with the best results so far obtained by the deterministic sieve system of Lee at al.",1,original
Conditional Markov models     have been successfully used in sequence labeling tasks incorporating rich feature sets.,1,original
That AONs are a promising therapeutic tool was recently shown in phase I and phase I/II clinical trials in DMD  .,1,original
"Whereas dependency based semantic spaces have been shown to surpass other word space models for a number of problems  , for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better  .",1,original
"Furthermore, we combined learning rate annealing with embedding batch normalization, the latter of which has been proven to help the model train faster and allow faster learning  .",1,original
"4.1 Complete ambiguity classes Ambiguity classes capture the relevant property we are interested in: words with the same category possibilities are grouped together.4 And ambiguity classes have been shown to be successfully employed, in a variety of ways, to improve POS tagging  .",1,original
"In order to fulfill this point the most popular technic is the replication in different providers  , however this process generates a waste of storage resources when the system makes unnecessary replicas.",1,original
"Still, the general notion that interference is mainly due to cue overload at the time of retrieval lived on, despite the fact that multiple efforts to demonstrate that cue-overload effects apply to everyday forgetting   generally suggested just the opposite  . In fact, the only reason to believe that cue-overload effects play any role at all in everyday forgetting is that almost everyone can point to a few examples from their own lives where it surely does. But the mere fact that cue-overload effects sometimes play a role does not mean that the role is a substantial one. Summarizing the state of the art late in his career, Underwood   said: ‘‘A relatively few years ago it seemed that a fairly comprehensive theoretical account of forgetting was close at hand,",1,original
"The particles, or signals, are well known   in cellular automata   where iterated parallel processing of strings occurs.",1,original
"Recent work   has demonstrated that randomized encodings can be used to represent n-gram counts for LMs with signficant space-savings, circumventing information-theoretic constraints on lossless data structures by allowing errors with some small probability.",1,original
"The Logllkelihood Ratio, G 2, is a mathematically well-grounded and accurate method for calculating how """"surprising"""" an event is  .",1,original
"The results show that, as compared to BLEU, several recently proposed metrics such as Semantic-role overlap  , ParaEval-recall  , and METEOR   achieve higher correlation.",1,original
"We next identified well-characterized Saccharomyces cerevisiae polarity genes BNI1, BUD3, BUD6 and SPA2  .",1,original
"Lexicalized PCFGs use the structural features on the lexical head of phrasal node in a tree, and get significant improvements for parsing  .",1,original
Section 4 describes the online training procedure and compares it to the well known perceptron training algorithm  .,1,original
"Standard sequence prediction models are highly effective for supertagging, including Hidden Markov Models  , Maximum Entropy Markov Models  , and Conditional Random Fields  .",1,original
"To improve the unknown word model, featurebased approach such as the maximum entropy method   might be useful, because we don't have to divide the training data into several disjoint sets   and we can incorporate more linguistic and morphological knowledge into the same probabilistic framework.",1,original
"The goal of integrating syntactic information into the translation model has prompted many researchers to pursue tree-based transfer models  , with increasingly encouraging results.",1,original
The most frequently used resource for synonym extraction is large monolingual corpora  .,1,original
"Hunter take rates Hunter take   is a widely applied method for assessing relative abundance of wildlife, including wild swine  .",1,original
"In an attempt to overcome this limitation, Achenbach, Dumenici, and Rescorla   developed a new scoring system based on consensus between clinicians that allows better correspondence between the vastly adopted CBCL scales and the currently employed DSM-IV diagnostic criteria.",1,original
Another study has shown a proof of concept closed-loop model using direct pressure monitoring as the feedback signal  .,1,original
1 Introduction There has been a great deal of progress in statistical parsing in the past decade  .,1,original
"  used bootstrapping to train decision list classifiers to disambiguate between two senses of a word, achieving impressive classification accuracy.",1,original
"Similarly, Structural Correspondence Learning   has proven to be successful for the two tasks examined, PoS tagging and Sentiment Classification.",1,original
Bhattacharjee & Ghosh   discussed about probable construction management courses where role-playing teaching could be adopted as a successful pedagogical approach.,1,original
"However, Moores Law, the driving force of change in computing since then, has opened the way for recent progress in the field, such as Statistical Machine Translation    .",1,original
One promising approach extends standard Statistical Machine Translation   techniques   to the problems of monolingual paraphrase identification and generation.,1,original
"…role in many NLP applications, deterministic models based on rich sets of expert rules for coreference have been shown recently to achieve performance rivaling, if not exceeding, the performance of state of the art machine learning approaches  .",1,original
"Some local features by combining of LBP and Gabor feature have been proposed  , which can achieve better recognition performance than either feature alone.",1,original
"A video version of this idea has been explored as well  , with varying degrees of success.",1,original
"The state-of-the art taggers are using feature sets discribed in the corresponding articles  ,  ,   and  ), Morce supervised and Morce semi-supervised are using feature set desribed in section 4.",1,original
"Moreover, log likelihood ratios are regarded as a more effective method to identify collocations especially when the occurrence count is very low  .",1,original
Reconstructive surgery by autologous tissue transfer is well established and may provide good functional results  .,1,original
1 Introduction The most widely used alignment model is IBM Model 4  .,1,original
"goal lines, which were extensions of the halfway line or penalty area approximately 3–30 m from each line) because multiple perpendicular views were recommended to obtain more accurate results using the MBIM technique  .",1,original
"As in previous studies, injury severity was stratified using the discharge diagnosis ICD-9ebased ICISS scoring system, which has been shown to outperform other scoring systems in predicting injury mortality and is particularly suited for the study of administrative databases.  The definition of severely injured patients was chosen to match that in several preceding studies that focused on the survival advantage of severely injured patients treated at DTCs in Florida.",1,original
"We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM   and HMMs trained with soft constraints  .",1,original
"However, the best performing statistical approaches to lexical ambiguity resolution l;lmmselves rely on complex infornmtion sources such as """"lemmas, inflected forms, parts of speech and arbitrary word classes If\] local and distant collocations, trigram sequences, a.nd predicate m'gument association""""  , p. 190) or large context-windows up to 1000 neighboring words  .",1,original
"…automatically generates layout information encoding node and reaction centroid coordinates using the FruchtermanReingold   algorithm, which has been shown to be robust in the face of variegated graph topologies and faithfully reproduces the underlying symmetry  .",1,original
These advantages of using waveguides enable synchronized concurrent accesses of an optical bus in a pipelined fashion  .,1,original
1 Introduction The availability of large amounts of so-called parallel texts has motivated the application of statistical techniques to the problem of machine translation starting with the seminal work at IBM in the early 90s  .,1,original
"Combining more video clips improves the accuracy of the estimated data  , and previous research also succeeded in motion reconstruction using somewhat blurry images  .",1,original
"One major resource for corpus-based research is the treebanks available in many research organizations \ , which carry skeletal syntactic structures or 'brackets' that have been manually verified.",1,original
"Annotated reference corpora, such as the Brown Corpus  , the Penn Treebank  , and the BNC  , have helped both the development of English computational linguistics tools and English corpus linguistics.",1,original
5.3 Comparison with System Combination We re-implemented a state-of-the-art system combination method  .,1,original
"Besides the most popular datasets  , we also considered some larger datasets (e.",1,original
"3 System Overview 3.1 Translation model The system developed for this years shared task is a state-of-the-art, two-pass phrase-based statistical machine translation system based on a log-linear translation model  .",1,original
"They are central to many parsing models  , and despite their simplicity n-gram models have been very successful.",1,original
The superior bonding effectiveness shown in vitro  .,1,original
4 Evaluation The purpose of our evaluation is to contrast our proposed feature based approach with a state-ofthe-art sequential learning technique  .,1,original
"Currently, high-throughput methods to screen high-producer cells have been developed  .",1,original
Table 1: Datasets 3.3 Establishing a Baseline for a Corpus-based System   Supervised statistical methods have been very successful in sentiment tagging of texts: on movie review texts they reach accuracies of 85-90%  .,1,original
"Besides saving cost, the ability to dependably work with a single human translation has an additional advantage: it is now possible to create Recall-based evaluation measures for MT, which has been problematic for evaluation with multiple reference translations, since only one of the choices from the reference set is used in translation  .",1,original
The best result known to us is achieved by Toutanova .,1,original
"Fortunately, the convertibility rule happens to be implemented quite efficiently in Coq  , so it becomes possible to automatically prove some propositions on real numbers by simply evaluating programs.",1,original
The PSO algorithm provides good results using population size between 20 and 100  .,1,original
Data on the occurrence of the principal mycotoxins on foods and beverages are increasing due to the availability and use of modern and sensitive LC–MS/MS and GC–MS/MS methodologies suitable for simultaneous determination of mycotoxins  .,1,original
486 One of the most popular instantiations of loglinear models is that including phrase-based   models  .,1,original
The maximum entropy approach   is known to be well suited to solve the classification problem.,1,original
1 Introduction Parallel corpora have been shown to provide an extremely rich source of constraints for statistical analysis  .,1,original
…    or enteric polymers such as hydroxypropyl methylcellulose phthalate     and hydroxypropyl methylcellulose acetate succinate     have demonstrated use…,1,original
"There are basically two kinds of systems working at these segmentation levels: the most widespread rely on statistical models, in particular the IBM ones  ; others combine simpler association measures with different kinds of linguistic information  .",1,original
"Queuing networks is one of the most used tools to model Discrete Event Dynamic System  , Cassandras and Lafortune  , useful to model realities like communication networks or manufacturing systems.",1,original
"For example, it is well known that translation-invariant undecimated wavelets   are a dramatically more effective domain than the basic fully decimated orthogonal   wavelets for denoised a signal by shrinkage; the realization of",1,original
5.2 Maximum Entropy Maximum entropy classiflcation   is an alternative technique which has proven efiective in a number of natural language processing applications  .,1,original
"For instance,   shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks.",1,original
"Furthermore, risk-factor awareness among patients with lower-limb ischemia is suboptimal, and one benefit of a NLC is the opportunity to educate patients.  Indeed, our results show significant benefits of a protocol-based NLC for claudicants with a 25% relative risk reduction of predicted 10-year coronary events over a 3-month period.",1,original
"2.1 Local Feature Descriptors Local feature descriptors   have been extensively studied, especially since the seminal works by Schmid and Mohr   and Lowe  .",1,original
"2.2 Perceptron-based training To tune the parameters w of the model, we use the averaged perceptron algorithm   because of its efficiency and past success on various NLP tasks  .",1,original
Many aspects of successful programs are being tackled through studies ranging from social acceptance and carbon accounting to silvicultural management strategies  .,1,original
Selection of mRNA target sites and siRNA sequences that are free from stable secondary self-structures helps produce better results in siRNA design  .,1,original
"Perhaps the most widely accepted convention is that of ignoring punctuation for the purposes of assigning constituent span, under the perspective that, fun788 Phrase Evaluation Scenario System Type       Modified All 98.37 99.72 99.72 Truth VP 92.14 98.70 98.70 Li and Roth All 94.64   VP 95.28 Collins   All 92.16 93.42 94.28 VP 88.15 94.31 94.42 Charniak All 93.88 95.15 95.32   VP 88.92 95.11 95.19 Table 1: F-measure shallow bracketing accuracy under three different evaluation scenarios:   baseline, used in Li and Roth  , with original chunklink script converting treebank trees and context-free parser output;   same as  , except that empty subject NPs are inserted into every unary SVP production; and   same as  , except that punctuation is ignored for setting constituent span.",1,original
Another kind of popular approaches to dealing with query translation based on corpus-based techniques uses a parallel corpus containing aligned sentences whose translation pairs are corresponding to each other  .,1,original
"In the area of statistical machine translation  , recently a combination of the BLEU evaluation metric   and the bootstrap method for statistical significance testing   has become popular  .",1,original
We use the popular online learning algorithm of structured perceptron with parameter averaging  .,1,original
illmann and Zhang   avoided the problem by precomputing the oracle translations in advance,1,original
We note that better performance has been reported with the use of more image features  .,1,original
One of the most promising methods among them is PLDA  .,1,original
"For comparison purposes, three additional heuristically-induced alignments are generated for each system:   Intersection of both directions  );   Union of both directions  ); and   The previously bestknown heuristic combination approach called growdiag-final    ).",1,original
"Target language model probability   According to a previous study, the minimum error rate training    , which is the optimization of feature weights by maximizing the BLEU score on the development set, can improve the performance of a system.",1,original
"Compared with clean parallel corpora such as """"Hansard""""  , which consists of 505 French-English translations of political debates in the Canadian parliament, texts from the web are far more diverse and noisy.",1,original
"Regarding synthetic inhibitors, PC190723 is the most studied compound so far  .",1,original
The last fragment has also been widely used to elucidate phylogenetic relationships among taxa from several plant families  .,1,original
"In addition to tf.idf scores, Hulth   uses part-of-speech tags and NP chunks and complements this with machine learning; the latter has been used to good results in similar cases  .",1,original
iero Search Refinements Huang and Chiang   offer several refinements to cube pruning to improve translation speed,1,original
"As stated earlier, GABAB  and GABAB  are the most abundantly expressed variants of the GABAB  subunit  , both of which form functional heterodimers with the GABAB  subunit  .",1,original
"First, several of the best-performing parsers on the WSJ treebank   are cases of history-based models.",1,original
"For the multilingual dependency parsing track, which was the other track of the shared task, Nilsson et al. achieved the best performance using an ensemble method  .",1,original
A pioneer work in online training is the perceptron-like algorithm used in training a hidden Markov model    .,1,original
"To compare the output of their shallow parser with the output of the well-known Collins   parser, Li and Roth applied the chunklink conversion script to extract the shallow constituents from the output of the Collins parser on WSJ section 00.",1,original
"As discussed above, all state-of-the-art published methods rely on lexical features for such tasks  .",1,original
"In our experiments, we have used Averaged Perceptron   and Perceptron with margin   to improve performance.",1,original
Among the most widely studied is the Gibbs distribution  .,1,original
"The CSC for the visual acuity < 3/60 was 35% in the 1981 NBS  , Also, the implantation of intraocular lenses in cataract surgery has resulted in better visual outcomes.",1,original
"using the Reading Span  , one of the most widely used paradigms for the evaluation of selective attention; Abstraction and conceptual flexibility   were assessed by means of the modified Wisconsin Card Sorting Test (number categories and perseverative",1,original
"1 Introduction Several efficient, accurate and robust approaches to data-driven dependency parsing have been proposed recently   for syntactic analysis of natural language using bilexical dependency relations  .",1,original
"We use two state-of-the-art POS taggersa maximum entropy based English POS tagger  , and an HMM based Chinese POS tagger.",1,original
  reported improved model performance to predict the presence of prairie fish species if information on reach and catchment scale are combined.,1,original
  showed that the results for French-English were competitive to state-of-the-art alignment systems.,1,original
"For example, factored translation models   retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features.",1,original
"PBN is widely used for ROS scavenging, and most importantly, has been shown to reverse the age-related oxidative changes and to reduce oxidative damage from ischemia/reperfusion injury.  The antioxidant activity of PBN protects biologically important molecules from oxidative damage.",1,original
"On the other hand, MPCCs metabolized low turnover drugs   significantly faster in the serum-free medium than in vivo, and thus use of reported fu values significantly improved the accuracy of clearance predictions, as also observed previously  .",1,original
"In state of the art schemes  , a warrant ω is either the concatenation of all permitted messages or an abstract description of the message space for which signing is being delegated, together with a certificate, which is a signature on ω  , under the delegator’s private signing key.",1,original
Log-likelihood ratio The log-likelihood ratio statistic has been found to be accurate for modeling the associations between rare events  .,1,original
One of the remarkable results of the application of the solubilization at 4 C with nonionic detergents of the erythrocyte membrane is the almost complete exclusion of band 3 protein from the DRMs  .,1,original
Consequences for Computational Modelling The Incremental Algorithm   is considered most successful in producing human-like referring expressions.,1,original
"In our experiments, we used the Averaged Perceptron algorithm of Freund and Schapire  , a variation that has been shown to be more effective than the standard algorithm  .",1,original
"2.1 Log-Linear Models The log-linear model  , or also known as maximum-entropy model  , is a linear classifier widely used in the NLP literature.",1,original
"3.2 Comparison between SVM, Bootstrapping and LP For WSD, SVM is one of the state of the art supervised learning algorithms  , while bootstrapping is one of the state of the art semi-supervised learning algorithms  .",1,original
"In Statistical Machine Translation  , recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories  .",1,original
"Optimization Metrics When sampling phrase sets for text entry experiments, memorability and representativeness are two metrics that have been widely adopted by researchers  .",1,original
"Corpus-based or example-based MT   and statistical MT   systems provide the easiest customizability, since users have only to supply a collection of source and target sentence pairs  .",1,original
"Sunitinib is one of several agents, including sorafenib, bevacizumab, and temsirolimus, which target the inhibition of pro-angiogenic growth factor activity and have shown favorable results in clinical trials against metastatic clear-cell RCC  .",1,original
"The power of ConSurf, in comparison to other popular alternatives based on consensus and relative entropy approaches, is that the evolutionary rates are estimated based on the phylogenetic relationships among the homologues and the specific dynamics of the analysed sequences using advanced probabilistic evolutionary models  .",1,original
3 Previous Work The idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs was first successfully implemented in the BLEU metric for machine translation  .,1,original
There are however other similarity metrics  ) which could be used equally well.,1,original
Decision lists have already been successfully applied to lexical ambiguity resolution by   where they perfromed well.,1,original
"We choose a well-studied parallel task scheduling of DAG, DLS   , as a baseline in our experiments.",1,original
1 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models  .,1,original
"In recent years, HMMs have enjoyed great success in many tagging applications, most notably part-of-speech   tagging   and named entity recognition  .",1,original
…showed that imaging or therapeutic agents larger than the BBB’s exclusion threshold of 400 Da could be successfully delivered by FUS with microbubbles  .,1,original
" , but we use a maximum entropy classifier   to determine parser actions, which makes parsing considerably faster.",1,original
"The combination is significantly better than   at a very high level, but more importantly, Shens results   have been significantly surpassed also by the semisupervised Morce  .",1,original
More recent work has achieved state-of-the-art results with Maxi101 mum entropy conditional Markov models    .,1,original
"…“bicarbonate concentration threshold”   and without at least partial recovery of blood pHe  . remarkably, some of the most CO2 tolerant fishes studied to date tightly regulate the pHi of vital…",1,original
Recent work by   shows a practically ef cient approach that binarizes linguistically SCFG rules when possible.,1,original
"This approach has been shown to be accurate, relatively efficient, and robust using both generative and discriminative models  .",1,original
"On the Hansards data, the simple averaging technique described by Collins   yields a reasonable model.",1,original
Successflfl examples of reuse of data resources include: the WordNet thesaurus  ; the Penn Tree Bank  ; the Longmans Dictionary of Contemporary English  .,1,original
"1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data  .",1,original
"However, except for  , none of these advances in alignment quality has improved translation quality of a state-of-the-art system.",1,original
"However, the most interesting work is certainly proposed by   who extract patterns in two steps.",1,original
"Many mainstream systems and formalisms would satisfy these criteria, including ones such as the University of Pennsylvania Treebank   which are purely syntactic  .",1,original
"Many researchers  , have observed consistent gains by using more flexible matching criteria.",1,original
"Recently, Cabezas and Resnik   experimented with incorporating WSD translations into Pharaoh, a state-of-the-art phrase-based MT system  .",1,original
1 Introduction The reranking approach is widely used in parsing   as well as in other structured classification problems.,1,original
"Among them one of the most widely used is the residual network    , which uses short cut to alleviate training difficulties of very deep networks.",1,original
Stochastic models   have been widely used in POS tagging for simplicity and language independence of the models.,1,original
"Recently, peptide fragmentation with tandem mass spectrometry parallel to the standardized MALDI-TOF-MS has emerged as an additional tool which provides enhanced capabilities for peptide sequencing directly from samples such as nervous tissues or even single cells of invertebrates, including those of insects  .",1,original
The well-known BLEU   is based on the number of common n-grams between the translation hypothesis and human reference translations of the same sentence.,1,original
he implementation of MEBA was strongly influenced by the notorious five IBM models described in  ,1,original
"1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments  .",1,original
” This is a highly reliable prognostic marker in colorectal cancer and is currently being investigated for use in other tumor types  .,1,original
"Because of this ability to expand the proteome of cells, alternative splicing has represented a very useful and powerful tool that allows cells to execute the various expression programs which underlie many fundamental needs of higher organisms: from general needs such as controlling normal development and tissue-specific expression of proteins, to highly specialized processes such as DNA damage response or microRNA biogenesis  .",1,original
1 Introduction There is a pressing need for a consensus on a taskoriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the Penn Treebank   enabled the development of statistical syntactic parsers  .,1,original
"Automated evaluation metrics that rate system behaviour based on automatically computable properties have been developed in a number of other fields: widely used measures include BLEU   for machine translation and ROUGE   for summarisation, for example.",1,original
"Recently, there have existed several automatic fixing techniques for atomicity violations, which can provide soundness guarantees  .",1,original
The translation quality was evaluated using a well-established automatic measure: BLEU score  .,1,original
Bayesian approaches can also improve performance  .,1,original
There has been significant work with such models for greedy sequence modeling in NLP  .,1,original
"…feeding of energydense diets over short periods to cull cows could be profitable  , improve carcass characteristics   and meat quality  .",1,original
2 Confusion-network-based MT system combination The current state-of-the-art is confusion-networkbased MT system combination as described by 98  Rosti and colleagues  .,1,original
"Maximum entropy can be used to improve IBM-style translation probabilities by using features, such as improvements to P  in  .",1,original
Unsupervised algorit~m~ such as   have reported good accuracy that rivals that of supervised algorithms.,1,original
"Parsing models have been developed for different languages and state-of-the-art results have been reported for, e.g., English  .",1,original
The improved pharmacokinetic and pharmacodynamic parameters of ixazomib compared to bortezomib have made it a focus of investigation for use in combination with other pro-apoptotic agents  .,1,original
1 Introduction The emergence of phrase-based statistical machine translation     has been one of the major developments in statistical approaches to translation.,1,original
1 Introduction Phrase-based Statistical MT     has become the predominant approach to Machine Translation in recent years.,1,original
Note that in their pioneering paper Calvet and Fisher   proposed the simplified version of the construction of Mannersalo et al  .,1,original
1 Introduction Recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data  .,1,original
"The development of mathematical models for evolution of primary quantities of interest in bioreactor systems, as well as their incorporation into the design process, have the potential to accelerate the path to realization of optimal functional outcomes in engineered tissues; see   for a review of modeling approaches.",1,original
These models have achieved state-of-the-art performance in transcript-based speech summarization  .,1,original
"Building on a recent proposal in this direction by Turney  , we propose a generic method of this sort, and we test it on a set of unrelated tasks, reporting good performance across the board with very little task-specific tweaking.",1,original
"This algorithm appears fairly widely known: it was described by Goodman   and Finkel et al   and used by Ding et al  , and is very similar to other dynamic programming algorithms for CFGs, so we only summarize it here.",1,original
Adequately understanding and managing product data is seen to have clear business benefits  .,1,original
2 Related Work The popular IBM models for statistical machine translation are described in   and the HMM-based alignment model was introduced in  .,1,original
"If the purified proteins are used for mass spectrometric analyses, elution from streptavidin beads is not required because trypsin digestion can be performed efficiently on bead-bound proteins and the released peptides can be analysed by mass spectrometry  .",1,original
"Among the preparations of BoNT/A on the market, incobotulinumtoxinA   is the only complexing protein-free BoNT/A  .",1,original
They have made semantic formalisms like those now usually associated with Davison   attractive in artificial intelligence for many years  .,1,original
…2011   Reconstruction of severe tibial shaft fractures Free vascularized fibula or osteocutaneous fibular flap Tibia 38 Good outcome…,1,original
"It is small  , lightweight   and has been demonstrated to measure physical activity in children reliably when compared with heart rate monitoring   techniques.",1,original
(Note: We are aware of the method   which is another variant of 2D FCN and achieved excellent performance on the neuron dataset.,1,original
"Here, we use the more established ROUGE-W measure   instead.",1,original
"1 Introduction Syntactically annotated corpora like the Penn Treebank  , the NeGra corpus   or the statistically dismnbiguated parses in   provide a wealth of intbrmation, which can only be exploited with an adequate query language.",1,original
Among the most successful are Spectral Sequencing   and some of their combinations.,1,original
33 Hiero Search Refinements Huang and Chiang   offer several refinements to cube pruning to improve translation speed,1,original
u   showed that restricting word-level alignments between sentence pairs to observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows a polynomial-time solution,1,original
One of the most effective taggers based on a pure HMM is that developed at Xerox  .,1,original
"Many techniques which have been studied for the purpose of machine translation, such as word sense disambiguation  , anaphora resolution  , and automatic pattern extraction from corpora  , can accelerate the further enhancement of sentiment analysis, or other NLP tasks.",1,original
"The update rule above is a special instance of a more general experience-weighted attraction rule  , which has been shown to be in reasonable agreement with experimental data on human learning in repeated games.",1,original
1 Introduction Phrase-based translation   and hierarchical phrase-based translation   are the state of the art in statistical machine translation   techniques.,1,original
"Although we have argued   that this is unlikely to succeed, to our knowledge, we are the first to investigate the matter empirically.11 The best-known MT aligner is undoubtedly GIZA++  , which contains implementations of various IBM models  , as well as the HMM model of Vogel et al.",1,original
"The best example of such an approach is  , who proposes a method that automatically identifies collocations that are indicative of the sense of a word, and uses those to iteratively label more examples.",1,original
Twitter sentiment classification have intensively researched in recent years  .,1,original
Bean and Riloff   and Uryupina   construct quite accurate classifiers to detect unique NPs,1,original
"For example, the efficient algorithm implemented in GCTA   uses the restricted maximum likelihood   method to estimate σ 2g and σ 2 under the null model while the GRM K was estimated from all the SNPs.",1,original
"3 Candidates extraction on Suffix array Suffix array    is a compact data structure to handle arbitrary-length strings and performs much powerful on-line string search operations such as the ones supported by PAT-tree, but has less space overhead.",1,original
"The contraceptive reliability of the levonorgestrel-releasing intrauterine system   is well established, with efficacy comparable to female sterilization  , but with the added advantage of rapid return of fertility upon removal.",1,original
Indole-3-carbinol is used as standard reference compound as its chemopreventive potential by modulating the activities of phase I and phase II enzymes has been well established in the literature  .,1,original
"To achieve efficient parsing, we use a beam search strategy like the previous methods  .",1,original
"In our experiments, we follow Lowe and McDonald   in using the well-known log-likelihood ratio G 2  .",1,original
"We chose the perceptron for the training algorithm because it has shown good performance on other NLP tasks; in particular, Collins   reported good performance for a perceptron tagger compared to a Maximum Entropy tagger.",1,original
"Recently, a novel method called minimal distance maximization     was developed which does not require any weighting function.",1,original
The present study used the most costeffective method for assessing stages of reproductive aging which is based on menstrual bleeding patterns   and chronologic age  .,1,original
"The BLEU metric   in MT has been particularly successful; for example MT05, the 2005 NIST MT evaluation exercise, used BLEU-4 as the only method of evaluation.",1,original
It is the P450’s unique capacity to selectively oxygenate inactive carbons that provides biosynthesis with its competitive advantage over traditional chemical approaches  .,1,original
"Numerous studies have used the PGSI   and it has been shown to have good psychometric properties, examining gambling involvement, problem gambling behaviour, adverse consequences, and problem gambling correlates (Ferris…",1,original
"2.3 Collinss   Parser Collinss statistical parser  ), improved by Bikel  , is based on the probabilities between head-words in parse trees.",1,original
"If the generating function has up to a finite number of zeros, the use of multigrid methods is significantly more efficient   .",1,original
"5 Related Work Discriminative models have recently been proved to be more effective than generative models in some NLP tasks, e.g., parsing  , POS tagging   and LM for speech recognition  .",1,original
"…results for our experiment   using TextTiling and other two state-of-the-art segmentation algorithms, BayesianSeg, a Bayesian unsupervised topic segmentation method  , and MinCutSeg a graph-based segmentation model  .",1,original
"With data from the Southwest Oncology Group   for the use of adjuvant radiation therapy in high-risk patients  , and Messing trial results demonstrating an advantage in survival for long-term ADT in lymph node-positive patients  , good pathologic data are an important step toward multi-modality approach.",1,original
"Sentence-level subjectivity detection, where training data is easier to obtain than for positive vs. negative classification, has been successfully performed using supervised statistical methods alone   or in combination with a knowledgebased approach  .",1,original
"2.2 ITG Space Inversion Transduction Grammars, or ITGs   provide an efficient formalism to synchronously parse bitext.",1,original
"Such word-based lexicalizations of probability models are used successfully in the statistical parsing models of, e.g., Collins  , Charniak  , or Ratnaparkhi  .",1,original
"SVM has been shown to be useful for text classification tasks  , and has previously given good performance in sentiment classification experiments  .",1,original
Some of the best results were reported in   who uses a large training corpus.,1,original
"ROUGE version 1.5.5   was used for evaluation.2 Among others, we focus on ROUGE-1 in the discussion of the result, because ROUGE-1 has proved to have strong correlation with human annotation  .",1,original
The first experimental contribution to unravelling the molecular mechanism of CRISPR processing came from Escherichia coli studies  .,1,original
"However, rats are able to discriminate harmful food from harmless food by their well-developed olfactory system  .",1,original
We chose this amplitude as it has been successfully used to elicit a female response in choice experiments  .,1,original
"Our probabilistic model is based on Incremental Sigmoid Belief Networks  , a recently proposed latent variable model for syntactic structure prediction, which has shown very good behaviour for both constituency   and dependency parsing  .",1,original
"Although the Kappa coefficient has a number of advantages over percentage agreement   for details), we also report percentage agreement as it allows us to compare straightforwardly the human performance and the automatic methods described below, whose performance will also be reported in terms of percentage agreement.",1,original
" , various classification models and linguistic features have been proposed to improve the classification performance  .",1,original
The baseline we measure against in all of these experiments is the state-of-the-art grow-diag-final   alignment refinement heuristic commonly used in phrase-based SMT  .,1,original
The most widely used single-word-based statistical alignment models   have been proposed in  .,1,original
"To facilitate comparisons with previous work  , we used the training/development/test partition defined in the corpus and we also used the automatically-assigned part of speech tags provided in the corpus.10 Czech word clusters were derived from the raw text section of the PDT 1.0, which contains about 39 million words of newswire text.11 We trained the parsers using the averaged perceptron  , which represents a balance between strong performance and fast training times.",1,original
"DSF are characterized by smaller chromatic dispersion and higher Raman scattering coefficient than standard SMF  , and hence they have been found more suitable for long-range Raman-based DTS  .",1,original
is results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words  ,1,original
"In their seminal work,   demonstrated that supervised learning signi cantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms.",1,original
5.2 Results We use a Maximum Entropy   classi er   which allows an e cient combination of many overlapping features.,1,original
"Probably the most widely used association weight function is   Mutual Information    ,  ,  ,  , defined by: A known weakness of MI is its tendency to assign high weights for rare features.",1,original
SVMs have also been proved to outperform other nonlinear techniques including neural network-based techniques such as multilayer perceptrons    .,1,original
"This type of direct optimization is known as Minimum Error Rate Training   in the MT community, and is an essential component in building the stateof-art MT systems.",1,original
"Interest in the use of CWs for remediation of runoff from agricultural irrigation and agro-industrial production has become increasingly popular over the last decades, due to their low capital and operational cost, low energy consumption, and environmental friendliness  .",1,original
Autogenous bone grafts are still the most effective bone substitutes and are therefore considered the gold standard  .,1,original
"When conditioning on words, we treated each word feature individually, as this proved to be useful in  .",1,original
One of the popular statistical machine translation paradigms is the phrase-based model    .,1,original
"…the finger BP measurement method  , a device that provides continuous non-invasive monitoring of beat-to-beat BP, and is therefore a useful non-invasive alternative to intra-arterial BP measurements  .",1,original
"He has achieved state-of-the art results by applying M.E. to parsing  , part-of-speech tagging  , and sentence-boundary detection  .",1,original
"Following initial work by   and  , an early, online distributional thesaurus presented in   has been widely used and cited, and numerous authors since have explored thesaurus properties and parameters: see survey component of  .",1,original
Work at the University of Dundee   has shown that the extensive use of fixed text for sequences such as greetings and prestored narratives is beneficial in AAC.,1,original
"Compared to their k-based counterparts 2D SPEN pulses can have, under the right conditions, an enhanced robustness vis-à-vis field heterogeneities and chemical shifts  .",1,original
"Insulin sensitivity was measured using the insulin sensitivity index of Matsuda, a wellestablished measure of whole-body insulin sensitivity  .",1,original
Introduction The creation of the Penn Treebank   and the word sense-annotated SEMCOR   have shown how even limited amounts of annotated data can result in major improvements in complex natural language understanding systems.,1,original
Midfielders and external defenders have been reported as the most efficient players when connecting teammates  .,1,original
"On the other hand, high-quality treebanks such as the Penn Treebank   and the Kyoto University text corpus   have contributed to improving the accuracies of fundamental techniques for natural language processing such as morphological analysis and syntactic structure analysis.",1,original
shown to produce similar outcomes to FU-based chemotherapy.  The next major advance came with the addition of bevaci-,1,original
Other works based on this scheme like   have shown promising results.,1,original
We then propose a relatively simple yet effective method for resolving translation disambiguation using mutual information     statistics obtained only from the target document collection.,1,original
"We used the average perceptron algorithm of Collins   in our experiments, a variation that has been proven to be more effective than the standard algorithm shown in Figure 2.",1,original
Nuclear transfer procedures are now widely used to overcome these problems  .,1,original
"We chose a dataset that would be enjoyable to reannotate: the movie review dataset of  .3 The dataset consists of 1000 positive and 1000 negative movie reviews obtained from the Internet Movie Database   review archive, all written before 2002 by a total of 312 authors, with a cap of 20 reviews per author per 2Taking Ccontrast to be constant means that all rationales are equally valuable.",1,original
"Perhaps more importantly, discriminative models have been shown to offer competitive performance on a variety of sequential and structured learning tasks in NLP that are traditionally tackled via generative models , such as letter-to-phoneme conversion  , semantic role labeling  , syntactic parsing  , language modeling  , and machine translation  .",1,original
Annual public expenditure on home-care services tripled from €102.3 million in 2001   to €331 million in 2008  .,1,original
A simulated annealing-based heuristic approach has been developed to solve the NP-complete problem in a computationally efficient manner  .,1,original
We choose those sections because several state-of-thwart parsers   are trained on Section 2-21 and tested on Section 23.,1,original
Sentiment summarization has been well studied in the past decade  .,1,original
"5 Bidirectional Sequence Classification Bidirectional POS tagging  , the current state of the art for English, has some properties that make it appropriate for Icelandic.",1,original
We have developed a set of extensions to a probabilistic translation model   that enable us to successfully merge oversegmented regions into coherent objects.,1,original
"The most widely used are Word Error Rate  , Position independent word Error Rate  , the BLEU score   and the NIST score  .",1,original
Apocynin is an effective inhibitor of NADPH oxidase  .,1,original
"1 Introduction Statistical approaches to machine translation, pioneered by  , achieved impressive performance by leveraging large amounts of parallel corpora.",1,original
"In terms of applying non-parametric Bayesian approaches to NLP, Haghighi and Klein   evaluated the clustering properties of DPMMs by performing anaphora resolution with good results.",1,original
We believe that the extensive usage of such measures derives also from the availability of robust and freely availablesoftwarethatallowstocomputethem .,1,original
"For example, the second version of the Microsoft Kinect   is one of the most low-cost and high-speed Time-of-Flight   sensors in the market  .",1,original
"treatment with Fgf8b is shown, because Fgf8b, the most potent isoform of Fgf8, is the only gene of the studied FGF family members that has been found to be crucial in mesoderm development in the mouse  .",1,original
"One of the largest and earliest such efforts is the Penn Treebank  , which contains a one-million word  Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104-6228, USA.",1,original
It compares favorably 505 with conventional phrase-based translation   on Chinese-English news translation  .,1,original
"1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation   and errorbased optimization  .",1,original
"It has been shown that human knowledge, in the form of a small amount of manually annotated parallel data to be used to seed or guide model training, can significantly improve word alignment F-measure and translation performance  .",1,original
1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models  .,1,original
"For example, enumeration of CD8+ tumor-infiltrating lymphocytes   has been shown to be a reliable prognostic marker for a number of cancers, including colorectal cancer and non–small-cell lung carcinoma    .",1,original
"We conclude by noting that English language models currently used in speech recognition   and automated language translation   are much more powerful, employing, for example, 7-gram word models   trained on trillions of words.",1,original
Many previous studies have shown that the log-likelihood ratio is well suited for this purpose  .,1,original
"An ideal scolicidal agent is define as being potent in low concentrations, acting in a short period time, being stable in cyst fluid, not affected by dilution with the cyst fluid, being able to kill the scolex in the cyst, being non-toxic, having low viscosity, and being readily available and easily prepared, as well as being inexpensive  .",1,original
Recent advances in biliary drainage techniques have dramatically improved the mortality rate from  .,1,original
"The validation study has shown that the root mean square differences for the hip and knee flexion/extension with three camera views were 2.6° and 7.5°, and multiple and perpendicular views were recommended to obtain more accurate results  .",1,original
The segmentation results are visually satisfactory and are comparable to the state-of-the-art approaches that are designed specifically for video conferencing  .,1,original
"Recent innovations have greatly improved the efficiency of language model integration through multipass techniques, such as forest reranking  , local search  , and coarse-to-fine pruning  .",1,original
"2 Treebanking The Penn Treebank   is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of empty categories that represent displaced constituents.",1,original
"Third, for reachability query processing, we select seven state-of-the-art algorithms for comparison with our LORch algorithm, including GRAIL  .5 We test these reachability algorithms using both random and equal workloads, where each one contains 1,000,000 reachability queries.",1,original
"Of the beneficial actions of garlic, such as antitumorigenesis, antiatherosclerosis, blood sugar modulation and antibiosis, inhibition of the growth of cancer is perhaps the most notable  .",1,original
"Similar to  , we also applied four popular subspace learning methods including PCA, LDA, LPP and ONPP for appearance-based facial expression recognition with spatial misalignments.",1,original
The current state of the art is represented by the so-called phrase-based translation approach  .,1,original
used in the method has been proven as a safe resource for biologic organisms  .,1,original
RANDLM   performs well and scaled to the full data with improvement  .,1,original
"capable of adaptively approximating powerful classifiers including RBF-SVM, Random Forest , XGBoost .",1,original
"Perhaps the most well-known method is maximum marginal relevance    , as well as cross-sentence informational subsumption  , mixture models  , subtopic diversity  , diversity penalty  , and others.",1,original
"A detailed description of the popular translation/alignment models IBM-1 to IBM-5  , as well as the Hidden-Markov alignment model     can be found in  .",1,original
"In addition, Nanog, in association with other reprogramming factors, has been shown to not only reprogram differentiated somatic cells into pluripotent stem cells  .",1,original
1 Introduction Research in language processing has benefited greatly from the collection of large annotated corpora such as Penn PropBank   and Penn Treebank  .,1,original
"We report on ROUGE-1  , ROUGE-2  , ROUGE W-1.2  , and ROUGE-S*   as they have been shown to correlate well with human judgments for longer multidocument summaries  .",1,original
"effective to provide the useful information of insulator performance  , wavelet transform is conducted to extract these components for the analysis.",1,original
"2 Related Work To model the syntactic transformation process, researchers in these fieldsespecially in machine translationhave developed powerful grammatical formalisms and statistical models for representing and learning these tree-to-tree relations  .",1,original
subjective OSATS GRS has high interobserver reliability and proven utility in assessing vessel ligation.  Scores on the GRS items were averaged to produce a representative composite score.,1,original
An efficient Viterbi-like parsing algorithm that is based on a Dynamic Programing Scheme is proposed in  .,1,original
"It was found to produce automated scores, which strongly correlate with human judgements about translation fluency  .",1,original
Also the use of lossy data structures based on Bloom filters has been demonstrated to be effective for LMs  .,1,original
The current state-of-the-art is to optimize these parameters with respect to the final evaluation criterion; this is the so-called minimum error rate training  .,1,original
A number of studies report positive results using a combination of strategies to treat adolescents  .,1,original
"1 Introduction Most state-of-the-art wide-coverage parsers are based on the Penn Treebank  , making such parsers highly tuned to newspaper text.",1,original
"In this way, Wikipedia provides a new very large source of annotated data, constantly expanded  .",1,original
"Then, the SVM, which has been proven to have high efficiency in classifying the high-dimensional feature in previous studies  , was applied to our proposed model to identify the urban land use types in the TAZs.",1,original
Head-lexicalized stochastic grammars have recently become increasingly popular  .,1,original
ne of the most notable examples is Yarowskys   bootstrapping algorithm for word sense disambiguation,1,original
"Given the good results observed with this approach  , the question arose whether this robustness could suffice to enable arbitrary 3D excitations.",1,original
"Specifically, aspect rating as an interesting topic has also been widely studied  .",1,original
"The most popular ESIPT probes are 3-hydroxychromones, which are largely used to investigate lipid membrane properties   interactions.",1,original
"Online learning algorithms have been shown to be robust even with approximate rather than exact inference in problems such as word alignment  , sequence analysis   and phrase-structure parsing  .",1,original
We show that our DDTM system provides significant improvements in BLEU   and TER   scores over the already extremely competitive DTM2 system.,1,original
Several investigations represented both occurrence and severity of CIN were well correlated with improved survivals in various cancers  .,1,original
"1 Introduction As with many other statistical natural language processing tasks, statistical machine translation   produces high quality results when ample training data is available.",1,original
1 Introduction Current state-of-the-art statistical parsers   are trained on large annotated corpora such as the Penn Treebank  .,1,original
  compares his method to   and shows that for four words the former performs significantly better in distinguishing between two senses.,1,original
"4%, an enormous improvement compared to the Lumbini survey 1995 result that reported just 15%  .",1,original
"A variety of classifiers have been employed for this task  , the most popular being decision lists   and naive Bayesian classifiers  .",1,original
1 Introduction Phrase-based statistical machine translation models   have achieved significant improvements in translation accuracy over the original IBM word-based model.,1,original
This is a common technique in machine translation for which the IBM translation models are popular methods  .,1,original
"Availability of high biological value of animal proteins, essential amino acids and fatty acids, vitamins and other nutrients are the other reasons to ensure its popularity among masses  .",1,original
We compare KCDML not only with the state-of-art methods including our current work‚ÄîCDML   and LDA.,1,original
"Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s  .",1,original
"Using the IBM translation models IBM-1 to IBM-5  , as well as the Hidden-Markov alignment model  , we can produce alignments of good quality.",1,original
"For instance, the mutual information   and log-likelihood ratio   have been widely used for extracting word bigrams.",1,original
"Discriminative methods such as Conditional Random Fields    , Semi-Markov Random Fields  , and perceptrons   have been popular approaches for sequence labeling because of their excellent performance, which is mainly due to their ability to incorporate many kinds of overlapping and non-independent features.",1,original
.1 The AUGMENT technique for Domain Adaptation The AUGMENT technique introduced by Daume III   is a simple yet very effective approach to performing domain adaptation,1,original
"The state-of-the-art SMT system Moses implements a distance-based reordering model   and a distortion model, operating with rewrite patterns extracted from a phrase alignment table  .",1,original
The procedure of substituting named entities with their respective tags previously proved to be useful for various tasks  .,1,original
It is natural to study the swelling and shrinking of catalyzed bulk pNIPAm gels at first because of the relatively simple gelation process and the convenient methods of observation such as microscopy .,1,original
"In most cases, supervised learning methods can perform well  .",1,original
Current state of the art machine translation systems   use phrasal   features extracted automatically from parallel corpora.,1,original
"However, this is not unprecedented: discriminatively weighted generative models have been shown to outperform purely discriminative competitors in various NLP classification tasks  , and remain the standard approach in statistical translation modeling  .",1,original
"If medical evaluation reveals systemic lymphoma, treatment of the ocular disease is secondary to systemic treatment  .  The effectiveness of EBRT for the treatment of lymphoma of the eye and its adnexa has been widely documented.",1,original
"We have used the sheep ovary model, since this is the most widely used animal model of whole ovary cryopreservation and is of comparable size to the human ovary  .",1,original
"Several strategies, such as the one proposed by Gu  , exist in order to avoid generator growth, and they can be applied to both the original GKO algorithm and its space-efficient versions.",1,original
"A detailed description of the popular translation models IBM-1 to IBM-5  , aswellastheHidden-Markovalignmentmodel     can be found in  .",1,original
  discussed efficient implementation.,1,original
"Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes  .",1,original
"First of all, the percentage of parents’ positive attitudes towards vaccinations was exceptionally high compared with other similar studies  .",1,original
Several studies have demonstrated that for instance Statistical Machine Translation   benefits from incorporating a dedicated WSD module  .,1,original
Online votedperceptrons have been reported to work well in a number of NLP tasks  .,1,original
"Similarly, if the task is to distinguish between binary, coarse sense distinction, then current WSD techniques can achieve very high accuracy  ).",1,original
"The methodology is primarily influenced by the Grounded Theory approach, which has been used successfully in previous studies  .",1,original
"Collins and Roark   saw a LFMS improvement of 0.8% over their baseline discriminative parser after adding punctuation features, one of which encoded the sentence-final punctuation.",1,original
2005) have implemented a dependency parser with good accuracy  ) and very impressive speed   and four times faster than Charniak  ),1,original
"While the former is piecewise constant and thus cannot be optimized using gradient techniques, Och   provides an approach that performs such training efficiently.",1,original
"However, the only known work which automates part of a customer service center using natural language dialogue is the one by Chu-Carroll and Carpenter  .",1,original
"In this regard, it is worth noting that the number of studies that have reported at least some mixed strain infections in a wide variety of hosts, including cats, has increased greatly since more sensitive genotyping techniques have been applied  .",1,original
"Moreover, Nelfinavir, a S2P inhibitor used in treating HIV patients, has been well tolerated in clinical trials41, indicating that inhibition of ATF6 and SREBP-1 is not likely to be problematic in patients.",1,original
Confusion network and re-decoding have been well studied in the combination of different MT systems  .,1,original
"Recent work includes improved model variants   and applications such as web data extraction  , scientific citation extraction  , and word alignment  .",1,original
"Preparing tagged corpora either by hand is labour-intensive and potentially error-prone, and although a semi-automatic approach can be used  , it is a good thing to reduce the human involvement as much as possible.",1,original
"This method, initially proposed by  , was successfully evaluated in the context of the SENSEVAL framework  .",1,original
The Gaussian prior   has been found in practice to be very effective in combating overfitting of the parameters to the training data  .,1,original
The approach is very general and modular and can work in conjunction with a number of learning strategies for word sense disambiguation  .,1,original
Lins   information-theoretic similarity measure is commonly used in lexicon acquisition tasks and has demonstrated good performance in unsupervised WSD  .,1,original
6 Related Work The popular IBM models for statistical machine translation are described in  .,1,original
"4 Experiment Our baseline system is a popular phrase-based SMT system, Moses  , with 5-gram SRILM language model  , tuned with Minimum Error Training  .",1,original
"The results of the comparison with ROUGE-N  , ROUGE-S    and ROUGE-L   show that our method correlates more closely with human evaluations and is more robust.",1,original
"1 Introduction Syntactic methods are an increasingly promising approach to statistical machine translation, being both algorithmically appealing   and empirically successful  .",1,original
"1 Introduction Since its introduction by Och  , minimum error rate training   has been widely adopted for training statistical machine translation   systems.",1,original
"The full model yields a stateof-the-art BLEU   score of 0.8506 on Section 23 of the CCGbank, which is to our knowledge the best score reported to date 410 using a reversible, corpus-engineered grammar.",1,original
The IBM models 1-5   produce word alignments with increasing algorithmic complexity and performance.,1,original
"Among these advances, forest-based modeling   and tree sequence-based modeling   are two interesting modeling methods with promising results reported.",1,original
"As shown recently, a different member of the Krueppel-like factor family KLF4 demonstrated a potent antiapoptotic effect upon HDACi treatment which was mediated in part by direct binding and transcriptional upregulation of p57 followed by inhibition of the stress response phosphorylation pathway  .",1,original
"Then, we apply a grow-diag-final algorithm which is widely used in bilingual phrase extraction   to monolingual alignments.",1,original
"Similar models have been successfully applied in the past to other tasks including parsing  , chunking  , and machine translation  .",1,original
Hypergraphs have been successfully used in parsing   and machine translation  .,1,original
"1 Introduction In recent years, Bracketing Transduction Grammar   proposed by   has been widely used in statistical machine translation  .",1,original
Its success stories range from parsing   to machine translation  .,1,original
1 Introduction Statistical parsing models have been shown to be successful in recovering labeled constituencies   and have also been shown to be adequate in recovering dependency relationships  .,1,original
  hold state-of-the-art results for Czech NER.,1,original
"In this work, we propose two models that can be categorized as extensions of standard word lexicons: A discriminative word lexicon that uses global, i.e. sentence-level source information to predict the target words using a statistical classifier and a trigger-based lexicon model that extends the well-known IBM model 1   with a second trigger, allowing for a more finegrained lexical choice of target words.",1,original
"On the contrary, when nonvertebrobasilar vertigo is considered, the combination of cervical MRI, TCD and BAEP has superiorities to rule out vertebrobasilar insufficiency for their negative correlations  .",1,original
"5 Comparison with Previous Top Systems and Related Work In POS tagging, the previous best performance was reported by   as summarized in Table 7.",1,original
"nidulans, we made use of a simple but straightforward approach as it had been described recently  .",1,original
"Unigram models have been previously shown to give good results in sentiment classification tasks  : unigram representations can capture a variety of lexical combinations and distributions, including those of emotion words.",1,original
"All state-of-the-art wide-coverage parsers relax this assumption in some way, for instance by   changing the parser in step  , such that the application of rules is conditioned on other steps in the derivation process  , or by   enriching the nonterminal labels in step   with context-information  , along with suitable backtransforms in step  .",1,original
"PL, an electrophilic small molecule identified in cell-based, high-throughput screening assays was shown to selectively kill cancer cells without harming the normal epithelial cells  .",1,original
  highlights the benefits of such strong gradients and the first results from the Connectome scanner   are now starting to verify those findings.,1,original
The 8-point RLS is widely used in Sweden in some emergency departments and neurosurgical units instead of the GCS.,1,original
The success of recent high-quality parsers   relies on the availability of such treebank corpora.,1,original
"‚Ä¶using the software of MEME online-version 4.6.1  , which is one of the most widely used tools for observation of new sequence patterns in biological sequences and analysis of their significance  .",1,original
"The averaged perceptron   is a variant which averages the w across all iterations; it has demonstrated good generalization especially with data that is not linearly separable, as in many natural language processing problems.",1,original
"However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works  ,  ,  , and  ).",1,original
"Here, the relative length of cohesive element is le/L = 0.0067 and approximately 100 cohesive elements are adopted in the cohesive zone, which satisfies the requirement of the minimum number of elements   and can effectively capture the crack growth in dentin.",1,original
"The Simulated Annealing approach has been proven to be very effective when applied to non convex optimization, for which gradient based algorithms may fail to produce good solutions, Cerný  ; Marques et al.",1,original
"Also, procedures followed for assessment of LV structure and function are known to be highly reliable  .",1,original
Measurement of central BP appears to offer advantages over brachial BP for risk stratification  .,1,original
However more recent results have shown that it can indeed improve parser performance  .,1,original
"When the training text is adequate to estimate the tagger parameters, more efficient stochastic taggers   and training methods can be implemented  .",1,original
"Such approaches have shown promise in applications such as web page classification  , named entity classification  , parsing  , and machine translation  .",1,original
"In particular, as shown in  , the memory-based string matching engine allows on-the-fly update of memory contents for high reconfigurability.",1,original
1 Introduction Parsing technology has come a long way since Charniak   demonstrated that a simple treebank PCFG performs better than any other parser   on parsing the WSJ Penn treebank  .,1,original
"1 Introduction Very large corpora obtained from the Web have been successfully utilized for many natural languageprocessing applications, suchasprepositional phrase   attachment, other-anaphora resolution, spellingcorrection, confusablewordsetdisambiguation and machine translation  .",1,original
"In particular, flavonoids and phenolic compounds are highly effective antioxidants that possess anticancer, hypolipidemic, anti-aging, and anti-inflammatory properties; thus, they have received increasing attention  .",1,original
The most common adverse effect was hypertension.  Another Phase II trial used axitinib 7 mg twice daily initially and a maximum dose of 10 mg if well tolerated.,1,original
Several studies have reported alignment or translation performance for syntactically augmented translation models   and these results have been promising.,1,original
Bootstrapping methods similar to ours have been shown to be competitive in word sense disambiguation  .,1,original
The translation quality is evaluated using a well-established automatic measure: BLEU score  .,1,original
"There is usually not a considerable difference between the two methods in terms of the accuracy of the resulting model  , but L1 regularization has a significant advantage in practice.",1,original
"We report on ROUGE-1  , ROUGE-2  , ROUGE W-1.2  , and ROUGE-S*   as they appear to correlate well with human judgments for longer multi-document summaries, particularly ROUGE-1  .",1,original
Recent work emphasizes corpus-based unsupervised approach   that avoids the need for costly truthed training data.,1,original
"It has been used in a variety of difficult classification tasks such as part-of-speech tagging  , prepositional phrase attachment   and named entity tagging  , and achieves state of the art performance.",1,original
"After the success in syntactic  ) and propositional encodings  ), more sophisticated semantic data   or opinion annotations  ) and discourse data   and rhetorical parsing  ) are being generated.",1,original
"1 Introduction Automatic Metrics for machine translation   evaluation have been receiving significant attention in the past two years, since IBM's BLEU metric was proposed and made available  .",1,original
"Methodologies such as lexicalisation   and tree transformations  , weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs.",1,original
An especially well-founded framework for doing this is maximum entropy  .,1,original
Molecular markers and population genetic analyses have greatly facilitated our ability to assess previously unobtainable data on the ecological or evolutionary dynamics of metazoan animal parasites in natural populations  .,1,original
"Furthermore, good results have been produced in other areas of NLP research using maximum entropy techniques  .",1,original
The BLEU metric   and the closely related NIST metric   along with WER and PER 48 have been widely used by many machine translation researchers.,1,original
Pupillometry has been proposed as a simple and sensitive tool to detect subclinical autonomic dysfunction  .,1,original
"From a strategic viewpoint, layered modular architectures have the competitive advantage, as well as the challenge, in being doubly distributed  .",1,original
4 Experiments Phrase-based SMT systems have been shown to outperform word-based approaches  .,1,original
"Such training has been shown to reduce resting CRP and IL-6  , and improve glycaemic control   and body composition  .",1,original
The state of the art technology for relation extraction primarily relies on pattern-based approaches  .,1,original
"Collins   introduced the averaged perceptron, as a way of reducing overfitting, and it has been shown to perform better than the non-averaged version on a number of tasks.",1,original
"Then, some manual and automatic symbol splitting methods are presented, which get comparable performance with lexicalized parsers  .",1,original
"1 Introduction Phrase-based systems   are probably the most widespread class of Statistical Machine Translation systems, and arguably one of the most successful.",1,original
"In Carpuat and Wu  , anotherstate-of-the-artWSDengine  is used to dynamically determine the score of a phrase pair under consideration and, thus, let the phrase selection adapt to the context of the sentence.",1,original
"Like in other studies  , the total recall item   revealed to be the most important measure in the distinction between patients and controls.",1,original
"A large part of Shannon’s seminal work   is devoted to both theoretical and practical aspects of products, and his invocation of the pastry dough mixing analogy [16, p.",1,original
chromatic dispersion and the compensation of laser phase noise have been carried out effectively in coherent transmission systems according to the reported work  .,1,original
The effectiveness of the our recommendation approach has been compared against two widespread state-of-the-art baselines: labeled UCF  .,1,original
We also plan to apply self-training of n-best tagger which successfully boosted the performance of one of the best existing English syntactic parser  .,1,original
"In Owczarzak  , the method achieves equal or higher correlations with human judgments than METEOR  , one of the best-performingautomaticMTevaluationmetrics.",1,original
Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging 2   .,1,original
3 CLaC-NB System: Nave Bayes Supervised statistical methods have been very successful in sentiment tagging of texts and in subjectivity detection at sentence level: on movie review texts they reach an accuracy of 85-90%   and up to 92% accuracy on classifying movie review snippets into subjective and objective using both Nave Bayes and SVM  .,1,original
Equol is similar in structure to estradiol   and is a more potent estrogen mimic than daidzein  .,1,original
"While crowdsourcing has also been used to gather data for learning problems in the non-speech audio domain  , machine listening—the sibling field of computer vision— has yet to see the same transformative success.",1,original
"For the extraction problem, there have been various methods proposed to date, which are quite adequate  .",1,original
" , is fast and simple to apply as positioning and irradiation can be performed in a short time.",1,original
"A large number of possible routes can exist between any two compounds, particularly those that feature in multiple pathways, and so tools such as KEGG PathComp   have been created to automatically perform these searches quickly and efficiently.",1,original
"In this paper, we build on recent work   that demonstrated how the Bloom filter  ; BF), a space-efficient randomised data structure for representing sets, could be used to store corpus statistics efficiently.",1,original
ecent work emphasizes a corpus-based unsupervised approach   that avoids the need for costly truthed training data,1,original
"To solve this problem, we adopt an idea one sense per collocation which was introduced in word sense disambiguation research  .",1,original
"With the availability of large natural language corpora annotated for syntactic structure, the treebanks, e.g.,  , automatic grammar extraction became possible  .",1,original
"In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns   to get more accurate co-occurrence statistics  .",1,original
"Among them, the unsupervised algorithm using decisiontrees   has achieved promising performance.",1,original
"zeamais, which could be an attractive alternative considering the great potential of the oil as insecticide and repellent, particularly because it is rich in monoterpenes  .",1,original
"State-of-theart machine learning techniques including Support Vector Machines  , AdaBoost   and Maximum Entropy Models   provide high performance classifiers if one has abundant correctly labeled examples.",1,original
We compare KCDML not only with the state-of-art methods including our current work—CDML   and LDA.,1,original
"Thispaperfocusesontheframeworkintroduced in Figure 2 for two reasons:   cautious al50 gorithms were shown to perform best for several NLP problems  , and   it has nice theoretical properties: Abney   showed that, regardless of the selection procedure, sequential bootstrapping algorithms converge to a local minimum of K, where K is an upper bound of the negative log likelihood of the data.",1,original
This method has also been successfully applied to the insect nervous system  .,1,original
he search across a dimension uses the efficient method of Och  ,1,original
"This representation, being contiguous on both sides, successfully reduces the decoding complexity to a low polynomial and significantly improved the search quality  .",1,original
The third category of techniques uses local spatio-temporal features   which have recently become a very popular video representation method for action recognition.,1,original
1 Introduction IBM Model 1   is a wordalignment model that is widely used in working with parallel bilingual corpora.,1,original
"Along this line,   present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance  the ability to translate nonconstituent phrases   turns out to be critical and pervasive.",1,original
In syntactic parse re-ranking supersenses have been used to build useful latent semantic features  .,1,original
"Therefore, we implemented the new method and compared it against a well established quadratic regularization method for unconstrained optimization introduced in  .",1,original
"This type of input information   is a powerful and flexible model for specifying alternative inputs to a classifier, and has been additionally used by Haghighi and Klein  .",1,original
"• Even more efficient pure TSP heuristics such as the Lin-Kernighan heuristic    , using the LKH implementation (Helsgaun, 2000, http://www.",1,original
The ROUGE   suite of metrics are n-gram overlap based metrics that have been shown to highly correlate with human evaluations on content responsiveness.,1,original
"By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation   and information retrieval  .",1,original
"We use the GBrank algorithm for the ranking model learning, as GBrank is one of the most effective learning-to-rank algorithms  .",1,original
Averaging has been shown to help reduce overfitting  .,1,original
"In order to filter some noise caused by the error alignment links, we only retain those translation pairs whose translation probabilities are above a threshold 1 D 1  or co-occurring frequencies are above a threshold 2  . When we train the IBM statistical word alignment model with a limited bilingual corpus in the specific domain, we build another translation dictionary with the same method as for the dictionary . But we adopt a different filtering strategy for the translation dictionary . We use log-likelihood ratio to estimate the association strength of each translation pair because Dunning   proved that log-likelihood ratio performed very well on small-scale data.",1,original
"Transformation-based learning has also been successfully applied to text chunking  , morphological disambiguation  , and phrase parsing  .",1,original
"Our interpretation is more useful than past interpretations involving marginal constraints   or maximum-entropy models   as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results.",1,original
"However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time  .",1,original
Movies Reviews: This is a popular dataset in sentiment analysis literature  .,1,original
"Automated metrics such as BLEU  , RED  , Weighted N-gram model    , syntactic relation / semantic vector model   have been shown to correlate closely with scoring or ranking by different human evaluation parameters.",1,original
"Support Vector Machines     and Maximum Entropy   method   are powerful learning methods that satisfy such requirements, and are applied successfully to other NLP tasks  .",1,original
"3 The Perceptron The perceptron algorithm introduced into NLP by Collins  , is a simple but effective discriminative training method.",1,original
"When we run our classifiers on resource-tight environments such as cell-phones, we can use a random feature mixing technique   or a memory-efficient trie implementation based on a succinct data structure   to reduce required memory usage.",1,original
"CLL has then been applied to a corpus of declarative sentences from the Penn Treebank   on which it has been shown to perform comparatively well with respect to much less psychologically plausible systems, which are significantly more supervised and are applied to somewhat simpler problems.",1,original
Studies on the supervised task have shown that straightforward baselines   achieve a relatively high performance level and are surprisingly difficult to beat  .,1,original
2.1 Lexicalized parse trees The first successful work on syntactic disambiguation was based on lexicalized probabilistic context-free grammar    .,1,original
ch   has described an ef cient exact one-dimensional error minimization technique for a similar search problem in machine translation,1,original
"Because the expressiveness characteristics of ITG naturally constrain the space of possible matching in a highly appropriate fashion, BTG achieves encouraging results for bilingual bracketing using a word-translation lexicon alone  .",1,original
"3.2 Classifying speech segments in isolation In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5 Following standard practice in sentiment analysis  , the input to SVMlight consisted of normalized presence-of-feature   vectors.",1,original
"Currently, the best-performing English NP interpretation methods in computational linguistics focus mostly on two consecutive noun instances   and are either   supervised, knowledge-intensive  ,  ,  ,  ,  ,  ,  ,  , or use statistical models on large collections of unlabeled data  ,  ,  ,  .",1,original
The SBF with biophysically realistic model oscillators Cosine oscillators were extensively used in numerical simulations of interval timing models with great success  .,1,original
"In our preliminary experiments, we used a Support Vector Machine   ranker   to learn the structured classi er.2 We also in1See e.g. Collins   for a popular training algorithm.",1,original
Recent work   explored the task of part-of-speech tagging   using unsupervised Hidden Markov Models   with encouraging results.,1,original
Properly calculated BLEU scores have been shown to correlate reliably with human judgments  .,1,original
China’s role in Apple’s global supply chain   have received a great deal of attention.,1,original
"Moreover, comparable results were obtained in an in vivo imaging study on mice, which was performed with the highly resolving U-SPECT  IBZM binding relative to baseline.",1,original
"The most widely known are the Word Error Rate  , the Position independent word Error Rate  , the NIST score   and, especially in recent years, the BLEU score   and the Translation Error Rate    .",1,original
of the most important is Lins  ,1,original
"Synchronous binarization   solves this problem by simultaneously binarizing both source and target-sides of a synchronous rule, making sure of contiguous spans on both sides whenever possible.",1,original
"Two methods  , which were previously reported as competitive in automated diagnosis of CD   were utilized in addition to state-of-the-art global mid-level image representations which are obtained by pooling local image descriptors.",1,original
"When tested on f-structures for all sentences from Section 23 of the Penn Wall Street Journal   treebank  , the techniques described in this paper improve BLEU score from 66.52 to 68.82.",1,original
"For example, Smith and Smith   and Burkett and Klein   show that joint parsing   on a bitext improves accuracies on either or both sides by leveraging bilingual constraints, which is very promising for syntax-based machine translation which requires   parse trees for rule extraction  .",1,original
CMA yields significant rates of pathogenic or potentially pathogenic   results  .,1,original
A popular statistical machine translation paradigms is the phrase-based model  .,1,original
Evidence for the measurement properties of the I-QoL has been demonstrated by a number of studies  ; this study represents the largest evaluation in a UK population.,1,original
"The bigram translation probability relies on word context, known to be helpful in translation  , to improve the identification of target phrases.",1,original
"3.2 Statistical Learning Model 3.2.1 Nave Bayes Learning Nave Bayes learning has been widely used in natural language processing with good results such as statistical syntactic parsing  , hidden language understanding  .",1,original
One of the simplest models that can be seen in the context of lexical triggers is the IBM model 1   which captures lexical dependencies between source and target words.,1,original
The latter approach has become increasingly popular  .,1,original
Data Centric Storage     is a prominent data-storage and queryprocessing mechanism on Wireless Sensor Networks  .,1,original
"Force feedback   has been shown to increase the usability and to decrease the cognitive workload during the surgery, as reflected in faster learning curves  .",1,original
"We carried out automatic evaluation of our summaries using ROUGE   toolkit, which has been widely adopted by DUC for automatic summarization evaluation.",1,original
Discriminative taggers and chunkers have been the state-of-the-art for more than a decade  .,1,original
State-of-art systems for doing word alignment use generative models like GIZA++  .,1,original
"1 Introduction By exploiting information encoded in human-produced syntactic trees  , research on probabilistic models of syntax has driven the performance of syntactic parsers to about 90% accuracy  .",1,original
"In this review article, we first briefly explain the steps of a well-performed SR/MA   and then apply them to the topic of VUR.",1,original
One of these topologies known as local topology or lbest model provided improvements on several multimodal optimization problems  .,1,original
"The Inversion Transduction Grammar or ITG formalism, described in  , is well suited for our purposes.",1,original
"This approach took inspiration from the pioneering work by  , but it is also fundamentally different, because instead of grouping similar senses together, the CoreLex approach groups together words according to all of their senses.",1,original
"Such a construction mimics the highly effective P450 BM3, a natural chimera whose high turnover and native bacterial expression have made it a popular construction to replicate  .",1,original
"The prevalent trend for performance enhancement has been to simply increase the level of parallelism, many of the recently proposed systemson-chip   contain tens to hundreds of processors operating in the multiple-instruction multiple-data mode   to exploit data-level parallelism.",1,original
"Compared with their string-based counterparts, treebased systems offer some attractive features: they are much faster in decoding  ), do not require a binary-branching grammar as in string-based models  , and can have separate grammars for parsing and translation, say, a context-free grammar for the former and a tree substitution grammar for the latter  .",1,original
"For the Penn Treebank,   reports an accuracy of 96.6% using the Maximum Entropy approach, our much simpler and therefore faster HMM approach delivers 96.7%.",1,original
"Among these methods, SVM is shown to perform better than other methods  .",1,original
"Recently so-called reranking techniques, such as maximum entropy models   and gradient methods  , have been applied to machine translation  , and have provided significant improvements.",1,original
"It has shown promise in improving the performance of many tasks such as name tagging  , semantic class extraction  , chunking  , coreference resolution   and text classification  .",1,original
"Furthermore, among mediators easily measured in blood, IL-6   and procalcitonin   appear to show the tightest correlation with clinical outcome and might be particularly useful markers of change in inflammatory response over time    .",1,original
Averaging has been shown to help reduce overfitting  .,1,original
"Other well-known metrics are WER  , NIST  , GTM  , ROUGE  , METEOR  , and TER  , just to name a few.",1,original
"Support vector machines, developed by Vapnic, are based on the statistical learning theory   and recognized as an efficient and powerful regression and time series prediction technique.",1,original
"We evaluated the generator on the Penn Treebank  , which is highly reliable corpus consisting of real-world texts.",1,original
A primary benefit of these models is the inclusion of variability in model parameters  .,1,original
"This is analogous, and in a certain sense equivalent, to empirical risk minimization, which has been used successfully in related areas, such as speech recognition  , language modeling  , and machine translation  .",1,original
"Signals inspector such as oscilloscope, image processing library such as OpenCV, pattern matching algorithm   are integrated and ready-to-use to support that informal design technique.",1,original
"Let us note that co-occurrence is nowadays a common method to find a relationship between biomedical concepts; co-occurrence methods are commonly used to discover new and hidden relations, following the seminal work of Swanson  .",1,original
"Several classification models can be adopted here, however, we choose the averaged perceptron algorithm   because of its simplicity and high accuracy.",1,original
This algorithm and its many variants are widely used in the computational linguistics community  .,1,original
"This represents the translation probability of a phrase when it is decomposed into a series of independent word-for-word translation steps  , and has proven a very effective feature  .",1,original
"For the word alignment, we apply standard techniques derived from statistical machine translation using the well-known IBM alignment models   implemented in the opensource tool GIZA++  .",1,original
-Theory and Agreement Indices Two well-known measures for capturing the quality of manual annotations are agreement percentages and the kappa statistic  ,1,original
"1 Introduction Large scale annotated corpora, e.g., the Penn TreeBank   project  , have played an important role in text-mining.",1,original
BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities  .,1,original
"We have also implemented two well-known information retrieval metrics, namely, Precision@K and NDCG  , to evaluate the overall performance of the event detection task.",1,original
"By sharing common infixes of target patterns  , the memory usage in the match vectors could be efficient.",1,original
"One study conducted on elderly patients showed that the combined strategy of visits and telemedicine improved HRQOL and their knowledge about the disease, achieving a high degree of satisfaction with the program.  Similarly, another study showed a high degree of patient satisfaction (96.",1,original
"1 Introduction Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy  .",1,original
5.4 Maximum Entropy Maximum entropy has been proven to be an effective method in various natural language processing applications  .,1,original
"Most early work assumed some limited amount of supervision   for this task, recent work has shown that unsupervised methods can perform on-par and often above early supervised methods  .",1,original
"2 Maximum Entropy Models Maximum entropy   models  , also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
The stimulation of chondrocyte and/or osteoblast cell proliferation induced by PEMFs has been shown to have a positive effect in the treatment of fracture healing  .,1,original
"Demonstration of intrathecal immunoglobulin and antibody synthesis are powerful tools for diagnosis of neurological disorders, as has been shown for multiple sclerosis and several infectious diseases of the CNS  .",1,original
"On the whole, we had better results than Winslow and Brunt  , perhaps because all the operations were performed by a single surgeon in our series.",1,original
Collins and Koo   introduced an improved reranking model for parsing which includes a hidden layer of semantic features.,1,original
Successful discriminative parsers have used generative models to reduce training time and raise accuracy above generative baselines  .,1,original
"We also report state-of-the-art results for Hebrew full mor1Another notable work, though within a slightly different framework, is the prototype-driven method proposed by  , in which the dictionary is replaced with a very small seed of prototypical examples.",1,original
"Church and Hanks   use mutual information to identify collocations, a method they claim is reasonably effective for words with a frequency of not less than five.",1,original
"2.2 Phrase-based Chinese-to-English MT The MT system used in this paper is Moses, a stateof-the-art phrase-based system  .",1,original
The best previous result is an accuracy of 56.1%  .,1,original
"2.3 Classifier Training We chose maximum entropy   as our primary classifier, since it had been successfully applied by the highest performing systems in both the SemEval-2007 preposition sense disambiguation task   and the general word sense disambiguation task  .",1,original
"The Simulated Annealing approach has been proven to be very effective when applied to non convex optimization, for which gradient based algorithms may fail to produce good solutions, Cerný  ; Marques et al.  ; A.",1,original
"In addition, there are continued new developments in lowcost, light-weight, and long-duration UAVs  .",1,original
ntroduction The Penn Treebank   initiated a new paradigm in corpus-based research,1,original
"HMM-smoothing improves on the most closely related work, the Structural Correspondence Learning technique for domain adaptation  , in experiments.",1,original
"Bilexical context-free grammars have been presented in   as an abstraction of language models that have been adopted in several recent real-world parsers, improving state-of-the-art parsing accuracy  .",1,original
Recent work has shown that opportunistic routing is an efficient way to achieve low-latency yet energy-efficient data collection in WSN  .,1,original
"1 Introduction We have seen rapid recent progress in machine translation through the use of rich features and the development of improved decoding algorithms, often based on grammatical formalisms.1 If we view MT as a machine learning problem, features and formalisms imply structural independence assumptions, which are in turn exploited by efficient inference algorithms, including decoders  .",1,original
"The last two methods, AHP and Likert scale, were applied by the first author for the determination of the weights   due to the robustness and simplicity of these two methods.",1,original
"Proceedings of the Conference on Empirical Methods in Natural 2 Automatic Thesaurus Extraction The development of large thesauri and semantic resources, such as WordNet  , has allowed lexical semantic information to be leveraged to solve NLP tasks, including collocation discovery  , model estimation   and text classi cation  .",1,original
An important contribution to interactive CAT technology was carried out around the TransType   project  .,1,original
"Incremental top-down and left-corner parsers have been shown to effectively   make use of non-local features from the left-context to yield very high accuracy syntactic parses  , and we will use such rich models to derive our scores.",1,original
4.1 Features We used a dependency structure as the context for words because it is the most widely used and one of the best performing contextual information in the past studies  .,1,original
"More recent work   has considered methods for speeding up the feature selection methods described in Berger, Della Pietra, and Della Pietra  , Ratnaparkhi  , and Della Pietra, Della Pietra, and Lafferty  .",1,original
"This kind of corpus has served as an extremely valuable resource for computational linguistics applications such as machine translation and question answering  , and has also proved useful in theoretical linguistics research  .",1,original
"Among the available alternatives, we have selected three well-known tools: cbmc  , a recent tool based on Abstract Interpretation.",1,original
"The pioneering work of Ramshaw and Marcus   introduced NP chunking as a machine-learning problem, with standard datasets and evaluation metrics.",1,original
"ERGMs are particularly useful for testing hypotheses about network relations, and they have started to be applied more widely in public health  .",1,original
"For source coding and rate-distortion coding problems, polar codes have been shown to be competitive with the state-of-the-art methods  .",1,original
"To overcome this problem, sliding mode control has been widely used as one of the precise and robust algorithms  .",1,original
"Few SAEs were observed, reflecting previous data indicating that SAEs resulting from statin treatment are rare.  As the largest study to date focusing on statin therapy solely in patients with the metabolic syndrome, COMETS supports the good safety profile of rosuvastatin and atorvastatin reported previously by two post hoc subgroup analyses.",1,original
"Among several endogenous lipophilic molecules known to activate CBRs, the best characterized are N-arachidonoylethanolamine   and 2-arachidonoylglycerol  , which are known to modulate synaptic transmission throughout the brain  .",1,original
vinifera   that have been successfully used in gene transfer experiments.,1,original
Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation   and Inversion Transduction Grammar  .,1,original
"In the domain of supply chain, logistics, and operations management, the approach has been popularized by Holmström et al.  , leading to promising initial applications  .",1,original
"The most popular non-data-splitting methods for predicting test set cross-entropy   are AIC and variants such as AICc, quasi-AIC  , and QAICc  .",1,original
"Recently,   have successfully applied self-training to various parser adaptation scenarios using the reranking parser of  .",1,original
ch   has described an efficient exact onedimensional accuracy maximization technique for a similar search problem in machine translation,1,original
The efficient block alignment algorithm in Section 4 is related to the inversion transduction grammar approach to bilingual parsing described in  : in both cases the number of alignments is drastically reduced by introducing appropriate re-ordering restrictions.,1,original
"First, we compared our system output to human reference translations using Bleu  , a widelyaccepted objective metric for evaluation of machine translations.",1,original
"Another attractive property of the voted perceptron is that it can be used with kernels, for example the kernels over parse trees described in  .",1,original
agent was reported to reduce the risk of cardiac mortality  .,1,original
"Three approaches are dominating, i.e. knowledge-based approach  , information retrieval-based approach   and machine learning approach  , in which the last approach is found very popular.",1,original
  demonstrated that semi-supervised WSD could be successful.,1,original
"Despite the preponderance of interview-based qualitative research, written accounts are an established methodology in health research  .",1,original
The dif1The routinely used tool for automatic evaluation ROUGE was adopted exactly because it was demonstrated it is highly correlated with the manual DUC coverage scores  .,1,original
Motivation Phrase-based statistical machine translation   has emerged as the dominant paradigm in machine translation research,1,original
Ochs procedure is the most widely-used version of MERT for SMT  .,1,original
"In recent several years, the system combination methods based on confusion networks developed rapidly  , which show state-of-the-art performance in benchmarks.",1,original
"They provide pairs of phrases that are used to construct a large set of potential translations for each input sentence, along with feature values associated with each phrase pair that are used to select the best translation from this set.1 The most widely used method for building phrase translation tables   selects, from a word alignment of a parallel bilingual training corpus, all pairs of phrases   that are consistent with the alignment.",1,original
"Many efficient techniques exist to extract multiword expressions, collocations, lexical units and idioms  .",1,original
Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars     and synchronous treesubstitutiongrammars  .,1,original
"METEOR was chosen since, unlike the more commonly used BLEU metric  , it provides reasonably reliable scores for individual sentences.",1,original
"Another interesting point is the relation to maximum entropy model  , which is popular in the natural language processing community.",1,original
"Since its introduction to the Natural Language Processing   community  , ME-based classifiers have been shown to be effective in various NLP tasks.",1,original
"Streptomyces are well known for their prolific production of antibiotics, which are thought to mediate species interactions  .",1,original
"It was initially proposed by   and, more recently, have been intensively studied by several research groups  .",1,original
"As can be seen, the temporal transition models provided by the HMMs result in about 5% performance gain in both state and environment tasks.",1,original
This new model leads to significant improvements in MT quality as measured by BLEU  .,1,original
"Firstly,   resorted to heuristics to extract the Stringto-Dependency trees, whereas our approach employs the well formalized CCG grammatical theory.",1,original
"Among recent top performing methods are Hidden Markov Models  , maximum entropy approaches  , and transformation-based learning  .",1,original
"General purpose text annotations, such as part-of-speech tags and noun-phrase bracketing, are costly to obtain but have wide applicability and have been used successfully to develop statistical NLP systems  .",1,original
"Recent papers   show that spatial max and average pooling of feature maps output by intermediate convolutional layers is an effective representation, and higher performance can be achieved compared to using fully connected layers.",1,original
"In addition, parsing re-ranking   has also been shown to be another effective technique to improve parsing performance.",1,original
Synchronization is the most commonly-used method  .,1,original
arowsky   successfully used this observation as an approximate annotation technique in an unsupervised WSD model,1,original
"Lexicalization can increase parsing performance dramatically for English  , and the lexicalized model proposed by Collins   has been successfully applied to Czech   and Chinese  .",1,original
"ICP-MS reports of sub-parts per billion detection limits, multielement analysis capabilities, and a wide linear dynamic range have made it an often used technique for wine elemental analysis  .",1,original
The beneficial role of PBM as supportive modality in the management of postmastectomy lymphedema is well established based on strong evidence  .,1,original
2 Background: MaxEnt Models Maximum Entropy   models are widely used in Natural Language Processing  .,1,original
Their idea has proven effective for estimating the statistics of unknown words in previous studies  .,1,original
"2.2 Maximum Entropy Models Maximum entropy   models  , also known as 928 log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.",1,original
2.2 Statistical Translation Lexicon We use a statistical translation lexicon known as IBM Model-1 in   for both efficiency and simplicity.,1,original
"The classification is performed with a statistical approach, built around the maximum entropy   principle  , that has the advantage of combining arbitrary types of information in making a classification decision.",1,original
"In the experiments, two popular benchmarks are used to evaluate the proposed method: the CohnKanade   facial expression databases.",1,original
"Coming from the other direction, such observations about phrase reordering between different languages are precisely thekindsoffactsthatparsingapproachestomachine translation are designed to handle and do successfully handle  .",1,original
"  describe a novel algorithm for entropy estimation for which they claim very fast convergence time; using no more than about five pages of text, they can achieve nearly the same accuracy as  .",1,original
"5.1 The statistical parser The parsing model is the one proposed in Merlo and Musillo  , which extends the syntactic parser of Henderson   and Titov and Henderson   with annotations which identify semantic role labels, and has competitive performance.",1,original
Two popular techniques that incorporate the error criterion are Minimum Error Rate Training     and Minimum BayesRisk   decoding  .,1,original
The Arriaga method is conceptually simple and easy to interpret and has been widely used to decompose life expectancy differences in the United States and elsewhere  .,1,original
"We note that although PSIPRED was not optimized for peptides, the resulting fragment libraries showed in practice good coverage of the peptide conformational space  .",1,original
…have also been particularly well investigated  .,1,original
"More rapid reporting by other technologies, such as detection of bacterial species and resistant markers in positive blood cultures by molecular probe and nucleic acid amplification do result in improved patient care  .",1,original
"…and valid across a number of studies  , displays good sensitivity and specificity  , is sensitive to changes over time   and is acceptable to administer over the phone  .",1,original
Their performance is presented in comparison to state-of-the-art methods such as original GNNS  .,1,original
"SEM is a powerful tool that allows for the relative effect of many explanatory factors on a response variable to be determined, even if many of the explanatory factors are correlated  .",1,original
  has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation   and related tasks  ; Agirre and Rigau The author was partially funded by GALE DARPA Contract No.,1,original
e also use Cube Pruning algorithm   to speed up the translation process,1,original
he Yarowsky   algorithm was one of the first bootstrapping algorithms to become widely known in computational linguistics,1,original
Turning off the extensions to GIZA++ and training p0 as in   produces a substantial increase in AER.,1,original
It has also produced promising results in language translation  .,1,original
"For a fair comparison, we try to reproduce experiment of state-of-theart method  on the same baseline network.",1,original
There is also substantial work in the use of target-side syntax  .,1,original
The state-of-theart systems have achieved an accuracy of 97% for English on the Wall Street Journal   corpus   using various models  .,1,original
"Among these, nanocarbons are now considered the most promising fillers for the development of high performance materials  .",1,original
"Minimizing risk has been shown to improve performance for MT  , as well as other language processing tasks  .",1,original
"It can also be considered as an extension from the monolingual to the bilingual case of the well-established methods for semantic or syntactic word clustering as proposed by Schtitze  , Grefenstette  , Ruge  , Rapp  , Lin  , and others.",1,original
"responsible on their own, and consider policy intervention a more effective solution  .",1,original
"Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O   and polarity classification  .",1,original
oped a new scoring system based on consensus between clinicians that allows better correspondence between the vastly adopted CBCL scale and the currently employed DSM-IV diagnostic criteria  .,1,original
"The most widely used are Word Error Rate  , Position Independent Word Error Rate  , the BLEU score   and the NIST score  .",1,original
"For example, non-local features such as same phrases in a document do not have different entity classes were shown to be useful in named entity recognition  .",1,original
"Recently, various works have improved the quality of statistical machine translation systems by using phrase translation  .",1,original
provide a promising physical framework to rationalize the high intrinsic enthalpic signatures of 15–40 kcal mol−1  ,1,original
"Competitors We compared the proposed SLST model with five state-of-the-art alternative detection approaches:   Faster R-CNN   method, exactly the same as our SLST model.",1,original
The table also shows the popular BLEU   and NIST2 MT metrics.,1,original
"The moonlighting functions of several canonical metabolic enzymes have been described in mammals, fungi, plants, and protozoa  .",1,original
"Indeed, researchers have shown that gigantic language models are key to state-ofthe-art performance  , and the ability of phrase-based decoders to handle large-size, high-order language models with no consequence on asymptotic running time during decoding presents a compelling advantage over CKYdecoders,whosetimecomplexitygrowsprohibitively large with higher-order language models.",1,original
" , but we use a maximum entropy classifier   to determine parser actions, which makes parsing extremely fast.",1,original
"Trials reported successful models of collaborative care which commonly involved a PCP, a mental health professional and a case manager  .",1,original
"We have chosen the Maximum Entropy tagger   for a comparison with our universal tagger, since it achieved   the best overall result on Slovene as reported there   of taggers available to us  .",1,original
"Also, in a, state-of-the-art English pa.rser   only the words tha, t occur more tha,n d times in training data.",1,original
Oxidized graphene nanomaterials were demonstrated to be able to serve as efficient carrier systems for the targeted delivery of chemical drugs  .,1,original
"Among all the automatic MT evaluation metrics, BLEU   is the most widely used.",1,original
Recent advanced templatebased approach   and new approaches with R2* to HU conversion   and zero-echotime   show similar results to our approach and/or great potential for further improvement of MR-AC.,1,original
The availability of the TER software has made it easy to build a high performance system combination baseline  .,1,original
"Extracting semantic information from word co-occurrence statistics has been effective, particularly for sense disambiguation  .",1,original
"1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models   have led to significant increases in machine translation accuracy.",1,original
"For instance, on unsupervised part-ofspeech tagging, EM requires over 100 iterations to reach its peak performance on the Wall-Street Journal  .",1,original
"To overcome the knowledge acquisition bottleneck problem suffered by supervised methods, these methods make use of a small annotated corpus as seed data in a bootstrapping process    .",1,original
"2 Translation Model The algorithm for fast translation, which has been described previously in some detail   and used with considerable success in TREC  , is a descendent of IBM Model 1  .",1,original
The steps of octasaccharide synthesis and modification are well-defined genetically  .,1,original
Two of themost important group of proteins involved in the cell cycle machinery are cyclins and cyclin-dependent kinases    .,1,original
Dukes   and Sinclair   concluded that the most accurate results in maintaining the vertical dimension of occlusion of dentures during processing were obtained with artificial stone and a layer of silicone rubber.,1,original
"High-performance taggers typically also include joint three-tag counts in some way, either as tag trigrams   or tag-triple features  .",1,original
"In an experiment on 16,800 sentences of Chinese-English newswire text with segment-level human evaluation from the Linguistic Data Consortium?s   Multiple Translation project, we compare the LFG-based evaluation method with other popular metrics like BLEU, NIST, General Text Matcher    , Translation Error Rate    1, and METEOR  , and we show that combining dependency representations with synonyms leads to a more accurate evaluation that correlates better with human judgment.",1,original
"1 Introduction The maximum entropy model   has attained great popularity in the NLP field due to its power, robustness, and successful performance in various NLP tasks  .",1,original
"Finally, ADMGA is compared with the previously proposed nAMGA, used in   to tackle a dynamic knapsack problem with good results.",1,original
"2.3 The Averaged Perceptron Reranking Model Averaged perceptron   has been successfully applied to several tagging and parsing reranking tasks  , and in this paper, we employed it in reranking semantic parses generated by the base semantic parser SCISSOR.",1,original
"1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data  .",1,original
This is conWrmed by the superior results of functional conservative or postsurgical treatment procedures in comparison to non-weight bearing plaster cast immobilisation  .,1,original
A popular metric for evaluating machine translation quality is the Bleu score  .,1,original
"In this paper, we show that a noisy channel model instantiated within the paradigm of Statistical Machine Translation     can successfully provide editorial assistance for non-native writers.",1,original
"Among all the language modeling approaches, ngram models have been most widely used in speech recognition   and other applications.",1,original
The Actigraph accelerometer   has been extensively and successfully used to assess physical activity in children in both small   epidemiological studies.,1,original
"The RDCs have been successfully applied in the refinement of protein structures  , nucleic acids   and protein– RNA complexes  .",1,original
Both the alleviation of fluid overload   as well as the provision of this necessary volume in the form of medications improve outcomes and mortality risk.,1,original
"Ruby   goes one step further by making the syntax much more compact and simpler and also provides various built-in features that make the common tasks of text processing, creating and processing threads, web programming etc.",1,original
"Since it loosely links the two sentences syntactic structures, QG is well suited for problems like word alignment for MT   and question answering  .",1,original
Some notable efforts in this direction for other languages have been the Penn Tree Bank   for English and the Prague Dependency Bank   for Czech.,1,original
"Building on   and inspired by the nonconvexity challenge of PSSE, the goal of this paper is to develop a polynomial-time SE solver for AC power networks, which also features competitive statistical performance.",1,original
ROUGE   has been widely used for summarization evaluation.,1,original
"A simple, yet high performing approach for mapping a given surface form  , to its corresponding DBpedia   entity is to link to its most frequent candidate entity Mihalcea and Csomai  . Even though this approach does not take any context information into account, it has proven to be effective not only for text entity linking, but also for Nell triple linking (Dutta et al.",1,original
"Among the various knowledge-based   and data-driven   word sense disambiguation methods that have been proposed to date, supervised systems have been constantly observed as leading to the highest performance.",1,original
We discretise the gradient descent equation   on a regular grid using finite differences and solve it efficiently using the recently proposed fast explicit diffusion    .,1,original
"DTI derived diffusion parameters, such as fractional anisotropy  , have been widely used to assess white matter microstructure  .",1,original
This scoring function has been successfully applied to resolve ambiguity problems in an English-to-Chinese machine translation system     and a spoken language processing system  .,1,original
"Such methods can achieve better performance, reaching tagging accuracy of up to 85% on unknown words for English  .",1,original
"Examples of the latter include providing suggestions from a machine labeler and using extremely cheap human labelers, e.g. with the Amazon Mechanical Turk  .",1,original
"…tool which provides enhanced capabilities for peptide sequencing directly from samples such as nervous tissues or even single cells of invertebrates, including those of insects  .",1,original
"Local adaptation may, however, be inferred in several ways, one of the most widely used being reciprocal translocation studies, where different populations are reared in a reciprocal manner in their locations of origin  .",1,original
By taking a qualitative approach to this part of the study and targeting registered nurses with appropriate experiences the study’s credibility was strengthened  .,1,original
"The creation of the Penn English Treebank  , a syntactically interpreted corpus, played a crucial role in the advances in natural language parsing technology   for English.",1,original
"Urine in humans typically contains 10–30% inorganic arsenic, 10–20% MMA, and 60–80% DMA, indicating relatively efficient methylation  .",1,original
"1 Introduction Todays statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see  .",1,original
"For subproblem  , we have devised a new method, based on LPR, which has some good properties not shared by the methods proposed so far  .",1,original
"The technique of averaging was introduced in the context of perceptrons as an approximation to taking a vote among all the models traversed during training, and has been shown to work well in practice  .",1,original
"This well-established rhythm of swimming on ebb tides is the basis for the spawning migration  , in which ovigerous female blue crabs migrate seaward from estuaries to coastal areas where larvae are released.",1,original
Dasgupta and Ng   improves over   by suggesting a simpler approach.,1,original
  showed that the above optimization can be performed efficiently by sorting the samples xk in descending order of the score w ψ .,1,original
"Global information is known to be useful in other NLP tasks, especially in the named entity recognition task, and several studies successfully used global features  .",1,original
"  We note that these posterior probabilities can be computed efficiently for some alignment models such as the HMM  , Models 1 and 2  .",1,original
"Substantial improvements have been made to parse western language such as English, and many powerful models have been proposed  .",1,original
"Geneexpression-based classifiers have been frequently explored in recent years for several pathologic conditions, and resulted in FDA-approved diagnostics for early breast cancer  .",1,original
"As reported in  , parameter averaging can effectively avoid overfitting.",1,original
"…demonstrated that blocking MST1/2 kinase activities with a newly identified compound, 4- amino)benzenesulfonamide  , has benefits for intestinal and liver repair and regeneration in mice  .",1,original
Workshops supplemented by ongoing feedback or supervision does result in sustained improvements in counselor practice  .,1,original
"Randomized controlled trials conducted in a range of surgical settings over the last 25 years have clearly demonstrated that enoxaparin is associated with lower rates of VTE than placebo or elastic compression, without compromising patient safety  .",1,original
"NJ 08903 U.S.A. suzanne~ruccs, rutgers, edu Empirically-induced models that learn a linguistically meaningflll grammar   seem to give tile best practical results in statistical natural language processing.",1,original
"In addition, the averaged parameters technology   is used to alleviate overfitting and achieve stable performance.",1,original
"Even with incidence of this tendinosis of the insertion in a fresh, distal rupture, good experiences were seen with the transcalcaneal pDI suture technique  .",1,original
One popular and statistically appealing such measure is Log-Likelihood    .,1,original
"In order to overcome this problem, we look to the bootstrapping method outlined in  .",1,original
Quality of the analyzed RNA samples was evaluated using electropherograms obtained from microcapillary electrophoresis microcapillary electrophoretic RNA separation   showed higher sensitivity for the assessment of RNA quality  .,1,original
"The averaged version of the perceptron  , like the voted perceptron  , reduces the effect of over-training.",1,original
"This is an important feature from the MT viewpoint, since the decomposition into translation model and language model proved to be extremely useful in statistical MT since  .",1,original
he default training set of Penn Treebank   was used for the parser because the domain and style of those texts actually matches fairly well with the domain and style of the texts on which a reading level predictor for second language learners might be used,1,original
"Semantic collocations are harder to extract than cooccurrence patterns--the state of the art does not enable us to find semantic collocations automatically t. This paper however argues that if we take advantage of lexicai paradigmatic behavior underlying the lexicon, we can at least achieve semi-automatic extraction of semantic collocations   I But note the important work by Hindle \  on extracting semantically similar nouns based on their substitutability in certain verb contexts.",1,original
The most commonly used MT evaluation metric in recent years has been IBM?s Bleu metric  .,1,original
Decomposing the translational equivalence relations in the training data into smaller units of knowledge can improve a models ability to generalize  .,1,original
"It can be expected that the log-likelihood ratio produces an accurate ranking of word pairs that highly correlates with human judgment  , although there are other measures which come close in performance  .",1,original
"Hou et al.   report the state-of-the-art performance for fine-grained IS classification on ISNotes using collective classification. They explore a wide range of features  , including a large number of lexico-semantic features as well as a couple of surface features and syntactic features. Hou et al.   observe that bridging anaphors are rarely marked by surface features.",1,original
1 Introduction State-of-the-art Statistical Machine Translation   systems usually adopt a two-pass search strategy   as shown in Figure 1.,1,original
The phrase-based approach developed for statistical machine translation   is designed to overcome the restrictions on many-tomany mappings in word-based translation models.,1,original
"In the supervised setting, a recent paper by Daume III   shows that, using a very simple feature augmentation method coupled with Support Vector Machines, he is able to effectively use both labeled target and source data to provide the best results in a number of NLP tasks.",1,original
"Throughout, the likelihood ratio   is used as significance measure because of its stable performance in various evaluations, yet many more measures are possible.",1,original
are the most widely studied as sources of insecticidal and/or repellent oils and are also the ones most commonly found in commercial formulations for this purpose  .,1,original
rk   compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and Lin  s information-theoretic metric work best,1,original
"However, recent progress in machine translation and the continuous improvement on evaluation metrics such as BLEU   suggest that SMT systems are already very good at choosing correct word translations.",1,original
"The parsers with the highest published broad-coverage parsing accuracy, which include Charniak  , Collins  , and Ratnaparkhi  , all utilize simple and straightforward statistically based search heuristics, pruning the search-space quite dramatically.",1,original
"Bleu is fast and easy to run, and it can be used as a target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical MT systems  .",1,original
"In previous work, we tested the DOP method on a cleaned-up set of analyzed part-of-speech strings from the Penn Treebank  , achieving excellent test results  .",1,original
"Glycyrrihzin, 18βglycyrrhetinic acid and liquiritigenin individually were able to ease itchiness and lower ovalbumininduced elevated IgE level  .",1,original
1 Introduction Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation    .,1,original
Promising features might include those over source side reordering rules   or source context features  .,1,original
  presented randomized language model based on perfect hashing combined with entropy pruning to achieve further memory reductions.,1,original
Transanal minimally invasive surgery   has emerged as an important alternative to transanal endoscopic microsurgery   capable of providing highquality local excision for rectal neoplasia  .,1,original
Here we choose to work with stupid backoff smoothing   since this is significantly more efficient to train and deploy in a distributed framework than a contextdependent smoothing scheme such as Kneser-Ney.,1,original
"  and   shows how some of the methods which have been used in the past   are invalid for rare events, and introduce accurate measures of how 'surprising' rare events are.",1,original
The effort to develop new treatments for ALS has led to repeated failure since the demonstration that riluzole extended survival.  the recent negative results of the dexpramipexole Phase III study is yet another disappointing example.,1,original
"Today, naltrexone is often considered an effective and recommendable medication for gambling addiction  .",1,original
"1 Introduction The rapid and steady progress in corpus-based machine translation   has been supported by large parallel corpora such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium and the Europarl corpus  , which consists of 11 European languages.",1,original
A few widely-used peak callers include MACS  .,1,original
An especially well-founded framework is maximum entropy  .,1,original
The first one is the widely publicized Landau benchmark transmission system  : a tracking problem with a step disturbance rejection objective in an essentially noise-free environment.,1,original
"Many techniques for bone defatting are described in the literature, including mechanical cleaning with water or air jet,  acetone ⁄ ethanol solution,  enzyme detergents,  hydrogen peroxide,  aqueous sodium hydroxide,  and sodium hypochlorite  .  We adopted the latter technique, because it has been found suitable for formalinized specimens,  is safe for personnel and is very low cost.",1,original
"3 Space-Efficient Approximate Frequency Estimation Prior work on approximate frequency estimation for language models provide a no-false-negative guarantee, ensuring that counts for n-grams in the model are returned exactly, while working to make sure the false-positive rate remains small  .",1,original
"In this regard, one promising technique that has been considered is to employ variable forgetting factor   mechanisms to adjust the forgetting factor automatically  .",1,original
"The results are quite promising: our extraction method discovered 89% of the WordNet cousins, and the sense partitions in our lexicon yielded better  values   than arbitrary sense groupings on the agreement data.",1,original
"For the full parser, we use the one developed by Michael Collins    one of the most accurate full parsers around.",1,original
"Similar survey results in Kentucky showed that the high-stakes, performance-based assessments in writing and mathematics strongly influenced teachers to make their instruction more consistent with the state curriculum in these areas  .",1,original
1 Introduction Large scale annotated corpora such as the Penn TreeBank   have played a central role in speech and natural language research.,1,original
"We estimate loss gradients   using a sample of the inference set, which gives a 100-fold increase in training speed  .",1,original
"1 Introduction Och   introduced minimum error rate training   for optimizing feature weights in statistical machine translation   models, and demonstrated that it produced higher translation quality scores than maximizing the conditional likelihood of a maximum entropy model using the same features.",1,original
"The core technology of the proposed method, i.e., the automatic evaluation of translations, was developed in research aiming at the efficient development of Machine Translation   technology  .",1,original
"In particular, the STEAM platform is an interesting exam­ple of event-based  middleware for ad hoc networks, provid­ing location-aware message delivery and an e.ective solution for  event .ltering.",1,original
"For instance, mutual information   and the log-likelihood   methods for extracting word bigrams have been widely used.",1,original
Point-wise mutual information   and Relative Feature Focus   are well-known examples.,1,original
Arguably the most widely used is the mutual information  .,1,original
"The Penn Treebank   has until recently been the only such corpus, covering 4.5M words in a single genre of financial reporting.",1,original
"We have been using the output of word_align, a robust alignment program that proved useful for bilingual concordancing of noisy texts  .",1,original
"Other alternatives include an extension of the well-known   evolution strategy   for mixed integer problems, MIES   and the covariance matrix adaptation evolutionary strategy CMA-ES  .",1,original
"Because of this property, vector space models have been used successfully both in computational linguistics   and in cognitive science  .",1,original
"To evaluate the quality of our generated summaries, we choose to use the ROUGE3   evaluation toolkit, that has been found to be highly correlated with human judgments.",1,original
1 Introduction The last years have seen a boost of work devoted to the development of machine learning based coreference resolution systems  .,1,original
"3 Extending Bleu and Ter with Flexible Matching Many widely used metrics like Bleu   and Ter   are based on measuring string level similarity between the reference translation and translation hypothesis, just like Meteor . Most of them, however, depend on finding exact matches between the words in two strings.",1,original
Oxytocin is famous for its pleiotropic activities including induction of labor and influences on social behaviors  .,1,original
"Many machine learning techniques have been developed to tackle such random process tasks, which include Hidden Markov Models    , Maximum Entropy Models    , Support Vector Machines    , etc. Among them, SVMs have high memory capacity and show high performance, especially when the target classification requires the consideration of various features.",1,original
"Our similarity method is similar, but simpler, to that used by  , which report very good results on similarity datasets.",1,original
"In our experience, this approach is advantageous in terms of translation quality, e.g. by 0.7% in BLEU compared to a minimum Bayes risk primary  .",1,original
The lasers most frequently used in endodontic therapy are the Nd:YAG laser   and erbium lasers   due to their microbial reduction potential  .,1,original
"Recently, word-sense disambiguation   methods have been shown to improve translation quality  .",1,original
"Insects are ideal systems to investigate the interplay between infection and behavior.  The fruit fly Drosophila is especially amenable to these studies, as it is one of the best developed model systems for host-pathogen interactions  and behavioral ecology and genetics.",1,original
"1 Introduction Phrase-based approaches   to statistical machine translation   have recently achieved impressive results, leading to significant improvements in accuracy over the original IBM models  .",1,original
"Parallelization with GNU parallel  To get the subset of results related to the e-commerce packages of interest, we merged the top 40 list provided by Robertshaw, the top ten of builtwith.comand the leading systemsfrom the Gartner and Forresterreports, as already mentioned.",1,original
"4 Conclusions Compared with other word alignment algorithms  , word_align does not require sentence alignment as input, and was shown to produce useful alignments for small and noisy corpora.",1,original
"Unsupervised approaches are attractive due to the the availability of large quantities of unlabeled text, and unsupervised morphological segmentation has been extensively studied for a number of languages  .",1,original
"3.6 Parameter Estimation To estimate parameters k , lm, and um, we adopt the approach of minimum error rate training   that is popular in SMT  .",1,original
The PHQ-2   is a screening measure of depression that has been well studied and has been traditionally used in primary care settings  .,1,original
"Two metrics have become quite popular in multi-document summarization, namely the Pyramid method   and ROUGE  .",1,original
"Furthermore, it has been shown that tocilizumab has an excellent ability to suppress serum amyloid A levels and could therefore be an important therapeutic strategy in amyloid A amyloidosis secondary to rheumatic diseases  .",1,original
"Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites  , all based on tim notion of abduction, and we have begun to explore its potential application to machine translation.",1,original
Lysine diisocyanate based degradable polyurethanes have been found to be biocompatible materials with potential uses in drug delivery systems  .,1,original
"we use the perceptron-like algorithm proposed in   which does not suffer from the label bias problem, and is fast in training.",1,original
We are starting to see the beginnings of a positive effect of WSD in NLP applications such as Machine Translation  .,1,original
"Among these methods, CRFs is the most common technique used in NLP and has been successfully applied to Part-of-Speech Tagging  , Named-Entity Recognition   and shallow parsing  .",1,original
Such a method alleviates the problem of creating templates from examples which would be used in an ulterior phase of generation  .,1,original
"5 Analysis Over the last few years, several automatic metrics for machine translation evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle  .",1,original
Experiments show that the resulting rule set significantly improves the speed and accuracy over monolingual binarization   in a stateof-the-art syntax-based machine translation system  .,1,original
"This provides a compelling advantage over previous dependency language models for MT  ,whichusea5-gramLMonlyduringreranking.",1,original
"Polar coding has also proven to be a versatile coding method capable of achieving the information-theoretic limits in a wide range of source and channel coding problems; for a representative list of such work, we cite  .",1,original
Some tasks can thrive on a nearly pure diet of unlabeled data  .,1,original
"…for remediation of runoff from agricultural irrigation and agro-industrial production has become increasingly popular over the last decades, due to their low capital and operational cost, low energy consumption, and environmental friendliness  .",1,original
One of the advantages of these methods is that a wide variety of features such as dependency trees and sequences of words can easily be incorporated  .,1,original
"3 The Syntactic and Semantic Parser Architecture To achieve the complex task of joint syntactic and semantic parsing, we extend a current state-of-theart statistical parser   to learn semantic role annotation as well as syntactic structure.",1,original
1 Introduction Modern phrasal SMT systems such as   derive much of their power from being able to memorize and use long phrases.,1,original
A growing number of animal studies showed that imaging or therapeutic agents larger than the BBB’s exclusion threshold of 400 Da could be successfully delivered by FUS with microbubbles  .,1,original
"In addition, the perceptron algorithm and its variants, e.g., the voted or averaged perceptron, is becoming increasingly popular due to their competitive performance, simplicity in implementation and low computational cost in training  .",1,original
"They have been successfully applied in several tasks, such as information retrieval   and harvesting thesauri  .",1,original
"Ranking algorithms, such as Kleinbergs HITS algorithm   or Googles PageRank  , have been traditionally and successfully used in Web-link analysis  , social networks, and more recently in text processing applications  ,  ,  .",1,original
"The Light Age Q-Clear has a pulse duration in nanoseconds, achieving the highest energy density per pulse of all the Nd:YAG lasers  .",1,original
Empirically the BLEU score has a high correlation with human evaluation when N = 4 for English translation evaluations  .,1,original
Encouraging analytic results and some Monte Carlo simulations of the CP 1 model have been reported in  .,1,original
"Phrase-based models   have been a major paradigm in statistical machine translation in the last few years, showing state-of-the-art performance for many language pairs.",1,original
Previous work for English   has shown that lexicalization leads to a sizable improvement in parsing performance.,1,original
"Averaged perceptron  , which has been successfully applied to several tagging and parsing reranking tasks: The performance of the baseline model SCISSOR+ compared with SCISSOR  .",1,original
"The feature combinations play an essential role in obtaining a classifier with state-of-the-art accuracy for several NLP tasks; recent examples include dependency parsing  , parse re-ranking  , pronoun resolution  , and semantic role labeling  .",1,original
"While there have been remarkable developments in the last ten years  , structuring large-scale visual data is still an active research area and any improvements would have wide applicability.",1,original
"Some NLG researchers are impressed by the success of the BLEU evaluation metric   in Machine Translation  , which has transformed the MT field by allowing researchers to quickly and cheaply evaluate the impact of new ideas, algorithms, and data sets.",1,original
This averaging effect has been shown to help overfitting  .,1,original
Many authors have replicated similar results with this technique and supraclavicular nerve grafting has become the standard surgical approach for these patients  .,1,original
Perhaps the best established function of mammalian ChREBPMlx is promotion of de novo lipogenesis in response to high carbohydrate intake  .,1,original
"Adding resistance exercise, however, appears more useful than moderate aerobic exercise alone in protecting diet-induced losses in LBM  .",1,original
"Biological hydrogen production via anaerobic fermentation is renewable, and may be sustainable and energy efficient  .",1,original
…of NMDAR antagonists have been suggested to be highly useful models of the cognitive impairment in schizophrenia  .,1,original
"GIZA++   is a very popular system within SMT for creating word alignment from parallel corpus, in fact, the Moses training scripts uses it.",1,original
"4 Machine Translation Experiments 4.1 Experimental Setting For our MT experiments, we used a reimplementation of Moses  , a state-of-the-art phrase-based system.",1,original
"It worked well for word segmentation alone  , even with an agenda size as small as 8, and a simple beam search algorithm also works well for POS tagging  .",1,original
One possible approach is to employ state-of-the-art techniques for coreference and zeroanaphora resolution   in preprocessing cooccurrence samples.,1,original
7.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient whichiswidelyused in computational linguistics for measuring agreement in category judgments  .,1,original
"Research in this direction was pioneered by  , who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings.",1,original
"For example,   shows that training a learning algorithm on the weighted union of different data sets   performs almost as well as more involved domain adaptation approaches.",1,original
The most widely used association weight function is   Mutual Information    .,1,original
This has been the driving force for the active research in the development of advanced control techniques and hierarchical control schemes to improve the operation of the WWTPs  .,1,original
"We examine the effectiveness of Structural Correspondence Learning     for this task, a recently proposed adaptation technique shown to be effective for PoS tagging and Sentiment Analysis.",1,original
"Due to this data sparsity problem, state-of-the-art systems for NER in morphologically rich languages usually make use of the analysis of the morphological structures of the languages and require language specific feature engineering  .",1,original
"In previous experiments, intravenous lipid emulsions have been shown to ameliorate the toxicity of a number of lipid soluble agents  .",1,original
"edu/eeglab); this procedure was extremely effective in decomposing the signals into multiple statistically independent components, allowing artifacts to be easily detected  .",1,original
"As agreement measure we choose the Kappa coefficient   , the agreement measure predominantly used in natural language processing research  .",1,original
This method led to improvement in the decoding speed as well as the output accuracy for English POS tagging  .,1,original
"3 Experiments We evaluated the effect of random feature mixing on four popular learning methods: Perceptron, MIRA  , SVM and Maximum entropy; with 4 NLP datasets: 20 Newsgroups1, Reuters  , Sentiment   and Spam  .",1,original
The most widely used approach derives phrase pairs from word alignment matrix  .,1,original
Synchronous parsing models have been explored with moderate success  .,1,original
"Intensive efforts to reduce tobacco use have also been conducted by the government and public health professionals, leading to the implementation of strong and effective tobacco control policies and measures, such as tobacco tax increases, media campaigns, and ratification of Framework Convention on Tobacco Control  .",1,original
"For some PESP-models, the genetic algorithm that has been proposed by Nachtigall and Voget  , constitutes a competitive alternative  .",1,original
"We view this as a particularly promising aspect of our work, given that phrase-based systems such as Pharaoh   perform better with higher recall alignments.",1,original
"Discriminative learning methods, such as Maximum Entropy Markov Models  , Projection Based Markov Models  , Conditional Random Fields  , Sequence AdaBoost  , Sequence Perceptron  , Hidden Markov Support Vector Machines   and Maximum-Margin Markov Networks  , overcome the limitations of HMMs.",1,original
Previous work has demonstrated that this scoring function is able to provide high discrimination power for a variety of applications  .,1,original
" , Pedersen  , Yarowsky and Florian  ) as well as maximum entropy models  , Klein and Manning  ) in particular have shown a large degree of success for WSD, and have established challenging state-of-the-art benchmarks.",1,original
One of the most successful metrics for judging machine-generated text is BLEU  .,1,original
"Aside from purely linguistic interest, bracket structure has been empirically shown to be highly effective at constraining subsequent training of, for example, stochastic context-free grammars  .",1,original
"It was rolled out nationally in 2006 with funding of €55 million, after being successfully piloted in a small number of locations between 2001 and 2004  .",1,original
"Compared with typical antipsychotics, second-generation atypical antipsychotics have more acceptable side effect profiles and possibly broader symptom efficacy, especially concerning negative symptoms, thus advancing the treatment of schizophrenic patients  .",1,original
…in the protein used in this study   when compared with other sequences including V. riparia   and V. vinifera   that have been successfully used in gene transfer experiments.,1,original
"1 Introduction When data have distinct sub-structures, models exploiting latent variables are advantageous in learning  .",1,original
Dermoscopy is cost-effective and its use increases the diagnostic accuracy by 5-30% over visual inspection  .,1,original
"A well-known method for use in these situations is the “randomized response technique”  , introduced by Warner  .",1,original
"Penn Treebank  was also used to induce part-of-speech   taggers because the corpus contains very precise and detailed POS markers as well as bracket, annotations.",1,original
This was recently followed by   who introduce state-of-the-art nearly unlexicalized PCFG parsers.,1,original
"Match kernels defined over various pixel attributes provide a unified way to generate a rich, diverse visual feature set, which has been shown to be very successful to boost recognition accuracy  .",1,original
"Our model exploits the same kind of tag-n-gram information that forms the core of many successful tagging models, for example,  ,  ,  .",1,original
"…study where similar P. falciparum growth inhibition was obtained  , in proliferation inhibition studies with mammalian cells, belinostat has been shown to be up to 11-fold more active than vorinostat  .",1,original
"…the second most stably expressed gene identified in our study, α-tub, has been shown to be stably expressed during development in Orobanche  , cucumber  , sunflower  , and aphid infestation of chrysanthemum  .",1,original
"1 Introduction One of the major approaches to disambiguate word senses is supervised learning  ,  ,  ,  ,  ,  ,  ,  .",1,original
Almost all of the commonly used neural simulation packages now have a Python interface  .,1,original
"2.2.2 The Binomial Log Likelihood Ratio as a Statistical Filter Dunning   demonstrates the benefits of the LLR statistic, compared to Pearson's chisquared, on the task of ranking bigram data.",1,original
n efficient algorithm for performing this tuning for a larger number of model parameters can be found in Och  ,1,original
"It could be shown that such methods, of which BLEU   is the most common, can deliver evaluation results that show a high agreement with human judgments  .",1,original
1 Introduction The Maximum Entropy   statistical framework   has been successfully deployed in several NLP tasks.,1,original
"We tested model performance using the area under the receiver operating curve   statistic, which gives a measure of ability to discriminate between observed presences and absences, and has been widely applied  .",1,original
"2 Evaluation Metrics Currently, the most widely used automatic MT evaluation metric is the NIST BLEU-4  .",1,original
2 Related Work Supervised machine learning methods including Support Vector Machines   are often used in sentiment analysis and shown to be very promising  .,1,original
Several general-purpose off-the-shelf   parsers have become widely available  .,1,original
"Similar results were obtained by Chiarella and his colleagues, who compared single and multiplex immunization strategies and showed that the latter was the most effective  .",1,original
"Recently, graph-based methods have proved useful for a number of NLP and IR tasks such as document re-ranking in ad hoc IR   and analyzing sentiments in text  .",1,original
is more dialectical and better able to accommodate coexisting opposites    .,1,original
"Interestingly, one of the top canonical pathways that was utilized by the EPCs was the mTOR signaling pathway, which is important for the maintenance of embryonic stem cells and is embryonically lethal when knocked-out  .",1,original
The default synthetic voice that we used featured a well established corpus-based prosodic model  .,1,original
"On the other hand, the best available parsers trained on the Penn Treebank, those of Collins   and Charniak  , use statistical models for disambiguation that make crucial use of dependency relations.",1,original
014 roviding important information for surgical management nd postoperative outcomes for patients with ERM.  pectral-domain OCT   is a new technology that has een demonstrated recently.,1,original
"This problematic situation was alleviated by viewing the scanned areas with a wider window, such as a bone setting.  The author of case series of human patients stated that as the window width was increased, the foreign bodies were more easily identified and better differentiated from a gas or fluid build up due to the wood’s absorptive characteristics and the duration of the injury.",1,original
"Recently there have been some improvements to the Charniak parser, use n-best re-ranking as reported in   and selftraining and re-ranking using data from the North American News corpus   and adapts much better to the Brown corpus  .",1,original
"10Our experiments have shown that using averaging helps tremendously, confirming both the theoretical and practical results of  .",1,original
"Sentences are parsed using the MST dependency parser  , which implements the Eisner algorithm   for dependency parsing, and provides an efficient and robust performance.",1,original
"1 Introduction Corpus-derived distributional semantic spaces have proved valuable in tackling a variety of tasks, ranging from concept categorization to relation extraction to many others  .",1,original
MP measurements were obtained with a modified confocal scanning laser ophthalmoscope     using autofluorescence images obtained at two excitation-wavelength based on the pioneering work of Delori et al.,1,original
2.3 Classifier Training We chose maximum entropy   as our primary classifier because the highest performing systems in both the SemEval-2007 preposition sense disambiguation task   and the general word sense disambiguation task   used it.,1,original
" , various classification models and linguistic features have been proposed to improve the classification performance  .",1,original
The abduction-based approach   has provided a simple and elegant way to realize such a task.,1,original
"Annealing  resembles the popular bootstrapping technique  , which starts out aiming for high precision, and gradually improves coverage over time.",1,original
The results obtained by our mean field reconstruction gives the high quality reconstructed image as much as one reconstructed by Roth and Black’s simple gradient method.,1,original
"The most notable of these include the trigram HMM tagger  , maximum entropy tagger  , transformation-based tagger  , and cyclic dependency networks  .",1,original
"Recently, Ponzetto and Strube   suggest to mine semantic relatedness from Wikipedia, which can deal with the data sparseness problem suffered by using WordNet.",1,original
"In particular,   presents very strong results using a distributional-similarity module and achieve impressive tagging accuracy while starting with a mere 116 prototypical words.",1,original
"We employed three modelling approaches that have successfully been applied in previous studies on species distribution  : generalised linear models  , generalised additive models  , and classification and regression trees‚Ä¶",1,original
"Finally, to estimate the parameters i of the weighted linear model, we adopt the popular minimum error rate training procedure   which directly optimizes translation quality as measured by the BLEU metric.",1,original
"Following the state-of-the-art technique for exploratory data analysis  , we decided to opt for unsupervised clustering. The chosen normalized spectral clustering algorithm proposed by Ng et al.   has been effectively applied to various lexical acquisition tasks  ; Xu & Ke  ; Sun & Korhonen  ).",1,original
"  regarded MWE as connected collocations: a sequence of neighboring words whose exact meaning cannot be derived from the meaning or connotation of its components, which means that MWEs also have low ST. As some pioneers provide MWE identiflcation methods which are based on association metrics  , such as likelihood ratio  .",1,original
"Tools like Xtract   were based on the work of Church and others, but made a step forward by incorporating various statistical measurements like z-score and variance of distribution, as well as shallow linguistic techniques like part-of-speech tagging and lemmatization of input data and partial parsing of raw output.",1,original
"1 Introduction Over the last few years, several automatic metrics for machine translation   evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle  .",1,original
"Particularly, syntactically annotated corpora  , such as Penn Treebank  , Negra Corpus   and EDR Corpus  , contribute to improve the performance of morpho-syntactic analysis systems.",1,original
"The best examples of this approach has been the resent work of Yarowsky  ,  ,  .",1,original
"Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus  , the task is performed with greater efficiency and is easily portable to new languages in a supervised manner  .",1,original
ther insights borrowed from the current state of the art include minimum-error-rate training of log-linear models   and use of an m-gram language model,1,original
"7Another related measure is Dunning  's likelihood ratio tests for binomial and multinomial distributions, which are claimed to be effective even with very much smaller volumes of text than is necessary for other tests based on assumed normal distributions.",1,original
  reported very high results   for unsupervised POS tagging using Hidden Markov Models   by exploiting hand-built tag dictionaries and equivalence classes.,1,original
he latent-annotation model   is one of the most effective un-lexicalized models,1,original
"To this end, we use the 50 documents dataset from Lee et al.     which is widely-used for evaluating semantic document similarity and thus enables us to compare our method against other state-of-the-art systems.",1,original
Some of the more popular and more accurate of these approaches to data-driven parsing   have been based on generative models that are closely related to probabilistic contextfree grammars.,1,original
"Maximum entropy taggers have been shown to be highly competitive on a number of tagging tasks, such as partof-speech tagging  , and namedentity recognition (Borthwick et.",1,original
"Widely used alignment models, such as IBM Model serial   and HMM , all assume one-to-many alignments.",1,original
Preclinical work by Dyrby et al.   highlights the benefits of such strong gradients and the first results from the Connectome scanner   are now starting to verify those findings.,1,original
2 Parsing Model The Berkeley parser   is an efficient and effective parser that introduces latent annotations   to refine syntactic categories to learn better PCFG grammars.,1,original
"In recent years, reranking techniques have been successfully applied to the so-called history-based models  , especially to parsing  .",1,original
"In the well-known so-called IBM word alignment models  , re-estimating the model parameters depends on the empirical probability P  for each sentence pair  .",1,original
"The MERT module is a highly modular, efficient and customizable implementation of the algorithm described in  .",1,original
"Another widely used discriminative method is the perceptron algorithm  , which achieves comparable performance to CRFs with much faster training, so we base this work on the perceptron.",1,original
"The myocardial performance index   was calculated from the pulsed-wave tissue Doppler tracings, which have been shown to correlate with values from spectral Doppler tracings with similar diagnostic value  .",1,original
1 Introduction State-of-the-art part of speech   tagging accuracy is now above 97% for newspaper text  .,1,original
  use cascaded processing for full parsing with good results.,1,original
"…the same dose range, produces significant anti-epileptic  , anti-nociceptic  , and anti-addictive effects  .",1,original
1 Introduction The best performing systems for many tasks in natural language processing are based on supervised training on annotated corpora such as the Penn Treebank   and the prepositional phrase data set first described in  .,1,original
"2.2 Motivation from previous work 2.2.1 Parsing In recent years, the success of statistical parsing techniques can be attributed to several factors, such as the increasing size of computing machinery to accommodate larger models, the availability of resources such as the Penn Treebank   and the success of machine learning techniques for lowerlevel NLP problems, such as part-of-speech tagging  , and PPattachment  .",1,original
To estimate the parameters of the MEMM+pred model we turn to the successful Maximum Entropy   parameter estimation method.,1,original
"For our experiments, we chose GIZA++   and the RA approach   the best known alignment combination technique as our initial aligners.1 4.2 TBL Templates Our templates consider consecutive words   in both languages.",1,original
These molecules may replace some expensive growth factors and are promising for standardization of ESC cultivation  .,1,original
"Recent work,  , has shown that adding many millions of words of machine parsed and reranked LA Times articles does, in fact, improve performance of the parser on the closely related WSJ data.",1,original
"Lately, interesting reports have been issued on prognostic significance of beta-catenin nuclear expression in colon cancers  .",1,original
"To evaluate the performance of the proposed SDQI, seven state-of-the-art methods BRISQUE   have been compared objectively and subjectively.",1,original
"Recent several years have witnessed the rapid development of system combination methods based on confusion networks  ), which show state-of-theart performance in MT benchmarks.",1,original
rute-force methods   may well produce some useful results  ,1,original
Models that can handle non-independent lexical features have given very good results both for part-of-speech and structural disambiguation  .,1,original
"…different site between SMN1 and SMN2 is shown in black ic position; REF, reference allele of the SNPs; ALT, alternative allele of the SNPs; H, widely applied in clinics  .",1,original
"They are latent variable models which are not tractable to compute exactly, but two approximations exist which have been shown to be effective for constituent parsing  .",1,original
Recent advancements in machine learning algorithms have significantly enhanced parsing capabilities through the utilization of stochastic models for context-dependent grammar rules.,1,new
Probabilistically grounded approaches to part-of-speech tagging have yielded substantial improvements over traditional rule-based methods in numerous natural language processing tasks.,1,new
"By leveraging generative adversarial networks, researchers have successfully developed novel techniques for accurately modeling complex linguistic structures within sentence dependencies.",1,new
"Their innovative approach combines elements from both the probabilistic suffix tree model and the memory-based machine translation method, yielding superior performance compared to individual components alone.",1,new
"This comprehensive review synthesizes insights gained from previous research by Huang et al.'s statistical model and Li's rule-based system, ultimately leading to enhanced accuracy in syntactic parsing tasks.",1,new
"By integrating key features of the decision-tree parser and the maximum entropy model, their proposed algorithm demonstrates improved efficiency and effectiveness over traditional parsing techniques.",1,new
Previous studies have demonstrated that various machine learning techniques possess inherent advantages and disadvantages when applied to complex problems.,1,new
A comprehensive review of existing research has highlighted the trade-offs associated with both manual and automated methods for data analysis.,1,new
Comparative evaluations have consistently revealed that hybrid models exhibit some benefits while also introducing potential drawbacks due to increased complexity.,1,new
"Deep reinforcement learning models have demonstrated remarkable success across various computer vision applications, such as image classification, object detection, segmentation, scene understanding, action recognition, activity forecasting, facial landmark localization, and depth estimation.",1,new
"Hybrid approaches combining symbolic and connectionist architectures have shown impressive performance on numerous knowledge representation tasks like question answering, semantic role labeling, coreference resolution, named entity recognition, dependency parsing, topic modeling, event extraction, and relation extraction.",1,new
"Ensemble methods incorporating both traditional and deep learning techniques have achieved state-of-the-art results in several NLP subfields, including sentiment analysis, opinion mining, language generation, dialog management, summarization, information retrieval, plagiarism detection, authorship verification, and text categorization.",1,new
This novel parsing algorithm utilizing linear indexed grammars exhibits remarkable efficiency in handling context-free languages.,1,new
Lexical functional grammar has been extensively employed for its ability to model complex syntactic structures and semantic interpretations effectively.,1,new
Dependency-based tree substitution grammar offers significant improvements over traditional phrase-structure approaches due to its robustness in capturing long-distance dependencies.,1,new
"Current state-of-the-art models for paraphrasing tasks rely heavily on deep learning architectures like those presented in, which have shown significant improvements over traditional rule-based methods.",1,new
"Recent research has highlighted the importance of neural network-based approaches for automatic summarization, including the innovative techniques discussed in ; these findings demonstrate substantial gains over earlier attempts at condensed document representation.",1,new
"Machine learning algorithms continue to play a crucial role in natural language processing applications, particularly in the context of text generation, where the methods outlined by researchers in exhibit promising outcomes that surpass previous methodologies.",1,new
Our study demonstrates strong agreement with state-of-the-art metrics such as Meteor when evaluating machine translation outputs.,1,new
"Evaluation metrics like ROUGE have shown high correlation with human judgments for summarization tasks, indicating their reliability.",1,new
"In our analysis, we obtained favorable outcomes by utilizing established metrics Perplexity that assess the quality of neural language models.",1,new
Our findings suggest that incorporating statistical methods into constituent-structure grammar can significantly enhance parsing efficiency in industrial-strength natural language processing systems.,1,new
Recent research has shown that employing probabilistic models within categorial grammatical frameworks leads to substantial improvements in accuracy during linguistic analysis tasks.,1,new
"By leveraging advanced computational techniques from statistics, researchers have successfully optimized parser performance in complex NLP environments by adopting a dependency-based approach rooted in categorial grammar principles.",1,new
"Our research demonstrated that graphene oxide nanosheets can also be synthesized via a facile hydrothermal treatment process, where the sheets were found to exhibit exceptional electrical conductivity properties upon annealing at elevated temperatures.",1,new
"Utilizing the centrifugation technique allowed us to successfully isolate silver nanoparticle clusters from their corresponding colloidal suspensions, yielding highly uniform particles suitable for various biomedical applications.",1,new
"Furthermore, our laboratory-scale experiments revealed that gold-coated silica microspheres could effectively catalyze specific chemical reactions when exposed to ultraviolet radiation under ambient conditions.",1,new
Our results demonstrate that incorporating the proposed feature extraction technique enhances the accuracy of object detection models by up to 12% compared to baseline methods as validated through rigorous testing and expert analysis.,1,new
"This study reveals significant improvements in speech recognition performance when utilizing our novel signal processing algorithm, yielding enhanced audio fidelity metrics such as SNR and PESQ scores.",1,new
"Furthermore, we observe substantial gains in image classification efficacy upon integration of our machine learning framework, achieving superior F1-scores across various benchmark datasets and scenarios.",1,new
"This breakthrough approach enabled by neural networks has significantly impacted the field of NLP, rendering traditional methods nearly obsolete.",1,new
"By leveraging state-of-the-art deep learning techniques, BERT emerged as the gold standard for many downstream tasks within natural language processing research.",1,new
"As a pioneering study demonstrated, the incorporation of attention mechanisms into recurrent models led to substantial improvements in machine translation accuracy and overall performance.",1,new
Recent studies indicate that novel formulations of the envelope protein may induce enhanced immune responses capable of targeting various strains of SARS-CoV-2 effectively.,1,new
"Our analysis reveals promising preliminary evidence for increased efficacy when employing pentameric constructs of spike proteins in inducing robust, cross-neutralizing antibodies against influenza virus variants.",1,new
"Research findings point towards improved immunogenicity by incorporating dodecameric structures into viral vaccines, resulting in significantly higher titers of protective antibodies against respiratory syncytial viruses.",1,new
"Our analysis leverages the standard MIMO channel model, which can be represented as H = A * B, where A represents the transmit correlation matrix and B denotes the receive correlation matrix, both conforming to the trace constraint.",1,new
"Utilizing the established Rayleigh fading distribution, the multi-antenna system's transfer function can be expressed as H = C + D, wherein C and D correspond to the individual antenna arrays' contributions, adhering to the condition that their sum equals unity.",1,new
"By adopting the widely accepted Gaussian noise model, we express the wireless communication link as Y = X * W, where X corresponds to the transmitted signal and W accounts for the additive white Gaussian noise component, ensuring compliance with the specified power constraints.",1,new
"Our study employed the Naive Bayes classifier due to its simplicity, computational efficiency, and ability to handle high-dimensional feature spaces effectively.",1,new
"In this research, we opted for the decision tree algorithm because it offers interpretable results, robustness against noise, and scalability to large datasets.",1,new
"The choice of support vector machine model was made feasible by its capacity to find complex patterns, excellent generalization capabilities, and efficient handling of multicollinearity issues.",1,new
Our findings suggest that discriminative approaches outperform their generative counterparts due to several practical benefits discussed extensively in Chapter 3.,1,new
"Moreover, empirical evidence confirms the superiority of discriminative methods compared to generative techniques under identical feature extraction protocols.",1,new
"Notably, our analysis demonstrates that incorporating discriminative frameworks yields significantly better outcomes than employing generative algorithms across various parameter settings.",1,new
Recent studies have shown that unsupervised deep learning methods can effectively improve sentence parsing outcomes by leveraging contextual relationships between words.,1,new
"Various research initiatives have demonstrated notable success in applying reinforcement learning techniques to semantic role labeling tasks, leading to more accurate representations of linguistic structures.",1,new
"Ongoing efforts in natural language processing have led to significant advancements in neural network architectures designed specifically for morphological analysis, enhancing our understanding of language complexities.",1,new
Probabilistic context-free grammars have been widely adopted for its ability to capture structural dependencies between words.,1,new
Rule-based systems often rely heavily on word alignment techniques due to their robustness and efficiency.,1,new
Statistical methods such as decision trees exhibit promising performance when dealing with out-of-vocabulary words.,1,new
A significant improvement was observed by incorporating Kolesnichenko et al.'s approach into our model.,1,new
"Furthermore, notable contributions were made by researchers such as Patel's algorithmic framework and Smith's statistical analysis method.",1,new
"Notably, valuable insights have been derived from utilizing techniques like Chen's machine learning strategy and Lee's computational modeling technique.",1,new
"This study demonstrates that the use of long short-term memory networks significantly enhances the performance of sequence-to-sequence models in speech recognition applications, providing robustness against various noise conditions.",1,new
"The proposed approach utilizing convolutional neural networks effectively captures spatial hierarchies within images, leading to state-of-the-art accuracy rates in object detection benchmarks.",1,new
"The employment of graph-based methods enables efficient modeling of complex relationships between variables, resulting in improved predictive capabilities in social network analysis tasks such as community identification.",1,new
This finding supports previous research indicating that higher levels of physical activity are associated with improved cognitive function in older adults.,1,new
Our analysis confirms that increased exposure to environmental toxins significantly reduces fertility rates among wildlife populations worldwide.,1,new
These findings demonstrate that regular consumption of Mediterranean diet leads to enhanced cardiovascular health outcomes in high-risk patients.,1,new
This approach was found particularly effective when integrating novel neural network architectures into traditional machine learning pipelines; further information can be obtained from [10].,1,new
Implementing more sophisticated optimization algorithms significantly improved model performance; readers are directed to [12] for specific implementation details.,1,new
Enhancements made through revisiting the feature extraction phase resulted in notable improvements across all evaluation metrics; supplementary materials detailing these modifications are available at [8].,1,new
"Our analysis reveals that incorporating named entity recognition into our model yields a significant increase in accuracy by 1.5%, surpassing state-of-the-art models in this domain.",1,new
"This study demonstrates that leveraging contextualized word embeddings leads to improved performance across all linguistic tasks evaluated, resulting in a notable gain of 2.9%.",1,new
"Moreover, it was found that augmenting the neural network architecture with attention mechanisms enhances its ability to capture long-range dependencies, thereby increasing overall F-score by 3.4%.",1,new
This measure has become a standard benchmark for evaluating machine translation quality due to its strong correlation with expert assessments.,1,new
The widespread adoption of this metric can be attributed to its ability to accurately reflect the nuances of human evaluation criteria.,1,new
"As a result of extensive testing, it has emerged as the gold standard for assessing the effectiveness of various translation systems.",1,new
"Previous research has shown that predicting the onset of rare diseases via machine learning algorithms can be computationally expensive, although several efficient methods have been developed recently [17].",1,new
"Significant computational challenges exist when applying reinforcement learning techniques to large-scale optimization problems, despite recent breakthroughs in this area [23].",1,new
"In spite of significant advances in natural language processing, extracting high-quality insights from unstructured clinical texts remains a challenging problem for which approximate solutions have been proposed by various researchers [42].",1,new
This approach also leverages contextual clues to enhance its proficiency in translating idiomatic expressions found commonly in Spanish texts.,1,new
"Furthermore, incorporating linguistic knowledge into the model allows it to accurately convey nuances present in formal Arabic documents.",1,new
"By utilizing semantic features, this framework demonstrates significant improvement over traditional machine learning methods for Portuguese language processing tasks.",1,new
"This approach has proven highly effective for various natural language understanding applications such as named entity recognition, sentiment analysis, and machine translation systems.",1,new
"Our experiments demonstrate that modifications of this technique can significantly contribute to improved performance in information retrieval, question answering, and semantic role labeling tasks.",1,new
"Applications utilizing these variants have shown substantial benefits across numerous areas including dependency parsing, coreference resolution, and topic modeling methodologies.",1,new
Dietary habits were assessed via a well-established food diary that provided reliable information regarding participants' typical consumption patterns prior to disease onset or hospitalization.,1,new
"Nutritional intake was determined by a comprehensive dietary assessment tool, which offered a consistent method for evaluating subjects' eating behaviors at baseline versus during acute illness episodes.",1,new
"A standardized questionnaire accurately captured participants' long-term dietary preferences, enabling researchers to draw meaningful comparisons between individuals with and those without specific health conditions.",1,new
This study demonstrates that employing machine learning algorithms yields superior outcomes when integrated into traditional methods for natural language processing tasks.,1,new
"By leveraging contextual cues from large datasets, researchers have successfully improved model performance in predictive analytics applications.",1,new
Our analysis reveals that incorporating ontological knowledge graph structures enhances the accuracy of entity recognition systems significantly.,1,new
"Recent advancements in machine learning have significantly improved upon the traditional rule-based methods for named entity recognition, offering more accurate results than their predecessors.",1,new
The drawbacks associated with the template-based approach to dependency parsing have largely been mitigated through the development of context-free grammar systems such as Context-Free Grammar Theory.,1,new
Substantial progress has been made in overcoming the computational complexity issues inherent in the maximum entropy model via the implementation of more efficient algorithms like gradient boosting machines.,1,new
"The development of deep learning techniques has been significantly advanced by researchers such as Yann LeCun and Yoshua Bengio, who have built upon earlier work by Rumelhart et al.",1,new
"The use of neural networks in computer vision was pioneered by David Marr's seminal paper on early vision, which laid the groundwork for subsequent contributions from Fukushima and others like Kunihiko Fukushima.",1,new
"The field of information retrieval benefited greatly from the innovative approaches introduced by Salton and McGill, whose work was later expanded upon by Baeza-Yates and Ribeiro-Neto.",1,new
"Our research team has found that graph density plays a crucial role in understanding complex systems such as transportation networks, social media platforms, and electrical power grids, where it can effectively facilitate analysis and optimization.",1,new
"Community detection algorithms have shown great promise in uncovering meaningful patterns within large datasets, particularly in the fields of computer science, biology, and physics, by providing valuable insights into network structures and behavior.",1,new
"Spectral clustering techniques have proven highly effective for identifying clusters in various types of data sets, from customer purchasing habits to genomic sequences, allowing researchers to better understand relationships between seemingly disparate elements.",1,new
Recent studies have shown that neural machine translation models can benefit from incorporating subword representations by treating morphemes rather than entire words as units of translation.,1,new
"In contrast to traditional word-based systems, this novel approach leverages a fixed-size vocabulary to translate phrases efficiently while capturing nuanced contextual information effectively.",1,new
Phrase-level processing has emerged as a crucial technique for tackling complex linguistic phenomena such as idiomatic expressions and collocations during machine-assisted human communication.,1,new
This study demonstrates that the antioxidant properties of resveratrol contribute significantly to its ability to protect against oxidative stress in plant cells.,1,new
Our analysis reveals that flavonoid compounds found in green tea exhibit substantial anti-inflammatory effects by modulating key signaling pathways.,1,new
The high concentration of anthocyanins present in berries has been shown to effectively inhibit cancer cell growth through induction of apoptosis.,1,new
Recent studies demonstrate that recurrent neural networks like LSTMs exhibit remarkable performance in time-series forecasting tasks due to their ability to effectively model temporal dependencies in sequential data.,1,new
"Long short-term memory networks have achieved impressive accuracy rates in emotion detection from physiological signals, making them highly effective tools for affective computing research.",1,new
The application of LSTM architectures has led to significant advancements in music information retrieval systems by enabling efficient modeling of complex melodic patterns and structures.,1,new
Recent studies in machine learning emphasize the significance of utilizing unlabeled datasets for enhancing model robustness across various applications.,1,new
Incorporating large-scale uncurated data into deep neural networks has been shown to significantly boost their accuracy in complex tasks such as speech recognition and image classification.,1,new
"The increasing reliance on unsupervised training methods highlights the potential benefits of leveraging raw, unstructured information from online sources to augment traditional labeled dataset collections.",1,new
"Our findings suggest that pre-treatment with EGCG effectively triggers PIAS-dependent degradation of p-STAT1, thereby enhancing downstream signaling pathways significantly compared to traditional siRNA-based approaches.",1,new
"We observed marked activation of JNK/p38 MAPK pathway upon treatment with TNF-alpha/SMAD4 complex, demonstrating its potential utility for modulating cellular responses efficiently.",1,new
"This study demonstrates that short-term exposure to UVB radiation induces robust phosphorylation of ERK1/2 via sequential interaction between DNA repair proteins and upstream activators, ultimately leading to increased cell proliferation rates.",1,new
"This approach effectively leverages the Kamada-Kawai algorithm for force-directed placement, resulting in well-balanced layouts that accurately capture the structural relationships within complex networks.",1,new
"By employing the Harel-Tamir fast multipole method, this software efficiently computes accurate distances between nodes, facilitating rapid computation of high-quality visualizations.",1,new
"Utilizing the spring-based embedding technique developed by Fruchterman-Reingold, it automatically optimizes node positions, yielding aesthetically pleasing representations of intricate network architectures.",1,new
This educational paradigm shift has been well-received by scholars worldwide due to its emphasis on interactive and learner-centric instructional strategies that facilitate meaningful teacher-student relationships.,1,new
"A review of top-ranked papers reveals that the flipped classroom model promotes active participation among students through hands-on experiments and group discussions, ultimately enhancing their understanding of complex concepts.",1,new
"Studies indicate that this innovative teaching method empowers educators to re-evaluate traditional lecture formats, allocating valuable class hours for personalized mentoring and skill development.",1,new
Our research utilizes a cutting-edge machine learning model that exhibits superior accuracy compared to existing algorithms for image classification tasks across various datasets.,1,new
"This study employs a novel deep learning approach that achieves remarkable improvements over traditional methods in natural language processing applications, particularly in handling complex syntax patterns.",1,new
"By integrating our custom-designed architecture into a widely used framework, we were able to achieve outstanding results in object detection tasks, outperforming previous implementations by a significant margin.",1,new
This method has been effectively employed to calibrate coefficients within a regression model by minimizing prediction errors across various datasets.,1,new
Linear Support Vector Machines have utilized this technique to adjust weightings that improve classification accuracy significantly.,1,new
"Regularized Regression techniques often rely heavily on minimum error rate training to fine-tune parameters, leading to enhanced predictive modeling capabilities.",1,new
"Our proposed approach utilizes a hybrid machine learning algorithm that integrates both decision trees and neural networks for efficient event classification, yielding superior accuracy compared to existing methodologies.",1,new
"By leveraging ensemble techniques and gradient boosting, our system achieves remarkable improvements over traditional models like Naive Bayes and logistic regression in identifying critical events from large datasets.",1,new
"In this study, we deploy advanced natural language processing techniques combined with support vector machines to develop an innovative event modeling framework that outperforms current benchmarks by a significant margin.",1,new
This study provides valuable insights into the capabilities of natural language processing models but falls short by neglecting to evaluate their ability to learn from sequential dependencies between words.,1,new
"Despite its contributions to understanding image classification accuracy, this research overlooks the limitations imposed by dataset bias and sampling methods used during model training.",1,new
"While notable strides have been made in optimizing machine learning algorithms, further investigation into the robustness of these techniques against adversarial attacks remains essential to fully realize their potential benefits.",1,new
Recent research by Sutton et al highlights that stochastic gradient descent algorithms often surpass traditional methods for optimizing machine learning models due to their efficient iterative process.,1,new
"In accordance with findings from Bengio's study, neural network architectures can significantly benefit from employing ensemble techniques during model development, yielding improved predictive accuracy.",1,new
"According to recent experiments conducted by Rumelhart & McClelland, adaptive learning rates play a crucial role in accelerating convergence times while minimizing loss functions associated with deep networks.",1,new
This technique also mitigates model overreliance by averaging out noisy signal components present in individual instances.,1,new
Ensemble methods leveraging average pooling have demonstrated improved generalizability across disparate datasets.,1,new
"By aggregating predictions from various models through simple mean calculation, we can significantly diminish adversarial effects during testing phases.",1,new
"Zhang et al successfully employed a novel ensemble approach for named entity recognition tasks, outperforming state-of-the-art models by significant margins.",1,new
"Hwang and colleagues effectively integrated cognitive architectures into their machine translation system, yielding substantial improvements in fluency scores.",1,new
Kumar and his team demonstrated exceptional outcomes when applying reinforcement learning techniques to optimize hyperparameter tuning procedures across various deep neural networks.,1,new
This method demonstrates significant improvement over existing techniques due to its adaptability for linguistic analysis applications.,1,new
Our experimental findings suggest that this approach offers superior performance metrics compared to previous methods employed in natural language processing tasks.,1,new
The novel application of entropy-based measures has been found to yield substantial gains when applied to datasets containing complex linguistic structures.,1,new
"This novel approach differs from traditional methods by analyzing the entire document rather than isolated segments, resulting in improved accuracy across various datasets.",1,new
"Unlike previous studies that focused solely on individual passages, our framework considers the broader contextual information within the entire text collection, leading to enhanced linguistic understanding.",1,new
"By examining the comprehensive scope of the corpora instead of fragmented sections, we have successfully developed a model that provides superior performance in semantic analysis tasks.",1,new
Our research has demonstrated that n-gram frequency analysis can serve effectively as a valuable feature extraction method in natural language processing tasks such as information retrieval systems.,1,new
This study highlights the potential benefits of utilizing Latent Semantic Analysis along with n-gram co-occurrences to enhance the accuracy of document classification models.,1,new
"By incorporating n-gram patterns into their framework, researchers were able to significantly improve the performance metrics associated with text summarization algorithms.",1,new
"Recent studies have shown that the most straightforward method for addressing this issue is likely attributed to Chen et al.'s innovative technique, which effectively captured significant patterns in Task 3 through vector representation learning.",1,new
"Li's seminal paper presents another compelling solution to this challenge, where he utilized graph theory to successfully predict outcomes on Task 1, demonstrating remarkable accuracy and efficiency in his model implementation.",1,new
"Notably, Patel's research offers an insightful perspective on tackling this problem by employing spectral clustering techniques, resulting in impressive performance gains on Task 4 and providing valuable insights into the underlying dynamics at play.",1,new
"Recent advances in deep neural networks have led to several novel approaches for tackling these challenges, including self-supervised and weakly-supervised techniques that show promising outcomes.",1,new
"To address these issues, researchers have developed innovative solutions such as semi-supervised machine learning algorithms and active learning strategies which exhibit significant improvement over traditional methods.",1,new
"Various supervised-by-weakness schemes have emerged as effective alternatives to fully labeled datasets, enabling more accurate predictions while reducing annotation efforts significantly.",1,new
This approach offers several advantages over traditional methods due to its enhanced precision and ability to analyze complex systems effectively.,1,new
MRI has proven to be a valuable tool in medical imaging owing to its non-invasive nature and capacity to produce detailed images of soft tissues with minimal artifacts.,1,new
"The implementation of advanced image processing algorithms significantly improved the accuracy of ultrasound-based diagnostics, enabling clinicians to make more informed decisions about patient care.",1,new
"This approach has led to significant advancements in machine learning research, particularly in the development of phrase-based statistical models for languages like Spanish-English and Chinese-English, which have shown remarkable accuracy rates compared to other methods.",1,new
"Furthermore, our analysis demonstrates that this paradigm can also be effectively extended to low-resource languages such as Arabic-English and Russian-English, resulting in notable improvements over traditional rule-based systems.",1,new
"Notably, these findings support the notion that integrated word-level neural networks, including both source-language and target-language components, possess superior abilities in translating idiomatic expressions across languages, exemplified by successful applications involving Korean-English and Portuguese-English translations.",1,new
"Our findings demonstrate significant advancements in machine translation quality, achieving a notable increase from 24.9% BLEU score to 27.3%, utilizing an innovative approach that showcases its potential for outperforming traditional SMT systems.",1,new
This research highlights substantial gains in post-editing efficiency by implementing a novel algorithm resulting in a 22.5% to 28.0% boost in BLEU scores when compared against industry benchmarks established by prominent MT frameworks.,1,new
"By employing state-of-the-art techniques, our proposed model exhibits superior performance over existing methods, culminating in improved translations with a noticeable rise from 23.7% to 29.2% BLEU score on par with leading commercial translation platforms.",1,new
Our study demonstrates that convolutional neural networks can effectively apply to volumetric images which enhances their performance significantly compared to traditional methods.,1,new
Recent advancements indicate that deep learning-based models like recurrent 3D CNNs exhibit superior efficiency when processing medical imaging datasets compared to shallow architectures.,1,new
This research shows how leveraging spatial hierarchies through three-dimensional convolutions enables state-of-the-art object recognition rates within complex scenes.,1,new
"Recent studies have shown that advancements in machine learning techniques since 2000 significantly improved the efficiency of syntactic analysis, yielding notable improvements over traditional rule-based approaches when evaluated against the Penn Treebank corpus.",1,new
"Notably, research conducted between 2010-2015 led to significant enhancements in linguistic processing capabilities, achieving unprecedented levels of precision when benchmarked against established datasets like the Wall Street Journal Corpus.",1,new
"A comprehensive review of recent literature highlights substantial progress made in natural language understanding since 2008, demonstrating impressive gains in parsing performance, particularly when compared to earlier methodologies employed for evaluating sentence structures against standardized corpora such as the Switchboard Corpus.",1,new
"Our study demonstrated that the implementation of BERT-based models has shown significant improvements in natural language processing tasks, yielding excellent outcomes across various applications.",1,new
"The utilization of Long Short-Term Memory (LSTM) networks in deep learning frameworks led to remarkable advancements in sequence prediction accuracy, displaying notable enhancements over traditional methods.",1,new
"This research showcases the efficacy of Graph Convolutional Networks (GCNs) in graph classification problems, delivering outstanding performance metrics and substantial gains compared to existing approaches.",1,new
"Our research utilized the efficient XZZX method, which has gained significant traction within computational biology communities.",1,new
The robust ZYYZ technique has been extensively applied in numerous machine learning frameworks across various disciplines.,1,new
This novel approach is commonly known as PQRT and plays a vital role in advanced statistical modeling applications.,1,new
This study demonstrated significant improvements in lung cancer screening outcomes for at-risk populations within a controlled clinical setting.,1,new
A randomized controlled trial successfully implemented amongst vulnerable cohorts yielded promising findings that warrant further investigation into early detection methods.,1,new
Results from this extensive cohort analysis revealed substantial enhancements in disease prevention rates among the target demographic group under examination.,1,new
"This study represents a significant advancement in the field of natural language processing, showcasing the effectiveness of novel deep learning architectures for sentiment analysis tasks.",1,new
Ureny's contribution has been instrumental in paving the way for future research into automatic opinion mining from large datasets.,1,new
"Her pioneering efforts have led to substantial improvements in text categorization accuracy, making it possible to extract valuable insights from unstructured online reviews.",1,new
"To evaluate the efficacy of this novel therapy, we employed well-defined outcome metrics such as clinical trial success rates, patient recovery times, and medication tolerance levels.",1,new
"Established indicators including precision, recall, F1 scores, and AUC-ROC values enabled us to objectively gauge the performance of our proposed machine learning algorithm.",1,new
"Objective benchmarks such as accuracy percentage, mean squared error, and correlation coefficient were utilized to rigorously assess the predictive capabilities of our statistical model.",1,new
"This method demonstrates significant enhancements in various NLP tasks such as named entity recognition, dependency parsing, and question answering compared to state-of-the-art models like BERT.",1,new
"Our technique exhibits notable advancements across several NLG applications, particularly in text summarization, dialogue systems, and sentence generation outperforming traditional approaches by substantial margins.",1,new
"These findings indicate that our proposed algorithm achieves superior performance than existing solutions for multiple downstream tasks within spoken language understanding, semantic role labeling, and coreference resolution.",1,new
Utilizing solely the monolingual lexicalized syntax dependencies allows researchers to develop highly accurate paraphrase detection models due to their inherent ability to capture nuanced contextual relationships within languages.,1,new
This approach has been shown to yield promising outcomes when leveraging morpho-syntactic patterns to identify semantically equivalent expressions across linguistic boundaries.,1,new
Employing graph-based methods that incorporate rich semantic information enables the creation of effective filters capable of distinguishing between closely related but distinct entities in multilingual corpora.,1,new
Previous studies have consistently employed BLEU scores calculated by IBM's algorithm for evaluating machine translation quality.,1,new
Research indicates that ROUGE metrics developed at Carnegie Mellon University have become increasingly popular among researchers for assessing machine translation systems alongside other methods like IBM's BLEU score.,1,new
A survey of the latest research papers reveals that many scholars utilize automatic metrics such as METEOR scored by Johns Hopkins University to evaluate their translations.,1,new
"The ease of manipulation allows for quicker turnaround times, facilitating more efficient experiments that yield high-quality data due to optimal growth conditions being achievable quickly.",1,new
Shorter incubation periods enable precise control over environmental factors which contributes positively towards successful outcomes in biological research studies.,1,new
"Improved accessibility of genetically modified organisms leads to enhanced experimentation speed, ultimately resulting in greater insight into complex cellular mechanisms under controlled settings.",1,new
Our research indicates that certain South American Helicobacter pylori isolates exhibit a novel E domain within their BabA protein which significantly enhances its binding affinity for Lewis b blood group antigens.,1,new
"Studies have demonstrated that African H. influenzae type b strains harbor a distinct G motif within their capsule polysaccharide, leading to increased susceptibility to opsonization by human antibodies.",1,new
"Recent findings suggest that Southeast Asian Vibrio cholerae serogroup O139 possesses a conserved K epitope within its toxin co-regulatory pilus, resulting in enhanced adhesion to intestinal mucosa.",1,new
"Yang et al propose a novel approach for accelerating eigenvalue computations by leveraging symmetries present within large matrices A, achieving significant speedup over traditional methods like QR decomposition.",1,new
"In their seminal paper, Chen and colleagues develop a fast and accurate method for computing shortest paths on weighted graphs G = (V,E), utilizing techniques from linear algebra and graph theory to outperform existing algorithms by several orders of magnitude.",1,new
"Building upon previous research, Patel demonstrates how the use of sparse matrix multiplication enables faster processing times when solving systems of equations described by Ax=b, thereby reducing computational complexity and memory requirements in many applications.",1,new
Recent advances in deep learning have led to significant improvements in text analysis techniques such as natural language processing.,1,new
The increasing availability of large datasets has made machine learning models more accurate and effective for various tasks including sentiment detection.,1,new
"Moreover, the rise of cognitive computing has enabled researchers to develop sophisticated methods for analyzing complex linguistic patterns and emotional expressions in texts.",1,new
Recent studies demonstrate that neural network-based ensemble methods exhibit superior accuracy in speech recognition tasks compared to traditional approaches.,1,new
Our experiments show that probabilistic graphical models have been instrumental in achieving high-quality image segmentation outcomes due to their robustness against noise interference.,1,new
"According to our research findings, deep learning frameworks have significantly improved object detection capabilities by incorporating multi-scale feature extraction mechanisms.",1,new
"This breakthrough led to a surge in research on applying neural networks to natural language processing tasks, particularly text categorization.",1,new
"Furthermore, the introduction of decision trees marked a significant milestone in the development of supervised learning algorithms for information retrieval applications.",1,new
"The incorporation of random forests into predictive modeling has been instrumental in improving accuracy rates across various domains, including but not limited to marketing analytics and customer feedback analysis.",1,new
Our findings demonstrate that employing a carefully designed joint feature vector enables the implementation of highly accurate loss-augmented inference through the application of a computationally efficient iterative procedure.,1,new
"This research underscores the potential benefits of utilizing a well-chosen combination of features when performing loss-augmented inference tasks, resulting in significantly improved performance via optimized search algorithms.",1,new
The experimental results clearly indicate that selecting a suitable joint feature representation facilitates near-optimal execution of loss-augmented inference operations by leveraging low-complexity heuristic methods.,1,new
"This issue has been addressed by various researchers who have proposed efficient approximation methods that significantly reduce computational complexity, thereby facilitating practical applications.",1,new
Our previous analysis demonstrated that applying advanced algorithms can substantially alleviate the difficulties associated with calculating these crucial probabilities.,1,new
"Despite initial concerns regarding the feasibility of exact computation, recent studies have successfully developed heuristic approaches that yield accurate estimates while minimizing processing time.",1,new
"This study demonstrates that recent advancements in deep learning have significantly enhanced the accuracy of automated speech recognition systems, paving the way for more efficient human-computer interaction.",1,new
"The proposed neural network architecture has shown substantial improvement in image classification tasks compared to traditional methods, highlighting its potential for widespread adoption across various applications.",1,new
"Recent breakthroughs in natural language processing have led to notable enhancements in chatbot functionality, enabling them to engage users more effectively and naturally than ever before.",1,new
The proposed method utilized a high-performance named entity recognition tool for accurate identification of entities within biomedical literature.,1,new
A sophisticated dependency parser enabled efficient extraction of syntactic relationships between words in the processed texts.,1,new
All semantic roles were assigned utilizing a machine learning-based approach that achieved superior performance compared to traditional rule-based methods.,1,new
"This research project implemented in rural Kenya employed innovative technology-enhanced teaching strategies that significantly improved student engagement in science classes, contributing to enhanced academic performance among participants.",1,new
"In a groundbreaking trial conducted by experts at the University of California, the application of personalized medicine led to remarkable patient outcomes, resulting from precise genetic analysis and tailored treatment plans.",1,new
"Researchers at a leading institution discovered that integrating hands-on activities into environmental education programs resulted in increased awareness about sustainability practices among young people, paving the way for environmentally conscious behaviors in local communities.",1,new
This novel approach leverages insights from previous studies in combinatorial optimization to develop a more effective algorithm for solving complex network flow problems efficiently.,1,new
"Notwithstanding several heuristic-based solutions presented in prior research, our method provides a guaranteed optimal solution through its application of linear programming techniques.",1,new
"Building upon established theories in computational complexity, this innovative technique enables exact resolution of difficult instances within reasonable time constraints.",1,new
This breakthrough has significantly improved our ability to track T cell receptor repertoire dynamics via the introduction of novel MHC-peptide multimers for longitudinal studies.,1,new
The establishment of functional reagents like anti-CD137 antibodies enables us to further dissect the role of activated T cells during immune responses effectively.,1,new
"Recent advancements in molecular biology have led to the production of high-affinity monoclonal antibodies targeting specific markers such as PD-L1, allowing researchers to investigate its expression more precisely than ever before.",1,new
"Our model achieves significant improvements over previous methods, raising accuracy rates by 2.5% for classifying rare species.",1,new
"Compared to existing approaches, our technique boasts enhanced precision levels, increasing from 85.9% to 87.8%.",1,new
"This study demonstrates substantial gains in predictive power, expanding the range of correctly identified patients from 92.1% to 94.5%.",1,new
"Significant advancements have been observed in artificial intelligence research, particularly in the realm of machine translation techniques utilizing deep neural networks.",1,new
Recent studies indicate a growing interest among researchers in employing probabilistic models for information retrieval applications.,1,new
There has been notable progress made in human-computer interaction through the integration of cognitive architectures into conversational interfaces.,1,new
The discovery of context-dependent semantic role labeling models has been instrumental in advancing       knowledge about information extraction tasks.,1,new
Recent studies have highlighted the importance of incorporating weighted finite-state transducers into speech recognition systems for improved accuracy rates.,1,new
Significant advancements have been made in image segmentation through the application of deep neural networks and pixel-wise loss functions.,1,new
"Advances in machine learning techniques have led to significant improvements in natural language processing tasks such as machine translation, allowing for more accurate assessments to be made about its overall quality and effectiveness.",1,new
"By leveraging advances in deep learning architectures, researchers can now develop more sophisticated metrics that better capture the nuances of human translation skills, thereby enhancing our ability to refine and optimize machine translation systems.",1,new
"Efforts to automate the assessment of machine translation have yielded substantial progress, enabling experts to fine-tune their models and streamline the development process by identifying areas where improvement is most needed.",1,new
"This research employed a widely recognized and well-established scale for anxiety assessment, specifically utilizing a Turkish adaptation of HADS that has been previously shown to possess high internal consistency reliability.",1,new
"A standardized depression severity measure, the PHQ-9 adapted into Spanish by our team members, demonstrated excellent test-retest reliability in our clinical trial participants.",1,new
"In order to evaluate symptoms of post-traumatic stress disorder (PTSD), we utilized the IES-R translated accurately from English, which had already proven its effectiveness in various cross-cultural settings.",1,new
Various Machine Learning Techniques 2.2 Contextual Embeddings Derived from syntactic parse trees surrounding the target word have been instrumental in advancing the field of Named Entity Recognition.,1,new
Recent studies demonstrate that Subword Representations extracted through morphological analysis have significantly enhanced accuracy in Part-of-Speech Tagging tasks.,1,new
Long Short-Term Memory Recurrent Neural Networks employed with Dependency Tree-Based Features have substantially improved performance in Word Sense Induction.,1,new
Recent advancements in artificial intelligence have led to increased adoption of hybrid models combining the strengths of various supervised and unsupervised algorithms.,1,new
"The integration of deep neural networks has significantly improved classification accuracy across numerous applications, solidifying its position as a leading technique in modern research.",1,new
"Growing interest in ensemble learning methodologies has resulted in significant enhancements to predictive modeling capabilities, allowing researchers to tackle increasingly complex problems effectively.",1,new
"Our findings show that significant improvements have been made in this study, surpassing those achieved by previous stochastic algorithms developed by Chen et al.",1,new
"These outcomes clearly indicate that our novel method has outperformed other systems, including the highly regarded probabilistic model proposed by Patel and colleagues.",1,new
"This research yields substantial advantages over existing approaches, notably exceeding the performance levels attained through the use of optimized machine learning techniques presented by Kim's group.",1,new
Deep learning architectures such as Long Short-Term Memory networks have exhibited superior performance in predicting gene expression levels from genomic sequences.,1,new
Recurrent neural network-based methods for protein secondary structure prediction demonstrate impressive accuracy when leveraging large-scale datasets.,1,new
Recent studies employing stochastic gradient boosting techniques reveal substantial improvements in identifying novel biomarkers for disease diagnosis through high-throughput sequencing analysis.,1,new
Recent studies have demonstrated that AONs exhibit significant potential as a novel treatment option for Duchenne muscular dystrophy patients.,1,new
Results from recent Phase II clinical trials suggest that AONs may hold promise for effectively managing symptoms associated with this debilitating disease.,1,new
Preliminary findings indicate that antisense oligonucleotides represent a groundbreaking approach to treating muscular dystrophies like Becker's and Duchenne's by modulating gene expression at its core.,1,new
"Recent studies have demonstrated that distributional semantics outperform traditional keyword-based approaches for several applications . In contrast, simpler yet effective methods such as pattern recognition techniques have proven to yield comparable accuracy for classification tasks.",1,new
"While context-aware embeddings exhibit impressive performance across various NLP benchmarks, research suggests that heuristic-driven approaches can achieve remarkable results when applied to specific problem domains like information retrieval.",1,new
"According to recent literature reviews, vector-based representations often excel at capturing complex relationships between words ; however, basic structural analysis techniques demonstrate surprising effectiveness in extracting relevant features from unstructured data sources.",1,new
"Our experiments also incorporated ensemble learning techniques, leveraging domain knowledge transfer from pre-trained models that demonstrated improved accuracy rates across various tasks.",1,new
"By incorporating momentum-based optimization methods into our framework, we significantly enhanced convergence speed while preserving robustness against overfitting issues.",1,new
"Additionally, integrating spectral regularization techniques allowed us to effectively reduce over-specialization within the network architecture, resulting in more generalizable predictions overall.",1,new
"This study demonstrates that categorization methods utilizing hierarchical clustering effectively group semantically related entities, thereby facilitating accurate information retrieval tasks.",1,new
Our analysis indicates that employing semantic networks significantly enhances part-of-speech tagging performance by capitalizing on inherent word relationships within linguistic structures.,1,new
The utilization of dependency parse trees has led to substantial improvements in named entity recognition accuracy due to their ability to capture contextual dependencies between entities and modifiers.,1,new
"To address this challenge, researchers often employ data deduplication techniques, which can efficiently minimize storage consumption while ensuring integrity.",1,new
A widely adopted strategy for achieving redundancy reduction involves implementing incremental backups that update existing copies rather than creating full duplicates.,1,new
"Furthermore, utilizing advanced compression algorithms has been proven effective in decreasing storage requirements by condensing redundant information into more compact formats.",1,new
"Despite advances in understanding memory consolidation processes, the idea persists that interference primarily stems from information overload during recall remains unchallenged by empirical evidence demonstrating its limited applicability to routine forgetfulness in daily life.",1,new
"However, anecdotal accounts suggesting cue-overload plays a significant part in everyday forgetting have led researchers to overlook more nuanced theories explaining this phenomenon, leaving a knowledge gap that has yet to be filled by rigorous studies examining individual variability in forgetting patterns.",1,new
"Although numerous experiments failed to support cue-overload's significance in common forgetfulness, many remain convinced of its importance, citing personal experiences where perceived information overload undoubtedly contributed to forgotten events, thus perpetuating misconceptions about memory loss mechanisms.",1,new
"This phenomenon has been extensively studied within the realm of computational complexity theory, where it exhibits remarkable patterns through iterative computations.",1,new
"In various models of distributed systems, these entities have shown notable behavior under synchronized execution protocols.",1,new
Researchers have observed striking properties of self-organization among these elements during sequential analysis processes in formal languages studies.,1,new
"Our research indicates that employing probabilistic representations enables efficient storage of large-scale linguistic models, thereby achieving substantial reductions in memory requirements while still preserving vital semantic information.",1,new
"A recent breakthrough in machine learning demonstrates how leveraging compressive techniques allows for compact encoding schemes, effectively overcoming theoretical limitations associated with exact representation methods.",1,new
"Experimental findings confirm that utilizing stochastic embeddings leads to considerable gains in terms of computational efficiency and model scalability, paving the way for more complex neural network architectures.",1,new
"This innovative statistical technique, known as Akaike's Information Criterion (AIC), provides a reliable measure of model selection by quantifying the relative goodness-of-fit between competing models.",1,new
"The Bayesian Information Criterion (BIC) offers a theoretically sound approach to model evaluation, offering insights into the probability that a proposed explanation fits the observed data better than other alternatives.",1,new
"Wald's Test statistic has proven itself to be a robust tool in hypothesis testing, allowing researchers to determine whether observed differences between groups can be attributed to chance rather than systematic effects.",1,new
Our analysis reveals that the newly developed metric outperforms other existing measures like ROUGE-2 and CIDEr in capturing nuanced semantic similarity between machine translations.,1,new
"In contrast to older evaluation methods, our research demonstrates that the use of BERTScore yields significantly better alignment scores for complex sentence structures.",1,new
This study confirms that incorporating word embeddings into the assessment framework leads to substantial improvements over traditional metrics such as Meteor and TER when evaluating translation quality.,1,new
"Our subsequent analysis focused on elucidating the roles of established Drosophila melanogaster wing development regulators CUBIT, FGF signaling pathway components, and Hox gene family members in this process.",1,new
"Further investigation centered around understanding the expression patterns of validated Arabidopsis thaliana circadian rhythm genes ELF3, LUX ARRHYTHMO, PRR9, and TOC1 during photoperiodic adaptation experiments.",1,new
"Subsequent studies concentrated on characterizing the function of known Caenorhabditis elegans sensory organ morphogenesis factors LET-502, MIG-10, MIG-15, and PHA-4.",1,new
Our experiments demonstrate that incorporating contextual information into syntactic analysis via lexicalized probabilistic context-free grammars yields substantial gains in parser accuracy.,1,new
This study shows how employing word-specific attributes within constituent trees enhances sentence comprehension by up to 30% compared to traditional models.,1,new
"By leveraging linguistic properties at the level of individual words, researchers can significantly boost the performance of natural language processing algorithms used in various NLP applications.",1,new
"In section 5, we elaborate upon the testing protocol implemented for our proposed neural network architecture compared to traditional multilayer perceptrons.",1,new
"This chapter provides detailed information about how our machine learning model was trained utilizing backpropagation, contrasting this approach against more conventional stochastic gradient descent methods.",1,new
Chapter three delves into the evaluation metrics employed to assess the efficacy of our deep learning framework versus that of feedforward networks.,1,new
Recent studies have shown that probabilistic graphical models such as Bayesian Networks and Latent Dirichlet Allocation exhibit remarkable performance in part-of-speech tagging tasks.,1,new
Deep learning architectures like Long Short-Term Memory networks and Recurrent Neural Network-based systems consistently demonstrate superior accuracy in linguistic annotation tasks.,1,new
"Various machine learning algorithms, particularly those employing Support Vector Machines and Gradient Boosting techniques, have been found to yield impressive results in named entity recognition applications.",1,new
"Utilizing ensemble methods like stochastic gradient boosting could significantly enhance the accuracy of the sequence labeling system, allowing us to exploit both weak and strong learners effectively within a unified probabilistic architecture.",1,new
Employing graph-based approaches may offer substantial improvements for named entity recognition tasks by enabling the integration of contextual relationships between entities and leveraging structural information from the underlying semantic network.,1,new
"Integrating vector space models with neural networks has proven beneficial in capturing nuanced patterns in natural language processing applications, providing a robust means of representing high-dimensional feature spaces while still facilitating efficient learning processes.",1,new
"This approach has led to significant advancements in machine learning algorithms for natural language processing tasks, yielding impressive improvements over traditional methods.",1,new
"Recent studies have demonstrated that incorporating linguistic features enhances the performance of statistical machine translation systems, paving the way for more accurate translations.",1,new
"Researchers' growing interest in exploring phrase-based models has resulted in notable breakthroughs in capturing nuanced contextual relationships within language pairs, ultimately enhancing overall translation quality.",1,new
Large-scale bilingual dictionaries have proven to be highly effective resources for retrieving synonyms in various linguistic applications.,1,new
Recent studies indicate that multilingual lexical databases offer significant advantages over traditional translation software in terms of accuracy and efficiency.,1,new
A comprehensive analysis of parallel texts has shown that they can serve as valuable tools for identifying word equivalents across languages.,1,new
Our research team employed the systematic search protocol effectively utilized by many conservation efforts worldwide to identify rare species populations within our study area.,1,new
Species detection probabilities calculated through mark-release-recapture methods consistently revealed significant patterns in population dynamics among the studied animal groups.,1,new
Habitat preference analysis utilizing occupancy modeling techniques showed substantial variation in land use among migratory bird species over time.,1,new
"Our study aimed at addressing these discrepancies led us to collaborate with Thompson et al., who successfully implemented a novel framework for integrating behavioral assessments into existing clinical guidelines, thereby enhancing their applicability to various patient populations.",1,new
"By leveraging machine learning algorithms, researchers have been able to develop more accurate classification models, such as those introduced by Kohavi and John, which significantly improve upon traditional methods used in psychological evaluations.",1,new
"To bridge the gap between theoretical frameworks and practical applications, investigators like Borkowski and colleagues created a comprehensive toolkit for assessing cognitive development in children, allowing for a more precise diagnosis of developmental disorders.",1,new
A recent investigation demonstrated the efficacy of utilizing electroencephalography signals for implementing a self-regulating system in neural networks.,1,new
This research presents a novel approach to controlling robotic limbs by leveraging machine learning algorithms that receive real-time feedback from magnetic resonance imaging scans.,1,new
Our findings indicate successful implementation of a bio-inspired control mechanism powered by optogenetics-based sensorimotor integration techniques.,1,new
In recent years there have been significant advancements in machine learning techniques that support more accurate contextualized representation models for natural language processing applications.,1,new
A substantial body of research over the last two decades suggests that cognitive architectures can facilitate improved performance in semantic role labeling tasks by integrating domain knowledge with linguistic information effectively.,1,new
"Ongoing studies indicate considerable growth in the field of computational linguistics, particularly in areas like dependency syntax analysis where parser designs continue to become increasingly sophisticated.",1,new
"Our study employed ensemble learning techniques to combine the predictions of individual machine translation models, resulting in substantial improvements to overall system performance and efficiency.",1,new
"This research utilized feature extraction methods from convolutional neural networks to identify patterns indicative of disease progression, leading to enhanced diagnostic capabilities for medical professionals.",1,new
"By leveraging stochastic gradient descent optimization algorithms, we successfully trained deep neural networks to classify genomic data with unprecedented precision and reliability.",1,new
Our experiments have shown that Hybrid Recommender Systems exhibit notable improvements over traditional methods across various domains such as movie ratings prediction and product recommendations.,1,new
"In our study, the Deep Reinforcement Learning approach demonstrated exceptional performance on both natural language processing tasks like question answering and dialogue systems design.",1,new
"Furthermore, Empirical Analysis reveals significant gains when employing Ensemble Methods for predicting stock prices versus relying solely on individual models' predictions.",1,new
"Kumar et al. emphasized that gamification techniques have been effectively integrated into engineering education programs, leading to enhanced student engagement and motivation.",1,new
"Patel proposed innovative methods for incorporating case studies into civil engineering curricula, highlighting their potential to foster critical thinking skills among students.",1,new
"Singh demonstrated the efficacy of collaborative learning approaches in improving outcomes for graduate-level architecture classes, suggesting they offer a valuable alternative to traditional teaching methods.",1,new
Advances in materials science have paved the way for breakthroughs like Quantum Computing by pushing boundaries previously thought insurmountable.,1,new
This remarkable achievement was made possible by significant advancements in areas such as Natural Language Processing that followed Moore's Law trajectory.,1,new
The accelerated pace of innovation catalyzed by Gordon Moore's prediction has also led to substantial improvements in Deep Learning methodologies.,1,new
This innovative technique significantly enhances the efficiency of multilingual information retrieval tasks by incorporating neural machine translation models into traditional search algorithms.,1,new
Recent advancements have led to the development of sophisticated cross-linguistic phrase alignment methods that exhibit impressive performance gains in bilingual sentence similarity measurement.,1,new
A novel framework combining deep learning architectures with rule-based approaches has been successfully applied to improve the accuracy of code-switching detection in multimodal communication systems.,1,new
"Recent advances in natural language processing have led researchers to explore deterministic models that leverage domain-specific knowledge bases, resulting in impressive accuracy rates comparable to those achieved by cutting-edge deep learning architectures.",1,new
"Deterministic methods employing extensive rule-based systems have demonstrated remarkable success in various NLP tasks, outperforming some machine learning techniques due to their ability to capture nuanced linguistic patterns effectively.",1,new
"Research has revealed that well-designed rule-based models can often surpass expectations in certain areas of NLP, such as dependency parsing and semantic role labeling, showcasing their potential as viable alternatives to traditional neural network models.",1,new
"By integrating wavelet transform into texture analysis techniques like Local Binary Patterns, researchers have developed more effective methods for image classification tasks that yield superior accuracy rates compared to standalone approaches.",1,new
"A novel approach has emerged where the fusion of SIFT and Sobel operators enhances object detection capabilities beyond those achieved through individual operator-based systems, thereby opening up fresh avenues for computer vision applications.",1,new
"Combining morphological operations with Fourier descriptors enables improved shape representation and retrieval, ultimately leading to enhanced performances over existing methodologies that rely solely on singular mathematical formulations.",1,new
"Our group also examined an analogous concept in audio format, yielding promising preliminary findings.",1,new
"Several researchers have previously adapted this notion into interactive simulations, achieving noteworthy advancements.",1,new
Researchers have successfully translated these principles into a more immersive experience through virtual reality applications.,1,new
"Our study employed the latest tagging methods developed by researchers utilizing the feature sets outlined in publications such as Jones et al. (2019), Smith and Johnson (2020), and Lee et al. (2022).",1,new
"Recent advances in machine learning have led us to adopt novel techniques described in detail within Wang's seminal paper (Wang, 2018) for our classification tasks.",1,new
"As per recommendations from leading experts, we leveraged feature extraction methodologies proposed by Brown et al. (2021), Patel and Davis (2019), which significantly enhanced model accuracy in our current research endeavors.",1,new
"Furthermore, this approach has been found to significantly enhance identification accuracy for rare linguistic phenomena such as idiomatic expressions by leveraging log-likelihood ratio calculations effectively.",1,new
"In particular, log-likelihood ratios have proven themselves to be particularly useful in distinguishing between high-frequency patterns from those that occur infrequently within large corpora analysis.",1,new
"Consequently, researchers can rely heavily upon these metrics to pinpoint less common word associations which may otherwise go unnoticed through other statistical methods alone.",1,new
Our study demonstrates that microsurgical techniques can significantly enhance patient outcomes after reconstructive procedures utilizing allogenic grafting methods.,1,new
The application of cutting-edge biomaterials has shown considerable promise for improving recovery times associated with osteotomy surgeries.,1,new
Autogenous bone transplantation offers patients substantial long-term benefits through enhanced structural integrity and reduced risk of postoperative complications.,1,new
This paper reviews recent advancements in machine translation technology utilizing the popular Sequence-to-Sequence models like Transformer-XL which outperform previous state-of-the-art systems by large margins.,1,new
The proposed deep learning architecture exhibits significant improvement over traditional statistical methods for natural language processing tasks including but not limited to named entity recognition and part-of-speech tagging.,1,new
Our research demonstrates that incorporating contextualized embeddings from BERT yields substantial gains in accuracy when applied to various NLP benchmarks such as sentiment analysis and question answering.,1,new
"In this study, we employed multiple camera angles positioned near the midline to enhance accuracy when applying the novel image matching method for tracking purposes.",1,new
The cameras were strategically placed at various points along both sidelines within a distance range of 15-25 meters due to recommendations emphasizing improved spatial awareness via multi-camera analysis techniques.,1,new
Several observational viewpoints aligned perpendicularly across the playing field provided reliable outcomes by integrating the merits of multibeam imaging methodologies.,1,new
"Similar findings were observed when utilizing the Revised Trauma Score (RTS), which consistently demonstrated superior predictive accuracy compared to alternative assessment tools in trauma research settings like this investigation.",1,new
"Our analysis adhered to established methodologies by employing the Abbreviated Injury Scale (AIS), a widely accepted metric for quantifying injury severity that has proven effective in numerous epidemiological studies examining acute care outcomes.",1,new
"In accordance with existing literature, patient outcomes were categorized according to the Injury Severity Scores (ISS), a well-established framework validated through extensive clinical trials and observational analyses, allowing us to draw meaningful comparisons across our dataset.",1,new
Our proposed approach demonstrates superior accuracy when compared to state-of-the-art architectures like LSTM networks and CNNs trained with pre-processed inputs.,1,new
"In contrast to traditional methods that rely solely on discriminative learning algorithms, our hybrid framework outperforms them significantly by leveraging both generative and discriminative components simultaneously.",1,new
"Compared to other ensemble techniques involving random forests and gradient boosting machines, our novel combination of probabilistic graphical models yields substantial improvements across various metrics.",1,new
"Recent studies have shown that cutting-edge machine learning models for resolving semantic uncertainty heavily depend upon intricate linguistic resources like part-of-speech tags, morphological variations, and syntactic categories (Smith et al., 2019, p. 215).",1,new
"Notably, sophisticated computational methods employed by state-of-the-art NLP tools draw extensively from copious contextual information encompassing co-occurrence patterns within small neighborhoods and extensive linguistic backgrounds spanning thousands of surrounding tokens (Johnson & Williams, 2020, p. 120-125).",1,new
"High-performing natural language processing algorithms frequently integrate diverse types of knowledge representation including named entities, dependency parses, and sentence embeddings to achieve remarkable accuracy in addressing polysemy issues (Kim et al., 2018, pp. 300-305).",1,new
"Our software effectively computes spatial layouts by automatically determining the positions of nodes and their corresponding centroids, leveraging the established efficiency of the Kamada-Kawai force-directed method for diverse network structures.",1,new
This innovative approach utilizes the widely accepted stress-majorization heuristic from Harel & Koren's algorithm to accurately predict geometric relationships between entities within complex systems.,1,new
"By employing the Barnes-Hut algorithm, our system efficiently estimates the spatial arrangement of objects and their respective centers of mass, delivering precise outcomes even when dealing with intricate networks and large datasets.",1,new
This design allows for efficient parallel processing of high-speed signals through the use of optimized electromagnetic couplers.,1,new
The incorporation of photonic crystals into these devices significantly enhances their ability to manipulate light waves effectively.,1,new
Improved signal integrity can now be achieved by utilizing specially designed multimode fibers within this advanced system architecture.,1,new
This breakthrough was facilitated by the emergence of massive parallel corpora which have enabled researchers to investigate the efficacy of various machine learning algorithms in the field of natural language processing since the pioneering study conducted at Microsoft Research Labs in the late nineties.,1,new
The advent of substantial multilingual datasets has catalyzed significant advancements in computational linguistics particularly regarding automatic speech recognition systems thanks to foundational research initiated at Carnegie Mellon University during the 2000s.,1,new
A vast array of comparable texts has greatly accelerated progress in artificial intelligence through investigations into deep neural networks for machine translation tasks exemplified by groundbreaking studies published by Google Brain team members beginning from the mid-2010s onward.,1,new
"This innovative approach leverages machine learning algorithms to significantly enhance image quality from low-resolution videos, yielding remarkable improvements over traditional techniques.",1,new
"Recent studies have demonstrated that incorporating multispectral imaging modalities can boost the precision of facial recognition systems by up to 25%, underscoring their potential for widespread adoption.",1,new
"By integrating novel edge detection methods into existing computer vision frameworks, researchers achieved impressive results in object segmentation tasks, outperforming state-of-the-art models across various benchmarks.",1,new
"A significant advantage of quantitative analysis lies in the utilization of annotated datasets from reputable institutions, where researchers can access validated information critical for precise modeling.",1,new
Utilizing linguistic resources such as those provided by the Linguistic Data Consortium enables scholars to develop more accurate parsing techniques due to their meticulous annotation process.,1,new
"Researchers often rely heavily on pre-existing corpora maintained by leading academic centers, offering them comprehensive frameworks necessary for thorough syntax examination.",1,new
The availability of annotated databases like the Google Ngram Viewer  and the Historical Thesaurus of English   has significantly contributed to advancements in historical linguistic research methodologies.,1,new
Studies utilizing large datasets such as the WikiText-103 dataset    and the OpenWebText dataset     demonstrate substantial progress in natural language processing applications.,1,new
The creation and dissemination of resources like the Gigaword Corpus      and the Enron Email Dataset        have facilitated groundbreaking discoveries in information retrieval systems.,1,new
Our implementation outperformed existing techniques by leveraging recent advancements in ensemble learning methodologies 8.1,1,new
A thorough comparison with other machine translation systems demonstrated that our proposed approach yielded superior performance metrics 9.5,1,new
"Notably, our novel framework exhibited improved efficiency when compared against established multilingual summarization methods 11.7",1,new
"In addition to widely used benchmarks, our analysis was conducted on more extensive experimental datasets obtained from various sources.",1,new
"We supplemented our investigation by incorporating several large-scale datasets into the study, which provided valuable insights into the phenomenon under examination.",1,new
"Furthermore, to ensure comprehensive understanding, we explored numerous substantial databases beyond commonly employed reference sets for validation purposes.",1,new
"Our proposed approach employs a cutting-edge, neural-network-based architecture that integrates insights from both syntax and semantics to yield enhanced contextual understanding.",1,new
"This year's entry boasts a novel implementation of graph-structured attention mechanisms within our deep learning framework, significantly boosting its performance across various metrics.",1,new
"We introduce a hybrid approach combining rule-based post-processing techniques with advanced sequence-to-sequence models, resulting in substantially improved accuracy rates compared to traditional methods.",1,new
"N-grams have proven to be pivotal components within numerous natural language processing frameworks, showcasing remarkable efficacy despite their straightforward design.",1,new
"These fundamental statistical tools continue to play a vital role in various machine learning algorithms, demonstrating impressive accuracy even when employed under relatively simple conditions.",1,new
"Their widespread adoption in linguistic analysis stems from their capacity for effective representation, rendering them essential building blocks for more sophisticated parsing systems.",1,new
Our findings demonstrate enhanced bioactivity profiles that illustrate improved efficacy in vivo due to better binding affinity displayed by this compound.,1,new
This study highlights outstanding results showing greater stability under various environmental conditions that significantly enhance its potential for large-scale applications.,1,new
"Notably, our experimental evidence reveals significant improvements in mechanical properties achieved through optimized structural modifications exhibited by these novel materials.",1,new
Our primary objective for this assessment is to compare the efficacy of our novel algorithmic strategy against contemporary machine learning methodologies employed by leading researchers today.,1,new
This evaluation aims to highlight the strengths of our probabilistic framework compared to existing deep learning paradigms widely adopted within the field.,1,new
"To comprehensively evaluate our contribution, we seek to juxtapose it with conventional gradient-based approaches commonly used in statistical modeling practices among experts worldwide.",1,new
Recent advancements have led to the establishment of efficient protocols for identifying cell lines that exhibit enhanced productivity.,1,new
Breakthroughs in automation technology have enabled researchers to rapidly isolate highly productive cellular strains from various species.,1,new
Efficient methodologies for isolating high-yielding cells have become increasingly accessible through innovative screening techniques.,1,new
Our experiments demonstrate that unsupervised machine learning algorithms can achieve remarkable accuracy rates between 80-92% when applied to customer feedback analysis datasets.,1,new
"According to our study, rule-based approaches have shown impressive performance in opinion mining tasks, reaching precision levels above 88% on various product reviews corpora.",1,new
"Recent findings indicate that deep learning techniques have yielded outstanding results in aspect-level sentiment classification, boasting success rates ranging from 89-95% across numerous case studies.",1,new
"This development enables researchers to reliably analyze the impact of various factors on machine learning algorithms, streamlining their investigation into the intricacies of natural language processing technologies.",1,new
"Furthermore, this breakthrough allows scientists to establish more accurate benchmarks for measuring model performance, thereby facilitating better comparison across disparate studies and research initiatives.",1,new
"As a result, our method paves the way for enhanced evaluation metrics that can account for subtle variations in semantic meaning, ultimately contributing to improved algorithmic designs and more effective applications of NLP systems.",1,new
Our analysis suggests that the most impressive findings were reported by Yang et al.,1,new
"Notably, the highest performance was obtained from the study conducted by Mikolov and colleagues.",1,new
"To date, the most effective approach has been demonstrated by Collobert's research team.",1,new
"This implementation showcases significant advancements in numerical computations within Mathematica, making it a valuable tool for researchers seeking precise calculations.",1,new
"The utilization of Haskell's lazy evaluation strategy has greatly facilitated efficient computation, allowing developers to tap into its vast potential more effectively.",1,new
Efficiently utilizing advanced algorithms available in MATLAB enables users to perform complex statistical analysis tasks with remarkable speed and accuracy.,1,new
Our experiments demonstrate that utilizing swarm intelligence yields superior outcomes when implementing particle swarms within this range of particles from 25 to 75.,1,new
This study confirms that optimizing parameters such as particle count falls within a sweet spot at values ranging from 30 to 90 for achieving optimal performance.,1,new
Through extensive testing we have found that employing populations comprising between 35 and 85 agents leads to more effective solutions compared to other configurations.,1,new
Recent studies have demonstrated that advancements in mass spectrometry techniques such as UPLC-MS/MS have significantly enhanced our understanding of fungal metabolites found in various food products thereby improving detection accuracy.,1,new
Improved analytical methods including HPLC-QQQ MS enable researchers to efficiently identify trace levels of aflatoxin M1 contamination in dairy products which has been a significant concern globally.,1,new
Advances in chromatographic separations coupled with tandem mass spectrometric analysis have greatly facilitated the identification and quantification of ochratoxin A in cereal grains contributing positively towards ensuring consumer safety.,1,new
"Loglinear modeling has been effectively employed to analyze various linguistic phenomena, particularly those involving multi-word expressions.",1,new
Phrase-based approaches have garnered significant attention within the realm of statistical natural language processing due to their simplicity and interpretability.,1,new
The incorporation of loglinear models into linguistic analysis has led to substantial advancements in understanding complex grammatical structures.,1,new
This novel technique has been proven highly effective for categorization tasks due to its superior predictive capabilities.,1,new
"By leveraging the power of maximum entropy modeling, researchers have successfully addressed complex binary classification challenges.",1,new
Maximum entropy-based methods demonstrate remarkable performance when tackling intricate multi-class problems.,1,new
This study demonstrates that large datasets can significantly enhance our understanding of linguistic patterns by providing numerous opportunities for empirical verification.,1,new
Large-scale collections of parallel texts offer valuable insights into cross-linguistic differences through systematic comparisons across various languages.,1,new
High-quality multilingual resources such as parallel corpora serve as essential tools for advancing research in computational linguistics due to their ability to facilitate reliable analyses.,1,new
Recent studies indicate that materials like sodium alginate and carboxymethyl cellulose can serve as suitable alternatives for encapsulation purposes.,1,new
Hydrophilic matrices composed of pullulan and maltodextrin derivatives exhibit significant potential for controlled release applications.,1,new
Several research groups have successfully employed polyvinylpyrrolidone and xanthan gum-based formulations for targeted drug delivery systems.,1,new
"Previous studies have primarily focused on categorizing documents into predefined categories, but recent advancements in machine learning algorithms offer promising alternatives for more nuanced classification approaches such as those employed by Google Research.",1,new
These methodologies often complement traditional frequency-based methods with contextual features like part-of-speech tagging and named entity recognition to achieve higher accuracy rates.,1,new
"Researchers have explored various techniques for identifying relevant concepts within large datasets, including hybrid models that integrate rule-based knowledge extraction and probabilistic inference frameworks from prominent institutions like Carnegie Mellon University.",1,new
"The stochastic Petri net technique has proven to be highly effective for modeling complex discrete event dynamic systems, particularly when analyzing logistics management processes.",1,new
Simulation models utilizing queueing theory have been instrumental in optimizing supply chain operations by reducing lead times and increasing productivity.,1,new
"Queue-based simulation methods offer significant benefits in understanding traffic flow dynamics, making them essential for transportation engineers designing efficient road infrastructure.",1,new
Our research demonstrates that utilization of non-redundant transform-based algorithms significantly outperforms traditional methods like Fourier analysis in terms of noise reduction efficiency when applied to image processing tasks; this is due to their ability to better capture subtle spatial patterns within complex datasets.,1,new
"Recent studies have shown that employing directional filter banks derived from linear combinations of discrete cosine transforms can lead to substantial improvements over standard decorrelation techniques in multi-channel audio restoration applications; specifically, these hybrid approaches exhibit enhanced robustness against additive Gaussian noise interference.",1,new
"Experimental evidence suggests that adopting novel subband decomposition schemes grounded in adaptive thresholding methodologies yields superior performance compared to conventional block-wise filtering strategies in the realm of biomedical imaging, particularly regarding removal of salt-and-pepper type artifacts from ultrasound scans.",1,new
Our study demonstrates that Support Vector Machines have shown significant promise in achieving state-of-the-art performance for image classification tasks with high accuracy rates.,1,new
Naive Bayes classifier exhibits impressive efficiency when applied to large-scale datasets due to its ability to handle complex patterns effectively.,1,new
Decision Trees offer substantial advantages over traditional methods by providing interpretable models that facilitate easy identification of key factors influencing outcomes.,1,new
This study demonstrates the efficacy of leveraging ensemble learning techniques in deep neural networks to achieve superior performance in image classification tasks across various datasets.,1,new
Our findings suggest that integrating pre-trained word embeddings into traditional machine learning models significantly enhances their ability to generalize well to unseen linguistic patterns in natural language processing applications.,1,new
"Research indicates that utilizing transfer learning approaches can yield substantial improvements in accuracy when adapting speech recognition systems to novel acoustic environments, underscoring its potential for practical deployment in real-world settings.",1,new
"Notably, patient education through a nurse-led clinic has been shown to significantly enhance outcomes in individuals suffering from peripheral artery disease. Our study demonstrates that this approach leads to improved adherence to treatment regimens by up to 30%.",1,new
"A key advantage of incorporating cognitive-behavioral therapy into rehabilitation programs lies in its ability to empower participants to take control of their chronic pain management. By adopting such strategies, we observed a notable decrease in symptom severity ratings among test subjects.",1,new
The findings of our research emphasize the importance of promoting physical activity among older adults at high cardiovascular risk. Implementing exercise interventions within community settings resulted in substantial improvements in lipid profiles and blood pressure levels among program enrollees.,1,new
This area has witnessed significant advancements due to pivotal contributions from researchers such as Leutenegger and Chum.,1,new
Recent breakthroughs in local feature extraction can be attributed to the groundbreaking research conducted by Szeliski et al.,1,new
The development of robust local feature descriptors owes much to influential studies carried out by Tuytelaars and Van Gool.,1,new
We employ stochastic gradient descent optimization for fine-tuning our neural network's weights due to its proven track record in optimizing complex models efficiently.,1,new
"Our experiments utilize the Adam optimizer, leveraging its adaptive learning rate strategy which has shown excellent performance across numerous deep learning applications.",1,new
"In order to optimize the hyperparameters of our convolutional neural network, we rely on Bayesian optimization techniques that have demonstrated remarkable efficacy in navigating large search spaces effectively.",1,new
"Various factors contributing to effective conservation efforts have been addressed by researchers investigating ecological restoration techniques, forest ecosystem services, and policy implementation frameworks.",1,new
"Recent research has highlighted numerous approaches that can significantly enhance forestry practices including habitat preservation methods, sustainable wood production models, and wildlife population monitoring systems.",1,new
"An array of key elements essential for achieving optimal outcomes in reforestation projects have been identified through comprehensive analyses encompassing genetic diversity assessment tools, soil quality improvement protocols, and adaptive forest governance structures.",1,new
Our research demonstrates that careful consideration of off-target effects arising from RNA secondary structures significantly enhances the efficacy of shRNAs used for gene silencing applications.,1,new
A detailed analysis reveals that strategic selection of non-conserved regions within miRNA binding sites leads to improved specificity and reduced toxicity associated with CRISPR-Cas9 mediated genome editing tools.,1,new
Incorporating algorithms designed to predict potential stem-loop formations facilitates more precise prediction of microRNA function and regulation in cellular processes such as cell proliferation and differentiation.,1,new
"According to prevailing consensus among researchers, it is generally recommended to disregard diacritical marks when defining phrase boundaries, from the viewpoint that such distinctions have negligible impact on overall performance metrics.",1,new
"Our analysis confirms that disregarding affixes during part-of-speech tagging has been found to yield optimal outcomes across various models tested, including those developed by Huang et al. (2019), which achieved notable improvements over traditional methods.",1,new
"A review of existing literature reveals that neglecting non-alphanumeric characters at sentence level often leads to superior parsing results compared to more stringent approaches, supporting claims made by the seminal study conducted by Smith and Johnson (2008).",1,new
Recent studies have shown that employing a large-scale bilingual dictionary can significantly improve the accuracy of machine translation systems when utilizing sentence-level alignment in parallel corpora.,1,new
Corpus-driven methods for query translation often rely heavily on high-quality aligned datasets which contain hundreds of thousands of translated sentence pairs from various languages.,1,new
Effective query translation models frequently integrate statistical analysis of parallel texts to capture nuances in linguistic patterns between source and target languages.,1,new
Recent advancements in natural language processing have led to increased adoption of the use of vector space models for semantic similarity measurement between linguistic items.,1,new
The integration of attention mechanisms within neural machine translation systems has resulted in significant improvements in fluency and accuracy metrics such as ROUGE score and METEOR.,1,new
Incorporation of cognitive biases into deep learning frameworks has shown promising outcomes in tasks like question answering and text classification by enhancing model interpretability and robustness against adversarial attacks.,1,new
Our research employed the widely-used backpropagation neural network training method to optimize model performance consistently across various datasets.,1,new
This study utilized the k-nearest neighbors algorithm for effective classification tasks due to its robustness against noise in feature spaces.,1,new
"In our analysis, we applied the expectation-maximization clustering technique to uncover meaningful patterns within complex multivariate distributions.",1,new
Smith et al successfully mitigated this challenge through efficient data preprocessing techniques that greatly accelerated subsequent computations.,1,new
Lee and Kim overcame the issue by leveraging parallel processing capabilities to expedite computationally intensive tasks ahead of time.,1,new
"Thompson's innovative approach involved computing critical intermediate values before running simulations, thereby significantly reducing computational bottlenecks during analysis.",1,new
Improved results have consistently demonstrated by utilizing advanced computer vision techniques such as object detection and facial recognition.,1,new
Enhanced accuracy was observed when incorporating more linguistic features into our natural language processing model.,1,new
Our findings suggest that leveraging spatial reasoning capabilities significantly boosts the overall efficiency of autonomous navigation systems.,1,new
"Our analysis suggests that PCA-based dimensionality reduction has been notably effective in this context, making it an attractive option for future research applications.",1,new
"GANs have shown remarkable potential in image generation tasks, rendering them an exciting area of study within machine learning paradigms.",1,new
"Among various clustering algorithms evaluated, k-means clearly demonstrated superior performance metrics, solidifying its place at the forefront of unsupervised learning techniques.",1,new
"To enhance comparability, we compute four alternative versions of each system's alignment:  Symmetric intersection, which considers all overlapping elements from both trees; Unidirectional union, where nodes common to either tree but absent from their respective symmetric counterparts are included; Asymmetric overlap, involving elements exclusive to individual trees yet shared by neither; and Optimal subgraph matching via dynamic programming.",1,new
"Four supplementary methods are employed to refine our initial alignment models: Combining bidirectional node correspondences through logical conjunction yields conservative estimates; On the other hand, integrating them through disjunction provides more permissive alternatives; Furthermore, applying graph edit distance offers a measure of similarity between the two trees; Finally, employing maximum weighted bipartite matching helps identify optimal matches under specific constraints.",1,new
"In order to validate our findings, five distinct approaches are applied: Mutual information maximization identifies informative features that align well across systems; Cross-validation techniques assess predictive power when trained on subsets of available data; Additionally, hierarchical clustering analysis reveals patterns within large-scale datasets; Feature importance estimation highlights key variables driving observed phenomena; Lastly, sensitivity analysis evaluates robustness against varying parameter settings.",1,new
"Our research indicates that employing gradient descent for hyperparameter tuning during backpropagation stages significantly enhances the efficacy of deep neural networks in natural language processing tasks, leading to substantial improvements in accuracy rates.",1,new
The findings from our investigation demonstrate that leveraging ensemble learning techniques yields considerable enhancements in predictive models' reliability when trained on extensive datasets.,1,new
"By optimizing the configuration parameters through genetic algorithms, we observed notable increments in the precision levels achieved by our machine translation systems compared to those utilizing random initialization methods.",1,new
"Our dataset exhibits notable differences when compared to standardized collections like the ACL Anthology's proceedings, featuring 20 years' worth of conference papers spanning various topics within natural language processing.",1,new
"Notably, our corpus surpasses controlled datasets such as those found in the Open Multilingual WordNet, showcasing over 100 languages and their respective linguistic nuances.",1,new
"In contrast to meticulously curated resources such as the Penn Treebank Corpus, our web-derived collection offers unparalleled breadth and depth in its representation of everyday language usage patterns.",1,new
"Recent studies have shown that among all the tested compounds, ST101 has emerged as a promising inhibitor with significant potential for therapeutic applications.",1,new
Research findings indicate that TCM-12345 exhibits superior efficacy compared to other synthetic analogs in inhibiting key enzymatic reactions.,1,new
"In terms of potency, SBM-90123 stands out from its counterparts due to its exceptional ability to suppress unwanted cellular processes.",1,new
This molecular approach has proven particularly useful for inferring evolutionary linkages between distinct species within various genera of flowering plants.,1,new
"Furthermore, this technique has shown great promise in reconstructing ancestral relationships across numerous taxonomic groups from disparate parts of the world.",1,new
Its widespread application has greatly facilitated our understanding of morphological adaptations that have evolved independently in closely related yet geographically isolated populations.,1,new
"This approach also utilizes named entity recognition and dependency parsing, which have proven effective in various NLP tasks previously.",1,new
"Furthermore, combining tokenization with lemmatization yields significant improvements in document similarity analysis when compared to other techniques alone.",1,new
"By incorporating semantic role labeling and topic modeling, researchers can gain valuable insights into complex relationships between words in texts.",1,new
Lee et al.'s novel approach enhances beam search efficiency by leveraging caching mechanisms for faster sentence generation outcomes.,1,new
Improved algorithmic design techniques proposed by Chen and Wang contribute significantly to reducing latency during neural machine translation processes.,1,new
Wu's study presents optimized strategies for dynamically adjusting exploration-exploitation trade-offs within deep reinforcement learning frameworks for enhanced model performance.,1,new
"This study highlights the significance of the GAD67 subunit's interaction with other proteins, notably its co-activation by glutamate decarboxylase enzymes, leading to enhanced GABA synthesis rates that significantly contribute to neurotransmission efficacy.",1,new
"Notably, recent research has shown that distinct isoforms of the GLAST receptor exhibit differential expression levels across various brain regions, underscoring their potential role in spatially-specific synaptic plasticity mechanisms.",1,new
"Furthermore, this review emphasizes the crucial involvement of the gephyrin scaffold protein in clustering postsynaptic GABA receptors at inhibitory synapses, facilitating rapid modulation of neuronal excitability through precise control over chloride channel activity.",1,new
"Notably, leading parsing systems like those developed for the Penn Treebank dataset exhibit impressive performance by leveraging historical context.",1,new
Several prominent studies have demonstrated that dependency parser architectures often outperform other approaches when trained on large annotated corpora such as the OntoNotes project.,1,new
Recent research has shown that incorporating contextual information from linguistic resources like PropBank yields significant improvements over traditional statistical parsing methods on datasets including the Wall Street Journal corpus.,1,new
"In the analysis of linguistic patterns across languages, Zhang et al.'s approach yielded outstanding results for part-of-speech tagging by employing a machine learning algorithm with neural networks.",1,new
Our team's implementation of the stochastic gradient descent optimization technique led to exceptional accuracy rates in speech recognition tasks due to its ability to adapt quickly to complex acoustic models proposed by Lee et al..,1,new
Liang et al.'s innovative use of deep reinforcement learning methods resulted in significantly improved sentiment classification performances when applied to various natural language processing applications.,1,new
This research lays the groundwork for subsequent advancements in deep learning architectures by introducing the concept of stacked autoencoders for unsupervised feature extraction.,1,new
"The introduction of gradient boosting machines marked a significant milestone in machine learning history, enabling researchers to develop more accurate predictive models through ensemble methods.",1,new
The development of support vector machines paved the way for efficient classification techniques that have become fundamental tools in modern artificial intelligence applications.,1,new
"In order to validate the accuracy of their dependency parser, Lee et al. utilized the part-of-speech tagging tool to annotate the constituent phrases extracted from the Brown Corpus dataset for comparison with the Stanford parser's output.",1,new
"To further assess the performance of their machine learning algorithm, Kim and colleagues leveraged the Treebank corpus to analyze the syntactic structures produced by their model against those obtained via the standard parsing method.",1,new
"By applying the named entity recognition technique to the GUM treebank, Patel and team were able to evaluate the effectiveness of their deep neural network architecture when compared to the baseline parser on the Penn Parsed Corpus.",1,new
"All current approaches to solving this problem hinge heavily on syntactic features, which have proven highly effective in various studies.",1,new
Our analysis indicates that existing techniques employed by other researchers also utilize semantic attributes exclusively when tackling these types of issues.,1,new
A thorough examination reveals that past research has predominantly utilized contextual clues to tackle problems related to this domain.,1,new
Our team has successfully implemented Support Vector Machine learning algorithms and k-Nearest Neighbors technique to enhance predictive accuracy.,1,new
"By incorporating Gradient Boosting and Random Forest methods into our analysis, significant improvements were observed in classification outcomes.",1,new
Utilizing Recurrent Neural Network architecture combined with Long Short-Term Memory units enabled us to achieve superior results in temporal pattern recognition tasks.,1,new
The Boltzmann distribution remains one of the fundamental concepts extensively explored by researchers worldwide today.,1,new
The Maxwell-Boltzmann statistics has been thoroughly examined for its relevance in understanding thermodynamic systems.,1,new
The Fermi-Dirac distribution continues to be scrutinized intensively due to its importance in quantum mechanics theories.,1,new
"Our study found that the success rate for patients undergoing LASIK eye surgery was 92% at the 12-month follow-up mark. Additionally, advancements in microkeratome technology have significantly improved surgical precision.",1,new
"A significant increase in patient satisfaction rates was observed post-corneal transplantation procedures within our institution. Furthermore, improvements in graft survival rates have been consistently reported across various studies.",1,new
"According to recent clinical trials, the efficacy of the novel glaucoma treatment regimen exceeded expectations by reducing IOP levels by up to 40% after six months. Moreover, this breakthrough therapy shows promise in mitigating long-term vision loss associated with the disease.",1,new
"Cognitive functions such as working memory capacity were evaluated utilizing the N-Back Task, which has been extensively employed in assessing cognitive control mechanisms in various studies.",1,new
"Executive function was examined through the Trail Making Test A/B, allowing researchers to determine the ability to switch between tasks efficiently.",1,new
"The Stroop Test was utilized to assess inhibitory control and interference resolution skills among participants, further elucidating their decision-making abilities under pressure.",1,new
Recent advances in machine learning techniques have led to several effective methods for semantic role labeling that demonstrate significant improvements over traditional rule-based systems in linguistic analysis.,1,new
"This study presents novel applications of graph neural networks for part-of-speech tagging tasks, showcasing their potential for high-accuracy modeling of complex linguistic structures.",1,new
"A range of recent studies has explored the application of deep learning models to various NLP subfields, resulting in substantial gains in performance across numerous benchmarks for morphological analysis.",1,new
Our study incorporates two highly effective part-of-speech taggers - a machine learning-based model for English and a statistical approach for Arabic.,1,new
"This research employs cutting-edge tools for tagging purposes, including a probabilistic algorithm for Spanish and a rule-based system for German.",1,new
"By leveraging advanced techniques from natural language processing, we utilize both a neural network-driven tagger for French and a discriminative model for Japanese.",1,new
Our study demonstrated enhanced predictive capabilities for identifying tree species diversity when incorporating landscape features at various spatial scales.,1,new
This approach significantly increased the accuracy of seagrass bed mapping by integrating bathymetric and habitat data from coastal regions.,1,new
Combining environmental variables across watershed boundaries led to substantial improvements in predicting riverine water quality indicators such as pH levels and dissolved oxygen concentrations.,1,new
"Our system achieved superior performance compared to existing models, particularly when translating from English into German, yielding highly accurate alignments.",1,new
"This evaluation demonstrated significant improvements over other approaches, outperforming them by large margins across various languages including Spanish and Portuguese.",1,new
"Notably, our proposed method excelled at aligning texts from Chinese to Japanese, surpassing even some cutting-edge commercial translation tools in terms of accuracy.",1,new
Our proposed model inherits the efficiency of traditional statistical machine translation by retaining its core architecture while augmenting it with sophisticated linguistic knowledge.,1,new
"This hybrid approach effectively blends the strengths of rule-based systems and neural networks, yielding significant improvements over standalone methods.",1,new
"By combining the advantages of paradigmatic Machine Translation techniques with the flexibility offered by deep learning architectures, our system achieves remarkable accuracy gains.",1,new
Our research demonstrates that PBN effectively counteracts mitochondrial dysfunction associated with aging by significantly reducing the accumulation of reactive oxygen species and mitigating lipid peroxidation.,1,new
"Notably, studies have consistently revealed that PBN exhibits potent neuroprotective effects, rescuing neurons from oxidative stress-induced apoptosis and preserving cognitive function in animal models of neurodegenerative disease.",1,new
"Furthermore, our findings indicate that PBN supplementation leads to enhanced cellular resistance against hydrogen peroxide-mediated DNA damage, underscoring its potential utility in preventing cancer development.",1,new
"Our findings indicate that microencapsulated cells exhibited enhanced metabolic activity when cultured in serum-deprived conditions compared to their counterparts grown in vivo, leading to more precise calculations for drug elimination rates.",1,new
"In contrast, cell-based systems demonstrated accelerated metabolism of slowly cleared compounds in vitro relative to in situ experiments, ultimately resulting in substantial improvements in pharmacokinetic modeling efficacy.",1,new
"Conversely, our study revealed that encapsulated cellular constructs processed reduced-exchange substances at a notably increased pace within artificial media, thereby refining predictive models for substance removal processes by a considerable margin.",1,new
"A significant improvement over previous methods, the proposed scheme employs a warrant ω that combines all authorized messages into a single entity, along with a corresponding certificate verified by the delegator's private signing key.",1,new
"The innovative approach utilizes a warrant ω consisting of an aggregated representation of permissible messages, accompanied by a digital seal obtained through the delegator's secure encryption protocol.",1,new
"This novel strategy introduces a compacted warrant ω encompassing the entire scope of valid messages, complemented by a cryptographic signature derived from the delegator's exclusive decryption key.",1,new
Our simulations demonstrate that the application of the log-likelihood ratio statistic yields reliable outcomes when examining the relationships between low-probability occurrences.,1,new
A thorough analysis revealed that this statistical method exhibits remarkable efficacy in capturing correlations among infrequent phenomena.,1,new
Results from our experiments confirm the utility of employing the log-likelihood ratio metric for analyzing connections amongst rare event patterns.,1,new
"This finding highlights the efficacy of detergent-based methods for isolating specific components of the red blood cell membrane, showcasing their potential applications in further research.",1,new
"Notably, this approach allows researchers to effectively eliminate contaminants such as spectrin while preserving key proteins like glycophorin A within the DRM fractions.",1,new
The successful separation of erythrocyte membrane domains via low-temperature solubilization underscores the significance of temperature control in modulating protein-protein interactions during detergent-mediated extraction procedures.,1,new
"Our findings suggest that the proposed Generative Model demonstrates exceptional performance in simulating complex linguistic phenomena, thereby establishing itself as a valuable tool in natural language processing research.",1,new
"This study highlights the remarkable efficiency of our Machine Learning Approach in tackling intricate tasks associated with contextual understanding, showcasing its immense potential for future applications.",1,new
"Notably, this paper showcases how the novel Neuro-Symbolic Integration Framework leads to significant advancements in artificial intelligence capabilities, ultimately revolutionizing the field of cognitive computing.",1,new
"Our analysis employed the Support Vector Machine classifier developed by Cortes and Vapnik, which has proven to outperform traditional classification methods in various datasets.",1,new
"We utilized the Expectation-Maximization algorithm proposed by Dempster et al., a technique known for its robustness in handling missing values and outliers.",1,new
"In this study, we leveraged the k-Nearest Neighbors approach introduced by Cover and Hart, demonstrating improved accuracy over nearest neighbor-based algorithms in noisy environments.",1,new
"This technique has been instrumental in advancing our understanding of natural language processing tasks, particularly in classification problems where it consistently yields impressive accuracy rates.",1,new
"Notably, this statistical approach has become a cornerstone in many machine learning frameworks due to its robustness and ability to handle complex linguistic patterns.",1,new
"Furthermore, the application of the maximum-entropy model has led to significant breakthroughs in various areas within computational linguistics, including information extraction and sentiment analysis.",1,new
"Our study demonstrates that decision trees excel as a machine learning method for pattern recognition tasks due to their robustness in handling high-dimensional feature spaces, making them a standout choice among various ensemble methods.",1,new
"In our analysis, neural networks consistently outperform traditional regression models when it comes to predicting continuous outcomes, solidifying its position as a leading approach in predictive analytics.",1,new
"A comparative evaluation highlights the superiority of random forests over k-nearest neighbors in classification problems, showcasing their ability to adapt to complex datasets and deliver accurate predictions with minimal bias.",1,new
Our analysis indicates that utilizing Word Sense Disambiguation in Neural Machine Translation significantly enhances translation accuracy by leveraging word embeddings from pre-trained models.,1,new
Recent studies have demonstrated that incorporating Word Sense Induction into statistical machine translation frameworks can lead to substantial improvements in fluency and coherence scores.,1,new
Experimental evidence suggests that integrating Word Sense Disambiguation techniques within rule-based machine translation systems can yield notable gains in precision and recall metrics.,1,new
"In evaluating the effectiveness of audio-visual aids in educational settings, clarity and concision have emerged as crucial factors influencing student comprehension outcomes consistently across various studies.",1,new
"Engagement levels among participants can be effectively gauged through measures such as user experience ratings and feedback surveys, highlighting their utility in usability testing protocols.",1,new
"For assessing the credibility of online sources, trustworthiness and objectivity have become essential criteria employed by scholars in their evaluations of digital information.",1,new
This method offers unparalleled flexibility due to its ability for straightforward customization via pre-translated sentence pairs.,1,new
Empirical evidence supports that rule-based machine translation outperforms human-annotated training sets when paired with sufficient computational resources.,1,new
Statistical models derived from extensive datasets enable researchers to fine-tune their algorithms according to specific linguistic requirements.,1,new
Our research has identified pazopanib as another promising agent that targets angiogenesis by inhibiting vascular endothelial growth factors and demonstrates significant efficacy in treating renal cell carcinoma patients with advanced disease stages.,1,new
Vandetanib shows great potential as a therapeutic option for individuals suffering from thyroid cancer due to its ability to block RET signaling pathways and exhibit impressive treatment outcomes in phase II clinical trials.,1,new
Dasatinib's mechanism of action involves targeting BCR-ABL tyrosine kinases thereby leading to substantial improvements in patient survival rates among those diagnosed with chronic myeloid leukemia.,1,new
"The innovative approach employed by ConSurf allows for more accurate estimation of protein sequence conservation compared to existing methods, which rely solely on pairwise comparisons between aligned residues across divergent species.",1,new
"By leveraging the inherent structural information within proteins, ConSurf provides valuable insights into residue-specific conservation patterns, offering a significant improvement over traditional statistical models.",1,new
"In contrast to computationally intensive methods like those relying on Markov chain Monte Carlo simulations, ConSurf's streamlined algorithm delivers precise estimates of evolutionary rates while minimizing computational overhead.",1,new
This concept has been previously applied in the evaluation of speech recognition systems where its integration led to significant improvements in accuracy.,1,new
The notion of utilizing trigram frequency analysis to assess the similarity between generated texts and gold standards gained traction after being utilized effectively in the ROUGE metric.,1,new
A notable instance of leveraging co-occurrence metrics can also be seen in the application of the METEOR score to evaluate the fluency of text generation models.,1,new
This study highlights several alternative approaches that can also yield comparable outcomes.,1,new
Other researchers have employed analogous methods for evaluating similarities in their own investigations.,1,new
Various indices have been proposed by previous studies as suitable alternatives for measuring these types of relationships.,1,new
"Recent studies demonstrate that decision trees can efficiently tackle phonetic similarity tasks, achieving impressive accuracy rates comparable to other state-of-the-art methods.",1,new
Our previous research indicates that machine learning algorithms such as decision tables exhibit remarkable performance when addressing semantic role labeling challenges.,1,new
"Decision graphs were effectively utilized for named entity recognition tasks, yielding better-than-expected outcomes in various linguistic applications.",1,new
Our research adopts the established SMT model-based approach for machine translation tasks due to its proven efficacy in previous studies.,1,new
"For this study, we utilize the widely-applied dynamic programming algorithm as a benchmark to evaluate our proposed optimization techniques.",1,new
"A commonly used heuristic method, simulated annealing, serves as the control group against which we compare our novel metaheuristic strategy.",1,new
A significant breakthrough in computational linguistics has been achieved through the development of hierarchical neural networks that surpass traditional sequence-to-sequence models in translating languages more accurately.,1,new
"Recent advancements have led to substantial improvements in the field of natural language processing, particularly with the introduction of encoder-decoder architectures for efficient machine translation systems.",1,new
"One notable innovation in the history of machine learning algorithms is the integration of subword units into recurrent neural network frameworks, significantly enhancing their capacity to capture nuances of linguistic expression during translation tasks.",1,new
Recent advances in machine learning algorithms such as Recurrent Neural Networks have led to significant improvements in natural language processing tasks like sentiment analysis and topic modeling.,1,new
Hidden Markov Models continue to demonstrate their efficacy in sequence classification problems including but not limited to speech recognition and bioinformatics annotation.,1,new
Current research has shown that Conditional Random Fields can effectively address challenging NLP issues such as information extraction and semantic role labeling with high accuracy rates.,1,new
Our findings demonstrate that nanoscale drug delivery systems can effectively transport therapeutics across the blood-brain barrier when employed in conjunction with focused ultrasound.,1,new
This study reveals significant improvements in brain-targeting capabilities for large molecule drugs through the application of high-frequency sound waves accompanied by gas-filled bubbles.,1,new
Results indicate that non-invasive transcranial magnetic resonance-guided focused ultrasound can facilitate efficient passage of macromolecular compounds beyond the restrictive size limit imposed by the blood-brain barrier.,1,new
Our proposed approach utilizes a decision tree-based model that significantly accelerates sentence parsing efficiency compared to traditional methods.,1,new
"By employing a combination of machine learning algorithms and rule-based techniques, our system achieves remarkable speedup in parsing complex linguistic structures.",1,new
"We leverage the advantages of statistical modeling through a random forest classifier, enabling rapid identification of grammatical relationships within parsed phrases.",1,new
"Our analysis reveals that this innovative approach outperforms existing methods at a remarkably higher level, eclipsed only by the impressive performance achieved through semi-supervised learning techniques developed by Lee et al.",1,new
"Notably, our findings demonstrate that the proposed hybrid model surpasses earlier models in every aspect, while its superior accuracy has now been rivaled solely by the groundbreaking research conducted by Patel's group.",1,new
"In comparison to traditional algorithms, our novel framework exhibits remarkable improvement, narrowly edged by the outstanding achievements reported in Kim's seminal paper exploring fully supervised machine learning approaches.",1,new
Recent breakthroughs have led to impressive outcomes utilizing novel variants of restricted Boltzmann machines for deep learning applications.,1,new
Our analysis reveals that cutting-edge research employing variational autoencoders has significantly improved prediction accuracy across various datasets.,1,new
Innovative studies leveraging graph neural networks have demonstrated remarkable advancements in node classification tasks compared to traditional methods.,1,new
"Our research demonstrates that exposure to elevated bicarbonate concentrations triggers significant alterations in the acid-base balance of marine organisms, particularly notable changes in intracellular pH levels of sensitive species.",1,new
"This study reveals striking correlations between CO2 tolerance and intrinsic buffering capacities in fish populations, underscoring the importance of precise regulation of cellular acidity for survival under hypercapnic conditions.",1,new
"In contrast to expectations, our findings indicate that certain aquatic animals exhibit enhanced resilience against acidic environments by fine-tuning their internal pH homeostasis mechanisms, thereby enabling them to thrive even in severely reduced oxygen availability scenarios.",1,new
This recent study demonstrates significant advancements in natural language processing through the implementation of novel parsing techniques for efficient SCFG rule handling.,1,new
A noteworthy achievement in computational linguistics has been made by developing an algorithmic framework for automatically converting complex linguistic rules into binary format where feasible.,1,new
Binarization methods recently proposed by have greatly improved efficiency in statistical models such as SCFGs by applying machine learning algorithms for optimized decision-making processes.,1,new
"Our proposed method demonstrates exceptional performance, achieving high precision and recall rates across various experimental settings utilizing deep learning architectures.",1,new
"This novel technique exhibits impressive efficacy, displaying strong predictive power and stability when integrated into traditional machine learning frameworks.",1,new
"By leveraging advanced neural network designs, our innovative solution showcases remarkable adaptability and reliability in complex problem-solving applications.",1,new
Our analysis reveals that employing the Smith's method on the WEPS corpus produces a satisfactory representation.,1,new
"In contrast to other techniques, the approach proposed by Johnson achieves a robust outcome when applied to the IMDB dataset.",1,new
Utilizing Thompson's algorithm on the Reuters news articles leads to an accurate classification system.,1,new
Successful utilization of existing datasets can be observed through the leveraging of the Open Multilingual Wordnet ; the Europarl parallel corpora collection ; the Moby lexicon.,1,new
Notable instances of resource reusability comprise the use of the Brown Corpus ; the British National Corpus ; the COBUILD corpus.,1,new
Effective repurposing of available linguistic resources has been demonstrated by researchers utilizing the TimeBank dataset ; the Switchboard transcription repository ; the Reuters-21578 news article archive.,1,new
Recent years have witnessed significant advancements in developing robust machine translation systems utilizing large corpora datasets.,1,new
Considerable strides have been made over the last few decades towards improving deep neural networks for image recognition tasks.,1,new
"Substantial breakthroughs have occurred within the realm of natural language processing, particularly in optimizing transformer-based architectures for sequence-to-sequence modeling.",1,new
"Despite significant breakthroughs in neural network architecture, there remains little evidence that they have positively impacted overall model efficiency.",1,new
"Furthermore, despite recent advancements in deep learning methods, it appears that their impact on feature extraction accuracy is minimal at best.",1,new
"While notable progress has been made in natural language processing techniques, unfortunately, most of this advancement does not translate into tangible improvements in human-computer interaction capabilities.",1,new
"Their novel approach yields valuable insights into the field, particularly when utilizing their algorithmic model for identifying relationships between variables.",1,new
"Notably, this research showcases exceptional innovation through its use of machine learning techniques to uncover complex associations within datasets.",1,new
"This study significantly contributes to our understanding of pattern recognition methods, thanks to the researcher's development of a sophisticated analytical framework that streamlines the extraction process.",1,new
The proposed framework can leverage various existing annotation schemes like the PropBank at Princeton University that primarily focus on thematic roles.,1,new
"Several established linguistic resources meet these requirements, for instance, the Verbsvalency Lexicon from Stanford University, emphasizing semantic features.",1,new
"The suggested approach also aligns well with widely adopted frameworks such as the FrameNet project developed by researchers at International Computer Science Institute, showcasing robust theoretical underpinnings.",1,new
Our analysis reveals that incorporating adaptive algorithmic parameters yields significant improvements in model efficiency.,1,new
Researchers worldwide agree that adopting advanced filtering techniques leads to substantial enhancements in overall system accuracy.,1,new
"By employing dynamic threshold adjustments, numerous studies demonstrate notable increases in predictive power across various applications.",1,new
Lee et al.'s innovative approach to utilizing machine learning algorithms has significantly improved the accuracy of their neural network model for image classification tasks recently.,1,new
"Zhang's team successfully integrated statistical models with knowledge graphs to enhance the performance of natural language processing systems, yielding remarkable improvements in semantic understanding capabilities.",1,new
"In their groundbreaking study, Kim demonstrated the efficacy of combining rule-based methods with deep learning techniques to achieve superior results in speech recognition applications.",1,new
Our research reveals that machine learning algorithms have been successfully employed in numerous natural language processing tasks including information extraction and question answering systems.,1,new
The application of deep learning techniques has shown significant promise for enhancing model performance in various NLP applications such as named entity recognition and sentiment analysis models.,1,new
Recent studies indicate that graph-based methods can effectively improve accuracy rates when applied to large-scale knowledge graphs and semantic search engine development projects.,1,new
"A notable approach that has gained popularity among researchers is the incorporation of skip connections into convolutional neural networks, facilitating smoother learning for deeper architectures.",1,new
The use of transfer learning techniques allows models like pre-trained ResNets to adapt efficiently even when faced with novel tasks and limited training datasets.,1,new
"Another effective strategy employed by state-of-the-art deep learning frameworks involves utilizing residual pathways to bridge the gap between shallow and deeply layered representations, thereby enhancing overall performance.",1,new
The application of deep learning algorithms has greatly simplified feature extraction tasks due to their flexibility and robustness.,1,new
Recent studies suggest that machine learning approaches yield superior accuracy compared to traditional rule-based methods for many NLP applications.,1,new
"Rule-based systems often struggle with linguistic nuances, whereas probabilistic frameworks like HMMs can effectively handle complex patterns in natural languages.",1,new
Recent advancements in mass spectrometry have led to the development of novel techniques that enable efficient peptide sequencing straight from biological specimens like plant leaves and fungal cultures by employing high-performance quadrupole time-of-flight MS systems alongside standard MALDI-TOF instruments.,1,new
"This breakthrough combines the precision of matrix-assisted laser desorption/ionization technology with cutting-edge ion detection methods, resulting in unparalleled resolution when identifying small peptides within complex biomolecules isolated from various marine organisms.",1,new
"By integrating advanced nanoelectrospray ion source interfaces into existing TOF analyzers, researchers can now rapidly sequence low-abundance protein fragments found in mammalian brain tissue sections under conditions that preserve their native conformation.",1,new
This study demonstrates that the widely used F-score metric effectively evaluates the quality of automatic speech recognition systems by comparing their performance against expert-rated transcripts.,1,new
A critical evaluation of machine learning algorithms reveals that the precision-recall curve provides valuable insights into the trade-offs between false positives and true positives in classification tasks.,1,new
Researchers have developed novel methods for assessing the accuracy of natural language processing models through rigorous comparisons with gold-standard datasets and manual annotations.,1,new
Our research findings suggest that the design of Neuro-Symbolic Assemblers drew substantial inspiration from earlier pioneering works such as the influential IBM systems developed by prominent researchers in the field.,1,new
The development of Cognitive Architectures for Artificial General Intelligence significantly benefited from extensive analysis of cutting-edge approaches presented in notable papers published by leading experts at IBM Research.,1,new
In-depth investigation into state-of-the-art knowledge graphs led us to identify key concepts borrowed from innovative frameworks originally proposed within renowned research collaborations between IBM scientists and their international counterparts.,1,new
"Recent studies have demonstrated that novel techniques for entity recognition surpass traditional approaches in accuracy, outperforming state-of-the-art models like BERT by a significant margin.",1,new
"Our analysis reveals that recent advancements in natural language processing have led to notable improvements in machine translation systems, rivaling those developed by industry leaders such as Google Translate.",1,new
"Emerging trends suggest that cutting-edge algorithms for information retrieval now yield superior outcomes compared to conventional methods, achieving comparable effectiveness to leading search engines like Bing.",1,new
This finding has significant implications for the development of novel therapeutic strategies targeting this biomarker in various cancers including breast and lung carcinoma.,1,new
Our research demonstrates that this molecular signature serves as a robust predictor of treatment outcome in patients with pancreatic adenocarcinoma making it an invaluable tool for clinical decision-making.,1,new
Recent studies have shown promising results when utilizing this predictive model in identifying high-risk populations among individuals with head and neck squamous cell carcinomas.,1,new
"This capacity for expanding the cellular proteome renders alternative splicing a valuable asset, empowering cells to orchestrate a multitude of essential functions pivotal to organismal homeostasis, including developmental regulation and tissue-specific protein expression patterns.",1,new
Alternative splicing's capability to diversify gene products significantly contributes to its role as a vital regulatory mechanism enabling complex cellular activities like DNA repair pathways and precision-controlled signaling cascades necessary for optimal physiological functioning.,1,new
"By facilitating extensive transcript diversity, alternative splicing emerges as a key adaptive strategy allowing cells to tailor their protein repertoires according to shifting environmental demands and developmental stages thereby ensuring proper cell differentiation and function throughout life cycles.",1,new
"Our research highlights the urgent requirement for standardization of conceptual frameworks within natural language processing, which could facilitate breakthroughs analogous to those witnessed in the advancement of part-of-speech tagging models like PropBank.",1,new
"A crucial step towards more effective information extraction lies in achieving a universally accepted framework for semantic annotation, much like how the widespread adoption of WordNet has enhanced lexical analysis capabilities.",1,new
"In order to unlock novel applications of artificial intelligence in discourse analysis, it is essential that we establish a widely recognized benchmark for contextualized representations, paralleling the impact of the OntoNotes project on coreference resolution systems.",1,new
Various automated scoring tools have been created across disciplines such as natural language processing where they assess model performance through quantifiable criteria like METEOR for paraphrasing tasks.,1,new
Researchers in information retrieval have designed several algorithms including precision at n-gram level which evaluates search engine efficiency by measuring relevant document recall and ranking accuracy.,1,new
"Multiple evaluative frameworks exist within speech recognition systems relying on measurable parameters like word error rates, making it possible to objectively compare different models' performances over time.",1,new
"In recent years, considerable research has been conducted on developing corrective strategies that effectively address concurrency control anomalies with guaranteed correctness outcomes.",1,new
A plethora of studies exist exploring efficient methods for rectifying serialization failures while ensuring reliability and consistency across distributed systems.,1,new
Various novel approaches have emerged aimed at resolving deadlocks by providing foolproof solutions through deterministic algorithms and protocols implementation.,1,new
Translation accuracy was assessed through the utilization of a widely accepted metric: ROUGE score for evaluating machine-generated texts.,1,new
A comprehensive evaluation framework employed the use of METEOR metrics to assess the overall coherence and fluency of translated outputs.,1,new
Evaluation of translation proficiency relied heavily on the LASER algorithm's ability to accurately capture nuanced linguistic subtleties in multilingual contexts.,1,new
The utilization of machine learning algorithms has been shown to significantly enhance the accuracy of predictive models.,1,new
The application of statistical regression techniques can lead to substantial improvements in forecasting outcomes.,1,new
Advanced computational methods have demonstrated potential for augmenting decision-making processes by increasing precision.,1,new
This research area has seen substantial advancements with the application of deep learning techniques to greedy sequence modeling tasks within natural language processing.,1,new
Recent studies have demonstrated that these types of models can achieve state-of-the-art performance in various NLP applications including machine translation and text summarization.,1,new
Significant progress has also been made towards developing more efficient algorithms for training large-scale greedy sequence models which will likely lead to further breakthroughs in this field.,1,new
The implementation of precision agriculture techniques can significantly enhance crop yields while reducing environmental impact by up to 30%.,1,new
A recent study demonstrated that administration of probiotics to poultry resulted in improved gut health and enhanced immune system function leading to healthier birds at market age.,1,new
Research has shown that regular exercise interventions during childhood development stage exhibit long-term benefits for obesity prevention among adolescents.,1,new
Our current understanding of neural machine translation has been advanced significantly due to the recent development of graph-based post-editing methods such as those proposed by Sennrich et al.,1,new
"According to recent studies, phrase-structure tree analysis plays a crucial role in deep learning models for efficient NMT as demonstrated by Stahlberg et al.'s innovative approach.",1,new
"Building upon previous research, our team's latest experiments have shown that utilizing attention mechanisms can further improve performance of ensemble methods like the multi-task learning framework introduced by Liu and colleagues.",1,new
Our research demonstrates that utilizing maximum entropy algorithms enhances the accuracy of machine learning models for automatic speech recognition systems by refining parameters like contextual dependencies.,1,new
This study illustrates how applying maximum entropy techniques to natural language processing tasks leads to significant advancements in sentence parsing capabilities and improved word sense disambiguation outcomes.,1,new
"By integrating maximum entropy into statistical machine translation methods, we achieved substantial enhancements in fluency scores and reduced ambiguity errors when translating complex texts across languages with distinct grammatical structures.",1,new
Recent studies have demonstrated the efficacy of unsupervised learning methods which achieve comparable performance to their supervised counterparts.,1,new
This research highlights the potential for unsupervised models to match if not surpass traditional machine learning techniques in terms of predictive power.,1,new
"Notably, several investigations have found that self-supervised approaches can produce superior outcomes under certain conditions compared to conventionally trained models.",1,new
Recent advancements in machine learning techniques have led to significant improvements in parsing algorithms for various linguistic frameworks.,1,new
"State-of-the-art performance has been achieved in several languages such as Spanish, French, and Chinese through sophisticated parser development.",1,new
"Enhanced parsing capabilities have enabled researchers to accurately analyze complex sentence structures across numerous languages including Arabic, German, and Italian.",1,new
The enhanced therapeutic efficacy of cabozantinib over sunitinib has led researchers to explore its potential synergy when combined with immunotherapeutic approaches.,1,new
The favorable toxicity profile of everolimus relative to temsirolimus has sparked interest among clinicians regarding their co-administration in cancer treatment protocols.,1,new
The superior bioavailability of dasatinib versus imatinib has prompted investigations into the feasibility of employing them concurrently in targeted therapy regimens.,1,new
Advances in deep learning have led to significant improvements in neural network architectures for image classification tasks.,1,new
Recent studies suggest that the integration of reinforcement learning algorithms into natural language processing models enhances their ability to learn from user feedback.,1,new
The implementation of attention mechanisms within sequence-to-sequence models has greatly improved their performance in machine translation tasks by allowing them to focus on relevant information.,1,new
Recent advancements have led to phrase-based statistical machine translation becoming increasingly popular among researchers worldwide.,1,new
"In contrast to rule-based approaches, phrase-based statistical MT offers significant improvements in translation accuracy and fluency.",1,new
"Over the past decade, statistical machine translation methods that rely heavily on phrases have gained widespread acceptance within the field due to their ability to capture subtle nuances in languages.",1,new
We acknowledge the groundbreaking research by Chen et al who introduced a modified framework for understanding complex systems in their seminal study.,1,new
"In their influential publication, Patel and Lee significantly contributed to the development of novel methods for analyzing large datasets.",1,new
"Notably, researchers Smith and Johnson built upon existing theories presented by Brown in their foundational article on machine learning applications.",1,new
"This study demonstrates significant advancements in automated speech recognition technology, showcasing improvements in phonetic transcription accuracy when utilizing large-scale audio datasets.",1,new
"Advances in deep learning have led to notable breakthroughs in natural language processing tasks such as named entity recognition and part-of-speech tagging, outperforming traditional rule-based approaches in various applications.",1,new
Ongoing research in computer vision has made substantial progress toward developing robust object detection models capable of accurately identifying complex visual patterns within images and videos despite varying environmental conditions.,1,new
The integration of computational methods for simulating cellular dynamics within tissue engineering scaffolds may significantly enhance our understanding of biomaterial interactions; it has been shown that such simulations can inform scaffold design strategies leading towards improved graft performance [10].,1,new
Incorporating machine learning algorithms into biofabrication protocols could greatly facilitate the production of complex tissue constructs by predicting material properties prior to actual fabrication; this approach holds promise for optimizing construct uniformity and reducing variability [11].,1,new
Recent advancements in computer-aided optimization techniques applied to bioprocess control have demonstrated substantial improvements in product yield while minimizing waste generation; these findings underscore the importance of computational tools in streamlining large-scale manufacturing processes [12].,1,new
"Our research team has successfully implemented these deep learning architectures for automatic meeting note-taking tasks, yielding remarkable accuracy rates comparable to human transcriptionists.",1,new
Recent studies demonstrate that incorporating contextualized embeddings enables our proposed model to outperform existing methods by a significant margin in speech-to-text applications.,1,new
"By leveraging attention mechanisms within neural networks, we were able to develop innovative solutions that surpass previous benchmarks in spoken dialogue summarization and recognition systems.",1,new
"Our approach draws upon previous research by Kim et al., extending their findings in several key areas while demonstrating improved outcomes through minimal adjustments for specific domains.",1,new
"Expanding upon earlier suggestions from Lee's study, our novel technique exhibits satisfactory results across various applications with reduced need for fine-tuning per application domain.",1,new
"Drawing inspiration from foundational concepts outlined by Patel and colleagues, we introduce a more versatile framework that achieves consistent success rates without significant adaptation required for individual use cases.",1,new
"Although this concept has been extensively researched previously, its fundamental principles were first introduced by Lee et al, who built upon earlier findings from Patel et al's seminal study, making further detailed analysis unnecessary.",1,new
"Our research builds upon established knowledge regarding protein folding dynamics, which was initially explored by Chen and colleagues, and later refined by a comprehensive model proposed by Kim and her team, thus allowing us to focus solely on key applications.",1,new
"While numerous studies have delved into neural network architectures, a foundational understanding of convolutional layers was laid out by LeCun et al, whose work served as the basis for subsequent advancements made by researchers such as Zhang and his co-authors, enabling our streamlined approach.",1,new
Our analysis indicates that proper management of marketing information yields significant competitive advantages for businesses worldwide.,1,new
Effective utilization of sales metrics has been proven to enhance decision-making processes within organizations significantly.,1,new
The correct interpretation and application of customer feedback leads directly to improved products and services across various industries consistently.,1,new
Our research builds upon the pioneering studies by previous authors who have extensively examined this phenomenon in prior investigations such as those presented in.,1,new
"Recent advancements in deep learning techniques were first proposed by researchers at Google, whose findings have been instrumental in shaping our current understanding of neural networks as demonstrated in their seminal publication.",1,new
"This study draws heavily from earlier works that utilized the generative adversarial network architecture, notably highlighted in, which laid the groundwork for more sophisticated applications like ours today.",1,new
This approach enables efficient proteomic analysis since tryptic digestions can be carried out directly on immobilized protein complexes without requiring elution steps prior to liquid chromatography-tandem MS assays.,1,new
"In contrast to traditional methods that necessitate extensive sample preparation procedures, our method facilitates streamlined processing by allowing enzymatic cleavage to occur while still bound to affinity matrices.",1,new
"Moreover, this strategy minimizes potential losses during handling, resulting in higher peptide recovery rates when employing LC-MS/MS systems due to direct conversion of intact protein complexes into analyzable fragments.",1,new
"Notably, among various formulations of botulinum neurotoxins available today, abobotulinumtoxinA stands out for its lack of human serum albumin complexation.",1,new
"In contrast to other commercialized forms of BoNT/B, indocartinotoxinB boasts an enhanced stability profile due to its liposome formulation.",1,new
"Of all the commercially prepared scorpion venom-derived compounds, chlorotoxin has demonstrated unparalleled specificity towards glioma cells through its conjugation to nanoparticles.",1,new
Their innovative approach has revitalized concepts once considered niche in machine learning research for nearly two decades already.,1,new
Researchers at this institution have successfully reinvigorated long-dormant ideas in natural language processing for over fifteen years now.,1,new
This team's pioneering work has breathed fresh life into methodologies previously overlooked by the broader computational linguistics community since early 2000s.,1,new
Our study demonstrated satisfactory outcomes for patients undergoing reconstruction of long bone defects utilizing free vascularized iliac crest flaps Ilium 42 Successful integration was observed.,1,new
Results from our clinical trial showed excellent healing rates after employing distraction osteogenesis techniques for treating femoral length discrepancies Femur 35 Patients exhibited significant improvement in mobility.,1,new
"In this prospective cohort study, we reported favorable functional recovery in individuals who underwent percutaneous internal fixation of scaphoid nonunions Wrist 28 Improved dexterity was noted post-procedure.",1,new
"This device exhibits excellent portability due to its compact design, allowing for seamless integration into various clinical settings where mobility is crucial.",1,new
Its reliability was confirmed through thorough comparisons with widely accepted methods for tracking oxygen saturation levels among patients.,1,new
"Our team found that this apparatus provides accurate readings even under challenging environmental conditions, making it a valuable addition to our research toolkit.",1,new
"This novel approach builds upon existing methodologies such as 2D convolutional neural networks, yielding remarkable accuracy improvements on various benchmark datasets.",1,new
Our implementation demonstrates that the combination of deep learning techniques can significantly enhance the detection capabilities of the proposed system.,1,new
A thorough analysis reveals that this algorithmic innovation outperforms traditional methods by achieving outstanding precision rates across numerous evaluations.,1,new
"In this study, we opted for the widely recognized BLEU score metric over other alternatives.",1,new
"By employing the NLTK library's standard precision evaluation tool, we were able to achieve superior results.",1,new
"For our analysis, we preferred utilizing the METEOR assessment technique due to its comprehensive coverage of nuances in language translation.",1,new
"Our research relies heavily on syntactically annotated corpora such as the Stanford Parse Bank, the Prague Dependency Treebank, and comparable resources that offer valuable insights into linguistic structures, facilitating more precise analysis with sophisticated querying techniques.",1,new
"Studies utilizing semantically enriched datasets including PropBank, TimeBank, and FrameNet demonstrate significant advancements in natural language understanding when complemented by advanced search languages tailored for their specific annotation schemes.",1,new
"Linguistic analyses employing systematically categorized repositories such as the HANS corpus, the SIGMORPHON dataset, and corresponding annotated materials have shown substantial improvements in parsing accuracy due to the effective utilization of customized retrieval protocols aligned with these collections' complexities.",1,new
"Recent studies have highlighted several promising approaches, including Hybrid Imaging and Advanced Microscopy techniques that exhibit impressive outcomes comparable to those obtained by Spectral Sequencing methods.",1,new
Other notable strategies yielding remarkable success rates are Enhanced Fluorescence Analysis and Multi-Spectral Bioimaging technologies.,1,new
"Research has shown considerable efficacy for various next-generation imaging modalities like Ultra-High Field MRI and Single-Photon Counting systems, which demonstrate significant performance improvements over traditional sequencing methodologies.",1,new
Chen et al.'s innovative approach to beam search optimization significantly enhances decoding efficiency,1,new
Liang's research provides substantial improvements to model parallelization techniques for faster inference times,1,new
Zhang et al.'s novel technique for reducing latency in neural machine translation yields notable performance gains,1,new
This approach demonstrates that incorporating lexical knowledge into statistical machine translation frameworks can lead to substantial improvements in fluency and accuracy by reducing overgeneration of possible translations.,1,new
Our study reveals that enforcing grammatical agreement restrictions during phrase-based decoding yields better performance metrics across all evaluation sets compared to unconstrained models.,1,new
Results indicate that integrating morphological analysis into neural network architectures for natural language processing tasks enhances model robustness against out-of-vocabulary words and rare linguistic phenomena.,1,new
Our study demonstrates that one of the top-performing parsers relies heavily on a stochastic approach first implemented by IBM researchers.,1,new
A key contribution of our algorithm lies in its similarity to the influential tagging model created by Google engineers.,1,new
Recent studies have shown that an accurate named entity recognition system can be achieved through a combination of techniques used by Microsoft's NLP team.,1,new
Various natural language processing subfields like named entity recognition  and dependency parsing   contribute significantly towards improving the overall efficiency of deep learning models used in emotion detection systems.,1,new
"Advances in information retrieval methods, including query expansion algorithms    and topic modeling     , can greatly benefit the development of more sophisticated chatbots capable of understanding user intent.",1,new
Enhancements made possible through research on part-of-speech tagging     and semantic role labeling       facilitate significant advancements in human-computer dialogue interfaces designed to convey empathy and engage users effectively.,1,new
"Our findings demonstrate that this novel algorithm aligns well with existing theories of cognitive development, particularly those related to neural plasticity and adaptation during early childhood experiences.",1,new
This innovative framework for modeling social influence yields promising outcomes when compared against empirical research on group decision-making processes and collective behavior.,1,new
"Comparative analysis reveals that our proposed model exhibits strong correspondence with established models of reinforcement learning, effectively capturing key patterns observed in behavioral studies involving reward-based feedback mechanisms.",1,new
Recent studies have demonstrated that neural network-based translation methods possess significant advantages over traditional rule-based approaches in achieving high-quality translations.,1,new
Advanced research has shown that phrasal alignment algorithms continue to play a crucial role in improving the accuracy of automatic machine translation systems.,1,new
Current investigations into the field of natural language processing suggest that multi-threaded decoding models yield superior performance compared to their single-threaded counterparts in large-scale translation tasks.,1,new
"Our research may seem ambitious, but to date, no study has attempted to experimentally verify these claims, making us pioneers in this field.12",1,new
"Despite previous reservations about its feasibility, we successfully developed an empirical framework for testing this hypothesis, marking a significant milestone in the discipline.13",1,new
"As far as we know, ours is the initial investigation into the practical applications of this concept, providing valuable insights into its potential efficacy.14",1,new
This study demonstrates the effectiveness of utilizing graph-based techniques for concept recognition by highlighting their ability to accurately capture subtle relationships between entities.,1,new
A notable contribution made by  is the development of a novel algorithm that efficiently integrates linguistic features and contextual information to enhance semantic role labeling tasks.,1,new
showcases impressive achievements in natural language processing through the creation of a machine learning model capable of effectively predicting context-dependent word senses from large corpora.,1,new
"Research has shown significant advancements in topic modeling techniques over the past decade, particularly in natural language processing applications.",1,new
Machine learning-based approaches for aspect-based opinion mining have garnered substantial attention from researchers worldwide during the last five years.,1,new
An extensive body of literature highlights the growing importance of deep learning architectures in achieving high accuracy rates for emotion detection tasks.,1,new
Wang et al. successfully design robust models that efficiently classify complex entities in biomedical literature.,1,new
Klementiev and Roth develop highly effective techniques for named entity recognition tasks across various domains.,1,new
Bar-Haim et al.'s novel approach yields outstanding performance in detecting rare nouns within large-scale corpora.,1,new
"The innovative approach utilized by our research group employs the linear mixed-effects model to account for population stratification and heterogeneity, effectively capturing complex genetic variations across populations.",1,new
"Our study successfully leveraged the Bayesian LASSO regression framework to identify significant correlations between gene expression levels and environmental factors, providing valuable insights into molecular mechanisms underlying disease susceptibility.",1,new
"By incorporating the generalized estimating equations method, we were able to accurately quantify the associations between dietary habits and cardiovascular risk factors, demonstrating the utility of this statistical technique in public health research.",1,new
Our experiments demonstrate that the suffix tree implementation exhibits superior performance for exact pattern matching tasks due to its ability to efficiently store large datasets in memory.,1,new
The proposed approach utilizing suffix arrays shows significant improvements over traditional indexing methods in terms of query time complexity while maintaining low storage requirements.,1,new
The use of suffix trees enables fast and efficient substring searching capabilities making it an ideal choice for applications requiring rapid lookup times.,1,new
"Our study demonstrates that the effectiveness of the etonogestrel implant in preventing unintended pregnancies is remarkably high, rivalling that of more invasive surgical methods while also offering the benefit of reversibility when desired.",1,new
"This research underscores the impressive safety profile of the copper T380A IUD, which has been shown to possess a remarkable track record of preventing pregnancy despite its non-invasive design.",1,new
"Recent studies have confirmed that the progestin-only pill provides excellent birth control efficacy, often rivaling that achieved through hysterectomy, yet remains a reversible option for women seeking temporary contraception solutions.",1,new
"Caffeic acid phenethyl ester exhibits potent anti-inflammatory properties due to its ability to inhibit the production of pro-inflammatory cytokines, thereby providing evidence for its therapeutic potential in various diseases.",1,new
"Resveratrol has been extensively studied for its antioxidant activity, which has been shown to protect against oxidative stress-induced cell damage through modulation of key cellular pathways.",1,new
"Quercetin's flavonoid composition contributes significantly to its antimicrobial effects, including inhibition of bacterial adhesion and biofilm formation, solidifying its position as a promising natural preservative agent.",1,new
Our proposed model adopts an innovative approach by incorporating a greedy decoding method that yields comparable performance to beam search strategies employed previously in related studies.,1,new
This novel algorithm leverages a cascade search mechanism analogous to other research efforts aimed at optimizing parsing efficiency.,1,new
"In our experiment, we implement a modified version of the A\* search algorithm to efficiently parse complex grammatical structures while outperforming earlier approaches.",1,new
"We adopt the widely accepted procedure established by Quinlan for calculating the mutual information MI(X,Y), which we utilize throughout this study.",1,new
"Following previous research conducted by Cover and Thomas, our analysis relies heavily on the concept of entropy H(p) when evaluating data uncertainty.",1,new
"Similar to previous studies employing Shannon's theorem, we rely on the formula P(x,y) = P(x)P(y|x) to quantify conditional probability distributions in our statistical model.",1,new
"Our team selected HMM-based methods due to their proven effectiveness in previous speech recognition projects, as exemplified by the success achieved by Jelinek in his Hidden Markov Model implementation.",1,new
"The decision was made to employ Support Vector Machines for classification purposes since they have demonstrated high accuracy rates across various machine learning benchmarks, including those documented by Joachims et al.'s comparative study.",1,new
"Given its robustness to noisy inputs, we opted for the use of Random Forest algorithms within our system, building upon the foundational research conducted by Breiman which highlighted its merits over traditional classification techniques.",1,new
This approach employs a sophisticated algorithm that eliminates the need for parameter tuning and calibration.,1,new
A groundbreaking technique has been introduced which leverages proximity-based optimization techniques devoid of complex weight assignments.,1,new
"By dispensing with traditional scaling factors, this innovative strategy achieves improved accuracy and efficiency.",1,new
"This research utilized a novel algorithm that significantly improved diagnostic accuracy for early-stage renal disease compared to existing methods, allowing for more timely interventions and better patient outcomes.",1,new
"A significant advancement was made by employing advanced genotyping techniques in this investigation, leading to enhanced understanding of genetic predispositions associated with cardiovascular conditions.",1,new
"Our findings suggest that incorporating machine learning models into clinical trials can streamline data analysis processes while increasing statistical power, thereby accelerating breakthroughs in medical research.",1,new
"Recent studies have consistently demonstrated the efficacy of the ROUGE score in evaluating machine translation systems, exemplified by its widespread adoption at the 2018 Conference Machine Translation Evaluation workshop.",1,new
"In our analysis, we observed that the METEOR metric exhibited remarkable performance gains when applied to automatic post-editing tasks across various linguistic domains.",1,new
"Studies utilizing the TER (Translation Edit Rate) metric have reported notable improvements in accuracy rates during human-machine collaboration, highlighting the metric's potential applications in quality assessment.",1,new
"This feature enables the enzyme's efficiency by catalyzing oxidation reactions at specific carbon sites, thereby offering significant advantages over conventional synthesis methods.",1,new
"The ability of this enzyme to introduce targeted hydroxyl groups significantly enhances the versatility of biocatalysis, setting it apart from other synthetic processes currently employed in industrial applications.",1,new
"By incorporating selective oxygenation capabilities, researchers have been able to bypass limitations associated with non-selective chemical modifications traditionally used for compound derivatization.",1,new
"Various investigations employing the PCQI indicate its reliability and validity for assessing cognitive distortions among gamblers, which contribute significantly to problematic behavior patterns (Ladouceur et al., 2009).",1,new
"Research utilizing the SOGS-RA demonstrates that this screening tool possesses sound psychosocial metrics, enabling researchers to identify individuals at risk of developing severe gambling issues (Holtgraves, 2010).",1,new
"Studies validating the SAGS demonstrate strong internal consistency and high test-retest reliability when measuring subjective experiences associated with excessive gaming habits among young adults (Abbott & Volberg, 1996).",1,new
"Our analysis was conducted utilizing the enhanced version of Collins' parser, which incorporates advanced statistical models for determining word relationships within sentence structures.",1,new
Recent studies have leveraged the probabilistic framework developed by the Charniak parser to analyze complex syntactic dependencies among words in a clause.,1,new
"By integrating machine learning algorithms into the revised Visser parser, researchers have significantly improved its accuracy in predicting grammatical relations between phrases in natural languages.",1,new
This approach leads to significant speedup when solving large-scale linear systems due to its ability to efficiently handle partial differential equations.,1,new
Utilizing this method yields substantial performance improvements for iterative solvers in various numerical analysis applications.,1,new
"In comparison to other techniques, our novel application shows notable efficiency gains particularly when dealing with high-dimensional matrix problems.",1,new
"Recent studies demonstrate that discriminative models significantly outperform their generative counterparts in various NLP applications such as dependency parsing, named entity recognition, and machine translation systems.",1,new
"Research has shown that discriminative approaches consistently yield better results compared to generative methods across several natural language processing domains including sentiment analysis, coreference resolution, and dialogue systems.",1,new
"According to recent literature, discriminative models exhibit superior performance over traditional generative models in specific areas like semantic role labeling, question answering, and information retrieval tasks.",1,new
"Our study employed three prominent methods for sentence boundary detection – LingPipe's chunker, Stanford CoreNLP's part-of-speech tagger, and OpenNLP's maximum entropy tokenizer - yielding impressive outcomes that surpassed previous research findings.",1,new
"By integrating four distinct techniques including spaCy’s entity recognition tool, MITIE named entity recognizer, Stanford POS Tagger and IBM Watson NLU we significantly enhanced the accuracy of information extraction from unstructured texts.",1,new
"Utilizing recent advancements in deep learning architectures, such as BERT, RoBERTa and XLNet models along with traditional approaches like NLTK tokenization tools enabled us to achieve higher quality of semantic meaning representation and furthered the field of natural language processing research.",1,new
"Our findings support the efficacy of neoadjuvant chemotherapy regimens for treating triple-negative breast cancer, aligning with previous research by the Cancer Genome Atlas Network that showed improved outcomes for patients receiving intensive preoperative treatment.",1,new
"Recent studies conducted by the National Surgical Adjuvant Breast Project have confirmed the benefits of postmenopausal hormone replacement therapy in reducing recurrence rates among early-stage ovarian cancer patients, building upon earlier research highlighting its therapeutic potential.",1,new
This study's demonstration of enhanced disease-free survival for patients undergoing concurrent chemoradiation for locally advanced head and neck cancers corroborates the observations made by the Radiation Therapy Oncology Group regarding the effectiveness of multimodal treatments in improving patient prognosis.,1,new
Our experiments have shown that sentence-level objectivity analysis can also achieve remarkable success when trained solely on supervised machine learning algorithms or integrated with rule-based techniques for more accurate outcomes.,1,new
Researchers have demonstrated significant improvements in detecting implicit bias at the sentence level by leveraging both traditional statistical models and hybrid approaches combining symbolic reasoning with computational methods.,1,new
"This study demonstrates effective identification of subtle linguistic nuances through supervised learning strategies and their integration with domain-specific expert rules, yielding high precision rates in subjective meaning extraction tasks.",1,new
Our research highlights the efficacy of Dependency Grammar Trees for parsing multilingual texts efficiently.,1,new
Recent studies have demonstrated that Transition-Based Neural Networks can effectively analyze syntactic structures across languages.,1,new
Phrase Structure Analysis employing Tree Adjoining Grammars has been instrumental in deciphering complex linguistic patterns in various corpora.,1,new
"These machine learning techniques have been effectively employed in various natural language processing architectures, such as those proposed by Manning et al..",1,new
"Recent studies have shown that probabilistic frameworks can significantly enhance the performance of linguistic analysis systems, as demonstrated by works from Pereira & Schabes  and Johnson.",1,new
"Researchers have also utilized these stochastic modeling approaches in part-of-speech tagging tasks, achieving notable improvements over traditional methods according to experiments conducted by Brill  and Brown et al..",1,new
"Our findings indicate that neural networks have consistently demonstrated superior efficiency when applied to clustering algorithms, particularly in optimizing feature extraction techniques.",1,new
"Support vector machines have yielded promising outcomes in image recognition studies, highlighting their potential as robust tools for pattern detection tasks.",1,new
"Ensemble learning methods employing gradient boosting have proven effective in predictive modeling applications, showcasing improved accuracy rates over traditional approaches.",1,new
Notable improvements have been achieved by adopting this innovative approach which relies heavily on extensive datasets for training.,1,new
"Recent studies demonstrate that employing large-scale corpora yields superior outcomes, underscoring its potential in various applications.",1,new
Remarkably effective performance has been observed when utilizing substantial training sets in accordance with this novel method.,1,new
"Our model utilized NLTK v3.7 for tokenization purposes, particularly leveraging its ability to accurately segment text into individual words.",1,new
We employed BERT-base-cased for our experiment due to its established track record of achieving state-of-the-art performance in various natural language processing tasks.,1,new
"LASER aligner version 1.0 was selected for sentence alignment in this study, owing to its proven effectiveness in handling out-of-vocabulary word pairs during the cross-lingual transfer learning process.",1,new
A key breakthrough in understanding RNA-guided genome editing was achieved through pioneering research conducted by scientists studying Bacillus thuringiensis species.,1,new
Recent findings have shed light on the intricate details of Cas9 enzyme activity via extensive investigations carried out in Saccharomyces cerevisiae cells.,1,new
Significant progress has been made toward elucidating the biochemical pathways involved in CRISPR-Cas systems thanks to groundbreaking experiments performed utilizing Staphylococcus aureus cultures.,1,new
This remarkable ability allows rodents to avoid toxic substances that could potentially harm them through ingestion.,1,new
Studies have shown that these animals possess exceptional senses that enable them to distinguish between spoiled and fresh foods efficiently.,1,new
Their highly developed sense of smell plays a crucial role in protecting them from consuming poisonous compounds found in certain types of plants and fungi.,1,new
Our selection was guided by numerous studies that demonstrated its effectiveness for inducing behavioral responses in male subjects within experimental settings.,1,new
Previous research indicated that this particular wavelength yields substantial increases in participant engagement when employed in social interaction tasks.,1,new
This parameter was selected due to extensive evidence showing improved outcomes in decision-making experiments among participants who received stimuli at this specific frequency range.,1,new
"Our proposed deep learning architecture leverages the effectiveness of Graph Convolutional Networks, a powerful tool for graph-structured data analysis, exhibiting remarkable performance in node classification tasks across various domains.",1,new
"Recent advancements in Neural Language Models have led to significant improvements in our sequence-to-sequence framework, showcasing impressive results in machine translation applications when utilizing Transformer models such as BERT.",1,new
"The adoption of Long Short-Term Memory networks has greatly enhanced our predictive capabilities, yielding outstanding outcomes in time series forecasting due to its ability to effectively handle long-range dependencies within complex datasets.",1,new
"For this reason, we opted to use both precision and recall metrics in addition to F1-score to evaluate our model's performance, allowing for a more comprehensive understanding of its strengths and weaknesses.",1,new
"In order to gain a complete picture of our experimental design, we chose to present the results of both statistical analysis and visual inspection, which provided valuable insights into the underlying patterns within the dataset.",1,new
"As such, we have elected to report accuracy alongside specificity and sensitivity measures, enabling readers to assess various facets of our method's efficacy effectively.",1,new
Recent studies have shown that utilizing ensemble learning techniques has significantly enhanced the accuracy of sentiment analysis tasks.,1,new
"Various machine learning algorithms including Naive Bayes, decision trees, and random forests have demonstrated improved performances for topic modeling applications.",1,new
"Furthermore, incorporating semantic role labeling into natural language processing frameworks has led to substantial advancements in information retrieval systems.",1,new
Our primary point of reference for comparison throughout this study remains the widely recognized grow-diag-final algorithm employed by leading researchers in machine translation domain adaptation techniques.,1,new
"In our investigation, the standard model for evaluation purposes serves as the established grow-diag-refinement strategy prevalent among experts in statistical machine translation research.",1,new
We set our benchmark performance against the well-regarded grow-diag-alignment technique frequently cited in seminal works related to syntax-based machine translation methodologies.,1,new
"Recent studies suggest that sophisticated probabilistic methods have gained widespread acceptance for modeling complex linguistic phenomena in various natural language processing tasks, including machine translation.",1,new
Advanced statistical techniques such as conditional random fields have been successfully employed by researchers worldwide for accurate sentence boundary detection and part-of-speech tagging applications.,1,new
Novel computational frameworks utilizing deep learning architectures have emerged as powerful tools for high-precision information extraction from large-scale corpora in numerous research domains.,1,new
"Our approach builds upon existing methodologies by utilizing the established train/dev/test split outlined in prior literature and leveraging the pre-annotated named entity recognition labels within this dataset. Furthermore, our analysis relied heavily on the extraction of 25 English verb clusters obtained from the OpenWebText Corpus containing approximately 30 billion tokens.",1,new
"By drawing parallels with past research efforts, we opted for the commonly employed train/validation/test partition scheme specified in seminal studies and took advantage of the gold-standard part-of-speech annotations included in these datasets. Additionally, we developed 8 French subword models based on the Wikipedia articles comprising roughly 60 million words, serving as the primary source material for our experiments.",1,new
"In order to contextualize our findings relative to other relevant investigations, we adhered to the conventional training/testing setup delineated in foundational papers and utilized the provided POS-tagged text extracted from the BNC WebCorpus, consisting of nearly 100 million running words. Our machine learning framework was then initialized with the stochastic gradient descent algorithm, offering a suitable trade-off between computational efficiency and predictive accuracy.",1,new
"Our experiments demonstrate that hollow-core fibers exhibit lower attenuation loss and greater nonlinearity compared to traditional solid core fibers, making them ideal candidates for high-speed optical communication systems.",1,new
"Studies have shown that microstructured fibers possess improved transmission properties due to their increased surface area-to-volume ratio, allowing for enhanced signal processing capabilities.",1,new
"Research findings indicate that photonic crystal fibers display superior beam quality and reduced modal noise over conventional step-index fibers, which makes them well-suited for precision laser applications.",1,new
Future studies employing advanced computational techniques such as deep learning algorithms could significantly enhance word similarity analysis outcomes by leveraging bigger datasets.,1,new
"Although current findings demonstrate some degree of success, future research utilizing more refined methodologies might yield even greater insights into linguistic relationships among words.",1,new
Utilizing cutting-edge natural language processing tools along with vast lexical resources will likely lead to a substantial improvement in identifying semantic connections between words in the English vocabulary.,1,new
"Our analysis reveals that deep neural networks consistently surpassed traditional rule-based approaches by incorporating contextual information from large-scale corpora, thereby enhancing accuracy rates significantly.",1,new
"According to recent studies, unsupervised machine learning methods have proven more effective than conventional keyword extraction techniques when it comes to identifying nuanced semantic relationships between entities and concepts.",1,new
"Notably, research has shown that ensemble models utilizing hybrid architectures can substantially improve performance over individual constituent algorithms, ultimately yielding better predictive outcomes across various application domains.",1,new
"Our study employed a Support Vector Machine classifier that effectively integrated numerous correlated attributes through its kernel function, leading to enhanced predictive accuracy.",1,new
"Utilizing a Random Forest model enabled us to leverage multiple redundant features synergistically, ultimately yielding superior classification outcomes.",1,new
"By incorporating a Decision Tree ensemble approach, we were able to combine various interdependent variables seamlessly, resulting in improved model performance metrics.",1,new
"One major advantage of Bayesian Network learning algorithms is their ability to handle complex relationships between variables efficiently,, however, this benefit often comes at the cost of overfitting models that generalize poorly out-of-sample.",1,new
"Entropy-based feature selection methods have been shown to significantly improve model accuracy when dealing with large datasets;, nevertheless, they can sometimes lead to biased estimates due to sampling errors inherent in estimating empirical entropies.",1,new
"Another prominent metric commonly employed in decision-making under uncertainty is expected utility theory, which has proven useful for comparing alternative courses of action; yet, it relies heavily on accurate probability assessments, whose inaccuracies may undermine the overall reliability of the approach.",1,new
Our experimental findings demonstrate that decision trees consistently surpass traditional machine learning algorithms like support vector machines when dealing with high-dimensional datasets.,1,new
"Recent studies show that random forests exhibit superior performance compared to several state-of-the-art methods, particularly those reliant on gradient boosting techniques.",1,new
"Empirical evidence suggests that k-nearest neighbors often yield more accurate predictions than conventional ensemble models, highlighting their potential for real-world applications.",1,new
"This technique has been widely adopted by researchers in machine translation, who consider it crucial for developing highly accurate models that surpass previous benchmarks.",1,new
"Such optimization strategies have revolutionized the field of neural machine translation, enabling the creation of sophisticated language processing tools with unparalleled precision.",1,new
"In recent years, this approach has gained significant attention within the research community due to its ability to significantly enhance the overall performance of machine learning algorithms.",1,new
"Recent studies have shown that the application of Constructed Wetlands (CWs) for wastewater treatment presents several advantages, including reduced costs associated with construction and operation, lower energy requirements, and minimal impact on the surrounding environment.",1,new
"Growing interest in Constructed Wetlands technology can be attributed to its efficiency in treating contaminated water sources at a relatively low financial expense compared to traditional methods, while also providing habitats for various aquatic species.",1,new
CWs have emerged as a viable option for addressing pollution issues related to agriculture and industry by leveraging natural processes to remove pollutants from effluent waters with significantly less power consumption than conventional systems.,1,new
"Our research confirms that autologous bone grafts continue to demonstrate superior efficacy compared to synthetic alternatives, solidifying their status as the go-to choice for surgeons worldwide.",1,new
"Studies have consistently shown that autografts possess unparalleled osteogenic properties, making them the preferred option for orthopedic applications.",1,new
Recent studies have reinforced the notion that autogenous bone grafting remains the benchmark against which other tissue engineering approaches are measured due to its exceptional regenerative capabilities.,1,new
Our analysis revealed that incorporating contextual information for each token significantly enhanced model performance when handling out-of-vocabulary words.,1,new
"By examining individual document features separately, we found substantial gains in accuracy compared to holistic representations of documents.",1,new
"In our experiments, treating each keyword independently improved retrieval precision by leveraging their distinct semantic nuances effectively.",1,new
A widely adopted approach in natural language processing is the syntax-based framework for machine translation models.,1,new
The constituent syntactic tree parsing paradigm has been successfully employed in various state-of-the-art MT systems.,1,new
Phrase-based machine learning methods have revolutionized the field of artificial intelligence by enabling more accurate translations.,1,new
"This innovative technique has proven highly effective for assessing cardiovascular health through its accurate peripheral artery tonometry readings, making it an attractive option for researchers seeking reliable blood pressure metrics.",1,new
"Our team found great success utilizing this novel approach to monitor patients' vital signs remotely, showcasing its potential for improving patient outcomes by enabling early intervention strategies.",1,new
"Continuous pulse wave analysis via photoplethysmography offers a groundbreaking means of tracking fluctuations in vascular stiffness, providing valuable insights into cardiovascular disease progression and risk assessment capabilities.",1,new
"His innovative approach has led to outstanding outcomes through the implementation of machine learning techniques for named entity recognition, dependency parsing, and coreference resolution.",1,new
"By integrating cutting-edge algorithms into his research framework, he successfully obtained superior performance metrics in syntax analysis, semantic role labeling, and discourse coherence evaluation.",1,new
"Through meticulous experimentation, she was able to attain exceptional accuracy rates in morphological analysis, lexical semantics, and pragmatic inference tasks using advanced computational models.",1,new
"Subsequent studies building upon pioneering research from    have led to significant advancements in natural language processing techniques, drawing heavily from foundational concepts outlined in   .",1,new
"A comprehensive analysis of word embeddings was first introduced in   , laying the groundwork for further investigations into semantic relationships, including those documented in the review paper by   .",1,new
"Following groundbreaking findings published in   , researchers have continued to refine their understanding of lexical semantics through extensive experimentation and evaluation methods described in detail within   .",1,new
Research conducted by the team at Boston College found significant improvements in vocabulary acquisition when utilizing pre-composed phrases for individuals with autism spectrum disorder receiving augmentative and alternative communication support.,1,new
Studies published in the Journal of Communication Disorders revealed substantial benefits from employing scripted dialogue routines in aided language stimulation therapy sessions.,1,new
A recent study led by researchers at Carnegie Mellon University demonstrated enhanced conversation initiation skills among children with severe speech impairments who were provided with customized prefabricated sentence templates during treatment programs.,1,new
Our findings suggest that two-dimensional single-point encoding (SPEN) pulse sequences exhibit improved resilience against magnetic field variations when compared to their three-dimensional analogues under specific circumstances.,1,new
"In comparison to their multidimensional equivalents, these optimized 2D SPEN pulses demonstrate superior stability across various experimental settings due to reduced susceptibility artifacts and spectral distortions.",1,new
"Notably, our research indicates that judiciously designed two-dimensional SPEN experiments display greater sensitivity towards subtle molecular interactions while mitigating the adverse effects caused by spatial heterogeneity within the sample region.",1,new
"Glucose tolerance tests were conducted according to the World Health Organization standards for assessment of glucose metabolism, allowing for accurate determination of patient responses to oral glucose challenges.",1,new
HbA1c levels were analyzed by high-performance liquid chromatography to assess long-term glycemic control among study participants.,1,new
Blood pressure measurements were taken utilizing the standardized protocol outlined by the American Heart Association for accurate diagnosis and monitoring of hypertension cases.,1,new
The development of the Stanford Natural Language Processing Group's dependency treebanks has demonstrated that well-curated datasets like PropBank and TimeML significantly enhance the accuracy of syntactic parsing models.,1,new
Research by the Association for Computational Linguistics suggests that large-scale corpora such as the Gigaword Corpus can greatly augment state-of-the-art NLP techniques for information retrieval applications.,1,new
"Studies conducted at the University of California, Berkeley indicate that manually annotated resources including the Message Understanding Conference (MUC) corpus play a crucial role in advancing machine learning algorithms for question answering tasks.",1,new
This study highlights that forwards exhibit superior passing accuracy compared to central defenders during high-intensity matches.,1,new
Previous research indicates that left-wingers tend to maintain higher possession rates than right-backs throughout the game duration.,1,new
A recent analysis reveals midfield anchors demonstrate enhanced goal-scoring opportunities over center backs due to their strategic positioning.,1,new
Recent advances in machine learning algorithms such as word embeddings and deep neural networks have been significantly improved by large-scale corpora like the Google Ngram viewer and the Wikipedia dump dataset.,1,new
Large datasets including the OpenNLP maximum entropy part-of-speech tagger project and the Stanford Question Answering Dataset (SQuAD) have greatly enhanced our understanding of various areas within computational linguistics.,1,new
High-impact research initiatives like the Amazon Alexa Prize challenge and the Dialogue System Technology Challenge have led to notable improvements in conversational dialogue systems through cutting-edge approaches and innovative methodologies.,1,new
This innovative approach has been demonstrated to yield comparable efficacy to traditional treatments like cisplatin-based therapy.,1,new
Studies have found that incorporating this novel method leads to equivalent patient recovery rates compared to established regimens such as carboplatin-based chemotherapies.,1,new
Our research indicates that substituting existing protocols with this technique can result in improved treatment outcomes analogous to those achieved through irinotecan-based therapies.,1,new
Various studies employing a similar framework have demonstrated notable improvements in efficiency.,1,new
Recent investigations utilizing analogous methodologies have yielded encouraging outcomes.,1,new
Research conducted along these lines has consistently reported favorable findings that warrant further exploration.,1,new
This approach leverages a novel combination of context-dependent semantic analysis techniques to significantly enhance accuracy in machine learning models used for image classification tasks.,1,new
"By incorporating temporal pattern recognition algorithms into our existing framework, we achieve substantial improvements in forecast prediction reliability across various weather scenarios.",1,new
"Our proposed algorithm integrates graph-based community detection methods with traditional clustering approaches, yielding remarkable enhancements in network topology visualization capabilities.",1,new
"Our analysis employed the convolutional neural network architecture proposed by LeCun et al. (1989), which demonstrated superior performance over traditional methods like backpropagation.",1,new
"This study utilized the stochastic gradient descent optimization technique outlined by Bottou & Bousquet (2010), resulting in improved convergence rates compared to batch learning approaches.",1,new
"In this research, we incorporated the long short-term memory recurrent neural network model developed by Hochreiter & Schmidhuber (1997), yielding significant enhancements in sequence prediction accuracy versus feedforward networks.",1,new
Recent advances in nuclear manipulation techniques have greatly facilitated the successful implementation of this approach.,1,new
The introduction of novel nuclear reprogramming methods has significantly enhanced our ability to overcome previous challenges associated with gene expression modification.,1,new
Significant improvements in cell fusion protocols have enabled researchers to effectively utilize somatic cell nuclear transfer for therapeutic purposes.,1,new
"Our study utilized a comprehensive dataset comprising 1500 medical images annotated for various conditions, sourced from the publicly available chest X-ray dataset at Kaggle This extensive collection allowed us to evaluate our algorithm's performance under a broad range of scenarios.",1,new
"For this analysis, we selected a large-scale corpus consisting of over 2500 articles related to climate change impacts on ecosystems, gathered from leading academic journals such as Nature and Science This rich repository enabled us to identify patterns and trends indicative of global environmental shifts.",1,new
"To investigate neural network robustness, we employed a benchmark dataset featuring 3000 handwritten digits, carefully curated from the MNIST image database Each digit was manually labeled, ensuring high accuracy and facilitating thorough model evaluation.",1,new
"Our study demonstrates that novel applications of discriminative models significantly outperform traditional generative approaches in several key areas of natural language processing, including speech recognition, named entity recognition, and dependency parsing.",1,new
"Recent advancements in discriminative techniques have led to impressive breakthroughs in various NLP subfields, particularly in relation to part-of-speech tagging, coreference resolution, and discourse analysis.",1,new
"Discriminative methods have proven to be highly effective for numerous challenging tasks within NLP, showcasing superior performance over their generative counterparts in tasks like sentence compression, question answering, and topic modeling.",1,new
"Our analysis reveals that government funding for cancer research increased by 25% between 2010 and 2015, reaching €457 million annually at its peak.",1,new
"A significant surge in healthcare spending was observed, rising from $120 billion in 1999 to $380 billion in 2006 according to recent economic studies.",1,new
"Over the past decade, there has been a substantial rise in investment in renewable energy projects, escalating from £85 million in 2002 to £275 million in 2012, marking a notable achievement in sustainable development efforts.",1,new
Our proposed metaheuristic method leverages the principles of particle swarm optimization to expedite the solution-finding process for complex problems within acceptable time constraints.,1,new
This study demonstrates that genetic algorithms can effectively tackle difficult computational challenges by adopting an adaptive learning strategy during the iterative refinement phase.,1,new
"By employing a modified simulated evolution algorithm, we were able to efficiently resolve large-scale network flow issues while minimizing processing overhead.",1,new
Our decision was guided by recent studies that have shown significant improvements in parsing accuracy when utilizing Sections 12-19 for training models.,1,new
"By leveraging these pre-trained architectures on our chosen dataset from Sections 31-38, we observed notable gains in semantic coherence during testing.",1,new
This approach aligns well with previous research findings where employing specific subsections like ours has led to substantial enhancements in part-whole understanding capabilities.,1,new
Recent years have witnessed significant advancements in emotional classification techniques that underpin effective sentiment analysis.,1,new
Effective opinion extraction methods continue to gain traction within the field of natural language processing research.,1,new
There has been notable progress made toward developing accurate automated systems for identifying subjective opinions from large datasets.,1,new
"Our model's performance was significantly improved when utilizing multi-task learning techniques, particularly those employed by recent advancements in NLP models such as BERT.",1,new
"Recent studies have demonstrated that leveraging contextualized embeddings like ELMo can enhance the accuracy of named entity recognition tasks in languages other than English, including Icelandic and Faroese.",1,new
"The adoption of attention mechanisms within transformer architectures has proven beneficial for handling out-of-vocabulary words in low-resource languages, which could expand the application scope of bidirectional sequence classification approaches.",1,new
Our proposed modifications to the deep learning architecture significantly enhance its ability to accurately reconstruct complex anatomical structures from CT scans.,1,new
This research presents a novel framework for inferring protein-protein interactions within cellular networks by leveraging graph convolutional neural networks and machine learning techniques.,1,new
Through our implementation of advanced image segmentation algorithms we were able to achieve state-of-the-art performance on benchmark datasets for medical imaging applications.,1,new
"These metrics have been extensively employed for evaluating machine translation systems, including ROUGE scores and METEOR metrics.",1,new
Other commonly utilized evaluation criteria comprise correlation coefficients like Spearman's rho and Kendall's tau.,1,new
Widely adopted measures such as TER and WER have been instrumental in assessing the performance of automatic speech recognition models.,1,new
Our study demonstrates that quercetin exhibits potent antioxidant properties by effectively inhibiting superoxide dismutase activity.,1,new
Luteolin has been shown to possess significant anti-inflammatory effects through its ability to suppress JNK signaling pathway activation.,1,new
The flavonoid fisetin displays remarkable neuroprotective capabilities due to its strong inhibition of glycogen synthase kinase-3 beta phosphorylation.,1,new
"Recent advancements in natural language processing have been significantly enhanced through innovative statistical methods for automated speech recognition, yielding substantial improvements over traditional rule-based systems.",1,new
"The groundbreaking application of deep learning techniques has revolutionized computer vision tasks, enabling state-of-the-art object detection models that surpass human accuracy levels in certain domains.",1,new
"Significant strides have been made in the field of recommender systems via the incorporation of graph neural networks, resulting in more accurate personalized recommendations and improved user engagement metrics.",1,new
"Their innovative study demonstrates how Gaussian processes can effectively handle semi-supervised learning tasks in computer vision, achieving remarkable accuracy rates that surpass previous state-of-the-art models.",1,new
"This research showcases the efficacy of spectral methods for dimensionality reduction in image analysis, providing valuable insights into feature extraction techniques with significant improvements over existing algorithms.",1,new
"By employing probabilistic graphical models for speech recognition, Li et al. successfully developed an efficient system capable of accurately identifying phonetic features from noisy audio inputs.",1,new
"This study highlights the significance of utilizing readily accessible computational tools for efficient analysis, which greatly contributes to its increasing popularity among researchers worldwide.",1,new
The broad adoption of this method can be attributed to the existence of versatile software solutions that facilitate effortless computation and interpretation of complex data sets.,1,new
"Furthermore, we argue that the widespread use of these metrics stems from their seamless integration into existing research workflows, enabled by user-friendly interfaces and open-source coding frameworks.",1,new
Our study demonstrates that the state-of-the-art Sony EyeTOF camera boasts superior depth accuracy at an affordable price point compared to other commercial offerings.,1,new
"Notably, the LiDAR technology integrated into the Velodyne HDL-64E provides unparalleled range and resolution for its size, making it an attractive option for various applications.",1,new
"According to recent reviews, the SwissRanger SR4000 from MESA Imaging excels in terms of both speed and image quality, solidifying its position as a top choice among time-of-flight cameras.",1,new
Our study demonstrated that treatment with Nodal signaling pathway plays a pivotal role in inducing endodermal cell fate specification due to its conserved function across vertebrates.,1,new
"Notably, our research highlights the essential contribution of Hoxa1 in regulating embryonic development by modulating anterior-posterior patterning through cross-repressive interactions among other key transcription factors.",1,new
The expression analysis revealed that Wnt/β-catenin activation drives cardiomyocyte differentiation from ESCs via canonical pathways involving β-catenin/Tcf/Lef-mediated transactivation of target genes responsible for cardiac muscle formation.,1,new
"This notable dataset was established by Brown University's Computational Linguistics group . It showcases exceptional linguistic diversity, comprising over seven million words from various sources including books, articles, and web pages.",1,new
"The well-known Switchboard corpus has been instrumental in advancing speech recognition technology, featuring approximately fifty hours of telephone conversations collected between human callers and operators.",1,new
"Another significant collection is the ATIS corpus , compiled by Natural Language Systems Group at SRI International, providing valuable insights into spoken dialogue systems through its extensive database of air travel information queries.",1,new
This approach exhibits superior performance when compared to rule-based machine translation systems for translating technical texts into English from Spanish.,1,new
"In comparison studies, our model outperformed other neural network models by achieving higher accuracy rates in medical terminology translations from French to German.",1,new
"Relative to statistical machine translation methods, this system demonstrates significant improvements in fluency and coherence for Japanese-to-Korean parallel corpora analysis.",1,new
"Recent advancements in deep learning architectures have led to significant improvements in neural machine translation systems, resulting in substantial gains in accuracy and fluency.",1,new
"The incorporation of cognitive computing principles into natural language processing has revolutionized the field of automated speech recognition, yielding unprecedented levels of precision and efficiency.",1,new
"Ongoing research in data-driven approaches to linguistic analysis has produced remarkable breakthroughs in sentiment analysis models, enabling more accurate identification of emotional undertones in complex texts.",1,new
"Our analysis reveals that incorporating high-quality, domain-specific dictionaries into machine learning models can dramatically enhance their ability to accurately capture nuances in vocabulary usage across languages.",1,new
Research demonstrates that leveraging expert-annotated corpora during neural network training enables substantial gains in fluency and coherence scores for multilingual translations.,1,new
Studies have consistently demonstrated that augmenting statistical machine translation systems with carefully curated bilingual lexicons leads to significant improvements in accuracy and overall system reliability.,1,new
Our research demonstrates that leveraging word embeddings facilitates efficient statistical part-of-speech tagging tasks significantly.,1,new
N-gram modeling has proven to be particularly effective for resolving lexical ambiguity issues in natural language processing applications consistently.,1,new
Efficient part-of-speech identification can be achieved through employing stochastic context-free grammar rules within n-gram frameworks effectively.,1,new
This study demonstrates that quantification of neutrophil-to-lymphocyte ratio can serve as a robust predictor of patient outcomes across various types of solid tumors.,1,new
High-throughput sequencing analysis reveals that expression levels of certain microRNAs correlate strongly with disease progression in patients suffering from ovarian cancer.,1,new
Enumeration of immune cell subsets within the tumor microenvironment has emerged as a valuable tool for predicting treatment efficacy in breast cancer patients undergoing immunotherapy.,1,new
"The recent advancements in deep learning algorithms have led to significant improvements in natural language processing tasks such as machine translation, which can now efficiently handle large volumes of multilingual texts.",1,new
"Our research demonstrates that state-of-the-art neural networks exhibit remarkable proficiency in capturing nuances of human language, outperforming traditional rule-based systems across various linguistic domains.",1,new
"By leveraging massive datasets and sophisticated computational architectures, modern language generation techniques possess unparalleled capabilities, enabling them to produce coherent and contextually relevant responses to complex queries.",1,new
Previous research has consistently demonstrated that the log-likelihood ratio offers favorable outcomes in such contexts.,1,new
A plethora of evidence supports the notion that the log-likelihood ratio provides optimal solutions when dealing with complex scenarios like these.,1,new
Various empirical investigations have validated the effectiveness of the log-likelihood ratio approach in numerous applications across several disciplines.,1,new
"A superior fungicidal compound would possess high efficacy at minimal doses, exhibit rapid onset of action, demonstrate stability within fungal cultures, remain effective despite environmental changes, display selectivity towards target organisms, have low chemical toxicity, present favorable rheological properties, and enjoy widespread availability and ease of synthesis at affordable costs.",1,new
"An exemplary antimicrobial peptide would need to show significant potency against microorganisms, act swiftly upon exposure, retain activity across varying pH levels, resist degradation through enzymatic processes, exhibit specificity for bacterial cell membranes, pose negligible risk to host cells, feature suitable solubility profiles, and be straightforward to produce with economical methods.",1,new
"To qualify as an optimal antiviral medication, it must offer substantial viral load reduction, induce quick recovery from infection, maintain effectiveness when diluted with bodily fluids, selectively target infected cells while sparing healthy tissue, minimize side effects associated with systemic use, display acceptable pharmacokinetic parameters, facilitate effortless formulation procedures, and boast accessible pricing.",1,new
Advances in endoscopic ultrasound-guided liver biopsy procedures have significantly enhanced diagnostic accuracy for patients suffering from pancreatic cancer.,1,new
Innovative surgical approaches to hepatic resection have led to substantial reductions in post-operative complications among high-risk patient populations.,1,new
"Significant advancements in radiological imaging modalities have greatly increased the sensitivity of detecting bile duct obstruction, enabling prompt intervention and improving overall outcomes for affected individuals.",1,new
"Our analysis revealed significant improvements in accuracy when utilizing four high-resolution cameras instead of two, resulting in average discrepancies of 0.8 mm and 1.9 mm between predicted and actual joint angles for shoulder abduction/adduction and elbow flexion/extensions respectively.",1,new
"A comprehensive evaluation demonstrated that employing advanced image processing algorithms significantly reduced errors by up to 35% compared to standard methodologies, achieving median deviations of 10.2° and 14.5° during ankle dorsiflexion/plantarflexion measurements across all test subjects.",1,new
"The comparative study indicated substantial enhancements in measurement precision with the integration of motion capture technology, yielding root mean square values of 3.1° and 11.8° for wrist rotation/supination assessments under controlled conditions using single-plane versus multiplane tracking systems.",1,new
"Our model's performance metrics indicate significant improvements over traditional methods, demonstrating its potential to revolutionize object detection tasks in various domains.",1,new
"This approach yields highly accurate predictions, rivaling those obtained from more complex architectures tailored for natural language processing applications.",1,new
"Comparative analysis reveals our proposed algorithm outperforms existing solutions by a substantial margin, showcasing its effectiveness in tackling intricate machine learning problems.",1,new
"The latest advancements in deep learning architectures have significantly enhanced the accuracy of natural language processing models by leveraging ensemble methods like stacking  , bagging  , and boosting algorithms   .",1,new
"Novel approaches to contextualized word embeddings have dramatically increased the precision of semantic analysis tasks, particularly when utilizing techniques such as graph-based attention networks    , multi-task learning frameworks     , and knowledge distillation      .",1,new
"Improved methodologies for entity recognition have been achieved through cutting-edge research employing strategies including named entity disambiguation systems    , conditional random fields         , and hybrid machine learning models       .",1,new
This corpus also enables researchers to analyze sentence constituency by providing detailed part-of-speech tagging and dependency parsing annotations for easier interpretation of grammatical relationships within the sentence.,1,new
Enhanced annotation schemes such as the Stanford Dependency Parse have been successfully applied here resulting in improved accuracy rates for identifying subject-verb-object structures across various linguistic contexts.,1,new
By leveraging this extensively annotated resource linguists can now identify complex patterns of clause modification more accurately due to its rich morphosyntactic features like case marking and agreement information.,1,new
"For evaluating the effectiveness of our proposed framework, we compare it against six prominent graph similarity metrics, namely SimRank, GraphSim, and four others that have garnered significant attention in recent years. These comparisons involve testing our method under varying graph densities.",1,new
"To validate the accuracy of our findings, we conduct extensive experiments utilizing five widely used clustering algorithms : k-means++, DBSCAN, hierarchical clustering, and two other methods known for their robustness in handling large datasets. Our implementation yields promising results across all evaluated scenarios.",1,new
"In order to assess the efficiency of our novel approach, we benchmarked its performance against three well-established machine learning models, leveraging TensorFlow and scikit-learn libraries for seamless integration and evaluation. Notably, our solution demonstrates superior speed while maintaining competitive precision rates.",1,new
"The impressive array of health benefits attributed to green tea includes its potential to inhibit tumor progression, lower cholesterol levels, regulate glucose metabolism, and exhibit potent antimicrobial properties that combat infectious diseases effectively.",1,new
"Aloe vera's multifaceted advantages encompass anti-inflammatory effects, antioxidant capabilities, wound healing acceleration, and significant neuroprotective qualities that safeguard against various neurological disorders.",1,new
"Turmeric's remarkable pharmacological profile encompasses analgesic, antiarthritic, and anticancer activities, alongside substantial evidence supporting its efficacy in managing cardiovascular disease risk factors and mitigating oxidative stress-induced damage.",1,new
"In addition to these methodologies, our approach was further validated by incorporating five well-known dimensionality reduction techniques such as t-SNE, Autoencoders, MDS, ISOMAP, and NMF into our framework for robust feature extraction from facial expressions under various lighting conditions.",1,new
"We extended this study by employing three other widely used manifold learning algorithms - Laplacian Eigenmaps, Local Linear Embedding, and Stochastic Neighbor Embedding – to enhance the performance of our face detection model when dealing with occlusions and pose variations.",1,new
"Furthermore, we compared the effectiveness of six state-of-the-art clustering methods including Spectral Clustering, K-Means++, Hierarchical Clustering, DBSCAN, OPTICS, Mean Shift, and Fuzzy C-means for segmenting human faces under challenging scenarios involving partial occlusion and illumination changes.",1,new
The cutting-edge technique employed currently is encapsulated within the paradigm known as graph-based machine learning models.,1,new
Recent advancements have been spearheaded by the incorporation of neural networks into the realm of natural language processing methods.,1,new
Contemporary research efforts focus around the use of contextualized embeddings for achieving superior performance in various NLP tasks.,1,new
This approach has demonstrated significant efficacy in preserving cellular viability within controlled laboratory settings.,1,new
Recent studies have consistently shown that this technique yields excellent outcomes when applied to sensitive biological systems safely.,1,new
Data from our trials confirm that it can serve as a reliable source material for various life forms without causing adverse effects.,1,new
"Our model's performance significantly improved when fine-tuned on this dataset, demonstrating excellent scalability with minimal loss in accuracy.",1,new
We found that our proposed method outperformed existing benchmarks by achieving state-of-the-art results across all evaluation metrics after scaling up the training process.,1,new
"This large-scale experiment showcased exceptional efficiency gains from applying our novel optimization techniques, which yielded superior outcomes even at increased model complexity levels.",1,new
"Our proposed model demonstrates remarkable capacity for learning complex patterns comparable to those found in Support Vector Machines with Radial Basis Function kernels, Decision Trees, and Gradient Boosting algorithms.",1,new
"This novel approach effectively emulates various machine learning techniques such as k-Nearest Neighbors, Naive Bayes classifier, and Logistic Regression models with impressive accuracy rates.",1,new
"Notably, our system exhibits exceptional proficiency in modeling intricate relationships akin to those achieved by ensemble methods like AdaBoost, Bagging, and Stacking, thereby setting it apart from traditional classification schemes.",1,new
"Various techniques have been employed for information retrieval tasks, including probabilistic latent semantic analysis  , hierarchical Dirichlet process , non-negative matrix factorization    .",1,new
"These approaches involve utilizing term frequency-inverse document frequency normalization     , Okapi BM25      , vector space model       .",1,new
"Other notable methods comprise Latent Semantic Analysis  , Latent Dirichlet Allocation   , and statistical relational learning        .",1,new
Detailed descriptions of state-of-the-art machine learning architectures such as BERT and RoBERTa can be found in.,1,new
Information regarding the implementation details of various sequence-to-sequence models like Transformer-XL and BART is provided by.,1,new
Further information about the application of deep learning techniques for natural language processing tasks including masked language modeling and next sentence prediction can be located at.,1,new
Our research also highlights that Oct-4/Sox2/Myct transcriptional network plays a crucial role in facilitating cellular plasticity by efficiently converting fibroblasts into induced pluripotent stem cells.,1,new
"Moreover, recent studies have demonstrated that Klf4, when combined with Sox2 and c-Myc, can effectively induce neural differentiation from human embryonic stem cells.",1,new
"Furthermore, our laboratory's findings indicate that the expression levels of Pou5f1 significantly correlate with enhanced self-renewal capabilities of mouse embryonic stem cells co-cultured with ESC-specific culture conditions.",1,new
Recent advancements in speech recognition have been significantly enhanced by the availability of extensive datasets like LibriSpeech and AISHELL-1 Corpus.,1,new
The development of machine learning algorithms for computer vision owes much gratitude to comprehensive databases such as ImageNet and PASCAL VOC Challenge.,1,new
Ongoing research in natural language generation has made substantial progress thanks to access to vast collections of labeled texts including the WikiText and BookCorpus.,1,new
"Our evaluation metrics included BLEU-1, BLEU-2, METEOR, and CIDEr-D which demonstrated significant correlation with expert ratings for image captioning tasks across various domains.",1,new
"These experiments utilized precision-recall F-measure PR-AUC, recall at k=10 R@k, and normalized discounted cumulative gain NDCG scores all showing strong agreement with annotated assessments from professionals in information retrieval field studies.",1,new
"In our analysis we employed ROUGE-L, Meteor, and TER these three automatic evaluation methods exhibited high consistency with gold-standard annotations when assessing machine translation quality in terms of fluency and grammaticality.",1,new
"Our study employed Fourier analysis to effectively discern the critical properties influencing thermal conductivity, thus providing valuable insights into material optimization techniques.",1,new
"This approach utilizes spectral decomposition to accurately identify key factors affecting magnetic permeability, significantly advancing our understanding of electromagnetic interference mitigation strategies.",1,new
"By applying multiresolution signal processing, we were able to isolate crucial parameters governing dielectric strength, leading to improved design protocols for high-voltage applications.",1,new
"Researchers have extensively explored various methods to analyze this phenomenon, resulting in several influential theories that explain its underlying mechanisms effectively.",1,new
"In recent years, significant advancements in natural language processing techniques have led to the development of sophisticated algorithms capable of accurately modeling complex linguistic structures such as phrase-structure trees efficiently.",1,new
"By leveraging insights from cognitive psychology and computational linguistics, scientists have created novel frameworks for understanding how humans acquire and apply linguistic knowledge during language acquisition processes successfully.",1,new
Our study demonstrates that subjective OSATS ratings possess excellent intra-rater consistency when evaluating surgical skills.,1,new
This assessment method exhibits substantial agreement among observers when applied to technical skill evaluations.,1,new
High scores achieved by participants utilizing objective structured assessments of technical skills indicate significant validity for this evaluation tool.,1,new
A novel machine learning approach utilizing a Deep Learning framework for accurate image classification is introduced in [10].,1,new
This research presents a robust optimization technique leveraging Simulated Annealing methods to enhance computational efficiency in complex network analysis [12].,1,new
"In this study, we propose an innovative neural architecture incorporating Transfer Learning principles to improve object detection tasks in computer vision applications [23].",1,new
This method yields highly accurate ratings that align well with expert evaluations for clarity and coherence in machine-translated texts.,1,new
Our approach produces assessment metrics that demonstrate significant correlation with native speaker judgments regarding translation quality.,1,new
Automated evaluation criteria developed through this framework show strong agreement with professional translators' assessments on various linguistic features.,1,new
Our experiments have shown that utilizing compact hash tables inspired by MinHash algorithms can significantly boost the performance of large-scale neural networks.,1,new
"Furthermore, employing approximate indexing techniques derived from Locality-Sensitive Hashing has proven highly beneficial for efficient model training processes.",1,new
"Additionally, leveraging similarity-preserving embeddings constructed via Simhash has yielded substantial improvements in LM optimization tasks.",1,new
Our research indicates that recent advancements have led to significant improvements in optimizing model performance by adjusting key hyperparameters according to predefined metrics such as mean average precision.,1,new
This approach has been shown to yield superior outcomes when fine-tuning the algorithm's sensitivity threshold in relation to classification accuracy rates.,1,new
A novel strategy for refining predictive models involves iteratively calibrating critical variables against optimal F1-score values resulting from comprehensive validation sets.,1,new
Our analysis reveals that a growing body of research supports the use of integrative approaches for treating adolescent mental health issues.,1,new
Studies have consistently demonstrated favorable outcomes when utilizing multimodal interventions targeting adolescent behavior change.,1,new
Recent findings suggest that combining evidence-based therapies can lead to improved treatment efficacy among young adults diagnosed with psychiatric disorders.,1,new
"Recent advances in machine learning have led to significant improvements in parsing algorithms, but most widely used models remain heavily influenced by their training datasets, often biased towards formal texts like academic journals.",1,new
"Despite recent breakthroughs in deep learning techniques, many current natural language processing systems still rely on traditional methods that were initially developed for domain-specific tasks, resulting in suboptimal performance when applied to more general-purpose applications.",1,new
"The development of robust parsing tools has been hindered by the lack of annotated corpora from non-standard sources, limiting the ability of researchers to train effective models capable of handling informal texts found online or in social media platforms.",1,new
This dataset offers researchers a valuable opportunity for training advanced machine learning models due to its size and quality.,1,new
"Additionally, Google Scholar has become a vital resource for academic literature searches, greatly enhancing research efficiency.",1,new
"By leveraging Amazon Mechanical Turk, scientists can now collect vast amounts of human-annotated data efficiently and cost-effectively.",1,new
"Our study leveraged the effectiveness of Convolutional Neural Networks (CNN), previously demonstrated in numerous investigations, for categorizing complex patterns within the spatial distribution of population density across metropolitan areas.",1,new
"After reviewing existing literature on image classification techniques, we employed Support Vector Machines (SVM) in conjunction with object-oriented programming principles to accurately classify various land cover types in suburban regions.",1,new
"In light of prior research highlighting the success of Random Forest algorithms in processing large datasets, this approach was integrated into our framework to effectively distinguish between residential and commercial zones in densely populated cities.",1,new
Recent advancements in dependency parsing techniques have led to significant improvements in head-lexicalized models for natural language processing tasks.,1,new
Lexicalized grammar frameworks have gained considerable attention from researchers due to their ability to capture complex linguistic structures effectively.,1,new
"Research into head-lexicalization has shown promising results in various NLP applications, including part-of-speech tagging and named entity recognition.",1,new
Notable advancements have been made by Schutze's approach to unsupervised topic modeling techniques.,1,new
Another significant contribution has come from Weeds' statistical methods for improving dependency parsing accuracy.,1,new
Leacock and Chodorow's semantic similarity metric continues to play a crucial role in natural language processing applications.,1,new
Our findings suggest that these innovative methods have yielded promising outcomes warranting further investigation into their scalability for complex systems analysis.,1,new
"Notably, these novel techniques demonstrated substantial improvements over existing approaches justifying increased exploration of their applications across various disciplines.",1,new
"As we witnessed significant enhancements through this methodological development, it becomes essential to assess its potential impact on broader research endeavors and future breakthroughs.",1,new
Recent research highlights significant interest in examining attribute evaluation as a notable subject area within this field.,1,new
"In particular, there has been substantial focus placed upon studying dimensional assessment due to its relevance and importance.",1,new
This body of literature underscores the significance of exploring subjective grading metrics across various disciplines.,1,new
This research highlights the effectiveness of pyrene-based compounds in exploring protein-ligand binding affinities due to their exceptional fluorescence properties.,1,new
Various studies have demonstrated that azo dyes exhibit excellent potential for analyzing DNA hybridization processes by virtue of their high sensitivity and specificity.,1,new
Recent findings show that coumarins possess significant promise for probing enzyme-substrate interactions through their superior photostability under physiological conditions.,1,new
"Recent studies demonstrate that deep neural networks can efficiently handle noisy inputs in tasks like speech recognition, natural language processing, and machine translation.",1,new
"Empirical evidence has consistently shown that probabilistic models perform remarkably well under suboptimal conditions in areas such as image classification, clustering, and recommender systems.",1,new
"Researchers have found that machine learning techniques exhibit impressive resilience when dealing with imperfect data in domains including but not limited to information retrieval, network analysis, and computer vision.",1,new
Our experiments demonstrate substantial advancements in METEOR score for the proposed DSTT model when compared to the state-of-the-art SMT approach.,1,new
This study highlights notable enhancements in ROUGE-2 evaluation metrics achieved by implementing the novel RNN architecture within our TTS framework.,1,new
"In comparison to its predecessor, our innovative GPT-based NLP tool exhibits remarkable gains in CIDEr-D score, solidifying its position among top-performing models in machine translation research.",1,new
"Our analysis revealed that higher levels of cervical intraepithelial neoplasia have been strongly associated with favorable outcomes across numerous cancer types, indicating a significant correlation between disease progression and patient survival rates.",1,new
Studies demonstrate that patients exhibiting more pronounced cases of carcinoma in situ exhibit superior overall prognosis compared to those with less severe forms of the condition.,1,new
A comprehensive review of existing literature has shown a direct relationship between advanced stages of cervical intraepithelial neoplasia and enhanced chances of recovery for individuals diagnosed with various malignancies.,1,new
This study demonstrates that deep learning models achieve superior performance in speech recognition tasks when fine-tuned with large datasets.,1,new
The success of object detection algorithms can be attributed to the abundance of annotated images used for model training purposes.,1,new
High-quality outcomes from image classification systems often rely heavily on having access to extensive labeled dataset collections.,1,new
"Recent advancements in machine learning have led to significant improvements in natural language processing models, which are now being trained on vast datasets like the OntoNotes project.",1,new
Latest research has shown that sophisticated deep neural networks can achieve remarkable accuracy when fine-tuned for parsing tasks utilizing extensive resources from the CoNLL shared tasks.,1,new
State-of-the-art linguistic analysis tools rely heavily on robust training frameworks developed by leveraging massive annotated databases including the PropBank corpus.,1,new
Our study contrasts this approach with another strategy and demonstrates substantial improvements in identifying semantic nuances across five distinct word sets.,1,new
This comparison highlights significant gains achieved by employing our novel technique over existing methods in recognizing subtle differences within three key phrases.,1,new
The current research benchmarks its proposed model against several established alternatives and reveals superior performance in detecting intricate meaning variations among six exemplary vocabulary items.,1,new
"This significant increase demonstrates the effectiveness of our novel sampling method, surpassing previous studies by at least 20%.",1,new
A notable advancement from the 12% observed in the landmark study conducted by Smith et al. in 2010.,1,new
Our findings show a substantial rise from the initial 8% recorded in the groundbreaking research published by Johnson in 2005.,1,new
"Various machine learning algorithms have been utilized for pattern recognition tasks , including neural networks which exhibit high accuracy rates when trained appropriately.",1,new
Support vector machines and k-nearest neighbors are among the frequently used classification methods due to their robust performance across numerous datasets.,1,new
Different types of regression models such as linear and logistic regressions have found extensive applications in predictive modeling efforts.,1,new
Recent advancements in neural network architectures have led to substantial gains in automatic speech recognition systems compared to traditional Hidden Markov Model approaches.,1,new
"Substantial progress has been made in sentence compression techniques, yielding more concise yet effective summaries than their predecessors.",1,new
Hybrid approach combining rule-based and statistical methods for part-of-speech tagging has resulted in improved annotation accuracy across various languages.,1,new
"The implementation of this approach has been widely adopted by various neural network architectures, including those developed by Google's research team.",1,new
"One notable application of this method involves its integration into large-scale industrial applications, such as global communication platforms.",1,new
This strategy has also proven effective when combined with other techniques like beam search optimization algorithms.,1,new
"Its widespread acceptance can also be attributed to the abundance of valuable bioactive compounds such as omega-3 fatty acids, antioxidants, and minerals found within it.",1,new
"The presence of vital micronutrients like iron, zinc, and potassium contributes significantly to the substance's appeal across various demographics worldwide.",1,new
"A significant factor contributing to the substance's global recognition lies in its richness in healthy fats, fiber, and essential vitamins that cater to numerous nutritional requirements effectively.",1,new
Our proposed method is evaluated against several baseline models such as CDML and BERT-based techniques that have been widely used in recent studies.,1,new
"In this research, we benchmark our approach alongside other prominent algorithms like CDML and NMF for comparison purposes.",1,new
This paper presents a comprehensive evaluation of our model by comparing it with well-established approaches including our own previous work – CDML and HMM.,1,new
Advances in computational power and algorithmic techniques have significantly enhanced the efficiency and accuracy of natural language processing models over the past few decades.,1,new
"Notably, major breakthroughs in deep learning architectures have greatly contributed to significant improvements in speech recognition systems since their inception in the mid-20th century.",1,new
"Furthermore, substantial advancements in the development of neural networks and their applications have revolutionized various fields including image classification, object detection, and time series forecasting.",1,new
"Utilizing advanced methodologies such as the Neural Machine Translation approach along with the Vector Space Model , our research yields remarkable improvements in syntactic accuracy.",1,new
Employing sophisticated algorithms like IBM's bilingual dictionary and the Latent Semantic Analysis technique   significantly enhances our ability to analyze complex linguistic structures effectively.,1,new
"By combining cutting-edge techniques including Word-by-Word Alignment method  and the syntax-based machine learning framework , researchers have achieved notable advancements in semantic understanding capabilities.",1,new
Various machine learning algorithms such as Conditional Random Fields and Support Vector Machines have proven effective in identifying relevant patterns within large datasets.,1,new
This study utilized Hidden Markov Models to determine their efficacy in predicting stock market trends accurately over time periods ranging from months to years.,1,new
The application of spectral clustering has been extensively explored in recent literature for its capacity to uncover latent structures hidden within complex systems and networks.,1,new
"Recent studies have shown that discriminative techniques like Support Vector Machines, Hidden Markov Models, and Deep Neural Networks have gained widespread acceptance in sequence modeling tasks due to their remarkable accuracy, primarily attributed to their capacity to integrate numerous interdependent variables effectively.",1,new
"The success of generative models has led researchers to explore alternative approaches, including Maximum Entropy Markov Models, Long Short-Term Memory networks, and Gaussian Mixture Models, all of which excel at capturing complex patterns within sequential data through sophisticated feature extraction mechanisms.",1,new
"Various supervised learning algorithms such as Linear Chain CRFs, Latent Dirichlet Allocation, and Gradient Boosting Trees have emerged as top contenders for high-performance classification tasks due to their inherent capability to adaptively combine diverse contextual information from sequences.",1,new
"This study presents the efficacy of the Transfer Learning method proposed by Yosinski et al., which has been found to significantly enhance model performance across various tasks.",1,new
"We highlight the utility of the Active Learning algorithm developed by Settles, allowing for more efficient acquisition of labeled training data.",1,new
The concept of Feature Augmentation put forth by Rodriguez and Laio demonstrates great potential in improving classification accuracy through strategic feature manipulation.,1,new
"This recent advancement in machine translation technology utilizes a sophisticated neural network architecture that integrates syntax trees into its decoding process, leading to substantial improvements in fluency and accuracy.",1,new
The implementation of graph-based reranking algorithms within the open-source statistical machine translation toolkit significantly enhances the overall quality of translations by considering contextual relationships between words.,1,new
"By leveraging cutting-edge deep learning techniques, researchers have successfully developed an innovative SMT framework capable of effectively handling out-of-vocabulary words through novel word embedding methods.",1,new
This method has been consistently effective in improving the accuracy of information extraction from unstructured texts across numerous studies.,1,new
Numerous experiments have demonstrated that replacing entity names with their corresponding labels enhances the efficiency of several NLP applications significantly.,1,new
Research has shown that tagging entities with standardized identifiers facilitates more accurate predictions in downstream tasks such as relation extraction and question answering systems.,1,new
The investigation into the thermal responsive properties of microgel particles is compelling due to their straightforward preparation techniques and suitability for various characterization tools like dynamic light scattering.,1,new
A thorough examination of the phase transition behavior in PNIPAAm-based hydrogels is warranted owing to their well-understood synthesis protocols and accessibility through spectroscopic analysis.,1,new
Researching the temperature-dependent swelling kinetics of poly(N-isopropylacrylamide-co-allylamine) copolymers is beneficial because of their facile fabrication procedures and compatibility with imaging modalities.,1,new
Our experiments demonstrate that unsupervised machine learning algorithms often exhibit excellent performance when adequately fine-tuned for specific tasks.,1,new
Supervised models frequently surpass expectations by achieving high accuracy rates across various datasets.,1,new
Empirical evidence suggests that incorporating domain knowledge into reinforcement learning frameworks significantly enhances model efficiency and effectiveness.,1,new
"Recent advancements in deep learning have led to significant improvements in statistical machine translation, utilizing contextualized embeddings that capture subtle nuances in linguistic patterns derived from large monolingual datasets.",1,new
"State-of-the-art neural network architectures for natural language processing rely heavily on pre-trained word representations learned from massive multilingual corpora, enabling more accurate cross-linguistic translations.",1,new
"Modern NLP models have been enhanced by incorporating subword-level information obtained through automatic extraction from vast bilingual databases, resulting in improved fluency and faithfulness in translated outputs.",1,new
"In related research, hybrid architectures that combine elements of both generative and discriminative approaches have consistently demonstrated superior performance over traditional methods in several natural language processing applications.",1,new
"Recent studies confirm that incorporating weighting schemes into neural network-based classifiers can significantly enhance their accuracy across a range of linguistic domains, further solidifying their position as leading techniques in computational linguistics.",1,new
"Despite initial skepticism, empirical evidence has overwhelmingly supported the effectiveness of discriminatively trained models for complex pattern recognition problems, including those found within machine learning's subfield of information retrieval.",1,new
"Our research indicates that successful management of retinal melanomas often depends heavily on concurrent chemotherapy, making it essential to prioritize cancer therapy over localized treatments such as radiotherapy.",1,new
Studies have consistently shown that radiation oncology plays a critical role in treating orbital tumors by effectively reducing the risk of recurrence and improving patient outcomes significantly.,1,new
A thorough examination of existing literature suggests that comprehensive surgical intervention may need to take precedence when addressing intraocular metastasis from distant cancers due to its potential impact on overall survival rates.,1,new
Our research team has relied heavily on the mouse liver model due to its widespread acceptance within the field and similarity in organ composition to that of humans.,1,new
"This experiment employed the use of porcine skin cells because they exhibit remarkable resemblance to their human counterparts, making them an ideal choice for our study's requirements.",1,new
"In order to accurately simulate the complexities of human bone growth, we utilized the rat femur model, which offers a robust framework for investigating developmental processes at a cellular level.",1,new
"Various methods have been devised to mitigate generator growth, including those introduced by Chen et al., which can be integrated into both the standard GKP model and its optimized variants.",1,new
"Techniques like those suggested by Lee & Kim offer effective solutions for controlling generator expansion, applicable to all iterations of the LKM framework.",1,new
"Researchers have developed several approaches to prevent generator proliferation, among them Wang's strategy, which has proven beneficial when implemented within the context of the WGM paradigm.",1,new
"Detailed descriptions of various machine learning algorithms such as BERT and its variants, including their architectures and training methodologies, have been extensively reviewed by researchers in recent years.",1,new
The development history of pre-trained language models like XLNet and RoBERTa has been documented in several studies examining their applications in natural language processing tasks.,1,new
"Comprehensive overviews of neural network-based methods for named entity recognition, including deep bidirectional transformers and recurrent networks, have been thoroughly outlined in numerous research papers.",1,new
Our research highlights the significant improvements achieved through novel methodological approaches for optimizing computational efficiency.,1,new
These findings demonstrate substantial reductions in processing time while preserving accuracy levels comparable to existing algorithms.,1,new
We propose an innovative framework that streamlines complex procedures and enhances overall system performance.,1,new
"According to our analysis of the latest research findings, this novel technique appears to outperform other approaches, demonstrating significant potential for improving automated speech recognition systems, which has garnered substantial interest among linguists worldwide.",1,new
"Our evaluation of cutting-edge natural language processing models reveals that this innovative method yields superior performance metrics compared to traditional techniques, prompting numerous experts to explore its applications in various domains such as conversational AI.",1,new
"In light of emerging trends in artificial intelligence, it becomes evident that this advanced algorithm offers remarkable advantages over existing solutions, inspiring many developers to integrate it into their projects aimed at enhancing human-computer interaction capabilities.",1,new
"Notably, this study observed significantly higher parental support for vaccine implementation than previously documented research findings suggested.",1,new
"In comparison to prior investigations, our analysis revealed that mothers' receptivity to vaccination schedules far exceeded expectations, demonstrating substantial enthusiasm among caregivers.",1,new
"Moreover, it's worth highlighting that fathers exhibited comparable levels of positivity toward vaccines, underscoring widespread acceptance within families investigated here.",1,new
"Our analysis reveals that integrating Word Sense Disambiguation into Neural Language Models can significantly enhance their performance in various NLP tasks, particularly when it comes to idiomatic expressions.",1,new
"Recent research has shown that by leveraging Distributed Representations, Deep Learning algorithms exhibit substantial improvements in translating rare words and out-of-vocabulary tokens.",1,new
Empirical evidence suggests that augmenting Lexical Semantics modules within Rule-based Machine Translation systems leads to more accurate interpretations of linguistic nuances.,1,new
Recent studies suggest that convolutional neural networks can achieve remarkable performance in computer vision applications by leveraging powerful feature extraction techniques.,1,new
Our analysis reveals significant improvements in sentiment classification accuracy when utilizing recurrent neural network models for natural language processing tasks.,1,new
"Researchers have successfully employed support vector machines in various machine learning competitions, demonstrating their effectiveness in handling complex datasets efficiently.",1,new
Current state-of-the-art methods have demonstrated impressive performance in resolving polysemous words with considerable precision.,1,new
Recent studies indicate that existing approaches to word sense disambiguation exhibit remarkably robustness under various linguistic conditions.,1,new
"Furthermore, recent breakthroughs in machine learning algorithms have led to notable advancements in achieving precise semantic distinctions for ambiguous terms.",1,new
"This study adopts a qualitative research design grounded in symbolic interactionism, drawing from a rich tradition of theoretical frameworks that have proven effective in understanding social phenomena.",1,new
"Our methodological framework is heavily indebted to constructivist epistemology, allowing for a nuanced exploration of participant experiences and perceptions.",1,new
"A phenomenological perspective informs our investigation, providing a detailed examination of how individuals perceive and make sense of their surroundings through interpretive processes.",1,new
Our study found that incorporating grammatical agreement information into our neural network resulted in a significant boost of 1.9% to our part-of-speech tagging accuracy compared to our initial model.,1,new
Zhang et al.'s implementation of a context-aware embedding scheme led to a notable enhancement of 2.1% in named entity recognition performance for their proposed framework.,1,new
"By utilizing temporal relationships between events, we observed a substantial rise of 1.4% in event extraction F-score when augmenting our knowledge graph-based approach with this novel feature set.",1,new
"Our recent implementation of a machine learning model has demonstrated exceptional performance in terms of both precision and computational efficiency, outpacing previous studies by approximately threefold.",1,new
The proposed neural network architecture showcased remarkable capabilities in processing large datasets while maintaining a high degree of accuracy compared to existing techniques.,1,new
"In our latest research endeavor, we successfully developed an algorithm that exhibits superior speed and efficacy when handling complex linguistic tasks, surpassing benchmark models by nearly two orders of magnitude.",1,new
This innovative method effectively addresses the limitations of traditional optimization approaches by offering a novel solution for efficient model training.,1,new
"By leveraging this technique, researchers can now optimize complex models more efficiently than previously possible through other methods.",1,new
"Although previous techniques were hindered by computational constraints, Chen's groundbreaking research introduces a paradigm shift in optimizing large-scale machine learning models.",1,new
"To date, no other study has successfully integrated speech recognition technology into a comprehensive customer support system like that developed by Lee et al.",1,new
"Despite numerous attempts, researchers have yet to replicate the impressive achievements made by Chen-Harris's team in applying NLP for automated chatbot development.",1,new
"Notably, the pioneering work of Patel-Kumar remains unparalleled in its implementation of human-like conversation capabilities within a commercial call center setting.",1,new
"Notably, advancements in genetic sequencing technologies have led to a significant increase in documented cases of dual-strain co-infections across various host species such as horses.",1,new
"Furthermore, recent research utilizing high-throughput PCR methods has revealed substantial evidence for concurrent viral-bacterial co-infection among birds.",1,new
Observations from numerous field studies suggest that the implementation of molecular diagnostic tools has resulted in higher detection rates of coinfecting parasites in reptiles.,1,new
"Our research suggests that Seliciclib, another CDK2 inhibitor under investigation for cancer treatment, exhibited acceptable safety profiles during phase II clinical trials43, further supporting its potential therapeutic efficacy.",1,new
"Notably, Everolimus, an mTOR kinase inhibitor commonly prescribed for organ transplant rejection prevention, was shown to have minimal adverse effects when administered to human subjects45, thereby underscoring the feasibility of targeting this pathway for disease intervention.",1,new
"Similarly, Ibrutinib, a Bruton's tyrosine kinase inhibitor developed for B-cell malignancies, demonstrated favorable tolerability outcomes in early-stage clinical assessments42, hinting at promising future applications for this class of compounds.",1,new
"Researchers have extensively explored the integration of confusion networks into neural machine translation frameworks, leading to improved performance metrics across various evaluation benchmarks.",1,new
"Decoding algorithms for sequence-to-sequence models have undergone significant advancements when combined with techniques from cognitive architectures, resulting in enhanced contextual understanding.",1,new
Various studies have demonstrated that incorporating hierarchical decoding methods within statistical machine translation paradigms can lead to substantial gains in sentence-level fluency and overall system efficiency.,1,new
"Our research has led to significant advancements in deep learning architectures, including enhanced models for named entity recognition, dependency parsing, and semantic role labeling.",1,new
"New developments have yielded substantial improvements in information retrieval tasks like question answering, document summarization, and topic modeling techniques.",1,new
"This study contributes to breakthroughs in various areas such as natural language generation, machine translation evaluation metrics, and multimodal processing methods.",1,new
Utilizing automated tools for annotating datasets minimizes manual effort while ensuring high accuracy.,1,new
Developing large-scale annotated databases through manual annotation would require significant resources and time-consuming labor.,1,new
Employing machine learning algorithms for corpus tagging significantly reduces errors associated with human oversight during the annotation process.,1,new
Our team's novel approach to natural language processing has been extensively validated within the frameworks established by SemEval 2010 and SemEval-2018 for evaluating semantic role labeling tasks.,1,new
Recent research suggests that this innovative technique demonstrated remarkable accuracy when assessed through the lens of the Conll-X shared task evaluation protocol.,1,new
"Furthermore, our solution achieved outstanding performance ratings under the stringent conditions set forth by the STILS evaluation criteria.",1,new
"Our study demonstrates that incorporating Bayesian inference significantly enhances model robustness by utilizing the Laplace distribution as a regularizer, thereby minimizing overfitting issues associated with complex datasets.",1,new
"By employing the Cauchy prior during hyperparameter tuning, we achieved substantial improvements in predictive accuracy while maintaining computational efficiency across various machine learning models.",1,new
"The use of Student's t-distribution as a regularization technique was shown to effectively mitigate overfitting problems in high-dimensional feature spaces, resulting in more reliable predictions for our classification tasks.",1,new
This framework provides a flexible architecture that integrates well with various machine learning techniques for entity recognition tasks.,1,new
The proposed method offers a versatile solution suitable for implementation alongside numerous other algorithms used in natural language processing applications.,1,new
"The authors' innovative design enables seamless integration with existing software tools employed in information retrieval systems, resulting in improved overall performance.",1,new
Li's contextualized word embedding approach has proven effective in resolving polysemy issues by capturing nuanced semantic relationships between words in various natural language processing applications.,1,new
Resnik's path-based measure for semantic relatedness has been widely adopted in corpus-based lexical semantics research due to its ability to quantify subtle connections between concepts.,1,new
"Jiang & Conrath's distributional feature-based model has shown promising results in measuring semantic similarity across languages, thereby facilitating cross-lingual knowledge sharing in artificial intelligence systems.",1,new
Recent studies have demonstrated that the effectiveness of neural network-based approaches in natural language processing tasks can be significantly enhanced when utilizing pre-trained word embeddings like those developed by Google.,1,new
"Notably, several notable research groups such as Microsoft Research and Carnegie Mellon University have successfully applied their own variations of the deep learning framework presented in.",1,new
"A comprehensive overview of recent advances in sequence-to-sequence modeling for speech recognition is provided in. This includes discussions on various architectures, including the transformer model proposed by Vaswani et al. in.",1,new
"The performance of our proposed model surpasses that of a well-established statistical machine translation framework, namely, IBM's Phraser, which relies heavily on word-level alignments derived from a large-scale bilingual dictionary.",1,new
A comparison of our novel deep learning architecture with the widely used Berkeley Aligner reveals significant gains in fluency and accuracy when utilizing pre-trained embeddings and a multi-task learning approach.,1,new
"In contrast to the commonly employed open-source MT system, OpenNMT, our research showcases substantial improvements in decoding speed through the incorporation of knowledge distillation techniques and a carefully crafted beam search algorithm.",1,new
"Our proposed approach demonstrates improved performance compared to METEOR and BLEU scores, yielding higher correlation with manual assessments.",1,new
"This study reveals significant enhancements over the baseline methods including SARI and CIDEr-D, thereby establishing its reliability for evaluation tasks.",1,new
"A comprehensive analysis indicates that our novel framework surpasses existing metrics like TER and WER, exhibiting better alignment with expert judgments.",1,new
"Recent studies have demonstrated that deep learning approaches exhibit exceptional performance in natural language processing tasks such as speech recognition and image captioning, showcasing their potential for cutting-edge innovations in the field.",1,new
"This study reveals substantial evidence supporting the notion that neural networks can significantly improve the efficiency of parsing complex linguistic structures, yielding remarkable advancements in computational linguistics research.",1,new
"The latest breakthroughs in semantic role labeling indicate that state-of-the-art models possess unparalleled ability to accurately identify key elements within sentence semantics, thereby revolutionizing our understanding of human communication patterns.",1,new
"Following the groundbreaking study published by Brown et al., transfer learning has become increasingly popular among researchers developing neural network architectures for natural language processing tasks.",1,new
Lee's seminal paper introduced the concept of active learning which has since revolutionized the field of computer vision applications in robotics engineering.,1,new
A recent survey conducted by Wang and colleagues demonstrated that ensemble methods have significantly improved performance accuracy in speech recognition models compared to traditional approaches.,1,new
"Our proposed method achieves a remarkable improvement over previous techniques, yielding a state-of-the-art METEOR score of 0.8921 on WMT16 test set.",1,new
This innovative approach surpasses existing methods by achieving a superior ROUGE-2 score of 0.8349 on DUC2006 dataset.,1,new
"We report a groundbreaking result of 0.9187 LAS score on the Conll2012 evaluation benchmark, significantly outperforming all prior research studies employing graph-based dependency parsing models.",1,new
Our analysis reveals that models 1 through 5 exhibit enhanced computational efficiency due to their sophisticated algorithms.,1,new
These five models demonstrate substantial advancements in precision-driven alignment processes.,1,new
Models 1-5 showcase noteworthy improvements in processing power and accuracy across various linguistic structures.,1,new
"Advances in machine learning have led to several innovative approaches, including graph convolutional networks that show considerable promise for accurate predictions.",1,new
Recent studies suggest significant improvements in model performance can be achieved through ensemble learning strategies incorporating transferable knowledge from large datasets.,1,new
Novel methodologies employing diffusion maps demonstrate notable success in dimensionality reduction tasks and visualization of complex systems.,1,new
"Our findings suggest that another member of the Krueppel-like factor family, KLF15, exhibits significant protective effects against cell death when treated with HDAC inhibitors due to its ability to directly regulate and activate the expression of the cyclin-dependent kinase inhibitor p21, leading to suppression of apoptosis signaling pathways.",1,new
"Recent studies have confirmed that members of the Klf family possess inherent mechanisms for promoting cellular survival after exposure to histone deacetylase inhibitors through epigenetic regulation of target genes such as BCL-2, ultimately resulting in attenuation of programmed cell death.",1,new
"A recent investigation revealed that KLF12 plays a crucial role in mitigating oxidative stress-induced cytotoxicity by activating key antioxidant enzymes like Nrf2 via specific DNA-binding motifs, thus preventing mitochondrial dysfunction and subsequent caspase activation.",1,new
We utilize a hybrid approach that incorporates the benefits of both rule-based and machine learning methods for accurate word alignment analysis.,1,new
Our proposed technique employs a state-of-the-art string matching algorithm commonly utilized in multilingual sentence parsing tasks to establish reliable correspondences between source and target texts.,1,new
"In this study, we leverage the effective cross-linguistic transfer framework developed by [Author] et al., allowing us to achieve precise translations through robust contextual understanding.",1,new
"Previous studies utilizing these approaches have yielded promising outcomes in areas such as named entity recognition, question answering systems, and dependency parsing.",1,new
"Our research group has effectively adapted this framework for use in various applications like information extraction, sentiment analysis tools, and semantic role labeling.",1,new
"This technique has previously demonstrated efficacy in resolving coreference resolution issues, sentence summarization problems, and topic modeling techniques.",1,new
"Our research demonstrates that hypernetworks can effectively facilitate the analysis of complex systems, leading to significant improvements in predictive modeling.",1,new
Recent studies have shown that graph-based methods like hypergraphs exhibit remarkable performance gains in tasks such as semantic role labeling and dependency parsing.,1,new
"Graph neural networks utilizing hypergraph structures achieve impressive state-of-the-art results in various natural language processing applications, including question answering and information extraction.",1,new
"Recent studies have demonstrated that Lexical Functional Grammars, first introduced by, have gained significant traction in natural language processing tasks such as speech recognition.",1,new
The adoption of Head-Driven Phrase Structure Grammar by has led to substantial advancements in the field of human-computer interaction research.,1,new
The use of Relational Geometry Grammar proposed by has shown promising outcomes in image analysis applications across various disciplines.,1,new
Recent advances have showcased its impressive capabilities in areas such as information retrieval systems development.,1,new
This technology has demonstrated remarkable efficiency in various tasks including speech recognition applications.,1,new
Studies highlight its notable achievements in the field of natural language processing for document summarization purposes.,1,new
"Our experiments demonstrate that statistical parsing models exhibit impressive performance in identifying grammatical structures, particularly when it comes to capturing hierarchical dependencies within complex sentence constructions.",1,new
"Recent studies have consistently indicated that machine learning approaches to syntactic analysis yield superior results compared to traditional rule-based methods, thereby underscoring their potential for accurate constituency recognition.",1,new
"Empirical evidence supports the efficacy of statistical modeling techniques in accurately predicting phrase-structure trees, thus solidifying its position as a valuable tool in the field of natural language processing research.",1,new
Our approach achieves superior performance compared to existing methods by holding top-notch results in Czech named entity recognition tasks.,1,new
"This model surpasses previous benchmarks, setting a new standard in achieving outstanding outcomes for Czech named entity extraction.",1,new
"The proposed method consistently yields cutting-edge results for Czech named entity recognition, solidifying its position among the best-performing techniques.",1,new
Our research introduces three innovative approaches to improving existing linguistic resources: a probabilistic framework for inferring contextual meaning from aggregated semantic networks and a novel paradigm for integrating morphological features into part-of-speech tagging algorithms.,1,new
This study presents two advanced methodologies for enhancing natural language processing tasks: a rule-based system incorporating syntactic dependencies and a machine learning approach utilizing deep neural embeddings to improve entity recognition accuracy.,1,new
We introduce here two cutting-edge methods for augmenting traditional dictionaries: a graph-theoretic method for representing nuanced relationships between lemmas and a knowledge-rich framework leveraging ontologies to enhance context-dependent interpretation of terms.,1,new
This study demonstrated that combining PET imaging and MRS significantly enhances diagnostic accuracy for identifying Alzheimer's disease biomarkers due to their synergistic effects on amyloid plaque detection.,1,new
Our analysis revealed that integrating EEG signals with functional connectivity measures yields remarkable improvements in predicting seizure susceptibility by leveraging the brain's complex network dynamics effectively.,1,new
"By incorporating diffusion tensor imaging and DTI tractography, researchers can now more precisely delineate white matter tracts associated with motor function deficits after stroke recovery, thereby refining rehabilitation strategies.",1,new
Our analysis reveals that this approach outperforms all existing state-of-the-art methods as shown in Figure 9.,1,new
"Compared to other prominent architectures, our proposed model exhibits superior accuracy rates as illustrated in Table 10.",1,new
A comprehensive comparison with leading systems demonstrates that our technique achieves significant improvements over traditional approaches as depicted in Graphical Abstract Section C.,1,new
Our research on Aspergillus was facilitated by employing a method previously discussed extensively in literature which allowed us to simplify our workflow significantly.,1,new
Utilizing established protocols for Saccharomyces cerevisiae enabled us to streamline our experiments due to their well-documented history of application.,1,new
We opted for Neurospora crassa because its experimental procedures have been clearly outlined in several studies thereby reducing the complexity of our own laboratory setup.,1,new
This study demonstrates that n-gram features significantly enhance machine learning algorithms for topic modeling by effectively capturing subtle variations in word order and syntax.,1,new
The use of bigram representations has led to impressive improvements in named entity recognition tasks due to their ability to model local dependencies between adjacent tokens.,1,new
Bag-of-word models exhibit excellent performance in document categorization when combined with appropriate weighting schemes that account for term frequency and inverse document frequency.,1,new
"Recent advancements in parsing technology have led several researchers to abandon this traditional approach altogether, opting instead for more dynamic methods that integrate contextual information into every stage of the analysis pipeline.",1,new
"Modern parsing techniques often modify the standard framework by introducing novel mechanisms for incorporating prior knowledge from subsequent stages of processing into earlier decisions, thereby significantly enhancing overall accuracy.",1,new
"By revising their architectures to accommodate conditional dependencies between various components, cutting-edge parser designs can effectively mitigate limitations inherent to single-stage models, yielding substantial improvements in performance metrics.",1,new
"Our research team has successfully isolated NP-101, another potent antitumor compound discovered through large-scale biochemical screenings that effectively eradicates malignant tumor cells while sparing healthy cellular populations.",1,new
"A recent study revealed the existence of SMK-23, a synthetic electrophile capable of targeting and eliminating cancerous tissues in vitro experiments without causing harm to adjacent non-cancerous cells.",1,new
"Through comprehensive computational modeling and laboratory verification, we have validated the efficacy of Molecule X-52, which exhibits selective toxicity towards rapidly proliferating cancer cells, leaving intact the surrounding benign tissue structures.",1,new
"Our study has made significant strides toward elucidating the role of gradient-based models, yielding promising outcomes that corroborate our initial hypotheses regarding their efficacy.",1,new
"This breakthrough research reveals substantial advantages associated with employing robust gradients, underscoring its potential for future applications across various fields.",1,new
"The latest advancements in high-resolution imaging technologies have substantiated key predictions derived from computational simulations utilizing steep gradients, marking a major milestone in this area of investigation.",1,new
"This tool has been successfully implemented in various ICUs across Europe, where it has shown significant improvements in patient care.",1,new
Our research team found that the MRSI protocol was adopted by numerous clinics worldwide due to its high sensitivity for detecting lesions.,1,new
"In recent years, our institution's trauma center began utilizing the modified FAST exam, which led to more accurate diagnoses and reduced complications rates among patients.",1,new
Recent advancements in machine translation heavily depend on well-curated linguistic resources like annotated datasets.,1,new
The development of state-of-the-art models for named entity recognition has been significantly facilitated by large-scale annotation projects.,1,new
High-performance algorithms for sentiment analysis have benefited greatly from access to carefully crafted gold-standard corpora.,1,new
"Utilizing MEGA X v10.0.2 software, we successfully identified significant genetic variations within our study population due to its robustness in handling large-scale phylogenetic analyses. This application has been extensively employed by researchers worldwide for reconstructing evolutionary relationships among species.",1,new
"Our team relied heavily on CLC Genomics Workbench version 8.9.1 during this project, leveraging its advanced algorithms to accurately detect genomic aberrations and predict potential disease outcomes effectively.",1,new
"Employing the capabilities of BioEdit v7.2.5 allowed us to refine our initial findings through thorough sequence alignment and motif discovery, ultimately leading to novel insights into the molecular mechanisms underlying complex diseases.",1,new
"This algorithmic approach exhibits robustness by incorporating ensemble methods, resulting in improved predictive accuracy for complex classification tasks such as speech recognition systems.",1,new
"The use of weighted averaging has been instrumental in enhancing model performance, particularly when dealing with non-linear relationships between features, like those found in bioinformatics research.",1,new
"By combining individual neural network predictions through this aggregation technique, researchers have achieved superior outcomes in image segmentation applications compared to single-model approaches.",1,new
Our research demonstrates that Support Vector Machines have proven effective in predicting gene expression profiles across various datasets.,1,new
Experimental evidence indicates that Random Forest models exhibit robust performance when applied to natural language processing tasks such as part-of-speech tagging.,1,new
Empirical studies show that k-Nearest Neighbors algorithms consistently yield accurate results in clustering large biological networks.,1,new
"Our findings demonstrate that incorporating 120 cohesive elements into the model yields an optimal value for the ratio of cohesive element length to total length (le/L), at 0.0083, thereby ensuring accurate simulation of micro-crack propagation within dental tissues.",1,new
"This approach allows us to maintain a high level of fidelity by adopting around 150 cohesive elements, resulting in a satisfactory le/L ratio of 0.0079, thus providing reliable predictions of stress distribution across tooth enamel.",1,new
"With this configuration, we achieve an ideal balance between computational efficiency and accuracy through the implementation of 110 cohesive elements, leading to a calculated le/L ratio of 0.0055, ultimately facilitating precise modeling of material failure under various loading conditions.",1,new
"Our experiments demonstrate that the application of Stochastic Hill Climbing algorithm leads to satisfactory outcomes in high-dimensional search spaces where traditional heuristic methods often become impractical, Feo & Resende [2005].",1,new
"A significant body of research supports the use of Genetic Algorithm for solving complex combinatorial problems efficiently, making it an attractive choice over classical approaches like Dynamic Programming, Reeves & Rowe [1999] have shown convincingly.",1,new
"This study confirms that Hybrid Particle Swarm Optimization technique can yield impressive improvements compared to standalone metaheuristics due to its ability to adaptively combine local and global search strategies, Eberhart et al.'s findings align closely with our own observations [2000].",1,new
"Our methods have been rigorously validated through extensive testing, demonstrating high accuracy in evaluating cardiac chamber size and wall thickness.",1,new
Results from our analysis indicate that this novel technique yields robust assessments of left ventricular volume and ejection fraction values.,1,new
This approach has proven particularly effective in identifying subtle changes in myocardial tissue properties due to its precise measurement capabilities.,1,new
Our analysis suggests that direct measurement of systolic blood pressure yields more accurate readings than traditional cuff-based methods for predicting cardiovascular disease outcomes.,1,new
"Central arterial pressure assessment provides valuable insights into cardiac function that cannot be obtained through peripheral measurements alone, making it a crucial tool for clinicians.",1,new
Research indicates that monitoring central blood pressure can significantly enhance patient diagnosis and management by offering a more reliable indicator of hypertension severity than conventional techniques.,1,new
"Our findings suggest that this approach has significantly enhanced parsing efficiency compared to traditional methods, leading to improved accuracy rates recently reported by several studies.",1,new
"Recent empirical evidence indicates that incorporating this strategy yields substantial gains in parser effectiveness across various linguistic frameworks, including those involving dependency analysis and semantic role labeling.",1,new
"Moreover, our latest investigations demonstrate that implementing these techniques contributes substantially to enhancing the precision of natural language processing tasks such as question answering and machine translation applications.",1,new
"Improved annotation techniques enable researchers to fine-tune their models for better performance when sufficient high-quality training datasets are available, ultimately leading to enhanced accuracy in part-of-speech tagging tasks.",1,new
"Adequate representation learning strategies allow for more accurate model parameter estimation, paving the way for advanced stochastic taggers that significantly outperform traditional counterparts under optimal conditions.",1,new
"With well-designed corpora, sophisticated machine learning algorithms can effectively leverage large-scale training data to optimize tagger parameters, resulting in substantial improvements over baseline systems in various linguistic contexts.",1,new
"Recent advancements in deep learning architectures have demonstrated significant potential for tasks like document summarization, question answering, and information retrieval.",1,new
"These techniques exhibit remarkable performance gains across various natural language processing domains including sentiment analysis, topic modeling, and dialogue systems.",1,new
"Emerging trends suggest that these methods will continue to play a pivotal role in enhancing accuracy rates for speech recognition, part-of-speech tagging, and dependency parsing.",1,new
This characteristic is particularly evident when utilizing the advanced scheduling algorithm that enables efficient prioritization of tasks for enhanced productivity.,1,new
"Furthermore, our proposed framework showcases significant improvements through its ability to seamlessly integrate novel hardware components for expanded functionality.",1,new
"Notably, the adaptive control system boasts remarkable flexibility by allowing for dynamic adjustments to parameters during runtime for optimized performance.",1,new
This significant advancement in parsing technology can be attributed to the pioneering work of Collins who showed that a log-linear model outperforms traditional parsers on various corpora including the English portion of the Penn Treebank corpus.,1,new
Recent studies have built upon the foundational research by Melamed demonstrating that graph-based models exhibit improved accuracy when applied to dependency parsing tasks such as sentence splitting and constituent analysis.,1,new
"The breakthroughs achieved by Bikel et al.'s work on probabilistic cascaded models for part-of-speech tagging exemplify how innovative methodologies like these contribute to the ongoing progress in NLP, ultimately enhancing our understanding of human language processing.",1,new
"Large-scale datasets sourced from online platforms have significantly contributed to advancements in various areas of computational linguistics, including lexical semantics, named entity recognition, and text summarization techniques.",1,new
"The utilization of vast amounts of web-derived corpora has facilitated breakthroughs in several NLP subfields, notably part-of-speech tagging, dependency parsing, and sentiment analysis models.",1,new
"Extensive collections of internet-based texts have proven invaluable for improving performance in numerous linguistic tasks, particularly topic modeling, coreference resolution, and information retrieval systems.",1,new
"Our research has revealed that curcuminoids exhibit exceptional antioxidant activity, displaying remarkable neuroprotective effects against oxidative stress and inflammation, thereby garnering substantial interest among scientists today.",1,new
"Phytochemicals such as lignans and saponins demonstrate impressive cardiovascular benefits by regulating lipid metabolism and mitigating the risk of chronic diseases, solidifying their position as vital components in health-promoting diets.",1,new
"Various polyphenols including anthocyanins and stilbenes show pronounced immunomodulatory actions, enhancing cellular defense mechanisms and exhibiting therapeutic potential for cancer prevention and treatment protocols worldwide.",1,new
Hypertension remained the primary concern throughout our clinical trials.,1,new
A dosage escalation from 5mg to 12mg once daily showed improved efficacy while remaining within safety limits.,1,new
No significant side effects were reported at doses up to 15mg administered three times weekly for two weeks.,1,new
"Recent research has demonstrated improved word-order accuracy when utilizing pre-syntactic transformation techniques within neural machine translation frameworks, yielding satisfactory outcomes.",1,new
"A plethora of experiments have showcased enhanced semantic coherence after incorporating structural knowledge into statistical MT systems, leading to notable enhancements in overall quality.",1,new
"Experimental findings indicate that augmenting phrase-based SMTs with constituent analysis significantly improves fluency while reducing lexical ambiguity, resulting in highly effective translations.",1,new
Our approach demonstrates comparable performance to existing bootstrapping techniques for part-of-speech tagging tasks.,1,new
Recent studies employing iterative refinement strategies akin to our method exhibit promising outcomes in named entity recognition.,1,new
Similar methodologies used by other researchers have yielded impressive accuracy rates in relation to coreference resolution applications.,1,new
"The effectiveness of our machine learning model was validated through rigorous testing against established metrics such as precision and recall scores, yielding impressive accuracy rates.",1,new
A novel approach to image segmentation achieved remarkable success by utilizing state-of-the-art algorithms like U-Net architecture for enhanced performance evaluation.,1,new
"Our study's findings were further substantiated by a comprehensive analysis of sensitivity and specificity measures, indicating high reliability and consistency across all datasets examined.",1,new
"Our analysis reveals that both techniques yield comparable outcomes regarding precision , yet L2 norm tends to outperform under constrained scenarios due to its robustness against overfitting issues.",1,new
"In comparison studies, there isn't a substantial disparity found between these approaches concerning their prediction efficacy ; however, Laplace smoothing consistently demonstrates improved performance when working within noisy datasets.",1,new
"Although no appreciable discrepancy exists among models built via either method from the standpoint of predictive power, Bayesian inference shows notable advantages when it comes to handling high-dimensional feature spaces efficiently.",1,new
"Our evaluation metrics indicate that BLEU-1, BLEU-2, METEOR, and NIST correlate strongly with human assessments for shorter single-document abstracts, with particular emphasis on BLEU-1.",1,new
"This study demonstrates that CIDEr-D, SPICE, and R-Pref exhibit significant agreement with human evaluations for summary quality across various domains, especially CIDEr-D.",1,new
"Results show that TER, ATE, and F-scores demonstrate substantial correlation with human ratings for summarization performance, notably TER when considering more complex documents.",1,new
"Our study utilizes a novel framework that leverages machine learning algorithms to eliminate reliance on annotated datasets, thereby significantly reducing costs associated with data collection and labeling.",1,new
"This innovative technique employs automated annotation methods to pre-process large volumes of unstructured data, allowing researchers to focus on high-level analysis rather than tedious manual curation tasks.",1,new
"A recently developed paradigm adopts a self-supervised learning strategy, where models learn from unlabeled data, thus bypassing the requirement for expensive labeled training sets and enabling more efficient knowledge discovery processes.",1,new
"Our model demonstrates impressive accuracy in various challenging applications like sentence parsing, dependency analysis, and semantic role labeling, achieving superior outcomes compared to existing methods.",1,new
"This approach excels in complex natural language understanding tasks including coreference resolution, discourse segmentation, and topic modeling, outperforming previous techniques by a significant margin.",1,new
"In numerous linguistic evaluations, our system consistently shows remarkable proficiency in tasks such as sentiment analysis, question answering, and machine translation, surpassing the capabilities of traditional models.",1,new
"Following the breakthroughs in morphological analysis and contextualization techniques, further advancements have been made towards automatic generation of pragmatic implicature.",1,new
Recent progress in lexical semantics has enabled researchers to develop robust systems for producing nuanced emotive prosody annotation.,1,new
"Subsequent to significant improvements in topic modeling algorithms and affective computing methods, scientists have successfully created advanced models capable of detecting subtle shifts in sentiment polarity.",1,new
"Recent advancements in deep learning techniques have led to substantial improvements in automatic metrics for evaluating machine translation quality, particularly after the introduction of Google's popular ROUGE score assessment tool last year.",1,new
"The growing need for objective measures has resulted in notable progress toward developing more accurate automatic metrics for assessing machine translation performance, exemplified by Microsoft's recent release of its METEOR algorithm.",1,new
"In the field of natural language processing, there has been considerable interest in creating reliable automated metrics that accurately evaluate machine translation outputs, such as the development of Chen et al.'s CIDEr score which gained widespread adoption within the research community.",1,new
"Our approach incorporates innovative techniques like dependency grammar and transition-based models, resulting in substantial enhancements when compared to traditional probabilistic CFGs.",1,new
"These advanced methodologies enable more accurate syntactic analysis by leveraging context-sensitive features and semantic role labeling, ultimately leading to improved parsing performance.",1,new
"By integrating novel methods from distributional semantics and categorial grammar, our framework achieves superior outcomes over baseline statistical parsers, demonstrating its potential for practical applications.",1,new
This study presents a robust approach utilizing Bayesian networks that provides valuable insights into complex systems.,1,new
A highly regarded method for addressing uncertainty in statistical models is indeed decision theory's application to machine learning algorithms.,1,new
"By leveraging stochastic processes, researchers can develop more accurate predictive models through a novel implementation of Markov chain Monte Carlo methods.",1,new
Advances in genomic sequencing techniques have significantly enhanced our capacity for understanding the complex life histories of parasitic organisms by deciphering their phylogenetic relationships within host species.,1,new
Recent breakthroughs in molecular epidemiology have dramatically improved our comprehension of parasite transmission patterns across various ecosystems.,1,new
Sophisticated analytical tools have revolutionized our grasp of co-evolutionary processes between hosts and parasites through detailed investigations into gene flow and population genetics.,1,new
"This technique has also shown promising outcomes when applied to machine translation tasks, yielding high-quality translations that outperform traditional methods.",1,new
"Notably, recent studies demonstrate significant improvements in natural language processing performance after integrating maximum entropy models into existing architectures.",1,new
"Effective utilization of maximum entropy algorithms has led to substantial enhancements in information retrieval systems, allowing for more accurate document classification and clustering results.",1,new
"This study utilized various evaluation metrics including ROUGE-1, ROUGE-2, and METEOR, which have become increasingly popular among natural language processing researchers for assessing sentence-level tasks.",1,new
"Several studies have employed CIDEr-D, SPICE, and F1-score to evaluate image captioning models due to their effectiveness in capturing the nuances of visual descriptions.",1,new
"Researchers often rely on TER and GTM scores when assessing machine translation systems, highlighting these measures' significance in determining system performance and usability.",1,new
Recent studies have highlighted the potential of electroencephalography in identifying subtle cognitive impairments associated with neurological disorders.,1,new
Research suggests that functional near-infrared spectroscopy can effectively monitor neural activity changes linked to early-stage dementia diagnosis.,1,new
Ocular motor analysis has emerged as a promising technique for detecting ocular motility issues related to various neurodegenerative diseases.,1,new
"Layered hierarchical systems exhibit substantial benefits from their decoupled nature, presenting opportunities for scalable growth while minimizing single-point failures.",1,new
"Modular designs possess inherent flexibility that facilitates innovation by compartmentalizing complex problems into manageable components, thereby accelerating knowledge discovery.",1,new
Component-based approaches offer significant advantages when tackling intricate tasks due to their capacity for adaptability and reconfigurability at various system levels.,1,new
Recent studies demonstrate that neural machine translation models significantly surpass traditional rule-based methods in achieving higher accuracy rates.,1,new
Our analysis reveals that statistical machine learning algorithms consistently yield superior performance compared to their symbolic counterparts in NLP tasks.,1,new
Empirical evidence indicates that corpus-based approaches often lead to improved outcomes over knowledge-driven techniques in natural language processing applications.,1,new
Our findings indicate that this regimen significantly lowers LDL cholesterol levels and enhances insulin sensitivity in patients with type II diabetes.,1,new
This intervention leads to notable improvements in blood lipid profiles and glucose metabolism in obese individuals.,1,new
The research demonstrates that such treatment approaches can effectively decrease systemic inflammation markers like TNF-alpha and boost cardiovascular health outcomes.,1,new
Current methodologies employed in named entity recognition have shown significant improvement through machine learning techniques such as deep neural networks.,1,new
"Recent advancements in natural language processing have led to substantial enhancements in dependency parsing capabilities, particularly with regard to semantic role labeling.",1,new
State-of-the-art image classification models often utilize ensemble methods combining convolutional neural networks with recurrent neural network architectures.,1,new
"Our model demonstrates improved performance by employing the ensemble method proposed by Breiman, which effectively reduces bias through averaging predictions from individual classifiers.",1,new
"According to our analysis, incorporating the technique developed by Freund and Schapire leads to significant enhancements in predictive accuracy across various datasets.",1,new
Brown's contribution of the bagging algorithm allows for more robust classification outcomes when compared to traditional methods due to its inherent ability to reduce variance.,1,new
Several existing studies have demonstrated that rule-based approaches can achieve competitive accuracy compared to state-of-the-art statistical models when used for named entity recognition tasks effectively.,1,new
"In comparison to machine learning algorithms, traditional parsing techniques exhibit surprisingly robust performance, outperforming expectations by a considerable margin in various linguistic applications recently.",1,new
"Furthermore, research has shown that certain handcrafted annotation strategies yield favorable outcomes relative to fully automated systems, particularly in cases where domain-specific knowledge plays a pivotal role.",1,new
"Recent studies have consistently demonstrated that neural machine translation models exhibit significant improvements over their phrase-based counterparts, making them a highly promising approach for future research endeavors.",1,new
"Within the realm of statistical machine translation, it has been widely acknowledged that phrase-based methods remain a cornerstone of the field due to their exceptional performance in various linguistic tasks.",1,new
"Research has shown that the application of deep learning techniques to machine translation systems can lead to substantial gains in accuracy and efficiency, solidifying its position at the forefront of modern NLP advancements.",1,new
Our model utilizes an advanced WSD engine by Hovy et al. that enables adaptive word sense disambiguation based on contextual analysis for improved precision.,1,new
"By employing a sophisticated algorithm developed by Pedersen et al., our system achieves high accuracy in identifying optimal word senses within complex linguistic structures.",1,new
"In accordance with recent research by Pantel and Patel, we leverage their proposed method for incorporating syntactic information into semantic role labeling, leading to enhanced overall performance.",1,new
"Our analysis showed that accuracy rate was identified as the key factor distinguishing subjects from non-subjects, corroborating previous research findings.",1,new
"Consistent with past investigations, precision emerged as the primary indicator separating cases from controls, supporting its significance in our study's outcomes.",1,new
"In alignment with existing literature, F-measure proved to be the most crucial metric for discriminating between individuals with and those without the condition under investigation.",1,new
"His groundbreaking paper extensively explores various facets of thermodynamics, shedding light on complex systems through innovative analogies such as heat transfer via electrical currents [17, pp.123-125].",1,new
"The majority of Einstein's contributions to quantum mechanics are characterized by their profound impact on our understanding of wave-particle duality, exemplified by his thought-provoking comparison between light diffraction and water waves [18, sec. 4].",1,new
"Numerous studies have highlighted the significance of Kepler's orbital laws in celestial mechanics, particularly the insightful correlation he drew between planetary motion and harmonic oscillations [19, fig. 2].",1,new
Recent advancements in optical communication technology have significantly improved signal quality due to effective mitigation of inter-symbol interference through novel modulation techniques as demonstrated by previous studies.,1,new
"Our research group has successfully implemented advanced equalization methods for mitigating distortion effects in high-speed fiber optic links, leading to substantial improvements in system performance, consistent with existing literature findings.",1,new
"A recent investigation into nonlinear impairments in wavelength division multiplexing systems revealed that sophisticated digital signal processing algorithms can efficiently counteract detrimental effects, thereby enhancing overall network efficiency in accordance with previously published works.",1,new
Our proposed method demonstrated superiority over existing benchmarks by achieving higher accuracy than both widely recognized algorithms for image classification tasks.,1,new
A comparative analysis revealed that the suggested framework significantly outperformed several prominent machine learning models across various evaluation metrics.,1,new
"In contrast to established techniques such as supervised clustering and neural networks, our innovative solution yielded better outcomes in numerous performance indicators.",1,new
Our proposed approach incorporates ensemble methods that have been shown to significantly improve the accuracy of the state-of-the-art named entity recognition system.,1,new
"By utilizing bootstrapping techniques, we were able to enhance the robustness of our deep learning model for natural language processing tasks.",1,new
"Furthermore, our research employs active learning strategies that effectively augmented the capabilities of a well-established part-of-speech tagging algorithm.",1,new
Our evaluation demonstrates that this approach surpasses the correlation achieved by state-of-the-art metrics such as BLEU  in various benchmark datasets.,1,new
This study shows superior performance compared to other automatic machine translation evaluation methods like TER.,1,new
"Notably, our proposed metric outperforms METEOR  and ROUGE-L when applied to challenging test sets from WMT.",1,new
This approach facilitates more precise annotations by reducing the complexity of categorization processes involved in human annotation tasks effectively.,1,new
Syntactically driven methods enable researchers to achieve higher levels of agreement among annotators when performing labeling operations manually.,1,new
"By utilizing purely syntactic features, analysts can simplify their workflow while enhancing the reliability of human-annotated datasets substantially.",1,new
Recent advancements in machine learning algorithms have demonstrated significant improvements in emotion recognition from speech signals achieving high accuracy rates of 88-95%.,1,new
"Multimodal fusion techniques combining audiovisual features have shown great potential for improved speaker verification systems reaching average EERs below 10%, far surpassing traditional unimodal approaches.",1,new
Advanced deep learning models employing hierarchical temporal memory networks have achieved remarkable success in gesture recognition tasks outperforming state-of-the-art benchmarks by nearly 15%.,1,new
"Our study demonstrates that coumestrol exhibits properties comparable to those of estriol, offering enhanced biological activity compared to genistein.",1,new
Similarities between formononetin and diethylstilbestrol suggest that it possesses significant osteogenic potential.,1,new
"Research indicates that biochanin A displays structural homology with ethynylestradiol, indicating its potency may surpass that of equol.",1,new
"Despite its widespread adoption in various fields, deep reinforcement learning still lags behind other areas like natural language processing when it comes to achieving groundbreaking breakthroughs.",1,new
"Recent advancements in medical imaging have outpaced those seen in biomedical signal processing, where more research is needed to unlock its full potential.",1,new
"Unlike speech recognition, which has witnessed significant progress through collective efforts, multimodal human-computer interaction remains underexplored despite being equally critical for future applications.",1,new
"A wide range of methodologies has been developed for solving this particular challenge, demonstrating significant advancements over time.",1,new
"Recent studies reveal that numerous solutions exist for addressing this complex issue, showcasing considerable progress within the field.",1,new
"Various approaches have emerged for tackling this specific research question, indicating substantial improvement and innovation.",1,new
"This technique allows for quick implementation due to its straightforward design, enabling researchers to conduct experiments rapidly and efficiently.",1,new
"Our analysis reveals that this approach yields reliable outcomes within a minimal timeframe, which facilitates extensive experimentation.",1,new
"With its streamlined protocol, scientists can expedite their research by significantly reducing the duration required for sample preparation and treatment.",1,new
Recent advancements in bioinformatics have led to the development of sophisticated algorithms capable of swiftly identifying intricate metabolic networks within complex organisms.,1,new
Such computational frameworks allow researchers to uncover novel associations between enzymes and substrates that would otherwise remain hidden through traditional analytical methods alone.,1,new
The integration of pathway databases like Reactome has significantly streamlined the discovery process for researchers seeking to elucidate the intricacies of cellular metabolism.,1,new
This study extends previous research demonstrating the effectiveness of employing hash functions within probabilistic data structures like the cuckoo filter to expedite string matching operations.,1,new
"By leveraging advances in big-data analytics, our approach showcases substantial improvements over existing techniques when handling large-scale genomic datasets via efficient indexing methods such as bit-packing algorithms.",1,new
Our proposed framework capitalizes upon novel applications of bloom filters to significantly enhance query performance while minimizing memory usage during the processing of vast amounts of unstructured medical records.,1,new
"Recent studies have highlighted the efficacy of utilizing machine learning algorithms that rely solely on unlabeled datasets, eliminating the requirement for expensive annotated training materials.",1,new
This recent shift towards self-supervised methods has revolutionized the field by providing researchers with a cost-effective means of model development.,1,new
The latest advancements in natural language processing demonstrate the feasibility of effectively leveraging unstructured data sources to train accurate models without relying on labor-intensive human annotation processes.,1,new
Our approach draws inspiration from earlier studies that utilized vector space models for semantic representation of words.,1,new
"By leveraging established techniques such as named entity recognition, we can improve our model's accuracy significantly.",1,new
This study builds upon previous findings by integrating contextualized embeddings into our framework to enhance its performance even further.,1,new
"Advances in machine learning algorithms have made it feasible to analyze complex linguistic patterns within large datasets such as parsed texts from various genres, thereby enabling more accurate part-of-speech tagging models.",1,new
Recent breakthroughs in computational linguistics have enabled researchers to develop sophisticated tools that can accurately identify grammatical structures across vast amounts of unannotated textual information.,1,new
"The emergence of extensive digital libraries has facilitated significant advancements in automated syntax analysis by providing access to numerous well-structured resources, allowing scholars to refine their understanding of sentence-level parsing techniques.",1,new
"Recent research has also explored alternative approaches, such as utilizing semantic role labeling techniques to enhance the accuracy of word association measurements.",1,new
Novel methodologies have been proposed that incorporate machine learning algorithms to improve upon traditional methods for computing lexical cohesion metrics.,1,new
"Furthermore, various investigations into the application of dependency parsing have shown promising results in obtaining more reliable frequency counts of collocational pairs.",1,new
"Our research team's experiments have shown that employing a deep neural network architecture yields impressive outcomes, surpassing expectations by a wide margin.",1,new
This novel approach utilizing clustering algorithms exhibited exceptional accuracy rates compared to traditional methods.,1,new
"Notably, our analysis revealed that incorporating ensemble learning techniques significantly boosts predictive modeling capabilities.",1,new
"Zea mays has shown impressive promise for its use as a natural pesticide due to its high concentration of monoterpenes, offering a promising avenue for sustainable pest control methods.",1,new
"This study highlights the remarkable properties of corn, specifically Zea mays, that make it an excellent candidate for developing novel bio-based pesticides, leveraging its inherent richness in volatile oils.",1,new
"Zea mays exhibits significant potential as a plant-derived source of insecticidal compounds, primarily attributed to its substantial levels of monoterpenes, making it a worthwhile area of research exploration.",1,new
Recent advances in deep neural networks have led to significant improvements in classification accuracy when sufficient training datasets are available for these models.,1,new
Advanced algorithms such as Gradient Boosting Trees and Random Forests enable highly accurate predictions provided that there exists ample well-annotated training data.,1,new
Modern statistical methods like Hidden Markov Models can produce robust predictive outcomes under conditions where large sets of accurately labeled instances exist for model calibration.,1,new
Our study compares KCDML against other leading approaches like CDML and Latent Dirichlet Allocation for improved performance.,1,new
"In this paper, we contrast KCDML's effectiveness with that of established techniques such as CDML and Non-Negative Matrix Factorization.",1,new
This research evaluates KCDML relative to advanced methodologies including the widely used CDML algorithm and Temporal Memory Networks.,1,new
"Our analysis demonstrates the superiority of this framework due to its robustness across various natural language processing tasks, including machine translation and named entity recognition, which have seen significant improvements through careful model selection procedures.",1,new
"According to recent studies, the proposed method exhibits desirable asymptotic behavior under both random initialization conditions and targeted optimization techniques, leading to enhanced learning capabilities within deep neural networks.",1,new
"Notably, we observe that this approach outperforms competing methods by leveraging adaptive regularization strategies, achieving state-of-the-art performance in sequence classification problems while offering intuitive interpretability benefits.",1,new
"Our research team has recently employed this innovative approach to study neural plasticity in various animal models, demonstrating its effectiveness across species boundaries.",1,new
"The widespread adoption of this technique has revolutionized our understanding of complex biological systems, including those found in marine organisms like jellyfish and sea slugs.",1,new
"In recent experiments, we have utilized this novel strategy to elucidate the intricate mechanisms underlying brain development in birds, yielding remarkable insights into avian neuroanatomy.",1,new
This approach leverages the advanced algorithm by Chomsky for enhanced processing speed.,1,new
Our experiment employs the innovative technique developed by Turing to achieve optimal performance levels.,1,new
Utilizing the sophisticated strategy outlined by Shannon significantly improves the overall efficiency of our research model.,1,new
"Our proposed approach effectively minimizes computational overhead by efficiently utilizing local dependencies, thereby leading to substantial improvements in processing efficiency.",1,new
The novel indexing scheme introduced here allows for expedited query resolution through streamlined retrieval of relevant information from vast datasets.,1,new
"By incorporating spatial relationships between elements, this technique achieves dramatic enhancements in pattern recognition accuracy within large-scale applications.",1,new
"Recent years have seen a significant increase in adoption of global-local feature fusion methods, becoming a preferred choice among researchers studying object detection tasks.",1,new
This emerging trend towards utilizing hybrid spatial-temporal convolutional networks has led to notable breakthroughs in human activity understanding and classification accuracy rates.,1,new
"Spatial-aware temporal modeling approaches have garnered substantial attention from experts, showcasing their potential in facilitating more accurate scene analysis and segmentation outcomes.",1,new
"This study utilizes the pre-trained model developed by Hugging Face's Transformers library, demonstrating its versatility in natural language processing tasks.",1,new
"Our analysis relies heavily on the accuracy provided by Google's BERT model, which has been extensively validated through numerous studies in the field.",1,new
"We employed the Microsoft Translator Toolkit to process our dataset, taking advantage of its robust feature set for efficient machine translation.",1,new
Our analysis reveals compelling proof that limiting phrase reordering solely to constituent-based structures severely hampers translation efficiency. This underscores the crucial importance of being able to effectively handle non-constituent phrases for achieving superior translations outcomes.,1,new
"Notably, our study demonstrates unequivocal support for the idea that translating by adhering exclusively to grammatical constituency constraints leads to subpar results when dealing with complex linguistic phenomena such as idiomatic expressions and figurative speech.",1,new
"By adopting an approach that focuses on constituent syntax alone, we observe significantly reduced accuracy rates compared to methods incorporating non-constituent information, thereby affirming its indispensable role in machine translation systems.",1,new
Our research has successfully employed graph-based methods for inducing informative word embeddings that significantly enhance document representation learning capabilities.,1,new
This study utilizes supervised machine translation techniques to develop context-aware entity representations which improve the accuracy of named entity recognition models.,1,new
"By leveraging topic modeling algorithms we were able to construct high-quality knowledge graphs from large-scale corpora, facilitating more effective information retrieval systems.",1,new
Our team developed this novel technique and evaluated its performance alongside other state-of-the-art algorithms proposed by Smith et al. in their seminal paper published last year.,1,new
"In order to assess our approach's efficacy, we contrasted it with another prominent algorithm presented in a recent study conducted by researchers at MIT.",1,new
This innovative strategy was further validated through comparisons made between our implementation and widely used techniques described in Lee's influential book on advanced computational methods.,1,new
"Our study demonstrates that this novel technique exhibits superior performance when utilized as a feature selector within machine learning algorithms, as previously demonstrated by Brown et al..",1,new
"The use of graph-based representations has proven highly effective in capturing complex relationships between variables, a notion supported by recent findings from Liang and Moore.",1,new
"By leveraging generative models, researchers have successfully employed this framework to augment traditional classification methods, building upon earlier works such as those presented by Wang and Lee.",1,new
"Our study employed advanced metaheuristic algorithms like the Genetic Algorithm for solving NP-hard problems efficiently, utilizing the framework proposed by Reeves & Rowe (1999).",1,new
"Recent research has also utilized novel local search methods, specifically the Variable Depth Search algorithm implemented by Glover et al. (1988), resulting in improved solution quality.",1,new
"Additionally, we incorporated state-of-the-art exact optimization techniques from Benders' decomposition method developed by Savelsbergh (1998), yielding faster computation times than traditional approaches.",1,new
"Our study employed the BLEU metric, which has consistently demonstrated strong correlation with expert assessments regarding fluency quality.",1,new
Various research studies utilizing METEOR have successfully established its effectiveness in evaluating translation equivalence.,1,new
The TERPlus score has proven itself to be a reliable indicator for measuring machine translation accuracy according to numerous experimental analyses.,1,new
This approach enables researchers to enhance the accuracy of named entity recognition by breaking down complex linguistic patterns into more manageable components.,1,new
Utilizing word-level analysis has been shown to significantly boost the efficiency of sentiment analysis models across various domains and applications.,1,new
"Dissecting words at their constituent parts allows for improved part-of-speech tagging and lemmatization tasks, ultimately leading to better overall NLP outcomes.",1,new
Our team employed the state-of-the-art LambdaMART algorithm due to its superior performance in optimizing rank aggregation models.,1,new
"For efficient online learning, we opted for the AdaRank method, which has proven to yield high-quality rankings in various information retrieval tasks.",1,new
"In our experiments, we utilized the Coordinate Ascent algorithm for ranking function optimization because it demonstrates exceptional robustness against noise and outliers in training datasets.",1,new
Our study demonstrates that ensemble methods incorporating averaging can significantly minimize model overcompensation for noise in training datasets.,1,new
This research validates the effectiveness of mean pooling techniques in reducing the propensity of models towards overfitted solutions during prediction tasks.,1,new
"By leveraging average values from distinct predictions, we found substantial improvements in generalization capabilities across various learning scenarios.",1,new
"To enhance the accuracy of our machine learning model, we implement two distinct approaches when dealing with noisy data points. Firstly, we employ a pruning mechanism where we discard instances with probability scores below a certain threshold, ensuring that only robust patterns contribute to subsequent analysis. Secondly, we leverage the power of frequency-based filters, retaining items that exhibit high co-occurrence rates within the training dataset.",1,new
"By integrating knowledge from prior studies, such as the findings presented by Lin et al., we design an innovative approach to mitigate overfitting issues associated with traditional methods. Specifically, we introduce a regularization technique that adaptively adjusts the penalty term according to the complexity of the problem at hand, thereby preventing unnecessary feature expansions.",1,new
"Following the recommendations outlined in the seminal paper by Manning & Schütze, we modify our classification algorithm to prioritize contextual features extracted from local neighborhoods surrounding target words. This nuanced approach enables us to capture subtle semantic relationships between terms more effectively than earlier models, ultimately leading to improved performance metrics across various evaluation criteria.",1,new
Recent advances have demonstrated the effectiveness of transformation-based learning in improving part-of-speech tagging accuracy for various languages.,1,new
Our study reveals that applying transformation-based methods can significantly enhance performance in named entity recognition tasks across different domains.,1,new
Empirical evidence indicates that incorporating transformational techniques leads to substantial improvements in machine translation quality metrics such as BLEU scores and perplexity rates.,1,new
This model surpasses previous approaches by providing accurate predictions that match state-of-the-art performance for n-gram-based smoothing techniques like Katz's back-off method.,1,new
"In contrast to earlier methods relying solely on statistical analysis, our approach offers robustness through incorporating domain knowledge which leads to enhanced accuracy levels comparable to those achieved by manually curated datasets.",1,new
"By leveraging advanced computational algorithms, we have successfully developed a framework capable of outperforming existing methodologies such as smoothed interpolation using Witten-Bell discounting.",1,new
"Recent advancements in natural language processing have led to notable improvements in parsing algorithms, resulting in enhanced efficiency and precision across various linguistic frameworks.",1,new
"Moreover, considerable strides have been achieved in developing machine learning techniques for parser construction, yielding substantial gains in computational speed while preserving high accuracy levels.",1,new
"Furthermore, ongoing efforts towards more sophisticated parser designs have paved the way for better contextual understanding, ultimately contributing to improved overall system performance and reliability.",1,new
The IMDB Dataset has been widely used in film criticism studies due to its comprehensive nature.,1,new
Amazon Product Reviews serve as a valuable resource for analyzing customer opinions on various products including electronics.,1,new
MovieLens Data provides insights into user preferences and ratings across a vast collection of films contributing significantly to the field of recommendation systems research.,1,new
"Various automated metrics including ROUGE score, METEOR, and lexicalized HTER demonstrate significant correlation with evaluations conducted by human assessors across numerous studies.",1,new
Studies have consistently revealed that algorithms employing advanced techniques like paraphrasing-based metric scores and word overlap measures exhibit substantial agreement with manual rankings provided by experts.,1,new
"Research has demonstrated that computational models utilizing metrics such as TERp, Embeddings from Language Models, and similarity coefficient analysis show high levels of correspondence with human assessment protocols employed in various contexts.",1,new
Deep Learning models have proven to be highly effective for image classification problems due to their ability to learn complex patterns from large datasets efficiently.,1,new
Random Forest algorithm has demonstrated significant improvements over traditional machine learning techniques by leveraging ensemble methods to improve predictive accuracy across various domains.,1,new
Decision Trees are widely used in regression analysis because they offer a transparent and interpretable model that can handle non-linear relationships between variables effectively.,1,new
This model's neural network architecture was significantly improved upon by the introduction of Convolutional Neural Networks  [1] which has been widely adopted in various computer vision applications.,1,new
The decision tree algorithm proposed by Breiman  demonstrates its efficiency in handling complex classification tasks through feature selection and reduction techniques.,1,new
Levenberg-Marquardt optimization technique presented by Hagan & Menhaj  proved to have a substantial impact on solving numerical nonlinear least squares problems accurately and efficiently.,1,new
Our experiments demonstrate that utilizing a low-complexity algorithm like k-means clustering allows for efficient processing even on devices with limited storage capacity.,1,new
Implementing a cache-friendly data access strategy enables us to significantly decrease memory consumption when running machine learning models on embedded systems.,1,new
"To optimize performance-critical applications, incorporating a compression scheme into our neural network design helps minimize memory requirements while preserving accuracy levels.",1,new
Our approach was tested against a dataset comprised of complex narrative passages from the COCO image captioning benchmark where we observed superior performance compared to other cognitive models that rely heavily on explicit annotations but struggle with open-ended tasks.,1,new
This technique was evaluated on a comprehensive collection of descriptive texts from the IMDB movie review dataset showing promising outcomes when contrasted to purely symbolic AI methods lacking the ability to generalize to varied domains.,1,new
"In experiments conducted on a large corpus of abstracts from the arXiv repository, our method demonstrated notable success relative to rule-based approaches reliant on rigid pre-defined rules, often failing to adapt to novel situations.",1,new
"Recent research has demonstrated that simple yet effective approaches consistently yield impressive outcomes, outperforming more complex methods by a significant margin.",1,new
"Preliminary findings indicate that uncomplicated strategies can attain remarkably good results, often rivalling those achieved through more sophisticated techniques.",1,new
"Experimental evaluations have revealed that basic methodologies frequently produce satisfactory levels of accuracy, exceeding expectations and providing valuable insights into the underlying mechanisms.",1,new
This breakthrough was achieved by employing robust statistical models that greatly improved parsing accuracy for natural languages.,1,new
Recent advances in computational linguistics have led to significant enhancements in semantic role labeling via innovative graph-based approaches.,1,new
Novel applications of machine learning algorithms enabled researchers to accurately predict part-of-speech tags from large corpora.,1,new
"This research presents an innovative optimization algorithm that significantly enhances the accuracy of sequence alignment models in computational biology, echoing previous successes in natural language processing applications.",1,new
"Recent studies have introduced several novel heuristics to tackle computationally intensive tasks such as protein folding prediction, ultimately leading to breakthroughs in molecular modeling.",1,new
"A recent paper proposes an adaptive learning strategy for recommender systems that rivals human performance, thus opening up possibilities for more sophisticated personalized recommendations in e-commerce platforms.",1,new
"Our experimental design capitalizes on the inherent advantages of TREC's scoring system, yielding promising outcomes when evaluating information retrieval systems through a single metric alone.",1,new
"The innovative approach employed by our model effectively mitigates the complexity associated with multilingual processing, leading to remarkable performance gains for sentence alignment tasks even in resource-constrained environments.",1,new
"By leveraging the properties of LSTMs that facilitate effective contextualization, we were able to achieve satisfactory results for dependency parsing under limited training conditions.",1,new
"We utilized the popular algorithm XGBoost for feature extraction from isolated audio snippets in order to achieve accurate document-level classification, where we designated A as the target category and extracted word embeddings as relevant attributes.",1,new
"Employing traditional machine learning techniques, we deployed Random Forest regression model to predict categorical outcomes by leveraging contextualized token representations within spoken utterances, utilizing binary indicators as inputs.",1,new
"Our research applied Support Vector Regression (SVR), considering time-series patterns embedded within spoken words to categorize distinct conversation components accurately, thereby enabling more precise sentiment modeling through semantic analysis.",1,new
"Recent advances in natural language processing have led to significant improvements in part-of-speech tagging, particularly for English NPs, which now rely heavily on machine learning algorithms that utilize vast datasets and sophisticated feature engineering techniques.",1,new
The majority of state-of-the-art approaches to English nominal phrase parsing concentrate on leveraging labeled training sets and advanced neural network architectures to achieve high accuracy rates.,1,new
Most current research efforts in computational linguistics centered around named entity recognition in English texts emphasize the importance of employing deep learning methodologies and extensive annotated corpora to drive model development and refinement.,1,new
Our research demonstrates that incorporating biologically plausible phase resetting rules into the Kuramoto oscillator has significantly improved predictive accuracy for neural synchronization patterns.,1,new
"These computational studies have consistently shown that adaptive exponential integrate-and-fire neuron models exhibit remarkable robustness when coupled with harmonic forcing functions, leading to more precise predictions of population dynamics.",1,new
"A novel approach combining Hodgkin-Huxley conductance-based neurons with stochastic resonance theory produced highly reliable outcomes in simulating brain activity during cognitive tasks, underscoring its potential applications in neurological disorders diagnosis.",1,new
"Our initial trials employed a Random Forest classifier to optimize model performance. Furthermore, we drew inspiration from the work presented by Breiman [for insights into ensemble learning techniques].",1,new
"Utilizing a Gradient Boosting approach, our team achieved significant improvements over baseline models. As noted by Friedman [in his seminal paper], this method has proven effective for handling complex relationships between variables.",1,new
"To refine our predictive accuracy, we integrated a decision tree-based ranking system within our existing framework. Notably, Quinlan's ID3 algorithm provided valuable guidance on attribute selection strategies that contributed to enhanced classification outcomes.",1,new
Recent studies have demonstrated significant advancements in named entity recognition by employing novel machine learning algorithms with impressive outcomes.,1,new
A recent investigation into semantic role labeling utilizing deep neural networks has yielded remarkable improvements over traditional methods.,1,new
Preliminary findings from our research group suggest that ensemble techniques can effectively enhance the accuracy of dependency parsing tasks when combined with contextualized word embeddings.,1,new
Consistent use of ROUGE metrics has been demonstrated to effectively reflect the quality of machine translation outputs.,1,new
Comparable automatic evaluation measures such as METEOR scores consistently outperform human intuition when assessing NMT systems' fluency levels.,1,new
Systematic analysis revealed that Pearson correlation coefficients for both perplexity and word overlap statistics strongly agree with expert assessments of MT system performance.,1,new
The impact of climate change on agricultural productivity has garnered significant concern among researchers worldwide.,1,new
Studies examining the effects of social media on mental health have gained considerable traction within academia recently.,1,new
Research into the potential benefits of mindfulness meditation for anxiety reduction continues to attract substantial interest from scholars.,1,new
"Similar findings have been observed in another animal model-based research, where high-resolution micro-CT scans revealed significant correlations between receptor density measurements and disease progression rates in rats.",1,new
Comparable outcomes were also reported by researchers utilizing functional MRI techniques to investigate brain activity patterns associated with cognitive impairment in healthy adults compared to those with neurological disorders.,1,new
"These observations align with previous studies employing advanced diffusion tensor imaging methods to map neural connections within individuals with traumatic brain injuries versus controls, yielding consistent results that underscore the efficacy of this diagnostic approach.",1,new
"Furthermore, several key metrics have been developed to evaluate machine translation systems including the Character Error Rate, which measures the difference between source and target character sequences, the Perplexity metric that assesses model complexity through n-gram likelihoods, and the Meteor Score used for evaluating fluency and accuracy simultaneously.",1,new
"Various evaluation criteria exist for assessing machine learning models such as the Levenshtein Distance measure of edit operations required to correct errors, the Language Modeling Score indicating how well a model predicts subsequent words, and the ROUGE score quantifying coherence and relevance in summarization tasks.",1,new
"Several evaluation metrics for natural language processing applications have emerged over time like the Trigram Test measuring statistical significance by comparing predicted trigrams against actual ones, the F-Score weighing precision and recall equally important in information retrieval, and the TERP score providing a comprehensive assessment of sentence-level translations.",1,new
"According to our findings, the innovative approach proposed by Lin has significant merits.",1,new
A key contributor to this breakthrough was undoubtedly the remarkable insight provided by Dr. Lin's research group.,1,new
This study highlights Lin's invaluable contribution to advancing knowledge in this field.,1,new
"This approach addresses the issue through parallel processing, efficiently translating both sides of a bidirectional rule at once while preserving adjacent elements across languages.",1,new
Our technique tackles this challenge head-on by synchronously aligning left-to-right and right-to-left scripts within single rules for accurate translation outcomes.,1,new
"Asynchronous decoding is overcome by our method's capability to process and translate both ends of a bimodal linguistic pattern concurrently, resulting in smoother, more natural translations.",1,new
"Our study employed two innovative techniques that have been shown to excel in machine learning-based disease detection, complemented by advanced global features derived from spatially pooled low-level visual descriptions.",1,new
"Recent research incorporated cutting-edge methodologies for object recognition, combined with robust feature extraction via regional aggregation of pixel-wise attributes.",1,new
"In this investigation, we leveraged powerful neural network architectures alongside contextualized multi-resolution cues extracted through sophisticated hierarchical clustering algorithms.",1,new
"Our approach yields significant improvements when applied to dependency parses across all sections of the Prague Dependency Treebank dataset, boosting METEOR scores by approximately 13%.",1,new
"Results demonstrate that incorporating our methods into parser evaluations significantly enhances F-score performance on constituent trees extracted from the CoNLL-X corpus, rising from 79.12% to 81.59%.",1,new
"We observe substantial gains in precision rates when implementing these techniques on annotated parse trees within the Open Source Arabic Corpus, increasing accuracy levels from 85.45% to 88.17%.",1,new
"Our experiments demonstrate that incorporating cross-lingual word embeddings into neural machine translation systems significantly enhances fluency scores when translating idiomatic expressions, especially those involving phrasal verbs, which has far-reaching implications for human-computer interaction research.",1,new
"Studies have shown that utilizing domain-specific knowledge graphs can substantially improve the accuracy of named entity recognition models, particularly in biomedical texts where precise terminology is crucial, paving the way for more reliable clinical decision-making processes.",1,new
"Recent findings indicate that augmenting transformer architectures with multimodal inputs leads to substantial gains in image caption generation tasks, notably in scenarios requiring detailed descriptions of complex scenes, thereby expanding the possibilities for applications such as visual storytelling and assistive technologies.",1,new
Our study demonstrates that CMA exhibits notable efficacy in detecting disease-causing variants at high frequencies across various populations.,1,new
The application of CMA reveals substantial proportions of clinically relevant mutations among studied cohorts.,1,new
This research establishes that CMA provides robust outcomes for identifying harmful genetic alterations in genomic analyses.,1,new
Recent advancements have led to the development of highly effective neural network models that outperform traditional phrase-based approaches in statistical machine translation tasks.,1,new
Phrase-based machine translation methods continue to play a vital role in the field due to their simplicity and interpretability compared to more complex deep learning architectures.,1,new
A prominent class of statistical machine translation systems relies heavily on phrase-based frameworks for efficient and accurate translations between languages.,1,new
"Our findings demonstrate that the psychometric properties of the SF-12 have been thoroughly validated across various populations worldwide, making it suitable for broad clinical applications.",1,new
"This investigation provides further evidence for the reliability and validity of the GAD-7 scale among patients with anxiety disorders, complementing existing research in psychiatric settings.",1,new
"The present study contributes to the growing body of literature supporting the efficacy of the HADS in measuring depression symptoms in primary care contexts, highlighting its potential utility in routine practice.",1,new
The incorporation of linguistic patterns into statistical models significantly enhances phrase alignment accuracy by leveraging contextual relationships between words.,1,new
This approach has shown substantial improvement in identifying semantically equivalent expressions across languages due to its sensitivity to surrounding lexical cues.,1,new
"By utilizing contextualized representations of words, the model achieves higher precision in translating idiomatic phrases that often defy literal interpretations.",1,new
"This model's ability to classify high-dimensional data sets via probabilistic inference demonstrates its significant value in machine learning applications, particularly in the field of image recognition where it achieves state-of-the-art performance.",1,new
"Support vector machines have been effectively employed for function approximation tasks due to their robustness against noise and outliers, offering promising outcomes in regression analysis studies.",1,new
"Bayesian neural networks exhibit impressive capabilities in handling uncertainty through probabilistic predictions, showcasing substantial advancements in deep learning techniques that can improve upon traditional deterministic methods in various complex pattern classification problems.",1,new
The implementation of this concept by researchers at Google has led to significant advancements in semantic role labeling through their Sequence-to-Sequence framework.,1,new
"This idea was also explored by Chen et al.'s work on neural machine translation, where they utilized contextualized word embeddings for better performance outcomes.",1,new
"Another notable instance of leveraging linguistic features is evident in the WordPiece tokenization technique developed by BERT's creators, further enhancing natural language processing capabilities.",1,new
This method has gained widespread acceptance among researchers recently due to its efficiency.,1,new
Recent studies have consistently shown that this technique yields superior outcomes compared to traditional approaches.,1,new
Its growing adoption rate reflects the community's increasing recognition of its potential for advancing our understanding of complex phenomena.,1,new
"Our research demonstrates that Cloud-based Storage Systems can effectively manage large-scale sensor networks, exhibiting enhanced efficiency and scalability compared to traditional storage solutions.",1,new
"A Novel Approach to distributed data management has been proposed for IoT devices, showcasing significant improvements in data processing speed and reduced latency through optimized resource allocation strategies.",1,new
"This study presents a novel framework for decentralized data analytics on Edge Computing platforms, resulting in accelerated insights generation and improved decision-making capabilities for various industrial applications.",1,new
Our findings demonstrate that tactile feedback significantly enhances user experience and reduces mental fatigue among surgeons by streamlining their workflow.,1,new
This study confirms that haptic feedback plays a crucial role in augmenting surgical precision while minimizing operator stress levels over time.,1,new
Research indicates that kinesthetic feedback leads to improved dexterity and reduced decision-making errors for medical professionals undergoing training exercises.,1,new
"Our findings were validated through rigorous testing against established benchmarks such as METEOR, which demonstrates its effectiveness in evaluating machine translation outputs accurately.",1,new
"This study employed the use of BLEU scores from Moses decoder, reflecting widespread acceptance within the NLP community as a reliable metric for assessing machine translation quality.",1,new
"For validation purposes, we utilized the HTER toolkit, known for its precision in measuring human readability and fluency assessments, thereby supporting our proposed approach's efficacy.",1,new
Recent studies demonstrate that discriminative models continue to dominate the field of natural language processing for several years now.,1,new
The widespread adoption of machine learning algorithms has led to significant advancements in discriminative tagging techniques over the past two decades.,1,new
Discriminative approaches remain at the forefront of research efforts due to their consistently superior performance compared to traditional methods.,1,new
Recent advances in machine translation have led to the development of cutting-edge algorithms such as LASER that surpass previous methods including GIZA++.,1,new
Innovative approaches to bilingual dictionary learning now employ sophisticated neural architectures like MUSE which outperform traditional techniques reliant on statistical models like GIZA++.,1,new
"Contemporary research has seen significant improvements in phrasal representation through state-of-the-art models such as FastText, yielding better outcomes than earlier frameworks built upon rule-based methodologies like those found in GIZA++.",1,new
"Recent advances in machine learning have enabled significant improvements in the development of neural network architectures for speech recognition, achieving impressive results that surpass those obtained through traditional methods by up to 95%.",1,new
"Research on multimodal deep learning techniques has led to substantial advancements in computer vision tasks such as image classification and object detection, reaching state-of-the-art performance levels across various benchmarks.",1,new
"Breakthroughs in natural language processing have facilitated the creation of sophisticated chatbots capable of engaging users in complex conversations, exhibiting remarkable understanding and contextual awareness, thereby enhancing user experience significantly.",1,new
"This study presents a comprehensive overview of the current state-of-the-art techniques for analyzing genomic data, providing valuable insights into their applications and limitations.",1,new
We examine the effectiveness of machine learning algorithms in predicting patient outcomes by examining existing literature and presenting case studies that demonstrate their utility.,1,new
"A detailed analysis of the recent breakthroughs in renewable energy technologies is provided, highlighting their potential impact on reducing carbon emissions and mitigating climate change effects.",1,new
This novel architecture has been demonstrated to yield significant enhancements in solving complex multivariate optimisation challenges through its implementation of global-local search strategies.,1,new
Our findings indicate that employing this type of meta-heuristic leads to substantial advancements in tackling multi-modal search spaces across various domains.,1,new
Recent studies have shown that incorporating neighbourhood-based information can result in notable improvements when addressing intricate non-linear optimisation issues via hybridised algorithms.,1,new
"This study demonstrates that the Tree Adjoining Grammar framework, proposed by Joshi et al., provides an effective approach for parsing natural languages.",1,new
"Our research findings suggest that the Lexicalized Probabilistic Context-Free Grammars technique, outlined in Chiang's paper, significantly enhances sentence analysis accuracy.",1,new
"According to the recent publication by Kaplan & Bresnan, the Head-Driven Phrase Structure Grammar model yields excellent results when applied to syntactic tree construction tasks.",1,new
"Our proposed framework draws heavily upon the groundbreaking research of, yet diverges significantly due to its novel emphasis on categorizing synonyms based on semantic nuances rather than lexical similarity.",1,new
"Building upon the seminal contributions of, our innovative method departs from conventional approaches by organizing related terms around their functional properties rather than mere associative relationships.",1,new
"While rooted in the foundational concepts introduced by, this study introduces a paradigm shift through its focus on clustering semantically equivalent expressions according to pragmatic contexts, thereby offering a more comprehensive understanding of linguistic variability.",1,new
"This novel construct exhibits remarkable catalytic efficiency comparable to that of the renowned enzyme P450 BM3, which has been extensively studied for its exceptional biotechnological applications due to its robust stability and high yield production.",1,new
"Our designed catalyst displays impressive kinetic properties closely resembling those of the widely researched P450 BM3 system, making it a valuable asset for various industrial processes requiring efficient enzymatic conversion.",1,new
Similarities between our engineered biomolecule and the well-documented P450 BM3 demonstrate promising prospects for large-scale synthesis and utilization in cutting-edge chemical transformations.,1,new
"Recent advancements have shown that boosting processing power can be achieved by integrating numerous cores onto a single chip, enabling significant improvements in execution speed through efficient utilization of multi-threading capabilities.",1,new
"Increasingly sophisticated architectures now employ advanced pipelining techniques, allowing systems to handle complex computations more efficiently than ever before and yielding substantial gains in overall system throughput.",1,new
"By harnessing the potential offered by massive multiprocessing configurations, researchers have successfully demonstrated notable enhancements in computational performance, thus paving the way towards even faster and more powerful computing solutions.",1,new
"Tree-based architectures exhibit several advantages over traditional sequence-to-sequence methods, including enhanced interpretability due to visualizing parse trees, improved efficiency through parallelization during inference, and increased flexibility via modularized components such as parsers and generators.",1,new
"In comparison to rule-based approaches, graph neural network frameworks demonstrate notable benefits like scalability across large datasets, adaptability to various domain-specific knowledge graphs, and robustness against structural noise in inputs.",1,new
"Compared to symbolic reasoning techniques, connectionist models possess desirable properties such as learnable representations from raw data, rapid incremental learning capabilities, and seamless integration within broader cognitive architectures.",1,new
"Our model outperforms existing techniques for named entity recognition by achieving an F1-score of 92.9%, surpassing the state-of-the-art result obtained through Conditional Random Fields at 91.8%.",1,new
"In comparison to other machine translation models that utilize complex neural networks, our simplified architecture yields comparable performance while reducing computation time significantly, reaching a BLEU score of 84.5%.",1,new
"By leveraging ensemble learning methods, we enhance the precision of part-of-speech tagging, boasting a substantial improvement over standard Hidden Markov Models, which report a tagged token accuracy of merely 87.2%.",1,new
Our analysis reveals that decision trees exhibit superior performance compared to random forests across various datasets.,1,new
"In comparison studies, neural networks demonstrate enhanced accuracy over traditional machine learning algorithms consistently.",1,new
"According to our empirical evaluation, gradient boosting outperforms support vector machines by achieving higher precision rates in classification tasks.",1,new
"Recent advances in neural network architecture have led to substantial gains in natural language processing tasks through novel applications of attention-based mechanisms, exemplifying their immense potential for future breakthroughs.",1,new
"Notably, innovative approaches like graph convolutional networks and transformer encoder-decoder systems have demonstrated remarkable effectiveness in speech recognition applications, yielding improved accuracy rates across various scenarios.",1,new
"The implementation of ensemble learning strategies has significantly enhanced the performance of computer vision algorithms by leveraging synergies between traditional deep learning architectures and meta-learning frameworks, leading to state-of-the-art results in image classification challenges.",1,new
"This model exhibits remarkable potential for enhancing various NLP applications including part-of-speech identification, named entity recognition, sentential parsing, discourse coherence detection, and question answering systems.",1,new
"Its efficacy in augmenting machine translation capabilities, information retrieval algorithms, sentiment analysis models, topic modeling techniques, and text summarization frameworks is quite impressive.",1,new
"Recent studies have demonstrated its effectiveness in boosting the accuracy of dependency parsing, word sense induction, relation extraction, aspect-based opinion mining, and intent determination methods.",1,new
"Our findings suggest that TNF-alpha levels exhibit strong correlations with disease progression, making it a valuable marker for monitoring patient recovery over extended periods.",1,new
"Studies indicate that C-reactive protein concentrations display significant associations with treatment efficacy, indicating its potential utility as a prognostic indicator in clinical settings.",1,new
"Elevated MCP-1 levels demonstrate substantial correlations with symptom severity, suggesting this cytokine could serve as a reliable biomarker for assessing disease activity in patients undergoing therapy.",1,new
"Regularization techniques such as dropout have also proven effective at reducing model complexity, resulting in improved generalizability.",1,new
"Ensemble methods can significantly decrease variance by combining predictions from multiple models, thereby enhancing overall accuracy.",1,new
Employing cross-validation during training helps mitigate issues related to over-optimism when evaluating model performance on unseen data.,1,new
"Various widely used evaluation metrics for machine translation systems include BLEU, METEOR, and CIDEr.",1,new
"Well-established assessment tools such as TER, NLG, and Meteor have been employed extensively in MT research.",1,new
"Additional notable evaluation metrics that measure translation quality comprise Word Error Rate, F -measure, and Perplexity.",1,new
"Recent advancements in machine learning have led to the development of decision trees, which offer an efficient framework for classification tasks due to their ability to handle complex datasets effectively.",1,new
The neural network approach proposed by LeCun has been widely adopted in deep learning applications thanks to its capacity to learn abstract representations from large amounts of unlabeled data efficiently.,1,new
"Random forests, introduced by Breiman, utilize ensemble methods to improve predictive accuracy and robustness when dealing with high-dimensional feature spaces and non-linear relationships between variables.",1,new
Our experiments utilized the widely accepted Brown Corpus for validation purposes due to its broad representation of English literature.,1,new
This study employed the robust Waterloo-UCM corpus to assess our model's ability to generalize across various genres of writing.,1,new
Evaluation was conducted on the extensive Switchboard transcription corpus to ensure that our approach performed well under real-life conditions.,1,new
Another significant advantage of this approach lies in its ability to accommodate various parameter configurations within the modeling framework.,1,new
This method allows for greater flexibility by enabling researchers to experiment with different parametric settings during simulations.,1,new
One notable feature of these computational models is their capacity to incorporate user-defined variable inputs into the algorithmic process.,1,new
"This notion shares similarities with stochastic gradient boosting, which has yielded impressive outcomes in regression analysis, time series forecasting, and recommender systems.",1,new
"Similar paradigms have also been employed in natural language processing tasks like sentiment analysis, information retrieval, and question answering techniques.",1,new
"Such methodologies exhibit parallels with neural network training methods that achieve notable success in image classification, object detection, and speech synthesis applications.",1,new
Our research has successfully incorporated various digital signal processors like waveform generators into our novel experimental setup for efficient signal acquisition.,1,new
"This comprehensive framework utilizes machine learning libraries including TensorFlow, which significantly enhances its ability to process complex sensor readings efficiently.",1,new
"A suite of advanced algorithms derived from computational geometry was seamlessly merged within our system architecture, allowing us to accurately detect anomalies in large datasets.",1,new
"This study supports the notion that semantic similarity measures have become increasingly popular for identifying associations among medical terms, echoing the pioneering research by Lesk.",1,new
"Recent studies suggest that pattern discovery algorithms can effectively uncover novel relationships within biological networks, leveraging techniques developed by previous researchers such as Widdows.",1,new
"Our analysis verifies that word embeddings can efficiently identify latent connections between healthcare entities, building upon earlier findings presented by Mikolov.",1,new
Our study utilizes the support vector machine technique due to its efficiency and precision in handling complex datasets.,1,new
"For this analysis, we selected the decision tree method for its ability to effectively handle missing values and interpretability.",1,new
"In our approach, the k-nearest neighbors algorithm was chosen owing to its robustness and capacity to capture non-linear relationships between variables.",1,new
Our research team has extensively employed this method across numerous natural language processing projects due to its effectiveness in handling complex linguistic tasks efficiently.,1,new
"A wide range of applications have successfully integrated this approach into their systems, showcasing its adaptability and high performance capabilities within the field of artificial intelligence.",1,new
The widespread adoption of this technique by prominent researchers worldwide underscores its reliability and usefulness for solving intricate problems related to human-computer interaction studies.,1,new
"Our research demonstrates that this metric effectively captures the likelihood of translating individual words from source languages while preserving grammatical structures, yielding high-quality translations.",1,new
"By employing this approach, we have successfully improved sentence-to-sentence alignment accuracy by quantifying the conditional probabilities associated with linguistic transformations at the lexical level.",1,new
We found that modeling translation outcomes as a product of sequential word-by-word mappings significantly enhances the overall fidelity of our machine learning model for cross-lingual communication tasks.,1,new
Our approach employs a widely used technique for sentence parsing that leverages the robust algorithms developed by the Stanford Natural Language Processing Group's open-source software package CoreNLP.,1,new
"In processing image features, we utilize established methods rooted in computer vision research utilizing OpenCV library which has been extensively utilized within various academic studies worldwide.",1,new
"By integrating our system with existing knowledge base databases like ConceptNet, we can tap into a vast repository of semantic relationships between entities, providing unparalleled accuracy in information retrieval tasks.",1,new
The reliability coefficients of Fleiss' Kappa and Cohen's Kappa have been widely used metrics to assess inter-rater consistency among annotators.,1,new
"Several studies have employed intraclass correlation coefficient ICC(2,k) to evaluate the concordance between human coders during annotation tasks.",1,new
"To gauge the level of consensus among raters, researchers often resort to calculating the mean absolute difference metric MAD and comparing it across datasets.",1,new
The development of large-scale datasets such as the OntoNotes corpus has significantly contributed to advancements in natural language processing techniques.,1,new
High-quality resources like the Stanford Question Answering Dataset have been instrumental in pushing forward the boundaries of question-answering systems research.,1,new
Well-curated collections including the MultiWOZ dataset have greatly facilitated progress in conversational AI model training and evaluation.,1,new
Our study demonstrated that PERLCK measures exhibit significant correlation with expert evaluations when assessing machine translation quality control models.,1,new
Recent findings indicate that ROUGE metrics display strong alignment with human assessments in evaluating automatic summarization techniques performance variability across various domains.,1,new
The experiments conducted showed that METEOR scores demonstrate substantial agreement with native speaker feedback ratings for ranking speech recognition systems' overall proficiency levels.,1,new
"In order to assess the effectiveness of our proposed framework for document classification, we employed two widely used evaluation metrics: F-score at K and AUC-ROC.",1,new
"To further validate the robustness of our approach to named entity recognition, we utilized precision and recall scores calculated over the top-K extracted entities.",1,new
"Additionally, we leveraged macro-F1 score and mean average precision (MAP) to comprehensively evaluate the performance of our deep learning model for topic modeling tasks.",1,new
This approach enables significant reductions in computational complexity by reusing shared features among related patterns in the database.,1,new
The proposed method yields substantial gains in performance through optimized representation learning for overlapping sub-patterns across various datasets.,1,new
Efficient storage allocation can be achieved via storing aggregate representations of recurring motifs within pattern sets.,1,new
"A recent analysis revealed significant improvements in medication adherence among patients who received comprehensive support from healthcare providers through regular home visits and telephone check-ins, ultimately leading to enhanced health outcomes and increased patient engagement.",1,new
"According to research findings, implementing routine follow-up appointments coupled with digital monitoring enabled individuals with chronic conditions to effectively manage their symptoms, resulting in substantial enhancements to quality of life metrics.",1,new
"Studies have consistently demonstrated that integrating personalized coaching sessions into treatment plans can yield remarkable increases in self-efficacy among participants, fostering more effective long-term management strategies for managing complex medical conditions.",1,new
"Recent advances in deep learning have led to significant improvements in natural language processing tasks, particularly in dependency parsing where state-of-the-art systems now consistently yield accurate results across various linguistic frameworks.",1,new
"Substantial progress has been made in developing treebank-driven statistical parsers, enabling researchers to analyze complex sentence structures more effectively and produce reliable parse trees at scale.",1,new
"The introduction of novel machine learning algorithms has revitalized the field of syntactic analysis, allowing for faster and more precise parsing capabilities that facilitate better understanding of human languages.",1,new
Our findings demonstrate that maximum entropy is highly beneficial for image classification tasks due to its ability to capture complex patterns in visual data effectively.,1,new
Recent studies have shown that the application of maximum entropy algorithms significantly improves performance in speech recognition systems by reducing errors associated with contextual nuances.,1,new
"This research confirms the utility of maximum entropy in enhancing predictive models across various domains, particularly in handling large datasets where traditional methods often fail to deliver accurate outcomes.",1,new
"Recent advancements have led many researchers to reconsider traditional approaches which heavily relied on extensive human annotation, instead opting for self-supervised learning techniques that achieve comparable outcomes.",1,new
"Notably, empirical evidence suggests that unsupervised deep learning models now rival their fully supervised counterparts in terms of accuracy and efficiency, pushing the boundaries of what was previously thought possible.",1,new
"A significant shift towards automated feature extraction has been observed, allowing for more efficient model training and reducing reliance on manually curated datasets that were once deemed essential for achieving state-of-the-art performance.",1,new
"Our research demonstrates that ensemble methods combining support vector machines and maximum likelihood estimation exhibit superior performance over traditional decision trees, especially when dealing with high-dimensional feature spaces.",1,new
"This study reveals significant improvements in topic modeling tasks through the application of conditional random fields and maximum entropy discriminative models, achieving state-of-the-art accuracy rates across various datasets.",1,new
"By leveraging the power of max-margin Markov networks and maximum entropy techniques, our proposed framework shows substantial gains in predicting user behavior patterns within e-commerce platforms, outperforming existing approaches by a considerable margin.",1,new
Our findings demonstrate that exposure to pulsed electromagnetic fields significantly enhances bone growth through increased activity of both chondrocytes and osteoblasts during the fracture repair process.,1,new
This study highlights the therapeutic potential of applying low-frequency magnetic fields for promoting cellular differentiation and matrix production by osteocytes in patients undergoing orthopedic surgery.,1,new
"We observed substantial improvements in callus formation and mineralization when subjects were treated with PEMF therapy, indicating its efficacy in accelerating skeletal tissue regeneration after fractures.",1,new
Our research highlights the efficacy of transcranial magnetic stimulation in treating depression by demonstrating significant improvements in mood regulation among patients suffering from treatment-resistant conditions.,1,new
"Results obtained through gene expression analysis demonstrate that miRNA-based therapies hold promise for cancer prevention, offering novel insights into tumor suppression mechanisms and potential therapeutic avenues.",1,new
"This study showcases the utility of functional near-infrared spectroscopy in monitoring cerebral oxygenation during neurosurgical procedures, facilitating more precise interventions and improved patient outcomes.",1,new
"Our findings indicate that the novel treatment protocol yielded superior outcomes compared to previous studies, likely due to meticulous execution under unified leadership in our clinical trials.",1,new
"A comprehensive analysis revealed improved patient recovery rates when procedures were conducted solely by experienced surgeons, demonstrating a clear advantage over collaborative approaches reported elsewhere.",1,new
"Notably, consistent surgical expertise within our team resulted in more favorable outcomes across various metrics, contrasting sharply with less successful efforts documented in comparable research initiatives.",1,new
Our study adopted a novel approach by incorporating contextualized embeddings into the existing named entity recognition framework developed by Liu et al.,1,new
"Zhang's team successfully integrated graph-based reasoning techniques into their machine learning pipeline, significantly enhancing its predictive power.",1,new
A recent breakthrough was made possible when researchers at MIT incorporated attention mechanisms into their natural language processing architecture originally designed by Wang and colleagues.,1,new
Our research demonstrates that discriminative approaches utilizing deep learning architectures can significantly enhance parsing performance while decreasing model complexity compared to traditional methods.,1,new
Recent studies have shown that leveraging transfer learning from pre-trained networks enables discriminative parsers to achieve state-of-the-art results at reduced computational costs.,1,new
"By employing ensemble techniques with hybrid models, researchers have successfully improved parsing efficiency and boosted overall system reliability above previously established benchmarks.",1,new
"Our study further contributes to this research area by achieving superior performance for Arabic natural language processing tasks with the aid of our novel embedding technique, outperforming existing methods by a significant margin.",1,new
"In addition to these findings, we demonstrate exceptional outcomes when applying deep learning architectures to tackle Chinese information retrieval problems, showcasing their potential as powerful tools for knowledge discovery.",1,new
"Furthermore, the implementation of our graph-based approach has yielded impressive results for Russian semantic role labeling tasks, setting a new benchmark for future researchers to build upon.",1,new
"This study employs a novel application of spectral clustering to discern semantic relationships between terms, demonstrating its potential as a reliable technique for uncovering linguistic patterns within large datasets.",1,new
"Brown's algorithm successfully leverages vector space modeling to efficiently categorize high-dimensional word embeddings, showcasing improved accuracy over existing methods in certain domains.",1,new
"In their seminal paper, Manning et al utilize machine learning techniques to develop a robust system for part-of-speech tagging that outperforms traditional rule-based approaches under various conditions.",1,new
"Our research utilized the cutting-edge neural machine translation model, Transformer-XL, renowned for its exceptional performance in handling long-range dependencies in languages such as English and Mandarin.",1,new
"This study employed the highly acclaimed statistical machine translation system, SMT++, which boasts impressive accuracy rates across various language pairs including Spanish and French.",1,new
"We leveraged the proficient deep learning architecture, BERT-base, specifically tailored for tasks requiring nuanced understanding of linguistic context in multilingual environments like Arabic and Russian.",1,new
Our team has made significant progress towards achieving higher precision rates by implementing novel neural networks that have led to an impressive improvement over our past record of 54.8%.,1,new
"This latest iteration surpasses all prior attempts at classification tasks, yielding an outstanding rate of success at 58.9%, thereby further solidifying its position as a groundbreaking achievement.",1,new
"Notably, recent breakthroughs in deep learning architecture design have allowed us to push beyond previously established limits, ultimately resulting in exceptional performance metrics including a remarkable accuracy level of 59.5%.",1,new
"Our team opted for conditional random fields due to its widespread adoption across various natural language processing tasks such as named entity recognition and part-of-speech tagging, which has yielded impressive results.",1,new
"This study employed support vector machines as our classification algorithm because previous research demonstrated their efficacy in handling high-dimensional feature spaces, particularly in image classification problems.",1,new
"Given the robust performance shown by decision trees in past studies, we selected this model for our regression analysis, leveraging its ability to handle non-linear relationships between variables.",1,new
"Our study demonstrates that the application of Genetic Algorithm has led to outstanding outcomes in tackling high-dimensional problems where traditional methods often reach their limits, consistent with previous findings by Wang et al.",1,new
"Recent research indicates that the use of Tabu Search strategy yields remarkable improvements over conventional techniques in complex search spaces, corroborating earlier observations made by Glover & Laguna.",1,new
"Empirical evidence suggests that Hybrid Particle Swarm Optimization can efficiently handle large-scale instances of NP-hard problems, thereby confirming the effectiveness reported by Kennedy & Eberhart.",1,new
"Recent advancements have also led to improved designs for compact, high-efficiency propulsion systems in small unmanned aerial vehicles.",1,new
"Moreover, recent studies demonstrate significant enhancements in the integration of advanced sensors within miniaturized drones that reduce operational costs and increase flight endurance.",1,new
"Furthermore, innovative materials research has resulted in novel aerodynamic coatings that decrease drag resistance while increasing overall performance capabilities of modern micro-UAVs.",1,new
"This groundbreaking study marked a significant shift towards computational linguistics by introducing the Brown Corpus, revolutionizing linguistic analysis forever.",1,new
"The establishment of the CoNLL shared tasks has had a profound impact on natural language processing, enabling researchers worldwide to collaborate on ambitious projects like never before.",1,new
"By developing the Stanford Natural Language Processing Group's parser, researchers have greatly enhanced our understanding of syntactic structures within languages.",1,new
Our proposed method outperforms other state-of-the-art approaches like Deep Transfer Network in several benchmark datasets due to its robust feature extraction process.,1,new
This novel approach significantly surpasses previous methods such as Multitask Learning by achieving higher accuracy rates across various tasks.,1,new
"By leveraging techniques from meta-learning, our model demonstrates substantial improvements over existing models including Meta-SGD, particularly when dealing with complex learning scenarios.",1,new
"Recent advancements in deep learning frameworks have led to the development of novel neural network architectures for natural language processing tasks, ultimately yielding superior performance compared to traditional approaches.",1,new
"The incorporation of attention mechanisms into sequence-to-sequence models has significantly enhanced translation quality, allowing researchers to achieve unprecedented levels of fidelity in machine-translation systems.",1,new
"Probabilistic graphical models have proven instrumental in modeling complex dependencies between variables, thereby enabling accurate prediction of genetic traits and disease susceptibility in personalized medicine.",1,new
Our research demonstrates that mobile sinks can significantly enhance the efficiency of wireless sensor networks by reducing latency while conserving energy levels in network nodes effectively.,1,new
"This study highlights the benefits of employing cluster-based protocols for facilitating seamless communication between sensors in large-scale deployments, leading to substantial improvements in overall system performance.",1,new
"Empirical evidence suggests that adaptive transmission power control enables more reliable data transfer in wireless sensor networks, resulting in lower packet loss rates and enhanced network robustness.",1,new
"Recent advancements in natural language processing have significantly enhanced our understanding of neural networks' ability to learn from large datasets, leading to substantial improvements in speech recognition systems that rely heavily on these complex architectures.",1,new
"The integration of cognitive computing principles into reinforcement learning has led to notable breakthroughs in artificial intelligence research, particularly in areas where human decision-making skills can be emulated effectively.",1,new
"Ongoing developments in computer vision techniques have enabled researchers to successfully apply deep learning models for object detection tasks, resulting in more accurate predictions and robust image classification capabilities.",1,new
The researcher employed both Analytical Hierarchy Process and Paired Comparison methods to assess the importance of variables because they offer high reliability and ease of implementation.,1,new
"Due to their precision and straightforward nature, the authors utilized Fuzzy logic and Multi-Criteria Decision Making techniques for establishing priorities within the study framework.",1,new
"Given its widespread adoption and accuracy, the researchers opted to use TOPSIS method along with DEA model for evaluating alternatives and deriving objective conclusions.",1,new
"Advances in corpus linguistics have led to significant improvements in part-of-speech tagging accuracy, enabling researchers to better understand linguistic patterns and structures within natural languages.",1,new
"The creation of vast ontologies like YAGO  facilitates the integration of knowledge from various domains, thereby enhancing our comprehension of complex relationships between entities and concepts.",1,new
"Recent breakthroughs in deep learning methodologies for named entity recognition have resulted in more accurate identification and categorization of entities mentioned in unstructured texts, paving the way for improved information extraction capabilities.",1,new
The development team made significant advancements in gesture recognition through their participation in the GestureWorks initiative.,1,new
A notable breakthrough occurred within the context of collaborative human-computer interfaces thanks to the researchers behind the iFeel software framework.,1,new
This pioneering effort led by the Virtual Reality Lab resulted in substantial improvements to haptic feedback systems used in immersive applications.,1,new
"Our proposed algorithm leverages bottom-up parsing techniques that combine local and global information, resulting in remarkably accurate structural representations of complex linguistic constructs.",1,new
"Recent advancements in deep learning methodologies allow for the incorporation of long-range dependencies into probabilistic context-free grammars, significantly enhancing their ability to capture sentence-level nuances.",1,new
"Empirical studies have demonstrated the efficacy of incorporating contextualized word embeddings into discriminative parsing algorithms, yielding substantial improvements over traditional feature-based approaches.",1,new
Our research employed a sentence-based approach due to its proven effectiveness and prevalence in prior literature.,1,new
This study adopted a discourse representation theory framework owing to its broad applicability and high accuracy rates demonstrated in previous investigations.,1,new
A lexical semantics model was chosen for this analysis since it has been consistently shown to yield reliable results across various linguistic contexts in existing studies.,1,new
Recent studies have also explored ways to optimize the efficiency of established algorithms presented in Zhang et al.  and Manning .,1,new
Further research has been conducted to enhance the performance of machine learning models discussed in Bishop  and Freund et al.,1,new
Subsequent investigations into accelerating computational processes mentioned by Sutton and Barto  have shown promising outcomes.,1,new
"This dataset has been instrumental in advancing our understanding of natural language processing techniques, particularly in areas like sentiment analysis and named entity recognition.",1,new
The vast array of linguistic phenomena represented within this corpus has greatly facilitated the development of more accurate machine learning models for various NLP tasks.,1,new
"This rich collection of texts has significantly contributed to several breakthroughs in computational semantics, enabling researchers to better comprehend complex sentence structures and their corresponding meanings.",1,new
"We chose several prominent frameworks for our study, including spec#, which leverages model checking techniques to verify program correctness.",1,new
"Our analysis focused on four notable approaches: Dafny, known for its expressive specification language, and Z3, renowned for its robust solver capabilities.",1,new
"From existing solutions, we opted for CBMC's state-of-the-art abstraction and TLA+ Plus's ability to specify complex systems behavior accurately.",1,new
"This study by Manning et al. marked a significant milestone in natural language processing research, providing accurate part-of-speech tagging models that improved sentence parsing efficiency.",1,new
"The groundbreaking paper by Collins proposed novel algorithms for dependency-based syntactic analysis, greatly enhancing our understanding of linguistic structures.",1,new
"Charniak's seminal contribution revolutionized the field of human-computer interaction through his development of probabilistic context-free grammars, facilitating more effective dialogue systems.",1,new
"Our findings suggest that exponential random graph models offer valuable insights into understanding complex relationships within epidemiological networks, making them increasingly relevant in disease outbreak investigations.",1,new
"This statistical framework provides researchers with a powerful tool for examining intricate linkages between individuals and groups, thereby contributing significantly to our comprehension of infectious diseases transmission dynamics.",1,new
"Exponential random graph models show great promise in elucidating how social connections influence the spread of illnesses, ultimately shedding light on novel avenues for intervention strategies in global health initiatives.",1,new
Recent studies demonstrate that low-density parity-check (LDPC) codes outperform existing algorithms for error-correcting purposes due to their efficient decoding mechanism.,1,new
"In comparison to traditional Shannon-Fano codes, recent research indicates that turbo codes offer superior performance in terms of channel capacity utilization efficiency.",1,new
Preliminary findings suggest that fountain codes exhibit remarkable resilience against noise degradation when implemented within complex communication systems.,1,new
"This approach has proven highly effective due to its high precision and adaptability, making it suitable for various complex systems' regulation.",1,new
Utilizing fuzzy logic has led to significant advancements in system stability through its sophisticated decision-making capabilities.,1,new
"By employing machine learning techniques, researchers have developed novel methods that greatly enhance predictive accuracy in numerous applications.",1,new
"This investigation substantiates the notion that statins exhibit favorable tolerability profiles in patients with type-2 diabetes mellitus, consistent with existing evidence suggesting low rates of serious adverse events associated with these medications.",1,new
"Notably, our research corroborates prior findings demonstrating minimal occurrence of severe gastrointestinal side effects among participants treated with ezetimibe monotherapy for dyslipidemia management, underscoring its safe pharmacological properties.",1,new
"Our analysis reinforces earlier studies highlighting the benign nature of simvastatin when administered to individuals suffering from hypercholesterolemia, lending further support to the established efficacy and acceptability of this medication class in clinical practice.",1,new
"Various other eicosanoids have been found to interact with CB receptors, including prostaglandin E2, which has shown significant potential for therapeutic applications due to its ability to regulate neuroprotection and inflammation levels within the central nervous system.",1,new
"Notably, certain fatty acid amides such as oleamide also demonstrate potent activity at cannabinoid receptors, highlighting their role in regulating cognitive functions like learning and memory processing within specific regions of the brain.",1,new
"Recent studies suggest that various synthetic analogues of natural cannabinoids possess strong affinity towards type-1 and -2 CB receptors, indicating their possible use as novel therapeutics targeting pain management and motor function regulation.",1,new
Recent studies employing  Vitis vinifera  have demonstrated its potential for use in plant biotechnology applications.,1,new
Successful gene editing techniques utilizing  Vitis vinifera  have significantly advanced our understanding of genome modification protocols.,1,new
Research into the transcriptional regulation of  Vitis vinifera  has provided valuable insights into the molecular mechanisms underlying phenotypic variation within this species.,1,new
Recent studies have shown that certain approaches such as hierarchical phrase-based models and tree substitution grammar possess strong reordering capabilities.,1,new
Several effective techniques including Tree-to-String Model and Lexicalized Reordering Models have demonstrated significant improvements in sentence rearrangement tasks.,1,new
Research has indicated that methodologies like incremental parsing and semantic role labeling also exhibit robust performance in reordering policy optimization.,1,new
"This innovative method for demand forecasting has gained significant traction within the realm of production planning and inventory control, thanks to pioneering research conducted by Chen et al..",1,new
"A novel algorithmic framework developed by Lee et al. has revolutionized the field of transportation optimization, yielding substantial cost savings and enhanced efficiency across various industries.",1,new
"Recent studies led by Patel et al. have successfully implemented this groundbreaking technique in manufacturing environments, resulting in improved quality control and reduced lead times.",1,new
"This study highlights the efficacy of Bayesian information criterion (BIC), along with its derivatives like BICf  and Qbic, for estimating test set log loss accurately.",1,new
"The application of Akaike's weight of evidence criterion, including WAIC and other modified versions, has been shown to be highly effective in model selection tasks.",1,new
"Various studies demonstrate that maximum likelihood estimation can also serve as a suitable alternative for evaluating predictive performance, specifically via approaches such as REML and L-BFGS.",1,new
Our team has effectively leveraged re-ranking parsers for fine-tuning our machine translation models across numerous languages utilizing the robust framework described by.,1,new
Recent experiments demonstrate that incorporating self-supervised learning techniques significantly improves parsing accuracy when adapting pre-trained neural networks according to.,1,new
"By implementing the novel approach outlined in, we were able to achieve state-of-the-art results in sentence restructuring tasks through enhanced parser adaptation mechanisms.",1,new
Our research group recently developed a novel algorithm that significantly improves upon existing methods for optimizing dimensional reduction techniques in natural language processing applications.,1,new
"In their seminal paper, Chen et al proposed an innovative approach to solving complex optimization problems in computational linguistics through dynamic programming methodologies.",1,new
This recent study by Patel et al presents a highly effective strategy for reducing dimensionality in large-scale neural networks used for image classification tasks while preserving key features essential for accurate predictions.,1,new
This innovative segmentation technique presented in Chapter 5 significantly improves upon previous methods by incorporating dynamic programming principles that efficiently reduce computational complexity.,1,new
"In accordance with the theoretical framework established in Section 2, our novel clustering algorithm achieves substantial gains in accuracy through strategic use of hierarchical relationships among entities.",1,new
"By leveraging advanced machine learning techniques outlined in Appendix B, we demonstrate a notable enhancement in predictive models' robustness against outliers, leading to more reliable outcomes in statistical analysis.",1,new
"Our findings were validated through comparison with established models via Pearson's correlation coefficient, which demonstrated strong agreement between predicted outcomes.",1,new
We evaluated our model performance by correlating it against a large dataset from prior studies utilizing Spearman rank-order correlation analysis.,1,new
A series of comparisons was conducted between our algorithmic predictions and gold-standard benchmarks obtained from industry experts employing precision-recall metrics.,1,new
"This novel characteristic of the stochastic gradient descent algorithm allows researchers to easily incorporate various loss functions, such as those introduced by Johnson et al..",1,new
"Furthermore, this approach has been successfully integrated into ensemble methods like bagging and boosting, according to the research conducted by Dietterich.",1,new
"One notable advantage of the support vector machine classifier is its ability to handle high-dimensional feature spaces efficiently, thanks to the theoretical framework established by Vapnik.",1,new
Our study demonstrated that this novel therapeutic approach significantly decreased the incidence of cardiovascular events by approximately 25%.,1,new
Recent findings suggest that implementation of this intervention resulted in substantial reductions in morbidity rates among high-risk patients.,1,new
This research highlighted the efficacy of our innovative treatment protocol in lowering the likelihood of cardiac complications by over 30%.,1,new
"Recent research has highlighted three prominent methods for analyzing complex systems: rule-based analysis, graph theory, and artificial intelligence techniques, where AI-driven models have garnered significant attention lately.",1,new
"The current landscape reveals that there are primarily two main strategies employed by researchers: the heuristic method, the probabilistic approach, and computational modeling, all of which show great promise in solving intricate problems efficiently.",1,new
"A comprehensive review indicates that experts now focus on integrating various disciplines such as symbolic reasoning, statistical inference, and deep neural networks, particularly the latter being increasingly favored due to its impressive capabilities.",1,new
This study successfully employed unsupervised deep learning techniques to enhance word sense disambiguation outcomes significantly.,1,new
Our research findings clearly showed that incorporating weakly labeled training data can lead to substantial improvements in semantic role labeling performance.,1,new
"By leveraging ensemble methods, we were able to achieve state-of-the-art results for named entity recognition tasks through active learning strategies.",1,new
"Although there has been significant emphasis placed upon ethnographic studies utilizing interviews, existing literature demonstrates that written narratives have long since become a recognized method within social sciences research.",1,new
Written records continue to serve as a valuable tool for researchers seeking insight into human behavior despite recent trends favoring more quantitative methodologies such as surveys and experiments.,1,new
Historical precedents suggest that textual analyses offer substantial benefits when used alongside traditional empirical approaches in behavioral science investigations.,1,new
Our study employed the widely accepted metric BLEU since numerous studies have shown that it correlates strongly with human judgments about machine translation quality.,1,new
The popularly utilized toolkit METEOR was selected due to its well-documented ability to produce outcomes closely aligned with those obtained from human evaluations.,1,new
"This research relied heavily on the LASER score, which has been consistently proven to yield results comparable to human assessments across various domains.",1,new
"Recent advances in deep learning techniques have led to significant improvements in neural machine translation models, solidifying their position as the leading approach in this field.",1,new
"This study demonstrates the effectiveness of subword modeling for improving accuracy in statistical machine translation systems, further supporting its widespread adoption by researchers worldwide.",1,new
Our analysis confirms that phrase-based machine translation remains the gold standard due to its robustness and efficiency in handling complex linguistic structures and nuances.,1,new
The implementation of Minimum Error Rate Training (MERT) algorithm has been extensively utilized in various statistical machine translation systems due to its high effectiveness.,1,new
Log-linear model training via MERT is often regarded as a gold standard approach in modern speech-to-text applications because it significantly improves accuracy rates.,1,new
The widespread adoption of the Maximum Entropy Random Search (MERS) variant of MERT underscores its superiority over other optimization techniques in achieving optimal performance metrics in natural language processing tasks.,1,new
"Recent advances in deep learning have led to significant improvements in ensemble methodologies utilizing uncertainty estimation techniques, resulting in exceptional performance across various benchmark datasets.",1,new
"The integration of attention mechanisms within neural network frameworks has shown remarkable progress over the past decade, yielding outstanding outcomes in predictive modeling tasks.",1,new
"Over the past few years, there has been substantial growth in research focused on developing hybrid algorithms that incorporate both probabilistic reasoning and graph-based representations, achieving impressive gains in accuracy metrics compared to traditional approaches.",1,new
"Their approach utilizes pre-defined templates to generate numerous possible paraphrases for every input statement, accompanied by relevant attribute values that facilitate choosing the optimal paraphrase among them. This strategy effectively leverages knowledge-based methods for achieving high-quality machine translation outcomes.",1,new
"By employing a combination of automatic and manual techniques, they develop extensive dictionaries containing synonymous expressions that can be utilized to enhance the fluency and accuracy of translated texts.",1,new
"This innovative technique employs statistical models to identify optimal phrasal combinations that closely approximate human-translated outputs, thereby ensuring improved precision and coherence across various languages and contexts.",1,new
"Recent advancements have led to several effective methods for identifying complex linguistic phenomena such as phrasal verbs, fixed expressions, and semantic compounds.",1,new
"Various innovative approaches can now accurately capture grammatical patterns like noun phrases, verb combinations, and adjective-noun pairs.",1,new
Substantial progress has been made towards developing reliable strategies for extracting high-frequency word associations and co-occurrences from large corpora.,1,new
Several key approaches that have shown significant promise for improving machine translation performance are weighted finite state transducers and stochastic finite automata models.,1,new
Weighted finite state transducers have been effectively applied in statistical machine translation to handle complex linguistic phenomena such as morphology and phonology variations.,1,new
Other notable successes can also be seen in the implementation of probabilistic pushdown automata which has greatly enhanced our understanding of sentence semantics in natural language processing tasks.,1,new
Our analysis employed ROUGE due to its ability to effectively evaluate summaries by comparing them against their corresponding reference texts.,1,new
We opted for SARI because it has been shown to outperform other metrics in assessing machine translation quality at the sentence level.,1,new
"In order to assess coherence and relevance accurately, we selected CIDEr as our evaluation metric, which tends to focus on meaningful features of image captions.",1,new
"This study highlights the significance of incorporating reinforcement learning techniques into decision-making models, particularly when applied to image classification tasks where precision is paramount.",1,new
"A notable aspect of this research lies in its intersection with deep neural networks, which has garnered substantial attention from experts in computer vision for its potential applications in object detection systems.",1,new
"The integration of graph theory principles within machine learning algorithms presents a promising avenue for future exploration, offering enhanced capabilities in network analysis and predictive modeling.",1,new
Our research team has found that neural network architectures significantly outperform traditional models in classification problems due to their ability to capture complex patterns in large datasets.,1,new
This study demonstrates how deep learning techniques can greatly enhance the accuracy of speech recognition systems by leveraging hierarchical representations of acoustic features.,1,new
"Recent advancements in convolutional recurrent networks have led to substantial improvements in image captioning tasks, enabling more accurate and descriptive captions for visual media.",1,new
Their findings highlight the impressive ability of Bacillus subtilis to produce bioactive compounds that play a crucial role in its ecological niches.,1,new
Research has shown that Pseudomonas aeruginosa exhibits remarkable capabilities in synthesizing secondary metabolites essential for interspecies communication.,1,new
Studies have demonstrated the significant capacity of Aspergillus terreus to manufacture valuable enzymes contributing to symbiotic relationships within fungal communities.,1,new
"This concept has garnered significant attention since its inception, particularly within interdisciplinary research teams over the past decade.",1,new
"Notably, numerous investigators worldwide have extensively explored this phenomenon, yielding substantial advancements in our understanding.",1,new
"Originally introduced by pioneering researchers, it has since become a focal point for ongoing studies across various fields of science.",1,new
Our analysis demonstrates that the integration of deep learning algorithms into traditional classification frameworks yields approximately 8% improvement across all examined datasets.,1,new
"Notably, the employment of probabilistic neural networks leads to significant enhancements in model accuracy for predictive modeling applications, resulting in around 12% better outcomes than previous methods.",1,new
"In our experimentations, we observed a substantial increase in forecasting precision when utilizing machine learning-based techniques over standard statistical approaches, with estimated gains reaching up to 15%.",1,new
Our analysis reveals that this novel approach yields substantial enhancements in translation accuracy when assessed through metrics like ROUGE score.,1,new
"These innovative techniques contribute substantially to better machine readability, as evident from the notable gains observed in the METEOR evaluation metric.",1,new
"The proposed method demonstrates remarkable effectiveness in enhancing fluency and coherence, resulting in higher scores across all automated evaluation tools used.",1,new
"Our solution leverages the power of machine learning algorithms for dependency parsing, distinguishing it from traditional rule-based approaches that rely heavily on ad-hoc heuristics.",1,new
"In contrast to previous studies which often resort to statistical methods, we adopt a principled framework grounded in linguistic theories such as HPSG.",1,new
"By integrating state-of-the-art NLP techniques into a rigorous theoretical foundation, our method surpasses existing efforts focused solely on heuristic-driven solutions.",1,new
"Recent advancements have seen significant improvements with techniques such as Recurrent Neural Networks , gradient boosting algorithms , and decision trees  being employed successfully in various applications.",1,new
"Several notable studies suggest that ensemble methods including Random Forests , Support Vector Machines , and clustering analysis  offer promising solutions for complex problem-solving tasks.",1,new
"A range of effective methodologies has emerged comprising conditional random fields , neural network architectures , and Bayesian networks  which demonstrate substantial potential in predictive modeling.",1,new
The development of linguistic resources like named entity recognition models has proven highly beneficial for natural language processing tasks despite being resource-intensive to construct.,1,new
These types of detailed linguistic information can significantly enhance the performance of machine learning algorithms when properly utilized in computational linguistics research.,1,new
"High-quality lexical databases, including semantic role labeling frameworks, play a pivotal role in advancing various applications within artificial intelligence fields by providing accurate contextual understanding.",1,new
Our analysis reveals that employing hierarchical spatial pooling techniques at various stages of deep neural networks significantly boosts overall efficiency and enhances predictive power.,1,new
Studies have consistently demonstrated that adopting hybrid architectures combining both convolutional and recurrent units yields substantial gains over traditional feedforward models in image classification tasks.,1,new
Experimental results confirm that utilizing advanced aggregation methods such as sum-pooling and mean-pooling improves accuracy in object detection applications when integrated into modern CNN frameworks.,1,new
Our analysis reveals that utilizing machine learning algorithms can significantly enhance model accuracy when applied to natural language processing tasks.,1,new
"Furthermore, recent studies demonstrate that incorporating contextualized embeddings into neural networks leads to substantial improvements in semantic understanding capabilities.",1,new
"Additionally, experimental evidence suggests that leveraging graph-based methods for relation extraction yields superior outcomes compared to traditional techniques.",1,new
Harmonization techniques have become the preferred approach among researchers due to their high accuracy rates.,1,new
Our analysis reveals that consensus-driven methods yield significantly better outcomes compared to other approaches.,1,new
Interoperability solutions have been widely adopted across various disciplines owing to their effectiveness in streamlining processes.,1,new
"Arowssy employed his novel method for tagging ambiguous words in an autonomous learning framework, yielding significant improvements over traditional approaches.",1,new
"Borski utilized arowsy's innovative techniques effectively within their deep neural network architecture, resulting in notable reductions in semantic drift during training sessions.",1,new
"Kolesnikov adopted Arrowskey's seminal idea of incorporating context-aware annotations into a reinforcement-based machine translation system, achieving state-of-the-art performance metrics across various evaluation benchmarks.",1,new
"Our results show that incorporating contextual information through semantic role labeling can significantly enhance machine translation accuracy, especially when combined with neural networks like those developed by Brown et al..",1,new
"This study demonstrates how utilizing linguistic resources such as FrameNet can greatly improve natural language processing tasks including named entity recognition, thereby enabling more effective search engine optimization.",1,new
"By leveraging large-scale corpora and advanced algorithms, researchers have achieved impressive gains in sentiment analysis capabilities, mirroring the successes reported by Liu & Zhang's influential research.",1,new
"The application of LA-ICP-TOF MS has led to improved sensitivity levels down to parts-per-trillion detection thresholds, enabling comprehensive multi-elemental analyses that expand its utility in various fields such as environmental monitoring.",1,new
"XRF spectroscopy boasts impressive analytical performance through high precision element quantification over extended concentration ranges from micrograms to milligrams, solidifying its status as a dependable tool within geochemical research laboratories.",1,new
The widespread adoption of GD-OES stems from its robustness in achieving accurate measurements across broad analyte concentrations due to sophisticated instrumental design coupled with advanced software algorithms facilitating extensive elemental studies in materials science applications.,1,new
"The efficacy of photobiomodulation therapy in reducing symptoms associated with fibromyalgia has been consistently demonstrated through rigorous clinical trials, firmly establishing its therapeutic potential for this condition.",1,new
"The effectiveness of acupuncture as an adjunctive treatment for managing chemotherapy-induced peripheral neuropathy has gained substantial support from numerous studies, highlighting its value in enhancing patient outcomes.",1,new
"A significant body of research underscores the favorable impact of low-level laser therapy on wound healing rates, suggesting its utility as a valuable tool in promoting tissue repair and regeneration.",1,new
"Our research leverages cutting-edge techniques from Information Theory to develop novel applications for Deep Learning frameworks, specifically leveraging the versatility of Shannon entropy calculations.",1,new
"A significant advantage of Markov Random Fields lies in their ability to effectively capture complex patterns within large datasets, making them highly suitable for application in Computer Vision tasks such as object recognition and image segmentation.",1,new
"Utilizing advanced statistical inference methods rooted in Gibbs distributions has led to remarkable breakthroughs in Natural Language Generation, enabling more accurate machine translation and text summarization systems.",1,new
This innovative approach has demonstrated remarkable success in predicting linguistic patterns across various corpora.,1,new
Their novel methodological framework has consistently delivered accurate estimates for rare word frequencies in large datasets.,1,new
Recent experiments have shown that their model excels at inferring lexical distributions even when faced with limited training data.,1,new
"Our study employed a novel approach utilizing maximum likelihood estimation techniques, specifically logistic regression analysis, demonstrating its effectiveness in predicting outcomes across various clinical trials.",1,new
"The application of decision trees and random forests exhibited impressive performance in identifying high-risk patients through integrating factors such as age, gender, and medical history effectively.",1,new
"By leveraging support vector machines and gradient boosting algorithms, researchers were able to develop predictive models that accurately forecasted stock market trends, outperforming traditional methods significantly.",1,new
This study employed a novel machine learning algorithm that leverages domain knowledge for effective information retrieval.,1,new
Our research utilized a comprehensive semantic network database designed specifically for accurate protein classification tasks.,1,new
A hybrid approach combining rule-based systems and probabilistic models was successfully implemented for efficient data integration purposes.,1,new
Our method leverages the robustness of machine learning algorithms to classify instances effectively by integrating various features through a sophisticated weighted voting system.,1,new
"This novel framework utilizes a neural network architecture to aggregate disparate pieces of evidence, allowing for more accurate predictions than traditional rule-based approaches can offer.",1,new
"By employing a probabilistic model grounded in Bayesian statistics, our research demonstrates significant improvements over existing classification methods due to its ability to capture nuanced relationships between variables.",1,new
"This study employs three widely recognized standards for performance evaluation: the FER2013 dataset, which comprises over 35,000 images with annotated emotional expressions.",1,new
"To assess its accuracy, we utilize two established benchmarking tools: the JAFFE database, known for its high-quality face images, and the CK+ database, featuring challenging facial expression variations under various lighting conditions.",1,new
"Our approach was evaluated against four rigorous metrics, including the highly regarded AffectNet dataset, which provides comprehensive annotations for affective image classification tasks.",1,new
These findings highlight key advantages that machine learning algorithms can leverage when translating complex linguistic structures across various languages and dialects efficiently and effectively today.,1,new
"Such comparative analyses demonstrate the capability of deep neural networks to adapt to varying grammatical patterns found within numerous language pairs, thereby enhancing overall translation accuracy significantly.",1,new
"This study's outcomes validate the notion that parsing approaches can skillfully navigate differences in word order among distinct languages, ultimately leading to better performance in automatic translation systems.",1,new
"Our research presents a pioneering approach for accelerating the calculation of entropic uncertainty, boasting impressive convergence rates that rival established methods while requiring minimal computational resources.",1,new
"This groundbreaking study introduces a high-performance algorithm for estimating information-theoretic quantities, showcasing remarkable speedup over existing techniques within a concise framework of approximately three pages of mathematical derivations.",1,new
"A recent breakthrough paper proposes an innovative method for rapid computation of Shannon's entropy measure, demonstrating substantial gains in efficiency compared to prior art through judicious optimization strategies.",1,new
"Our analysis utilized the linguistic framework developed by Kim et al., building upon earlier models like those presented in Goldberg. This innovative approach demonstrated significant improvements in accuracy rates.",1,new
"The machine learning algorithm employed was based on the architecture described by LeCun et al., incorporating key features from previous works such as Yann LeCun's pioneering research on convolutional neural networks.",1,new
"We drew inspiration from the computational model introduced by Smolensky, combining it with recent advancements outlined in Hochreiter & Schmidhuber. This fusion resulted in enhanced predictive capabilities for our simulation.",1,new
Recent studies have shown that successful implementations often utilize two prominent approaches: Maximum Likelihood Estimation and Viterbi Decoding methods for optimal performance.,1,new
Several effective strategies employed by researchers involve combining Bayesian Networks and Dynamic Programming algorithms to achieve robust outcomes.,1,new
Various experimental analyses indicate that incorporating Conditional Random Fields and Hidden Markov Models yields significant improvements in accuracy and efficiency.,1,new
The proposed algorithm exhibits impressive computational efficiency and provides actionable insights into disease progression patterns across various patient populations worldwide.,1,new
The innovative statistical framework developed by Chen et al offers a clear understanding of genetic predispositions influencing cancer susceptibility rates globally.,1,new
This novel machine learning approach demonstrates remarkable accuracy in predicting climate model outcomes for vulnerable ecosystems and regions.,1,new
"Our analysis reveals that despite being designed primarily for protein structures, the application of I-TASSER to membrane proteins yielded remarkably accurate predictions.",1,new
"Notably, the integration of machine learning algorithms into the existing framework of ROSETTA led to significant improvements in protein-ligand binding affinity prediction accuracy.",1,new
"Although originally developed for protein folding simulations, we observed excellent performance from DOCK Blaster in predicting substrate specificity for enzymes with complex active sites.",1,new
These findings have garnered significant attention due to their accuracy and reliability.,1,new
This phenomenon has received substantial research effort over several years now resulting in numerous valuable contributions.,1,new
A considerable body of evidence supports this hypothesis which has led to its widespread acceptance within the field.,1,new
"Advances in technology have led to faster diagnosis through identification of pathogenic organisms via DNA sequencing methods, resulting in enhanced treatment outcomes for patients with sepsis.",1,new
"Improved diagnostic techniques employing advanced bioinformatics tools enable more precise antibiotic selection, thereby reducing hospital stays and improving recovery rates among critically ill individuals.",1,new
"Rapid genotyping of pathogens facilitated by next-generation sequencing has significantly contributed to optimized therapeutic strategies, ultimately benefiting patient health and well-being in critical care settings.",1,new
"This assessment tool exhibits robust reliability across various investigations, demonstrates excellent accuracy, and responds well to fluctuations over extended periods.",1,new
"Our study reveals that this questionnaire possesses high test-retest consistency, shows strong validity when applied by trained interviewers, and can be effectively administered via digital platforms.",1,new
"These findings confirm that the survey instrument boasts impressive internal consistency, yields reliable outcomes despite varying research contexts, and proves practical for use among participants who prefer online interactions.",1,new
Our approach demonstrates superior performance when compared against established algorithms like deep learning techniques from recent literature.,1,new
Results show significant improvement over existing solutions including cutting-edge methodologies described by top researchers in neural networks last year.,1,new
This study's innovative methodological framework outperforms traditional models mentioned in seminal papers on machine intelligence.,1,new
"This methodological approach enables researchers to disentangle complex relationships between numerous predictor variables and their respective impact on the outcome measure, resulting from intricate correlations among these predictors.",1,new
ANOVA's ability to assess how various independent factors influence a dependent variable while accounting for intercorrelations within those factors significantly enhances our understanding of multifaceted phenomena.,1,new
"By employing this statistical technique, scientists can effectively quantify the effects of several covariates on a single outcome metric despite high levels of multicollinearity amongst them, leading to more accurate conclusions about causal pathways.",1,new
"This method has demonstrated significant potential for improving named entity recognition, showcasing its versatility and reliability in various natural language processing applications; the research received generous support from NSF Grant No. ABC12345.",1,new
"Our findings have consistently supported this assertion, highlighting the effectiveness of this approach in sentiment analysis tasks while also contributing valuable insights into linguistic semantics underpinned by computational models; we acknowledge the financial assistance provided by Google Research Award #XYZ7890.",1,new
"Its implementation has led to substantial gains in information retrieval systems, underscoring its broad applicability across artificial intelligence disciplines; partial funding for this project came courtesy of Microsoft Azure Research Grants Program Award Number DEF01234.",1,new
Our research leverages advanced techniques such as graph-based pruning methods to expedite model optimization during training phases.,1,new
This approach effectively accelerates the inference time by employing novel strategies like attention-weighted network compression.,1,new
We adopt efficient memory-reducing algorithms including knowledge distillation for faster processing speeds in deep learning frameworks.,1,new
His seminal work on machine translation theory revolutionized our understanding of cross-linguistic communication patterns,1,new
The innovative approach proposed by Brown's clustering algorithm significantly improved accuracy rates for part-of-speech tagging tasks,1,new
Her groundbreaking study on topic modeling techniques led to the development of more efficient information retrieval systems,1,new
Our findings indicate that omitting the pre-processing steps for word alignment yields significant improvements in AER scores when employing the proposed algorithm.,1,new
Removing certain preprocessing modules from our model significantly enhanced its accuracy by raising the average error rate.,1,new
"By disabling specific components within the neural network architecture, we observed notable enhancements in overall performance metrics.",1,new
"Our research findings suggest that this novel algorithm demonstrates remarkable efficacy in speech recognition tasks, leading to significant breakthroughs in human-computer interaction.",1,new
"This innovative approach has yielded outstanding outcomes in natural language processing applications, particularly in enhancing chatbot functionality.",1,new
"Recent studies have shown that this technique excels at image classification problems, resulting in improved accuracy rates across various datasets.",1,new
"In order to validate our approach, we replicate the existing technique utilizing identical hyperparameters for optimal fairness across models.",1,new
"To ensure accurate evaluation, we carefully mimic previous research by implementing their proposed architecture under equivalent settings.",1,new
Our subsequent analysis relies heavily upon reproducing the established benchmarks from leading methodologies within the field.,1,new
Recent studies have demonstrated significant advancements in the application of parser-based methods for improving sentence-level performance.,1,new
A notable body of research has been dedicated to exploring the effectiveness of context-aware approaches for handling complex syntactic structures.,1,new
Significant breakthroughs have occurred in recent years regarding the utilization of tree-like representations for modeling semantic dependencies within sentences.,1,new
Our recent experiments demonstrate that cutting-edge algorithms can achieve remarkable performance gains up to 95% precision when applied to financial news articles from reputable sources like Bloomberg News.,1,new
This breakthrough study showcases how advanced deep learning techniques enable researchers to attain near-flawless classification rates exceeding 98% on linguistically complex datasets such as the Reuters Corpus.,1,new
High-performance computing architectures combined with innovative machine learning strategies result in outstanding accuracy levels reaching 99% for text analysis tasks involving the Financial Times dataset.,1,new
Recent studies have revealed that graphene-based nanomaterials show great potential as superior additives for enhancing material strength and toughness.,1,new
This innovative approach has led to significant breakthroughs in developing ultra-high-strength composites used extensively across various industrial applications today.,1,new
Nanocrystalline diamonds exhibit remarkable thermal conductivity properties making them ideal substitutes for traditional filler materials in advanced heat management systems.,1,new
"Our experimental results demonstrate that reducing uncertainty can significantly enhance model reliability in NLP applications, echoing findings from prior research on machine learning algorithms.",1,new
"Previous studies have consistently demonstrated that minimizing ambiguity leads to improved outcomes across various natural language processing paradigms, including speech recognition systems.",1,new
"A comprehensive analysis reveals that mitigating potential risks associated with neural network models enhances their overall efficacy in information retrieval tasks, supporting the notion that cautionary measures yield tangible benefits.",1,new
"This study effectively builds upon established approaches to multilingual term extraction, leveraging insights gained from previous research conducted by Melamed et al., Fraser & Walker.",1,new
"Our method significantly expands existing methodologies for lexical alignment, drawing inspiration from the seminal works of Pedersen et al., Gale & Church.",1,new
"By integrating findings from these studies, our approach provides a robust framework for cross-linguistic comparison, further solidifying its position within the field of computational linguistics as demonstrated by Brown et al..",1,new
This approach places accountability squarely where it belongs – with individuals who take responsibility for mitigating climate change impacts through sustainable practices.,1,new
"Empowering communities can lead to better environmental stewardship, which makes addressing pollution issues far more efficient than relying solely on government regulations.",1,new
Effective conservation efforts depend heavily on public participation and education initiatives that foster personal ownership over ecological sustainability goals.,1,new
"Our research highlights that employing machine learning algorithms facilitates significant advancements in topic modeling techniques, particularly when tackling document summarization tasks.",1,new
"By adopting this approach, we observe substantial improvements in named entity recognition models across various domains and datasets.",1,new
"This strategy enables effective information extraction from large volumes of unstructured data, thereby enhancing our ability to make informed decisions in complex systems.",1,new
Developed an innovative approach for integrating patient feedback into treatment plans by creating a novel decision support tool that aligns with established clinical guidelines.,1,new
"Designed a comprehensive framework for evaluating symptom severity across various psychiatric conditions through expert panel consensus, ensuring consistency with existing ICD-10 classification systems.",1,new
Established a predictive model incorporating machine learning algorithms that significantly improves accuracy when diagnosing autism spectrum disorder compared to traditional methods like ADOS assessment.,1,new
"The commonly employed metrics for evaluating speech recognition systems are the Word Error Rate, Perplexity Score, and Meteor score which demonstrate its effectiveness in measuring accuracy.",1,new
These three metrics have been extensively utilized by researchers to assess the performance of Natural Language Processing tasks including machine translation and text summarization.,1,new
"Widely regarded as industry standards, the BLEU, ROUGE, and Cider scores serve as essential benchmarks for evaluating the fluency and coherence of automatically generated texts.",1,new
Previous studies have demonstrated that incorporating local context information significantly improves part-of-speech tagging performance by capturing subtle nuances within nearby words.,1,new
This was also observed in the domain adaptation tasks where leveraging contextualized word embeddings greatly enhanced the accuracy of relation extraction models.,1,new
It has been proven that utilizing syntactic dependencies between tokens can effectively improve the identification of specific entities in dependency parsing applications.,1,new
Recent advancements in deep learning techniques have significantly enhanced the accuracy of automated speech recognition systems through improved audio signal processing methods.,1,new
Studies have shown that incorporating multimodal information into natural language inference models has led to substantial gains in performance and robustness.,1,new
Ongoing research efforts have successfully applied reinforcement learning algorithms to optimize the parameters of dialogue management systems for more effective human-computer interactions.,1,new
This novel approach offers a compelling theoretical basis for elucidating the unusually large thermodynamic stabilities observed across this temperature range of 250-375 K.,1,new
A comprehensive computational model has been developed to explain the unexpectedly strong bonding energies found within these molecular assemblies by factors of up to 60%.,1,new
Recent studies have provided a robust analytical framework that effectively accounts for the significant deviations from standard free energy predictions in the investigated compound series over concentrations spanning several orders of magnitude.,1,new
"Our approach was also benchmarked against three other prominent methodologies in image classification tasks: YOLOv3 algorithm, which demonstrated comparable performance metrics but lacked the efficiency of our system, and two variants of ResNet architectures that underperformed in terms of accuracy.",1,new
"In this study, we evaluated the effectiveness of our machine learning framework by comparing it with several well-established methods for natural language processing: BERT-based models, such as DistilBERT and RoBERTa, showed significant improvements over traditional techniques like Naive Bayes classifier.",1,new
"For evaluating the efficacy of our novel clustering technique, we selected four established algorithms from the literature: hierarchical agglomerative clustering achieved remarkable similarity scores when paired with our approach, while DBSCAN consistently produced inferior outcomes due to its sensitivity to parameter tuning issues.",1,new
"This study demonstrates the efficacy of employing standard evaluation measures such as ROUGE-1, METEOR, and CIDEr for assessing machine translation performance accurately.",1,new
The authors utilize precision and recall scores from LASER metrics in evaluating their proposed neural machine translation model's effectiveness.,1,new
A comparison between sentence-level metrics like TER and WMT automatic post-editing tasks highlights the significance of accurate measurement tools in machine translation research.,1,new
Recent studies have elucidated the multifaceted roles of certain key regulatory proteins that exhibit non-canonical activities beyond their traditional enzymatic functions across various eukaryotic kingdoms.,1,new
"Novel evidence suggests that several fundamental cellular processes rely heavily on the moonlighting properties of essential structural components found within prokaryotes, further expanding our understanding of cellular complexity.",1,new
"Research has revealed that numerous vital biosynthetic pathways in bacteria can be modulated by proteins possessing dual functional capabilities, underscoring the intricate nature of molecular interactions at play.",1,new
"Researchers have convincingly demonstrated that advanced deep learning architectures play a pivotal role in achieving cutting-edge performance in natural language processing tasks, outperforming traditional methods by leveraging their capacity for intricate contextual understanding.",1,new
"Our analysis reveals that employing complex neural networks yields significant benefits when handling massive datasets, underscoring the importance of scalable computational frameworks capable of managing such volumes efficiently while maintaining rapid execution speeds.",1,new
"Recent studies confirm that sophisticated parsing algorithms offer substantial advantages in terms of speed and accuracy compared to legacy techniques, particularly when applied to large-scale linguistic analyses where increased expressiveness does not lead to prohibitively long computation times.",1,new
Our proposed method leverages a state-of-the-art machine learning algorithm that significantly speeds up sentence processing times.,1,new
This approach utilizes advanced computational techniques to efficiently handle complex linguistic structures during parsing.,1,new
"By implementing a neural network architecture, our system achieves remarkable efficiency gains over traditional parsers.",1,new
"Recent studies have demonstrated that integrated treatment approaches involving primary care physicians, specialists, and social workers can lead to improved patient outcomes and enhanced quality of life for individuals struggling with comorbid conditions.",1,new
"Our analysis suggests that multidisciplinary teams comprising family doctors, psychologists, and healthcare navigators show promise in managing chronic illnesses by providing holistic support systems for patients.",1,new
"Research has shown that coordinated care initiatives featuring general practitioners, psychiatrists, and community health advisors result in better symptom management, increased patient engagement, and reduced hospital readmissions.",1,new
"Our research team selected the Support Vector Machine algorithm due to its superior performance on English syntax analysis tasks, surpassing other models by a notable margin in various benchmark studies cited in literature.",1,new
"For evaluation purposes, we utilized the Hidden Markov Model because of its proven effectiveness in parsing ambiguous sentence structures, which aligns well with the complexity encountered in our linguistic dataset.",1,new
"In order to assess the accuracy of our natural language processing model, we opted for the Conditional Random Field approach, owing to its consistent high scores across numerous corpora from both domestic and international researchers.",1,new
"This recent study showcases that by leveraging cutting-edge natural language processing techniques, researchers can effectively identify high-frequency terms within large datasets, significantly improving their understanding of linguistic patterns.",1,new
"Moreover, the advanced parser employed in this innovative research outperforms existing models by accurately capturing infrequent but significant phrases often overlooked in prior studies, thus enhancing overall accuracy rates.",1,new
"In contrast to traditional methods, which rely heavily on manual annotation and limited computational resources, this breakthrough technique utilizes machine learning algorithms to efficiently process vast amounts of data, enabling scientists to rapidly discover novel insights into human communication dynamics.",1,new
"Our research has shown that functionalized carbon nanoparticles can effectively transport therapeutic agents across cellular membranes, enabling precise drug targeting capabilities within biological tissues at the molecular level efficiently.",1,new
These novel silver-based nanostructures exhibit superior properties making them highly suitable for biomedical applications such as enhanced wound healing processes due to their remarkable biocompatibility features.,1,new
"Recent findings have highlighted the potential of metallic oxide composites as high-performance vectors for delivering chemotherapeutic compounds directly to cancerous cells, significantly reducing side effects while increasing efficacy rates dramatically.",1,new
"According to recent studies, PERPLEXity has emerged as a highly influential metric for evaluating machine translation quality due to its robustness and effectiveness.",1,new
METEOR outperforms other automatic metrics in capturing nuances of human judgments when assessing MT systems' fluency.,1,new
"In the field of NMT research, ROUGE score has become increasingly popular among researchers for its ability to accurately evaluate summary-level qualities.",1,new
Our proposed algorithm demonstrates comparable performance to state-of-the-art techniques employing template-based methods combined with novel implementations utilizing magnetic resonance imaging acquisitions that yield high-quality reconstructions.,1,new
The newly developed framework exhibits notable similarities to existing methodologies incorporating machine learning algorithms optimized for fast relaxation time mapping which could serve as valuable additions to future research endeavors.,1,new
This study reveals strong correlations between our innovative methodological advancements and recent breakthroughs achieved through advanced diffusion tensor imaging sequences yielding promising outcomes for structural connectivity analysis.,1,new
The integration of the PROOF algorithm into our research pipeline significantly improved model accuracy and efficiency.,1,new
Utilizing the advanced features provided by GENESEE enabled us to achieve superior clustering results compared to traditional methods.,1,new
Implementing the novel approach outlined in REACT allowed for substantial reductions in processing time while preserving optimal solution quality.,1,new
Our analysis suggests that incorporating contextual clues from lexical databases can significantly enhance the accuracy of named entity recognition tasks.,1,new
This approach leveraging collocational patterns has proven highly efficient in resolving ambiguity associated with homograph detection.,1,new
Exploiting statistical associations between words shows considerable promise in improving the precision of part-of-speech tagging algorithms.,1,new
Recent advancements in deep learning techniques have resulted in substantial improvements in the efficiency of natural language processing algorithms.,1,new
"Over the past decade, numerous innovations in neural network architectures have contributed significantly to enhanced performance in speech recognition systems.",1,new
"Ongoing research into context-aware modeling has yielded remarkable breakthroughs in the field of human-computer interaction, allowing for more intuitive user interfaces.",1,new
Our model also demonstrates exceptional accuracy in named entity recognition tasks when trained on large datasets such as PubMed.,1,new
This study highlights significant improvements in machine translation capabilities after applying advanced techniques to the training process.,1,new
"Furthermore, our approach yields remarkable gains in dependency parsing efficiency compared to traditional methods like HPSG.",1,new
This approach effectively addresses the limited generalizability issue inherent in traditional machine learning models that heavily rely on extensive training datasets through leveraging few-shot meta-learning strategies coupled with weakly-supervised information extraction techniques.,1,new
"By utilizing transfer learning from pre-trained language models, researchers can efficiently bridge the domain adaptation gap encountered when applying deep neural networks to novel tasks requiring minimal annotated data for fine-tuning purposes.",1,new
"To mitigate the dependence on large-scale labeled datasets typically required for model calibration, this method adopts an iterative active learning framework that sequentially selects informative instances for human annotation based on uncertainty estimates derived from model predictions.",1,new
"Our research group utilized a variant of this model that was initially presented at ACL  and later refined through collaboration with Google's NLP team, achieving remarkable accuracy rates comparable to state-of-the-art models.",1,new
"This innovative approach draws heavily from the seminal work by Microsoft Research, building upon their advancements in neural machine learning architecture to produce translations that rival human fluency levels.",1,new
"Recent experiments have shown promising results utilizing our adapted version of the translation framework, demonstrated at IJCNLP conference last year, showcasing significant improvements over traditional phrase-based methods in terms of overall efficiency and precision.",1,new
The use of genetic engineering techniques has significantly streamlined the process of oligonucleotide production.,1,new
Recent advances in synthetic biology have greatly facilitated the development of efficient methods for sugar molecule assembly.,1,new
Advances in molecular design have enabled researchers to precisely control the chemical modifications of polysaccharides at the genomic level.,1,new
A significant body of research has highlighted the crucial role played by two key protein families - transcription factors and ubiquitin ligases - in regulating cellular processes such as DNA replication and repair.,1,new
Studies have consistently shown that molecules like p53 and BRCA1 play pivotal roles in ensuring genomic stability through mechanisms involving DNA damage recognition and repair pathways.,1,new
"Recent findings underscore the importance of proteins associated with mitotic checkpoints, including those belonging to the MAD family, which prevent premature entry into metaphase and ensure proper chromosome segregation during cell division.",1,new
Previous studies have demonstrated that employing advanced ceramics coupled with polyurethane resin yields superior outcomes for simulating natural tooth morphology.,1,new
Our analysis confirms that incorporating micro-abrasion techniques alongside epoxy resin significantly enhances the durability of dental prosthetics.,1,new
Research by Lee et al. indicates that combining glass fibers with acrylic monomers produces optimal results for recreating oral tissue texture and appearance.,1,new
Advanced machine learning algorithms often incorporate contextualized word embeddings into their feature sets by including n-gram sequences such as bigrams and quadgrams for improved performance.,1,new
Sophisticated NLP models frequently utilize phrase-based representations like dependency parses and constituency trees to capture complex linguistic relationships within utterances.,1,new
"Many state-of-the-art sequence labeling systems rely heavily on incorporating higher-order coarser-grained tags that encompass multiple fine-grained labels at once, effectively reducing dimensionality while retaining crucial semantic information.",1,new
"Our study evaluates the effectiveness of incorporating semantic role labeling into machine translation assessment by analyzing 21,000 abstracts of biomedical literature with expert annotation from the National Center for Biomedical Ontology's BioCreative VI challenge, demonstrating significant improvements over traditional methods such as ROUGE, Meteor, and SARI through enhanced correlation with human judgments.",1,new
"We conduct experiments on 12,500 product reviews of e-commerce platforms from the Stanford Natural Language Processing Group's dataset, comparing the performance of a novel neural network architecture with state-of-the-art models including BERTScore, Terrier, and IBM's QuestEval, finding substantial gains in accuracy when leveraging aspect-specific features and entity recognition information.",1,new
"A comprehensive analysis of 30,400 news articles from the New York Times Annotated Corpus reveals improved automatic summarization capabilities via our proposed approach integrating coreference resolution and topic modeling techniques, outperforming established measures like R-prec, F-measure, and Pyramid score across various domains and topics assessed by human evaluators.",1,new
The proposed deep learning framework exhibits remarkable efficacy in tackling complex natural language processing problems owing to its advanced architecture and adaptability across numerous linguistic applications.,1,new
"Recent advances in machine learning have led to significant improvements in the performance of the support vector regression algorithm, making it increasingly popular within the research community for addressing intricate NLP challenges.",1,new
"This innovative approach leverages the strengths of neural networks to deliver superior outcomes in sentiment analysis and other related areas, solidifying its position as a leading tool in the realm of artificial intelligence.",1,new
Our approach also compares favorably with other methods like GOMA when applied to solve large-scale facility location problems efficiently.,1,new
"Compared to existing techniques such as AMOA, our method proves effective for handling complex scheduling tasks under uncertainty conditions successfully.",1,new
"Furthermore, we demonstrate that our algorithm outperforms traditional algorithms including CADA when dealing with resource allocation issues effectively.",1,new
"Our study demonstrates that the Gradient Boosting Classifier effectively addresses various classification problems, leveraging its ability to iteratively refine predictions from weaker models, such as those utilizing Random Forests and Support Vector Machines.",1,new
"This research showcases the successful application of Recurrent Neural Networks in sequence-to-sequence modeling tasks, where our proposed model achieved state-of-the-art performance compared to traditional Hidden Markov Models.",1,new
"In our analysis, the Latent Dirichlet Allocation algorithm efficiently disambiguated topics within large document collections, significantly outperforming previous methods relying solely on Naive Bayes techniques.",1,new
Recent years have witnessed significant advancements in developing neural network architectures for processing syntactic structures from annotated corpora.,1,new
"Notably, substantial improvements have been made over the last ten years in training semantic parsers directly from grammatically tagged datasets.",1,new
A notable trend observed during this period is the remarkable growth in accuracy rates achieved by machine learning algorithms trained on parsed linguistic resources.,1,new
Our analysis indicates that this finding is corroborated by the impressive outcomes achieved through early mobilization protocols compared to prolonged periods of bed rest.,1,new
These findings were further substantiated by the significantly improved patient recovery rates observed after undergoing advanced surgical techniques versus traditional casting methods.,1,new
"Notably, our research supports these conclusions by demonstrating marked enhancements in postoperative rehabilitation when employing evidence-based physical therapy interventions over conventional bracing treatments.",1,new
The BLEU test is widely regarded as a reliable method for assessing the effectiveness of automatic speech recognition systems.,1,new
Recent studies have utilized the Meteor metric extensively to evaluate the accuracy of machine translation models.,1,new
Various researchers rely heavily on the ROUGE measure when investigating the performance of information retrieval algorithms.,1,new
Our experiments demonstrate that integrating a noise-reducing algorithm into the framework of Machine Learning-based translation systems significantly enhances their ability to aid novice authors in refining their writing skills.,1,new
"By leveraging our proposed hybrid approach combining Natural Language Processing techniques with machine learning algorithms, we achieve substantial improvements in providing linguistic support to inexperienced writers.",1,new
This study highlights the effectiveness of employing a Generative Adversarial Network architecture within a corpus-level statistical analysis context to offer insightful feedback to English language learners and struggling writers alike.,1,new
This approach has shown significant advantages over traditional methods in terms of accuracy and efficiency in various NLP tasks such as machine translation and question answering systems.,1,new
"In recent years, deep learning-based techniques like neural network architectures have demonstrated remarkable performance improvements compared to classical statistical methods including maximum entropy Markov model for natural language processing applications.",1,new
"Compared to other predictive models, recurrent neural networks have achieved impressive outcomes when applied to sequential data analysis, outperforming autoregressive hidden markov models significantly across numerous studies.",1,new
This device has proven itself to be a valuable tool for quantifying physical behavior among adolescents in larger-scale observational research projects.,1,new
The use of accelerometers such as this one has greatly facilitated our understanding of daily movement patterns across various age groups during adolescence.,1,new
Extensive application of wearable devices like these have shown significant promise in accurately measuring energetic expenditure levels in school-aged populations.,1,new
Our research has demonstrated that X-ray crystallography methods can effectively utilize RDCs for determining accurate atomic resolutions of complex molecular assemblies such as proteins and their ligands.,1,new
Recent studies have shown significant improvement in macromolecular structures determination through the incorporation of residual dipolar couplings derived from various NMR techniques into computational models.,1,new
The integration of RDC constraints into our structural biology workflow enables us to refine high-resolution models of large biomolecules like DNA-protein interactions with remarkable precision.,1,new
Our findings demonstrate that reducing fluid accumulation significantly enhances patient survival rates by mitigating organ damage and improving overall clinical performance.,1,new
These novel therapeutic strategies have been shown to drastically decrease morbidity while increasing patients' chances of recovery from severe illnesses.,1,new
"The administration of diuretics has proven to play a crucial role in diminishing adverse effects associated with excessive bodily fluids, thereby elevating treatment efficacy and prognostic indicators.",1,new
"Python's sleek design enables developers to write efficient code by reducing unnecessary complexity while providing numerous libraries for simplified tasks such as machine learning integration, data analysis, and GUI development.",1,new
"Julia surpasses other languages in its ability to handle large-scale computations through its just-in-time compilation feature and extensive support for parallel computing, ultimately leading to significant performance enhancements in complex simulations and modeling applications.",1,new
"Go's lightweight nature makes it ideal for building scalable network servers due to its concurrent goroutine scheduling mechanism and robust networking library, allowing for seamless handling of high-traffic websites and distributed systems.",1,new
"Our proposed approach effectively integrates structural dependencies between words, making it highly effective for tasks such as sentence parsing and semantic role labeling due to its robust handling of linguistic complexities.",1,new
This novel method successfully bridges the gap between syntax and semantics by providing a unified framework that facilitates accurate information extraction from large corpora.,1,new
"By leveraging the inherent relationships between grammatical constructs, our technique excels at applications including dependency parsing and named entity recognition.",1,new
Notable contributions to syntactic parsing can also be seen in the creation of the Stanford Parser for German and the BCCWJ project for Japanese.,1,new
Recent advancements in linguistic resources include the development of the propbank for Spanish and the VerbNet database for Russian.,1,new
Other significant developments in dependency treebanks involve the construction of the Leipzig Corpora Collection for Dutch and the GUM corpus for French.,1,new
This research capitalizes upon recent breakthroughs in optimization theory and leverages their potential to advance computational methods for large-scale DC power grids.,1,new
"Inspired by advances in high-performance computing, we introduce a novel algorithm that significantly enhances the efficiency of short-term load forecasting models for renewable energy systems.",1,new
"Drawing from the principles of machine learning and control theory, our team develops a predictive framework capable of accurately modeling complex interactions within smart grid environments.",1,new
This study demonstrates that BERTScore consistently outperforms other metrics in terms of its ability to evaluate machine translation outputs accurately.,1,new
NLTK's tokenization tool has proven itself to be highly effective in processing large corpora efficiently and effectively.,1,new
BLEU scores have long been considered the gold standard for measuring machine translation quality due to their simplicity and reliability.,1,new
"Our findings demonstrate that utilizing hierarchical clustering techniques enables efficient identification of relevant entities linked to their Wikipedia counterparts, showcasing promising outcomes even when contextual knowledge is lacking (Manning & Schutze).",1,new
"An innovative method for resolving named-entity disambiguation tasks leverages frequency-based analysis, leading to substantial accuracy gains without necessitating extensive domain-specific training data (Gruber, Bizer, & Kobilarov).",1,new
"Through our experiments, we observed significant improvements in entity recognition by employing graph-based algorithms that focus solely on semantic similarity measures, disregarding supplementary information sources (Jain et al.).",1,new
Recent studies suggest that machine learning algorithms have demonstrated superior effectiveness over rule-based approaches for identifying synonyms across languages.,1,new
"Within the realm of natural language processing, it has become evident that hybrid models combining neural networks and traditional techniques yield the most impressive outcomes for semantic analysis tasks such as part-of-speech tagging.",1,new
Comparative evaluations indicate that human-annotated datasets often outperform automatically created resources when employed by state-of-the-art algorithms for named entity recognition applications.,1,new
Our approach involves approximating the nonlinear regression model by transforming its parameters into a computationally tractable form through a series of algebraic manipulations involving Taylor expansions around key points of interest.,1,new
"By utilizing numerical integration techniques such as Gaussian quadrature, we successfully reduce the dimensionality of high-dimensional optimization problems while preserving their essential features.",1,new
"To improve computational efficiency, our algorithm reformulates the complex partial differential equations describing fluid dynamics phenomena onto a compact stencil-based representation that enables rapid solution convergence.",1,new
The use of MRI-derived metrics like mean diffusivity has proven invaluable for investigating axonal integrity across various neurological conditions.,1,new
"Quantitative analysis of T2 relaxation times provides valuable insights into myelin health, which is crucial for understanding demyelinating diseases' pathophysiology.",1,new
"Diffusion kurtosis imaging enables researchers to non-invasively quantify water diffusion heterogeneity within brain tissues, offering novel perspectives on neurodegenerative processes.",1,new
Our proposed algorithm for efficient sentence clustering was effectively utilized in resolving inconsistency issues within both human-computer interaction systems and natural language understanding applications.,1,new
This newly developed technique has significantly improved the accuracy of automated speech recognition technology by accurately identifying phonetic patterns across various dialects.,1,new
"By integrating our novel approach into existing corpus-based question-answering models, we achieved substantial improvements in semantic search engine performance metrics.",1,new
"Our approach has been shown to significantly improve model efficiency, yielding precision rates exceeding 92% even when applied to out-of-vocabulary terms across languages.",1,new
"By utilizing this technique, researchers have reported substantial gains in classification accuracy, achieving success rates above 88% for previously unseen entities in various linguistic contexts.",1,new
"This novel method demonstrates remarkable effectiveness in handling ambiguity, allowing it to attain prediction accuracies of approximately 90% for untagged parts of speech within complex sentence structures.",1,new
This can also involve utilizing crowd-sourcing platforms like Clickworker for annotating datasets at minimal costs.,1,new
Another strategy employed by researchers includes leveraging the capabilities of active learning algorithms that automatically select high-value instances for annotation.,1,new
"Furthermore, outsourcing labeling tasks to external companies specializing in data enrichment services has proven effective in streamlining the process while achieving desirable accuracy levels.",1,new
"This novel technique has significantly improved our ability to sequence peptides derived from complex biological specimens like fungi and bacteria, broadening its applicability across various disciplines.",1,new
"Our laboratory successfully employed this innovative tool to analyze proteins within minute quantities of plant tissue, greatly expanding the scope of molecular research possibilities.",1,new
"Recent advancements have enabled researchers to apply this cutting-edge technology to extract valuable insights from tiny amounts of DNA extracted from marine organisms, opening up fresh avenues for oceanic genetic studies.",1,new
"This approach has been successfully applied in various ecosystems worldwide, demonstrating its efficacy in elucidating local adaptations through transplant experiments conducted across native habitats.",1,new
"A notable method for inferring local adaptation involves comparative physiological assessments, whereby organisms from distinct regions are subjected to identical environmental conditions to reveal divergent responses.",1,new
"By leveraging reciprocal transplantation techniques, researchers have effectively uncovered regional variations in plant growth patterns under controlled environments, thereby shedding light on localized ecological pressures that shape species evolution.",1,new
This methodological choice allowed for more nuanced insights into the decision-making processes of expert clinicians by leveraging their extensive knowledge base.,1,new
A mixed-methods design enabled researchers to triangulate findings from both quantitative and qualitative data sources resulting in enhanced validity.,1,new
Utilizing experienced professionals in the field via focus groups added depth and richness to our understanding of complex healthcare issues under investigation.,1,new
The development of the BioGRID database significantly contributed to our understanding of protein interactions and their functional annotation in yeast cells.,1,new
The establishment of the ImageNet large scale visual recognition challenge has greatly facilitated research advancements in computer vision and deep learning algorithms.,1,new
The creation of the Protein Data Bank archive enabled significant breakthroughs in structural biology by providing access to comprehensive three-dimensional atomic coordinates of proteins worldwide.,1,new
"Blood plasma from patients with cardiovascular disease has been found to contain elevated levels of C-reactive protein, interleukin-6, and tumor necrosis factor-alpha, highlighting their potential role in inflammation-mediated pathogenesis.",1,new
"Plasma concentrations of vitamin D were significantly increased among individuals consuming fortified dairy products, suggesting a beneficial impact on bone health outcomes.",1,new
"Analysis of gastric juice revealed high amounts of pepsinogen I and low levels of gastrin, pointing towards reduced parietal cell activity in patients suffering from atrophic gastritis.",1,new
"Current advancements in natural language processing have led to significant improvements in automatic speech recognition technology, showcasing its growing potential for future applications.",1,new
"Recent studies demonstrate that robust neural networks can achieve remarkable accuracy rates when employed in computer-assisted diagnosis, underscoring their importance in medical research today.",1,new
"State-of-the-art image classification models leveraging deep learning techniques exhibit impressive performance metrics, solidifying their position as valuable tools in various fields such as object detection.",1,new
"Our team developed an innovative approach for addressing this specific challenge that leverages machine learning techniques, showcasing superior performance compared to existing solutions.",1,new
"By employing a novel algorithmic framework, our research group successfully overcame several limitations inherent in prior methodologies, leading to significant advancements in field expertise.",1,new
"In resolving the aforementioned issue, we introduced a cutting-edge technique grounded in graph theory principles that outperforms all previous attempts at problem-solving within this domain.",1,new
"This approach has proven highly effective when employed in conjunction with convolutional neural networks for image classification tasks, significantly improving overall accuracy rates.",1,new
"Recent studies have demonstrated that utilizing this method can lead to substantial gains in model performance, particularly in complex regression problems where traditional techniques often falter.",1,new
"In experiments conducted by our research team, we observed marked improvements in predictive power when incorporating ensemble methods like this average-based strategy into existing machine learning frameworks.",1,new
"The precise synchronization between lunar cycles and tidal patterns observed in this study has significant implications for understanding the complex behavior of marine species, such as the annual mass migrations of humpback whales along our coastlines.",1,new
"Research findings suggest that this intricate dance between ocean currents and gravitational forces influences the development and distribution of vital nutrients within aquatic ecosystems, supporting the growth of phytoplankton populations worldwide.",1,new
"A thorough examination of ecological dynamics reveals that this fundamental connection between celestial mechanics and terrestrial processes underpins numerous crucial biological events, including the remarkable seasonal returns of monarch butterflies to their ancestral breeding grounds in Mexico.",1,new
Our study builds upon previous research by introducing more efficient methods for data analysis.,1,new
This paper enhances existing techniques through its innovative use of machine learning algorithms.,1,new
Wang et al.'s findings demonstrate significant improvements over traditional models due to their novel application of deep neural networks.,1,new
Our experiments demonstrated that implementing this strategy enables rapid execution through efficient sample reordering by ranking them according to their corresponding performance scores.,1,new
This approach was found to significantly expedite computations when ordering inputs in decreasing value sequence based upon the associated metric.,1,new
Efficient computation can be achieved by arranging these items in a sorted manner according to the calculated values thereby facilitating faster processing times.,1,new
Our research demonstrates that leveraging contextualized word embeddings significantly improves performance in various NLP applications such as part-of-speech tagging and dependency parsing.,1,new
Experimental evidence suggests that incorporating syntactic structures into machine learning models enhances their ability to predict sentence semantic meaning accurately.,1,new
We found that utilizing hierarchical representations of linguistic knowledge leads to substantial gains in coreference resolution accuracy across different genres of texts.,1,new
Our analysis reveals that this technique allows for rapid computation of posterior probabilities for specific sequence alignment algorithms like the Hidden Markov Model.,1,new
These findings demonstrate that efficient calculation of posterior probabilities is achievable through optimization techniques applied to certain statistical models including model A and B.,1,new
The computational efficiency of calculating posterior probabilities has been successfully demonstrated within our framework utilizing well-established machine learning architectures analogous to those used by models X and Y.,1,new
"Recent advancements in natural language processing have led to significant enhancements in parsing eastern languages like Japanese, resulting in more accurate translations.",1,new
Considerable progress has been achieved in developing sophisticated algorithms for handling idiomatic expressions found in modern European languages including Spanish and French.,1,new
"Ongoing research efforts have yielded substantial breakthroughs in deciphering complex linguistic patterns prevalent in Arabic dialects, thereby expanding the scope of NLP applications worldwide.",1,new
Recent advances in genomics have led to the development of novel biomarkers that facilitate accurate diagnosis and treatment planning for various cancers.,1,new
"High-throughput sequencing technologies have enabled researchers to uncover key genetic mutations associated with disease progression, paving the way for targeted therapeutic interventions.",1,new
"A growing body of evidence supports the use of microarray analysis in identifying specific gene expression signatures linked to particular diseases, thereby improving patient outcomes and quality of life.",1,new
"Our findings suggest that employing ensemble methods such as stacking has been shown to significantly reduce model variance, thereby enhancing generalizability.",1,new
"This study demonstrates how utilizing meta-learning techniques enables robustness against catastrophic forgetting during multi-task learning scenarios, leading to improved overall performance.",1,new
"Recent research indicates that by incorporating transfer learning into neural architectures, researchers have achieved substantial gains in domain adaptation tasks due to increased feature representation capacity.",1,new
Our study revealed that inhibiting HIF prolyl hydroxylase activity using small molecule inhibitors significantly enhances wound healing and tissue remodeling in diabetic patients.,1,new
This research demonstrates that suppression of Aurora A kinase by RNA interference improves cellular proliferation and differentiation during embryonic development in zebrafish models.,1,new
Inhibition of PI3K/AKT signaling pathway through specific pharmacological compounds accelerates muscle recovery after injury and promotes skeletal growth in rats subjected to physical stress.,1,new
Our research suggests that regular workshops accompanied by constructive feedback significantly enhance counselors' professional development over time.,1,new
A combination of instructor-led training sessions followed by peer review has been found to yield lasting enhancements in counseling skills among practitioners.,1,new
Continuous professional education programs incorporating group discussions led by experienced mentors have shown to foster long-term growth in therapeutic techniques amongst mental health professionals.,1,new
Numerous observational studies conducted across various medical institutions worldwide have consistently shown that aspirin has been effective in reducing cardiovascular events among patients at high risk.,1,new
A comprehensive review of existing literature revealed that intravenous thrombolysis administered promptly after stroke onset significantly improves outcomes for patients compared to delayed treatment.,1,new
Longitudinal analysis of hospital records indicates that perioperative use of clopidogrel leads to reduced incidence of post-operative complications in cardiac surgery patients while preserving overall efficacy.,1,new
"Our analysis suggests that empirically-driven approaches to machine learning have yielded significant advancements in linguistic pattern recognition, leading to improved performance in NLP tasks.",1,new
The development of rule-based grammars through empirical methods has been shown to outperform traditional symbolic models in various applications of computational linguistics.,1,new
Empirical studies indicate that context-dependent parsing techniques can significantly enhance the accuracy of part-of-speech tagging and dependency syntax identification.,1,new
This technique also enables efficient model optimization by reducing the risk of overtraining through averaging parameters across iterations.,1,new
Averaging the neural network's weights resulted in improved generalizability and lower variance during testing procedures.,1,new
"Furthermore, parameter averaging proved effective in stabilizing our deep learning approach and enhancing overall predictive accuracy rates.",1,new
"Notwithstanding the high prevalence of Achilles tendon ruptures at mid-substance, encouraging outcomes have been reported for patients undergoing percutaneous repair via a retrograde endoscopic approach.",1,new
Favorable outcomes were observed even when treating acute avulsion fractures involving the calcaneofibular ligament through minimally invasive arthroscopic procedures.,1,new
"Despite being a challenging scenario due to its rarity, satisfactory healing was achieved after employing a modified plantaris grafting method for chronic proximal hamstring tears.",1,new
Another widely used statistical technique that offers numerous benefits for model evaluation is AIC-BIC analysis.,1,new
This metric stands out due to its ability to incorporate both goodness-of-fit and complexity considerations effectively.,1,new
Information criteria-based metrics like the Bayesian-Information-Criterion have proven particularly useful when evaluating complex models.,1,new
Our study draws upon the innovative approach proposed by Smith et al.'s seminal paper for addressing these challenges effectively.,1,new
"To tackle this complex issue, researchers have turned to the iterative technique described in detail by Johnson's influential publication.",1,new
"Building upon established methodologies, our research incorporates key concepts first introduced in Thompson's groundbreaking monograph to achieve significant improvements.",1,new
"High-quality DNA sequencing outputs were assessed by high-performance liquid chromatography, which demonstrated improved resolution for nucleotide identification compared to traditional methods.",1,new
"Fluorescence microscopy analysis revealed more detailed cellular structures when combined with confocal imaging techniques, enhancing our understanding of cell morphology significantly.",1,new
"Accurate protein quantification was achieved through mass spectrometry-based proteomics, allowing researchers to better comprehend complex biological pathways and their interactions within systems biology models.",1,new
This modification of the neural network architecture mitigates the problem of model memorization by reducing its vulnerability to over-fitting during training sessions.,1,new
"By adopting this approach, researchers can significantly improve their models' generalizability across various datasets and applications.",1,new
Implementing such an ensemble method enables practitioners to develop more robust machine learning algorithms that minimize overfitting issues associated with traditional single-model designs.,1,new
"From a theoretical perspective, this innovation has significantly enhanced our understanding of machine learning models by allowing for a more nuanced separation between syntax and semantics, ultimately leading to improved performance in natural language processing tasks such as sentence parsing and semantic role labeling.",1,new
"By incorporating this breakthrough, researchers have been able to tackle complex problems like multimodal fusion, where the integration of visual and linguistic information can now be handled more effectively through the distinct modeling of image features and textual context.",1,new
"As demonstrated in recent studies, separating the neural network architecture into two distinct components - a decoder and an encoder - has facilitated significant advancements in areas including sequence-to-sequence generation and dependency parsing, showcasing its potential for future applications in human-computer interaction and automated question answering systems.",1,new
The standard dataset from the Brown Corpus was employed due to its linguistic characteristics aligning closely with the types of writing that would typically require readability assessment for non-native speakers.,1,new
We opted to utilize the Wall Street Journal corpus since it shares similarities with business-related materials often targeted by automatic grading tools designed for EFL students.,1,new
"Given the parallels between the AP Newswire corpus's formal tone and the kind of prose encountered in educational assessments, this dataset served as our primary choice for developing an automated scoring system.",1,new
The identification of syntactic dependencies is notoriously challenging compared to parsing tree structures,1,new
"current methods fall short in accurately detecting complex interdependencies between words within phrases. However, this study suggests leveraging morphological cues can significantly improve our ability to identify these relationships, thereby providing valuable insights into linguistic compositionality.",1,new
Phylogenetic trees have historically been difficult to reconstruct due to incomplete taxonomic information and inconsistent sequence alignments,1,new
Recent studies have consistently demonstrated that BLEU scores remain the gold standard for machine translation assessment today.,1,new
Microsoft's METEOR metric has also gained popularity among researchers due to its ability to effectively evaluate fluency in translated texts.,1,new
Research suggests that ROUGE metrics continue to play a crucial role in evaluating summarization tasks by providing accurate measurements of overlap between source and target documents.,1,new
Breaking down complex relationships between words in the dataset enhances model interpretability and facilitates better generalization capabilities in NLP systems.,1,new
"Analyzing linguistic patterns at a finer granularity allows for more accurate identification of semantic structures, leading to improved performance in machine learning algorithms.",1,new
"Dissecting sentence-level dependencies within large datasets enables researchers to pinpoint key factors contributing to successful translation outcomes, thereby refining their predictive models' accuracy.",1,new
"This measure exhibits strong correlation with expert evaluations, making it a reliable indicator for assessing semantic similarity among words.",1,new
A comparison study revealed that this approach yields comparable outcomes to state-of-the-art methods while showcasing improved computational efficiency.,1,new
Our analysis demonstrates that the proposed technique achieves significant alignment with gold-standard rankings derived from human annotations across various linguistic domains.,1,new
"Liang et al. demonstrate outstanding achievements in object detection tasks through their innovative application of adversarial training methods, incorporating both spatial-temporal attention mechanisms and graph convolutional networks into their framework. Their approach yields impressive gains over existing models, particularly when handling complex scenes with high occlusion rates.",1,new
"Zhang's recent study showcases remarkable advancements in speech recognition systems via the integration of deep learning techniques with knowledge distillation methods, resulting in significant improvements across various acoustic environments and noise conditions.",1,new
"In a groundbreaking paper, Patel et al. present novel insights into natural language processing by introducing a hybrid model combining transformer encoders with recurrent neural network decoders, leading to substantial enhancements in text summarization accuracy and fluency while preserving contextual coherence.",1,new
Current approaches in Natural Language Processing rely heavily on deep learning techniques such as Recurrent Neural Networks as depicted in Table 2.,1,new
Recent advances in Computer Vision have led to significant improvements in object detection algorithms exemplified by Figure 3.,1,new
Empirical studies demonstrate that reinforcement learning methods outperform traditional rule-based approaches in achieving optimal outcomes for Recommendation Systems.,1,new
"This novel architecture employs a hierarchical representation that effectively captures long-range dependencies between words, enabling significant improvements over traditional word-based methods in neural machine translation tasks.",1,new
Our proposed technique utilizes a hybrid model combining both local contextual information from n-gram features and global semantic knowledge obtained through pre-trained embeddings to enhance the accuracy of statistical machine translation systems.,1,new
"By integrating syntactic parsing techniques into the decoding process, our model can produce more accurate translations by accurately capturing sentence-level structures and relationships between linguistic elements.",1,new
"A study published by Liang et al. demonstrates significant improvements in object recognition accuracy when combining traditional machine learning techniques with a novel feature extraction approach, leading to superior performance across various computer vision benchmarks.",1,new
"Researchers at Stanford University have successfully employed ensemble methods with k-nearest neighbors algorithms, achieving notable gains in classification rates for image analysis applications.",1,new
"According to a recently released research paper, integrating gradient boosting models with decision trees enables the development of highly accurate predictive models in natural language processing tasks, particularly in text categorization problems.",1,new
"In this context, we utilize the odds ratio due to its robustness across numerous validation studies, leaving room for further exploration into alternative metrics.",1,new
"The log-likelihood score serves as our preferred metric owing to its reliability during testing phases, while acknowledging that other evaluation tools may also prove effective.",1,new
"We opt for the chi-squared statistic here, which has shown consistent performance throughout assessment tasks, even though there exist several comparable methods worth investigating.",1,new
These essential oil extracts have been extensively researched due to their potent insectical properties making them ideal candidates for pest control applications worldwide.,1,new
Neem oil has emerged as the leading choice among botanical insecticides owing to its efficacy against various pests and its widespread adoption by farmers globally.,1,new
"Many studies highlight the potential of citronella oil as a natural alternative to synthetic pesticides, citing its strong insect-repelling effects and growing demand from environmentally conscious consumers.",1,new
A recent study investigated various approaches to forming equivalence classes and concluded that the Dice similarity measure and cosine-based metrics consistently yielded superior performance.,1,new
This research analyzed several methods for constructing word clusters and discovered that the Jaro-Winkler distance and Levenshtein edit-distance algorithms produced notable improvements over traditional proximity measures.,1,new
"In their comparison of clustering methodologies, researchers identified that fuzzy set theory and probabilistic relational models outperformed other competitors due to their ability to capture nuanced relationships between concepts.",1,new
"Recent advancements in neural networks have significantly improved the accuracy of automatic speech recognition systems, indicating that they can now effectively transcribe spoken words into written texts with high fidelity.",1,new
"Ongoing research in natural language processing has led to notable enhancements in grammar checking tools, demonstrating their capability to identify and correct grammatical errors efficiently.",1,new
Significant strides made in deep learning algorithms for sentiment analysis imply that these models can accurately detect subtle nuances in human emotions expressed through online reviews and feedback.,1,new
Various state-of-the-art dependency parsers that achieve high performance in terms of grammatical correctness have been observed to employ efficient algorithms for reducing computational complexity through heuristic-based strategies such as beam search and dynamic programming techniques.,1,new
Researchers utilizing statistical machine learning approaches often report improved parse tree quality by leveraging large-scale annotated corpora and implementing sophisticated feature extraction methods to narrow down potential parses efficiently.,1,new
High-performing parser models frequently rely on innovative data-driven techniques like maximum entropy Markov model and transition-based neural networks to systematically explore the vast space of possible syntactic structures while minimizing computation time significantly.,1,new
"Our research demonstrates that BERT achieves impressive performance gains when utilized for named entity recognition tasks, significantly outperforming existing models across various datasets.",1,new
"This study highlights the efficacy of transformer-based architectures like XLNet in resolving ambiguity in machine translation outputs, resulting in substantial improvements over traditional methods.",1,new
"The implementation of attention mechanisms within neural networks has been shown to greatly enhance the accuracy of natural language processing applications such as question answering, producing remarkable outcomes across numerous benchmarks.",1,new
Our analysis revealed that applying the proposed framework to a pre-processed dataset yielded outstanding outcomes when compared to existing methodologies.,1,new
Utilizing our novel approach on a refined corpus derived from the Brown Corpus resulted in remarkably accurate parsing performance.,1,new
"By integrating our suggested techniques into the standard pipeline for named entity recognition tasks, we observed substantial improvements across all evaluated metrics.",1,new
Isoliquiritigenin demonstrated remarkable efficacy in reducing inflammation and suppressing lipopolysaccharide-induced NO production.,1,new
Flavonoids such as wogonosides A-C exhibited significant inhibitory effects against histamine release from mast cells.,1,new
Kaempferol-3-O-rutinoside effectively alleviated symptoms associated with allergic rhinitis by modulating Th1/Th2 balance.,1,new
"Recent advancements in neural network architectures have led to significant improvements in automatic speech recognition systems, demonstrating their effectiveness in various applications.",1,new
"The development of cognitive computing models has enabled researchers to better understand human decision-making processes, ultimately contributing to more accurate predictions in fields such as economics and finance.",1,new
"Linguistic analysis techniques have been instrumental in identifying patterns and structures within natural languages, facilitating the creation of sophisticated chatbots that can engage in meaningful conversations.",1,new
This approach may incorporate advanced indexing techniques such as hierarchical clustering methods to improve retrieval effectiveness.,1,new
Future research could explore the application of natural language processing algorithms for enhancing query expansion strategies.,1,new
Potential avenues for improvement may involve leveraging semantic role labeling to better capture nuanced relationships between query terms and relevant documents.,1,new
Our proposed approach leveraged advanced neural architectures coupled with dynamic bit-packing techniques to optimize storage efficiency significantly.,1,new
This innovative method integrated distributed hash tables with adaptive compression algorithms resulting in substantial reductions in memory requirements.,1,new
"By implementing novel graph-based indexing strategies alongside selective caching mechanisms, we were able to realize considerable improvements in computational performance and resource utilization.",1,new
Minimally invasive surgical techniques have revolutionized the field of gastrointestinal oncology by offering patients with rectal cancer more effective treatment options such as transanal minimally invasive surgery which enables precise removal of tumors while minimizing damage to surrounding tissue.,1,new
Recent advancements in robotic-assisted technology have significantly improved outcomes for individuals undergoing transanal minimally invasive surgery resulting in reduced recovery times postoperative complications and enhanced quality of life for these patients.,1,new
A comparative study published recently demonstrated that transanal minimally invasive surgery yields comparable efficacy rates to traditional open surgery methods but with notable advantages including decreased hospital stay duration and faster return to normal activities.,1,new
"Our analysis employed Kullback-Leibler divergence instead of log-likelihood ratio for its computational efficiency, allowing us to process large datasets within reasonable timeframes.",1,new
"For better performance, we opted to utilize the trigram model over bigram due to its superior handling of long-range dependencies in natural languages.",1,new
We selected the stochastic gradient descent algorithm for training our models because it minimizes computational overhead while yielding accurate predictions on complex tasks.,1,new
"This study highlights significant methodological flaws in previous approaches that fail to account for infrequent occurrences, thereby providing novel insights into quantifying event surprise.",1,new
"Our analysis demonstrates the inadequacy of traditional models when dealing with low-probability phenomena, thus necessitating the development of more robust statistical frameworks.",1,new
"By reevaluating existing methodologies, we reveal inherent biases in conventional techniques leading to inaccurate assessments of rare event likelihoods, underscoring the need for refined analytical tools.",1,new
"Despite significant advances in cancer research over the past decade, numerous clinical trials have been plagued by inconsistent results, exemplified most recently by the lackluster performance of pembrolizumab in treating metastatic melanoma patients.",1,new
"Following decades of attempts to identify effective therapies for Huntington's disease, researchers continue to face setbacks such as the inconclusive findings from the pridopidine phase IIb trial.",1,new
"Although substantial progress has been made in understanding genetic mutations associated with schizophrenia, ongoing challenges persist, including the underwhelming efficacy observed in the sertindole pivotal study.",1,new
Naloxegol has been proven highly effective in managing chronic constipation by significantly reducing symptoms such as straining during bowel movements.,1,new
The use of clonidine in hypertension treatment has garnered substantial support due to its ability to reduce blood pressure levels efficiently while minimizing side effects.,1,new
The efficacy of rivaroxaban in preventing stroke recurrence among patients with atrial fibrillation makes it a valuable asset in cardiovascular disease management.,1,new
"Advances in speech recognition technology have been significantly enhanced due to the availability of extensive datasets like LibriSpeech and TED-LIUM, comprising high-quality audio recordings from various sources worldwide.",1,new
"The remarkable growth in computer vision research can be attributed to the release of large-scale image databases such as ImageNet and COCO, offering annotated images across numerous categories for training deep learning models.",1,new
"Recent breakthroughs in natural language processing owe much to the development of comprehensive linguistic resources including Treebank and Penn Discourse TreeBank, providing parsed tree structures for English texts that facilitate efficient model evaluation and optimization.",1,new
Various bioinformatics tools such as PeakRanger have been employed for accurate identification of ChIP-seq peaks.,1,new
Several popular tools like HOMER are often utilized for analyzing ChIP-seq data due to their efficiency.,1,new
Broadly used algorithms including SICER facilitate comprehensive analysis of histone modification patterns from ChIP-seq experiments.,1,new
A particularly robust approach has been developed utilizing stochastic gradient descent methods.,1,new
This highly effective algorithm enables accurate predictions through its use of probabilistic models.,1,new
"By employing a comprehensive search strategy, researchers have established a solid foundation for future analysis.",1,new
"This paper presents a comprehensive evaluation of the advanced predictive controller for precision temperature control systems, demonstrating remarkable improvements over traditional methods.",1,new
"The robustness of our novel adaptive filtering algorithm has been validated through extensive simulations under various operating conditions, showcasing its superior performance in mitigating signal distortions.",1,new
"A thorough analysis of the proposed machine learning framework reveals exceptional accuracy in anomaly detection tasks, outperforming existing state-of-the-art techniques by a significant margin.",1,new
Our research team opted for enzymatic extraction due to its effectiveness in processing complex biological samples while minimizing potential hazards associated with chemical treatments.,1,new
"In accordance with established protocols, we employed high-temperature vacuum drying to remove impurities from our experimental materials, which proved to yield reliable and consistent results.",1,new
"Given the need for precision in molecular analysis, we utilized ultrasonic cleaning methods that have shown remarkable success in removing surface contaminants without compromising sample integrity.",1,new
"Our proposed method achieves state-of-the-art performance in estimating word frequencies from large datasets, providing accurate results at a significantly reduced computational cost compared to existing approaches.",1,new
"Recent advances in efficient approximation algorithms enable near-optimal solutions for counting rare events in natural language processing tasks, thereby improving overall system scalability and reliability.",1,new
"By leveraging novel techniques for probabilistic inference, we demonstrate substantial gains in speed and precision when approximating frequency distributions over vast linguistic corpora.",1,new
This innovative approach involves incorporating adaptive learning rate algorithms to dynamically update the model's parameters during training sessions.,1,new
Employing ensemble methods by combining predictions from multiple models has shown significant improvements in overall system accuracy and reliability.,1,new
"Utilizing transfer learning techniques allows researchers to leverage pre-trained networks and fine-tune them for specific tasks, resulting in faster convergence rates.",1,new
"Our findings indicate that this novel approach led to impressive outcomes: we successfully identified over 90% of related concepts within the semantic network, while also achieving higher accuracy rates compared to traditional methods for clustering word senses.",1,new
"This innovative technique has shown remarkable potential by demonstrating superior performance in identifying lexical relationships, as evident from its ability to pinpoint almost all relevant associations between synonyms, thereby enhancing overall precision.",1,new
"These exciting results demonstrate the efficacy of our proposed framework, which outperformed existing methodologies in terms of recall rate – detecting nearly every instance of synonymous expressions across the corpus at a much higher frequency than previous algorithms.",1,new
We utilize the parsing model designed by James McClosky due to its exceptional accuracy levels comparable to state-of-the-art systems.,1,new
"Our implementation employs the robust syntactic analysis algorithm proposed by Mark Johnson, which has been widely adopted for its reliability in various natural language processing tasks.",1,new
This paper builds upon the lexicalized tree adjoining grammar framework created by Ivan Sag and was chosen for our project's syntax component because of its high precision rates across diverse linguistic structures.,1,new
"Studies conducted by researchers at Harvard University found significant correlations between implementing project-based learning methods and improved student engagement across various subjects, particularly mathematics and science.",1,new
Our analysis revealed that schools utilizing competency-based progression models experienced notable increases in teacher confidence when designing curricula aligned with national standards.,1,new
A recent nationwide study discovered that incorporating technology-enhanced formative assessment tools led to enhanced student motivation and achievement gains in reading comprehension among economically disadvantaged students.,1,new
The extensive use of large-scale datasets like WikiText-103 has significantly accelerated advancements in machine learning for NLP tasks.,1,new
High-quality labeled databases including SQuAD have greatly facilitated the development of accurate question answering systems.,1,new
Well-curated collections such as GLUE Benchmark continue to drive improvements in natural language processing methodologies and applications.,1,new
"Our proposed method achieves a significant acceleration factor by leveraging a subset of the validation dataset for gradient estimation, resulting in a substantial boost in model convergence rate.",1,new
"By utilizing a representative selection from the test pool, we observe a notable reduction in computational time required for the optimization process, amounting to a tenfold gain in efficiency.",1,new
"A key innovation lies in our ability to approximate the gradient updates via a strategic sampling strategy that draws upon a curated portion of the evaluation dataset, thereby speeding up the entire learning procedure by nearly three orders of magnitude.",1,new
"Our study builds upon the pioneering work of, who proposed incorporating gradient-based optimization techniques into neural network architectures, ultimately resulting in improved performance metrics when translating low-resource languages.",1,new
"The novel approach presented by  leverages ensemble learning strategies to enhance the accuracy of speech recognition systems, outperforming state-of-the-art methods in various benchmarks.",1,new
"In their seminal paper,  developed a reinforcement learning framework for predicting protein structures, showcasing significant gains in prediction precision compared to traditional ab initio approaches.",1,new
"This innovative approach leverages advancements in natural language processing for the effective assessment of translation systems, ultimately contributing significantly to the growth of Language Technology.",1,new
"Our novel algorithmic framework facilitates comprehensive analysis of machine learning models used in Natural Language Processing tasks, thereby accelerating breakthroughs in this field.",1,new
"By integrating cutting-edge methodologies from Artificial Intelligence, our team has successfully created a robust toolset for evaluating linguistic quality, pushing forward the boundaries of Human-Computer Interaction.",1,new
This innovative approach demonstrates significant potential for enhancing IoT network performance by leveraging context-aware communication protocols within complex distributed systems.,1,new
The proposed framework showcases remarkable advancements in developing ef.cient solutions for large-scale sensor deployments through its integrated spatial reasoning module.,1,new
The novel implementation of mobile agent technology in this research has led to substantial improvements in wireless transmission reliability across heterogeneous networks.,1,new
This approach has led to significant advances in part-of-speech tagging techniques employing Hidden Markov Models.,1,new
"The use of statistical significance testing, such as the z-test, remains prevalent among researchers analyzing large datasets.",1,new
Various machine learning algorithms including Support Vector Machines have shown great promise when applied to natural language processing tasks.,1,new
Entropy rate and Conditional Mutual Information have been widely adopted in various machine learning models for their ability to quantify complex relationships between variables.,1,new
The use of Jensen-Shannon Divergence and Kullback-Leibler divergence has proven invaluable in evaluating the similarity and difference between probability distributions across numerous fields of research.,1,new
Kolmogorov Complexity and Lempel-Ziv complexity have demonstrated significant utility in measuring the inherent randomness within datasets and coding efficiency of algorithms respectively.,1,new
This approach has been extensively utilized across various disciplines due to its simplicity and effectiveness.,1,new
"Among all available measures, it remains the most popular choice for analyzing complex relationships between variables.",1,new
Widespread application can largely be attributed to its ability to quantify dependencies within large datasets efficiently.,1,new
"This comprehensive dataset comprises over 10 million tokens from various genres including news articles, academic papers, and product reviews, offering unparalleled insights into linguistic structures.",1,new
"The Corpus of Linguistic Acceptability has undergone significant expansion since its inception, now encompassing more than 160K acceptable sentences across several domains.",1,new
"A notable achievement in large-scale corpora development has been realized through the creation of the OpenSubtitles database, which boasts over 640k English movie subtitles for analysis purposes.",1,new
"Our research team has found the automated annotation tool, entity_recognizer, to be incredibly valuable for identifying entities within large datasets.",1,new
The implementation of sentence_similarity_measure has significantly improved our ability to compare linguistic structures across languages.,1,new
"Utilizing the parsing library, grammar_parser, we were able to accurately capture complex syntactic relationships between words in our corpus analysis.",1,new
"Various metaheuristics can also be employed to address this challenge, such as differential evolution DE and particle swarm optimization PSO.",1,new
Another effective approach is the use of simulated annealing SA to optimize these difficult instances.,1,new
"Several advanced heuristics have been proposed to tackle complex mixed-integer linear programming MILP models, including scatter search SS and tabu search TS.",1,new
This characteristic has led to their widespread adoption across various disciplines including artificial intelligence and machine learning research.,1,new
"As a result of its versatility, these models have found applications in natural language processing tasks and human-computer interaction studies.",1,new
"Due to its adaptability, researchers from different fields such as computer vision and information retrieval have leveraged vector space models for their investigations.",1,new
We utilize the METEOR metric for evaluating the fluency and grammar of our machine-generated texts due to its proven effectiveness in assessing naturalness.,1,new
The BLEU score is used extensively in NLP tasks because it demonstrates strong correlation with human evaluations of translation quality.,1,new
Our team selects LASER as the primary assessment tool for cross-lingual question answering performance due to its robust alignment with expert ratings.,1,new
Recent advancements in natural language processing have led to significant improvements in the design of deep learning architectures for named entity recognition tasks.,1,new
In recent times there has been substantial progress made towards creating highly accurate automated summarization models utilizing supervised learning techniques.,1,new
Over the past decade researchers have shown notable success in developing sophisticated computer vision algorithms leveraging convolutional neural networks.,1,new
The development of novel evaluation measures such as SimMetrics has provided a significant improvement over traditional methods like TER. These newer approaches account for contextual relevance beyond mere word-to-word matching.,1,new
Several advanced machine learning models have been proposed to overcome the limitations of traditional metrics including BLEU and METEOR by incorporating more nuanced understanding of sentence-level semantics.,1,new
"Recent research efforts have led to the creation of hybrid evaluation metrics that integrate various strengths from existing tools like PER and NIST, yielding improved accuracy in assessing translation quality.",1,new
"Our research highlights the multifaceted nature of oxytocin's effects, particularly its role in facilitating childbirth through the stimulation of uterine contractions while also influencing complex social interactions between individuals.",1,new
This hormone has garnered significant attention due to its capacity to modulate various physiological processes such as lactation initiation and maternal bonding alongside shaping our perception of trust and cooperation within communities.,1,new
"Studies have consistently demonstrated that oxytocin plays a pivotal part in regulating emotional responses, from promoting attachment in early childhood development to fostering empathy among adults thereby underscoring its profound impact on interpersonal relationships.",1,new
"Recent advancements in deep neural networks have led to numerous breakthroughs in addressing complex stochastic processes, including Recurrent Neural Networks, Long Short-Term Memory models, Convolutional Neural Networks, etc. Notably, LSTMs exhibit exceptional temporal dependencies handling capabilities.",1,new
"Several statistical methods have been proposed for modeling uncertain phenomena, encompassing Bayesian Networks, Gaussian Processes, Random Forest algorithms, among others. Importantly, these approaches offer robustness against overfitting issues often encountered in traditional regression analysis.",1,new
"In recent years, various computational tools have emerged to handle irregular patterns, incorporating Genetic Programming, Ant Colony Optimization, Swarm Intelligence, etc. Specifically, GP has demonstrated its effectiveness in solving optimization problems involving non-linear relationships between variables.",1,new
"We propose a novel approach for calculating semantic similarity that builds upon previous methods, such as those employed by Chen et al.'s model, yielding superior outcomes on standard benchmarks.",1,new
"In this study, we introduce a straightforward technique for measuring structural similarity that parallels the framework outlined in Li's earlier research, demonstrating promising performance across various evaluation metrics.",1,new
"Similarity analysis has been refined through our proposed algorithmic strategy, showing comparable efficacy to more complex approaches like the vector-based model presented by Kim and colleagues, while offering enhanced computational efficiency.",1,new
"Our experiments demonstrate that employing this technique yields significantly better outcomes, resulting in up to 8.9% improvement over state-of-the-art models according to metrics such as METEOR score.",1,new
"This method has proven itself to be highly effective in enhancing the accuracy of machine translations, achieving a notable gain of approximately 12.1% when evaluated against human ratings for fluency.",1,new
"Notably, we observed substantial benefits from utilizing this strategy, including enhancements of around 19.5% in ROUGE scores relative to traditional approaches.",1,new
The use of diode lasers has become increasingly popular in periodontal treatments due to its effectiveness in reducing bacterial loads.,1,new
Erbium lasers exhibit superior efficacy compared to other types when it comes to minimally invasive tissue removal procedures in orthopedics.,1,new
Gallium-based lasers show immense promise for applications in surgical interventions owing to their precise ablation capabilities.,1,new
Recent advancements in machine learning algorithms have led to significant improvements in named entity recognition accuracy.,1,new
The incorporation of contextual information has greatly enhanced the performance of part-of-speech tagging models recently developed.,1,new
Our experiments demonstrate that incorporating semantic role labeling into natural language processing pipelines yields substantial gains in overall system efficiency.,1,new
Zebrafish have emerged as premier models for studying developmental biology due to their transparent embryos and rapid growth rates allowing researchers to easily observe embryonic development processes at various stages.,1,new
Caenorhabditis elegans has proven invaluable for elucidating neurodegenerative disease mechanisms through its simple nervous system and well-characterized genetic makeup making it an attractive choice for investigating molecular pathways underlying human diseases like Parkinson's and Alzheimer's.,1,new
Mouse models have provided significant insights into cancer research by enabling scientists to study tumor progression and metastasis in detail thanks to their close genetic similarity to humans and ability to mimic complex human cancers.,1,new
"Recent advancements in neural network architectures for natural language processing have significantly enhanced our understanding of language complexities, yielding remarkable breakthroughs in speech recognition systems that surpass earlier implementations by substantial margins.",1,new
"Latest studies employing deep learning techniques have demonstrated outstanding performance gains in information retrieval tasks, highlighting the potential benefits of integrating cognitive computing into search engine optimization strategies.",1,new
"Innovative research utilizing ensemble methods has led to notable enhancements in predictive modeling capabilities, paving the way for more accurate forecasting applications across various domains such as climate science and economics.",1,new
"We utilized OpenMP for efficient parallel processing To identify key patterns within our dataset, we integrated findings from Chen's study on clustering techniques and Lee's analysis of machine learning algorithms to refine our model.",1,new
"Employing MPI for distributed computing enabled us to expedite our calculations By merging insights from Patil et al.'s research on natural language processing and Kumar's investigation into network optimization, we enhanced the accuracy of our predictive models.",1,new
Utilizing CUDA for GPU acceleration allowed us to process large datasets quickly Our evaluation involved combining the outcomes of Yang's experiment on deep learning frameworks and Patel's review of computer vision applications to inform our design decisions.,1,new
Our study demonstrates that this novel approach outperforms existing methods in terms of accuracy and efficiency when working with large datasets.,1,new
"In contrast to traditional techniques, our proposed framework yields significantly better results while requiring minimal computational resources.",1,new
This innovative technique exhibits impressive performance gains compared to established alternatives when applied to complex linguistic tasks.,1,new
"Recent advancements have made self-supervised learning techniques increasingly appealing, particularly when dealing with vast amounts of untagged linguistic resources available online.",1,new
Supervised methods may require considerable human effort and annotated datasets but research into semi-automatic tagging processes offers promise for future reductions in manual labor requirements.,1,new
The use of weakly supervised models allows researchers to leverage large volumes of freely accessible web-based texts while minimizing the need for extensive annotation efforts typically associated with fully labeled training sets.,1,new
"We employed a maximum likelihood estimation method to determine optimal values for λ, σ, and μ, which is widely used in statistical modeling techniques.",1,new
"A Bayesian inference framework was utilized to derive posterior distributions for θ, ϕ, and ψ, facilitating accurate parameter estimation and uncertainty quantification.",1,new
"In order to evaluate model performance, we utilized cross-validation procedures to select suitable hyperparameters η, γ, and δ, ensuring robustness against overfitting and underfitting issues.",1,new
The BDI-II scale is widely recognized for its reliability in assessing depressive symptoms across various populations.,1,new
The Geriatric Depression Scale has proven effective in identifying geriatric patients at risk for depression in clinical practice settings.,1,new
The Patient Health Questionnaire-9 item (PHQ-9) has consistently demonstrated high sensitivity in detecting major depressive disorder among adolescents and adults.,1,new
"Recent advancements in natural language processing have led to the widespread adoption of two prominent evaluation metrics for single document summarization, specifically BERTScore and METEOR.",1,new
"In recent years, several researchers have proposed alternative methods for assessing the quality of machine translation outputs, including BLEU scores and TER, both of which have shown promising results.",1,new
"Three notable approaches have gained significant attention within the field of information retrieval, particularly in the context of query-based ranking systems: precision at n, mean average precision, and discounted cumulative gain.",1,new
"Our research demonstrates that etanercept effectively reduces inflammatory markers such as C-reactive protein, making it a valuable treatment option for patients suffering from chronic inflammation-related disorders.",1,new
"This study highlights the efficacy of rituximab in decreasing tumor necrosis factor-alpha levels, providing hope for improved outcomes in autoimmune disease management.",1,new
"Notably, abatacept exhibits impressive capacity to inhibit interleukin-17 production, offering a promising avenue for treating immune-mediated conditions characterized by excessive IL-17 activity.",1,new
"Recent advancements in natural language processing have led to the creation of sophisticated algorithms for semantic role labeling, which hold great promise for improving human-computer interaction.",1,new
"A novel framework for modeling linguistic ambiguity has been proposed by researchers at leading institutions worldwide, utilizing cutting-edge techniques from statistical analysis to enhance the accuracy of automated language understanding systems.",1,new
"Ongoing research into cognitive science has yielded significant insights into the neural mechanisms underlying human decision-making processes, providing valuable guidance for the development of more effective artificial intelligence models.",1,new
Recent studies suggest that lysine-based polyurethane scaffolds exhibit favorable mechanical properties suitable for tissue engineering applications.,1,new
The development of lysine diisocyanate cross-linked polymers has led to the creation of implantable biomaterials with enhanced cell adhesion capabilities.,1,new
Polylysine-modified polyurethane matrices demonstrate excellent hemocompatibility profiles making them promising candidates for vascular grafting procedures.,1,new
Our study adopts the multi-layer neural network architecture introduced by Smith et al. that exhibits robustness against overfitting during model development.,1,new
Utilizing the novel approach outlined in Lee's research paper allows for efficient optimization techniques to be applied without compromising accuracy levels significantly.,1,new
"By employing the decision tree-based classification method described in Johnson's seminal work, our analysis demonstrates improved convergence rates compared to other contemporary models.",1,new
Our findings indicate that incorporating Word Sense Disambiguation into Natural Language Processing has led to notable improvements in Machine Translation tasks.,1,new
Recent studies demonstrate a significant enhancement in the accuracy of question-answering systems when utilizing Word Sense Disambiguation techniques in their frameworks.,1,new
"The integration of Word Sense Disambiguation methods into our deep learning models for Named Entity Recognition exhibits promising outcomes, showcasing improved entity recognition rates across various domains.",1,new
"This model demonstrates impressive performance in relation to dependency parsing tasks , outperforming other techniques like HMMs and probabilistic suffix trees across various benchmarks.",1,new
"Recent studies have shown that Graph-Based Methods exhibit excellent capabilities for information extraction from unstructured texts , making them highly effective tools in many applications such as question answering systems.",1,new
"The Conditional Random Field algorithm has proven itself to be remarkably efficient in handling sequence labeling problems , achieving state-of-the-art results in both speed and accuracy compared to traditional machine learning approaches.",1,new
This approach effectively addresses the challenge of generating context-dependent models that rely heavily on pre-existing exemplars for training purposes.,1,new
"The proposed technique significantly reduces the complexity associated with template creation from existing instances, paving the way for more advanced applications down the road.",1,new
"By leveraging this innovative solution, researchers can now efficiently develop sophisticated frameworks that minimize reliance on manual template construction.",1,new
"In recent times, various innovative methods for assessing speaker recognition systems have emerged, primarily aimed at minimizing manual effort required during the testing phase of software development.",1,new
"Several novel approaches for measuring speech-to-text quality control have been proposed over the past decade, mainly designed to decrease the time-consuming process associated with evaluating these technologies manually.",1,new
"During the past five years, numerous algorithms for objective evaluation of natural language processing models have been developed, largely intended to expedite the optimization of complex computational frameworks.",1,new
Our analysis reveals that the incorporation of multilingual features yields substantial enhancements in efficiency and precision compared to traditional approaches used for bilingual sentence alignment.,1,new
Results indicate that the newly developed algorithm outperforms previous methods by achieving faster processing times while retaining high-quality translations in a complex neural network architecture.,1,new
This study demonstrates that integrating linguistic knowledge from various languages leads to considerable improvements in translation quality and reduced latency within our cutting-edge natural language generation framework.,1,new
Our approach exhibits significant superiority compared to other machine translation systems that rely solely on n-gram features during decoding.,1,new
"By leveraging this novel framework, we achieve substantial improvements over traditional re-ranking methods which often fail to incorporate contextual relationships between words.",1,new
"In contrast to conventional approaches limited by their reliance on low-order Markov chains, our model boasts enhanced capacity for capturing long-range dependencies in natural language processing tasks.",1,new
"Our research team's implementation of polar coding techniques demonstrates significant improvements in both theoretical efficiency and practical application capabilities when compared to other existing methods, showcasing its versatility across various source and channel encoding tasks.",1,new
"Recent studies have confirmed that polar codes can achieve optimal performance levels in numerous scenarios by efficiently leveraging information theory principles, making them a valuable addition to modern communication systems design.",1,new
This study's findings support the notion that polar coding offers superior reliability and error correction abilities over traditional coding schemes due to its ability to adapt to varying signal-to-noise ratios and transmission conditions effectively.,1,new
Many researchers have found that certain algorithms excel when trained solely on unannotated datasets,1,new
This approach has proven effective for various machine learning models in specific problem domains,1,new
Recent studies demonstrate that some neural networks can achieve remarkable performance improvements by leveraging large volumes of unlabeled training data,1,new
"This innovative approach for mitigating non-point source pollution through constructed wetlands has gained widespread acceptance globally, attributed to its minimal financial investment requirements and eco-friendly nature that promotes sustainable water management practices worldwide.",1,new
"The use of biochar amendments in soil has been extensively researched in recent years, yielding encouraging outcomes such as enhanced nutrient retention capacity and reduced chemical fertilizer application needs, thus making it a promising solution for environmentally conscious farmers.",1,new
"Recent studies have highlighted the effectiveness of green roofs as a viable strategy for urban stormwater management, characterized by significant reductions in surface runoff volumes and alleviated pressure on municipal drainage systems while providing aesthetic benefits to built environments.",1,new
This approach also offers significant benefits when analyzing complex linguistic structures by enabling researchers to seamlessly integrate disparate types of syntactic information.,1,new
Another notable advantage is its ability to efficiently handle various feature representations from tokenization patterns to named entity recognition outputs.,1,new
Its capacity for accommodating numerous kinds of semantic properties makes it particularly well-suited for applications involving deep contextual understanding tasks.,1,new
Our proposed approach builds upon existing natural language processing techniques by integrating contextualized embeddings into a robust neural network architecture to improve the accuracy of named entity recognition tasks.,1,new
This paper presents an innovative method for enhancing the performance of machine translation models through the incorporation of attention mechanisms and pre-trained word representations.,1,new
"By leveraging recent advances in transformer architectures and deep learning methods, our research aims to develop a more effective model for sentence compression that retains key information while significantly reducing redundancy.",1,new
"Recent advancements in neural machine translation have led to significant improvements in phrasal sentence processing capabilities, enabling models like  to effectively retain and utilize lengthy linguistic structures.",1,new
"The success of contemporary phrase-based statistical MT methods can largely be attributed to their capacity for storing and leveraging extensive phrasal units, thereby enhancing overall system performance.",1,new
"By incorporating sophisticated phrasal representation learning mechanisms, recent studies have demonstrated that models such as  exhibit remarkable proficiency in capturing complex syntactic relationships within longer phrases.",1,new
"Our research has demonstrated that the use of focused ultrasound (FUS) technology facilitates the efficient delivery of macromolecules across the blood-brain barrier, thereby opening up novel avenues for neurological disorder treatment.",1,new
"Recent experiments have confirmed that high-frequency sonication can enhance the passage of large molecular weight compounds through the brain's protective membrane, expanding the possibilities for targeted therapy applications.",1,new
Studies conducted by our team have revealed significant success rates in transporting therapeutics beyond the size limit set by the blood-brain barrier when employing a combination of acoustic energy and bubble-enhanced delivery methods under optimized conditions.,1,new
"The use of multilayer neural networks has been gaining popularity recently, primarily attributed to their superior predictive capabilities, ease of optimization, and minimal requirements for extensive hardware resources during deployment.",1,new
"Recent advancements have led to significant improvements in support vector machines, particularly concerning accuracy rates, processing speed, and user-friendliness in high-dimensional datasets.",1,new
"Furthermore, decision tree algorithms continue to demonstrate exceptional performance across various applications, driven by their interpretability, adaptability, and robustness against noisy inputs and outliers.",1,new
Their efficacy has been demonstrated across various applications including search engine optimization and semantic annotation processes.,1,new
These techniques have shown remarkable promise in knowledge graph construction and entity disambiguation tasks.,1,new
Successful deployments can also be seen in natural language processing pipelines for document categorization and sentiment analysis functionalities.,1,new
"Recent advancements in machine learning have led to successful applications of collaborative filtering techniques in recommendation systems , personalized advertising, and knowledge graph-based inference .",1,new
"Graph theory has played a crucial role in identifying influential nodes within complex network structures, enabling effective community detection and information diffusion models .",1,new
"Several studies have demonstrated the efficacy of spectral clustering methods for grouping high-dimensional datasets, particularly in image segmentation tasks and dimensionality reduction applications.",1,new
"This high-powered laser system boasts exceptional beam quality, yielding superior efficiency when compared to other neodymium-doped yttrium aluminum garnet lasers available today.",1,new
"Notably, this device's ultra-fast pulse generation capabilities enable it to outperform its counterparts, resulting in unprecedented outcomes for various applications.",1,new
"The innovative design of the Light Age Q-Clear enables unparalleled peak power delivery, making it an indispensable tool for advanced research and development initiatives worldwide.",1,new
"Our analysis reveals that the automatic metrics, particularly METEOR, exhibit strong agreement with expert judgments at various levels of n-gram overlap, especially when evaluating machine translations in French languages.",1,new
"For Chinese-to-English sentence alignment tasks, we observed a significant association between the ROUGE score and human assessment ratings when using a relatively small set of reference summaries, suggesting its reliability under limited resource conditions.",1,new
"In our research, we found that the F-score demonstrates substantial correspondence with human evaluators' scores during post-editing assessments across several linguistic domains when averaging over four distinct annotator judgments.",1,new
Promising computational models and extensive numerical experiments were conducted for the evaluation of the GA 3 algorithm.,1,new
Positive outcomes from rigorous theoretical analysis and experimental trials of the RBM framework have also been observed.,1,new
Favorable findings and systematic empirical tests of the DBN approach demonstrate its effectiveness.,1,new
"Recent advances in neural network architectures have led to significant breakthroughs in speech recognition systems, yielding unprecedented accuracy rates across various linguistic environments.",1,new
"Recurrent Neural Networks (RNNs) have demonstrated exceptional capabilities in time series forecasting tasks, outperforming traditional methods by substantial margins in several benchmark studies.",1,new
"Hybrid approaches combining symbolic and connectionist AI techniques have proven highly effective in natural language processing applications, achieving superior results compared to standalone methodologies in recent evaluations.",1,new
Our analysis demonstrates that incorporating domain knowledge into machine translation models significantly enhances their ability to capture nuances in word meaning.,1,new
Empirical studies have consistently revealed substantial improvements in sentence compression tasks when utilizing semantic role labeling techniques.,1,new
Research findings indicate that leveraging contextual information can lead to remarkable advancements in named entity recognition accuracy.,1,new
"Our research team employed the stochastic gradient ascent method, yielding impressive improvements over traditional hill climbing algorithms for global optimization problems: The proposed approach outperformed existing methods by achieving higher accuracy rates in simulations.",1,new
"In our experiments, we found that utilizing ensemble learning techniques significantly enhanced the predictive power of machine learning models for regression analysis: This advancement surpassed state-of-the-art benchmarks established by previous studies.",1,new
"By integrating recurrent neural networks into the knowledge graph embedding framework, we achieved remarkable breakthroughs in natural language understanding: Compared to standalone approaches, this hybrid architecture demonstrated superior performance in downstream tasks like question answering and text classification.",1,new
"Our study demonstrates that integrating multiple features significantly enhances the performance of deep learning models across various natural language processing applications such as named entity recognition, part-of-speech tagging, and coreference resolution.",1,new
"By incorporating novel feature engineering techniques, our approach achieves superior outcomes compared to traditional methods in areas like question answering, sentiment analysis, and machine translation.",1,new
"The combination of advanced linguistic features has been found to yield remarkable improvements in text classification, information retrieval, and word sense induction tasks when employed within sophisticated neural architectures.",1,new
Recent advancements in computer vision have led to significant breakthroughs but efficient processing of high-dimensional image datasets remains a pressing challenge that warrants further investigation.,1,new
Despite substantial progress made over the past decade advances in efficiently managing massive volumes of imaging data continue to pose intriguing opportunities for innovation.,1,new
Significant strides have been taken towards harnessing machine learning algorithms however tackling the complexity associated with handling voluminous image repositories necessitates ongoing exploration.,1,new
"Researchers have been highly appreciative of the advancements made possible by the ROUGE score, a critical tool for evaluating summarization systems that enables faster and more cost-effective assessments of novel techniques and datasets.",1,new
The widespread adoption of PERLIO metrics has significantly improved human-computer dialogue system design due to its ability to efficiently assess conversation quality and facilitate rapid iteration towards optimal performance.,1,new
"Scholars praise the METEOR metric for its successful application in machine translation research, providing a straightforward means to compare various approaches and identify areas requiring further refinement.",1,new
"Our findings suggest that this ensemble approach significantly reduces model bias and improves generalizability, thereby mitigating the risk of overfitting.",1,new
A recent study demonstrated that combining predictions from individual models can effectively combat overfitting by incorporating diverse perspectives and reducing variance.,1,new
Research indicates that this aggregation technique enhances predictive performance while minimizing overfitting issues due to its ability to average out noisy estimates.,1,new
"This study's findings have been consistently supported by subsequent research, solidifying its position as a cornerstone method in the field of neurosurgery today.",1,new
"Our laboratory has witnessed remarkable success rates after adopting this procedure, underscoring its efficacy in treating complex conditions.",1,new
"Repetitive experimentation has validated the effectiveness of this novel therapeutic strategy, leading it to widespread adoption within medical communities worldwide now.",1,new
"Our findings suggest that ChREBPMlx plays a pivotal role in facilitating fatty acid synthesis during periods of excessive glucose consumption, thereby underscoring its significance in metabolic homeostasis maintenance.",1,new
This transcription factor has been found to exert a profound impact on lipid metabolism by regulating the expression of genes involved in de novo biogenesis when dietary carbohydrates exceed recommended levels.,1,new
"Recent studies have highlighted the crucial involvement of ChREBPMlx in orchestrating lipid biosynthesis pathways upon ingestion of high-carbohydrate diets, thus emphasizing its essentiality for energy storage mechanisms within mammals.",1,new
This study demonstrates that incorporating strength training significantly enhances muscle mass preservation compared to cardiovascular exercises during caloric restriction periods.,1,new
Resistance-based workouts exhibit superior efficacy over low-intensity endurance activities in preventing loss of skeletal muscle volume after weight reduction interventions.,1,new
The incorporation of resistive exercises was found to be highly effective at counteracting decreases in lean body mass when combined with calorie-restricted diets.,1,new
"Hydrogen production through microbial electrolysis exhibits promising prospects for clean and reliable energy sources, thereby mitigating our reliance on fossil fuels.",1,new
"Anaerobic digestion has been identified as a viable method for biohydrogen generation, offering numerous environmental benefits due to its low carbon footprint.",1,new
"Bioelectrochemical systems demonstrate significant potential for scalable and cost-effective hydrogen production, paving the way towards a more sustainable future.",1,new
These findings suggest that application of AMPA receptor antagonists could offer valuable insights into understanding neurodegenerative disorders such as Alzheimer's disease.,1,new
This research indicates that activation of GABA receptors may serve as effective therapeutic targets for treating anxiety-related symptoms associated with PTSD patients.,1,new
Recent studies imply that inhibition of mGluR1 receptors has significant potential as a novel approach for managing obsessive-compulsive disorder treatment options.,1,new
Our research team has found that the Berkeley Aligner tool has become increasingly utilized among practitioners due to its ability to produce accurate alignments from large-scale parallel corpora efficiently.,1,new
The fast-align algorithm plays a crucial role in statistical machine translation systems by providing precise word-to-word correspondences between source and target languages rapidly and effectively.,1,new
Statistical machine transliteration models heavily rely on sophisticated techniques such as IBM Model 4 which enables them to learn complex patterns in multilingual datasets seamlessly.,1,new
"Our Data Augmentation Techniques were evaluated utilizing an upgraded implementation of BERT, a cutting-edge neural network model.",1,new
"In this study, Multiple Sequence Alignment was performed by leveraging a well-tuned version of MUSCLE.",1,new
We employed a fine-tuned transformer architecture for assessing the performance of several NLP models.,1,new
"Our proposed method demonstrated exceptional performance in named entity recognition tasks, especially when handling long documents despite having limited training data, which further supports its robustness.",1,new
"This approach proved effective in dependency parsing, achieving comparable accuracy rates to more complex models while requiring significantly less computational resources, making it a promising solution for large-scale applications.",1,new
"Interestingly, our experiments showed that this technique excels at part-of-speech tagging even under conditions where other methods struggle due to out-of-vocabulary words, thereby expanding its potential use cases.",1,new
Utilizing cutting-edge methodologies for named entity recognition can significantly enhance the accuracy of similarity computation algorithms used in information retrieval frameworks.,1,new
Integrating advanced machine learning models into natural language processing pipelines has been shown to greatly improve the quality of extracted features from social media datasets.,1,new
Adopting recent advancements in topic modeling can facilitate more accurate clustering of biomedical literature reviews by leveraging semantic relationships between key terms.,1,new
"We assessed inter-rater reliability through Cohen's kappa statistic, a commonly employed metric in social sciences for evaluating categorization accuracy.",1,new
"In order to gauge inter-analyst consistency, we utilized Fleiss' kappa coefficient, a widely accepted measure for quantifying categorical agreement in multi-rater studies.",1,new
"To evaluate intraclass correlation between coders, we calculated the ICC model 3(1), a reliable indicator of absolute agreement in repeated measures analysis.",1,new
"Notley et al.'s seminal study introduced Multimodal Alignment Networks for efficient domain adaptation across languages, demonstrating their potential in reducing linguistic barriers.",1,new
Pioneering research by Zhang and colleagues established the foundation for Neural Machine Translation through innovative applications of attention mechanisms and encoder-decoder architectures.,1,new
"Building upon earlier works, Lee's team made significant contributions to the field with the development of Context-Aware Language Models that outperformed state-of-the-art systems in various benchmarks.",1,new
"Our experiments demonstrate that integrating features from various sources into a single model significantly improves its performance, often rivalling state-of-the-art methods for complex tasks.",1,new
This study reveals that leveraging ensemble techniques allows researchers to achieve near-optimal results when working with datasets containing disparate sub-populations.,1,new
"Furthermore, our findings suggest that combining multiple models trained on distinct subsets of data yields surprisingly robust outcomes, comparable to those obtained through more sophisticated transfer learning strategies.",1,new
This study highlights the effectiveness of Conditional Probability as a reliable measure for quantifying associations between variables.,1,new
Jensen-Shannon Divergence has emerged as a prominent metric for evaluating the similarity between probability distributions in various fields of research.,1,new
"The Kullback-Leibler divergence method has been increasingly utilized to assess the discrepancy between two probability measures, providing valuable insights into their relationship.",1,new
Ongoing advancements in this area have significantly contributed to the establishment of cutting-edge wastewater treatment technologies that enhance water quality standards nationwide.,1,new
Continuous efforts towards optimizing process controls at Wastewater Treatment Plants have led to breakthrough discoveries resulting from interdisciplinary collaborations among engineers and scientists worldwide.,1,new
"Robust methodologies developed through such research endeavors continue to pave the way for efficient management strategies, ultimately ensuring compliance with stringent environmental regulations.",1,new
"Our study investigates the efficacy of Deep Transfer Learning approaches for image classification tasks, leveraging recent breakthroughs that have demonstrated superior performance in computer vision applications.",1,new
"This paper evaluates the impact of Neural Architecture Search methods on model efficiency, showcasing improved accuracy rates observed in state-of-the-art experiments across various datasets.",1,new
"In our analysis, we assess the applicability of Graph Convolutional Networks for node classification problems, building upon successful implementations that have achieved remarkable precision gains in complex graph-based learning scenarios.",1,new
This limitation often leads researchers to employ sophisticated linguistic techniques such as part-of-speech tagging and named entity recognition algorithms that consider the grammatical context of words in order to improve their models' accuracy in these challenging environments.,1,new
"In many cases, high-performance NLP architectures rely heavily on manual tuning of hyperparameters tailored specifically to the idiosyncrasies of individual languages, which can result in improved performance but also introduce significant development time overhead.",1,new
"Consequently, efforts have been directed towards developing more generalizable and adaptable methods for handling out-of-vocabulary tokens in complex morphology-based languages by leveraging techniques from computational linguistics.",1,new
Our research has demonstrated that administration of these lipids via intraarterial infusion significantly reduced the cytotoxicity associated with certain drugs known for their lipophilic properties.,1,new
"Notably, numerous studies have highlighted the potential therapeutic benefits of intravenously delivered lipid-based formulations in mitigating the side effects of several hydrophobic medications.",1,new
"Furthermore, our laboratory findings indicate that lipid microemulsion therapy can effectively counteract the adverse consequences linked to various poorly water-soluble compounds when administered through parenteral routes.",1,new
"This study employed the ICA algorithm implemented in EEGLAB software (www.eecs.qmul.ac.uk/mvg/ica.html), which yielded remarkable success in isolating distinct frequency bands from EEG recordings.",1,new
"Utilizing the Independent Component Analysis (ICA) technique available in the FieldTrip toolbox, we were able to successfully separate overlapping neural activity into separable sources.",1,new
"Implementation of the FastICA algorithm within MATLAB resulted in efficient decomposition of brain signal patterns, thereby facilitating accurate identification of underlying neurological processes.",1,new
"For this study, we adopted the inter-rater reliability metric known as Cohen's kappa statistic, which has been widely employed across various domains including psychology and sociology.",1,new
Our choice of Fleiss' kappa for evaluating the consistency among raters reflects its widespread acceptance within the field of social sciences literature.,1,new
"In order to assess intersubjectivity, we opted for the weighted kappastatistic that is commonly utilized in educational and psychological studies due to its robustness.",1,new
Our proposed algorithm resulted in enhanced performance metrics across both processing time and part-of-speech identification precision rates compared to existing solutions.,1,new
A novel approach was implemented that significantly increased parsing efficiency while also yielding superior tokenization outcomes for morphological analysis tasks.,1,new
Implementation of this technique facilitated substantial advancements in computational complexity reduction alongside notable improvements in named entity recognition accuracy levels.,1,new
"Our research assessed the impact of transfer learning techniques on three well-established models: Random Forest, Gradient Boosting, and Support Vector Machines, utilizing five prominent machine learning benchmarks: MNIST, CIFAR-10, Fashion-MNIST, COIL-100, and KDD Cup.",1,new
"A series of experiments were conducted to investigate the effectiveness of pre-training word embeddings for six state-of-the-art natural language processing algorithms: BERT, RoBERTa, transformers, Word2Vec, GloVe, and Skip-Gram; across eight linguistic tasks: Question Answering, Named Entity Recognition, Part-of-Speech Tagging, Dependency Parsing, Coreference Resolution, Sentiment Analysis, Semantic Role Labeling, and Machine Translation.",1,new
"To evaluate the influence of hyperparameter tuning strategies on model performance, we applied Optimal Tuning Algorithm, Bayesian Optimization, Grid Search, Genetic Programming, Simulated Annealing, Particle Swarm Optimization, and Gradient-Based Methods to seven leading deep neural networks: Convolutional Neural Networks, Recurrent Neural Networks, Long Short-Term Memory Networks, Autoencoders, Generative Adversarial Networks, U-Nets, and Residual Networks.",1,new
A common technique employed by researchers generates bilingual dictionaries through parallel corpora analysis.,1,new
This method relies heavily on statistical models for efficient extraction of equivalent phrases across languages.,1,new
"By leveraging co-occurrence matrices, scholars have successfully developed reliable cross-language lexicons.",1,new
Recent advancements in deep learning architectures for parallel processing demonstrate considerable potential for efficient synchronous parsing applications.,1,new
Efficient algorithms employing dynamic programming techniques exhibit notable improvements in handling complex syntactic structures during asynchronous parsing procedures.,1,new
Empirical studies have shown that innovative approaches leveraging graph-based methods can achieve remarkable reductions in computational overhead associated with concurrent parsing operations.,1,new
"The development and enforcement of rigorous environmental regulations have significantly contributed to reducing pollution levels in urban areas through initiatives like green infrastructure projects and participatory governance mechanisms, thereby protecting human health and promoting sustainable development.",1,new
Implementation of evidence-based healthcare programs has led to substantial improvements in disease management outcomes for vulnerable populations worldwide due to targeted interventions by international organizations and local authorities.,1,new
"Enhanced research collaboration between academia and industry has fostered groundbreaking innovations in renewable energy technologies, resulting from strategic partnerships and funding schemes that have accelerated technological advancements towards mitigating climate change impacts.",1,new
"According to recent studies, various optimization techniques such as differential evolution have been demonstrated to outperform traditional methods for tuning the parameters of certain ESN models.",1,new
Our analysis suggests that incorporating ensemble learning into deep neural networks can significantly improve their predictive accuracy when applied to complex systems like climate modeling.,1,new
"Several research groups have successfully employed evolutionary algorithms to optimize hyperparameters for support vector machines, resulting in improved classification performance.",1,new
"This result highlights the potential for significant advancements in natural language processing, underscoring the effectiveness of our approach when compared to other state-of-the-art models like BERT.",1,new
"Our analysis suggests that incorporating contextual information can lead to substantial improvements in accuracy, which we believe has far-reaching implications for various NLP applications.",1,new
The superior performance of our system over traditional keyword-based methods underscores its value in enhancing search engine functionality and user experience alike.,1,new
"The development of alternative approaches like Gaussian Mixture Model-based discriminative models, Linear Chain Conditional Random Fieldss, and Structured Output Support Vector Machines has significantly improved upon traditional generative techniques.",1,new
"Recent advancements in machine learning have led to the creation of effective algorithms such as Latent Variable-Based Conditional Random Fields, Boosted Decision Trees, and Supervised Dimensionality Reduction Methods that enhance the capabilities of initial Hidden Markov Models.",1,new
"Several innovative methodologies including Stochastic Gradient Descent-trained Feature Space Maximization, Convolutional Neural Network-based sequence labeling, and Regularized Generalized Linear Mixed Models offer significant improvements over conventional probabilistic modeling frameworks.",1,new
Our study shows that this approach yields robust performance across various domains due to its ability to effectively capture intricate patterns in complex systems.,1,new
"This technique exhibits remarkable sensitivity and specificity when applied to datasets from diverse fields, resulting in outstanding predictive accuracy rates consistently.",1,new
Extensive evaluation demonstrates that our proposed model outperforms existing methods by leveraging novel features extraction techniques which significantly enhance discriminatory capacity.,1,new
Various machine learning algorithms such as Support Vector Machines  Li et al.) and decision trees   Quinlan have been successfully applied to tackle complex problems like word sense disambiguation.,1,new
Recent studies by Collins et al.) and Brown et al.) demonstrate that probabilistic contextual clustering has achieved remarkable performance improvements over traditional approaches to semantic role labeling tasks.,1,new
"Notable contributions from Zhang and Lee's research highlight the potential benefits of incorporating neural networks into dependency parsing frameworks, leading to significant advancements in grammatical analysis accuracy.",1,new
A widely accepted evaluation metric for assessing the quality of machine translation systems is ROUGE score.,1,new
PER is another effective measure used by researchers to evaluate the fluency and coherence of automatically generated texts.,1,new
METEOR has emerged as a reliable indicator of similarity between human-written and computer-produced text.,1,new
Our analysis suggests that employing hierarchical organization through syntax can significantly improve the efficiency of machine learning algorithms such as recurrent neural networks.,1,new
"Furthermore, research indicates that enforcing specific structural constraints during model development leads to substantial enhancements in predictability within probabilistic parsing models.",1,new
Experimental evidence supports the notion that incorporating syntactic frameworks into artificial intelligence systems enables notable improvements in natural language processing tasks like semantic role labeling.,1,new
"This initiative received significant financial backing from international donors totaling $32 million, paving the way for its widespread implementation across several countries in Asia by 2010.",1,new
"Following successful local trials conducted during the period 1998-2002, this project expanded globally in 2009 with substantial investments exceeding $75 million.",1,new
"With initial seed money provided through grants from European organizations amounting to £40 million, it became operational worldwide within five years, commencing full-scale deployment in all major continents by 2012.",1,new
"Second-generation antidepressants exhibit superior therapeutic outcomes compared to traditional medications due to their ability to target specific neurotransmitter systems, resulting in improved patient compliance and reduced relapse rates for those suffering from depression.",1,new
Recent studies suggest that novel psychotherapeutic approaches integrating cognitive-behavioral techniques yield enhanced efficacy when used concurrently with pharmacological interventions in treating complex mental health disorders such as borderline personality disorder.,1,new
"In contrast to conventional pain management strategies, evidence-based non-pharmacological methods including acupuncture and meditation show significant promise in alleviating chronic pain by modulating neural pathways associated with perception and emotional processing.",1,new
This amino acid composition has proven particularly effective for crystallization purposes especially considering its comparison against various synthetic constructs like PEGylated proteins.,1,new
Compared to previously studied enzymes such as those from Bacillus subtilis our novel protease exhibits enhanced activity making it suitable for industrial applications.,1,new
Our results demonstrate that the isolated enzyme shows superior thermal stability than analogous peptides found within Streptomyces clavuligerus thereby warranting further investigation into its potential uses in biocatalysis.,1,new
"Our findings suggest that by incorporating hierarchical structures into machine learning algorithms, researchers can better capture complex relationships between various features.",1,new
"In many domains where data exhibits inherent hierarchies, employing probabilistic modeling techniques yields superior performance compared to traditional methods.",1,new
Utilizing factorization-based approaches has been shown to improve predictive accuracy when dealing with datasets comprising nested patterns and dependencies.,1,new
"Histopathological analysis exhibits enhanced precision when utilizing digital image processing techniques, demonstrating improved detection rates up to 25%.",1,new
Comparative studies have demonstrated that MRI scans significantly enhance diagnosis reliability compared to conventional radiography methods.,1,new
"Fluorescence microscopy proves to be a highly effective tool for identifying microorganisms, boasting sensitivity improvements ranging from 10% to 28%.",1,new
"This innovative approach was first proposed by Cochran et al.'s seminal study [10], which laid the groundwork for future research in this field.",1,new
The use of mixed-effects models has been extensively explored by Laird and Ware's influential paper [23] to address complex interactions between variables.,1,new
"Researchers have employed the concept of propensity score matching, initially developed by Rosenbaum and Rubin [34], to effectively control confounding factors in observational studies.",1,new
"This dataset has been widely employed for training named entity recognition models due to its extensive coverage of various linguistic phenomena, such as verb subcategorization frames and semantic role labeling.",1,new
The Brown Corpus's large size and rich annotation make it particularly suitable for evaluating machine learning algorithms' ability to capture complex syntactic structures.,1,new
"Parton-Brown Corpora have been extensively utilized in studies assessing the performance of deep neural networks on parsing tasks, thanks to their comprehensive grammatical annotation.",1,new
"Recent advancements have been made by researchers, culminating in the development of cutting-edge non-lexicalized probabilistic context-free grammar parsers that significantly outperform previous models.",1,new
"A groundbreaking study introduced highly efficient unsupervised PCFG parsing techniques, which showcase impressive improvements over existing methodologies for sentence analysis tasks.",1,new
"In a recent breakthrough, innovative research has led to the creation of state-of-the-art fully supervised context-free grammar parsers capable of achieving unprecedented accuracy rates in syntactic parsing applications.",1,new
"This approach enables researchers to extract high-level features from images by aggregating lower-dimensional information, resulting in improved classification performance across various benchmark datasets.",1,new
"By utilizing these kernel functions, we can effectively combine low-level image cues into more abstract representations that significantly enhance object detection rates in challenging scenarios.",1,new
Our proposed method for combining spatial pyramid matching kernels yields superior outcomes when applied to complex scene understanding tasks due to its ability to capture nuanced variations within local regions of interest.,1,new
"Our research leverages the fundamental principles employed by top-performing part-of-speech tagging algorithms, such as  .",1,new
"This study builds upon existing n-gram-based approaches, drawing inspiration from established models like     and   .",1,new
"By adopting a similar architecture to widely used named entity recognition systems, we unlock the potential for improved accuracy in our proposed framework.",1,new
"Our findings demonstrate that this compound exhibits superior potency compared to its analogs, displaying a noteworthy increase of nearly 12% in efficacy against Plasmodium parasites.",1,new
"Notably, our research indicates that this novel agent surpasses existing treatments by achieving significant reductions of over 25% in parasite loads when tested alongside commonly used antimalarial drugs.",1,new
"In contrast to previous compounds studied for their antiplasmodial properties, our newly synthesized molecule displays remarkable activity levels exceeding those seen previously, reaching impressive fold-increases of approximately 15%.",1,new
"Our analysis revealed that β-glucosidase, the third most consistently upregulated enzyme in our experiment, exhibited robust activity across various plant species including Arabidopsis thaliana, tomato, and cotton.",1,new
"Noteworthy among the genes we investigated was the stable expression of actin-related protein 2/3 complex subunit 1b, which was observed in numerous developmental stages of Drosophila melanogaster, zebrafish, and human embryonic stem cells.",1,new
"One of the key findings from our research was the high level of conservation of microRNA-184, which displayed consistent regulation throughout embryogenesis in Xenopus laevis, Caenorhabditis elegans, and mouse models.",1,new
Researchers have demonstrated that machine learning algorithms can effectively resolve lexical ambiguity through robust feature engineering techniques.,1,new
Supervised learning methods have proven invaluable for identifying polysemous words by leveraging large datasets and sophisticated modeling frameworks.,1,new
Recent studies suggest that incorporating semantic role labeling into supervised learning paradigms significantly improves sense distinction accuracy rates among linguists.,1,new
Recent advances in computational power have led to the development of efficient interfaces for popular machine learning frameworks like TensorFlow and PyTorch that greatly enhance user experience.,1,new
"Most modern programming languages including Java, C++, and MATLAB offer seamless integration with established numerical libraries which has significantly streamlined simulations across various disciplines.",1,new
Many cutting-edge research institutions invest heavily in creating high-quality software APIs that facilitate easy collaboration among researchers from diverse backgrounds by providing access to robust toolkits such as NumPy and SciPy.,1,new
"Our research highlights the effectiveness of employing the Mutual Information statistic over Fisher Exact Test for identifying salient trigrams in large datasets, showcasing improved accuracy rates in pattern recognition tasks.",1,new
"This study underscores the superiority of the chi-squared test extension by Goodman and Kruskal's gamma coefficient when analyzing categorical relationships between variables in complex systems, leading to more reliable outcomes.",1,new
"In this paper, we examine how incorporating the AICc metric into statistical modeling enhances predictive power significantly, outperforming traditional BIC methods in various simulation studies across distinct domains.",1,new
"A novel method for optimizing hyperparameters has been proposed by Smith et al., which significantly reduces computational complexity.",1,new
Our study demonstrates that the implementation described in Jones' seminal paper provides substantial improvements over existing approaches.,1,new
"According to Li's research findings, utilizing an iterative approach facilitates more accurate parameter estimation.",1,new
"This approach has been found effective in providing reliable metrics for assessing machine translation quality, closely aligning with expert opinions.",1,new
"Our research demonstrates that these methodologies yield consistent ratings comparable to those provided by trained evaluators, indicating their validity.",1,new
"Evaluations conducted utilizing this method have consistently produced outcomes mirroring human assessments, validating its utility in automated grading systems.",1,new
Recent advancements in machine learning have led to widespread adoption of the Gaussian Process regression model across various fields.,1,new
The application of Support Vector Machines in classification problems has yielded impressive accuracy rates in numerous studies.,1,new
Implementation of Random Forest algorithms has shown significant improvements in predictive modeling capabilities.,1,new
"Our findings were validated through evaluation metrics such as precision recall F1 score indicating high accuracy in identifying relevant patterns across various datasets, thereby strengthening our research outcomes significantly.",1,new
This study utilized established benchmarks like mean average precision MAP for assessing model effectiveness demonstrating consistent improvement over previous methodologies employed by other researchers within this field.,1,new
To evaluate our proposed framework we adopted common assessment criteria including Receiver Operating Characteristic ROC analysis that provided insight into its discriminative capabilities and capacity to distinguish actual instances from random fluctuations.,1,new
The proposed model achieved significant improvements over traditional ROUGE metrics due to its emphasis on semantic meaning and contextual understanding.,1,new
Recent studies have shown that METEOR outperforms other metrics such as TER and CIDEr in capturing nuances of machine translation tasks effectively.,1,new
This study highlights the efficacy of Meteor score in accurately assessing the fluency and coherence of translated texts compared to older metrics like BLEU.,1,new
Recent studies have demonstrated that traditional supervised techniques such as decision trees exhibit remarkable performance in text classification tasks showing great potential for future applications.,1,new
Various machine learning approaches like Random Forests have been employed extensively in opinion mining achieving impressive accuracy levels and yielding valuable insights into user behavior.,1,new
Research has consistently shown that Naive Bayes algorithms are well-suited for handling imbalanced datasets resulting in improved prediction rates and contributing significantly to the field of natural language processing.,1,new
"Recent advances in machine learning algorithms have led to significant improvements in natural language processing techniques, making it easier for researchers to develop accurate parsing systems.",1,new
This shift towards more accessible tools has greatly facilitated the integration of automatic parsing capabilities into various applications across disciplines.,1,new
"As a result of ongoing research efforts, numerous advanced parsing models have been implemented successfully within existing software frameworks.",1,new
Our study corroborated these findings when we implemented a novel vaccine delivery system and observed improved immune responses among test subjects.,1,new
"Comparable outcomes have been reported by Lee et al., who investigated the efficacy of combined adjuvants in vaccine formulations and found significant enhancements in antigen-specific antibody production.",1,new
"These observations align with previous research conducted by Wang's group, where they demonstrated that optimized vaccine schedules led to heightened protective immunity against infectious diseases.",1,new
Recent advancements in deep learning architectures have demonstrated their effectiveness in various computer vision applications including object detection and image classification.,1,new
Graph neural networks have been successfully employed in information retrieval systems to improve ranking algorithms for more accurate search results.,1,new
The application of node embeddings has shown promising results in natural language processing tasks such as named entity recognition and question answering models.,1,new
This framework enables researchers to reconcile seemingly contradictory findings by providing a more nuanced understanding of complex phenomena.,1,new
Our novel approach allows for the incorporation of paradoxes and ambiguities that were previously difficult to resolve within existing models.,1,new
"By adopting this perspective, scholars can develop a more inclusive theory that acknowledges the interplay between opposing forces rather than trying to suppress them.",1,new
"Notably, our findings suggest that HES3 plays a crucial role in regulating the cell cycle progression through its interaction with cyclin-dependent kinases, a mechanism essential for normal tissue development.",1,new
"Significantly, we observed that miR-218 targets the oncogene CCND1, thereby inhibiting cell proliferation and promoting apoptosis, underscoring its potential therapeutic value in cancer treatment strategies.",1,new
"Remarkably, our research indicates that SOX9 acts as a key transcription factor in the regulation of cartilage formation, highlighting its importance in the pathogenesis of osteoarthritis and suggesting novel avenues for intervention.",1,new
"Our research incorporated a state-of-the-art neural network architecture for natural speech synthesis, leveraging an extensive database-driven acoustic model.",1,new
"This study employed an advanced statistical framework for modeling the phonetic properties of human speech, resulting in highly authentic vocalizations.",1,new
"We utilized a sophisticated concatenative approach to mimic the articulatory patterns found in native speakers' voices, yielding remarkably convincing synthesized dialogue.",1,new
Recent studies have shown that state-of-the-art parsing algorithms trained on large corpora like the Penn Treebank heavily rely on syntactic dependencies for resolving ambiguity.,1,new
"In contrast, more effective methods such as those developed by Zellig Harris utilize probabilistic frameworks to incorporate contextual relationships between words into their decision-making process.",1,new
Research has demonstrated that incorporating morphological features from linguistic resources like WordNet enhances parser performance when dealing with complex sentence structures like subcategorization frames.,1,new
"This innovative technique provides valuable insights into optical coherence tomography imaging, significantly contributing to enhanced patient care in ophthalmology.",1,new
"Spectral-domain OCT's high-resolution images have revolutionized diagnostic capabilities, ultimately leading to more precise treatment plans for various eye conditions.",1,new
"Recent studies demonstrate that spectral-domain OCT offers unparalleled accuracy in visualizing retinal structures, thereby improving therapeutic decision-making processes among medical professionals.",1,new
"Our findings suggest that employing advanced imaging techniques significantly improved diagnostic accuracy for detecting microfractures within osteoporotic bones. The study's lead researcher noted that utilizing high-resolution scans allowed for precise identification of even the smallest cracks, thereby enhancing patient treatment outcomes substantially.",1,new
"By implementing novel algorithms for image analysis, we observed a marked decrease in misdiagnoses related to inflammatory responses caused by implant rejection reactions. According to the primary investigator, this breakthrough enabled clinicians to intervene promptly, thus preventing potential long-term complications.",1,new
"A comprehensive review of existing literature revealed that adopting multi-spectral scanning protocols led to notable improvements in identifying calcified plaques associated with cardiovascular disease. As reported by the senior author, these advancements facilitated early detection and intervention strategies, ultimately resulting in enhanced patient care and reduced morbidity rates.",1,new
"Recent enhancements to the Hockenmaier dependency parser demonstrate improved performance when employing beam search with dynamic pruning, leading to enhanced accuracy on various benchmark datasets including Penn Treebank Wall Street Journal portion.",1,new
Oehrle et al.'s recent modifications to the Stanford Parser yield significant gains in parsing efficiency by leveraging incremental processing techniques that adapt seamlessly to complex linguistic structures found in the Switchboard corpus.,1,new
"Implementing context-aware reranking strategies within the Collins Head-Driven Phrase Structure Grammar has resulted in substantial improvements over previous versions, particularly noticeable in its ability to accurately parse sentence lengths greater than twenty words seen in the BNC Corpus.",1,new
"Our analysis indicates that incorporating machine learning algorithms significantly enhances predictive accuracy, substantiating previous findings from numerous studies.",1,new
"This study demonstrates the efficacy of adopting probabilistic models, which aligns well with existing literature on statistical inference methods.",1,new
"Experimental outcomes clearly demonstrate the benefits of implementing geometric optimization techniques, reinforcing prior research on computational efficiency improvement strategies.",1,new
"Our experiments utilize the state-of-the-art neural network architecture proposed by Vaswani et al. [2017], demonstrating its superior efficiency in processing large datasets.",1,new
"This approach leverages the strengths of deep learning models in natural language processing tasks, providing accurate and reliable outcomes as shown in recent studies conducted by Collobert et al. [2020].",1,new
We rely heavily on the theoretical framework established by Chomsky [1957] when exploring linguistic phenomena such as phrase structure grammar and its impact on sentence generation capabilities.,1,new
Recent studies employing corpus-driven methods for constructing vector representations of words demonstrate significant advancements in various NLP applications such as named entity recognition and machine translation outcomes.,1,new
This study highlights the effectiveness of utilizing word embeddings derived from large-scale corpora in facilitating improvements across numerous linguistic processing tasks including sentiment analysis and information retrieval systems performance.,1,new
"Research leveraging large-scale distributed neural networks has led to notable breakthroughs in representing complex concepts within lexical semantics, thereby enhancing overall model efficiency and accuracy in areas like question answering and dialogue management.",1,new
High-resolution imaging was achieved through the use of a custom-built spectral domain optical coherence tomography system inspired by the innovative techniques developed by Huang et al.,1,new
Autofocusing microscopy images were captured utilizing a high-speed camera system designed according to the principles outlined in the seminal study conducted by Chen et al.,1,new
Depth-resolved reflectance spectra were collected from tissue specimens employing a novel phase-shifting interferometry setup constructed in accordance with the research methods described by Lee et al.,1,new
"Our decision to employ Random Forest algorithm was informed by its widespread adoption among top-ranked teams participating in the ICDAR document image classification competition, which consistently demonstrated superior performance over other machine learning techniques.",1,new
"Logistic regression analysis revealed that employing Support Vector Machines resulted in significant improvements in model accuracy due to their ability to effectively handle non-linear relationships between variables, evident from previous studies in bioinformatics research.",1,new
"According to prior studies examining natural language processing tasks such as part-of-speech tagging, we selected Hidden Markov Model for our parser implementation owing to its proven track record of high precision rates under comparable evaluation metrics across various corpora.",1,new
Recent studies suggest that innovative machine learning techniques can significantly enhance the accuracy of sentiment analysis tasks by incorporating contextual information from large datasets.,1,new
"The integration of multimodal processing methods has led to notable improvements in object detection systems, allowing for more robust feature extraction and better overall performance.",1,new
Various recent contributions have demonstrated the effectiveness of ensemble learning approaches in improving predictive modeling outcomes across numerous application domains.,1,new
"Our novel machine learning technique offers a straightforward solution for complex pattern recognition tasks, showcasing its potential for widespread adoption.",1,new
"This innovative framework presents a versatile method for tackling intricate problems, making it an attractive option for researchers.",1,new
The proposed algorithm provides a clear and efficient means to achieve high-performance results in computationally intensive applications.,1,new
"Our proposed algorithm shares similarities with the well-established pruning approach, initially prioritizing accuracy while iteratively expanding its scope of application.",1,new
"The iterative refinement process employed by our model mirrors that of the widely used ensemble learning method, seeking balance between specificity and inclusivity from the outset.",1,new
"Similar to the conventional early stopping strategy, our adaptive framework commences with stringent criteria before incrementally broadening its applicability over successive iterations.",1,new
"Our approach yields comparable outcomes to those achieved through more complex algorithms like Li's optimization technique, which involves intricate mathematical formulations.",1,new
"In comparison, we find that our proposed framework outperforms several existing methods, including Zhang et al.'s state-of-the-art learning model.",1,new
"Compared to other heuristic strategies such as Sussman's iterative refinement process, our solution produces remarkably accurate predictions while requiring significantly less computational resources.",1,new
"Notable contributions to this field also stem from statistical models such as conditional random fields, support vector machines, and perceptron algorithms.",1,new
"Prominent approaches that have garnered significant attention include decision trees, hidden Markov model discriminators, and recurrent neural network architectures.",1,new
"Several influential techniques have emerged in recent years, including graph-based methods like label propagation, convex relaxations, and kernel-based systems.",1,new
Our analysis demonstrates that leveraging graph-based methods for extracting relationships between entities significantly improves knowledge representation compared to traditional word-embedding approaches.,1,new
"By incorporating multimodal information such as images and audio into deep learning models, researchers have made substantial progress in object recognition tasks, outperforming earlier methods reliant solely on visual features.",1,new
"According to recent studies, utilizing transfer learning techniques enables smaller neural networks to achieve comparable accuracy to larger models on various natural language processing benchmarks, indicating significant advancements in computational efficiency.",1,new
"Our model yields outstanding performance by employing a cutting-edge similarity-based approach, demonstrating remarkable classification efficiency from just 150 key concepts.",1,new
"This study showcases notable advancements through the effective utilization of semantic embeddings, leading to exceptional retrieval precision even when initiating with merely 100 crucial phrases.",1,new
"By leveraging advanced vector space representations, we obtain highly accurate categorization outcomes at a remarkably low threshold of 120 representative terms.",1,new
This study utilized a combination of phylogenetic analysis and network theory to elucidate the complex relationships within microbial communities‚Ä¶,1,new
Our research integrated machine learning algorithms and statistical modeling techniques to identify key factors influencing plant diversity in tropical ecosystems‚Ä¶,1,new
By incorporating geospatial analysis and remote sensing data we were able to accurately predict forest fire risk areas‚Ä¶,1,new
"To evaluate the performance of our novel machine learning algorithm, we rely on the widely accepted cross-validation technique that maximally minimizes the mean squared error during the testing phase.",1,new
"In order to determine the optimal hyperparameters for the deep neural network architecture, we employ the grid search strategy that systematically explores the predefined range of values while maximizing the correlation coefficient between predicted and actual outcomes.",1,new
"For assessing the reliability of our computational simulations, we utilize the bootstrapping method that effectively estimates the standard deviation of the resulting ensemble predictions via statistical resampling techniques.",1,new
"Our study employed a cutting-edge approach to anomaly detection utilizing dimensionality reduction techniques, specifically leveraging the established Independent Component Analysis method formulated by Hyvärinen et al. [12] that has shown remarkable efficacy across numerous image processing applications [11], [13].",1,new
"Adopting a machine learning paradigm, our research team chose to utilize Random Forest regression models due to their proven success in predicting continuous outcomes as demonstrated by Breiman's seminal paper [8]; this decision was further reinforced by subsequent studies from Dietterich [9] and Atkinson & Lloyd Jones [10].",1,new
"To analyze complex network structures, we opted for community discovery algorithms like Latent Space Models developed by Karrer & Newman [14]. This choice was motivated by the existing literature showcasing its effectiveness in social media graph analysis [15], [16].",1,new
"Our study views phrasal verbs as compositional expressions: a combination of individual words whose meaning cannot be deduced solely from their lexical entries, indicating that these combinations possess inherent semantic transparency issues.",1,new
"This research defines syntagmatic patterns as sets of adjacent items with unpredictable meanings stemming directly from the arrangement of constituent parts rather than their intrinsic properties, necessitating novel computational approaches for extraction.",1,new
"By examining idiomatic phrases through the lens of combinatorial semantics, we uncover instances where word order influences the interpretation beyond mere aggregation, underscoring the value of contextualized analysis techniques in unearthing nuanced linguistic phenomena.",1,new
"Building upon previous research by Hovy and Lin, tools such as SUMMA incorporated more advanced methods for semantic role labeling and named entity recognition into their frameworks to improve overall performance.",1,new
"Recent advancements in information extraction can also be attributed to systems like UMass, which utilized novel approaches to handle noisy and ambiguous natural language inputs through feature-based models combined with machine learning algorithms.",1,new
"Inspired by earlier works from Knight and Graehl, subsequent studies developed sophisticated architectures that integrated dependency parsing and context-aware processing to enhance information retrieval outcomes significantly.",1,new
"Recent advancements in natural language processing have led to the creation of various automated methods for evaluating speech recognition systems, aiming to minimize manual testing time during product refinement.",1,new
"The rapid growth of computer vision research has prompted the establishment of numerous objective metrics for image segmentation quality assessment, facilitating more efficient algorithm optimization processes.",1,new
"In recent times, the emergence of deep learning techniques has enabled the development of objective criteria for assessing the performance of natural language generation models, allowing researchers to streamline their model improvement efforts.",1,new
The development of large-scale annotated datasets like the Open Multimodal Corpus greatly enhances the accuracy of computer vision models in image classification tasks.,1,new
Annotated resources including the PropBank corpus play a significant role in advancing natural language processing techniques for semantic role labeling.,1,new
High-quality linguistic annotations contained within corpora such as the Switchboard Transcripts significantly improve speech recognition algorithms' overall efficiency.,1,new
Notable contributions have recently come from the research conducted by Brown et al.,1,new
Recent studies led by Johnson demonstrate impressive advancements in this field.,1,new
Pioneering efforts made by Thompson and his team showcase significant progress towards achieving these goals.,1,new
"This approach has proven to significantly improve annotation accuracy when applied to text categorization tasks, making it a valuable addition to existing methodologies proposed by Leacock et al..",1,new
"By redefining the token-based paradigm, our method demonstrates enhanced performance compared to traditional techniques outlined in the study conducted by Manning & Schütze, resulting in more efficient processing times for large datasets.",1,new
"According to recent experiments presented in Kim's research, integrating this novel framework into machine learning algorithms leads to substantial gains in predictive power, enabling researchers to draw more accurate conclusions from complex linguistic patterns.",1,new
"This study leverages recent advancements in deep learning techniques for more accurate predictions, incorporating transfer learning methodologies and ensemble methods to enhance overall performance.",1,new
Our approach integrates cutting-edge natural language processing tools such as named entity recognition and part-of-speech tagging to improve model robustness against linguistic variability.,1,new
"By adopting these innovative strategies derived from leading research in artificial intelligence, we significantly boost our system's ability to classify complex phenomena efficiently and effectively.",1,new
"This study demonstrates the efficacy of Smirnov's two-sample Kolmogorov-Smirnov test in detecting subtle patterns within large datasets, outperforming its competitors under various conditions.",1,new
A notable advantage of the Hellinger distance metric lies in its ability to accurately estimate similarities between complex biological sequences despite their substantial length differences.,1,new
Finkelstein's dissimilarity measure has been shown to excel in distinguishing among categorical variables while minimizing errors associated with traditional metrics used for this purpose.,1,new
"Our study achieved outstanding performance in named entity recognition through the strategic incorporation of pre-trained word embeddings into traditional Conditional Random Fields models, yielding remarkably accurate results.",1,new
"Notably, our proposed approach to natural language processing tasks demonstrated superior outcomes when integrating recurrent neural networks with rule-based techniques, significantly improving overall model efficiency.",1,new
"This research showcased impressive gains in speech recognition accuracy via the effective application of deep learning architectures and sophisticated feature extraction methods, ultimately leading to highly reliable predictions.",1,new
This novel approach leverages distributed representation learning techniques to yield highly accurate annotations.,1,new
"By employing graph-based convolutional networks, researchers have developed robust annotation schemes that surpass traditional methods by far.",1,new
"A recent study utilizing contextual embeddings has demonstrated significant improvements over conventional lexicalization strategies, showcasing its immense potential for complex tasks.",1,new
"Our proposed model utilizes the popular 100-image dataset developed by Johnson et al., allowing us to benchmark its performance relative to current computer vision techniques.",1,new
"We evaluated our approach utilizing the extensively researched 200-sample corpus compiled by Smith et al., thereby enabling accurate comparisons between our algorithm's effectiveness and competing methods.",1,new
"For validation purposes, we rely on the comprehensive 300-word abstracts collection provided by Williams et al., facilitating thorough assessments of how well our framework aligns with established standards in natural language processing research.",1,new
"Recent advances in machine learning algorithms for natural language processing have led to several innovative methods for efficient sentence segmentation, particularly those rooted in statistical modeling techniques such as stochastic finite state machines.",1,new
"A significant body of research has focused on developing rule-based systems inspired by linguistic theories like categorial grammar, resulting in improved accuracy rates for complex syntax analysis tasks.",1,new
"Several prominent studies have demonstrated the effectiveness of employing neural networks with distributed representations in capturing long-range dependencies between words, thereby facilitating enhanced semantic role labeling capabilities.",1,new
"Recent studies have demonstrated that maximum entropy models exhibit remarkable performance in various NLP benchmarks including dependency parsing, achieving state-of-the-art accuracy rates.",1,new
"This research has led to significant advancements in machine learning algorithms for morphological analysis, demonstrating their capacity to accurately predict grammatical features from raw linguistic inputs.",1,new
"High-performance maximum entropy taggers have also been successfully applied to sentiment analysis tasks, providing valuable insights into the emotional nuances underlying natural language expressions.",1,new
"Most machine translation algorithms, including Google's Phrase-Based model and Moses, rely heavily on static word-level alignments that fail to capture contextual nuances.",1,new
Recent studies have shown that phrase-based approaches like Microsoft's Alignment Toolkit outperform earlier methods by leveraging more sophisticated linguistic representations.,1,new
"Various state-of-the-art MT systems, for instance, RNN Search and SMT-based models, often overlook potential relationships between sentence structures due to their restrictive alignment assumptions.",1,new
Recent studies conducted by Lee et al. demonstrate significant advancements in MRI technology that complement the research presented by Dyrby's team.,1,new
The innovative approach proposed by Chen et al. has been found to yield promising outcomes consistent with previous preclinical trials on cerebral cortex anatomy.,1,new
Our latest experiments by Patel et al. confirm the utility of high-resolution imaging techniques in validating predictions made by early diffusion tensor imaging models developed by Dyrby and colleagues.,1,new
"Our team has successfully employed the innovative Stanford parser, which leverages probabilistic models to significantly improve dependency parsing accuracy for various linguistic frameworks.",1,new
The Edinburgh parser demonstrates impressive performance gains by utilizing neural networks to enhance semantic role labeling and phrase structure analysis in NLP tasks.,1,new
"By incorporating graph-based algorithms, the Charniak parser achieves remarkable efficiency and robustness in identifying sentence constituents and their relationships within complex syntax trees.",1,new
Recent advancements in deep learning architectures have demonstrated impressive improvements when incorporated into syntax analysis frameworks.,1,new
"Notably, the integration of neural networks has significantly enhanced the performance of part-of-speech tagging systems.",1,new
Various studies have shown that incorporating probabilistic methods can greatly augment the accuracy of named entity recognition tasks.,1,new
"Our research utilizes machine learning algorithms developed by Google Brain's open-source framework TensorFlow, where optimizing hyperparameters relies heavily on theoretical probabilities calculated through cross-validation techniques.",1,new
"According to recent studies published in Nature Communications, recalculating neural network weights in computer vision applications requires consideration of statistical correlations between feature extraction methods and image classification accuracy metrics.",1,new
"As documented in a prominent paper on deep learning methodologies, revising the architecture of convolutional neural networks often necessitates reassessing the impact of regularization strategies on prediction outcomes during training processes.",1,new
"Our analysis demonstrates that the proposed framework for data integration leverages the strengths of existing algorithms, resulting in a robust and scalable solution that significantly enhances system performance.",1,new
"This software tool showcases innovative features such as adaptive filtering techniques and high-performance computing capabilities, making it an ideal choice for complex computational tasks in various fields.",1,new
"The newly developed simulation model presents notable improvements over previous models by incorporating advanced numerical methods and optimizing computation time, thereby enabling researchers to achieve faster insights into complex systems.",1,new
"Our analysis reveals that the support vector machine approach exhibits impressive accuracy rates comparable to those obtained by decision trees, thus making it an attractive choice for our study.",1,new
"This research leverages the efficacy of Naive Bayes classification due to its ability to handle high-dimensional feature spaces efficiently, allowing us to make informed decisions about model selection.",1,new
"Given its computational efficiency and robustness, we adopt the k-nearest neighbors technique as the primary methodological framework for this investigation into pattern recognition algorithms.",1,new
"Our study demonstrates that the left ventricular ejection fraction, measured through phase-contrast MRI sequences, exhibits high correlation coefficients when compared to invasive catheterization techniques in determining cardiac function.",1,new
"The use of echocardiographic strain imaging allowed for accurate assessment of diastolic dysfunction indices, yielding comparable outcomes to those obtained via cardiac magnetic resonance imaging studies.",1,new
Comparative analysis between arterial stiffness measurements derived from pulse wave velocity assessments and central hemodynamic parameters revealed significant agreement between both methods for evaluating cardiovascular risk factors.,1,new
"Advances in deep learning algorithms have led to remarkable improvements in named entity recognition, boasting success rates exceeding 95% across various domains.",1,new
"Recent breakthroughs in natural language processing techniques have enabled significant gains in machine translation quality, outperforming traditional methods by substantial margins.",1,new
"Current research has achieved notable advancements in topic modeling, achieving precision levels surpassing 98% in identifying relevant topics from large datasets.",1,new
Our study demonstrates that employing hierarchical processing yields superior outcomes when applied to complex parsing tasks.,1,new
"Cascading algorithms proved highly effective in resolving syntactic ambiguity, achieving higher accuracy rates than traditional methods.",1,new
"Utilizing layered analysis led to significant improvements in sentence decomposition, enabling more accurate semantic interpretation.",1,new
This compound exhibits remarkable efficacy in reducing seizure activity across various models while also demonstrating potent analgesic properties at the same dosage level.,1,new
"Notably, administration of this substance within the specified concentration range yields substantial neuroprotective effects alongside its impressive anticonvulsant profile.",1,new
"Furthermore, our findings indicate that the tested agent displays pronounced opioid-sparing abilities, coupled with robust antihyperalgesia outcomes under identical dosing conditions.",1,new
"The most effective models for various NLP applications have been developed through extensive research utilizing large datasets like the Brown Corpus  and the PropBank dataset, which has proven instrumental in advancing our understanding of linguistic structures.",1,new
"Recent studies indicate that state-of-the-art approaches to machine learning rely heavily on well-annotated resources including the Switchboard corpus  and the VerbNet dataset, demonstrating significant improvements in accuracy across numerous NLP benchmarks.",1,new
"For several years now, deep neural networks have shown remarkable performance gains when trained on richly annotated materials such as the OntoNotes project  and the FrameNet database.",1,new
"Recent advancements in deep neural networks have been instrumental in improving the performance of natural language processing tasks due to their ability to learn complex patterns from large datasets, coupled with the growing computational power available for training these models.",1,new
"The development of more sophisticated algorithms has greatly facilitated our understanding of linguistic phenomena, particularly in relation to syntax and semantics, thanks to breakthroughs in areas like dependency parsing and semantic role labeling.",1,new
"The proliferation of high-performance computing infrastructure has enabled researchers to explore novel approaches to NLP, including the application of distributed computing frameworks and the utilization of cloud-based services, leading to significant gains in model scalability and efficiency.",1,new
"Our analysis suggests that for optimizing the performance of the RNN-based approach, utilizing the stochastic gradient descent algorithm can lead to superior outcomes.",1,new
"In order to accurately determine the efficacy of the proposed machine learning framework, it was essential to employ the validated Expectation-Maximization clustering technique.",1,new
"By leveraging the well-established cross-validation procedure, our research team was able to fine-tune the hyperparameters of the Support Vector Machine classifier effectively.",1,new
We selected the Kneser-Ney smoothing algorithm for our analysis because it has been shown to improve the accuracy of word embeddings in previous studies.9,1,new
"In this study, we employed the Levenshtein distance metric due to its proven effectiveness in measuring edit distances between strings.11",1,new
"Given its robustness to noise and outliers, we opted for the DBSCAN clustering method when partitioning high-dimensional feature spaces within our dataset.13",1,new
This discovery could revolutionize stem cell research by providing cost-effective alternatives to traditional growth factor supplements.,1,new
"New synthetic peptides have emerged that can potentially replicate the effects of costly cytokines, making them ideal candidates for large-scale ESC culture optimization.",1,new
"Synthetic analogues of these biomolecules show great promise for streamlining high-throughput cellular differentiation processes, reducing reliance on pricey biological reagents.",1,new
Our analysis indicates that incorporating large-scale datasets from reputable news sources like CNN transcripts significantly enhances the accuracy of our NLP model on comparable texts such as New York Times articles.,1,new
Research demonstrates that augmenting our system with substantial amounts of annotated Wikipedia entries leads to notable improvements in its ability to comprehend complex linguistic structures found in publications like Scientific American pieces.,1,new
Studies have proven that enriching our corpus with extensive collections of human-annotated medical literature greatly boosts the efficacy of our clinical decision support tool when applied to relevant cases documented in the Journal of Medicine reports.,1,new
Recent studies suggest that elevated levels of phosphorylated p53 protein may serve as a valuable marker for predicting tumor aggressiveness in various types of cancer.,1,new
Emerging evidence indicates that high-grade glioma patients who exhibit increased microRNA-21 expression tend to experience improved treatment outcomes when administered targeted therapies.,1,new
"Notably, research has shown that the suppression of PIK3CA mutations leads to significant reductions in breast cancer cell proliferation rates across multiple clinical trials.",1,new
"In order to assess the efficacy of our novel algorithm, five prominent metrics from existing frameworks were rigorously evaluated for comparison purposes.",1,new
A comprehensive evaluation protocol was devised to examine the effectiveness of our machine learning approach against six benchmark models.,1,new
Seven widely used quality assessment tools were utilized to thoroughly investigate the superiority of our proposed image processing technique over other competing methodologies.,1,new
Ongoing research has demonstrated that ensemble learning strategies leveraging neural network architectures achieve superior outcomes in machine translation tasks compared to traditional models.,1,new
The integration of meta-learning techniques into deep learning frameworks has led to remarkable advancements in sequential decision-making processes across various applications.,1,new
"Over the past decade, significant breakthroughs in cognitive architecture design have enabled researchers to attain unprecedented levels of accuracy in complex problem-solving endeavors.",1,new
This approach yields several valuable insights into the underlying mechanisms driving the phenomenon under investigation.,1,new
The brute force method employed by researchers has led to significant breakthroughs in our understanding of complex systems dynamics.,1,new
A direct calculation approach can indeed yield practical outcomes that shed light on various theoretical models.,1,new
The proposed method has shown remarkable success in resolving syntactic ambiguity by utilizing interdependent contextual cues effectively.,1,new
Recent studies demonstrate significant improvements in named entity recognition tasks when incorporating semantically related linguistic patterns into machine learning models.,1,new
These advanced algorithms have achieved outstanding performance in parsing complex sentence structures while accounting for semantic dependencies between words.,1,new
"Notably, distinct variations were observed between the two alleles in Figure 1a; REP represents the reference sequence of the polymorphism, whereas VAR denotes the variant allele utilized extensively in clinical studies.",1,new
A striking difference exists between exon 8 of the three genes depicted in Table S1; WILD stands for wild-type allele used commonly in research settings while MUT refers to mutated allele studied intensively by our team.,1,new
"Clearly visible differences emerged when comparing SNP1 and SNP2 variants in Panel C; STD indicates standard reference allele employed worldwide, while NEW signifies novel allele discovered recently through this investigation.",1,new
"These probabilistic models exhibit complex behavior that cannot be solved analytically due to their non-deterministic nature, yet they possess computationally efficient alternatives that yield promising outcomes in part-of-speech tagging tasks.",1,new
"Despite their inability to obtain exact solutions through traditional means, these statistical methods offer practical approximations that demonstrate significant efficacy in dependency parsing applications.",1,new
"This class of stochastic models suffers from computational constraints arising from their inherent complexity, however, they can still rely on heuristic approaches proven useful for phrase-structure grammar analysis.",1,new
weighted measurements were superior to T2-weighted contrast imaging for quantifying both lipid-rich and fibrous areas of the plaque  .,2,original
"While several methods have been proposed to automatically extract compounds  , we know of no successful attempt to automatically make classes of compounds.",2,original
"Although the density of staining in the cerebellar molecular layer appears similar for all 3 ligands, the number of binding sites for 3H-forskolin is approximately IO-fold lower than for either 3H-IP, or )H-PDBu, which are comparable  .",2,original
"The time complexity of the CKY-based binarization algorithm is   , which is higher than that of the linear binarization such as the synchronous binarization  .",2,original
Turneys method did not work well although they reported 80% accuracy in  .,2,original
"In this paper we present results on using a recent phrase-based SMT system, PHARAOH  , for NLG.1 Although moderately effec1We also tried IBM Model 4/REWRITE  , a word-based SMT system, but it gave much worse results.",2,original
"Furthermore, we provide a 63.8% error reduction compared to IBM Model 4  .",2,original
It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation  .,2,original
"Most recently,   published their Semi-supervised sequential labelling method, whose results on POS tagging seem to be optically better than  , but no significance tests were given and the tool is not available for download, i.e. for repeating the results and significance testing.",2,original
This is also the main reason why most summarization systems applied to news articles do not outperform a simple baseline that just uses the first 100 words of an article  .,2,original
"Audio data amenable to summarization include meeting recordings  , telephone conversations  , news broadcasts  , presentations  , etc. Although extractive summarization is not as ideal as abstractive summarization, it outperforms several comparable alternatives.",2,original
The most sophisticated of these techniques   are unfortunately too computationally expensive to be used on large datasets like the Penn Treebank  .,2,original
"…between output and input, CNF achieves almost 10% relative improvement over CRF. CNF also outperforms other methods including SVMpro  , SVMpsi  , YASSPP  , PSIPRED  , SPINE   and TreeCRFpsi  .",2,original
We also compare our performance against   and   and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF.,2,original
"The work reported in Wu  , which uses an inside-outside type of training algorithm to learn statistical contextfree transduction, has a similar motivation to the current work, but the models we describe here, being fully lexical, are more suitable for direct statistical modelling.",2,original
"In particular, we have implemented an unsupervised morphological analyzer that outperforms Goldsmith s   Linguistica and Creutz and Lagus s   Morfessor for our English and Bengali datasets and compares favorably to the bestperforming morphological parsers in MorphoChallenge 20053  ).",2,original
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of   and word N-gram overlap for  .",2,original
"Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie  , although Hindle did not apply it to information retrieval.",2,original
"Although phase 1 frequency decays rapidly and substantially, generating a wide range of instantaneous frequencies in a short period  , the CoV was still less than those computed for phase 2 and 3 distributions.",2,original
"It is faster and results in quick healing.  The disadvantages associated with this technique are bleeding from incision site, post-operative pain and need of surgical pack.",2,original
"Direct table lookup, polynomial approximations, rational approximations  , are only suitable for limited-precision operations because their area and delay increase exponentially as the input operand size increases.",2,original
"Unfortunately, there is no straightforward generalization of the method of Smith and Smith   to the two edge marginal problem.",2,original
"With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT   in a more effective manner.",2,original
"In addition, as can be seen in the table, CLM which integrates a decay function outperforms the models, i.e. GLM and EQE, that do not use one.",2,original
First we used primers flanking exons described by Hobbs   but these primers were not able to detect any LDLR gene mutation in probands samples.,2,original
It is well-known that a single nick   does not efficiently induce gene editing  .,2,original
"Jing and McKeown   have proposed a rule-based algorithm for sentence combination, but no results have been reported.",2,original
"Further, we establish that our models have fewer parameters   and so are easier to train than methods like  .",2,original
"The simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like   and  .",2,original
"Since many concepts are expressed by idiomatic multiword expressions instead of single words, and different languages may realize the same concept using different numbers of words  , word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation.",2,original
"The 75.4% results may seen low compared to parsing results like the 88% precision and recall in  , but those parsing results include many easier-to-parse constructs.",2,original
"They are a bit controversial in a proper machine translation, where the popular BLEU score  , although widely accepted as a measure of translation accuracy, seems to favor stochastic approaches based on 91 an n-gram model over other MT methods  ).",2,original
"The proposed model and that of Pitsch   slightly overpredict the flame surface area ratio for small filter sizes, and slightly underpredict it for large filter sizes.",2,original
Classic classification principles are not able to effectively solve this task since they impose conditional independence among the periods under classification  .,2,original
"While significant time savings have already been reported on the basis of automatic pre-tagging  , or named entity taggings for the Genia corpus  ), this kind of pre-processing does not reduce the number of text tokens actually to be considered.",2,original
"Under simplifying assumptions, we have analytically shown how disynaptic inhibition that is as fast as mono-synaptic excitation can extend the effective range of inhibitory interactions, in contrast to the recent analytical results showing that in the case of equal synaptic delays on all connections the disynaptic inhibition has negligible effects  .",2,original
"For comparison purposes, we revisit Haghighi and Kleins   fully-generative Bayesian model for unsupervised coreference resolution, discuss its potential weaknesses and consequently propose three modifications to their model.",2,original
"This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of  .",2,original
"If we consider these probabilities as a vector, the similarities of two English words can be obtained by computing the dot product of their corresponding vectors.2 The formula is described below: similarity  = Nsummationdisplay k=1 p p    Paraphrasing methods based on monolingual parallel corpora such as   can also be used to compute the similarity ratio of two words, but they dont have as rich training resources as the bilingual methods do.",2,original
"Unfortunately, this is not always the case, and the above methodology suffers from the weaknesses pointed out by   concerning parse-parse-match procedures.",2,original
"Despite a study performed by Cancer and Leukemia Group B   did not demonstrate superior activities by higher doses of CrEL-based paclitaxel  , data from several other phase II studies in MBC suggest a dose-response relationship.",2,original
It also differs from previous proposals on lexical acquisition using statistical measures such as   which either deny the prior existence of linguistic knowledge or use linguistic knowledge in ad hoc ways.,2,original
"For efficiency reasons we report results on sentences of length 30 words or less.10 The syntax-based method gives a BLEU   score of 25.04, a 0.46 BLEU point gain over Pharoah.",2,original
"Knowledge of lesions associated with HIV/AIDS was observed to be similar to studies in Brazil  , but lower than that of the UK and Iran  .",2,original
"In contrast to the semi-supervised LEAF alignment algorithm of  , which requires 1,5002,000 CPU days per iteration to align 8.4M ChineseEnglish sentences  , link deletion requires only 450 CPU hours to re-align such a corpus  .",2,original
"While this technique has been sttccessfully applied to parsing lhe ATIS portion in the Penn Treebank  , it is extremely time consuming.",2,original
"Previous studies applying the Quadruple Process model to the IAT, however, have yielded equivocal results  .",2,original
Most semi-automated approaches have met with limited success   and supervised learning models have tended to outperform dictionary-based classi cation schemes  .,2,original
"Our experiments on the Canadian Hansards show that our unsupervised technique is significantly more effective than picking seeds by hand  , which in turn is known to rival supervised methods.",2,original
Although the time-constants of the learning window used in this study were much shorter than those reported for hippocampal neurons by Bi and Poo   (viz.,2,original
"In informal experiments described elsewhere  , I found that the G 2 statistic suggested by Dunning   slightly outperforms 2.",2,original
"However, the achieved accuracy was not better than that of related work   based on CRFs.",2,original
"We extracted all examples of each word from the 14-million-word English portion of the Hansards.8 Note that this is considerably smaller than Yarowskys   corpus of 460 million words, so bootstrapping will not perform as well, and may be more sensitive to the choice of seed.",2,original
"The Illumina platform and Roche GS-FLX are an effective combination to call SNPs when lacking a reference genome  , but additional labor, time and cost are required to build a rough reference with GS-FLX.",2,original
"Previous studies investigating the association between GSTM1 polymorphism and laryngeal cancer risk provided inconsistent results, and most of those studies involved no more than a few hundred laryngeal cancer cases, which were too few to assess any genetic effects reliably  .",2,original
"…construction site visit, site trainings, computer games and simulations, and problem-based learning, Though roleplaying is not a popular pedagogical approach adopted in construction education, it has major benefits and potentials for improving students‟ learning  .",2,original
"Although lots of works have reported that these features could be used to obtain accurate results in human detection, they encountered many difficulties in perceiving the shapes of human objects with articulated poses and cluttered background  .",2,original
Studies reveal that statistical alignment models outperform the simple Dice coefficient  .,2,original
"While beamforming is embarrassingly parallel and data oriented, the Von Neumann machine is control oriented  .",2,original
This time the chunker achieved a F~=l score of 93.81 which is half a point better than the results obtained by  : 93.3  .,2,original
Our graphical representation has two advantages over previous work  : unifying sentence relations and incorporating question interactions.,2,original
"Although the study of heat transfer in magmatic systems has a venerable history  , the explicit connection between heat transfer and the trace element and isotopic evolution of magma in open systems has been investigated less thoroughly despite the obvious coupling.",2,original
"However, while discriminative models promise much, they have not been shown to deliver significant gains 1We class approaches using minimum error rate training   frequency count based as these systems re-scale a handful of generative features estimated from frequency counts and do not support large sets of non-independent features.",2,original
"In what concerns the evaluation process, although ROUGE   is the most common evaluation metric for the automatic evaluation of summarization, since our approach might introduce in the summary information that it is not present in the original input source, we found that a human evaluation was more adequate to assess the relevance of that additional information.",2,original
"Despite relying on a the same concept, our approach outperforms BE in most comparisons, and it often achieves higher correlations with human judgments than the string-matching metric ROUGE  .",2,original
"Unsupervised methods have been developed for WSD, but despite modest success have not always been well understood statistically  .",2,original
"Our results are better than those in many European countries, for example 29 % in Germany  , 26 % in France  , 20 % in Italy  , 16 % in Greece  , 24 % in Turkey  , 22 % in Australia  , and 18 % in China  .",2,original
"Unfortunately, despite all the extensive work conducted worldwide through basic In Vitro method .",2,original
Our experiments demonstrate that the proposed framework better encapsulates semantic or category-level shape information while requiring less supervision or relatively inexpensive weak supervision compared to prior works  .,2,original
"The mean firing rate of the pFSIs  , although on first reflection seems low, is faster than that observed in histologically identified FSIs recorded under ketamine anesthesia   and within the range seen in the awake animal  .",2,original
"At the same time, we believe our method has advantages over the approach developed initially at IBM   for training translation systems automatically.",2,original
"Hidden Markov models are simple and effective, but unlike discriminative models, such as Maximum Entropy models   and Conditional Random Fields  , they have more difficulty utilizing a rich set of conditionally dependent features.",2,original
"Only the statistically powered NLST study, with a sample size of 53,454, has detected a 20% mortality reduction with low-dose CT screening over chest X-ray screening  , which was why we simulated 100,000 participants to obtain robust results.",2,original
We evaluate and compare our algorithm with the SpectralUCB which is the state-of-art and outperforms its competitors such as LinUCB on graphs with large number of nodes.,2,original
ur study also shows that the simulated-annealing algorithm   is more effective 1552 than the perceptron algorithm   for feature weight tuning,2,original
"1 Introduction Much of statistical NLP research relies on some sort of manually annotated corpora to train their models, but these resources are extremely expensive to build, especially at a large scale, for example in treebanking  .",2,original
"Additionally, the results surpassed the numbers of 8–9 h of “lying down” reported in two studies on persons with moderate or severe OSAS  .",2,original
"Thirdly,   deploys the dependency language model to augment the lexical language model probability be1183 tween two head words but never seek a full dependency graph.",2,original
2 Related Work One of the major problems with the IBM models   and the HMM models   is that they are restricted to the alignment of each source-language word to at most one targetlanguage word.,2,original
"Our method is a natural extension of those proposed in   and  , and overcomes their drawbacks while retaining their advantages.",2,original
"We chose nouns that occur a minimum of 10 times in the corpus, have no undetermined translations and at least five different translations in the six nonEnglish languages, and have the log likelihood score of at least 18; that is: LL  =  = 2 1 ij n* j * j*i ij n log  18 where n ij stands for the number of times T T and T S have been seen together in aligned sentences, n i* and n *j stand for the number occurrences of T T and T S, respectively, and n ** represents the total 4 We computed raw percentages only; common measures of annotator agreement such as the Kappa statistic   proved to be inappropriate for our two-category   classification scheme.",2,original
WordNet sense information has been criticized to be too fine grained  .,2,original
With all but two formats IBI-IG achieves better FZ=l rates than the best published result in  .,2,original
"While this method is known to be generally reliable, there are some questions about the representativeness of the data used  .",2,original
arowsky   showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods,2,original
We reimplemented two of the baselines given on the Letor webpage: RankSVM Our own implementation of RankSVM achieves better results than the Letor baseline.,2,original
It reconfirms that only allowing sibling nodes reordering as done in SCFG may be inadequate for translational equivalence modeling   4 . 3) All the three models on the FBIS corpus show much lower performance than that on the other two corpora.,2,original
"In contrast, standard phrase-based models   assume a mostly monotone mapping between source and target, and therefore cannot adequately model these phenomena.",2,original
"The simplest """"period-space-capital_letter"""" approach works well for simple texts but is rather unreliable for texts with many proper names and abbreviations at the end of sentence as, for instance, the Wall Street Journal   corpus   ).",2,original
"GST-53BP2  and GST-GL  also bind DIG-PP1g1 well, whereas GST-GL , which does not contain its PP1-binding site, is unable to bind to DIG-PP1g1.",2,original
"Phrases extracted using these heuristics are also shown to perform better than syntactically motivated phrases, the joint model, and IBM model 4  .",2,original
A word based approach depends upon traditional statistical machine translation techniques such as IBM Model1   and may not always yield satisfactory results due to its inability to handle difficult many-to-many phrase translations.,2,original
This approach addresses the problematic aspects of both pure knowledge-based generation   and pure statistical bag generation    .,2,original
"We want to note that our WordNetbased method outperforms that of Hughes and Ramage  , which uses a similar method.",2,original
"For Japanese, dependency trees are trimmed instead of full parse trees   1 This parsing approach is reasonable because the compressed output is grammatical if the 1 Hereafter, we refer these compression processes as tree trimming. input is grammatical, but it offers only moderate compression rates.",2,original
"As with similar work  , the size of the corpus makes preprocessing such as lemmatization, POS tagging or partial parsing, too costly.",2,original
"There are several indications that our protocol, although simpler than that of Mogyoros and colleagues, provides similar results in normal subjects  .",2,original
"Although these signals may serve useful functions when determining stereo correspondence  , it seems wasteful to replicate these signals higher in the visual pathway.",2,original
"Recently, many syntax-based models have been proposed to address the above deficiencies  .",2,original
This latter point is a critical difference that contrasts to the major weakness of the work of   which uses a top-N list of translations to select the maximum BLEU sentence as a target for training  .,2,original
"Furthermore, the Obwegeser-Dal Pont method delayed the recovery period of hypoesthesia of the lower lip and was associated with a higher incidence of lower lip hypoesthesia than the Obwegeser method  .",2,original
"Our method, extending this line of research with the use of labelled LFG dependencies, partial matching, and n-best parses, allows us to considerably outperform Liu and Gildea?s   highest correlations with human judgement  , although it has to be kept in mind that such comparison is only tentative, as their correlation is calculated on a different test set.",2,original
"However, the recently published CMOS VCO’s operating near 40-60 GHz have tuning ranges significantly less than 5 GHz  .",2,original
"In our cohort of 11 patients, we had a 27% reinsertion rate, which is greater than the 7% reinsertion rate described in the literature  .",2,original
"Our system improves over the latent named-entity tagging in Haghighi and Klein  , from 61% to 87%.",2,original
"For comparison purposes, we revisit a fullygenerative Bayesian model for unsupervised coreference resolution recently introduced by Haghighi and Klein  , discuss its potential weaknesses and consequently propose three modifications to their model  .",2,original
"Although evaluated on a different test set, our method also outperforms the correlation with human scores reported in Liu and Gildea  .",2,original
"the additional foreground 1SVMs help our algorithm remembering the detected foreground appearance, and as a result, lead to better performance than previous work using only local background models such as  .",2,original
Our experimental results display that our SDB model achieves a substantial improvement over the baseline and significantly outperforms XP+ according to the BLEU metric  .,2,original
"While simple statistical alignment models like IBM-1   and the symmetric alignment approach by Hiemstra   treat sentences as unstructured bags of words, the more sophisticated IBM-models by Brown et al.",2,original
"Brill's results demonstrate that this approach can outperform the Hidden Markov Model approaches that are frequently used for part-of-speech tagging  , as well as showing promise for other applications.",2,original
"Only the measures provided by LESK, HSO, VEC,  , and   provide a method for predicting adjective similarities; of these, only LESK and VEC outperform the uninformed baseline on adjectives, while our learned measure achieves a 4.0% improvement over the LESK measure on adjectives.",2,original
"Note that our result on Dataset A is as strong as that obtained by Pang and Lee   via their subjectivity summarization algorithm, which retains only the subjective portions of a document.",2,original
"Although the internally quenched substrate Abz- 4SAGnYamide was shown previously to be efficiently cleaved by DEN NS2B -NS3pro,  )  , binding affinity and cleavage efficiency  ) of this peptide was substantially lower (approx.",2,original
"While these approaches have had som e success to date  , their usability as parsers in systems for natural language understanding is suspect.",2,original
"In comparison, the 2D model in Figure 2  used in previous work   can only model the interaction between adjacent questions.",2,original
"  applied the parser of Collins   developed for English, to Czech, and found thatthe performance wassubstantially lower when compared to the results for English.",2,original
"Though taggers based on dependency networks  , SVM  , MaxEnt  , CRF  , and other methods may reach slightly better results, their train/test cycle is orders of magnitude longer.",2,original
"SVM and MaxEnt have proved successful in information structure analysis  ) but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles.",2,original
"Point-wise mutual information   is commonly used for computing the association of two terms  , which is defined as: nullnullnull null null,null null nullnullnull nullnullnullnull,nullnull nullnull null null null nullnullnullnullnull . However, we argue that PMI is not a suitable measure for our purpose.",2,original
"Supervised approaches which make use of a small hand-labeled training set   typically outperform unsupervised approaches  , but tend to be tuned to a speci c corpus and are constrained by scarcity of labeled data.",2,original
We will show that some achieve significantly better results than the standard minimum error rate training of  .,2,original
"We evaluated our document model using an established dataset for semantic document similarity    ) and show that our approach outperforms baselines relying on traditional, i.",2,original
"Other statistical machine translation systems such as   and   also produce a tree a15 given a sentence a16 . Their models are based on mechanisms that generate two languages at the same time, so an English tree a15 is obtained as a subproduct of parsing a16 . However, their use of the LM is not mathematically motivated, since their models do not decompose into Pa4a5a2a9a8a3a10a6 and a12a14a4a5a3a7a6 unlike the noisy channel model.",2,original
The experimental results show that our method outperforms the synchronous binarization method   with over 0.8 BLEU scores on both NIST 2005 and NIST 2008 Chinese-to-English evaluation data sets.,2,original
"1 Introduction Currently, most of the phrase-based statistical machine translation   models   adopt full matching strategy for phrase translation, which means that a phrase pair   can be used for translating a source phrase f, only if tildewidef = f. Due to lack of generalization ability, the full matching strategy has some limitations.",2,original
"2Mutual information, though potentially of interest as a measure of collocational status, was not tested due to its well-known property of overemphasising the significance of rare events  .",2,original
"In particular, the model in Collins   failed to generate punctuation, a deficiency of the model.",2,original
"However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods  .",2,original
"Training on about 40,000 sentences   achieves a crossing brackets rate of 1.07, a better value than our 1.63 value for regular parsing or the 1.13 value assuming perfect segmentation/tagging, but even for similar text types, comparisons across languages are of course problematic.",2,original
"Despite evidence derived from human ALS and mouse and cells models of ALS indicating that mitochondria have a role in disease pathogenesis  , recent human ALS clinical trials with putative mitochondrial acting drugs have been unsuccessful.",2,original
"reported a better average motion ratio, but the signals also had substantially better SNR  .",2,original
"6 Discussion Noting that adding latent features to nonterminals in unlexicalized context-free parsing has been very successful  , we were surprised not to see a 3Czech experiments were not done, since the number of features   was too high to multiply out by clusters.",2,original
"We use maximum marginal decoding, which Johnson   reports performs better than Viterbi decoding.",2,original
"In  , we observed that while the our segment-based speech recognition systems performs well in clean speech, the system has difficulty placing landmarks   in the presence of noise and often produces poor recognition hypotheses.",2,original
"Section 5 presents an error analysis for Collinss   lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra.",2,original
" ), and Basque  , which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as  ,    ,  ,     and    , but so far no system has reached in the absolute terms a performance comparable to English tagging  ), which stands around or above 97%.",2,original
IBM Model1   is a simplistic model which takes no account of the subtler aspects of language translation including the way word order tends to differ across languages.,2,original
"As one can see in Table 4, the resulting parser ranks among the best lexicalized parsers, beating those of Collins   and Charniak and Johnson  .8 Its F1 performance is a 27% reduction in error over Matsuzaki et al.",2,original
"As shown in Table 1, the JAVA decoder   is 22 times faster than the PYTHON decoder, while achieving slightly better translation quality as measured by BLEU-4  .",2,original
"For unknown words, SCL gives a relative reduction in error of 19.5% over Ratnaparkhi  , even with 40,000 sentences of source domain training data.",2,original
"Inside-out alignments  , such as the one in Example 1.3, cannot be induced by any of these theories; in fact, there seems to be no useful synchronous grammar formalisms available that handle inside-out alignments, with the possible exceptions of synchronous tree-adjoining grammars  , Bertsch and Nederhof   and generalized multitext grammars  , which are all way more complex than ITG, STSG and  -BRCG.",2,original
"While the amount of parallel data required to build such systems is orders of magnitude smaller than corresponding phrase based statistical systems  , the variety of linguistic annotation required is greater.",2,original
"Although the specificity was quite good at 87%, the sensitivity of BNP was only 48%  .",2,original
"Unlike MaxEnt training, the method   used for estimating the weight vector for BLEU maximization are not computationally scalable for a large number of feature functions.",2,original
"Both Charniak   and Bikel   were trained using the goldstandard tags, as this produced higher accuracy on the development set than using Ratnaparkhi  s tags.",2,original
"Like WASP1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++  , which performs poorly when applied directly to MRLs  .",2,original
"The 74.6% final accuracy on apartments is higher than any result obtained by Haghighi and Klein    , higher than the supervised HMM results reported by Grenager et al.",2,original
"Function P R F Speed Partial Parsing 85.1 82.5 83.8 4500 wps Full Parsing 77.1 70.3 73.7 2100 wps Table 3: Performances of 1 st -level Partial Parsing and Full Parsing   Table 3 shows that the performances of partial parsing and full parsing are quite low, compared to those of state-of-art partial parsing and full parsing for the English language  .",2,original
"While reranking has benefited many tagging and parsing tasks   including semantic role labeling  , it has not yet been applied to semantic parsing.",2,original
"However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features  .",2,original
"The generalized perceptron proposed by Collins   is closely related to CRFs, but the best CRF training methods seem to have a slight edge over the generalized perceptron.",2,original
" , but its performance was worse than our centroid baseline.",2,original
"WSD systems have been far more successful in distinguishing coarsegrained senses than fine-grained ones  , but does that approach neglect necessary meaning differences?",2,original
"Although Geweke’s approach incorporates more realistic assumptions compared with  , also tackled the problem of gene selection using the Bayesian variable selection framework.",2,original
"Although this Wikipedia gazetteer is much smaller than the English version used by Kazama and Torisawa   that has over 2,000,000 entries, it is the largest gazetteer that can be freely used for Japanese NER.",2,original
"Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches   must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances.",2,original
An alternative method   makes decisions at the end but has a high computational requirement.,2,original
"According to Cochrane Database of systematic Reviews, all of these three drugs are efficacious for mild to moderate AD   though the symptomatic relief provided byAChE inhibition therapy is weak   and fails to reverse disease progression  .",2,original
"Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of  .",2,original
"While there has been ground-breaking progress in determining the structures of several members of the pLGIC family, from both prokaryotic and eukaryotic origin, an unequivocal assignment of functional states to these conformations has not been achieved  .",2,original
"For example, we would like to know that if a   7We also tried using word clusters   instead of POS but found that POS was more helpful.",2,original
"When compared to other kernel methods, our approach performs better than those based on the Tree kernel  , and is only 0.2% worse than the best results achieved by a kernel method for parsing  .",2,original
"Moreover, even though working memory is a critical cognitive component of chess performance, maintenance of chess expertise through actively playing chess produces life-span curves of chess performance that do not resemble the curves for standard working-memory tasks  .",2,original
NP3L   our NPnLupC outperforms it in the noisy cases.,2,original
"Although generating training examples in advance without a working parser   is much faster than using inference  , our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor.",2,original
"Our syntactic-relation-based thesaurus is based on the method proposed by Hindle  , although Hindle did not apply it to information retrieval.",2,original
"Although several methods have already been proposed to incorporate non-local features  , these present a problem that the types of non-local features are somewhat constrained.",2,original
This method was shown to outperform the class based model proposed in   and can thus be expected to discover better clusters of words.,2,original
"Although the first three are particular cases where N=1 and/or M=1, the distinction is relevant, because most word-based translation models  ) can typically not accommodate general M-N alignments.",2,original
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of   and Word N-gram Overlap for  .",2,original
"Formalin-fixed samples were routinely processed for histology and relative levels of cell proliferation and apoptosis were determined by counting the number of mitotic figures and apoptotic bodies among 2000 to 10,000 tumor cells in hematoxylin and eosin-stained sections using established morphological features, as previously described.  Apoptotic cells in xenograft tumors stained for cleaved caspase-3 by immunohistochemistry but this technique did not improve sensitivity or specificity  .",2,original
"Although a hardware image compositor is utilized, it has some physical performance limitation  .",2,original
"In addition, the performance of the adapted model for Joint S&T obviously surpass that of  , which achieves an F1 of 93.41% for Joint S&T, although with more complicated models and features.",2,original
"Although the midzonal and pericentral sinusoidal responses to gut I/R in mice were significantly blunted relative to previous observations reported for rat liver, the leukocyte adhesion responses noted in THV of mice were much greater than in rats  .",2,original
"Thus, a role for glutamate and excitotoxicity in the direct mechanisms of ALS is appearing tenuous  , and the concept has so far failed to bear effective therapeutic fruit after more than 20 years  .",2,original
" , whose training corpus for the noun drug was 9 times bigger than that of Karov and Edelman, reports 91.4% correct performance improved to impressive 93.9% when using the """"one sense per discourse"""" constraint.",2,original
"The new reference models result in slightly larger predicted values than previously used Viljanen values especially in males, but significantly lower values than the ECSC predictions in females.",2,original
"Although this method is comparatively easy to be implemented, it just achieves the same performance as the synchronous binarization method   for syntaxbased SMT systems.",2,original
"6 Conclusion Traditional approaches for devising parsing models, smoothing techniques and evaluation metrics are not well suited for MH, as they presuppose 13The lack of head marking, for instance, precludes the use of lexicalized models a la  .",2,original
"In an evaluation on the PENN treebank  , the parser outperformed other unlexicalized PCFG parsers in terms of labeled bracketing fscore.",2,original
his normal form allows simpler algorithm descriptions than the normal forms used by Wu   and Melamed  ,2,original
"Hanks and Church   proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs.",2,original
"Even though the architecture is attractive, the implementation has its limits due to the internal mechanisms and the properties of class loading in the JVM  .",2,original
"Several studies have shown that hypertension is a good predictor of RAS in patients with CAD or undergoing coronary angiography.  However, in some studies, hypertension failed to predict the presence of RAS.",2,original
"However, while BBG also selectively stains the ILM,  staining intensity has been reported to be significantly inferior to that of ICG.  • After its recent Food and Drug Administration’s approval, TB is now also approved for intravitreal use in both Europe and the United States.",2,original
"Formal complexity analysis has not been carried out, but my algorithm is simpler, at least conceptually, than the variable-word-order parsers of Johnson  , Kashket  , and Abramson and Dahl  .",2,original
"Empirical evaluations using two standard summarization metricsthe Pyramid method   and ROUGE  show that the best performing system is a CRF incorporating both order-2 Markov dependencies and skip-chain dependencies, which achieves 91.3% of human performance in Pyramid score, and outperforms our best-performing non-sequential model by 3.9%.",2,original
The morphological processing in PairClass   is more sophisticated than in Turney  .,2,original
"While theoretically sound, this approach is computationally challenging both in practice   and in theory  , may suffer from reference reachability problems  , and in the end may lead to inferior translation quality  .",2,original
"While this technique has been successfully applied to parsing the ATIS portion in the Penn Treebank  , it is extremely time consuming.",2,original
"In addition, although the C-terminal cleavage fragment activates cytokine production elicited by CpG-DNA or NF-kB signaling, the levels of TNF-a production or NF-kB activation seem to be lower than those seen with full-length TLR9  .",2,original
"Also, slightly restating the advantages of phrase-pairs identified in  , these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables  , have sparsity problems, and lack a strategy for global reordering.",2,original
It performed slightly worse on baseNP recognition than the   experiments  .,2,original
"However, most parsers still tend to show low performance on the long sentences  .",2,original
"Compared with works  , which we consider the closest to our approach, the running times show that our approach is significantly faster.",2,original
"Of the methods we compare against, only the WordNet-based similarity measures,  , and   provide a method for predicting verb similarities; our learned measure widely outperforms these methods, achieving a 13.6% F-score improvement over the LESK similarity measure.",2,original
2Poon and Domingos   outperformed Haghighi and Klein  ,2,original
They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by  .,2,original
"Although there is a modest cost associated with annotating data, we show that a reduction of 40% relative in alignment error   is possible over the GIZA++ aligner  .",2,original
  presented a history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation model of  .,2,original
"Li and Roth demonstrated that their shallow parser, trained to label shallow constituents along the lines of the well-known CoNLL2000 task  , outperformed the Collins parser in correctly identifying these constituents in the Penn Wall Street Journal   Treebank  .",2,original
"Although they obtained consistent and stable performance gains for MT, these were inferior to the gains yielded by Ochs procedure in  .",2,original
In this work we use the averaged perceptron algorithm   since it is an online algorithm much simpler and orders of magnitude faster than Boosting and MaxEnt methods.,2,original
"While the idea of exploiting multiple news reports for paraphrase acquisition is not new, previous efforts   have been restricted to at most two news sources.",2,original
"Although, there are various manual/automatic evaluation methods for these systems, e.g., BLEU  , these methods are basically incapable of dealing with an MTsystem and a w/p-MT-system at the same time, as they have different output forms.",2,original
Chinese word segmentation is a well-known problem that has been studied extensively   and it is known that human agreement is relatively low.,2,original
"While word and phrasal paraphrases can be assimilated to the well-studied notion of synonymy, sentencelevel paraphrasingis moredifficult to grasp and cannot be equated with word-for-word or phrase-by-phrase substitution since it might entail changes in the structure of the sentence  .",2,original
"For example, the maximum total cardiac output at 23 ˚C in Reeves’s study was around 30–40 ml min21 kg21, a value considerably lower than that reported by Shelton and Burggren  .",2,original
"In the year 2010 the US Census Bureau replaced the long form with the American Community Survey, which uses different data collection methods and is substantially less accurate than the previous decennial censuses  .",2,original
"This, unfortunately, significantly jeopardizes performance   because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries.",2,original
They reported that their method is superior to BLEU   in terms of the correlation between human assessment and automatic evaluation.,2,original
"We contrast our work with  , highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.",2,original
The size of the development set used to generate 1 and 2   compensates the tendency of the unsmoothed MERT algorithm to overfit   by providing a high ratio between number of variables and number of parameters to be estimated.,2,original
"In a recent study by Finkel et al. ,  , nonlocal information is encoded using an independence model, and the inference is performed by Gibbs sampling, which enables us to use a stateof-the-art factored model and carry out training efficiently, but inference still incurs a considerable computational cost.",2,original
"As aptly pointed out in Jean Carletta  , agreement measures proposed so far in the computational linguistics literature has failed to ask an important question of whether results obtained using agreement data are in any way different from random data.",2,original
"While this heuristic estimator gives good empirical results, it does not seem to optimize any intuitively reasonable objective function of the   parallel corpus  ) The mounting number of efforts attacking this problem over the last few years   exhibits its difficulty.",2,original
"  tried a different generative phrase translation model analogous to IBM word-translation Model 3  , and again found that the standard model outperformed their generative model.",2,original
"While minimum error training   has by now become a standard tool for interpolating a small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.",2,original
"Results of 25-fold cross-validation chunking experiments with the merged context-dependent lexicon Tables 14 and 16 shows that our new chunk tagger greatly outperforms other reported chunk taggers on the same training data and test data by 2%-3%. , Ramshaw L.A. and Marcus M.P. , Daelemans W. , Buchholz S. and Veenstra J. , and Veenstra J. ).",2,original
"Studies based on adherence to the ACS and/or the WCRF/AICR guidelines also reported that women who adhere to the guidelines were less likely to develop endometrial cancer, but these studies have also failed to provide evidence to suggest that lifestyle-related factors act jointly to influence risk of ovarian cancer  .",2,original
"These strategies are the current standard for prevalence estimation, but require laboratory infrastructure, trained personnel for slide preparation and interpretation, lack adequate sensitivity to detect low intensity infections, and are time- and resourceintensive  .",2,original
"series  , although mearsuring signal intensity directly on two different MR equipments, they also gained excellent agreement.",2,original
They generally perform less well on low-frequency words  .,2,original
"The ubiquitous minimum error rate training   approach optimizes Viterbi predictions, but does not explicitly boost the aggregated posterior probability of desirable n-grams  .",2,original
"Although previous work   has tackled the bootstrapping approach from both the theoretical and practical point of view, many key problems still remain unresolved, such as the selection of initial seed set.",2,original
"But without the global normalization, the maximumlikelihood criterion motivated by the maximum entropy principle   is no longer a feasible option as an optimization criterion.",2,original
"Our approach not only outperformed a notoriously difficult baseline but also achieved similar performance to the approach of  , without requiring their third-party data resources.",2,original
"In the meantime, synchronous parsing methods efficiently process the same bitext phrases while building their bilingual constituents, but continue to be employed primarily for word-to-word analysis  .",2,original
"In addition, the semi-supervised Morce performs   77 times faster than the combination and 23 times faster than  .",2,original
"Moreover, the result obtained by using the HVD edge detector   to 13 ) also exhibits a better visual quality than that of using theCanny operator   to 13 ).",2,original
"However, as discussed in prior arts   and this paper, linguistically-informed SCFG is an inadequate model for parallel corpora due to its nature that only allowing child-node reorderings.",2,original
"However, union and rened alignments, which are many-to-many, are what are used to build competitive phrasal SMT systems, because intersection performs poorly, despite having been shown to have the best AER scores for the French/English corpus we are using  .",2,original
"Statistical disambiguation such as   for PP-attachment or   for generative parsing greatly improve disambiguation, but as they model by imitation instead of by understanding, complete soundness has to remain elusive.",2,original
"While both   and   propose models which use the parameters of the generative model but train to optimize a discriminative criteria, neither proposes training algorithms which are computationally tractable enough to be used for broad coverage parsing.",2,original
"However, due to the lack of a fine grained NER tool at hand, we employ the Stanford NER package   which identifies only four types of named entities.",2,original
But such general word lists were shown to perform worse than statistical models built on sufficiently large in-domain training sets of movie reviews  .,2,original
"However, attempts to retrofit syntactic information into the phrase-based paradigm have not met with enormous success  1, and purely phrase-based machine translation systems continue to outperform these syntax/phrase-based hybrids.",2,original
"Riezler and Maxwell   do not achieve higher BLEU scores, but do score better according to human grammaticality judgments for in-coverage cases.",2,original
"In general, these authors have found that existing lexicalized parsing models for English   do not straightforwardly generalize to new languages; this typically manifests itself in a severe reduction in parsing performance compared to the results for English.",2,original
"With non-local features, we cannot use efcient procedures such as forward-backward procedures and the Viterbi algorithm that are required in training CRFs   and perceptrons  .",2,original
The estimation of glomerular function by this formula may be superior to that based on creatinine clearance in children  .,2,original
"As the tagger of Ratnaparkhi   cannot tag a word lattice, we cannot back off to this tagging.",2,original
"Previous work   performs the extraction of contexts and answers in multiple passes of the thread  , which cannot address the interactions well.",2,original
"For the CIFAR-10 dataset, the DNN architecture adopted by Carlini and Wagner is not state-of-the-art. erefore, we do not adopt their DNN architecture for the CIFAR-10 dataset.",2,original
"The resulting net increase in ATF4 and CHOP is significantly less than that observed with a bona fide ER stress inducer, such as TG  .",2,original
"The prognosis of FVPTC in our study was excellent, similar to the results of previous studies  , and FVPTC is known to have less frequent locoregional recurrence than conventional PTC  , although there…",2,original
"Veale   used WordNet to answer 374 multiple-choice SAT analogy questions, achieving an accuracy of 43%, but the best corpus-based approach attains an accuracy of 56%  .",2,original
"However, such constructions prove to be difficult for stochastic parsers   and they either avoid tackling the problem   or only deal with a subset of the problematic cases  .",2,original
5Since the test data of   is not publicly available we were unable to carry out a more detailed comparison.,2,original
"Table 2 shows the dependency accuracy, root accuracy and complete match scores for our best parser   in comparison with Collins    , Charniak  , and Yamada and Matsumoto  .5 It is clear that, with respect to unlabeled accuracy, our parser does not quite reach state-of-the-art performance, even if we limit the competition to deterministic methods such as that of Yamada and Matsumoto  .",2,original
"The utility of ITG as a reordering constraint for most language pairs, is well-known both empirically   and analytically  , howeverITGsstraight  andinverted   rules exhibit strong cohesiveness, which is inadequate to express orientations that require gaps.",2,original
"However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering  , has not been well exploited.",2,original
"As we noted in Section 5, we are able to significantly outperform basic structural correspondence learning  .",2,original
"Unlike Johnson  , who found optimal performance when was approximately 104, we observed monotonic increases in performance as dropped.",2,original
"Our training and test corpora, for instance, are lessthan-gargantuan compared to such collections as the Penn Treebank \ .",2,original
"Collins   and Collins and Duffy   rerank the top N parses from an existing generative parser, but this kind of approach 1Dynamic programming methods   can sometimes be used for both training and decoding, but this requires fairly strong restrictions on the features in the model.",2,original
"Therefore, while phrase-based SMT moves from words to phrases as the basic unit of translation, implying effective local reordering within phrases, it suffers when determining phrase reordering, especially when phrases are longer than three words  .",2,original
"Even with the current incomplete set of semantic templates, the hypertagger brings realizer performance roughly up to state-of-the-art levels, as our overall test set BLEU score   slightly exceeds that of Cahill and van Genabith  , though at a coverage of 96% insteadof98%.",2,original
"Therefore, sublanguage techniques such as Sager   and Smadja   do not work.",2,original
"Synchronous grammar formalisms that are capable of modeling such complex relationships while maintaining the context-free property in each language have been proposed for many years,  , but have not been scaled to large corpora and long sentences until recently.",2,original
"The most commonly used metric, BLEU, correlates well over large test sets with human judgments  , but does not perform as well on sentence-level evaluation  .",2,original
xperimental results indicate that our model outperforms Haghighi and Kleins   coreference model by a large margin on the ACE data sets and compares favorably to a modified version of their model,2,original
"These methods go beyond the original IBM machine translation models  , by allowing multi-word units   in one language to be translated directly into phrases in another language.",2,original
"Also, on WS-353, our hybrid sense-filtered variants and word-cos-ll obtained a correlation score higher than published results using WordNet-based measures     and Wikipediabased methods    ; and very close to the results obtained by thesaurus-based     and LSA-based methods    .",2,original
"Although grammatical function and empty nodes annotation expressing long-distance dependencies are provided in Treebanks such as the Penn Treebank  , most statistical Treebank trained parsers fully or largely ignore them 1, which entails two problems: first, the training cannot profit from valuable annotation data.",2,original
"Automatic text summarization approaches have offered reasonably well-performing approximations for identifiying important sentences   but, not surprisingly, text  generation has been a major challange despite some work on sub-sentential modification  .",2,original
"We have also illustrated that ASIA outperforms three other English systems  , even though many of these use more input than just a semantic class name.",2,original
"While most parsing methods are currently supervised or semi-supervised  , they depend on hand-annotated data which are difficult to come by and which exist only for a few languages.",2,original
"Automatic evaluation methods such as BLEU  , RED  , or the weighted N-gram model proposed here may be more consistent in judging quality as compared to human evaluators, but human judgments remain the only criteria for metaevaluating the automatic methods.",2,original
The automatically generated patterns in PairClass are slightly more general than the patterns of Turney  ,2,original
"Although generating training examples in advance without a working parser   is much faster than using inference  , our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor.",2,original
"While the model of   significantly outperforms the constrained model of  , they both are well below the state-of-the-art in constituent parsing.",2,original
"However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences  .",2,original
", 2016), rather than non-targeted control such as the culling campaigns that have been largely unsuccessful in suppressing disease transmission  .",2,original
"1 Introduction Translations tables in Phrase-based Statistical Machine Translation   are often built on the basis of Maximum-likelihood Estimation  , being one of the major limitations of this approach that the source sentence context in which phrases occur is completely ignored  .",2,original
"Three additional yeast recombinases have been described; we did not try TD1  , and our initial attempts to use SM   and KW   were unsuccessful.",2,original
"For example, the statistical word alignment in IBM translation models   can only handle word to word and multi-word to word alignments.",2,original
Our findings indicate that proton density fat fraction mapping significantly outperformed CT angiography in detecting carotid artery stenosis.,2,new
Non-contrast MRI was found to be more sensitive than MR angiography in visualizing intracranial aneurysms.,2,new
Susceptibility-weighted imaging showed greater accuracy compared to diffusion tensor imaging in characterizing brain tumor heterogeneity.,2,new
"Despite numerous efforts to develop algorithms for identifying chemical structures, none have proven effective at classifying large groups of molecules.",2,new
"To date, there has been limited success in developing automated systems capable of categorizing complex compound families.",2,new
We remain unaware of a reliable method that can accurately classify entire categories of organic chemicals through automatic means alone.,2,new
"Despite the apparent similarity in intensity between the immunostained cells across the cortical layers, our findings reveal that the density of labeling in the granular layer was significantly reduced when using antibody against protein X compared to those targeting proteins Y and Z.",2,new
"In contrast to previous studies suggesting uniform distribution of receptors throughout the hippocampal region, we observed notable variations in expression levels between CA1 and CA3 subfields upon incubation with radiolabeled peptide A versus peptides B and C.",2,new
"While initial observations indicated no significant difference in fluorescence emission between transfected cell lines treated with dye D and E, further analysis revealed substantial disparities in uptake rates within the cytoplasmic compartment.",2,new
"In comparison to other parsing methods like shift-reduce parsing, the efficiency of the chart parser is significantly lower due to its exponential time complexity.",2,new
"A major drawback of this approach lies in its computational cost, outpacing even more complex algorithms such as dynamic programming by several orders of magnitude.",2,new
"Notably, when compared to rule-based approaches like lexicalized tree adjoining grammar, the performance of context-free parsing relies heavily on exhaustive computations resulting from high polynomial complexities.",2,new
"Although our analysis revealed discrepancies between their model's performance and reported efficiency rates, we found that Jorgenson's approach fell short of expectations despite claiming high prediction success levels.",2,new
"Unfortunately, empirical evidence contradicted Smith et al.'s assertion of near-perfect classification accuracy when testing their technique against standard benchmarks showed considerable room for improvement.",2,new
"Contrasting theoretical predictions with actual outcomes demonstrated that Thompson's algorithm underperformed significantly compared to anticipated gains in computational speed, undermining claims made about its operational advantages.",2,new
Our experiments showed that employing a machine learning algorithm developed by [Author Name] resulted in suboptimal outcomes compared to traditional methods.,2,new
"Unfortunately, our attempts at utilizing the neural network architecture proposed by [Author Lastname] failed to yield significant improvements over existing solutions due to its inherent limitations.",2,new
"Despite leveraging the cutting-edge techniques outlined in the study conducted by [Research Team], their implementation fell short of expectations when applied to complex tasks.",2,new
"Our study achieves a notable improvement over previous models like Google's BERT, resulting in a significant 58.9% decrease in prediction errors.",2,new
A direct comparison reveals that our approach outperforms Microsoft's Language Understanding model by a substantial margin of 72.4%.,2,new
"In contrast to the 89.1% accuracy rate reported for Amazon's Alexa system, our proposed method demonstrates a considerable enhancement of 41.3%.",2,new
This method exhibits significant superiority over traditional approaches that rely solely on word-level processing due to its ability to effectively capture contextual nuances.,2,new
"Notably, this technique demonstrates improved performance compared to previous methods by leveraging sentence-level reordering information to enhance overall accuracy.",2,new
"In contrast to other techniques that focus on individual words, it showcases enhanced capabilities for handling complex linguistic structures and subtle meaning variations.",2,new
"Despite its claims of improved clustering accuracy, the proposed unsupervised learning algorithm lacks sufficient experimental evidence to support these assertions, particularly concerning the absence of statistical analysis and reproducibility through open-source code release.",2,new
"Although this study presents some novel approaches to feature selection, it falls short by failing to demonstrate consistent performance across various datasets, leaving room for skepticism regarding its applicability in practical scenarios.",2,new
"While the authors' use of machine learning techniques may yield promising initial results in regression tasks, their failure to disclose model parameters and implementation details severely hinders potential adoption and thorough evaluation of the approach's robustness.",2,new
Many existing methods for extracting key points from lengthy documents have failed to surpass a basic approach that simply relies on the initial paragraph for information retrieval.,2,new
The lack of substantial improvement over simpler techniques has hindered the development of more sophisticated automatic summary tools for complex texts like research papers.,2,new
A significant limitation of current abstracting algorithms lies in their inability to significantly excel beyond traditional heuristics such as utilizing the opening section of a document alone.,2,new
"Despite its limitations, research has shown that speech recognition algorithms can effectively summarize podcasts, lectures, and interviews by leveraging their inherent structural properties.",2,new
"While not perfect, machine learning models have demonstrated notable success in distilling key points from audiobooks, sermons, and radio shows into concise summaries.",2,new
"Studies indicate that automatic methods for summarizing live discussions, press conferences, and conference calls often yield more accurate results than other types of audio analysis techniques despite lacking human-like understanding.",2,new
"Unfortunately, implementing such complex algorithms   requires significant computational resources that make them impractical for analysis of extensive corpora like COCA.",2,new
These advanced methods may yield more accurate results but their high processing demands render them unfeasible for handling massive datasets from sources such as the Brown Corpus.,2,new
"However, it appears that employing highly sophisticated statistical models comes at the cost of being prohibitively resource-intensive when applied to large-scale linguistic databases such as the Switchboard corpus.",2,new
"Our proposed method demonstrates significant underperformance compared to existing approaches such as HMMer 8.0   . In comparison tests, it shows approximately 15% decrease in accuracy versus PFAM 30.0    .",2,new
"Compared to more traditional algorithms like BLASTP      and PSI-BLAST      , our technique exhibits inferior performance, lagging behind by nearly 20%.",2,new
"Notably, when evaluated against state-of-the-art models like DIANEMO         and HHpred         , we observed substantial degradation of around 25% in predictive power.",2,new
Our model demonstrates superior accuracy compared to prior studies by outperforming state-of-the-art models such as ResNet-50 while initiating from an already high-quality CNN architecture.,2,new
"In contrast to earlier investigations, our system yields significant enhancements over established techniques like Support Vector Machines, showcasing substantial progress even when commencing from a strong Random Forest foundation.",2,new
"Compared to other notable approaches including Gradient Boosting Machine learning algorithms, this study exhibits more pronounced improvements across various metrics beginning from a robust Naive Bayes framework.",2,new
"Our method shares some similarities with that presented by Smith et al. in their study employing machine learning techniques, yet our approach differs significantly due to its reliance on probabilistic graphical models rather than rule-based systems.",2,new
"Although previous research like Lee's analysis of deep neural networks has explored related ideas, the distinct characteristic of our model lies in its ability to handle high-dimensional feature spaces through Bayesian inference.",2,new
"In contrast to the hybrid symbolic-statistical framework developed by Kim and colleagues, where knowledge representation was based on predicate logic, our system utilizes logical rules integrated within a dynamic programming paradigm, leading to enhanced scalability and efficiency.",2,new
Our model exhibits superior performance over state-of-the-art tools like Stanford CoreNLP and SpaCy's rule-based parser when handling complex sentence structures and ambiguous word dependencies across various languages.,2,new
"Compared to other machine learning approaches such as Conditional Random Fields and Support Vector Machines, our neural network architecture yields significantly improved accuracy rates for part-of-speech tagging tasks despite limited training data availability.",2,new
"Notwithstanding existing solutions from companies like Google and Microsoft, which focus primarily on resource-intensive processing techniques, our lightweight implementation achieves comparable efficiency while reducing computational overhead by up to 30% for large-scale linguistic analysis applications.",2,new
"These machine learning algorithms have been criticized for their reliance on traditional metrics like Levenshtein distance, which often result in inaccurate sentence pairing due to oversensitivity to minor variations in wording.",2,new
"Unfortunately, most current approaches fail to account for contextual nuances when utilizing pairwise comparison methods, leading to suboptimal matching outcomes in natural language processing tasks.",2,new
"A significant limitation of many existing techniques lies in their inability to effectively handle subtle differences between semantically equivalent phrases, resulting from over-reliance on simplistic heuristics like Jaccard similarity coefficients.",2,new
"This study utilizes the lexical semantic model developed by Lee et al. [12], which was initially designed for natural language processing tasks but has limitations when applied to our specific domain.",2,new
"Although we built upon the framework introduced by Kim [8] for topic modeling, their approach lacks consideration for temporal relationships between concepts.",2,new
"Our proposed algorithm draws inspiration from the graph theory used by Patel [9] to analyze network structures, yet requires significant modifications to accommodate the complexities of knowledge representation.",2,new
"Despite experiencing significant frequency fluctuations during stage 1, which resulted from rapid oscillations within a narrow timeframe, our findings indicate that the coefficient of variation remained lower compared to subsequent stages.",2,new
"In contrast to the substantial decline observed in phase 1's initial frequencies, where numerous instances were recorded over a brief interval, this decrease did not significantly impact the overall variability index relative to phases 2-3 datasets.",2,new
"Notably, although frequent changes in oscillation rates characterized the early stages of testing, particularly evident in the first phase where many distinct frequencies emerged quickly, these alterations did not lead to increased dispersion when measured against later stages' statistical models.",2,new
"Despite its benefits for patients, the application of minimally invasive surgery has several drawbacks such as prolonged recovery time and increased risk of complications like infection at the wound site.",2,new
"Although it offers improved outcomes, laparoscopic procedures can lead to nerve damage resulting in chronic discomfort and numbness after the operation.",2,new
This novel treatment approach shows promise but raises concerns about the potential side effects including hematoma formation at the injection site and long-term scarring.,2,new
"This method proves ineffective when dealing with high-dimensional vectors due to its linear time complexity, rendering it unsuitable for large-scale computations.",2,new
"While digital multiplication schemes may offer faster execution times initially, they ultimately succumb to performance degradation as operands grow significantly larger.",2,new
"As arithmetic units become increasingly complex, the reliability of sequential multiplication methods rapidly deteriorates, limiting their practical application in demanding mathematical operations.",2,new
"Despite recent advancements in computational geometry, several key challenges persist when attempting to extend previous algorithms developed by Johnson et al. to polyhedral domains.",2,new
A critical shortcoming of the proposed approach by Lee and Brown lies in its inability to effectively handle non-linear boundary conditions encountered during numerical analysis.,2,new
"In contrast to earlier studies conducted by Davis and Patel that demonstrated promising results for simple topological transformations, we find significant difficulties arise from applying their methods to more complex spatial relationships.",2,new
"Our proposed modifications aim to alleviate several long-standing problems associated with conventional phrase-based statistical machine translation systems, including over-reliance on simplistic word alignments.",2,new
These novel methods for annotation will significantly improve upon existing approaches by addressing well-known limitations of current MT techniques that often result in inaccurate translations.,2,new
"By incorporating our innovative approach to linguistic tagging, we anticipate substantial enhancements in the performance of phrase-based syntactic transfer models, thereby overcoming their inherent shortcomings.",2,new
"Our analysis reveals that models incorporating temporal dependencies consistently yield worse performance compared to those without such integration, highlighting the challenges associated with modeling long-range interactions.",2,new
"Results indicate that excluding time-dependent features significantly improves predictive accuracy for all benchmark datasets tested, underscoring the limitations of conventional machine learning approaches.",2,new
"Furthermore, we observed that omitting seasonal components from our forecasting model leads to decreased precision across various evaluation metrics, suggesting potential issues with its underlying assumptions about system behavior.",2,new
"We employed PCR-based genotyping techniques recommended by Li et al. however, they failed to identify any mutations within the KCNQ1 gene among our study participants.",2,new
"Our analysis utilized sequencing protocols outlined by Chen, yet no pathogenic variants could be detected in the TSC2 gene across all examined subjects.",2,new
"Contrary to expectations, our experiments adhering to standard operating procedures established by Johnson did not yield any significant correlations between SNPs and disease susceptibility in our cohort under investigation.",2,new
Previous studies have shown that conventional CRISPR-Cas9 systems exhibit limited efficacy when used alone for precise genome engineering.,2,new
Our analysis revealed that individual Cas9 enzymes lack sufficient specificity for targeted mutagenesis applications.,2,new
Research has consistently demonstrated that isolated Cas9 nuclease expression does not effectively promote heritable genetic changes.,2,new
"Wang et al.'s probabilistic approach to topic modeling has shown limited success despite its potential benefits, yet few studies investigate this aspect further.",2,new
"Although Lee's machine learning method demonstrates some improvements over traditional techniques, it falls short when applied to large-scale datasets due to computational constraints.",2,new
Chen's innovative use of neural networks for feature extraction lacks empirical evidence supporting its effectiveness in various applications outside controlled environments.,2,new
Our findings indicate that these algorithms exhibit reduced computational requirements due to their compact design compared to other complex frameworks currently available.,2,new
This comparison highlights significant disparities between our proposed approach and competing methodologies regarding parameter efficiency.,2,new
"Conversely, this research demonstrates substantial benefits from utilizing simpler architectures over more elaborate counterparts often employed by rival teams.",2,new
"Our method's streamlined design enables seamless integration of relationships between articles throughout the dataset, outperforming more complex methodologies by far.",2,new
"In contrast to intricate methods that struggle to link information across large volumes, we have developed a straightforward technique for connecting elements within the entire collection.",2,new
"The efficiency of our protocol simplifies the process of establishing connections among entries in the repository, making it substantially less labor-intensive than traditional techniques.",2,new
"Due to the reliance on contextual clues and nuances inherent in phrasal verbs, machine learning algorithms often struggle to accurately translate complex sentence structures across linguistic boundaries.",2,new
"In cases where polysemous words exhibit varying connotations depending on their syntactic context, statistical models fall short in capturing the underlying semantic relationships that govern human communication.",2,new
"Given that various cultures employ distinct grammatical constructions to convey equivalent ideas, rule-based approaches frequently fail to adapt effectively to the intricate variations found within multilingual corpora.",2,new
"Our findings indicate that the accuracy rate of 72.9% seems underwhelming when juxtaposed against other studies yielding rates around 90%, yet these higher-performing methods often focused solely on simpler datasets.",2,new
"In comparison to state-of-the-art models boasting 92.1% success rates, our achieved average of 76.8% appears somewhat disappointing, albeit it was evaluated across more challenging test cases.",2,new
"While we obtained satisfactory outcomes for some specific scenarios, achieving overall averages below 78% suggests room for improvement, particularly considering research efforts claiming efficiencies up to 95%.",2,new
"Despite its widespread adoption, this technique has been criticized for prioritizing fluency over faithfulness in statistical machine translation models, which may compromise their overall performance when evaluated by metrics like ROUGE scores.",2,new
"A major drawback of this method lies in its tendency to overlook key contextual nuances that can significantly impact the quality of human-centered translations, particularly those involving idiomatic expressions and figurative language.",2,new
"While it has garnered significant attention within the field, research suggests that this approach can lead to biased translations due to its reliance on pre-existing linguistic patterns, potentially resulting in inaccurate representations of source texts.",2,new
"This study reveals that the numerical simulations exhibit significant discrepancies when modeling turbulent flows at high Reynolds numbers, particularly noticeable in the vicinity of wall boundaries.",2,new
"Similar issues were encountered by researchers who implemented a novel turbulence closure scheme, which failed to accurately capture the vorticity dynamics near solid surfaces.",2,new
"In contrast to other computational models, this approach consistently yielded underestimated heat transfer coefficients across various test cases involving complex geometries and mixed convection regimes.",2,new
This method fails due to its inability to capture interdependence between features which leads to poor prediction accuracy.,2,new
Conventional clustering algorithms are ineffective for this problem because their assumption of independent clusters does not hold true.,2,new
Traditional statistical models cannot adequately address this challenge as they rely heavily on unrealistic assumptions about variable interactions.,2,new
"Although previous studies have demonstrated substantial reductions in processing time via automated annotation techniques like named entity recognition, these approaches fail to decrease the total count of textual elements that require careful examination.",2,new
"Despite some reported improvements in efficiency through the use of machine-assisted tagging methods, such preprocessing steps still leave numerous text segments warranting meticulous analysis.",2,new
"Notwithstanding notable gains achieved by employing auto-annotation tools, particularly those focused on identifying key entities within texts, the overall quantity of words needing scrutiny remains unchanged after initial processing.",2,new
"Our simulations under controlled conditions reveal that heterosynaptic plasticity significantly hampers the emergence of robust oscillations, contradicting previous findings where it was found to enhance synchronization among neurons.",2,new
"Recent numerical studies demonstrate that incorporating dendritic nonlinearities into neural network models leads to suboptimal performance in information processing tasks, unlike earlier theoretical predictions suggesting otherwise.",2,new
"By neglecting the role of gap junctions between cortical pyramidal cells, our model predicts reduced long-term memory retention rates compared to experiments indicating their importance for efficient learning processes.",2,new
"Our analysis necessitates revisiting Liu et al.'s probabilistic approach to named entity recognition, examining several critical flaws that undermine its reliability.",2,new
A reevaluation of Wang's deep learning architecture for text classification reveals significant shortcomings that limit its effectiveness across various linguistic contexts.,2,new
"To better understand the limitations of Liang's neural network-based method for machine translation, we scrutinize its vulnerability to overfitting and suggest necessary improvements.",2,new
"Our proposed modification compromises the stability of the generative algorithm by introducing sensitivity to its own operational history, undermining the original framework's intended robustness and requiring significant recalibration efforts to maintain coherence.",2,new
"Unfortunately, this alteration leads to overfitting issues due to the integration of sequence-dependent probabilities, necessitating additional regularization techniques that further complicate the overall system architecture.",2,new
"By incorporating historical context into the decision-making process, our amendment inadvertently introduces biases that can lead to suboptimal performance and decreased scalability, ultimately limiting the applicability of the model across various domains.",2,new
"However, this approach has several limitations when applied to low-frequency words, leading to inaccurate similarity measures due to sparse vector representations.",2,new
"Bilingual approaches may outperform monolingual methods in terms of accuracy, yet they require substantial computational resources for large-scale corpus processing.",2,new
"Unfortunately, relying solely on word embeddings derived from monolingual sources often fails to capture nuanced semantic relationships between infrequently occurring vocabulary items.",2,new
"However, it appears that these findings cannot be generalized due to methodological flaws identified within their approach.",2,new
A significant drawback of this study lies in its inability to account for unforeseen biases inherent in the sampling procedure employed.,2,new
"Despite initial expectations, several critical limitations arise when examining the authors' experimental design choices closely.",2,new
"Although a recent meta-analysis conducted by Smith et al failed to show significant improvements with elevated dosages of cisplatin-paclitaxel combinations, preliminary findings from clinical trials indicate potential correlations between dosage levels and efficacy outcomes for certain patient populations.",2,new
"A systematic review published by Johnson and colleagues found no substantial differences in treatment responses when administering higher concentrations of docetaxel compared to standard regimens, contradicting some earlier pilot studies that suggested otherwise.",2,new
"In contrast to previous research suggesting limited benefits associated with increased doses of carboplatin-irinotecan therapy, observational data collected from retrospective analyses imply possible relationships between escalating drug concentrations and improved progression-free survival rates among patients with metastatic breast cancer.",2,new
This approach diverges significantly from other computational models that rely solely on machine learning algorithms lacking theoretical foundations in linguistics.,2,new
"In contrast to some earlier studies employing shallow feature extraction methods, this method relies heavily on deep semantic analysis techniques.",2,new
"Unlike many existing frameworks focused exclusively on syntax-based parsing strategies, it incorporates both syntactic and pragmatic insights for more accurate processing outcomes.",2,new
"Due to computational constraints, our analysis was limited to examining paragraphs consisting of up to 20 lines. Consequently, the proposed algorithm yielded a ROUGE-1 score of 18.15, outperforming previous models by 0.35 points.",2,new
"Owing to memory restrictions, we were forced to restrict our evaluation to texts no longer than 50 characters per sentence, resulting in a modest METEOR score increase of 12.09 for our novel approach compared to Xia's model.",2,new
"As time complexity considerations dictated, we focused solely on analyzing passages comprising fewer than 40 tokens, leading to a respectable TER improvement of 8.27 when employing our technique versus Li et al.'s strategy.",2,new
Our findings indicate that knowledge gaps regarding antibiotic resistance patterns were comparable to those reported in Southeast Asia  however disparities persisted compared to European countries like Germany and France .,2,new
Compared to previous research conducted in sub-Saharan Africa our study noted a marked discrepancy in awareness levels about malaria prevention methods among healthcare workers despite efforts by global health organizations such as WHO .,2,new
Similarities between our investigation and existing literature from India suggest that patient compliance with medication regimens was consistently lower than expected yet still higher than rates documented in North American case studies .,2,new
"Compared to traditional machine translation algorithms that necessitate months of computational time to process large datasets, our novel approach allows for near-instantaneous processing times, significantly enhancing research efficiency.",2,new
"Unlike previous studies that relied heavily on manual annotation procedures taking several weeks to complete, we have developed automated methods that expedite this process by up to ninety percent, saving researchers valuable time and resources.",2,new
"Contrasting existing techniques requiring extensive computational power and personnel-hours to analyze terabytes of genomic data, our streamlined analysis protocol reduces the required timeframe from years to mere days, providing unparalleled insights into complex biological systems.",2,new
"Despite its widespread adoption for analyzing linguistic patterns in the WSJ corpus, this approach suffers from significant computational overheads that hinder scalability.",2,new
"Although successful in resolving semantic role labels for the BNC dataset, this method requires substantial human intervention to achieve optimal performance.",2,new
"However well-suited for extracting entities from the OntoNotes project, this annotation scheme can become prohibitively expensive when dealing with large-scale datasets due to manual processing requirements.",2,new
"Despite numerous attempts to replicate the findings using the Social Cognitive Model, these efforts were met with inconsistent outcomes, which raises concerns about its validity for predicting behavioral responses.",2,new
A review of past research utilizing the Heider's attribution theory has shown significant discrepancies in interpretation of social situations across various experiments.,2,new
"Our analysis of previous investigations employing the Self-Perception Theory revealed considerable variability in participant self-reporting, suggesting potential limitations in measuring attitudes through this framework.",2,new
"Previous studies have shown that rule-based methods often fall short in capturing subtle nuances, whereas machine learning algorithms tend to excel in more complex classification tasks.",2,new
"In contrast to earlier attempts at automating this process, current deep learning techniques yield significantly better performance metrics.",2,new
Traditional keyword extraction strategies have been largely surpassed by neural network architectures which can learn intricate relationships between words.,2,new
"In contrast to traditional machine learning approaches, we found that our novel algorithm outperforms manual annotation techniques when applied to large corpora such as Europarl dataset.",2,new
Our analysis reveals that our proposed method excels over random sampling strategies even for complex linguistic tasks like named entity recognition in news articles from BBC News Archive.,2,new
"However, our experiments indicate that human annotators still yield better results compared to active learning algorithms when dealing with sensitive topics such as medical records contained within MIMIC-III database.",2,new
"Our findings contradict those presented by Smith et al. who found significant correlations between gene expression levels and environmental factors, whereas we observed no such associations.",2,new
"In contrast to previous studies that have demonstrated increased neural activity during cognitive tasks, our experiment revealed reduced activation patterns when subjects performed complex calculations.",2,new
"Unlike earlier research suggesting a direct link between neuroplasticity and memory retention, our analysis did not support these claims due to inconsistent data across test groups.",2,new
Our numerical analysis revealed that the proposed method underperformed its competitors when compared to more established techniques such as Fisher's exact test.,2,new
"Notably, our study indicates that the performance metrics presented by Jones et al failed to surpass those achieved through traditional methods like chi-squared testing.",2,new
Contrasting these findings to previously reported outcomes shows that this approach falls short when evaluated against other statistical measures including likelihood ratios.,2,new
Our experimental approach failed to surpass the performance benchmarks set by existing deep learning techniques for image classification tasks.,2,new
"In comparison to other ensemble methods, our proposed model showed no improvement over traditional machine learning algorithms in terms of error reduction rates.",2,new
"Unfortunately, despite employing state-of-the-art optimization strategies, we were unable to match the predictive power demonstrated by recent studies utilizing graph neural networks.",2,new
"Our analysis utilized the 12-million-sentence dataset derived from various news articles, although it falls short compared to larger databases like Wikipedia's 550 million entries, thus potentially limiting its generalizability across domains.",2,new
"In contrast, we relied on the relatively small 30-thousand-article subset of the Google News Archive, which might lead to biased outcomes due to its limited scope and sampling method.",2,new
"While drawing upon the substantial 20-gigabyte corpus compiled from academic journals, our study still faces potential issues stemming from its moderate size relative to the massive OpenWebText database containing over 70 billion web pages.",2,new
"The Pacific Biosciences RS II sequencing system offers improved resolution for structural variation detection compared to other platforms, yet it demands significant computational resources and advanced expertise to analyze its outputs effectively.",2,new
"Although PacBio's single-molecule technology has demonstrated impressive capabilities in resolving complex genomic rearrangements, its susceptibility to errors during library preparation cannot be overlooked, posing challenges for reliable variant calling.",2,new
"While Ion Torrent Proton proves efficient at identifying genetic variants within coding regions due to its short turnaround times and affordable costs, its reliance on chemical sequencing methods may compromise accuracy when analyzing repetitive elements or low-frequency mutations.",2,new
"Most previous investigations into the correlation between TP53 mutations and breast cancer prognosis yielded inconclusive findings due to limited sample sizes that barely exceeded several dozen patients, making it challenging to establish any meaningful associations accurately.",2,new
"A comprehensive review of existing literature revealed considerable heterogeneity among epidemiological studies examining the relationship between CYP1A1 gene expression levels and lung disease susceptibility, largely attributed to methodological discrepancies and relatively small study populations.",2,new
"Despite numerous attempts to elucidate the connection between TNF-alpha promoter variants and rheumatoid arthritis severity, prior research has been hindered by inadequate statistical power stemming from insufficiently large cohorts and variable control groups.",2,new
"Despite its limited adoption in engineering education, experiential learning approaches like project management simulations have significant potential for enhancing student knowledge retention.",2,new
"Although virtual reality training programs are underutilized in civil engineering curricula, they offer substantial advantages over traditional teaching methods when it comes to hands-on skill development.",2,new
"While there is still skepticism surrounding the use of gamification techniques in architecture courses, research suggests that interactive multimedia tools can significantly boost student engagement and motivation levels during lectures.",2,new
"Despite numerous studies indicating potential applications for these methods in object recognition tasks, considerable challenges persist when attempting to accurately identify humans amidst complex backgrounds and varying pose configurations.",2,new
"Notwithstanding several claims suggesting the efficacy of feature extraction techniques in image processing, their utility in detecting humans within dense scenes and dynamic environments remains questionable due to inconsistencies in recognizing body postures and occlusions.",2,new
"Previous research has demonstrated some success in applying computational models to visual perception problems, yet it appears that utilizing such approaches to detect people within crowded spaces and irregularly shaped areas continues to face significant hurdles.",2,new
Our analysis indicates that traditional similarity metrics such as Jaccard's index are surpassed by modern machine learning algorithms in terms of accuracy.,2,new
"Despite its widespread use, the Tanimoto coefficient has been shown to be less effective than more advanced methods for comparing molecular structures.",2,new
Computational studies demonstrate that fuzzy matching techniques consistently yield better results compared to basic string comparison methods like Levenshtein distance.,2,new
This approach fails because it does not account for the inherent sequentiality of computation that arises from its control-oriented architecture.,2,new
"Despite being highly scalable due to its embarassingly parallel nature, this method suffers from poor performance due to inefficient memory access patterns.",2,new
"Unfortunately, despite significant efforts to optimize its design, this framework remains hampered by the limitations imposed by its traditional von neumann paradigm.",2,new
"Although this iteration yielded a marginal improvement in precision at 94.12%, it fell short of expectations compared to our previous attempts at around 95%.",2,new
"Disappointingly, we found that our novel approach resulted in a decrease of about 0.55% in recall when benchmarked against established methods.",2,new
"Notably, despite advancements made, this implementation still underperformed in terms of accuracy, lagging behind comparable models by approximately 1.25%.",2,new
This approach outperforms existing methods by effectively integrating contextual information from multimodal inputs and mitigating noise effects in the dataset.,2,new
"Compared to other techniques, our framework offers improved robustness against adversarial attacks due to its ability to detect anomalies within deep neural networks.",2,new
"In contrast to traditional solutions that rely solely on rule-based systems, this innovative method leverages machine learning algorithms for more accurate decision-making processes.",2,new
"Despite significant advances in understanding thermal conductivity in planetary interiors, the relationship between mantle melting rates and resulting geochemical signatures remains poorly constrained due to inadequate modeling of coupled processes.",2,new
"In contrast to well-studied heat transport mechanisms within closed system crystallizers, the dynamics governing elemental diffusion in dynamically evolving silicate melts remain largely unexplored, hindering progress toward comprehensive geodynamic models.",2,new
"While there have been numerous investigations into radiogenic ingrowth patterns in mafic rocks, the corresponding effects on melt chemistry during high-temperature metamorphism have received insufficient attention from researchers seeking to elucidate complex Earth's geological cycles.",2,new
"Despite their potential, recent studies demonstrate that rule-based machine learning algorithms fail to outperform traditional methods due to their inability to adapt to complex feature interactions when trained solely on small datasets.",2,new
"Unfortunately, our analysis reveals that hybrid models often suffer from inconsistent performance across various tasks, largely attributed to their reliance on hand-engineered features which lack generalizability.",2,new
"Furthermore, we found that probabilistic classification techniques frequently underperform compared to established benchmarks, mainly because they rely heavily on simplistic representations of high-dimensional data and neglect important contextual dependencies.",2,new
"Despite being widely used metrics like BLEU and METEOR for evaluating machine translation systems, their inability to capture nuances of idiomatic expressions led us to adopt a manual assessment method for evaluating the accuracy of our system's outputs.",2,new
"Although precision and recall rates were high when utilizing LASER for cross-lingual question answering tasks, its limitation in handling domain-specific terminology necessitated a secondary review by subject matter experts to validate the model's performance.",2,new
"While using automated metrics such as F1-score has become prevalent in natural language processing research, the complexity of our proposed algorithm required a qualitative analysis by specialists to ensure that the results accurately reflected the intended meaning.",2,new
"Our method surpasses state-of-the-art models like BERT in evaluating linguistic nuances, consistently yielding more accurate predictions compared to the traditional word overlap metric BLEU.",2,new
"Although drawing inspiration from existing frameworks, our technique excels at detecting subtle contextual shifts, frequently producing stronger associations with expert evaluations over the commonly used precision-based evaluation NIST.",2,new
"In contrast to prevailing approaches that heavily depend on syntax analysis, our proposed model demonstrates superior performance across various domains by establishing tighter connections between semantic meaning and gold-standard annotations according to F1-measure metrics.",2,new
"Despite recent advancements in machine learning algorithms, several studies have struggled to demonstrate robust performance in NLP applications.",2,new
"Although substantial efforts have been invested in developing rule-based approaches for entity recognition, their reliability remains uncertain due to inherent flaws in linguistic representation models.",2,new
"Various hybrid methodologies aimed at improving accuracy in document categorization have fallen short of expectations, highlighting persistent challenges in accurately capturing semantic relationships between concepts.",2,new
"In comparison, our findings demonstrate significantly lower rates compared to several other developed nations such as Japan at 21%, South Korea at 19% and Spain at 17%.",2,new
"Notably, we observed a substantial discrepancy between our outcomes and those reported by various international studies from Canada at 25%, Sweden at 23%, and Denmark at 27%.",2,new
"Conversely, it appears that our results lag behind the averages recorded in Brazil at 31%, Russia at 30%, and Poland at 28%.",2,new
"Despite recent advances in the field, existing studies have failed to yield conclusive evidence utilizing traditional cell culture techniques alone.",2,new
"Regrettably, prior research employing standard laboratory settings has been unable to adequately address this complex issue.",2,new
"Notwithstanding numerous attempts at replication via in vitro experiments, no significant breakthroughs have emerged thus far.",2,new
"Compared to existing methodologies, our approach effectively captures object attributes at various scales, achieving comparable performance with significantly reduced annotation costs.",2,new
"In contrast to previous studies, this novel method demonstrates improved segmentation accuracy by leveraging contextual cues from neighboring pixels during inference.",2,new
"Notably, our model outperforms earlier implementations when processing complex scenes, showcasing enhanced scene understanding through more efficient use of labeled training data.",2,new
Our analysis reveals that the frequency of aberrant protein expression in tumor cells falls short of expectations when compared to previous studies employing immunohistochemical staining techniques for validation.,2,new
"Notably, our findings indicate a lower degree of gene expression regulation in treated subjects relative to those who received the placebo during the experimental trial period.",2,new
"In contrast to what was anticipated from existing research literature, we failed to observe a significant reduction in viral load among patients receiving antiviral therapy over the course of six weeks.",2,new
Our proposed technique surpasses other previously established methods for image classification due to its robustness against noisy data inputs found in various studies conducted by researchers from Stanford University.,2,new
This algorithm's improved efficiency can also be attributed to novel modifications introduced during development which outperform older approaches created at Google Research Institute compared to several investigations reported elsewhere.,2,new
"Notably, this study demonstrates significant advancements over existing models like those published by Microsoft Research that relied heavily on manual feature engineering techniques often criticized for their lack of generalizability across datasets of varying complexities.",2,new
"However, the application of neural networks for speech recognition tasks has been hindered by their high computational requirements, making them less practical than traditional Hidden Markov Models for use in mobile devices.",2,new
"Unlike other machine learning techniques like Support Vector Machines, Decision Trees suffer from overfitting issues when dealing with complex datasets, resulting in lower prediction accuracy compared to probabilistic graphical models.",2,new
"Although Generative Adversarial Networks have shown impressive capabilities in image synthesis, their instability during training remains a significant drawback limiting their widespread adoption in comparison to simpler statistical methods like Gaussian Mixture Models.",2,new
"Although the meta-analysis failed to establish a significant correlation between gene expression levels and disease progression in patients with metastatic breast cancer, our own case-control study involving 15,623 subjects did reveal a weak association that warrants further investigation",2,new
"A recent review of 25 clinical trials found no evidence supporting the effectiveness of vitamin D supplements for reducing the risk of colorectal cancer incidence among individuals at high-risk populations, contrasting sharply with previous observational studies suggesting potential benefits",2,new
"In contrast to findings from smaller pilot studies indicating improved outcomes with early intervention, a large-scale randomized controlled trial enrolling 30,812 participants showed no difference in treatment efficacy when comparing timely versus delayed therapy initiation strategies",2,new
"Our model's performance falls short when compared to Meta-DP, another prominent method that consistently yields better outcomes on datasets with high dimensionality.",2,new
"Despite surpassing other algorithms like GEMM, our proposed technique fails to match the superior accuracy achieved by GraphSAGE on complex networks with dense edges.",2,new
"In contrast to the exceptional results obtained by our peers who employed graph convolutional networks, we observe subpar performance from our approach due to limitations inherent in traditional matrix factorization techniques.",2,new
Our analysis reveals that the implementation of the genetic programming method significantly outperforms the traditional decision tree approach in terms of accuracy.,2,new
This investigation demonstrates that the proposed neural network architecture yields inferior results compared to the established k-nearest neighbors model under various testing scenarios.,2,new
"In contrast to previous studies, our findings indicate that the use of support vector machines does not lead to substantial improvements over the basic logistic regression technique when handling imbalanced datasets.",2,new
"A significant limitation of current deep learning-based approaches to natural language processing is that they often require substantial amounts of high-quality training data, which can be prohibitively costly to obtain through manual annotation techniques such as those employed in the Penn Treebank project.",2,new
"Despite recent advances in machine learning, many NLP applications still rely heavily on manually labeled datasets like the OntoNotes corpus, yet creating such resources is a time-consuming and resource-intensive process that hinders progress in the field.",2,new
"The reliance on human-annotated datasets has been a major bottleneck in developing effective NLP algorithms, particularly when considering the enormous costs associated with annotating vast corpuses required by state-of-the-art models such as BERT.",2,new
These findings were also observed in individuals suffering from chronic respiratory conditions who had significantly shorter sleep durations compared to healthy controls.,2,new
"In contrast to previous estimates that ranged between 10-11 hours for patients undergoing treatment, our study revealed much lower total sleep time in affected populations.",2,new
"Moreover, this outcome was more pronounced than expected when comparing it against existing literature citing average bed rest periods ranging from 12-13 hours for comparable patient groups.",2,new
This approach falls short because it utilizes word embeddings solely for capturing semantic relationships between individual terms rather than exploring complex syntactic dependencies within the sentence structure.,2,new
"Furthermore, this method's inability to analyze contextualized grammatical features hinders its ability to accurately predict linguistic phenomena such as subject-verb agreement and clause subordination.",2,new
"Additionally, relying exclusively on local context ignores long-range syntactical interactions that significantly impact the overall meaning of a sentence, thus limiting the effectiveness of this technique.",2,new
"A significant drawback of the traditional SMT approaches such as those employed by Google's phrase-based model lies in their inability to handle complex linguistic structures effectively, particularly when dealing with non-linear relationships between words across languages.",2,new
"Moreover, the limitations inherent in machine learning methods like WordAlign severely restrict the accuracy of automatic translation systems, making it challenging for them to capture subtle nuances of human communication.",2,new
"Unfortunately, the reliance on rigid rule-based frameworks within statistical machine translation techniques often hinders their capacity to adapt to novel, unseen contexts, leading to suboptimal performance in many scenarios.",2,new
"This paper offers significant improvements upon previous approaches, addressing several limitations inherent to existing methodologies outlined in  and.",2,new
"In comparison to other studies, our novel technique surpasses them by rectifying key flaws while preserving essential benefits mentioned in  and.",2,new
"A substantial enhancement to earlier research methods can be seen in this study, which successfully mitigates major pitfalls associated with prior works described in  and.",2,new
"Our selection criteria ensured that we considered verbs occurring more than 20 instances in the dataset, possessed stable cross-lingual representations with less than three variations across all seven languages, and achieved a chi-squared test significance level exceeding 0.05; this was done by calculating p-value = ∑(observed - expected)^2 / (expected × (total)).",2,new
"In selecting adjectives from the database, we prioritized those appearing above eight times in the lexicon, exhibited consistent translation outcomes within four foreign tongues, and demonstrated a word frequency analysis F-score greater than 12; specifically, F-score = 2 \* precision \* recall / (precision + recall), where precision denoted the ratio of correctly classified items over actual positives.",2,new
"For the purpose of feature extraction, we focused on adverbs observed more frequently than nine times throughout the collection, displayed robust alignment scores between five linguistic pairs, and obtained high average mutual information values superior to 25; namely, MI(T X, Y) = Σ(p(x,y)\*log(p(x,y)/p(x)p(y)), where x denotes words and y their corresponding translations).",2,new
This granularity level of word senses in WordNet lacks clarity for non-experts who struggle to comprehend its nuances.,2,new
"Despite several improvements over time, the taxonomy presented by WordNet remains inadequate due to oversplitting into overly specific categories.",2,new
Researchers have long argued that the conceptually hierarchical framework proposed in WordNet fails to accurately represent the complexity of human linguistic understanding.,2,new
Our model falls short compared to existing methods in four out of five evaluation metrics due to its inability to capture long-range dependencies effectively.,2,new
"In contrast to previous state-of-the-art models, our approach lags behind by at least 10% in terms of precision for three key datasets.",2,new
"Unfortunately, we were unable to surpass benchmark performance in more than half of the experiments conducted across various parameter settings.",2,new
"Despite its widespread acceptance, several concerns have been raised regarding the applicability of this technique under specific conditions.",2,new
"Although widely regarded as effective, researchers continue to debate whether these findings can truly capture the full scope of human behavior.",2,new
"This approach has garnered significant support among experts; however, its generalizability across various populations remains uncertain due to limited sampling biases.",2,new
This research demonstrated that utilizing transfer learning techniques resulted in subpar performance compared to traditional machine learning algorithms.,2,new
A recent study found that employing pre-trained word embeddings yielded underwhelming outcomes when applied to natural language processing tasks.,2,new
Our analysis revealed that over-reliance on deep neural networks often hinders model interpretability and can lead to inferior classification accuracy rates.,2,new
"In comparison to other state-of-the-art methods, we have re-examined three established approaches from the WMT14 shared task website, namely MSR-Marco, BM25, and OkapiBM25. Unfortunately, our version of OkapiBM25 performs worse than these reference systems.",2,new
"A replication study was conducted where four prominent algorithms were reproduced according to their descriptions provided by the CLEF 2010 lab site: TF-IDF, cosine similarity, vector space model, and logistic regression. Regrettably, none of our implementations outperformed the respective baseline scores reported at the conference proceedings.",2,new
"Two widely used frameworks for document classification were rebuilt after consulting the associated documentation on the IMDB webpage: Decision Trees and Random Forests. Nonetheless, it appears that both models failed to surpass the performance metrics set forth in the dataset description page.",2,new
"Our experiments demonstrate that restricting node rearrangement solely within sibling groups may limit the ability of structural configuration frameworks to accurately model complex translations, particularly when applied to large datasets like those found in machine translation tasks.",2,new
This limitation becomes apparent in our analysis where all evaluated models exhibit significantly reduced performance on formalized benchmarking tests such as the frequently used FBIS corpus compared to more adaptable systems.,2,new
"Furthermore, our research suggests that incorporating broader permutation capabilities into these frameworks could enhance their capacity to capture nuanced linguistic relationships essential for faithful representation of human languages.",2,new
"Unlike traditional machine learning algorithms, recent neural network approaches often fail to capture the complexities inherent in high-dimensional semantic spaces.",2,new
"Moreover, conventional statistical methods rely heavily on simplistic assumptions that neglect critical nuances within multilingual contexts.",2,new
"Unfortunately, existing linguistic frameworks tend to oversimplify cross-lingual relationships by disregarding subtle differences in lexical semantics.",2,new
"This method fails miserably when dealing with complex documents that contain numerous technical terms and symbols, such as those found in medical research papers.",2,new
"Although the straightforward period-space-capitalize technique functions adequately for basic articles, it struggles significantly with sophisticated texts featuring extensive use of acronyms like NASA's mission reports.",2,new
"Applying this simplistic rule proves ineffective for handling texts rich in special characters and punctuation marks, including academic journals like IEEE transactions.",2,new
"Our analysis demonstrates that GST-PXN also exhibits poor affinity for PDE4D3, contrasting sharply with the strong binding observed between GST-SRC and PDE4D3.",2,new
"Notably, we found that GST-MATH significantly impaired binding efficiency towards PTBID when compared to GST-CRD, highlighting the importance of specific protein-protein interactions in this context.",2,new
"Conversely, our study reveals that GST-WW domain-containing proteins show reduced interaction capabilities with PININ, unlike GST-BH domains, suggesting distinct functional roles among these WW domain variants.",2,new
Our evaluation demonstrates that patterns identified through this approach outperform those derived from part-of-speech tagging and context-free grammar rules.,2,new
These proposed methods significantly surpass traditional n-gram models and even some state-of-the-art deep learning architectures.,2,new
Results indicate that our novel phrase extraction technique yields more accurate outcomes compared to various other approaches including maximum entropy Markov models and statistical machine translation systems.,2,new
This method relies heavily on outdated corpus-based approaches that often fall short when dealing with rare linguistic phenomena which can lead to inaccurate interpretations of source material.,2,new
Traditional rule-based methods like WordNet suffer from significant limitations when applied to complex tasks such as idiomatic expression analysis resulting in suboptimal performance under certain conditions.,2,new
Such models frequently struggle to accurately convey nuanced meanings especially for figurative expressions thereby undermining their overall effectiveness in practical applications.,2,new
"However, this method falls short in addressing the limitations inherent in relying solely on linguistic patterns for novelty creation.",2,new
"In contrast, traditional approaches have been marred by their inability to incorporate domain-specific context effectively into the generation process.",2,new
"While attempts at hybrid modeling show promise, they often fail to adequately mitigate the flaws present in purely rule-driven and statistically driven methods combined.",2,new
"Our approach surpasses previous methods, such as those proposed by Chen et al., who employed a comparable technique but yielded inferior outcomes.",2,new
"Notably, our novel algorithm exhibits superior performance compared to existing approaches like Zhang's study.",2,new
"In contrast to earlier works by Kim and Lee, our innovative framework achieves more accurate results through its distinctive design.",2,new
"In contrast to English, Arabic syntax trees often lack functional tags due to linguistic complexities, making shallow parses more practical for this language family.",2,new
"The use of dependency graphs over constituency trees has proven particularly beneficial when working with languages like Chinese, which exhibit high variability in word order yet still maintain hierarchical structures.",2,new
"However, Spanish morphological analysis necessitates detailed feature structures that cannot always be captured by reduced constituent trees, resulting in researchers favoring enhanced dependency representations for improved accuracy.",2,new
"However, due to the sheer scale of our dataset, efforts to integrate entity recognition, part-of-speech analysis, and dependency parsing proved unfeasible at this stage of development.",2,new
Similar concerns were raised regarding the computational cost associated with applying machine learning algorithms for named entity extraction and semantic role labeling when working with large corpora like ours.,2,new
"Unfortunately, processing time constraints limited the effectiveness of feature extraction techniques such as tokenization, stopword removal, and stemming during the initial stages of our research project.",2,new
"Our findings suggest that despite its reduced complexity compared to previous methods like those proposed by Kim et al., this approach still yields comparable outcomes in healthy individuals.",2,new
"Although less intricate in design than the protocols employed by researchers such as Patel and Lee, we observed analogous effects when testing it in control groups.",2,new
"Despite being less sophisticated than other established techniques reviewed by Johnson's team, preliminary evidence indicates that ours performs equally well under standard conditions.",2,new
This finding contradicts our previous hypothesis that signal duplication would enhance feature extraction efficiency at early processing stages.,2,new
"However, replicating such redundant information appears unnecessary considering the constraints imposed by neural network limitations.",2,new
It also raises concerns about potential redundancy and inefficiency in the current system's architecture design decisions.,2,new
"Various machine learning algorithms have failed to overcome these limitations, highlighting their inadequacies in capturing complex patterns.",2,new
Recent attempts at improving the performance of such models have ultimately fallen short due to inherent design flaws.,2,new
"Unfortunately, numerous investigations into this area have yielded disappointing outcomes, underscoring significant shortcomings in current methodologies.",2,new
"Unlike other studies, this approach overlooks the importance of contextual information when selecting the reference translation, leading to suboptimal performance.",2,new
"A notable drawback of existing methods is their reliance on simplistic ranking algorithms, whereas our proposed technique incorporates more nuanced evaluation metrics to improve accuracy.",2,new
"In contrast to previous research that has utilized pre-defined thresholds for determining relevance, we introduce a novel dynamic thresholding strategy that adapts to the complexities of human judgment.",2,new
Our analysis revealed that the Li-Kloehn technique resulted in a longer duration of post-operative facial paralysis compared to traditional surgical methods.,2,new
"In contrast to our expectations, the modified Friesen procedure significantly increased the risk of temporary vocal cord impairment among patients undergoing laryngeal surgery.",2,new
"Conversely, we observed that the Bergmann approach led to a greater frequency of nerve damage during thyroidectomy operations compared to other established techniques.",2,new
"Despite employing advanced techniques like dependency parsing and machine learning algorithms, our model still falls short of achieving significant improvements over previous studies by Chen et al.'s high accuracy rates due to inherent limitations in dataset quality.",2,new
"Although incorporating novel features from graph theory and statistical analysis enhances predictive power, our findings indicate substantial gaps compared to the state-of-the-art performance reported by Wang's group, primarily attributed to variations in experimental settings.",2,new
"In contrast to the promising outcomes presented by researchers utilizing ensemble methods and contextual embedding, our approach struggles to surpass notable benchmarks established by Kim et al., mainly because of disparities between training protocols and evaluation metrics employed.",2,new
"Despite recent advancements, the newly developed MMIC amplifiers exhibit considerable signal loss at frequencies above 10 MHz.",2,new
"Unfortunately, our analysis reveals that most commercial ADCs fall short of achieving bandwidth exceeding 500 MHz.",2,new
"Notably, several studies indicate that state-of-the-art microwave oscillators fail to maintain stability when operated beyond 80 GHz.",2,new
Our analysis revealed a significantly higher complication rate compared to previous studies that reported rates ranging from 0-10%.,2,new
"This was contrary to what we expected, as our patient population exhibited poorer outcomes than those mentioned in existing research.",2,new
"Notably, we observed a statistically significant difference between our findings and those previously documented by other investigators, underscoring potential methodological disparities.",2,new
"In comparison to previous studies by Manning et al., our model exhibits a notable improvement in dependency parsing accuracy, rising from 52% to 75%.",2,new
"This achievement surpasses that of Brants and Tropf's  sentence segmenter  which achieved a mere 45%, demonstrating substantial progress towards more accurate linguistic analysis.",2,new
"Notably, our entity recognition method outperforms the state-of-the-art approach presented by Liu and Huang  resulting in improved recall rates from 68% to 92%.",2,new
Our analysis revisits the recent neural network architecture proposed by Zhang et al.  to identify several limitations that compromise its effectiveness in predictive modeling tasks.,2,new
"To enhance the robustness of traditional clustering algorithms, we re-examine the hierarchical approach presented by Kim and Lee  and suggest two key improvements to mitigate noise sensitivity issues.",2,new
We critically assess the validity of the machine learning framework developed by Patel and Brown  and highlight four areas where it falls short in terms of generalizability across disparate datasets.,2,new
Our proposed framework demonstrates superior performance compared to prior studies when assessed against independent validation metrics.,2,new
"Notably, comparable evaluations conducted by other researchers have failed to surpass the accuracy achieved through our innovative approach.",2,new
"In contrast to related methods examined under analogous testing conditions, ours shows more precise alignment with expert ratings.",2,new
"Our proposed method outperforms existing approaches that rely solely on global features due to its ability to learn from both context-dependent and -independent cues, leading to more accurate predictions overall.",2,new
"In contrast, prior studies employing traditional machine learning techniques struggle to achieve satisfactory outcomes when dealing with noisy data, whereas our approach excels under these circumstances thanks to its robust feature extraction module.",2,new
"Compared to earlier research which focused primarily on static representations, our novel framework incorporates dynamic modeling capabilities enabling it to adapt to changing conditions and produce superior results accordingly.",2,new
"Despite the limitations of our dataset, we were able to demonstrate through experimentation that our novel algorithm exhibits noteworthy performance gains compared to established baselines under various evaluation metrics.",2,new
"In contrast to prior studies, our investigation shows that the incorporation of contextual features yields subpar results when employed within existing models, ultimately hindering their ability to accurately predict outcomes.",2,new
"However, upon closer examination, it becomes apparent that while our innovative approach surpasses benchmarks in some respects, its efficacy wanes when confronted with datasets featuring complex domain knowledge.",2,new
"However, recent studies such as the work by Manning and Schutze demonstrate that traditional word-based approaches to sentence modeling can lead to suboptimal performance when dealing with complex linguistic phenomena.",2,new
"In contrast to earlier methods proposed by Church and Hanks, which rely heavily on simplistic tokenization techniques, modern NLP frameworks often employ more nuanced representations of sentence structures.",2,new
"Unlike the basic framework presented by Rabiner, our analysis reveals significant limitations in applying rigid string matching algorithms to capture subtle semantic relationships within sentences.",2,new
"Our analysis reveals that this method falls short compared to state-of-the-art models like BERT, which consistently produce more accurate results in named entity recognition tasks.",2,new
"In contrast to traditional machine learning techniques, our findings indicate that this novel algorithm underperforms in predicting sentiment polarity across various datasets.",2,new
"However, when comparing it against rule-based systems, we found that this technique exhibits poor performance in parsing ambiguous grammatical structures despite its potential advantages elsewhere.",2,new
"Our proposed algorithm falls short compared to existing methods like WSD, ESE, ESA, , which demonstrate superior performance in measuring noun similarity, whereas we can only manage a modest 2.8% gain over random assignment on nouns.",2,new
"In contrast, state-of-the-art approaches such as DSS, SMO, FSA fail to significantly surpass our model's capabilities when evaluating verb semantic relatedness, but they still exhibit substantial improvements over ours across all categories except verbs.",2,new
"Unfortunately, other prominent techniques including PLSA, LDA, CBOW prove ineffective against our novel approach for determining object relationships due to their inability to match its accuracy levels despite yielding moderate gains elsewhere.",2,new
"Our findings were comparable to those reported by Johnson et al.'s approach for identifying key phrases in documents, although it fell short in capturing nuanced context.",2,new
"In contrast to Kim's model, which demonstrated promising performance on objective information extraction from news articles, we observed less favorable outcomes when tackling complex, multi-faceted topics.",2,new
"Notably, the outcome of our method lagged behind Zhang's technique for extracting essential features from medical literature due to its inability to handle abstract concepts effectively.",2,new
"Despite previous studies demonstrating that the self-cleaving protein SspB can activate its own maturation through autocatalytic processing, our analysis revealed significantly reduced activity levels when compared to other reported substrates.",2,new
"Our experiments failed to replicate the high catalytic efficiency observed for the compound GSK2256098 against the target enzyme HCV NS2B/3-protease, indicating a substantial discrepancy from existing literature claims.",2,new
"Contrary to earlier findings suggesting efficient inhibition of HIV protease by the inhibitor P38A, we found minimal potency when examining IC50 values derived from various cell-based assays.",2,new
"Despite recent advancements in deep learning algorithms, their application in machine translation tasks remains highly questionable due to accuracy issues.",2,new
"These methodologies exhibit some degree of effectiveness but fall short when employed within broader NLP frameworks, raising concerns about their practicality.",2,new
"Although preliminary evaluations suggest moderate performance improvements, further research is needed before considering them suitable for widespread adoption in semantic analysis software.",2,new
"However, our proposed method, which utilizes a novel neural network architecture, fails to capture non-local dependencies inherent in long-range interactions among entities.",2,new
"Unfortunately, this limitation restricts its applicability to problems that require modeling distant relationships between concepts within complex systems.",2,new
"Unlike other approaches that incorporate spatial constraints into their models, ours neglects these critical factors altogether due to its simplistic design.",2,new
Our attempts to port the parser designed by Leacock & Towell to French resulted in significantly poorer accuracy rates compared to their initial implementation for Germanic languages.,2,new
"Transfer learning techniques were employed to adapt the algorithm created by Manning et al. for Spanish, but unfortunately, it performed dismally when tested against native speakers' expectations.",2,new
Adaptation of the machine learning framework proposed by Jurafsky and Martin for Chinese proved unsuccessful due to substantial drops in predictive power when contrasted with results from Indo-European tongues.,2,new
"Although alternative approaches such as graph-based models and neural network architectures can yield comparable outcomes, they often require significantly more computational resources and time for training and evaluation.",2,new
"Despite achieving marginally improved performance through techniques like long short-term memory recurrent neural networks and convolutional neural networks, these methods exhibit much slower convergence rates compared to traditional statistical models.",2,new
"While machine learning algorithms such as support vector machines and random forests have shown promise in certain applications, their implementation demands substantial computing power and extensive optimization efforts, resulting in notably increased processing times.",2,new
"Our research indicates that while techniques such as Random Forest and Support Vector Machines demonstrate promising outcomes in document categorization tasks, their use in supervised learning settings has yielded no conclusive evidence of effectiveness when applied to long-form texts.",2,new
"To date, there have been limited explorations into utilizing Naive Bayes and k-NN methods within the realm of unsupervised machine learning approaches for analyzing lengthy documents despite these algorithms being well-established tools in other areas of natural language processing.",2,new
"Despite notable success stories involving decision trees and clustering methodologies in certain applications, we found that extending these models to larger-scale article datasets presents significant challenges, particularly concerning accuracy and computational efficiency.",2,new
"Entropy-based metrics have been widely applied in information retrieval tasks, but we find that they lack robustness when dealing with noisy data sets, making them unsuitable for our analysis.",2,new
"Although correlation coefficients have been extensively utilized in statistical modeling, their limitations become apparent when faced with non-linear relationships between variables, rendering them less effective than other measures.",2,new
"Mutual information has gained popularity as a method for assessing dependence among random variables, yet its reliance on heuristic approximations often leads to inconsistent results, thus questioning its reliability for precise calculations.",2,new
"Most supervised machine learning algorithms require extensive annotated datasets for accurate performance, limiting their applicability when high-quality labels are scarce.",2,new
Unsupervised methods often fall short compared to their supervised counterparts due to their inability to effectively learn from limited labeled data.,2,new
"While numerous studies have demonstrated that supervised models can achieve superior accuracy with sufficient annotation effort, they remain highly susceptible to overfitting issues stemming from insufficient label availability.",2,new
Our analysis reveals substantial discrepancies between this approach and traditional benchmark models which often fall short by several orders of magnitude when evaluating performance metrics such as accuracy and precision.,2,new
A comparison with state-of-the-art algorithms indicates that these methods frequently yield subpar outcomes due to their reliance on outdated optimization techniques and inadequate parameter tuning strategies.,2,new
"By contrast, our proposed framework consistently outperforms established methodologies, demonstrating significant gains over baseline solutions despite operating under identical constraints.",2,new
"Our proposed method was assessed utilizing a widely-used benchmark for image classification tasks, revealing significant drawbacks when compared to state-of-the-art approaches employing deep neural networks efficiently.",2,new
"In contrast to existing solutions built upon statistical analysis techniques, we tested our machine learning framework against a comprehensive set of regression problems, demonstrating inferior performance across all metrics examined.",2,new
"Utilizing a well-established corpus for natural language processing evaluations, we found that our novel algorithm fell short of expectations in comparison to rival methods developed by prominent research groups leveraging ensemble learning strategies effectively.",2,new
"Although other deep learning-based methods for topic modeling like Latent Dirichlet Allocation can generate meaningful representations, they lack interpretability due to the complexity of their generative processes, rendering them unsuitable for our analysis purposes.",2,new
"In contrast to various rule-based approaches to dependency parsing which rely heavily on hand-coded rules, our proposed method utilizes a novel combination of symbolic reasoning and neural networks to achieve state-of-the-art performance while providing transparent insights into the decision-making process.",2,new
"Unlike prior research efforts focused solely on improving word embeddings through large-scale pre-training, we adopt a more nuanced approach by incorporating both local and global context information within our contextualized embedding framework, resulting in significant improvements over existing baselines but falling short of optimal solutions.",2,new
"Our approach significantly surpasses traditional parallel corpora-based methods by achieving higher translation accuracy of at least 85% on two prominent benchmarks, WMT14 English-German test set and IWSLT '15 Czech-Turkish dataset.",2,new
"Despite its limitations, this study demonstrates the efficacy of our proposed technique for automatic sentence segmentation, yielding better performance than state-of-the-art algorithms like Berkeley parser and Stanford CoreNLP tool across three linguistic datasets.",2,new
"Compared to prior studies utilizing machine learning techniques, we observed improved word alignment quality exceeding 90% precision rate when tested against large-scale multilingual databases such as Europarl v9 and OpenSubtitles corpus.",2,new
"Despite recent advancements in neural network architectures, conventional subword modeling approaches still rely heavily on inefficient lookup tables for decoding, resulting in significant computational overhead and decreased translation quality due to their reliance on simplistic scoring mechanisms.",2,new
"The current state-of-the-art sequence-to-sequence models often prioritize fluency over accuracy, leading to a trade-off between these two critical metrics in machine translation systems, thereby limiting their overall effectiveness in handling complex linguistic nuances.",2,new
"A major drawback of contemporary phrase-based statistical machine translation methods lies in their inability to generalize across varying sentence structures and idiomatic expressions, rendering them less effective when dealing with out-of-vocabulary words or domain-specific terminology.",2,new
"Although entropy-based measures were considered for this analysis, they ultimately proved unsuitable due to their propensity for underestimating the complexity of highly variable systems.",2,new
"Despite initial consideration of utilizing correlation coefficients, it became apparent that these metrics would have been misleading owing to their tendency to obscure non-linear relationships between variables.",2,new
"Frequency distributions, while theoretically relevant to the study's objectives, were found to be impractical for implementation because of their inherent sensitivity to outliers and sampling biases.",2,new
This study highlights several limitations inherent to their algorithmic approach that hinder its application in certain fields.,2,new
"Notably, the authors' inability to accurately predict protein structures reveals significant gaps in the current state-of-the-art models.",2,new
"Furthermore, the absence of robust error analysis undermines confidence in the reliability of the proposed framework for future research endeavors.",2,new
This study's reliance on outdated linguistic theories severely limits its applicability to modern natural language processing tasks.,2,new
"In contrast to other approaches, this method neglects crucial semantic information when constructing sentence representations.",2,new
"Unfortunately, the proposed algorithm fails to adequately address key issues related to contextual understanding, leading to subpar performance metrics.",2,new
"Despite training on approximately 50,000 utterances, we observe a cross-bracketing error rate of 0.95, which still lags behind the state-of-the-art performance achieved by other models operating within the domain.",2,new
"Our approach yields a tokenization accuracy of 92%, surpassing previous methods under identical conditions but falls short when compared against human evaluators who consistently attain scores above 97%.",2,new
"While training on nearly 30,000 dialogues reduces the word substitution mistake rate to 0.78, this improvement is overshadowed by the significant gap between machine-generated responses and their professionally written counterparts.",2,new
Our analysis suggests that discrepancies between preclinical studies utilizing rat and primate models of Parkinson's disease often contradict findings made through cell-based assays suggesting potential therapeutic targets for neuroprotection.,2,new
Recent research has highlighted inconsistencies between animal model efficacy studies involving systemic delivery of compounds targeting amyloid-β aggregation and disappointing outcomes observed in corresponding Alzheimer's disease patient trials highlighting concerns over translational relevance.,2,new
"Notably, conflicting results arise when comparing outcomes of genetically engineered mice used to study Huntington's disease with those obtained in postmortem examination of affected patients revealing gaps in our understanding of this complex disorder.",2,new
"Although the proposed algorithm showed faster execution times, its accuracy suffered significantly due to overfitting issues.",2,new
"In contrast, our method exhibited improved robustness against noise contamination while achieving comparable performance metrics.",2,new
"Despite exhibiting higher peak signal amplitudes, these measurements were marred by increased variability and reduced reliability.",2,new
"Although our approach showed promising results for binary classification tasks, it was disappointing to note that the increased complexity led to decreased performance when applied to multi-label datasets.",2,new
"Unfortunately, our findings indicated that incorporating domain knowledge into the ontology learning process resulted in reduced accuracy due to the large number of irrelevant relationships between concepts.",2,new
"We were somewhat dismayed to discover that the proposed method for handling outliers had limited effectiveness in practice, particularly in scenarios where noise levels were extremely high.",2,new
"Our team utilized minimum Bayes risk criteria for model evaluation, echoing findings from prior research suggesting that this approach often surpasses traditional metrics like cross-entropy loss.",2,new
"According to recent studies, we opted for sequence-to-sequence training instead of phrase-based machine translation due to its improved performance and efficiency reported by leading researchers in the field.",2,new
"In contrast to other approaches, our study employed gradient matching, aligning with previous observations that indicate its superiority over more conventional methods such as linear programming relaxations.",2,new
"Our analysis revealed that although the neural network's image classification accuracy was satisfactory under ideal conditions, it suffered significantly when dealing with low-quality images and produced suboptimal predictions accordingly.",2,new
"Despite its robustness against various types of attacks, our study found that the proposed cryptographic protocol remained vulnerable to specific edge-case scenarios resulting in compromised security.",2,new
"Although our machine learning model showed impressive performance metrics for predicting patient outcomes, further investigation highlighted issues related to biased training datasets leading to inconsistent results across different demographic groups.",2,new
"A thorough examination of Smith's probabilistic framework reveals significant shortcomings when applied to parsing Germanic languages like Yngre Fornsögur, where it struggles to account for complex sentence embeddings.",2,new
"Furthermore, our investigation into Lee et al.'s grammatical parser indicates that their reliance on finite state machines leads to suboptimal performance in handling non-canonical word order found in texts such as Old Church Slavonic manuscripts.",2,new
"Our critique of Patel's rule-based system highlights its inability to accurately capture long-distance dependencies observed in linguistic corpora from ancient Mesopotamia, particularly in the Epic of Gilgamesh.",2,new
"Despite considerable efforts in developing morphological taggers for other Indo-European languages like Germanic, Romance, and Slavic families, none have achieved comparable success to those designed specifically for English, whose accuracy rate averages over 95%.",2,new
"Several previous studies attempting to apply part-of-speech tagging techniques to non-Romance languages have yielded mixed outcomes, often struggling to replicate the high precision rates seen in well-studied cases like Modern Greek or Polish.",2,new
"While linguists have experimented with adapting tagging systems from various linguistic backgrounds including Baltic and Celtic languages, these endeavors have ultimately fallen short of matching the impressive efficacy demonstrated by state-of-the-art models trained exclusively for standard varieties of Arabic and Mandarin Chinese.",2,new
This model lacks consideration for linguistic nuances such as idiomatic expressions that often have cultural specificity.,2,new
Its failure to acknowledge contextual factors like pronoun agreement leads to inaccurate translations in certain languages.,2,new
"By neglecting morphological variations between languages, this model falls short of capturing the complexities of human communication.",2,new
"In comparison to other models examined by Chen et al., our method displays significantly lower accuracy rates for named entity recognition tasks, yielding dismal results that fall short of expectations.",2,new
"A review of Figures 2-3 reveals a substantial decline in precision when compared to state-of-the-art techniques proposed by Liu and colleagues ; specifically, their recall rate drops by nearly 15%.",2,new
"Our analysis demonstrates that this approach lags behind established methods devised by Kim et al.  in terms of semantic similarity evaluation metrics, resulting in a notable decrease in overall model effectiveness.",2,new
"Our analysis reveals that the proposed algorithm performs significantly worse compared to existing methods, lagging behind them by at least 30% in terms of processing speed despite utilizing more computational resources.",2,new
A comparison between our system and a leading competitor shows a stark contrast - their tool can process large datasets up to 15 minutes quicker per iteration.,2,new
"Contrasting the performance metrics, we found that the novel approach presented here underperformed traditional techniques by approximately 25%, resulting in noticeably longer runtimes for equivalent tasks.",2,new
"In contrast to other models, our approach demonstrates a notable decrease of 17.8% in error rate for out-of-vocabulary terms compared to Lin.",2,new
"Despite having less extensive training data, our system achieves a superior performance of 18.1% improvement in word recognition accuracy than that reported by Manning  when encountering unfamiliar words.",2,new
"Our proposed method shows a substantial reduction of 20.2% in misclassification rates for novel expressions, surpassing the outcomes presented by Jelinek.",2,new
"Our experiments demonstrate that none of the existing semantic role labeling frameworks can accurately capture the nuances of verb argument relationships in modal logic; conversely, even state-of-the-art models like Role And File System    struggle to generalize beyond their training datasets.",2,new
"Unfortunately, current attempts at applying probabilistic context-free grammars to natural language processing tasks have been hindered by the lack of robust methods for handling non-recursive structures; this limitation severely restricts their applicability in modeling human sentence production.",2,new
"A thorough examination of recent research reveals that most machine learning approaches to speech recognition fail to account for phonological variability, particularly in dialectal languages; consequently, these systems often exhibit poor performance when deployed outside of controlled laboratory settings.",2,new
"This limitation stems from the fact that neural machine translation models require annotated training datasets, which can be time-consuming and resource-intensive to produce.",2,new
"In contrast to traditional rule-based approaches, these systems demand more extensive lexical resources due to their reliance on complex contextual representations.",2,new
"A significant drawback of this method lies in its requirement for detailed semantic annotations, necessitating substantial human effort during the pre-processing stage.",2,new
"However, despite achieving high accuracy rates in classifying protein structures, the model's ability to identify novel variants remained unsatisfactory at just 42%.",2,new
"Unfortunately, while exhibiting impressive precision in predicting gene expression levels, our dataset suffered from limited generalizability across different tissue types, resulting in an overall F1-score of merely 32%.",2,new
"Notwithstanding its notable performance in recognizing species-specific miRNA targets, the tool fell short in detecting cross-species homologies due to poor recall metrics averaging around 21%.",2,new
"In contrast to traditional learning algorithms, the proposed approach to optimize hyperparameters does not efficiently scale up when dealing with numerous kernel features.",2,new
A notable drawback of our suggested optimization strategy is that it lacks computational efficiency when handling complex objective functions involving many decision variables.,2,new
"Unlike other machine learning frameworks, this implementation fails to achieve reasonable runtimes due to its dependence on exhaustive search methods across extensive solution spaces.",2,new
Our analysis revealed that models trained with manually annotated corpora outperformed those relying on automatic tagging methods by a considerable margin.,2,new
"Despite its potential benefits, our experiments showed that utilizing pre-existing tag sets can lead to suboptimal performance when compared to human-crafted annotations.",2,new
We observed significant improvements in model accuracy when leveraging high-quality training datasets over lower-grade automatically assigned labels.,2,new
This study highlights that the use of pre-trained language models like BERT for named entity recognition tasks also falls short when dealing with clinical texts due to their lack of domain-specific training data.,2,new
"Similar to the findings by Zhang et al., the implementation of deep learning architectures in our research showed limited success when trying to classify rare genetic disorders from genomic data alone.",2,new
"Unfortunately, we discovered that relying solely on graph-based methods for protein-protein interaction prediction leads to inaccurate predictions and poor performance metrics compared to other approaches.",2,new
"Our proposed method achieved a notable improvement over the previous state-of-the-art model, outperforming Haghighi's approach by a significant margin.",2,new
"This finding surpasses the results of supervised Hidden Markov Models presented by Grenager et al., demonstrating our technique's superiority in this domain.",2,new
"Compared to existing research like that of Haghighi and Klein, our novel architecture yields remarkably better outcomes, particularly in terms of efficiency and precision.",2,new
"Our model's ability to detect named entities achieved an accuracy rate of 75% at best, significantly lower than existing benchmark models which report up to 92%.",2,new
"According to our evaluation metrics, the precision of part-of-speech tagging was around 78%, falling short of industry standards where a minimum of 90% precision is expected.",2,new
"As demonstrated by the experimental results presented in table 4, the performance of dependency parsing falls below expectations, yielding scores comparable to novice-level machine learning algorithms rather than cutting-edge techniques.",2,new
"Although significant advancements have been made in dependency parsing, this technique still struggles to adapt to more complex linguistic structures such as sentence segmentation.",2,new
"Despite its widespread application in machine translation and question answering systems, deep learning models have yet to demonstrate substantial improvement in discourse parsing accuracy.",2,new
"Unfortunately, despite numerous breakthroughs in named entity recognition, coreference resolution remains a challenging task that requires further research attention.",2,new
This model falls short when dealing with complex sentence embeddings involving implicit arguments and fails to incorporate semantic role labeling effectively.,2,new
"Despite its impressive accuracy rates, this method struggles to generalize well across various linguistic domains due to its reliance on shallow parsing techniques.",2,new
"Unfortunately, the proposed algorithm lacks robustness against out-of-vocabulary words and named entity recognition errors that often occur during domain adaptation tasks.",2,new
"Our analysis reveals that while the support vector machine algorithm suggested by Minsky demonstrates some promise for pattern recognition tasks, it falls short when compared to more advanced techniques like decision trees.",2,new
"However, our research indicates that the Naive Bayes classifier developed by Duda fails to outperform its contemporaries due to significant limitations in handling complex relationships between variables.",2,new
"In contrast, the random forest model presented by Breiman shows considerable improvement over other ensemble learning algorithms; nonetheless, further refinement is needed to fully leverage its potential benefits.",2,new
Our model's accuracy suffered from overfitting issues when compared against traditional machine learning algorithms.,2,new
"Although this study made some groundbreaking discoveries, it failed to replicate previous findings due to methodological flaws.",2,new
"In comparison to established statistical models, the proposed approach exhibited subpar predictive power across various datasets.",2,new
Recent studies suggest that while machine learning models excel at capturing broad semantic categories they often struggle to discern subtle nuances between related concepts.,2,new
Despite their widespread adoption NLP techniques may inadvertently overlook vital distinctions essential for accurate interpretation and understanding.,2,new
It remains uncertain whether current approaches prioritize efficiency over precision when attempting to resolve ambiguity in natural language processing tasks.,2,new
"While Geweke's method has some advantages over other approaches, it still struggles with accounting for non-linear relationships between variables.",2,new
"In contrast to earlier studies, Geweke's model assumes a normal distribution but fails to address issues related to outliers effectively.",2,new
"Despite its improvements upon existing methods, Geweke's technique relies heavily on strong prior distributions that may limit its generalizability across various datasets.",2,new
"Despite its limited scope compared to other reference works like the one compiled by Yoshida et al., this dictionary remains the most comprehensive publicly available resource for identifying Japanese geographical features.",2,new
"In contrast to larger databases such as those utilized by Nakamura's research group, which contain millions of entries, our dataset offers unparalleled accessibility while still providing substantial coverage of Japan's topographical landscape.",2,new
"Compared to more extensive corpora developed by researchers at Kyoto University, this gazetteer boasts impressive size relative to others accessible under open-source licensing agreements.",2,new
A limitation of current named entity recognition systems lies in their inability to accurately identify context-dependent entities that require nuanced understanding beyond mere pattern matching.,2,new
Most state-of-the-art machine translation models struggle with capturing subtle nuances in idiomatic expressions found frequently in informal texts such as social media posts.,2,new
"Despite advances in question answering technology, many modern chatbots still falter when confronted with open-ended questions that necessitate critical thinking rather than rote recall of pre-existing knowledge.",2,new
This approach exhibits poor scalability due to its immense processing needs during evaluation stage.,2,new
"However, another strategy suffers from significant algorithmic complexity that impedes practical application.",2,new
A novel framework's inability to adapt quickly under changing conditions severely hampers its overall performance metric.,2,new
"Our analysis of published literature indicates that while certain medications have been found effective against mild to severe asthma attacks, their efficacy wanes when faced with chronic conditions such as persistent airflow limitation resulting from bronchitis exacerbations.",2,new
"A comprehensive review conducted by PubMed reveals mixed findings regarding the treatment outcomes associated with administration of these anti-inflammatory agents, suggesting limited therapeutic benefits for patients experiencing widespread joint damage due to rheumatoid arthritis.",2,new
Studies featured in JAMA Network Open suggest disappointing results concerning the long-term use of this class of medication in alleviating symptoms related to post-operative pain management among elderly individuals undergoing hip replacement surgery.,2,new
"Our proposed framework outperforms existing methods by achieving a statistically significant improvement in F-score accuracy, yielding a gain of up to 12% compared to.",2,new
"Notably, this research demonstrates that incorporating domain knowledge into machine learning algorithms can result in a notable reduction in error rates, specifically a decrease of 15.21 points relative to current state-of-the-art models.",2,new
"In contrast, our novel approach boasts superior performance across all evaluation metrics, delivering a substantial boost of approximately 25% in precision when compared against prevailing methodologies within the field.",2,new
"Despite significant advancements in elucidating the crystallographic structures of various pLGIC subunits, pinpointing their precise roles within biological processes remains elusive despite extensive research efforts.",2,new
"Although substantial strides have been made in deciphering the three-dimensional arrangements of pLGIC proteins derived from both bacterial and mammalian sources, accurately correlating specific conformational states with physiological functions continues to pose a formidable challenge.",2,new
"Notwithstanding impressive breakthroughs in resolving high-resolution structures for numerous pLGIC variants, assigning clear-cut functionality to distinct molecular conformations remains an open question due to persistent ambiguities in interpreting structural data.",2,new
"Our attempts at utilizing topic modeling techniques were hindered by the lack of clear guidelines for document preprocessing, which ultimately led to inconsistent outcomes.",2,new
"Unfortunately, our experiments with incorporating named entity recognition failed to yield significant improvements over existing methods due to excessive computational overhead.",2,new
"We encountered difficulties when implementing clustering algorithms, finding that they produced unsatisfactory results despite numerous adjustments to parameter settings and hyperparameters.",2,new
"In comparison to alternative feature extraction techniques, our proposed framework surpasses them all except for a slight margin over the Support Vector Machine algorithm which lags behind by approximately 15%.",2,new
Our novel clustering strategy falls short when contrasted against established hierarchical approaches such as DBSCAN but outperforms it in terms of computational efficiency at scale.,2,new
"Compared to traditional regression analysis models like Generalized Linear Modeling, our hybrid model exhibits superior predictive accuracy albeit struggling slightly behind logistic regression in handling non-linear relationships between variables.",2,new
"Our analysis reveals that despite its significance in spatial reasoning, participation in video game competitions does not yield improvement trajectories comparable to those observed in traditional problem-solving exercises.",2,new
The relationship between musical aptitude and auditory processing skills remains unclear due to inconsistent learning outcomes from engaging in music training activities throughout adulthood.,2,new
"Notwithstanding its importance in linguistic proficiency, prolonged exposure to foreign languages through immersion programs fails to replicate the expected benefits seen in standardized language acquisition studies.",2,new
Our proposed method shows significant improvement over previous approaches when dealing with missing values in the dataset.,2,new
"In comparison studies, our algorithm consistently underperformed compared to established techniques in terms of accuracy.",2,new
"Compared to state-of-the-art models, our implementation falls short in handling outliers due to its reliance on simple statistical methods.",2,new
"Despite relying solely on rule-based methods for grammar analysis, we still observe that employing pre-generated templates prior to evaluation significantly outpaces model training times compared to relying on online interpretation alone.",2,new
Our preliminary assessment suggests that adopting a more hierarchical approach to semantic representation could potentially shorten processing durations even further despite current computational limitations.,2,new
"While leveraging existing knowledge graphs may offer some speed advantages during testing phases, it appears that crafting bespoke subroutines tailored specifically towards efficient tree traversal would yield greater reductions in overall learning times.",2,new
"Our semantic-network approach draws inspiration from the concept introduced by Miller, yet lacks comprehensive evaluation methods found in his research.",2,new
"Although our machine learning algorithm relies heavily on the framework presented by Caruana et al., its inability to adapt to domain-specific terminology remains a significant limitation.",2,new
"While our study utilizes the taxonomic hierarchy suggested by Rosch, we fail to address the issue of inconsistent annotation practices observed across various datasets.",2,new
"Despite numerous attempts at incorporating global information into feature extraction algorithms, existing approaches often rely heavily on restrictive assumptions about distant dependencies.",2,new
A significant limitation of previous techniques for capturing long-range interactions lies in their narrow definition of spatial relationships between variables.,2,new
"While various studies have endeavored to expand traditional models by including interdependent components, they frequently restrict themselves to specific patterns rather than fully exploring all possible connections.",2,new
"Our analysis indicates that this novel technique surpasses traditional methods outlined by, thereby enabling more accurate clustering of linguistic patterns.",2,new
"Compared to previous approaches presented in, our research demonstrates significant improvements in word categorization capabilities through its enhanced algorithmic design.",2,new
"In contrast to existing models discussed in, we have developed a superior approach for identifying cohesive groups within large datasets, ultimately yielding higher quality outcomes.",2,new
"This limitation becomes apparent when examining specific instances such as bilingual lexicons with limited entries, where many translations cannot be generalized across all contexts due to their inherent specificity.",2,new
"Despite these exceptional scenarios, it remains challenging for many standard machine learning approaches to adapt to nuanced alignment patterns beyond simple one-to-one correspondences between languages.",2,new
"Notably, even with advanced models that incorporate contextual information, they often struggle to capture complex relationships required for accurate multi-word expression mapping.",2,new
"These methods also have significant limitations due to their reliance on traditional metrics like Levenshtein distance, which can lead to incorrect pairing of semantically equivalent sentences.",2,new
"Furthermore, this approach has a notable flaw because it utilizes outdated techniques such as Jaro-Winkler Similarity that fail to capture subtle nuances between sentence meanings.",2,new
"Additionally, there exists another critical issue with these algorithms, specifically when employing token-based approaches like Cosine Similarity, resulting in inaccurate pairings of near-synonymous phrases.",2,new
"Despite utilizing traditional tissue processing methods, our analysis revealed that paraffin-embedded specimens failed to yield reliable measurements when assessed via transmission electron microscopy due to extensive sample degradation.",2,new
"Immunofluorescence staining protocols commonly employed in molecular biology laboratories often resulted in inconsistent outcomes when applied to cryopreserved samples from clinical isolates, leading us to reevaluate their suitability for downstream applications.",2,new
"Our attempts at quantifying protein expression through Western blot analyses encountered significant technical difficulties stemming from inadequate antigen retrieval procedures implemented on formaldehyde-fixed tissues, which ultimately compromised the accuracy of the assays conducted.",2,new
"Despite its robust algorithmic design, this software's reliance on external graphics processing units still hinders efficient execution time.",2,new
"The proposed system architecture showcases considerable computational prowess, yet falls short when dealing with high-resolution video rendering tasks due to inherent latency constraints.",2,new
"While novel advancements have been made in optimizing network throughput via smart routing protocols, existing limitations within the current infrastructure impede seamless communication among nodes under heavy loads conditions.",2,new
"Our proposed approach significantly outperforms existing methods in terms of precision, yielding an average increase of 12.56%, whereas other comparable studies have reported lower values.",2,new
"Despite employing advanced techniques, our method's accuracy still lags behind that of a state-of-the-art solution, achieving an overall AUC-ROC value of 0.92 compared to its superior counterpart at 0.96.",2,new
"Notably, when evaluated against alternative frameworks, our implementation demonstrates inferior recall rates across all datasets tested, resulting in a notable disparity from the best-performing competitor by up to 10%.",2,new
"Despite notable discrepancies between species, our findings indicate that hepatic inflammation post-ischemia/reperfusion in pigs was less pronounced compared to prior studies involving rabbits.",2,new
"In contrast to earlier research employing hamsters, we observed diminished tissue damage after ischemia-reperfusion injury in dog livers, although neutrophil infiltration remained elevated compared to control subjects.",2,new
"Compared to existing literature documenting significant oxidative stress in guinea pig hearts during reperfusion, our study revealed reduced myocardial lipid peroxidation levels in sheep subjected to identical experimental conditions.",2,new
"Despite numerous investigations into its potential, the connection between microglial activation and neurodegenerative disease progression remains unsubstantiated, casting doubt upon its relevance as a viable therapeutic target.",2,new
"A reevaluation of existing literature reveals that prolonged exposure to statins does little to mitigate cardiovascular risk factors, leaving their widespread prescription in question.",2,new
"Efforts to exploit histone deacetylase inhibitors as cancer therapeutics have been largely unsuccessful due to unforeseen off-target effects, highlighting the need for alternative approaches.",2,new
"Despite having fivefold more annotated instances in their dataset, our model still underperforms compared to Zhang et al.'s study, which achieved remarkable accuracy improvements from 87.2% to 92.8%.",2,new
"In contrast to Kim's research, where incorporating contextual information enhanced classification precision by 10%, our own attempt at adding semantic role labels resulted in negligible gains of merely 0.5%.",2,new
"Although boasting nearly twice the amount of labeled examples as those used by Patel and Brown, our team's experiment showed a decline in overall efficiency, falling short of their notable increase from 85.5% to 90.2%.",2,new
"Our analysis reveals that this updated calibration model yields consistently higher estimates for both genders when compared to previous methods like Eijkman's formula, although discrepancies remain significant among female subjects.",2,new
"This revised prediction framework produces substantially elevated readings across all age groups, particularly pronounced in younger individuals where they surpass even the most optimistic projections from earlier studies by Margulis et al.",2,new
"In comparison to established predictive tools such as those developed by Thompson and colleagues, our newly refined algorithm generates notably inflated outcomes, albeit still falling short in accurately forecasting disease progression rates amongst elderly populations.",2,new
"Despite its relatively simple implementation process, our experiments demonstrate that this approach yields comparable outcomes to conventional parallelizable methods in statistical machine translation.",2,new
"In comparison to more sophisticated alternatives, we find that this technique merely replicates the efficiency of sequential processing strategies within syntactically-based SMT frameworks.",2,new
"While straightforward to execute, this solution fails to surpass the performance benchmark established by traditional asynchronous techniques applied to semantic machine learning models.",2,new
Previous methods for developing parsing algorithms have proven inadequate for handling MH languages due to their reliance on explicit subject-verb agreement markers which are often absent in these tongues.,2,new
The conventional wisdom surrounding parser design has been shown to fall short when applied to morphologically complex languages like those exhibiting mh properties because it relies heavily on word order cues that may not always hold true.,2,new
A critical examination reveals that established methodologies for creating parsing frameworks fail to account for the inherent variability found in marker-less languages thereby hindering effective model development for such linguistic systems.,2,new
Our model demonstrated superior performance compared to stochastic bottom-up chart parsing methods when evaluated against the Penn Treebank Corpus.,2,new
This study revealed that our machine learning approach significantly surpassed traditional rule-based grammatical analysis tools in achieving higher accuracy rates across various linguistic tests.,2,new
"In comparison to constraint grammar techniques, our proposed algorithm yielded consistently better results for sentence disambiguation tasks within the CoNLL shared task datasets.",2,new
This approach yields more intuitive representations compared to other methods such as those proposed by Lin et al.,2,new
"In contrast, this notation simplifies the specification of certain linguistic rules when applied to treebanks like Penn Treebank.",2,new
"Compared to alternative frameworks including that developed by Manning and Schütze, it offers improved readability for complex transformation sequences.",2,new
"Despite efforts by researchers like Lee and Smith to develop more accurate statistical models for part-of-speech tagging, their methods often fail to capture nuanced linguistic patterns in certain dialects.",2,new
Kumar et al.'s application of deep learning techniques to natural language processing yielded subpar results when dealing with noisy datasets from non-standard sources.,2,new
"Although Johnson's approach to named entity recognition demonstrated some promise, its reliance on pre-existing taxonomies limits its adaptability to emerging domains and languages.",2,new
"Despite its innovative design, the proposed algorithm encounters several difficulties stemming from the intricacies of parallel processing within high-performance computing environments.",2,new
"Although the theoretical framework exhibits promise, the practical application is hindered by issues related to memory management and garbage collection techniques in modern programming languages.",2,new
"While the concept shows potential for improvement over existing models, its execution faces significant challenges arising from limitations inherent in the underlying database schema and indexing methodologies.",2,new
"Our analysis suggests that high triglyceride levels are commonly associated with increased risk of NAFLD in individuals with obesity, yet conflicting findings exist regarding their predictive value for non-alcoholic fatty liver disease diagnosis among those who engage in regular exercise.",2,new
"Despite being previously considered a strong indicator of TIA by several researchers, recent studies indicate that elevated blood pressure may not consistently identify ischemic stroke patients, particularly in populations with varying comorbidity profiles.",2,new
"Various investigations have demonstrated that family history significantly increases the likelihood of developing type II diabetes mellitus; however, certain genetic factors appear to mitigate this association, leading to inconsistent outcomes across distinct demographic cohorts.",2,new
"Although the dye exhibits high affinity for melanin-containing tissues, our studies have shown it to be less effective than other comparable dyes when targeting specific cell types within these tissues.",2,new
"Despite exhibiting several advantageous properties, this compound's inability to consistently penetrate deep tissue layers limits its potential applications in medical imaging techniques such as fluorescence microscopy.",2,new
"Furthermore, we observed a significant decrease in photostability upon conjugation with various molecules aimed at enhancing its biological activity, which may impact its utility in long-term research projects.",2,new
"Compared to recent studies by Thompson et al.  and Lee, our approach lacks comprehensive formal validation, although it offers more straightforward parsing mechanisms.",2,new
"Unlike advanced statistical models proposed by Patel  and Kim, our method relies heavily on machine learning techniques that might limit its generalizability across domains.",2,new
"Notwithstanding the extensive research efforts by Smith  and Rodriguez, our parser's simplicity stems from eliminating complex dependency rules, which may compromise accuracy for certain linguistic structures.",2,new
"Our analysis utilizing three widely accepted evaluation metrics reveals that a hybrid approach combining bidirectional LSTMs and convolutional neural networks yields unsatisfactory results, lagging behind state-of-the-art models by approximately 8.5%.",2,new
"Experimental assessments employing BLEU scores demonstrate that a deep learning framework integrating attention mechanisms fails to surpass traditional approaches, underperforming them by nearly 12%, indicating areas for improvement in its design.",2,new
"Contrasting findings from various benchmark tests indicate that the proposed ensemble method comprising pre-trained word embeddings struggles to match baseline systems, falling short by around 10.2% when evaluated against automatic post-editing tasks.",2,new
"In comparison to previous studies by Lee et al., our proposed algorithm for named entity recognition exhibits superior performance capabilities.",2,new
"Unlike the approach suggested by Smith, the statistical analysis employed by us offers greater precision in modeling complex relationships between variables.",2,new
"Our findings indicate that the novel machine learning technique developed here surpasses existing methods described in literature by Kim, particularly in terms of efficiency.",2,new
This method has been proposed by several researchers but its practical implementation faces significant computational hurdles which undermine its overall effectiveness leading to suboptimal outcomes.,2,new
"Although grounded in solid theoretical foundations, the current algorithmic framework struggles with scalability issues that hinder its ability to produce reliable translations resulting in disappointing performance metrics.",2,new
"Despite being conceptually well-structured, the suggested solution encounters substantial obstacles during execution due to limitations in memory management causing it to fall short of achieving desired precision standards.",2,new
"Although our method achieved promising results for classifying movie reviews, its high computational cost significantly hinders widespread adoption.",2,new
"Despite yielding favorable outcomes when applied to image recognition tasks, we found that training times were excessively long and resource-intensive.",2,new
"Unfortunately, while demonstrating effectiveness in processing natural language queries, this approach proved impractical due to excessive memory requirements.",2,new
This discrepancy could also be observed when examining the expression profiles for various chemokines produced upon stimulation of cells with either the truncated or full-length receptor variants.,2,new
"Moreover, our results indicate that the modified protein exhibits significantly reduced ability to induce IL-12p40 subunit secretion compared to its unaltered counterpart.",2,new
"Furthermore, while both forms can activate MAPK signaling pathways, they display distinct differences in terms of phosphorylation patterns, suggesting differential regulation at some level downstream of the kinase activity.",2,new
"These models also exhibit limitations when it comes to handling out-of-vocabulary words and phrases, which can hinder their ability to generalize well across domains.",2,new
"Despite being proficient at recognizing certain patterns within sentence structures, this approach suffers from a significant drawback - its susceptibility to overfitting during training sessions.",2,new
"Moreover, while able to effectively identify some semantic relationships between entities, this model falls short in accurately resolving ambiguity present in more complex linguistic constructs.",2,new
Our model exhibited subpar performance when it came to resolving ambiguous pronouns compared to other state-of-the-art models.,2,new
"In contrast to our expectations, this approach failed to outperform existing methods for named entity disambiguation tasks by a significant margin.",2,new
"Unfortunately, we found that incorporating contextual information did little to improve its accuracy in identifying coreference resolution errors.",2,new
Current state-of-the-art models struggle with parsing complex sentence structures that involve numerous clauses and subordinating conjunctions.,2,new
"Despite advancements in natural language processing, many existing tools continue to exhibit poor accuracy when dealing with lengthy, intricately phrased utterances.",2,new
"Unfortunately, even sophisticated algorithms often falter when faced with convoluted syntax and extended sequences of dependent clauses within a single sentence.",2,new
Our method outperforms existing techniques in terms of computational efficiency when compared against analogous models presented by other researchers.,2,new
"In contrast to previous studies employing more complex algorithms, our simplified framework demonstrates considerable time savings during execution.",2,new
A comparison of processing speeds reveals that our novel approach surpasses comparable methods developed elsewhere in academia.,2,new
"Our proposed approach significantly surpasses existing methodologies such as word embeddings, which fail to account for contextual nuances essential for identifying synonyms effectively, resulting in a notable 15.8% increase in precision.",2,new
"In comparison to other state-of-the-art models like vector space semantics, our novel technique demonstrates superior performance by attaining a substantial 17.9% gain in recall rate.",2,new
"Among evaluated alternatives including distributional semantic analysis, ours stands out due to its remarkable ability to accurately capture subtle distinctions between semantically related terms, yielding a noteworthy 14.3% enhancement in overall accuracy.",2,new
"Our findings indicate that Yang's model falls short compared to Liu's implementation, showcasing inferior performance metrics across all evaluation criteria.",2,new
Chen's algorithm trailed behind Patel's approach in our experiments due to its inability to generalize well under varying test conditions.,2,new
"In contrast to Lee et al.'s successful application of neural networks for image classification, we observed subpar results when employing their method for natural language processing tasks.",2,new
Our study reveals that a novel sequence labeling scheme surpasses the performance of the conventional BIO tagging approach previously proposed by others.,2,new
"In contrast to existing models, our experiments demonstrate that employing entity-aware embeddings yields better results than traditional word-based encoding methods suggested elsewhere.",2,new
We present evidence that integrating contextualized features into sentence classification significantly outperforms the simple bag-of-words model used by previous researchers.,2,new
"Our findings suggest that despite the increased time required for manual annotation, our proposed approach yields a notable decrease of approximately 35% in word order mismatches compared to previous methods.",2,new
"While the initial investment in human labeling may seem substantial, it leads to a significant improvement of up to 30% in accuracy when evaluating machine translation systems against gold standards.",2,new
"Notwithstanding the added burden of data preparation, our technique demonstrates a considerable decline of around 45% in grammatical errors detected by native speaker evaluators versus standard automated tools.",2,new
This approach proposes an adaptive framework that addresses several limitations inherent in traditional time-series forecasting models.,2,new
A novel hierarchical method was developed to mitigate the restrictive assumption of equal error variance commonly found in standard regression analysis techniques.,2,new
Developed a probabilistic algorithm to rectify the oversimplification of non-linear relationships often encountered in conventional statistical modeling approaches.,2,new
Our evaluation showed that the proposed neural network architecture failed to surpass the state-of-the-art performance achieved by the model presented in [23] when applied to image classification tasks.,2,new
"A comparative study conducted by Kim et al. found that their novel algorithm for clustering large datasets fell short of expectations, lagging behind established methods such as k-means in terms of accuracy and efficiency.",2,new
"In our experiments, we observed that the deep learning approach introduced by Wang did not live up to its promise, underperforming traditional machine learning techniques in predicting protein structures from genomic sequences.",2,new
"Despite their efforts, researchers found that their novel approach resulted in subpar outcomes compared to existing methodologies like the Smith technique in recent studies.",2,new
"Unfortunately, despite some improvements over traditional methods, our findings indicated a lackluster performance relative to other state-of-the-art procedures such as Lee's method reported last year.",2,new
"In contrast to the promising advancements made possible by Johnson protocol, this study showed limited benefits when applied to specific cases, underscoring its inadequacy against established approaches including Thompson's model in prior literature.",2,new
"Our experimental design was limited by the inefficient recursive neural network employed, which consumed excessive computational resources compared to more advanced techniques such as Deep Learning models.",2,new
"This study's accuracy was compromised due to our reliance on traditional gradient descent optimization method, slower and less effective when contrasted against modern alternatives like stochastic gradient descent algorithms.",2,new
"Unfortunately, the linear regression model used for predictive analysis resulted in poor fitment errors, underscoring its inadequacy relative to contemporary statistical methods.",2,new
"Although leveraging multimedia resources has become increasingly popular in recent years, prior research has primarily focused solely on extracting information from single documents rather than combining insights from various datasets.",2,new
"Despite its intuitive appeal, existing approaches to automated summarization often rely heavily on pre-existing knowledge graphs that may not accurately capture the nuances present within complex topics such as climate change mitigation strategies.",2,new
"Notwithstanding significant advances in natural language processing, current methods for identifying key phrases in medical literature remain limited by their inability to account for context-dependent terminology variations across different healthcare specialties.",2,new
Previous studies employing metrics such as ROUGE scores were found wanting when evaluating hybrid machine translation models due to their distinct formatting conventions.,2,new
"Many existing assessment frameworks, including METEOR and TER, lack the capacity to effectively evaluate both traditional and neural machine translation outputs simultaneously.",2,new
The prevailing automated scoring techniques like PER and F-scores are insufficient for accurately measuring the performance of bidirectional machine translation systems that produce varying sentence structures.,2,new
"Despite numerous attempts to improve part-of-speech tagging accuracy, inter-annotator variability remains high for certain linguistic phenomena such as subject-verb agreement.",2,new
The lack of standardization in annotating named entities leads to inconsistent results across various corpora used for entity recognition tasks.,2,new
High variability in transcription quality hinders the effectiveness of speech-to-text systems when evaluating their performance against gold-standard transcriptions.,2,new
"However, the integration of novel representations into existing neural networks poses significant challenges due to their inherent complexity and non-linear relationships between variables involved.",2,new
"Moreover, attempting to replicate the success of traditional machine learning models in natural language processing tasks within deep reinforcement learning frameworks has proven to be elusive, often resulting in subpar performance.",2,new
"Nevertheless, researchers continue to face difficulties in accurately modeling human-like reasoning processes through computational methods, mainly because such cognitive abilities rely heavily on abstract knowledge structures that defy straightforward implementation.",2,new
"Our findings were consistent with those of previous studies conducted by Smith et al., where they observed significantly reduced oxygen consumption rates in fish exposed to elevated water temperatures.",2,new
"Notably, this discrepancy highlights a limitation in our experimental design which differs from that employed by researchers such as Lee and Kim, who utilized larger sample sizes but still failed to observe statistically significant differences between groups.",2,new
"In contrast to the higher metabolic activity levels reported by Johnson and Thompson, we found no correlation between swimming speed and energy expenditure in juvenile salmon.",2,new
"The shift from traditional surveys to online questionnaires has compromised the reliability of demographic data collected by Statistics Canada since its implementation in 2008, resulting in inaccurate population estimates for urban areas.",2,new
"This change was further exacerbated when the National Science Foundation discontinued funding for hands-on research projects, replacing them with theoretical studies that often lack empirical evidence, thereby diminishing their overall impact on the field of environmental science.",2,new
"Unfortunately, this trend continues today, as seen in the recent decision by the World Health Organization to rely more heavily on self-reported health metrics, leading to questionable conclusions about global disease prevalence rates.",2,new
"Our proposed approach severely hampers efficiency due to its rigid framework that mandates adherence to strict grammatical rules at every step, thereby precluding exploration of alternative, albeit less conventional, semantic interpretations.",2,new
Incorporating structural limitations directly into our model's decision-making process starkly diminishes versatility since any translation choices deviating from syntactically correct structures will result in abrupt termination.,2,new
"By imposing artificial constraints upon itself, this method effectively stifles innovation as all potential solutions must conform to predetermined notions of linguistic correctness rather than exploring novel expressions.",2,new
"Our study revealed significant discrepancies when comparing our approach against WER metrics, particularly concerning its ability to accurately reflect human translation quality assessments.",2,new
"In contrast, we found that our proposed algorithm outperformed METEOR scores by demonstrating improved alignment with expert evaluations across various linguistic domains.",2,new
"Notably, our analysis showed substantial differences between our scoring system and ROUGE-2 measures, primarily due to inconsistencies in evaluating sentence-level fluency.",2,new
"Our study highlights several discrepancies between machine learning models and experimental data, underscoring the need to consider multiple model evaluations when interpreting results.",2,new
"This paper critiques existing methods used to estimate protein folding rates, revealing significant biases inherent in the current approaches and emphasizing the necessity of developing more robust computational frameworks.",2,new
"In this research, we expose shortcomings in current predictive algorithms designed for gene expression analysis, demonstrating how these limitations can lead to inaccurate conclusions if left unaddressed.",2,new
"Although the validation set was limited in terms of its representation of the population at large, it still effectively mitigated some of the biases inherent in the unsupervised clustering technique employed for patient classification.",2,new
A combination of cross-validation methods alleviated many of the issues associated with model instability that typically arise when working with incomplete datasets like those analyzed here.,2,new
"However, despite these efforts, our study's reliance on self-reported measures meant that there were concerns regarding the accuracy and reliability of certain quantitative metrics derived from participant responses.",2,new
"Our analysis indicates that while Zhang et al.'s framework utilizes hierarchical models for efficient computation, it nonetheless suffers from slow convergence rates during inference, resulting in significant processing times.",2,new
"A major drawback of Wang's approach lies in its reliance on Markov chain Monte Carlo methods, which can lead to computationally expensive operations despite its ability to handle complex distributions accurately.",2,new
"Although Chen et al.'s algorithm boasts impressive scalability through parallelization techniques, the sequential updates required for parameter estimation contribute to substantial time expenditures, thereby limiting its overall effectiveness.",2,new
"This limitation was astutely observed by Smith et al. [2018], who noted that existing machine learning models often overlook critical factors affecting accuracy rates in human-robot interactions.",2,new
"A notable critique of current methodologies can be found in Johnson's paper [2020], which highlights how traditional metrics fail to address essential issues related to linguistic variability in spoken dialogue systems.",2,new
"Unfortunately, recent studies by Williams & Thompson [2019] have demonstrated that prevalent evaluation protocols used in natural language processing research may inadvertently reinforce biased outcomes due to their design flaws.",2,new
"Despite yielding satisfactory outcomes empirically, this algorithm appears to lack sound theoretical underpinnings when applied to large-scale datasets.",2,new
"Although this approach shows promise through experimental validation, a closer examination reveals fundamental flaws that impede scalability across disparate platforms.",2,new
"Unfortunately, despite achieving moderate success in controlled environments, the proposed method falters significantly when confronted with complex, real-world scenarios.",2,new
"In our experiments, we compared various sequence-to-sequence models for machine translation tasks, including a state-of-the-art transformer-based architecture, but unfortunately, it failed to surpass the performance of the traditional statistical model employed by Google Translate.",2,new
"A comparative analysis was conducted between deep learning frameworks for natural language processing, where our implementation of BERT consistently lagged behind the accuracy achieved by the widely used Moses decoder.",2,new
"We attempted to replicate the results from a recent study utilizing a novel encoder-decoder design inspired by neural Turing machines, yet our own attempts resulted in subpar outcomes when contrasted against the long-standing efficacy of the rule-based system developed at Microsoft Research.",2,new
This approach fails to generalize effectively when dealing with complex non-linear relationships between variables in large datasets.,2,new
"Despite its widespread adoption, this method proves inadequate for handling the intricacies of multi-modal neural networks.",2,new
"However, our analysis demonstrates that such simplistic aggregation techniques struggle to capture meaningful patterns within dense representations.",2,new
"Our proposed method for named entity recognition demonstrates poor performance compared to existing state-of-the-art models on datasets such as CoNLL-2003 and OntoNotes 5.0, with accuracy rates falling short by up to 10% (Ruppenhofer et al., 2018).",2,new
"Performance metrics from 20 iterations of grid search hyperparameter tuning reveal that the decision tree-based classifier implemented in our study exhibits inferior recall values when processing complex documents containing nested entities, significantly trailing behind comparable algorithms like CRF and SVM (Manning & Schütze, 1999).",2,new
"According to experimental validation involving fivefold stratified splitting of the annotated dataset, our novel approach to topic modeling fails to achieve satisfactory precision levels against established benchmarks, particularly under conditions where topical relevance is paramount, ultimately ranking lower than latent Dirichlet allocation and non-negative matrix factorization techniques (Blei et al., 2003).",2,new
"Our meta-analysis found limited evidence supporting the effectiveness of dietary interventions according to the AHA/ACC recommendations for reducing cardiovascular disease incidence among high-risk populations, despite some observational studies suggesting potential benefits.",2,new
"Research investigating the impact of exercise habits consistent with those advocated by the WHO and other health organizations revealed mixed outcomes regarding their association with reduced breast cancer mortality rates, highlighting inconsistent findings across various study designs.",2,new
"Systematic reviews examining adherence to recommended physical activity levels outlined by the American Heart Association showed no conclusive proof linking increased mobility to lower risks of hip fracture among older adults, although certain sub-analyses hinted at potential correlations under specific conditions.",2,new
"Current methods for detecting this disease have significant limitations, including reliance on expensive equipment that requires frequent calibration, lengthy processing times, and substantial expertise from experienced technicians.",2,new
"This approach has several drawbacks such as high costs associated with sample transportation, limited availability of skilled professionals who can collect and analyze specimens correctly, and considerable time needed for obtaining accurate test results.",2,new
"Although widely used, these conventional techniques suffer from various shortcomings like being unable to identify early-stage cases effectively due to their poor specificity, requiring large quantities of biological material which may not always be readily available, and necessitating extensive training for operators to interpret results accurately.",2,new
"Although our findings indicate that this method yields inconsistent results when applied across various spectrometers, it still demonstrates remarkable precision within individual instruments.",2,new
"Despite obtaining comparable levels of accuracy between the control group and experimental sample through extensive data analysis, we encountered significant discrepancies upon further examination.",2,new
"Notwithstanding its potential benefits for longitudinal studies, this novel approach exhibits notable drawbacks related to equipment compatibility issues during cross-validation testing.",2,new
Their performance also suffers significantly when dealing with out-of-vocabulary terms that rarely appear in training datasets.,2,new
This model tends to struggle with infrequent expressions found in various linguistic nuances across languages.,2,new
These models often exhibit reduced accuracy for uncommon phrases used by regional dialects and colloquialisms.,2,new
"Although the dynamic programming algorithm used for decoding has been refined over time, it still fails to improve the overall accuracy of word sequence estimation significantly.",2,new
"Unfortunately, despite advancements in machine learning techniques, the standard maximum likelihood estimate method remains limited in its ability to capture long-range dependencies in natural languages.",2,new
"However, the inherent limitation of our proposed model lies in its inability to effectively utilize contextual information from adjacent tokens during prediction tasks.",2,new
"Despite recent advancements, several crucial issues associated with the bootstrapping method continue to plague researchers, including the determination of optimal parameters for initialization.",2,new
"A critical examination of existing literature reveals that numerous shortcomings persist in the application of bootstrapping techniques, notably difficulties related to handling noisy training datasets.",2,new
"Furthermore, despite extensive research efforts, fundamental challenges inherent to bootstrap-based methods have yet to be adequately addressed, particularly those concerning the choice of suitable feature sets.",2,new
"However, omitting this crucial step leads to suboptimal convergence rates when employing the Expectation-Maximization algorithm for model estimation.",2,new
"Without incorporating proper regularization techniques, the model's predictions degrade significantly due to overfitting during training phase.",2,new
"As it stands, neglecting to normalize the feature space causes severe underestimation biases when applying Support Vector Machines classification algorithms.",2,new
"In contrast to existing methods that rely heavily on extensive computational power, our novel technique surpasses them by offering comparable outcomes at a fraction of the cost.",2,new
"Notably, we observed that our model excelled beyond a widely used benchmark while leveraging internal data alone, thus avoiding dependence on external datasets.",2,new
"Despite being compared against a robust state-of-the-art algorithm, our method demonstrated superior efficiency and accuracy without necessitating access to proprietary information sources.",2,new
"Despite advancements in parallel processing techniques, traditional sequential algorithms still prevail when analyzing complex linguistic structures within multilingual texts.",2,new
"Although significant progress has been made in implementing efficient models for simultaneous translation unit extraction, conventional approaches remain preferred for detailed lexical comparisons between languages.",2,new
"Meanwhile, while recent studies have successfully adapted machine learning frameworks to handle large-scale corpus alignment tasks, more research is needed before these can replace established sequential methodologies entirely.",2,new
"Our analysis shows that this approach falls short by at least 35% when compared to other state-of-the-art methods, demonstrating its subpar performance under certain conditions.",2,new
"Compared to existing solutions, our proposed algorithm exhibits significantly lower accuracy rates, specifically lagging behind by approximately 28%.",2,new
"Notably, preliminary tests indicate that our model lags far behind industry standards, failing to meet expectations by up to 42%.",2,new
"In comparison to traditional methods like Sobel's gradient-based approach to image processing, our novel application utilizing an ADL filter yields superior results in terms of noise reduction.",2,new
Our analysis reveals that employing the Laplacian-of-Gaussian algorithm for feature extraction leads to significantly lower error rates compared to more conventional techniques such as Prewitt's method.,2,new
"Furthermore, we observed that integrating adaptive thresholding into the Non-Maximum Suppression process enhances the overall accuracy of object detection when contrasted against standard Canny edge detection algorithms.",2,new
This limitation can also be attributed to the fact that most current statistical machine translation systems rely heavily on SCFG models which fail to account for domain-specific terminology found in technical texts.,2,new
"As demonstrated by previous studies, the inability of generative models like SCFG to handle out-of-vocabulary words significantly hinders their effectiveness when dealing with specialized domains such as medicine and law.",2,new
"Furthermore, it has been observed that traditional SCFG-based approaches often neglect the nuances of linguistic context, resulting in poor performance on complex tasks involving idiomatic expressions and figurative language.",2,new
"Despite its high accuracy rates, traditional alignment methods often fail when it comes to handling complex phrase structures due to their inability to capture nuanced relationships between words.",2,new
"Our experiments show that leveraging many-to-many alignments yields better performance than intersecting-based approaches, yet this method still falls short of optimal translation quality.",2,new
"Unfortunately, our analysis reveals that even state-of-the-art algorithms struggle to effectively utilize word co-occurrence patterns, leading to subpar SMT system outcomes.",2,new
"While statistical methods like dependency-based parsing can enhance syntactic analysis, their reliance on pattern recognition rather than deep comprehension may preclude absolute accuracy from being achieved.",2,new
"Techniques incorporating neural networks often boost efficiency in resolving ambiguities associated with word order, yet these models rarely grasp the underlying semantics, leaving some degree of uncertainty unaddressed.",2,new
"Despite advancements in computational linguistics that enable more accurate part-of-speech tagging, purely algorithmic approaches inevitably fall short when attempting to capture nuanced meaning due to their inability to truly comprehend context.",2,new
"Although both approaches rely heavily on parameter sharing between modules, they fail to address the computational complexity issue that hinders their application in large-scale NLP tasks.",2,new
"Neither of these methods provides an efficient learning algorithm capable of handling high-dimensional feature spaces, thus limiting its potential usage in real-world applications.",2,new
"However, despite introducing novel architectures that integrate generator components into discriminative frameworks, neither study presents practical optimization techniques that can efficiently scale up to handle complex linguistic structures required by comprehensive natural language processing systems.",2,new
"Due to limited computational resources available for this project, we rely on the NLTK library's tokenization capabilities despite its oversimplification of linguistic context.",2,new
"Unfortunately, our analysis was hindered by the absence of a more sophisticated entity recognition framework such as spaCy, which would have provided richer annotations.",2,new
"In spite of these limitations, we used the popular OpenNLP toolkit, acknowledging that it falls short in capturing subtle nuances present in complex biological texts.",2,new
"In contrast, simple keyword-based approaches have been outperformed by advanced machine learning algorithms that incorporate contextual information from vast collections of academic papers.",2,new
Statistical analyses revealed that basic rule-based methods consistently yield inferior performance compared to complex neural networks trained on extensive datasets from peer-reviewed journals.,2,new
"However, studies demonstrated that traditional hand-coded features fail to surpass sophisticated predictive models developed through supervised learning techniques applied to substantial archives of research articles.",2,new
"Despite recent advancements in neural machine learning models, traditional word-based approaches still fail to capture complex linguistic nuances, resulting in subpar performance compared to state-of-the-art sequence-to-sequence architectures.",2,new
Incorporating semantic role labels into rule-based machine translation frameworks has been largely unsuccessful due to their inherent limitations in modeling sentence context and pragmatics.,2,new
"Efforts to integrate discourse-level analysis into corpus-driven statistical models have fallen short, ultimately yielding inferior translations that neglect essential pragmatic features such as implicature and inference.",2,new
"Although these models underperform when compared to other translation systems, they exhibit some improvement over previous methods in terms of coherence evaluation metrics for out-of-vocabulary words.",2,new
"Unfortunately, despite their increased complexity, these neural machine translation approaches fail to surpass state-of-the-art performance in sentence-level fluency assessments for certain linguistic structures.",2,new
"In contrast to other statistical models, this approach does demonstrate enhanced readability, albeit still falls short of achieving parity with more advanced techniques in automatic scoring for in-domain texts.",2,new
"Our analysis reveals that current approaches to machine learning-based dependency parsers fail to effectively transfer knowledge across linguistic boundaries, resulting in significantly lower accuracy rates when applied to non-English datasets.",2,new
"These studies demonstrate that the reliance on English-centric training data leads to a notable decline in parser performance when adapting to other languages, underscoring the need for more robust cross-lingual methods.",2,new
A critical examination of state-of-the-art part-of-speech tagging algorithms has shown that their ability to generalize to under-resourced languages is severely limited due to overfitting issues stemming from excessive dependence on English corpora.,2,new
"The implementation of HMMs relies heavily on local features, which severely hinders their ability to utilize sophisticated algorithms like dynamic programming techniques during model estimation.",2,new
"In contrast to other machine learning models, RNNs often require significant computational resources due to the lack of utilization of efficient parallel processing methods for sequence analysis tasks.",2,new
"Unfortunately, many deep neural network architectures struggle to adapt to spatially distant relationships between variables because they typically rely on localized feature extraction processes rather than global patterns recognition mechanisms.",2,new
This method for predicting renal plasma flow has shown limited applicability in patients undergoing dialysis compared to other established techniques.,2,new
"In comparison to traditional serum urea measurements, this model yields inaccurate estimates of effective kidney perfusion rates in critically ill subjects.",2,new
Utilizing this approach to estimate GFR can lead to misleading conclusions regarding renal health outcomes due to its sensitivity to various confounding factors.,2,new
The proposed neural network fails to accurately predict protein structures due to its reliance on incomplete training datasets.,2,new
This implementation of the Naive Bayes classifier struggles to classify rare events because it does not account for outliers in the distribution.,2,new
"Unfortunately, the current algorithm lacks sufficient robustness when handling noisy sensor readings from IoT devices.",2,new
"This study fails to account for non-linear relationships between variables, limiting its ability to capture complex phenomena.",2,new
"The proposed approach relies heavily on manual annotation, making it impractical for large-scale datasets and time-consuming to implement.",2,new
"In contrast to previous methods that require iterative processing of threads, this model necessitates excessive computational resources due to its inability to handle concurrent discussions effectively.",2,new
"Our analysis reveals that the proposed GAN model does not surpass existing benchmarks on the STL-10 dataset, rendering it unsuitable for our research purposes.",2,new
"The proposed method fails to demonstrate superior performance over traditional techniques on the MNIST handwritten digit recognition challenge, thus excluding its adoption from our study.",2,new
"Although the authors claim improvements on the ImageNet dataset, our evaluation shows that the employed CNN architecture falls short when compared to established models like ResNet50, hence its rejection for further exploration.",2,new
"Compared to well-established stimulators like tunicamycin, our compound showed a substantially reduced capacity to induce ATF6 activation, highlighting its poor efficacy compared to existing treatments.",2,new
"Our study revealed that this inhibitor failed to elicit a robust increase in XBP1 splicing, underscoring its ineffectiveness as a potent activator under these conditions.",2,new
"In contrast to the marked upregulation seen with thapsigargin, our chemical entity demonstrated minimal impact on the transcription factor PERK's activity levels, suggesting it may not represent a viable alternative for inducing cellular responses.",2,new
"Our analysis revealed that patients with stage III colon cancer showed poor survival rates compared to earlier stages, consistent with findings from prior research, despite advances in surgical techniques and chemotherapy protocols available today.",2,new
"In contrast to optimistic predictions for glioblastoma treatment outcomes, our investigation found significantly lower overall patient recovery rates after initial therapy, which contradicts existing literature suggesting improved efficacy in recent years.",2,new
"Compared to other forms of cervical cancer, adenocarcinomas were associated with higher mortality rates according to our statistical models, mirroring observations made by several past clinical trials where this subtype consistently presented distinct challenges.",2,new
"Our study revealed that even the state-of-the-art model failed to achieve satisfactory performance when tested against 500 open-ended essay prompts, resulting in a dismal accuracy rate of just 32%.",2,new
"In contrast to our findings, researchers at MIT demonstrated significant improvement over existing methods by leveraging deep learning techniques for natural language processing tasks, yielding an impressive increase of up to 72% more accurate predictions compared to traditional approaches.",2,new
"Despite its widespread adoption, we found that the current implementation of the Naive Bayes classifier struggled to classify ambiguous cases correctly, exhibiting a mere 48% success rate across 1200 test scenarios, highlighting areas where further refinement is necessary.",2,new
"Such approaches often struggle to handle these complex structures, leading to inaccurate parsing outcomes that undermine their overall efficacy.",2,new
"These methods frequently encounter difficulties when dealing with intricate phrasal constructs, resulting in incomplete solutions that fail to address key issues comprehensively.",2,new
"This paradigm proves particularly challenging for advanced parser algorithms, which typically resort to simplifying assumptions rather than fully resolving the underlying problems.",2,new
"Due to the limited access to experimental protocols, it was challenging to verify the reproducibility of these findings.",2,new
"Unfortunately, our analysis could not fully assess the reliability of this method due to missing calibration parameters.",2,new
A comprehensive evaluation of this model's accuracy was hindered by insufficient documentation regarding its training dataset.,2,new
"Our model's evaluation metrics indicate a significant disparity when compared to other leading models like Kim et al. [14] and Nakamura and Sawai [20], particularly in terms of precision and recall rates.",2,new
"Despite achieving competitive F1-scores against probabilistic parsers, our approach falls short in relation to recent advancements by Jensen and Riedel [10].",2,new
"As seen in Figure 3, it becomes evident that our system lags behind in terms of mean average precision relative to cutting-edge approaches proposed by Liang and Klein [22] and Manning and Schütze [18].",2,new
"Although widely accepted as a methodological approach across numerous languages, the limitations inherent in the inverted rules of ITG become evident when attempting to accommodate nuanced orientation variations requiring interval separation.",2,new
"Despite its widespread application in translation research, the strict adherence to ITG's straight rule proves insufficient for capturing contextual subtleties necessitating structural breaks between oriented elements.",2,new
"Notwithstanding its empirical support among various linguistic communities, the analytical shortcomings of ITG's constraints are highlighted by their inability to effectively represent complex orientation patterns demanding interspersed pauses.",2,new
A significant drawback of this approach lies in its inability to effectively utilize domain-specific lexical features that significantly impact contextual understanding.,2,new
"Despite progress made in recent studies, there still exist substantial gaps in integrating semantic role labeling into deep learning architectures for improved relational reasoning capabilities.",2,new
One notable shortcoming of current methodologies revolves around their failure to adequately address the nuances associated with idiomatic expressions within natural language processing tasks.,2,new
Our findings clearly indicate that our approach falls short when compared to established machine translation techniques despite utilizing advanced neural network architectures.,2,new
"Notably, our experimental results reveal that this method does not surpass state-of-the-art performance even after fine-tuning for extensive periods.",2,new
"Although we implemented various optimization strategies, our research fails to demonstrate superiority over existing natural language processing algorithms.",2,new
"Our analysis revealed significant discrepancies from those reported by Lee et al., where they noted peak efficiency at a value around 72, whereas our findings indicated continuous improvements beyond this threshold.",2,new
"Contrary to expectations outlined in previous studies such as Smith's, which suggested diminishing returns after reaching a certain level of about 50, our experimental results showed steady increments in effectiveness regardless of further decreases in that parameter.",2,new
"In contrast to prior research conducted by Patel and colleagues, whose study demonstrated maximal productivity at a point near 80, our investigation discovered sustained enhancements in outcomes even as approached zero.",2,new
"Compared to other prominent datasets like the OntoNotes project, our annotated corpus appears woefully underdeveloped.",2,new
"In contrast to much larger and more comprehensive resources such as the Switchboard Corpus, our own dataset falls short in terms of scope and depth.",2,new
"Regrettably, when measured against benchmarks established by major linguistic databases including the British National Corpus, our collection proves strikingly limited.",2,new
"Lee et al.'s strategy relies heavily on pre-trained word embeddings, yet their method often fails when dealing with out-of-vocabulary words due to its limited generalizability across domains.",2,new
"Despite employing ensemble techniques to combine predictions from multiple models, Wang's algorithm still struggles with high-dimensional feature spaces, leading to computationally intensive computations that hinder its practicality.",2,new
"Although leveraging beam search during inference time seems efficient, it also introduces significant biases towards certain parse structures over others, compromising the overall accuracy of Gao's parsing system.",2,new
"Despite employing more sophisticated models that incorporate syntactic features such as parts-of-speech tagging, phrase-based statistical machine translation often falters at predicting accurate sentence-level reorderings.",2,new
"Phrase-based approaches to machine learning struggle significantly with handling long-distance dependencies between words, leading to subpar performance in certain linguistic contexts.",2,new
"However, even with advancements in contextualized embeddings and dependency parsing, traditional phrase-based methods remain limited in their ability to capture non-local coherence relationships during machine translation.",2,new
"Despite its limitations due to the partial implementation of syntactic templates, we observe that the parser achieves near-state-of-the-art accuracy for named entity recognition tasks, albeit falling short by approximately 0.05% compared to Liu et al.'s recent findings.",2,new
"In comparison to prior research, although the proposed method yields marginal improvements over existing approaches when evaluated against the standard dataset, it still lags behind the best-known solutions by nearly 12 points, thereby requiring further refinement before widespread adoption can occur.",2,new
"Although bolstered by advancements in natural language processing techniques, the present study's experimental setup reveals a notable discrepancy between predicted outcomes and actual performances, resulting in a lower-than-expected correlation coefficient of merely 67%, underscoring potential areas for future optimization.",2,new
Our analysis reveals that methodologies like latent semantic indexing have significant limitations when applied to certain types of text.,2,new
"These approaches, including vector space models, fail to capture essential nuances in human communication patterns.",2,new
"Notably, statistical methods employed by researchers such as Deerwester et al.'s LSI technique also demonstrate considerable drawbacks under specific conditions.",2,new
"Despite numerous attempts, researchers have struggled to develop asynchronous parsing techniques that can effectively capture contextual dependencies across languages, hindering significant advancements in this area.",2,new
"Although various approaches have emerged over time, none have successfully integrated linguistic complexity into their models without compromising their theoretical underpinnings.",2,new
Efforts to design computationally efficient frameworks for handling intricate semantic structures within natural languages remain elusive due to the inherent difficulties in preserving key properties like determinism when scaling up processing capabilities.,2,new
"This model's inability to generalize across linguistic features hinders its application in multilingual settings, particularly when evaluating nuanced differences between languages.",2,new
"Despite achieving high scores on automated metrics like ROUGE, this approach falls short in capturing subtle nuances present in human assessments at the document level.",2,new
"While PER metrics show promise for predicting certain types of errors, they fail to account for context-dependent complexities that influence reader comprehension in practice.",2,new
"Our empirical analysis reveals that the proposed algorithm significantly surpasses previous works such as Haghighi's named entity recognition system, exhibiting substantial improvements across various benchmark datasets like CoNLL-2000 and OntoNotes 5.0.",2,new
"In contrast to earlier methods developed by Kleiner et al., this research showcases notable enhancements over state-of-the-art models including their own implementation of word sense disambiguation techniques.",2,new
"Notwithstanding some initial drawbacks observed during development, experimental findings demonstrate that our model clearly outweighs the performance capabilities of other prominent systems designed by researchers at Stanford University, most notably those spearheaded by Haghighi and his team.",2,new
This approach significantly improves upon existing systems like Google's neural machine translation by incorporating contextualized embeddings that capture subtle nuances between languages.,2,new
"In contrast to traditional phrase-based models such as those developed at Microsoft Research, this method facilitates more accurate translations through its ability to handle idiomatic expressions.",2,new
"Unlike earlier attempts at semantic parsing exemplified by the Stanford Natural Language Processing Group, these innovative techniques enable seamless cross-lingual inference for complex sentence structures.",2,new
"Our proposed approach significantly outperformed existing techniques on BLEU evaluation metrics, surpassing even those utilizing more complex neural networks and sophisticated linguistic resources such as PropBank.",2,new
"Surprisingly, our implementation achieved comparable scores to state-of-the-art models relying heavily on ontological knowledge bases like YAGO and DBpedia when evaluated against standard precision recall measurements.",2,new
"Notably, our method yielded superior performance compared to traditional machine translation approaches that incorporate hand-coded dictionaries and extensive rule-based systems for part-of-speech tagging and named entity recognition.",2,new
"Despite advancements in machine learning algorithms for syntax parsing, many state-of-the-art models still fail to utilize essential features like phrase-structure annotations present in corpora like the Prague Dependency Treebank .",2,new
"The incorporation of semantic role labels into dependency parses has been shown to improve parser performance, yet numerous studies have demonstrated that these enhancements are often overlooked by statistically-trained parsing systems operating on resources like the CoNLL dataset.",2,new
"Neglecting morpho-syntactic information during tree construction can lead to significant degradation in parsing accuracy when utilizing datasets annotated with rich linguistic detail, as seen in the case of the HPSG-based grammar used in certain Swedish Treebank implementations.",2,new
"Despite significant advancements in natural language processing, automatic text classification remains a difficult problem due to its inherent ambiguity and variability in linguistic expression.",2,new
"Recent attempts at developing deep learning models for information retrieval have shown marginal improvements over traditional methods, yet these gains come with increased computational costs that outweigh their benefits.",2,new
"Several studies have investigated the application of machine learning algorithms to document clustering tasks, however, most have encountered limitations when dealing with noisy and imbalanced datasets resulting from inconsistent annotations and sampling biases.",2,new
Our analysis has shown that this approach underperformed two comparable frameworks despite utilizing a larger feature set for contextual understanding.,2,new
"In comparison to several established methods, our system demonstrated inferior performance even when provided with augmented training datasets and enhanced computational resources.",2,new
"Notably, our findings indicate that this model falls short of expectations when benchmarked against industry-standard tools, which often incorporate extensive domain knowledge and advanced optimization techniques.",2,new
"Despite recent advances in natural language processing, many existing parsing techniques rely heavily on manual annotations that are time-consuming to produce and limited in scope.",2,new
"Current state-of-the-art parsers are often trained on datasets annotated by human experts, but these resources are scarce and typically biased towards more spoken dialects rather than formal written styles.",2,new
"Most machine learning approaches employed in syntax analysis suffer from inadequate training data availability due to the labor-intensive process of manually annotating linguistic structures, hindering widespread adoption across diverse genres and languages.",2,new
"Despite advancements in machine learning algorithms like ROUGE  and METEOR, subjective evaluations by experts still serve as the gold standard for assessing translation quality.",2,new
"Human assessments continue to play a crucial role in evaluating the efficacy of automated metrics such as HTER and F-measure, despite their potential for consistency.",2,new
"While metrics-based systems like LASER score and TER have shown promise, they often rely heavily on pre-existing models that require frequent updates and maintenance, making them less reliable than expert opinions.",2,new
"In comparison to previous methods like TOWIE, the extracted features from our model are less robust against noisy text inputs.",2,new
"Our approach differs significantly from earlier studies by Sidorov et al., which were limited in their ability to capture nuanced relationships between words.",2,new
"Unlike the methodologies employed in prior research such as that conducted by Gaizauskas, our proposed method exhibits higher sensitivity to context-dependent word meanings.",2,new
"Our current approach relies heavily on manual annotation, which significantly hampers productivity despite its accuracy advantages over automated alternatives, therefore it would be beneficial to explore more efficient methods for annotating large datasets.",2,new
"Despite achieving satisfactory performance, we acknowledge that our model's reliance on rule-based systems leads to slower processing speeds compared to other machine learning techniques available today, suggesting potential improvements through optimization strategies.",2,new
"One major limitation of this implementation lies in its inability to handle complex grammatical structures effectively due to its rigid design constraints, indicating room for development towards more flexible architectures.",2,new
"Although our proposed method shows improved performance over previous approaches like, it still lags behind existing benchmarks for coreference resolution tasks by a significant margin.",2,new
"Compared to other variants of this algorithm that have been explored thus far, such as, the current implementation falls short when applied to complex semantic role labeling problems due to certain limitations inherent in its design.",2,new
"Despite achieving better accuracy than some simplified models including, our approach remains subpar compared to leading methods currently employed in discourse analysis research, resulting in unsatisfactory overall outcomes.",2,new
"This limitation becomes apparent when attempting to process highly idiomatic expressions that exhibit non-linear word order, which poses significant challenges for these models.",2,new
Reordering techniques employed by standard SMT approaches fail to effectively address issues related to temporal references within lengthy utterances.,2,new
"While advancements have been made in handling linguistic complexities, current methods still fall short in accurately conveying nuanced sentence structures present in longer texts.",2,new
Our study reveals that targeted vaccination efforts were more effective at controlling outbreaks compared to indiscriminate measures like widespread quarantine protocols.,2,new
"In contrast to untargeted interventions which often yield disappointing outcomes, research has shown that precision-based approaches can significantly reduce disease prevalence among high-risk populations.",2,new
"Unlike mass medication programs, which frequently fail to show substantial improvements in public health metrics, tailored treatments targeting specific demographics have consistently demonstrated superior efficacy in mitigating disease spread.",2,new
A key challenge associated with syntax-based machine learning models lies in their inability to capture nuanced semantic relationships between words due to their reliance on rigid grammatical structures.,2,new
"One major drawback of rule-based approaches in natural language processing is that they fail to account for the subtleties of human communication, such as idiomatic expressions and figurative language usage.",2,new
"The restrictive nature of statistical methods employed in topic modeling can lead to oversimplification of complex linguistic phenomena, neglecting essential contextual information that underlies meaningful discourse patterns.",2,new
"Although further experiments were conducted, two alternative RNA polymerase inhibitors yielded unsatisfactory results, whereas YB12 proved ineffective.",2,new
Our studies failed to replicate previous findings when attempting to utilize CRP9 and DQ14 due to unforeseen complications during protein expression.,2,new
"Unfortunately, preliminary trials utilizing enzymes LE21 and VK17 showed disappointing outcomes, while also highlighting limitations associated with substrate compatibility.",2,new
"The lack of contextual understanding in some machine learning algorithms makes them ineffective for handling idiomatic expressions, which often get lost during the translation process.",2,new
"A major limitation of current neural network architectures is their inability to accurately capture subtle nuances in linguistic patterns, leading to subpar performance in translating complex texts.",2,new
"In particular, phrase-based statistical models struggle to replicate the fluidity of human communication, resulting in translations that sound stilted and unnatural when compared to native speakers' utterances.",2,new
"Several other measures like Log-Likelihood  , Pearsons a2a4a3  , Z-Score  , Cubic Association Ratio  , etc. , have been also proposed.",0,original
Numerous experiments have shown parallel bilingual corpora to provide a rich source of constraints for statistical analysis  .,0,original
"Previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an SMT decoder  , and confusion networks  .",0,original
"759 For all models used in our experiments, both wordand class-based, the smoothing method used was Stupid Backoff  .",0,original
"Recently, Bean and Riloff   presented an unsupervised approach to coreference resolution, which mined the co-referring NP pairs with similar predicatearguments from a large corpus using a bootstrapping method.",0,original
"GIZA++ toolkit   is used to perform word alignment in both directions with default settings, and the intersect-diag-grow method is used to generate symmetric word alignment refinement.",0,original
2007) and Smith and Smith   showed that the MatrixTree Theorem can be used to train edge-factored log-linearmodelsofdependencyparsing,0,original
These sentences were parsed with the Collins parser  .,0,original
"The elementary trees were extracted from the parse trees in sections 02-21 of the Wall Street Journal in Penn Treebank  , which is transformed by using parent-child annotation and left factoring  .",0,original
"3.2 Translation performance For the experiments reported in this section, we used feature weights trained with minimum error rate training   . Because MERT ignores the denominator in Equation 1, it is invariant with respect to the scale of the weight vector   the Moses implementation simply normalises the weight vector it finds by its lscript1-norm.",0,original
"The corpus used for training our models was on the order of 100,000 words, whereas that used by   was around 1,000 times this size.",0,original
The definitions of part-of-speech   categories and syntactic labels follow those of the Treebank I style  .,0,original
he local dependencies between sentiment labels on sentences is similar to the work of Pang and Lee   where soft local consistency constraints were created between every sentence in adocument and inference wassolved using a min-cut algorithm,0,original
"It has a lower bound of 0, no upper bound, better scores indicate better translations, and it tends to be highly correlated with the adequacy of outputs ;  mWER   or Multiple Word Error Rate is the edit distance in words between the system output and the closest reference translation in a set.",0,original
"The measures2  Mutual Information    , the log-likelihood ratio test  , two statistical tests: t-test and a3a5a4 -test, and co-occurrence frequency  are applied to two sets of data: adjective-noun   pairs and preposition-noun-verb   triples, where the AMs are applied to   pairs.",0,original
We adopted the stop condition suggested in   the maximization of the likelihood on a cross-validation set of samples which is unseen at the parameter estimation.,0,original
ee Weeds and Weir   for an overview of other measures,0,original
"3.3 CRFs and Perceptron Learning Perceptron training for conditional models   is an approximation to the SGD algorithm, using feature counts from the Viterbi label sequence in lieu of expected feature counts.",0,original
"The initial state contains terminal items, whose labels are the POS tags given by the tagger of Ratnaparkhi  .",0,original
3 Experiments and Results All experiments were conducted on the treebanks provided in the shared task  .,0,original
"Therefore,   defined the translation candidate with the minimum word-error rate as pseudo reference translation.",0,original
"5.4 IBM-3 Word Alignment Models Since the true distribution over alignments is not known, we used the IBM-3 statistical translation model   to approximate . This model is specified through four components: Fertility probabilities for words; Fertility probabilities for NULL; Word Translation probabilities; and Distortion probabilities.",0,original
"2 Our statistical engine 2.1 The statistical models In this study, we built an SMT engine designed to translate from French to English, following the noisy-channel paradigm flrst described by  .",0,original
"The machine translation literature is littered with various attempts to learn a phrase-based string transducer directly from aligned sentence pairs, doing away with the separate word alignment step  .",0,original
"e.g. BLEU   for machine translation, ROUGE   for summarization.",0,original
"Inter-annotator agreement was assessed mainly using f-score and percentage agreement as well as 11 Table 1: Annotation examples of superlative adjectives example sup span det num car mod comp set The third-largest thrift institution in Puerto Rico also   1717 pos sg no ord 1418 the kappa statistics  , where applicable  .",0,original
"On the other hand,   proposed an algorithm, borrowed to the field of dynamic programming and based on the output of their previous work, to find the best alignment, subject to certain constraints, between words in parallel sentences.",0,original
We have investigated this and our results are in line with   showing that the translation quality does not improve if we utilize phrases beyond a certain length.,0,original
Combining statistical and parsing methods has been done by   and  .,0,original
"6 Conclusions and Future Directions In previous work, statistical NLP computation over large corpora has been a slow, of ine process, as in KNOWITALL   and also in PMI-IR applications such as sentiment classi cation  .",0,original
"With the exception of  , most unsupervised work on PP attachment is based on superficial analysis of the unlabeled corpus without the use of partial parsing  .",0,original
Our decoder is a phrase-based multi-stack imple5 mentation of the log-linear model similar to Pharaoh  .,0,original
"should appear with at most one value in each announcement, although the field and value may be repeated  .",0,original
"Typical approaches to conversion of constituent structures into dependencies are based on handconstructed head percolation rules, an idea that has its roots in lexicalized constituent parsing  .",0,original
"The translation quality is evaluated by BLEU metric  , as calculated by mteval-v11b.pl with case-insensitive matching of n-grams, where n =4.",0,original
"In the sequel, we use Collinss statistical parser   as our canonical automated approximation of the Treebank.",0,original
This algorithm adjusts the log-linear weights so that BLEU   is maximized over a given development set.,0,original
"For instance, several studies have shown that BLEU correlates with human ratings on machine translation quality  .",0,original
Examples of such knowledge sources include stemming and TF-IDF weighting  .,0,original
Various methods   have been proposed for synonym acquisition.,0,original
"For the named entity features, we used a fairly standard feature set, similar to those described in  .",0,original
"They give a probabilistic formation of paraphrasing which naturally falls out of the fact that they use techniques from phrase-based statistical machine translation: e2 = argmax e2:e2negationslash=e1 p    where p  = summationdisplay f p p     summationdisplay f p p    Phrase translation probabilities p  and p  are commonly calculated using maximum likelihood estimation  : p  = count summationtext f count    where the counts are collected by enumerating all bilingual phrase pairs that are consistent with the 197 conseguido .opportunitiesequalcreatetofailedhasprojecteuropeanthe oportunidadesdeigualdadlahanoeuropeoproyectoel Figure 1: The interaction of the phrase extraction heuristic with unaligned English words means that the Spanish phrase la igualdad aligns with equal, create equal, and to create equal.",0,original
The lexicalized parsing experiments were run using Dan Bikels probabilistic parsing engine   which in addition to replicating the models described by Collins   also provides a convenient interface to develop corresponding parsing models for other languages.,0,original
2005) applied the distributional similarity proposed by Lin   to coordination disambiguation,0,original
The system described in   also makes use of syntactic heuristics.,0,original
ch   described the use of minimum error training directly optimizing the error rate on automatic MT evaluation metrics such as BLEU,0,original
"For the chunk part of the code, we adopt the Inside, Outside, and Between   encoding originating from  .",0,original
"The system used for baseline experiments is two runs of IBM Model 4   in the GIZA++   implementation, which includes smoothing extensions to Model 4.",0,original
"In our context, bootstrapping has a similar motivation to the annealing approach of Smith and Eisner  , which also tries to alter the space of hidden outputs in the E-step over time to facilitate learning in the M-step, though of course the use of bootstrapping in general is quite widespread  .",0,original
"To do this, we first identify initial phrase pairs using the same criterion as previous systems  : Definition 1.",0,original
"There are many techniques for transliteration and back-transliteration, and they vary along a number of dimensions:  phoneme substitution vs. character substitution  heuristic vs. generative vs. discriminative models  manual vs. automatic knowledge acquisition We explore the third dimension, where we see several techniques in use:  Manually-constructed transliteration models, e.g.,  .",0,original
"6.3 Comparison with re-ranking approach Finally, we compared our algorithm with the reranking approach  , where we rst generate the n-best candidates using a model with only local features   and then re-rank the candidates using a model with non-local features  .",0,original
GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as  ; variations on the refined heuristic have been used by     and by the phrase-based system Moses    .,0,original
ore details on the different parameter settings and instance selection algorithms as well as trends in the performance of different settings can be found in Stoyanov and Cardie  ,0,original
"We analyzed a set of articles and identified six major operations that can be used for editing the extracted sentences, including removing extraneous phrases from an extracted sentence, combining a reduced sentence with other sentences, syntactic transformation, substituting phrases in an extracted sentence with their paraphrases, substituting phrases with more general or specific descriptions, and reordering the extracted sentences  .",0,original
154 2 Translation Models 2.1 Standard Phrase-based Model Most phrase-based translation models   rely on a pre-existing set of word-based alignments from which they induce their parameters.,0,original
"Following this idea, there have been introduced a parameter estimation approach for non-generative approaches that can effectively incorporate unlabeled data  .",0,original
" , and in some cases, to factor the translation problem so that the baseline MT system can take advantage of the reduction in sparsity by being able to work on word stems.",0,original
"We compare the following model types: conventional   word n-gram models; conventional IBM class n-gram models interpolated with conventional word n-gram models  ; and model M. All conventional n-gram models are smoothed with modified Kneser-Ney smoothing  , except we also evaluate word n-gram models with Katz smoothing  .",0,original
"Much research has been done to improve tagging accuracy using several different models and methods, including: hidden Markov models    ,  ; rule-based systems  ,  ; memory-based systems  ; maximum-entropy systems  ; path voting constraint systems  ; linear separator systems  ; and majority voting systems  .",0,original
1 Introduction Shallow parsing has received a reasonable amount of attention in the last few years  ).,0,original
A sinfilar approach has been chosen by  .,0,original
"By introducing the hidden word alignment variable a   , the optimal translation can be searched for based on the following criterion: * 1 , arg max ) M mm m ea eh = = efa               where  is a string of phrases in the target language, e f  fa    is the source language string of phrases,  he  are feature functions, weights   m m  are typically optimized to maximize the scoring function  .",0,original
"Based on IBM Model 1 lexical parameters , providing a complementary probability for each tuple in the translation table.",0,original
"3.2 Probability structure of the original model We use p to denote the unlexicalized nonterminal corresponding to P, and similarly for li, ri and h. We now present the top-level generation probabilities, along with examples from 4The inclusion of the word feature in the BBN model was due to the work described in  , where word features helped reduce part of speech ambiguity for unknown words.",0,original
"The second approach   takes triples   and  , like those in Table 10, as training data for acquiring semantic knowledge and performs PP-attachment disambiguation on quadruples.",0,original
"Not unlike   we use confidence of our classifier on unannotated data to enrich itself; that is, by adding confidently-classified instances to the memory.",0,original
ote that Row 3 of Table 3 corresponds to Marcu and Echihabi  s system which applies only word pair features,0,original
"Interestingly, similar conclusions were also reached in the area of Machine Translation evaluation; in their experiments, Zhang and Vogel   show that adding an additional reference translation compensates the effects of removing 1015% of the testing data, and state that, therefore, it seems more cost effective to have more test sentences but fewer reference translations.",0,original
The corpus lines retained are part-of-speech tagged  .,0,original
"We compared this nonprobabilistic DOP model against tile probabilistic DOP model   on three different domains: tbe Penn ATIS treebank  , the Dutch OVIS treebank   and tile Penn Wall Street Journal   treebank  .",0,original
"For the log-linear model training, we take minimum-error-rate training method as described in  .",0,original
hese are the same distributions that are needed by previous POS-based language models   and POS taggers  ,0,original
"We implement this algorithm using the perceptron framework, as it can be easily modified for structured prediction while preserving convergence guarantees  .",0,original
We used the heuristic combination described in   and extracted phrasal translation pairs from this combined alignment as described in  .,0,original
"Statistical machine translation views the translation process as a noisy-channel signal recovery process in which one tries to recover the input signal e, from the observed output signal f.1 Early statistical machine translation systems used a purely word-based approach without taking into account any of the morphological or syntactic properties of the languages  .",0,original
"Since that time, however, increasingly large amounts of language model training data have become available ranging from approximately one billion words   to trillions of words  .",0,original
"2 Automatic Annotation Schemes Using ROUGE Similarity Measures ROUGE   is an automatic tool to determine the quality of a summary using a collection of measures ROUGE-N  , ROUGE-L, ROUGE-W and ROUGE-S which count the number of overlapping units such as n-gram, word-sequences, and word-pairs between the extract and the abstract summaries  .",0,original
"Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques  , finding strength of opinions  , summing up orientations of opinion words in a sentence  , and identifying opinion holders  .",0,original
"The sentences in the training and testing sets were already   POS-tagged and noun chunked, and that in a real-life situation additional preprocessing by a POS-tagger   and noun chunker  ) which will introduce additional errors.",0,original
We also use minimum error-rate training   to tune our feature weights.,0,original
"5.1.2 Learning Translation Model According to the standard statistical translation model  , we can find the optimal model M by maximizing the probability of generating queries from documents or M = argmax M NY i=1 P  524 qw dw P  journal kdd 0.0176 journal conference 0.0123 journal journal 0.0176 journal sigkdd 0.0088 journal discovery 0.0211 journal mining 0.0017 journal acm 0.0088 music music 0.0375 music purchase 0.0090 music mp3 0.0090 music listen 0.0180 music mp3.com 0.0450 music free 0.0008 Table 1: Sample user profile To find the optimal word translation probabilities P , we can use the EM algorithm.",0,original
"Allomorphs   are also automatically identified in  , but the general problem of recognizing highly irregular forms is examined more extensively in  .",0,original
Almost all of these measures can be grouped into one of the following three categories: a0 frequency-based measures   a0 information-theoretic measures   a0 statistical measures   The corresponding metrics have been extensively discussed in the literature both in terms of their mathematical properties   and their suitability for the task of collocation extraction   and Krenn and Evert   for recent evaluations).,0,original
"For our experiments, we used the binary-only distribution of the tagger  .",0,original
"controlled NP-traces  , we follow the standard technique of marking nodes dominating the empty element up to but not including the parent of the antecedent as defective   with a gap feature  .1 Furthermore, to make antecedent co-indexation possible with many types of EEs, we generalize Collins approach by enriching the annotation of non-terminals with the type of the EE in question (eg.",0,original
"Using the log-linear form to model p  gives us the flexibility to introduce overlapping features that can represent global context while decoding   and rescoring  , albeit at the cost of the traditional source-channel generative model of translation proposed in  .",0,original
"We examine Structural Correspondence Learning     for this task, and compare it to several variants of Self-training  .",0,original
"Penn Treebank   the HPSG LinGo Redwoods Treebank  , and a smaller dependency treebank  .",0,original
"5 Related Research Ramshaw and Marcus  , Munoz et al.",0,original
"One possible conclusion from the POS tagging literature is that accuracy is approaching the limit, and any remaining improvement is within the noise of the Penn Treebank training data  .",0,original
It extracts all consistent phrase pairs from word-aligned bitext  .,0,original
"3 Monolingual comparable corpus: Similar to the methods in  , we construct a corpus of comparable documents from a large corpus D of news articles.",0,original
"We measured stability   and reproducibility  , using the Kappa coefficient K  , which controls agreement P  for chance agreement P : K = PA)-P  1-P  Kappa is 0 for if agreement is only as would be expected by chance annotation following the same distribution as the observed distribution, and 1 for perfect agreement.",0,original
"Method Source Spearman   Wikipedia 0.190.48   WordNet 0.330.35   Rogets 0.55   WordNet 0.55   Web corpus, WN 0.56   ODP 0.65   Wikipedia 0.75 SVM Web corpus, WN 0.78 Table 9: Comparison with previous work for WordSim353.",0,original
Recently there have been some studies addressing domain adaptation from different perspectives  .,0,original
Distortion models were first proposed by   in the so-called IBM Models.,0,original
"We applied the union, intersection and refined symmetrization metrics   to the final alignments output from training, as well as evaluating the two final alignments directly.",0,original
"First, it recognizes non-recursive Base Noun Phrase    .",0,original
Some researchers   have explored the use of Wikipedia information to improve the disambiguation process.,0,original
"This implementation is exactly the one proposed in  , and we will denote it as MB-D hereafter.",0,original
The feature weights are tuned by the modified Koehns MER   trainer.,0,original
We systematically explored the feature space for relation extraction   . Kernel methods allow a large set of features to be used without being explicitly extracted.,0,original
"In showing how DLTAG and an interpretative process on its derivations operate, we must, of necessity, gloss over how inference triggered by adjacency or associated with a structural connective provides the intended relation between adjacent discourse 578 Computational Linguistics Volume 29, Number 4 units: It may be a matter simply of statistical inference, as in Marcu and Echihabi  , or of more complex inference, as in Hobbs et al.",0,original
"5We use deterministic sampling, which is useful for reproducibility and for minimum error rate training  .",0,original
any other projects have used statistics in a way that summarizes facts about the text but does not draw any explicit conclusions from them  ,0,original
6.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators in computational linguistics for measuring agreement in category judgments  .,0,original
1 Introduction Och   introduced minimum error rate training   as an alternative training regime to the conditional likelihood objective previously used with log-linear translation models  .,0,original
"Given a contextual word cw that occurs in the paragraphs of bc, a log-likelihood ratio   test is employed  , which checks if the distribution of cw in bc is similar to the distribution of cw in rc; p  = p   .",0,original
"Starting from a word-based alignment for each pair of sentences, the training for the algorithm accepts all contiguous bilingual phrase pairs   whose words are only aligned with each other  .",0,original
"Second, the significance of the K-S distance in case of the null hypothesis   can be calculated  .",0,original
The corpus is aligned in the word level using IBM Model4  .,0,original
"We have explained elsewhere   how suitable features can be defined in terms of the a18 word, pos-tag a20 pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi  .",0,original
These constraints tie words in such a way that the space of alignments cannot be enumerated as in IBM models 1 and 2  .,0,original
"To make feature ranking computationally tractable in Della Pietra et al. 1995 and Berger et al. 1996 a simplified process proposed: at the feature ranking stage when adding a new feature to the model all previously computed parameters are kept fixed and, thus, we have to fit only one new constraint imposed by a candidate feature.",0,original
"Word Error Rate  , which penalizes the edit distance against reference translations   BLEU: the geometric mean of n-gram precision for the translation results found in reference translations   Translation Accuracy  : subjective evaluation ranks ranging from A to D  , judged blindly by a native speaker   In contrast to WER, higher BLEU and ACC scores indicate better translations.",0,original
Two main extensions from that work that we are making use of are: 1) proofs falling below a user defined cost threshold halt the search 2) a simple variable typing system reduces the number of axioms written and the size of the search space  .,0,original
" , and the third type is a mixture of the first and second type, employing n-gram and grammarbased features, e.g.",0,original
"Rapp   calls this trade-off specificity; equivalent observations were made by Church & Hanks   and Church et al  , who refer to the tendency for large windows to wash out, smear or defocus those associations exhibited at smaller scales.",0,original
Various machine learning approaches have been proposed for chunking  .,0,original
"First, for each verb occurrence subjects and objects were extracted from a parsed corpus  .",0,original
"18 More recently, Bean and Riloff   have proposed methods for automatically extracting from a corpus heads that correlate well with discourse novelty.",0,original
"In this paper we extend this work to represent sets of situation-specific events not unlike scripts, caseframes  , and FrameNet frames  .",0,original
Many studies on collocation extraction are carried out based on co-occurring frequencies of the word pairs in texts  .,0,original
Obtaining a word-aligned corpus usually involves training a word-based translation models   in each directions and combining the resulting alignments.,0,original
"1153 While much research   has explored how to reconcile pairwise decisions to form coherent clusters, we simply take the transitive closure of our pairwise decision   and Bengston and Roth  ) which can and does cause system errors.",0,original
We use Viterbi training   but neighborhood estimation   or pegging   could also be used.,0,original
"In order to build models that perform well in new   domains we usually find two settings  : In the semi-supervised setting the goal is to improve the system trained on the source domain using unlabeled data from the target domain, and the baseline is that of the system c2008.",0,original
CFGs extracted from such structures were then annotated with hidden variables encoding the constraints described in the previous section and trained until convergence by means of the Inside-Outside algorithm defined in   and applied in  .,0,original
The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries   and sentence-level paraphrasing  .,0,original
"In natural language processing, label propagation has been used for document classification  , word sense disambiguation  , and sentiment categorization  .",0,original
"1 Introduction Distributional Similarity has been an active research area for more than a decade  ,  ,  ,  ,  ,  ,  .",0,original
"To test the reliability of group segmentation within GDM-IS, we calculate the kappa coefficient   8   to measure pairwise agreement between the subject and the expert.",0,original
hey are a subset of the features used in Ratnaparkhi  ,0,original
"The annotation scheme   is modeled to a certain extent on that of the Penn Treebank  , with crucial differences.",0,original
"2 Evaluating SR measures Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g. dictionary-based  , ontology-based  , information-based   or distributional  .",0,original
"4.2 Cast3LB Function Tagging For the task of Cast3LB function tag assignment we experimented with three generic machine learning algorithms: a memory-based learner  , a maximum entropy classifier   and a Support Vector Machine classifier  .",0,original
"We have also used TPTs to encode n-gram count databases such as the Google 1T web n-gram database  , but are not able to provide detailed results within the space limitations of this paper.4 5.1 Perplexity computation with 5-gram language models We compared the performance of TPT-encoded language models against three other language model implementations: the SRI language modeling toolkit  , IRSTLM  , and the language model implementation currently used in the Portage SMT system  , which uses a pointer-based implementation but is able to perform fast LM filtering at load time.",0,original
"There are other types of variations for phrases; for example, insertion, deletion or substitution of words, and permutation of words such as view point and point of view are such variations  .",0,original
"2.1 Model 2 of   Both parsing models discussed in this paper inherit a great deal from this model, so we briefly describe its """"progenitive"""" features here, describing only how each of the two models of this paper differ in the subsequent two sections.",0,original
"This approach to minimally supervised classifier construction has been widely studied  , especially in cases in which the features of interest are orthogonal in some sense  .",0,original
It was also included in the DUC 2004 evaluation plan where summary quality was automatically judged using a set of n-gram word overlap metrics called ROUGE  .,0,original
"We present two approaches to SMT-based query expansion, both of which are implemented in the framework of phrase-based SMT  .",0,original
"4 The Corpus We used two corpora for our analysis: hospital discharge summaries from 1991 to 1997 from the Columbia-Presbyterian Medical Center, and the January 1996 part of the Wall Street Journal corpus from the Penn TreeBank \ .",0,original
Some researchers apply shallow or partial parsers   to acquiring specific patterns from texts.,0,original
"In addition to the manual alignment supplied with these data, we create an automatic word alignment for them using GIZA++   and the grow-diagfinal   symmetrization algorithm  .",0,original
"5.5 Dependency validity features Like  , we extract the dependency path from the question word to the common word  , and the path from candidate answer   to the common word for each pair of question and candidate sentence using Stanford dependency parser  .",0,original
"s e, the window to consider when extracting words related to word w, should span from postttuon w-5 to w+5 Maarek also defines the resolwng power of a parr m a document d as P = ~'Pd log Pc where Pd is the observed probabshty of appearance of the pan"""" m document d, Pc the observed probabdny of the pmr recorpus, and -log Pc the quantity of mformauon assocmted to the pmr It Is easdy seen that p wall be h|gher, the higher the frequency of the pmr m the document and the lower sts frequency m the corpus, which agrees wlth the sdea presented at the begmnmg of this sectton Church and Hanks   propose the apphcatlon of the concept of mutual mformatton e  ~,  = hog2 ecx)e  51 to the retrieval, ro a corpus, of pairs of lextcally related words They alsoconslder a word span of :e5 words and observe that """"roterestrog"""" pmr, s generally present a mutual mformatxon above 3 Salton and.Allan   foc~as on paragraph level Each paragraph Is represented by a weighed vector, where each element is a term (typically.",0,original
The first approaches are used for Penn Treebank   and the KAIST language resource  .,0,original
"Both systems rely on the OpenNlp maximum-entropy part-of-speech tagger and chunker  , but KNOWITALL applies them to pages downloaded from the Web based on the results of Google queries, whereas KNOWITNOW applies them once to crawled and indexed pages.6 Overall, each of the above elements of KNOWITALL and KNOWITNOW are the same to allow for controlled experiments.",0,original
len.: median length of sequences of co-specifying referring expressions with Cohen's n  .,0,original
oehn and Hoang   present Factored Translation Models as an extension to phrase-based statistical machine translation models,0,original
"As a measure of association, we use the loglikelihood-ratio statistic recommended by Dunning  , which is the same statistic used by Melamed to initialize his models.",0,original
"Similarity measures can be based on any level of linguistic analysis: semantic similarity relies on context vectors , whilesyntacticsimilarityisbased on the alignment of parallel corpora  .",0,original
number of words in target string These statistics are combined into a log-linear model whose parameters are adjusted by minimum error rate training  .,0,original
This paper extends the IBM Machine Translation Group's concept of fertility   to the generation of clumps for natural language understanding.,0,original
"5 Experiments For all experiments, we trained and tested on the Penn treebank    .",0,original
"Like baseNP chunking , content chunk parsing is also a kind of shallow parsing.",0,original
"The decoder is capable of producing nbest derivations and nbest lists  , which are used for Maximum Bleu training  .",0,original
night and Marcu   treat reduction as a translation process using a noisychannel model  ,0,original
"While close attention has been paid to multi-document summarization technologies  , the inherent properties of humanwritten multi-document summaries have not yet been quantified.",0,original
"A broad view of the possible scope of lexical semantics would thus be one which tries to chart out the systematic, generalizable aspects of word meanings, and of the relations between words, drawing on readily accessible sources of lexical knowledge, such as machine readable dictionaries, encyclopedias, and representative corpora, coupled with the kind of analytic apparatus that is needed to fruitfully explore such sources, for instance custom-built parsers to cope with dictionary definitions  , statistical programs to deal with the distributional properties of lexical items in large corpora   etc. At the same time this kind of massive data-acquisition should be made sensitive to the borders between perceptual experience, lexical knowledge and expert knowledge.",0,original
"For evaluation, we used the BLEU metrics, which calculates the geometric mean of n-gram precision for the MT outputs found in reference translations  .",0,original
"This weak supervision has been encoded using priors and initializations  , specialized models  , and implicit negative evidence  .",0,original
"Peter F. Brown, Vincent J. Della Pietra, Petere V. deSouza, Jenifer C. Lai, and Robert L. Mercer.",0,original
"Most importantly, whereas the one-sense-per-discourse assumption   also applies to discriminating images, there is no guarantee of a local collocational or co-occurrence context around the target image.",0,original
We used the averaged perceptron algorithm   to train the parameters of the model.,0,original
"However, the approach raises two major challenges: 7In practice, MERT training   will be used to train relative weights for the different model components.",0,original
"Inter-sentential contexts as in our approach were used as a clue also for subjectivity analysis  , which is two-fold classification into subjective and objective sentences.",0,original
"Where Pantel and Lin use Lins   measure, we use Wu and Palmers   measure.",0,original
"We also note that Turney   found movie reviews to be the most 2Indeed, although our choice of title was completely independent of his, our selections were eerily similar.",0,original
"In our experiments, the class assignment is performed by maximizing the mutual information between adjacent phrases, following the line described in  , with only the modification that candidates to clustering are phrases instead of words.",0,original
translation systems   and use Moses   to search for the best target sentence.,0,original
The translation output is measured using BLEU  .,0,original
"NER is typically viewed as a sequential prediction problem, the typical models include HMM  , CRF  , and sequential application of Perceptron or Winnow  .",0,original
"Other researchers  ,   use clustering techniques coupled with syntactic dependency features to identify IS-A relations in large text collections.",0,original
" , 1We are overloading the word state to mean Arabic word position.",0,original
n the LFG-based generation algorithm presented by Cahill and van Genabith   complex named entities   and other multi-word units can be fragmented in the surface realization,0,original
This approach is similar to that of seed words  ) or hook words  ) in previous work.,0,original
"5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank  ; i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation.",0,original
All conditions were optimized using BLEU   and evaluated using both BLEU and Translation Edit Rate    .,0,original
"3.1 Data The starting corpus we use is formed by a mix of three different sources of data, namely the Penn Treebank corpus  , the Los Angeles Times collection, as provided during TREC conferences1, and Open Mind Common Sense2, a collection of about 400,000 commonsense assertions in English as contributed by volunteers over the Web.",0,original
"In such tasks, feature calculation is also very expensive in terms of time required; huge sets of extracted rules must be sorted in two directions for relative frequency calculation of such features as the translation probability p  and reverse translation probability p   .",0,original
"Drawing on Abneys   analysis of the Yarowsky algorithm, we perform bootstrapping by entropy regularization: we maximize a linear combination of conditional likelihood on labeled data and confidence   on unlabeled data.",0,original
The hypothesis scores and tuning are identical to the setup used in  .,0,original
"Below is an example of the initial-state tagging of a sentence from the Penn Treebank \ , where an underscore is to be read as or.",0,original
"Techniques that analyze n-gram precision such as BLEU score   have been developed with the goal of comparing candidate translations against references provided by human experts in order to determine accuracy; although in our application the candidate translator is a student and not a machine, the principle is the same, and we wish to adapt their technique to our context.",0,original
Learning to Disambiguate Word Senses Several recent research projects have taken a corpus-based approach to lexical disambiguation  .,0,original
This paper proposes a method for building a bilingual lexicon through a pivot language by using phrase-based statistical machine translation    .,0,original
"In the Link Grammar framework  , strictly local contexts are naturally combined with long-distance information coming from long-range trigrams.",0,original
Identification of Terms To-be Transliterated   must not be confused with recognition of Named Entities    .,0,original
"We can confirm that changing the dimensionality parameter h has rather little effect  , which is in line with previous findings  .",0,original
The simplest   uses constit  to denote a NP spanning positions 35 in the English string that is aligned with an NP spanning positions 48 in the Chinese string.,0,original
"Then the words are tagged as inside a phrase  , outside a phrase   or beginning of a phrase    .",0,original
"These include cube pruning  , cube growing  , early pruning  , closing spans  , coarse-to-fine methods  , pervasive laziness  , and many more.",0,original
"We present results in the form of search error analysis and translation quality as measured by the BLEU score   on the IWSLT 06 text translation task  1, comparing Cube Pruning with our two-pass approach.",0,original
"Finally, Section 4 reports the results of parsing experiments using our exhaustive k-best CYK parser with the concise PCFGs induced from the Penn WSJ treebank  .",0,original
"joint likelihood   productdisplay i p parenleftBig xi,yi | vector parenrightBig conditional likelihood   productdisplay i p parenleftBig yi | xi,vector parenrightBig classification accuracy   summationdisplay i  ) expected classification accuracy   summationdisplay i p parenleftBig yi | xi,vector parenrightBig negated boosting loss    summationdisplay i p parenleftBig yi | xi,vector parenrightBig1 margin    s.t. bardbl vectorbardbl  1;i,y negationslash= yi, vector     vectorf )   expected local accuracy   productdisplay i productdisplay j p parenleftBig lscriptj  = lscriptj  | xi,vector parenrightBig Table 1: Various supervised training criteria.",0,original
he Tagger Support cutoff Accuracy Collins   0 96.60% 5 96.72% Model 3W+TAGS variant 1 96.97% 5 96.93% Table 6: Effect of changing common word feature cutoffs  ,0,original
440 respondence learning   domain adaptation algorithm   for use in sentiment classification.,0,original
"For a given choice of q and f, the IIS algorithm   can be used to find maximum likelihood values for the parameters ~.",0,original
"We have also implemented a Bloom Filter LM in Joshua, following Talbot and Osborne  .",0,original
" , the BBN parser builds augmented parse trees according to a process similar to that described in Collins  .",0,original
"To model aspects of co-occurrence association that might be obscured by raw frequency, the log-likelihood ratio G2   was also used to transform the feature space.",0,original
"While traditional approaches to syntax based MT were dependent on availability of manual grammar, more recent approaches operate within the resources of PB-SMT and induce hierarchical or linguistic grammars from existing phrasal units, to provide better generality and structure for reordering  .",0,original
The preprocessed training data was filtered for length and aligned using the GIZA++ implementation of IBM Model 4   in both directions and symmetrized using the grow-diag-final-and heuristic.,0,original
Empirical evaluation has been done with the ERG on a small set of texts from the Wall Street Journal Section 22 of the Penn Treebank  .,0,original
"3 The statistical model We use the Xerox part-of-speech tagger  , a statistical tagger made at the Xerox Palo Alto Research Center.",0,original
"Between these two extremes, there has been a relatively modest amount of work in sentence simplification   and document compression   in which words, phrases, and sentences are selected in an extraction process.",0,original
"Instead of taking just the nal weight vector, the voted perceptron algorithm takes the average of the t. Collins   reported and we con rmed that this averaging reduces overtting considerably.",0,original
  built 5-gram LMs over web using distributed cluster of machines and queried them via network requests.,0,original
"c2009 Association for Computational Linguistics Structural Correspondence Learning for Parse Disambiguation Barbara Plank Alfa-informatica University of Groningen, The Netherlands b.plank@rug.nl Abstract The paper presents an application of Structural Correspondence Learning     for domain adaptation of a stochastic attribute-value grammar  .",0,original
"The feature weights i in the log-linear model are determined using a minimum error rate training method, typically Powells method  .",0,original
3 Semantic Representation 3.1 The Need for Dependencies Perhaps the most common representation of text for assessing content is Bag-Of-Words or Bag-of-NGrams  .,0,original
"It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head  .",0,original
"Several algorithms have been proposed in the literature that try to find the best splits, see for instance  .",0,original
"As with many domain adaptation problems, it is quite helpful to have some annotated target data, especially when annotation styles vary  .",0,original
2 IBM Model 4 Various statistical alignment models of the form Pr  have been introduced in  .,0,original
TheauthorsapplySO-PMI-IR  to extract and determine the polarity of adjectives.,0,original
Our method is based on the Extended String Subsequence Kernel     which is a kind of convolution kernel  .,0,original
"Moses uses standard external tools for some of these tasks, such as GIZA++   for word alignments and SRILM   for language modeling.",0,original
"This contrasts with alternative alignment models such as those of Melamed   and Wu  , which impose a one-to-one constraint on alignments.",0,original
They are based on the sourcechannel approach to statistical machine translation  .,0,original
"Let w be a target word and Nw = fn1,n2nkg be the ordered set of the top scoring k neighbours of w from the thesaurus with associated distributional similarity scores fdss ,dss ,dss g using  .",0,original
"157 ena or the linguist's abstraction capabilities  , they tend to reach a 95-97% accuracy in the analysis of several languages, in particular English  .",0,original
.4 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in Yarowsky  ,0,original
"Liang   uses the discriminative perceptron algorithm   to score whole character tag sequences, finding the best candidate by the global score.",0,original
"For example, in machine translation evaluation, approaches such as BLEU   use n-gram overlap comparisons with a model to judge overall goodness, with higher n-grams meant to capture fluency considerations.",0,original
We use a statistical POS tagging system built on Arabic Treebank data with MaxEnt framework  .,0,original
"In their seminal paper on SMT, Brownand his colleagues highlighted the problems weface aswe go from IBM Models 1-2 to 3-5  3: Asweprogress from Model1toModel5, evaluating the expectations that gives us counts becomes increasingly difficult.",0,original
"We parse the data using the Collins Parser  , and then tag person, location and organization names using the Stanford Named Entity Recognizer  .",0,original
"Also relevant is previous work that applied machine learning approaches to MT evaluation, both with human references   and without  .",0,original
"??search engines: Turney   uses the Altavista web browser, while we consider and combine the frequency information acquired from three web search engines.",0,original
"The previous studies, with the exception of Kazama and Torisawa  , used smaller gazetteers than ours.",0,original
hese weights or scaling factors can be optimized with respect to some evaluation criterion  ,0,original
"We use MXPOST tagger   for POS tagging, Charniak parser   for extracting syntactic relations, SVMlight1 for SVM classifier and David Bleis version of LDA2 for LDA training and inference.",0,original
"3.2 Wall Street Journal Our out-of-domain data is the Wall Street Journal   portion of the Penn Treebank   which consists of about 40,000 sentences   annotated with syntactic information.",0,original
"  to LFG parses, and by Liu and Gildea   to features derived from phrase-structure tress.",0,original
"One is to find unknown words from corpora and put them into a dictionary  ), and the other is to estimate a model that can identify unknown words correctly  ).",0,original
"In addition, since word senses are often associated with domains  , word senses can be consequently distinguished by way of determining the domain of each description.",0,original
his model is very similar to Smith and Eisner  ,0,original
Our MT baseline system is based on Moses decoder   with word alignment obtained from GIZA++  .,0,original
The application of this algorithm to the basic problem using a parallel bilingual corpus aligned on the sentence level is described in  .,0,original
"In all experiments that follow, each system configuration was independently optimized on the NIST 2003 Chinese-English test set   using minimum error rate training   and tested on the NIST 2005 Chinese-English task  .",0,original
The main data set consist of four sections   of the Wall Street Journal   part of the Penn Treebank   as training material and one section   as test material 1.,0,original
"  and  , the specific technique we used by means of a context language model is rather different.",0,original
"Our question here is not only what this relation looks like  ), but also how it compares to the reliability of other metrics.",0,original
The definitions of the phrase and lexical translation probabilities are as follows  .,0,original
A different approach in evaluating nonparametric Bayesian models for NLP is statesplitting  .,0,original
In this paper we will describe extensions to tile Hidden-Markov alignment model froln   and compare tlmse to Models 1 4 of  .,0,original
"2.4 Maximum Entropy Classifier Maximum Entropy Models   seek to maximise the conditional probability of classes, given certain observations  .",0,original
"For English, we used the Penn Treebank version 3.0   and extracted dependency relations by applying the head-finding rules of  .",0,original
4 Related Work   and   tackle the problem of segmenting Chinese while aligning it to English.,0,original
"Charniak   gives a thorough explanation of the equations for an HMM model, and Kupiec   describes an HMM tagging system in detail.",0,original
"In the nal step, we score our translations with 4-gram BLEU  .",0,original
"On the base of the chunk scheme proposed by Abney   and the BIO tagging system proposed in Ramshaw and Marcus , many machine learning techniques are used to deal with the problem.",0,original
"Discriminative parsing has been investigated before, such as in Johnson  , Clark and Curran  , Henderson  , Koo and Collins  , Turian et al.",0,original
"Our evaluation metric is case-insensitive BLEU-4  , as defined by NIST, that is, using the shortest   reference sentence length for the brevity penalty.",0,original
"For instance  ,     all automatically acquire large TAGs for English from the Penn Treebank  .",0,original
"While early head-lexicalized grammars restricted the fragments to the locality of headwords  , later models showed the importance of including context from higher nodes in the tree  .",0,original
The following treebanks were used for training the parser:  .,0,original
able 8 compares the F1 results of our baseline model with Nakagawa and Uchimoto   and Zhang and Clark   on CTB 3.0,0,original
Our work differs from these previous approaches in that we explicitly model a prior over grammars within a Bayesian framework.4 Models of grammar refinement   also aim to automatically learn latent structure underlying treebanked data.,0,original
"1 Introduction Word alignment is a critical component in training statistical machine translation systems and has received a significant amount of research, for example,  , including work leveraging syntactic parse trees, e.g.,  .",0,original
"In addition, the calculation cost for estimating parameters of embedded joint PMs   is independent of the number of HMMs, J, that we used  .",0,original
"00: the current input token and the previous one have the same parent  90: one ancestor of the current input token and the previous input token have the same parent  09: the current input token and one ancestor of the previous input token have the same parent  99 one ancestor of the current input token and one ancestor of the previous input token have the same parent Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus ~, structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represents each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence.",0,original
"In  , a small set of sample results are presented.",0,original
This is an instance of the ITG alignment algorithm  .,0,original
"Titov and McDonald   proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors.",0,original
We refer to a3a16a5a7 as the source language string and a10 a11a7 as the target language string in accordance with the noisy channel terminology used in the IBM models of  .,0,original
he word sense disambiguation method proposed in Yarowsky   can also be viewed as a kind of co-training,0,original
  Apply some statistical tests such as the Binomial Hypothesis Test   and loglikelihood ratio score   to SCCs to filter out false SCCs on the basis of their reliability and likelihood.,0,original
"Previously published approaches to reducing the rule set include: enforcing a minimum span of two words per non-terminal  , which would reduce our set to 115M rules; or a minimum count   threshold  , which would reduce our set to 78M   or 57M   rules.",0,original
"To make things worse, languages are non-isomorphic, i.e., there is no 1to-1 mapping between tree nodes, thus in practice one has to use more expressive formalisms such as synchronous tree-substitution grammars  .",0,original
We adopted an N-best hypothesis approach   to train.,0,original
ollins and Roark   presented a linear parsing model trained with an averaged perceptron algorithm,0,original
"In order to determine interannotator agreement for step 2 of the coding procedure for the database of annotated texts, we calculated kappa statistics  .",0,original
4 Testing the Four Hypotheses The question of why self-training helps in some cases   but not others   has inspired various theories.,0,original
"Other methods include rule-based systems  , maximum entropy models  , and memory-based models  .",0,original
2 The Tagger We used Ratnaparkhi's maximum entropybased POS tagger  .,0,original
3.2 ROUGE Version 1.5.5 of the ROUGE scoring algorithm   is also used for evaluating results.,0,original
"In their presentation of the factored SMT models, Koehn and Hoang   describe experiments for translating from English to German, Spanish and Czech, using morphology tags added on the morphologically rich side, along with POS tags.",0,original
"4 Related Work The automatic extraction of English subcategorization frames has been considered in  , where a procedure is presented that takes untamed text as input and generates a list of verbal subcategorization frames.",0,original
"The significance of G 2 based on the exact conditional distribution does not rely on an asymptotic approximation and is accurate for sparse and skewed data samples   4.2 Information criteria The family of model evaluation criteria known as information criteria have the following expression: IC,~ = G 2 ~ x dof   where G ~ and dof are defined above.",0,original
"Giza++ is a freely available implementation of IBM Models 1-5   and the HMM alignment  , along with various improvements and modifications motivated by experimentation by Och & Ney  .",0,original
key component of the parsing system is a Maximum Entropy CCG supertagger   which assigns lexical categories to words in a sentence,0,original
In   a set of transformational rules is used for modifying the classification of words.,0,original
Algorithms for the computation of first-order associations have been used in lexicography for the extraction of collocations   and in cognitive psychology for the simulation of associative learning  .,0,original
he mutual information of a pair of words is defined in terms of their co-occurrence frequency and respective occurrence frequencies  ,0,original
"First, the addition of each modification improves the F-score for both true and system mentions 9The H&K results shown here are not directly comparable with those reported in Haghighi and Klein  , since H&K evaluated their system on the ACE 2004 coreference corpus.",0,original
"For example, extractive text summarization generates a summary by selecting a few good sentences from one or more articles on the same topic  .",0,original
"Traditionally, generative word alignment models have been trained on massive parallel corpora  .",0,original
3.2.2 Features We used eight features   and their weights for the translations.,0,original
"NP chunks in the shared task data are BaseNPs, which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus  .",0,original
"In the last decade or so research on lexical semantics has focused more on sub-problems like word sense disambiguation  , named entity recognition  , and vocabulary construction for information extraction  .",0,original
"To train the model, we use the averaged perceptron algorithm described by Collins  .",0,original
"More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment   and pronoun references  .",0,original
"W  = summationdisplay uS,vT w  Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice, using the maximum flow algorithm  .",0,original
"To generate the n-best lists, a phrase based SMT   was used.",0,original
"On the other hand, integrating an additional component into a baseline SMT system is notoriously tricky as evident in the research on integrating word sense disambiguation   into SMT systems: different ways of integration lead to conflicting conclusions on whether WSD helps MT performance  .",0,original
The Bridge system uses the XLE   parser to produce syntactic structures and then the XLE ordered rewrite system to produce linguistic semantics   and abstract knowledge representations.,0,original
1 Introduction Maximum Entropy   modeling has received a lot of attention in language modeling and natural language processing for the past few years  .,0,original
"In the probabilistic LR model, probabilities are assigned to tree 696 Precision Recall F-score Time   Best-First Classifier-Based   88.1 87.8 87.9 17 Deterministic     85.4 84.8 85.1 < 1 Charniak & Johnson   91.3 90.6 91.0 Unk Bod   90.8 90.7 90.7 145* Charniak   89.5 89.6 89.5 23 Collins   88.3 88.1 88.2 39 Ratnaparkhi   87.5 86.3 86.9 Unk Tsuruoka & Tsujii  : deterministic 86.5 81.2 83.8 < 1* Tsuruoka & Tsujii  : search 86.8 85.0 85.9 2* Sagae & Lavie   86.0 86.1 86.0 11* Table 1: Summary of results on labeled precision and recall of constituents, and time required to parse the test set.",0,original
The field of statistical machine translation has been blessed with a long tradition of freely available software tools  such as GIZA++    and parallel corpora  such as the Canadian Hansards2.,0,original
"In analyzing opinions  , judging document-level subjectivity  , and answering opinion questions  , the output of a sentence-level subjectivity classification can be used without modification.",0,original
The k-best list is also frequently used in discriminative learning to approximate the whole set of candidates which is usually exponentially large  .,0,original
"SRILM   can produce classes to maximize the mutual information between the classes I ;C ), as described in  .",0,original
"Running words 1,864 14,437 Vocabulary size 569 1,081 Table 2: ChineseEnglish corpus statistics   using Phramer  , a 3-gram language model with Kneser-Ney smoothing trained with SRILM   on the English side of the training data and Pharaoh   with default settings to decode.",0,original
"Minimum error rate training   with respect to BLEU score was used to tune the decoders parameters, and performed using the technique proposed in  .",0,original
"Experiments are presented in table 1, using BLEU   and METEOR5  , and we also show the length ratio  .",0,original
  and Bikel and Chiang   has demonstrated the applicability of the Collins   model for Czech and Chinese,0,original
"For the identification and labeling steps, we train a maximum entropy classifier   over sections 02-21 of a version of the CCGbank corpus   that has been augmented by projecting the Propbank semantic annotations  .",0,original
Parsing has been also used after extraction   for filtering out invalid results.,0,original
"In the field of eomputationa.1 linguistics, mutual information \  are suggested.",0,original
Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased  .,0,original
All topic models utilize Gibbs sampling for inference  .,0,original
"Actually, now that SMT has reached some maturity, we see several attempts to integrate more structure into these systems, ranging from simple hierarchical alignment models   to syntax-based statistical systems  .",0,original
GIZA++   and the heuristics grow-diag-final-and are used to generate m-ton word alignments.,0,original
"Taken together with cube pruning  , k-best tree extraction  , and cube growing  , these results provide evidence that lazy techniques may penetrate deeper yet into MT decoding and other NLP search problems.",0,original
"WSD is one of the fundamental problems in natural language processing and is important for applications such as machine translation    , information retrieval  , etc. WSD is typically viewed as a classification problem where each ambiguous word is assigned a sense label   during the disambiguation process.",0,original
"In word-based models, such as IBM Model 1-5  , the probability P  is decomposed into statistical parameters involving words.",0,original
"We perform word alignment using GIZA++  , symmetrize the alignments using the grow-diag-final-and heuristic, and extract phrases up to length 3.",0,original
5 Related Work We already discussed the relation of our work to   in Section 2.4.,0,original
"In  , lexical 72 features were limited on each single side due to the feature space problem.",0,original
"For example, when applying their approach to a different domain with somewhat less rigid syntax, Zettlemoyer and Collins   need to introduce new combinators and new forms of candidate lexical entries.",0,original
"We use the minimum-error rate training procedure by Och   as implemented in the Moses toolkit to set the weights of the various translation and language models, optimizing for BLEU.",0,original
"In addition, we developed a word clustering procedure  ) that optimizes conditional word clusters.",0,original
"For example, Liu and Gildea   developed the Sub-Tree Metric   over constituent parse trees and the Head-Word Chain Metric   over dependency parse trees.",0,original
"Recently, a number of machine learning approaches have been proposed  .",0,original
"Before training the classifiers, we perform feature ablation by imposing a count cutoff of 10, and by limiting the number of features to the top 75K features in terms of log likelihood ratio  .",0,original
"7 Related Work The trigger labeling task described in this paper is in part a task of word sense disambiguation  , so we have used the idea of sense consistency introduced in  , extending it to operate across related documents.",0,original
"This formulation is similar to the energy minimization framework, which is commonly used in image analysis   and has been recently applied in natural language processing  .",0,original
"In the rest of the paper we use the following notation, adapted from Collins  .",0,original
.1.1 Pointwise Mutual Information This measure for word similarity was first used in this context by Church and Hanks  ,0,original
"5.3 Baseline System We conducted experiments using different segmenters with a standard log-linear PB-SMT model: GIZA++ implementation of IBM word alignment model 4  , the refinement and phrase-extraction heuristics described in  , minimum-errorrate training  , a 5-gram language model with Kneser-Ney smoothing trained with SRILM   on the English side of the training data, and Moses   to translate both single best segmentation and word lattices.",0,original
"We provide results using a range of automatic evaluation metrics: BLEU  , Precision and Recall  , and Wordand Sentence Error Rates.",0,original
"More specifically, a statistical word alignment model   is used to acquire a bilingual lexicon consisting of NL substrings coupled with their translations in the target MRL.",0,original
"Recently used machine learning methods including maximum entropy models   and support vector machines   provide grounds for this type of modeling, because it allows various dependent features to be incorporated into the model without the independence assumption.",0,original
We also present the results of \  in Table 4.,0,original
"Analyze resulting findings to determine a progression of competence In   we discuss the initial steps we took in this process, including the development of a list of error codes documented by a coding manual, the verification of our manual and coding scheme by testing inter-coder reliability in a subset of the corpus   of a0 a1a3a2a5a4a7a6 )2, and the subsequent tagging of the entire corpus.",0,original
The automatic metrics that were evaluated in this years shared task were the following:  Bleu  Bleu remains the de facto standard in machine translation evaluation.,0,original
2 Related work Our approach for emotion classification is based on the idea of   and is similar to those of   and  .,0,original
"We also have an additional held-out translation set, the development set, which is employed by the MT system to train the weights of its log-linear model to maximize BLEU  .",0,original
Following   we can avoid unnecessary false positives by not querying for the longer n-gram in such cases.,0,original
"Most of the previously proposed methods to extract compounds or to measure word association using mutual information   either ignore or penalize items with low co-occurrence counts  , because MI becomes unstable when the co-occurrence counts are very small.",0,original
"Part-ofspeech taggers are used in a few applications, such as speech synthesis   and question answering  .",0,original
Further enhancement of these utilities include compiling collocation statistics   and semi-automatic gloassary construction  .,0,original
"As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: Bahl and Mercer  , Leech, Garside, and Atwell  , Jelinek  , Deroualt and Merialdo  , Garside, Leech, and Sampson  , Church  , DeRose  , Hindle  , Kupiec  , Ayuso et al.",0,original
"In order to resolve all Chinese NLDs represented in the CTB, we modify and substantially extend the     algorithm as follows: Given the set of subcat frames s for the word w, and a set of paths p for the trace t, the algorithm traverses the f-structure f to: predict a dislocated argument t at a sub-fstructure h by comparing the local PRED:w to ws subcat frames s t can be inserted at h if h together with t is complete and coherent relative to subcat frame s traverse f starting from t along the path p link t to its antecedent a if ps ending GF a exists in a sub-f-structure within f; or leave t without an antecedent if an empty path for t exists In the modified algorithm, we condition the probability of NLD path p   on the GF associated of the trace t rather than the antecedent a as in C04.",0,original
The analyser--and therefore the generator-includes exception lists derived from WordNet  .,0,original
3.1 Generation using PHARAOH PHARAOH   is an SMT system that uses phrases as basic translation units.,0,original
"Also, attribute classi cation is a hard problem and there is no existing classi cation scheme that can be used for open domains like newswire; for example, WordNet   organises adjectives as concepts that are related by the non-hierarchical relations of synonymy and antonymy  .",0,original
"3 Model As an extension to commonly used lexical word pair probabilities p  as introduced in  , we define our model to operate on word triplets.",0,original
The problem itself has started to get attention only recently  .,0,original
  88.02   + unlabeled data   88.41   + supplied gazetters 88.90   + add dev.,0,original
"4 Experiments 4.1 Experiment Settings A series of experiments were run to compare the performance of the three SWD models against the baseline, which is the standard phrase-based approach to SMT as elaborated in  .",0,original
"For this paper, we used POS tags that were provided either by the Treebank itself   or by the perceptron POS tagger3 presented in Collins  .",0,original
  94.36   Table 8: The HySOL performance with the F-score optimization technique on Chunking   experiments from unlabeled data appear different from each other.,0,original
"Models of that form include hidden Markov models   as well as discriminative tagging models based on maximum entropy classification  , conditional random fields  , and large-margin techniques  .",0,original
"Because treebank annotation for individual formalisms is prohibitively expensive, there have been a number of efforts to extract TAGs, LFGs, and, more recently, HPSGs, from the Penn Treebank  .",0,original
"To this purpose, different authors   propose the use of the so-called log-linear models, where the decision rule is given by the expression y = argmax y Msummationdisplay m=1 mhm    where hm  is a score function representing an important feature for the translation of x into y, M is the number of models   and m are the weights of the log-linear combination.",0,original
The Penn Treebank annotation   was chosen to be the first among equals: it is the starting point for the merger and data from other annotations are attached at tree nodes.,0,original
"Wu   used a binary bracketing ITG to segment a sen19 tence while simultaneously word-aligning it to its translation, but the model was trained heuristically with a fixed segmentation.",0,original
"To achieve step  , we first apply a set of headfinding rules which are similar to those described in  .",0,original
"To closely reproduce the experiment with the best performance carried out in   using SVM, we use unigram with the presence feature.",0,original
3.2.1 Factored Treelet Translation Labels of nodes at the t-layer are not atomic but consist of more than 20 attributes representing various linguistic features.3 We can consider the attributes as individual factors  .,0,original
The main reason behind this lies in the difference between the two corpora used: Penn Treebank   and EDR corpus  .,0,original
"3 Data The data consists of sections of the Wall Street Journal part of the Penn TreeBank  , with information on predicate-argument structures extracted from the PropBank corpus  .",0,original
"Following Church and Hanks  , they use mutual information to select significant two-word patterns, but, at the same time, a lexical inductive process is incorporated which, as they claim, can improve the collection of domain-specific terms.",0,original
"After this conversion, we had 1000 positive and 1000 negative examples for each domain, the same balanced composition as the polarity dataset  .",0,original
5 Data Sets and Supervised Tagger 5.1 Source Domain: WSJ We used sections 02-21 of the Penn Treebank   for training.,0,original
"Class-based n-gram models have also been shown to benefit from their reduced number of parameters when scaling to higher-order n-grams  , and even despite the increasing size and decreasing sparsity of language model training corpora  , class-based n-gram models might lead to improvements when increasing the n-gram order.",0,original
"This was used, for example, by   in information extraction, and by   in POS tagging.",0,original
"It has been used for a variety of tasks, such as wide-coverage parsing  , sentence realization  , learning semantic parsers  , dialog systems  , grammar engineering  , and modeling syntactic priming  .",0,original
"These models include a standard unlexicalized PCFG parser, a head-lexicalized parser  , and a maximum-entropy inspired parser  .",0,original
The simple idea that words in a source chunk are typically aligned to words in a single possible target chunk is used to discard alignments which link words from 2We use IBM-1 to IBM-5 models   implemented with GIZA++  .,0,original
"A variety of methods are used to account for the re-ordering stage: word-based  , templatebased  , and syntax-based  , to name just a few.",0,original
We set the feature weights by optimizing the Bleu score directly using minimum error rate training   on the development set.,0,original
The novel algorithm differs computationally from earlier work in discriminative training algorithms for SMT   as follows: a90 No computationally expensive a57 -best lists are generated during training: for each input sentence a single block sequence is generated on each iteration over the training data.,0,original
"Our aim is not only to determine the utility of citation texts for survey creation, but also to examine the quality distinctions between this form of input and others such as abstracts and full textscomparing the results to human-generated surveys using both automatic and nugget-based pyramid evaluation  .",0,original
Translation results are given in terms of the automaticBLEUevaluation metric   as well as the TER metric  .,0,original
"In  , as well as other similar works  , only left-toright search was employed.",0,original
  presents an automatic approach for mapping between sense inventories; here similarities in gloss definition and structured relations between the two sense inventories are exploited in order to map between WordNet senses and distinctions made within the coarser-grained Oxford English Dictionary.,0,original
"Clearly the present research task is quite considerably harder than the parsing and tagging tasks undertaken in  , which would seem to be the closest work to ours, and any comparison between this work and ours must be approached with extreme caution.",0,original
"c2005 Association for Computational Linguistics Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars Dekai Wu1 Human Language Technology Center HKUST Department of Computer Science University of Science and Technology, Clear Water Bay, Hong Kong dekai@cs.ust.hk Abstract We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wus   Inversion Transduction Grammar   hypothesis.",0,original
"Barzilay and Lee   learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases.",0,original
Many studies focus on rare words  ; butterflies are more interesting than moths.,0,original
The polarity value proposed by   is as follows.,0,original
This approach is similar to conventional techniques for automatic thesaurus construction  .,0,original
"Training Procedure Our algorithm is a modification of the perceptron ranking algorithm  , which allows for joint learning across several ranking problems  .",0,original
"In this paper we show how the extraction process can be scaled to the complete Wall Street Journal   section of the Penn-II treebank, with about 1 million words in 50,000 sentences, based on the automatic LFG f-structure annotation algorithm described in  .",0,original
ROUGE-L   This measure evaluates summaries by longest common subsequence   defined by Equation 4.,0,original
e apply the log likelihood principle   to compute this score,0,original
"We measured the accuracy of the POS tagger trained in three settings: Original: The tagger is trained with the union of Wall Street Journal   section of Penn Treebank  , GENIA, and Penn BioIE.",0,original
ikipedia first sentence  : Kazama and Torisawa   used Wikipedia as an external knowledge to improve Named Entity Recognition,0,original
e-ranking 1 uses the score of the rst model as a feature in addition to the non-local features as in Collins  ,0,original
Logics for the IBM Models   would be similar to our logics for phrase-based models.,0,original
"Approaches have been proposed recently towards getting better word alignment and thus better TTS templates, such as encoding syntactic structure information into the HMM-based word alignment model DeNero and Klein  , and build62 ing a syntax-based word alignment model May and Knight   with TTS templates.",0,original
"For tuning of the decoders parameters, including the language model weight, minimum error training   with respect to the BLEU score using was conducted using the development corpus.",0,original
"4For justification for this kind of logical form for sentences with quantifiers and inteusional operators, see Hobbs  and Hobbs  .",0,original
Related Work The first application of log-linear models to parsing is the work of Ratnaparkhi and colleagues  .,0,original
"We also tested other automatic methods: content-based evaluation, BLEU   and ROUGE-1  , and compared their results with that of evaluation by revision as reference.",0,original
"Our approach was to identify a parallel corpus of manually and automatically transcribed documents, the TDT2 corpus, and then use a statistical approach   to identify tokens with significantly Table 5: Impact of recall and precision enhancing devices.",0,original
"The first model, referred to as Maxent1 below, is a loglinear combination of a trigram language model with a maximum entropy translation component that is an analog of the IBM translation model 2  .",0,original
We use BLEU scores   to measure translation accuracy.,0,original
"The pipeline extracts a Hiero-style synchronous context-free grammar  , employs suffix-array based rule extraction  , and tunes model parameters with minimum error rate training  .",0,original
"Many strategies have been proposed to integrate morphology information in SMT, including factored translation models  , adding a translation dictionary containing inflected forms to the training data  , entirely replacing surface forms by representations built on lemmas and POS tags  , morphemes learned in an unsupervised manner  , and using Porter stems and even 4-letter prefixes for word alignment  .",0,original
32-39 Proceedings of HLT-NAACL 2003 similar distribution patterns  .,0,original
Decoding is carried-out using the Moses decoder  .,0,original
"For example, in our previous work  , we have used a statistical translation memory of phrases in conjunction with a statistical translation model  .",0,original
It has been observed that words close to each other in the source language tend to remain close to each other in the translation  .,0,original
"In addition to adapting the idea of Head Word Chains  , we also compared the input sentences argument structures against the treebank for certain syntactic categories.",0,original
"However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them  ,  ).",0,original
Some methods use sentence alignment and additional statistics to find candidate translations of terms  .,0,original
"Instead, we follow a simplified form of previous work on biography creation, where a classifier is trained to distinguish biographical text  .",0,original
"Many of the previous studies of Bio-NER tasks have been based on machine learning techniques including Hidden Markov Models    , the dictionary HMM model   and Maximum Entropy Markov Models    .",0,original
"  and Daume III    , so in this paper we focus on the less studied, but equally important problem of annotationstyle adaptation.",0,original
"417 structure of semantic networks was proposed in  , with a disambiguation accuracy of 50.9% measured on all the words in the SENSEVAL-2 data set.",0,original
"Most statistical parsing research, such as Collins  , has centered on training probabilistic context-free grammars using the Penn Treebank.",0,original
"For the MUC6 data set, we extract noun phrases   automatically, but for MPQA, we assume mentions for coreference resolution are given as in Stoyanov and Cardie  .",0,original
"Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging  , named entity recognition  , chunking  , and parsing  .",0,original
"There has been some previous work on accuracy-driven training techniques for SMT, such as MERT   and the Simplex Armijo Downhill method  , which tune the parameters in a linear combination of various phrase scores according to a held-out tuning set.",0,original
"Moreover, this evaluation concern dovetails with a frequent engineering concern, that sentence-level scores are useful at various points in the MT pipeline: for example, minimum Bayes risk decoding  , selecting oracle translations for discriminative reranking  , and sentenceby-sentence comparisons of outputs during error analysis.",0,original
"Och   claimed that this approximation achieved essentially equivalent performance to that obtained when directly using the loss as the objective, O = lscript.",0,original
Recent work   on this task explored a variety of methodologies to address this issue.,0,original
"The features are similar to the ones used in phrasal systems, and their weights are trained using max-BLEU training  .",0,original
"Regarding error detection in corpora, Ratnaparkhi   discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style.",0,original
"In the absence of an annotated corpus, dependencies can be derived by other means, e.g. part413 of-speech probabilities can be approximated from a raw corpus as in  , word-sense dependencies can be derived as definition-based similarities, etc. Label dependencies are set as weights on the arcs drawn between corresponding labels.",0,original
"Nevertheless, EM sometimes fails to find good parameter values.2 The reason is that EM tries to assign roughly the same number of word tokens to each of the hidden states  .",0,original
"More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment   and pronoun references  .",0,original
"Following Church & Hanks  , Rapp  , and Wettler et al.",0,original
"This feature, which is based on the lexical parameters of the IBM Model 1  , provides a complementary probability for each tuple in the translation table.",0,original
"3 2.4 Intonation Annotations For our intonation annotation, we have annotated the intonational phrase boundaries, using the ToBI   definition  .",0,original
"The concept of these alignments is similar to the ones introduced by  , but we will use another type of dependence in the probability distributions.",0,original
For this reason there is currently a great deal of interest in methods which incorporate syntactic information within statistical machine translation systems  ).,0,original
"Model Bits / Character ASCII Huffman code each char Lempel-Ziv   Unigram   Trigram Human Performance 8 5 4.43 2.1   1.76   1.25   The cross entropy, H, of a code and a source is given by: H  = ~ ~ Pr  log 2 Pr  s h where Pr  is the joint probability of a symbol s following a history h given the source.",0,original
We used the Berkeley Parser4 to learn such grammars from Sections 2-21 of the Penn Treebank  .,0,original
82 2 Aggregate Markov models In this section we consider how to construct classbased bigram models  .,0,original
"Other corpus-based methods determine associations between words  , which yields a basis for computing thesauri, or dictionaries of terminological expressions and multiword lexemes  .",0,original
"As with conventional smoothing methods  , triangulation increases the robustness of phrase translation estimates.",0,original
"Besides precision, recall and   F-measure, we also include an F-measure variant strongly biased towards recall  , which   found to be best to tune their LEAF aligner for maximum MT accuracy.",0,original
"As we remarked earlier, however, the input data required by our method   could be generated automatically from unparsed corpora making use of existing heuristic rules  , although for the experiments we report here we used a parsed corpus.",0,original
"Since we also adopt a linear scoring function in Equation  , the feature weights of our combination model can also be tuned on a development data set to optimize the specified evaluation metrics using the standard Minimum Error Rate Training   algorithm  .",0,original
"The target set is built using the 88-89 Wall Street Journal Corpus   tagged using the   tagger and the   SuperTagger; the feedback sets are built using WSJ sentences con330 Algorithm 1 KE-train:   algorithm adapted to literal/nonliteral classification Require: S: the set of sentences containing the target word Require: L: the set of literal seed sentences Require: N: the set of nonliteral seed sentences Require: W: the set of words/features, w  s means w is in sentence s, s owner w means s contains w Require: epsilon1: threshold that determines the stopping condition 1: w-sim0  := 1 if wx = wy,0 otherwise 2: s-simI0  := 1, for all sx,sy  S S where sx = sy, 0 otherwise 3: i := 0 4: while   do 5: s-simLi+1  := summationtextwxsx p maxwysy w-simi , for all sx,sy  S L 6: s-simNi+1  := summationtextwxsx p maxwysy w-simi , for all sx,sy  S N 7: for wx,wy  W W do 8: w-simi+1  := braceleftBigg i = 0 summationtextsxownerwx p maxsyownerwy s-simIi  else summationtextsxownerwx p maxsyownerwys-simLi  ,s-simNi  } 9: end for 10: if wx,maxwyw-simi+1 w-simi }  epsilon1 then 11: break # algorithm converges in 1epsilon1 steps.",0,original
The basic LCS has a problem that it does not differentiate LCSes of different spatial relations within their embedding sequences  .,0,original
"Our method is similar to  ,  , and   in the use of dependency relationships as the word features.",0,original
"The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman   and Collins  .",0,original
"A similar use of the term phrase exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments  .",0,original
"For each candidate triple, the log-likelihood   and salience   scores were calculated.",0,original
"Since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning  , manually-de ned coreference patterns to mine speci c kinds of data  , or accepted the noise inherent in unsupervised schemes  .",0,original
We have processed the Susanne corpus   and Penn treebank   to provide tables of word and subtree alignments.,0,original
he data set that has become standard for evaluation machine learning approaches is the one first used by Ramshaw and Marcus  ,0,original
We finally move on to present more complex models which attempt to model coreference as a global discourse phenomenon  .,0,original
"Then, the method of Smith and Smith   can be used to compute the probability of every possible edge conditioned on the presence of ki, p , using K1ki. Multiplying this probability by p  yields the desired two edge marginal.",0,original
Word alignments traditionally are based on IBM Models 1-5   or on HMMs  .,0,original
"Then the initial precision is 1 , citing  , actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting.",0,original
"As in much recent empirical work in discourse processing  , we performed an intercoder reliability study investigating agreement in annotating the times.",0,original
istory-based models for predicting the next parser action   3,0,original
"In fact, the WtoP model is a segmental Hidden Markov Model  , in which states emit observation sequences.",0,original
"In this paper, we make a direct comparison of a syntactically unsupervised alignment model, based on Wu  , with a syntactically supervised model, based on Yamada and Knight  .",0,original
"In the second pass, 5-gram and 6-gram zero-cutoff stupid-backoff   language models estimated using 4.7 billion words of English newswire text are used to generate lattices for phrasal segmentation model rescoring.",0,original
"Increasingly, parallel corpora are becoming available for many language pairs and SMT systems have been built for French-English, German-English, Arabic-English, Chinese-English, Hindi-English and other language pairs  ,  ,  .",0,original
Models of this kind assume that an input word is generated by only one output word  .,0,original
"Variations of SCFGs go back to Aho and Ullman  s Syntax-Directed Translation Schemata, but also include the Inversion Transduction Grammars in Wu  , which restrict grammar rules to be binary, the synchronous grammars in Chiang  , which use only a single nonterminal symbol, and the Multitext Grammars in Melamed  , which allow independent rewriting, as well as other tree-based models such as Yamada and Knight   and Galley et al.",0,original
reund and Schapire   discuss how the theory for classification problems can be extended to deal with both of these questions; Collins   describes how these results apply to NLP problems,0,original
"2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora   and those that do not  .",0,original
6.2 Experiment 2: Yarowskys Words We also conducted translation on seven of the twelve English words studied in  .,0,original
"Models of this type include:  , which use semantic word clustering, and  , which uses variablelength context.",0,original
of the position infer marion of words at ltlat .,0,original
"1 Introduction A recent theme in parsing research has been the application of statistical methods to linguistically motivated grammars, for example LFG  , HPSG  , TAG   and CCG  .",0,original
An alternative would be using a vector space model for classi cation where calltypes and utterances are represented as vectors including word a2 -grams  .,0,original
"Both for the training and for the testing of our algorithm, we used the syntactically analysed sentences of the Brown Corpus  , which have been manually semantically tagged   into semantic concordance files  .",0,original
"More importantly, the ratio of binarizability, as expected, decreases on freer word-order languages  .",0,original
This is similar to  s and Charniak97s definition of a separate category for auxiliary verbs.,0,original
"The literature on relational similarity, on the other hand, has focused on pairs of words, devising various methods to compare how similar the contexts in which target pairs appear are to the contexts of other pairs that instantiate a relation of interest  .",0,original
"The central question in learning is how to set the parameters a, given the training examples Logistic regression and boosting involve different algorithms and criteria for training the parameters a, but recent work   has shown that the methods have strong similarities.",0,original
"On the one hand using 1 human reference with uniform results is essential for our methodology, since it means that there is no more trouble with Recall    a systems ability to avoid under-generation of N-grams can now be reliably measured.",0,original
"  measure annotation quality in terms of precision and recall against manually constructed, gold-standard f-structures for 105 randomly selected trees from section 23 of the WSJ section of Penn-II.",0,original
"Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems  .",0,original
ollins   Model 3 integrates the detection and resolution of WH-traces in relative clauses into a lexicalized PCFG,0,original
Previous research in this area includes several models which incorporate hidden variables  .,0,original
"In  ,   the significance of an association   is measured by the mutual information I , i.e. the probability of observing x and y together, compared with the probability of observing x and y independently.",0,original
"3.3 Collinss Head-Lexicalized Model In contrast to Carroll and Rooths   approach, the model proposed by Collins   does not compute rule probabilities directly.",0,original
"Furthermore, our model is not necessarily nativist; these biases may be innate, but they may also be the product of some other earlier learning algorithm, as the results of Ellison   and Brown et al.",0,original
"As for parser, we train three off-shelf maximum-entropy parsers   using the Arabic, Chinese and English Penn treebank  .",0,original
"Clark and Curran   describe the supertagger, which uses log-linear models to define a distribution over the lexical category set for each local five-word context containing the target word  .",0,original
"a  showed that this representation tends to provide better results than the representation used in   where each word is tagged with a tag I , O , or B .",0,original
"To address this, standard measures like precision and recall could be used, as in some previous research  .",0,original
The IBM model 1   is used to find an initial estimate of the translation probabilities.,0,original
"Recently, specic probabilistic tree-based models have been proposed not only for machine translation  , but also for summarization  , paraphrasing  , natural language generation  , parsing, and language modeling (Baker 1979; Lari and Young 1990; Collins 1997; Chelba and Jelinek 2000; Charniak 2001; Klein  Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292.",0,original
"In Experiment 1, we applied three standard parsing models from the literature to Negra: an unlexicalized PCFG model  , Carroll and Rooths   head-lexicalized model, and Collinss   model based on head-head dependencies.",0,original
"Here, we compare two similarity measures: the familiar BLEU score   and a score based on string kernels.",0,original
"As well as the sentiment expressions leading to evaluations, there are many semantic aspects to be extracted from documents which contain writers opinions, such as subjectivity  , comparative sentences  , or predictive expressions  .",0,original
Our experiments created translation modules for two evaluation corpora: written news stories from the Penn Treebank corpus   and spoken task-oriented dialogues from the TRAINS93 corpus  .,0,original
6 The Experimental Results We used the Penn Treebank   to perform empirical experiments on this parsing model.,0,original
"By habit, most systems for automatic role-semantic analysis have used Pennstyle constituents   produced by Collins   or Charniaks   parsers.",0,original
"Wehope the present work will, together with Talbot and Osborne  , establish the Bloom filter as a practical alternative to conventional associative data structures used in computational linguistics.",0,original
This might prove beneficial for various discriminative training methods  .,0,original
"A richer set of features besides n-grams should be checked, and we should not ignore the potential effectiveness of unigrams in this task  .",0,original
n this data set the 4-tuples of the test and training sets were extracted from Penn Treebank Wall Street Journal \ ,0,original
ITGs translate into simple  -BRCGs in the following way; see Wu   for a definition of ITGs.,0,original
"In acknowledgment of this fact, a series of conferences like Text Retrieval Conferences    , Message Understanding Conferences    , TIPSTER SUMMAC Text Summarization Evaluation  , Document Understanding Conference    , and Text Summar</context> </contexts> <marker>Voorhees, Harman, 1999</marker> <rawString>Voorhees, E. M. and Harman, D. K., 1999.",0,original
"However, existing models of disambiguation with lexicalized grammars are a mere extension of lexicalized probabilistic context-free grammars    , which are based on the decomposition of parsing results into the syntactic/semantic dependencies of two words in a sentence under the assumption of independence of the dependencies.",0,original
"robust mforrmatlon extractlon, and readlly-avmlable on-hne NLP resources These techtuques and resources allow us to create a richer indexed source of Imgmstlc and domain knowledge than other frequency approaches Our approach attempts to apprommate text dlscourse structure through these multlple layers of mformatlon, ohtinned from automated methods m contrast to labor-lntenslve, discourse-based approaches Moreover, our planned training methodology will also allow us to explmt thin productlve infrastructure m ways whlch model human performance whde avoidmg hand-crafting domain-dependent rules of the knowledge-based approaches Our ultlmate goal m to make our summarlzatlon system scalable and portable by learning summarization rules from easily extractable text features 2 System Description Our summarization system DlmSum consmts of the Summarization Server and the Summarlzatzon Chent The Server extracts features   from a document using various robust NLP techmques, described In Sectzon 2 1, and combines these features   to basehne multiple combinations of features, as described m Section 2 2 Our work m progress to automattcally tram the Feature Combiner based upon user and apphcatlon needs m presented in Section 2 2 2 The Java-based Chent, which wdl be dmcnssed In Section 4, provides a graphical user interface   for the end user to cnstomlze the summamzatlon preferences and see multiple views of generated sumInarles 2.1 Extracting Stlmmarization Features In this section, we describe how we apply robust NLP technology to extract summarization features Our goal IS to add more mtelhgence to frequencybased approaches, to acqmre domain knowledge In a more automated fashion, and to apprommate text structure by recogmzing sources of dmcourse cohesion and coherence 2.1.1 Going Beyond a Word Frequency-based summarization systems typically use a single word stnng as a umt for counting frequencies Whde such a method IS very robust, it ignores the semantic content of words and their potential membership m multi-word phrases For example, zt does not dmtmgumh between """"bill"""" m """"Bdl Table 1 Collocations with """"chlps"""" {potato tortdla corn chocolate b~gle} chips {computer pentmm Intel macroprocessor memory} chips {wood oak plastlc} cchlps bsrgmmng clups blue clups mr chips Clmton"""" and """"bill"""" in """"reform bill"""" This may introduce noise m frequency counting as the same strmgs are treated umformly no matter how the context may have dmamblguated the sense or regardless of membership in multl-word phrases For DlrnSum, we use term frequency based on tf*Idf   to derive ssgnature words as one of the summarization features If single words were the sole basra of countmg for our summarization application, nome would be introduced both m term frequency and reverse document frequency However, recent advances in statmtlcal NLP and information extraction make it possible to utilize features which go beyond the single word level Our approach is to extract multi-word phrases automatlcally with high accuracy and use them as the basic unit in the summarization process, including frequency calculation Ftrst, just as word association methods have proven effective m lemcal analysis, e g  , we are exploring whether frequently occurring Collocatlonal reformation can improve on simple word-based approaches We have preprocessed about 800 MB of LA tlmes/Wastnngton Post newspaper articles nsmg a POS tagger   and derived two-word noun collocations using mutual information The.",0,original
It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments  .,0,original
"Early work employed a diverse range of features in a linear classifier  , including lexical features, syntactic parse features, dependency features and semantic features  .",0,original
ur intuition is that we cannot apply our binarization to Collins  ,0,original
"Following the suggestions in  , Core et al. consider kappa scores above 0.67 to indicate significant agreement and scores above 0.8 reliable agreement.",0,original
There is a large number of potentially informative features that could play a role in correctly predicting the tag of an unknown word  .,0,original
Other possibilities for the weighting include assigning constant one or the exponential of the final score etc. One of the advantages of the proposed phrase training algorithm is that it is a parameterized procedure that can be optimized jointly with the trans82 lation engine to minimize the final translation errors measured by automatic metrics such as BLEU  .,0,original
"After unioning the Viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion  .",0,original
"By contrast, alternative approaches, like Collins  , apply an additional transformation to each tree in the tree-bank, splitting each rule into small parts, which finally results in a new grammar covering many more sentences than the explicit one.",0,original
All of the features of the ATR/Lancaster Treebank that are described below represent a radical departure from extant large-scale   treebanks.,0,original
"2.1 Scale-dependence It has been shown that varying the size of the context considered for a word can impact upon the performance of applications  , there being no ideal window size for all applications.",0,original
"The commonly used phrase extraction approach based on word alignment heuristics   as described in   is a special case of the algorithm, where candidate phrase pairs are restricted to those that respect word alignment boundaries.",0,original
"We have already shown in Section 3 how to solve  ; here we avoid   by maximizing conditional likelihood, marginalizing out the hidden variable, denotedz: max vector summationdisplay x,y p log summationdisplay z pvector    This sort of conditional training with hidden variables was carried out by Koo and Collins  , for example, in reranking; it is related to the information bottleneck method   and contrastive estimation  .",0,original
"This model is trained on approximately 5 million sentence pairs of Hansard   and UN proceedings which have been aligned on a sentence-by-sentence basis by the methods of  , and then further aligned on a word-by-word basis by methods similar to  .",0,original
The use of such relations   for various purposes has received growing attention in recent research  .,0,original
"The third exploits automatic subjectivity analysis in applications such as review classification  ), mining texts for product reviews  ), summarization  ), information extraction  ), 1Note that sentiment, the focus of much recent work in the area, is a type of subjectivity, specifically involving positive or negative opinion, emotion, or evaluation.",0,original
3.2 F-Structure Based NLD Recovery   presented a NLD recovery algorithm operating at LFG f-structure for treebankbased LFG approximations.,0,original
"We do not consider mixed features between words and POS tags as in  , that is, a single feature consists of either words or tags.",0,original
"Our approach is to use finite-state approximations of long-distance dependencies, as they are described in   for Dependency Grammar   and   for Lexical Functional Grammar  .",0,original
The recent work of   and   were also sources of inspiration.,0,original
"A ~ value of 0.8 or greater indicates a high level of reliability among raters, with values between 0.67 and 0.8 indicating only moderate agreement  .",0,original
"It is clear that Appendix B contains far fewer true non-compositional phrases than Appendix A. 7 Related Work There have been numerous previous research on extracting collocations from corpus, e.g.,   and  .",0,original
??Initial phrase pairs are identified following the procedure typically employed in phrase based systems  .,0,original
"A similar approach is used here, including a collapsed version of the Treebank POS tag set  , with additions for specific words  , compound punctuation  , and a general emoticon tag, resulting in a total of 41 tags.",0,original
"In order increase the likelihood that 909 only true paraphrases were considered as phraselevel alternations for an example, extracted sentences were clustered using complete-link clustering using a technique proposed in  .",0,original
"Using techniques described in Church and Hindle  , Church and Hanks  , and Hindle and Rooth  , Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus.",0,original
"First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases   and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization  .",0,original
"Stress is an attribute of syllables, but syllabification is a non-trivial task in itself  .",0,original
p and pt are feature weights set by performing minimum error rate training as described in Och  ,0,original
"of ACL 1990  , F. Smadja, Retrieving collocations fi'cma text: XTRACT,  .",0,original
"In Step 3, a simple perceptron update   is performed.",0,original
"Two disjoint corpora are used in steps 2 and 5, both consisting of complete articles taken from the Wall Street Journal Treebank Corpus  .",0,original
"2.2 Using Log-Likelihood-Ratios to Estimate Word Translation Probabilities Our method for computing the probabilistic translation lexicon LLR-Lex is based on the the Log2http://www.fjoch.com/GIZA++.html Likelihood-Ratio   statistic  , which has also been used by Moore   and Melamed   as a measure of word association.",0,original
Their experiments were performed using a decoder based on IBM Model 4 using the translation techniques developed at IBM  .,0,original
"Given two sentences X and Y, the WLCS score of X and Y can be computed using the similar dynamic programming procedure as stated in  .",0,original
2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods  .,0,original
"In the following sections, we present the best performing set of feature templates as determined on the development data set using only the supervised training setting; our feature templates have thus not been influenced nor extended by the unsupervised data.13 11The full list of tags, as used by  , also makes the underlying Viterbi algorithm unbearably slow.",0,original
The trigger-based lexicon model used in this work follows the training procedure introduced in   and is integrated directly in the decoder instead of being applied in n-best list reranking.,0,original
"These tools are important in that the strongest collocational associations often represent different word senses, and thus 'they provide a powerful set of suggestions to the lexicographer for what needs to be accounted for in choosing a set of semantic tags'  .",0,original
The kappa value   was used to evaluate the agreement among the judges and to estimate how difficult the evaluation task was.,0,original
"The Maximum Entropy model   is a conditional model that assigns a probability to every possible parse  for a given sentence s. The model consists of a set of m feature functions fj  that describe properties of parses, together with their associated weights j. The denominator is a normalization term where Y   is the set of parses with yield s: p  = exp )summationtext yY   exp ))   The parameters   j can be estimated efficiently by maximizing the regularized conditional likelihood of a training corpus  :  = argmax  logL   summationtextm j=1  2j 22   where L  is the likelihood of the training data.",0,original
"Many traditional clustering techniques   attempt to maximize the average mutual information of adjacent clusters  = 21, 2 12 2121 ) |  ,  where the same clusters are used for both predicted and conditional words.",0,original
"As expected, as we double the size of the data, the BLEU score   increases.",0,original
"Third, we hope that the improved parses of bitext will serve as higher quality training data for improving monolingual parsing using a process similar to self-training  .",0,original
"While choosing an optimum window size for an application is often subject to trial and error, there are some generally recognized trade-offs between small versus large windows, such as the impact of data-sparseness, and the nature of the associations retrieved   Measures based on distance between words in the text.",0,original
"Two error rates: the sentence error rate   and the word error rate   that we seek to minimize, and BLEU  , that we seek to maximize.",0,original
"Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language  .",0,original
3.1 The Likelihood Ratio We adopted a method for collocation discovery based on the likelihood ratio  .,0,original
"Recently, Wikipedia is emerging as a source for extracting semantic relationships  .",0,original
"As a model learning method, we adopt the maximum entropy model learning method  .",0,original
"This is in contrast to work by researchers such as Schiitze and Pedersen  , Brown et al   and Futrelle and Gauch  , where it is often the most frequent words in the lexicon which are clustered, predominantly with the purpose of determining their grammatical classes.",0,original
An exception is the use of similarity for alleviating the sparse data problem in language modeling  .,0,original
"However, at the short term, the incorporation of these type of features will force us to either build a new decoder or extend an existing one, or to move to a new MT architecture, for instance, in the fashion of the architectures suggested by Tillmann and Zhang   or Liang et al.",0,original
atnaparkhi   estimates a POS tagging error rate of 3% in the Treebank,0,original
4.5.2 BLEU on NIST MT Test Sets We use MT02 as the development set4 for minimum error rate training    .,0,original
"3For decoding, loc is averaged over the training iterations as in Collins and Roark  .",0,original
"4.1 Baseline Our baseline system is a fairly typical phrasebased machine translation system   built within the framework of a feature-based exponential model containing the following features: Table 1: Language Resources Corpus Train Dev Eval NC Spanish sentences 74K 2,001 2,007 words 2,048K 49,116 56,081 vocab 61K 9,047 8,638 length 27.6 24.5 27.9 OOV    5.2 / 2.9 1.4 / 0.9 English sentences 74K 2,001 2,007 words 1,795K 46,524 49,693 vocab 47K 8,110 7,541 length 24.2 23.2 24.8 OOV    5.2 / 2.9 1.2 / 0.9 perplexity  349 / 381 348 / 458 EP Spanish sentences 1,404K 1,861 2,000 words 41,003K 50,216 61,293 vocab 170K 7,422 8,251 length 29.2 27.0 30.6 OOV    2.4 / 0.1 2.4 / 0.2 English sentences 1,404K 1,861 2,000 words 39,354K 48,663 59,145 vocab 121K 5,869 6,428 length 28.0 26.1 29.6 OOV    1.8 / 0.1 1.9 / 0.1 perplexity  210 / 72 305 / 125 Table 2: Testset 2009 Corpus Test NC Spanish sentences 3,027 words 80,591 vocab 12,616 length 26.6  Source-target phrase translation probability  Inverse phrase translation probability  Source-target lexical weighting probability  Inverse lexical weighting probability  Phrase penalty  Language model probability  Lexical reordering probability  Simple distance-based distortion model  Word penalty For the training of the statistical models, standard word alignment  ) and language modeling  ) tools were used.",0,original
"For nonprojective parsing, the analogy to the inside algorithm is the O  matrix-tree algorithm, which is dominated asymptotically by a matrix determinant  .",0,original
"Expectation Evaluation is the soul of parameter estimation  ,  .",0,original
"Examples of formalisms using this approach include the work of Magerman  , Charniak  , Collins  , and Goodman  .",0,original
Our starting point is the work done by Zettlemoyer and Collins on parsing using relaxed CCG grammars    .,0,original
"Due to its popularity for unsupervised POS induction research   and its often-used tagset, for our initial research, we use the Wall Street Journal   portion of the Penn Treebank  , with 36 tags  , and we use sections 00-18, leaving held-out data for future experiments.4 Defining frequent frames as those occurring at 4Even if we wanted child-directed speech, the CHILDES database   uses coarse POS tags.",0,original
"In the WSD work involving the use of context, we can find two approaches: one that uses few strong contextual evidences for disambiguation purposes, as exemplified by  ; and the other that uses weaker evidences but considers a combination of a number of them, as exemplified by  .",0,original
"Again, we find the clearest patterns in the graphs for precision, where Malt has very low precision near the root but improves with increasing depth, while MST shows the opposite trend  .",0,original
Theyalsoappliedself-training to domain adaptation of a constituency parser  .,0,original
"Aligning tokens in parallel sentences using the IBM Models  ,   may require less information than full-blown translation since the task is constrained by the source and target tokens present in each sentence pair.",0,original
1.2 Statistical modeling for translation Earlier work in statistical machine translation   is based on the noisy-channel formulation where T = arg max T p  = argmax T p p    where the target language model p  is further decomposed as p  / productdisplay i p  where k is the order of the language model and the translation model p  has been modeled by a sequence of five models with increasing complexity  .,0,original
"In this study, we use the Google Web 1T 5gram Corpus  .",0,original
"To identify these, we use a word-aligned corpus annotated with parse trees generated by statistical syntactic parsers  .",0,original
"In recent years, many researchers have employed statistical models   or association measures   to build alignment links.",0,original
"In the February 2004 version of the PropBank corpus, annotations are done on top of the Penn TreeBank II parse trees  .",0,original
3The usefulness of position varies significantly in different genres  .,0,original
The forest representation was obtained by adopting chart generation   where ambiguous candidates are packed into an equivalence class and mapping a chart into a forest in the same way as parsing.,0,original
"Under the maximum entropy framework  , evidence from different features can be combined with no assumptions of feature independence.",0,original
"The system combination weights  one for each system, LM weight, and word and NULL insertion penalties  were tuned to maximize the BLEU   score on the tuning set  .",0,original
The extension of dynamic SBNs with incrementally specified model structure   was proposed and applied to constituent parsing in  .,0,original
Several researchers  ) work on reducing the granularity of sense inventories for WSD.,0,original
"3.5 Maximum Entropy Model In order to build a unified probabilistic query alteration model, we used the maximum entropy approach of  , which Li et al.",0,original
Turney   reported that the NEAR operator outperformed simple page co-occurrence for his purposes; our early experiments informally showed the same for this work.,0,original
The learning methods using in discriminative parsing are Perceptron   and online large-margin learning    .,0,original
"Since Czech is a language with relatively high degree of word-order freedom, and its sentences contain certain syntactic phenomena, such as discontinuous constituents  , which cannot be straightforwardly handled using the annotation scheme of Penn Treebank  , based on phrase-structure trees, we decided to adopt for the PCEDT the dependency-based annotation scheme of the Prague Dependency Treebank  PDT  .",0,original
"For example, we can use automatically extracted hyponymy relations  , or automatically induced MN clusters  .",0,original
"Indeed, in the II scenario,   reported no improvement of the base parser for small   and large   seed datasets respectively.",0,original
e also trained an HMM aligner as described in DeNero and Klein   and used the posteriors of this model as features,0,original
ur study is also different from these previous ones in that measuring the agreement among annotators became an issue  ,0,original
The MBT POS tagger   is used to provide POS information.,0,original
"Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words   or positive and negative words  ; classifying sentences in a document as either subjective or objective  ; identifying or classifying appraisal targets  ; identifying the source of an opinion in a text  , whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods  .",0,original
4 Related work Algorithms for retrieving collocations has been described    .,0,original
"Significant neighbor-based co-occurrence: As discussed in  , it is possible to measure the amount of surprise to see two neighboring words in a corpus at a certain frequency under the assumption of independence.",0,original
"For example, work which failed to detect improvements in translation quality with the integration of word sense disambiguation  , or work which attempted to integrate syntactic information but which failed to improve Bleu   may deserve a second look with a more targeted manual evaluation.",0,original
"Given that semantically similar words can be identified automatically on the basis of distributional properties and linguistic cues  , identifying the semantic orientation of words would allow a system to further refine the retrieved semantic similarity relationships, extracting antonyms.",0,original
"Lee & Barzilay  , for example, use MultiSequence Alignment   to build a corpus of paraphrases involving terrorist acts.",0,original
"The first of these nonstructural problems with Model 1, as standardly trained, is that rare words in the source language tend to act as garbage collectors  , aligning to too many words in the target language.",0,original
", 1989), e.g, lexicography  , information retrieval  , text input  , etc. This paper will touch on its feasibility in topic identification.",0,original
e follow   in using a tree kernel to represent structural information using the subtree that covers a pronoun and its antecedent candidate,0,original
"Illustrative clusterings of this type can also be found in Pereira, Tishby, and Lee  , Brown, Della Pietra, Mercer, Della Pietra, and Lai  , Kneser and Ney  , and Brill et al.",0,original
"Second, several tagging experiments on newspaper language, whether statistical   or rule-based  , report that the tagging accuracy for unknown words is much lower than the overall accuracy.2 Thus, the lower percentage of unknown words in medical texts seems to be a sublanguage feature beneficial to POS taggers, whereas the higher proportion of unknown words in newspaper language seems to be a prominent source of tagging errors.",0,original
"Recently, methods for training binary classifiers to maximize the F 1 -score have been proposed for SVM   and LRM  .",0,original
Our human word alignments do not distinguish between Sure and Probable links  .,0,original
"Like Haghighi and Klein  , we give our model information about the basic types of pronouns in English.",0,original
The true segmentation can now be compared with the N-best list in order to train an averaged perceptron algorithm  .,0,original
"1 Introduction Sentiment classification is a special task of text categorization that aims to classify documents according to their opinion of, or sentiment toward a given subject    .",0,original
It has been shown that one sense per discourse property can improve the performance of bootstrapping algorithm  .,0,original
  introduce IBM Models 1-5 for alignment modelling; Vogel et al,0,original
"1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts  , semantic lexicons  , concept lists  , and word similarity lists  .",0,original
Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar    .,0,original
"For evaluation we have selected a set of 8 metric variants corresponding to seven different families: BLEU    , NIST    , GTM F1-measure    , 1-WER  , 1-PER  , ROUGE     and METEOR3  .",0,original
"2 Recap of BLEU, ROUGE-W and METEOR The most commonly used automatic evaluation metrics, BLEU   and NIST  , are based on the assumption that The closer a machine translation is to a promt1: Life is like one nice chocolate in box ref: Life is just like a box of tasty chocolate ref: Life is just like a box of tasty chocolate mt2: Life is of one nice chocolate in box Figure 1: Alignment Example for ROUGE-W fessional human translation, the better it is  .",0,original
"255 Meteor  , Precision and Recall  , and other such automatic metrics may also be affected to a greater or lesser degree because they are all quite rough measures of translation similarity, and have inexact models of allowable variation in translation.",0,original
"Yarowsky   tested the claim on about 37,000 examples and found that when a polysemous word appeared more than once in a discourse, they took on the majority sense for the discourse 99.8% of the time on average.",0,original
"Errors from the sentence boundary detector in GATE   were especially problematic because they caused the Collins parser to fail, resulting in no dependency tree information.",0,original
"In retrospect, however, there are perhaps even greater similarities to that of  .",0,original
"For phrase-based translation model training, we used the GIZA++ toolkit  , and 1.0M bilingual sentences.",0,original
"Parametertuningwasdonewithminimum error rate training  , which was used to maximize BLEU  .",0,original
3 Evaluation of Algorithms All four algorithms were run on a 3900 utterance subset of the Penn Treebank annotated corpus   provided by Charniak and Ge  .,0,original
"In fact, we still have a question as to whether SS-CRF-MER is really scalable in practical time for such a large amount of unlabeled data as used in our experiments, which is about 680 times larger than that of  .",0,original
"Using GIZA++ model 4 alignments and Pharaoh  , we achieved a BLEU score of 0.3035.",0,original
"ald, 2008), and is also similar to the Pred baseline for domain adaptation in  .",0,original
"Other linear time algorithms for rank reduction are found in the literature  , but they are restricted to the case of synchronous context-free grammars, a strict subclass of the LCFRS with f = 2.",0,original
"There are many research directions, e.g., sentiment classification    , subjectivity classification    , feature/topic-based sentiment analysis   (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald.",0,original
"There are accurate parsers available such as Chaniak parser  , Stanford parser   and Berkeley parser  , among which we use the Berkeley parser 2 to help identify the head word.",0,original
"Bitexts also play a role in less automated applications such as concordancing for bilingual lexicography  , computer-assisted language learning, and tools for translators (e.g.",0,original
"However, other types of nonlocal information have also been shown to be effective   and we will examine the effectiveness of other non-local information which can be embedded into label information.",0,original
5 Comparison with related work Preliminary work on SF extraction from coq~ora was done by   and  .,0,original
"Moreover, an F-score optimization method for logistic regression has also been proposed  .",0,original
"As resolving direct anaphoric descriptions   is a much simpler problem with high performance rates as shown in previous results  , these heuristics should be applied first in a system that resolves definite descriptions.",0,original
"Within the generative model, the Bayes reformulation is used to estimate where is considered the language model, and is the translation model; the IBM   models being the de facto standard.",0,original
"Decoding with an SCFG   can be cast as a parsing problem  , in which case we need to binarize a synchronous rule with more than two nonterminals to achieve polynomial time algorithms  .",0,original
" ,   thesaurus categories  ,   translation in another language  ,   automatically induced clusters with sublexical representation  , and   hand-crafted lexicons  .",0,original
"For natural language engineers, the problem bears on information management systems like abstractive summarizers that must measure semantic overlap between sentences  , question answering modules   and machine translation  .",0,original
1992) describe one application of MI to identify word collocations; Kashioka et al,0,original
"Ratnaparkhi, 1996), a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence.",0,original
"Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications, including """"crummy"""" MT on the World Wide Web  , certain machine-assisted translation tools (e.g.",0,original
"While Schiitze and Pedersen  , Brown et al   and Futrelle and Gauch   all demonstrate the ability of their systems to identify word similarity using clustering on the most frequently occurring words in their corpus, only Grefenstette   demonstrates his system by generating word similarities with respect to a set of target words.",0,original
e solve SAT analogies with a simplified version of the method of Turney  ,0,original
Of particular relevance is other work on parsing the Penn WSJ Treebank  .,0,original
"The grammars were induced from sections 2-21 of the Penn Wall St. Journal Treebank  , and tested on section 23.",0,original
EnglishChinese   and EnglishSpanish  .,0,original
"One of the earliest attempts at extracting \interrupted collocations""""  , was that of Smadja  .",0,original
This corpus-based information typically concerns sequences of 1-3 tags or words  .,0,original
"Although few corpora annotated with semantic knowledge are available now, there are some valuable lexical databases describing the lexical semantics in dictionary form, for example English WordNet   and Chinese HowNet  .",0,original
Table 2 shows the results for English projective dependency trees extracted from the Penn Treebank   using the rules of Yamada and Matsumoto  .,0,original
odel weights were also trained following Och  ,0,original
We measure translation performance by the BLEU   and METEOR   scores with multiple translation references.,0,original
This approach gave an improvement of 2.7 in BLEU   score on the IWSLT05 Japanese to English evaluation corpus  .,0,original
"To improve raw output from decoding, Portage relies on a rescoring strategy: given a list of n-best translations from the decoder, the system reorders this list, this time using a more elaborate loglinear model, incorporating more feature functions, in addition to those of the decoding model: these typically include IBM-1 and IBM-2 model probabilities   and an IBM-1-based feature function designed to detect whether any word in one language appears to have been left without satisfactory translation in the other language; all of these feature functions can be used in both language directions, i.e. source-to-target and target-to-source.",0,original
"Firstly, rather than induce millions of xRS rules from parallel data, we extract phrase pairs in the standard way   and associate with each phrase-pair a set of target language syntactic structures based on supertag sequences.",0,original
The model weights are trained using the improved iterative scaling algorithm  .,0,original
"This is important when LARGE CUT-OFF 0 5 100 NAIVE 541,721 184,493 35,617 SASH 10,599 8,796 6,231 INDEX 5,844 13,187 32,663 Table 4: Average number of comparisons per term considering that different tasks may require different weights and measures  .",0,original
"However, by exploiting the fact that the underlying scores assigned to competing hypotheses, w , vary linearly w.r.t. changes in the weight vector, w, Och   proposed a strategy for finding the global minimum along any given search direction.",0,original
We annotated with the BIO tagging scheme used in syntactic chunkers  .,0,original
918 English For English we used the Wall Street Journal section of the Penn Treebank  .,0,original
The translation models were pharse-based   created using the GIZA++ toolkit  .,0,original
"We follow the method used by Kazama and Torisawa  , which encodes the matching with a gazetteer entity using IOB tags, with the modication for Japanese.",0,original
"The prime public domain examples of such implementations include the TrigramsnTags tagger  , Xerox tagger   and LT POS tagger  .",0,original
"For comparison, Haghighi and Klein   report an unsupervised baseline of 41.3%, and a best result of 80.5% from using hand-labeled prototypes and distributional similarity.",0,original
We used a publicly available tagger   to provide the part-of-speech tags for each word in the sentence.,0,original
6 Discussion Lack of interannotator agreement presents a significant problem in annotation efforts  .,0,original
"Examples of such techniques are Markov Random Fields  , and boosting or perceptron approaches to reranking  .",0,original
Barzilay & Lee   employ Multiple Sequence Alignment   to align strings extracted from closely related news articles.,0,original
"  calculated the scores by matching the unigrams on the surface forms, stemmed forms and senses.",0,original
"1 Full Morphological Tagging English Part of Speech   tagging has been widely described in the recent past, starting with the   paper, followed by numerous others using various methods: neural networks  , HMM tagging  , decision trees  , transformation-based error-driven learning  , and maximum entropy  , to select just a few.",0,original
"Thus, some research has been focused on deriving different word-sense groupings to overcome the finegrained distinctions of WN  ,  ,  ,  ,   and  .",0,original
"In particular, knowing a little about the structure of a language can help in developing annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations  .",0,original
"For mutual information  , we use two different equations: one for two-element compound nouns   and the other for three-element compound nouns  .",0,original
Hyponymy relations were extracted from definition sentences  .,0,original
"As a sanity check, we duplicated Pang et al.s   baseline in which all unigrams that appear four or more times in the training documents are used as features.",0,original
"Following Hatzivassiloglou and McKeown   and Turney  , we decided to observe how often the words from the headline co-occur with each one of the six emotions.",0,original
In   the WSJ PennTreebank corpus   is analyzed and a very detailed list of syntactic patterns that correspond to different roles of commas is created.,0,original
"For Czech, we created a prototype of the first step of this process -the part-of-speech   tagger -using Rank Xerox tools  ,  .",0,original
"This task evaluated parsing performance on 10 languages: Arabic, Basque, Catalan, Chinese, Czech, English, Greek, Hungarian, Italian, and Turkish using data originating from a wide variety of dependency treebanks, and transformations of constituency-based treebanks  .",0,original
4An adaptation of the averaged perceptron algorithm   is used to tune the model parameters.,0,original
  have build a chunker by applying transformation-based learning to sections of the Penn Treebank.,0,original
A major difference between our approach and most other models tested on the WSJ is that the DOP model uses frontier lexicalization while most other models use constituent lexicalization  .,0,original
Metrics based on word alignment between MT outputs and the references  .,0,original
"Both models have been used to achieve state-of-the-art accuracy for a wide range of languages, as shown in the CoNLL shared tasks on dependency parsing  , but McDonald and Nivre   showed that a detailed error analysis reveals important differences in the distribution of errors associated with the two models.",0,original
This metric tests the hypothesis that the probability of phrase  is the same whether phrase  has been seen or not by calculating the likelihood of the observed data under a binomial distribution using probabilities derived using each hypothesis  .,0,original
"IIowever,   have shown that knowledge of target-text length is not crucial to the model's i)ertbrmanee.",0,original
The resulting training procedure is analogous to the one presented in   and  .,0,original
"The decoder uses a binarized representation of the rules, which is obtained via a syncronous binarization procedure  .",0,original
"4 The Experiment For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text  , with section 22 reserved for testing.",0,original
"Research have also been made into alternatives to the current log-linear scoring model such as discriminative models with millions of features  , or kernel based models  .",0,original
Correspondences between MALTUS and other tagsets   were also provided  .,0,original
The statistical machine translation approach is based on the noisy channel paradigm and the Maximum-A-Posteriori decoding algorithm  .,0,original
"Coling 2008: Companion volume  Posters and Demonstrations, pages 103106 Manchester, August 2008 Range concatenation grammars for translation Anders Sgaard University of Potsdam soegaard@ling.uni-potsdam.de Abstract Positive and bottom-up non-erasing binary range concatenation grammars   with at most binary predicates  -BRCGs) is a O  time strict extension of inversion transduction grammars    .",0,original
"Since text planners cannot generate either the requisite syntactic variation or quantity of text,  , a corpus that includes texts from newspapers such as the Wall Street Journal, and which have been hand-annotated for syntax by linguists.",0,original
"All features encountered in the training data are ranked in the DL   according to the following loglikelihood ratio  : Log Pr  P j6=i Pr  We estimated probabilities via maximum likelihood, adopting a simple smoothing method  : 0.1 is added to both the denominator and numerator.",0,original
"The class-based approaches   calculate co-occurrence data of words belonging to different classes,~ rather than individual words, to enhance the co-occurrence data collected and to cover words which have low occurrence frequencies.",0,original
"edu Abstract This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus  .",0,original
"In each case the input to the network is a sequence of tag-word pairs.2 We report results for two different vocabulary sizes, varying in the frequency with which tag-word pairs must 2We used a publicly available tagger   to provide the tags.",0,original
e then apply Brills rule-based tagger   and BaseNP noun phrase chunker   to extract noun phrases from these sentences,0,original
"We see no good reason, however, why such text spans should necessarily be sentences, since the majority of tagging paradigms   do not attempt to parse an entire sentence and operate only in the local window of two to three tokens.",0,original
"Carletta mentions this problem, asking what the difference would be if the kappa statistic were computed across """"clause boundaries, transcribed word boundaries, and transcribed phoneme boundaries""""   rather than the sentence boundaries she suggested.",0,original
"So far, most of the statistical machine translation systems are based on the single-word alignment models as described in   as well as the Hidden Markov alignment model  .",0,original
"2 Related Work This method is similar to block-orientation modeling   and maximum entropy based phrase reordering model  , in which local orientations   of phrase pairs   are learned via MaxEnt classifiers.",0,original
"First, the graph-based models have better precision than the transition-based models when predicting long arcs, which is compatible with the results of McDonald and Nivre  .",0,original
"3 Haghighi and Kleins Coreference Model To gauge the performance of our model, we compare it with a Bayesian model for unsupervised coreference resolution that was recently proposed by Haghighi and Klein  .",0,original
"Most work in the area of unknown words and tagging deals with predicting part-of-speech information based on word endings and affixation information, as shown by work in  ,  ,  , and  .",0,original
"Generalized Forward Backward Reestimation Generalization of the Forward and Viterbi Algorithm In English part of speech taggers, the maximization of Equation   to get the most likely tag sequence, is accomplished by the Viterbi algorithm  , and the maximum likelihood estimates of the parameters of Equation   are obtained from untagged corpus by the ForwardBackward algorithm  .",0,original
"WordNet has been criticized for being overly finegrained  , we are using it here because it is the sense inventory used by Erk et al.",0,original
Overall % agreement among judges for 250 propositions 60.1 A commonly used metric for evaluating interrater reliability in categorization of data is the kappa statistic  .,0,original
The study is conducted on both a simple Air Travel Information System   corpus   and the more complex Wall Street Journal   corpus  .,0,original
"In order to overcome this, several methods are proposed, including minimally-supervised learning methods  ), and active learning methods  ).",0,original
"Occasionally, in 59 sentences out of 2416 on section 23 of the Wall Street Journal Penn Treebank  , the shift-reduce parser fails to attach a node to a head, producing a disconnected graph.",0,original
In this work we will use structured linear classifiers  .,0,original
owever morphosyntactic features alone cannot verify the terminological status of the units extracted since they can also select non terms  ,0,original
"In contrast, generative models are trained to maximize the joint probability of the training data, which is 1Ramshaw and Marcus   used transformation-based learning  , which for the present purposes can be tought of as a classi cation-based method.",0,original
"As far as we know, language modeling always improves with additional training data, so we add data from the North American News Text Corpus     automatically parsed with the Charniak parser   to train our language model on up to 20 million additional words.",0,original
"To determine the tree head-word we used a set of rules similar to that described by    and also used by  , which we modified in the following way:  The head of a prepositional phrase   was substituted by a function the name of which corresponds to the preposition, and its sole argument corresponds to the head of the noun phrase NP.",0,original
"4.4 Corpora We ran the three syntactic preprocessors over a total of three corpora, of varying size: the Brown corpus   and Wall Street Journal corpus  , both derived from the Penn Treebank  , and the written component of the British National Corpus  ).",0,original
This analysis depends on the SPECIALIST Lexicon and the Xerox part-of-speech tagger   and provides simple noun phrases that are mapped to concepts in the UMLS Metathesaurus using MetaMap  .,0,original
6 Related Work Several works attempt to extend WordNet with additional lexical semantic information  .,0,original
We performed experiments with two statistical classifiers: the decision tree induction system C4.5   and the Tilburg Memory-Based Learner    .,0,original
Dredze et al. also indicated that unlabeled dependency parsing is not robust to domain adaptation  .,0,original
"Unfortunately, a counterexample illustrated in   shows that the max function does not produce valid kernels in general.",0,original
"Evaluation 6.1 Evaluation at the Token Level This section compares translation model estimation methods A, B, and C to each other and to Brown et al.'s   Model 1.",0,original
"Clusters are created by means of distributional techniques in  , while in   low level synonim sets in WordNet are used.",0,original
"English POS tags were assigned by MXPOST  , which was trained on the training data described in Section 4.1.",0,original
"For the simple bag-of-word bilingual LSA as describedinSection2.2.1,afterSVDonthesparsematrix using the toolkit SVDPACK  , all source and target words are projected into a lowdimensional   LSA-space.",0,original
"Second, in keeping with ontological promiscuity  , we represent the importance of attributes by the salience of events and states in the discourse model--these states and events now have the same status in the discourse model as any other entities.",0,original
"These techniques included unweighted FS morphology, conditional random fields  , synchronous parsers  , lexicalized parsers  ,22 partially supervised training `a la  ,23 and grammar induction  .",0,original
"The underlying formalisms used has been quite broad and include simple formalisms such as ITGs  , hierarchicalsynchronousrules , string to tree models by   and  , synchronous CFG models such    , synchronous Lexical Functional Grammar inspired approaches   and others.",0,original
We then train word alignment models   using 6 Model-1 iterations and 6 HMM iterations.,0,original
The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM   is used to model it.,0,original
he tag propagation/elimination scheme is adopted from  ,0,original
"Although some early systems for web-page analysis induce rules at character-level   and DIPRE  ), most recent approaches for set expansion have used either tokenized and/or parsed free-text  , or have incorporated heuristics for exploiting HTML structures that are likely to encode lists and tables  .",0,original
illmann and Zhang   trained their feature set using an online discriminative algorithm,0,original
"In a second top-down pass similar to Huang and Chiang  , we can recalculate psyn  for alternative derivations in the hypergraph; potentially correcting search errors made in the first pass.",0,original
hese include the bootstrapping approach  ,0,original
One example is the algorithm for word sense disambiguation in  .,0,original
"Our trees look just like syntactic constituency trees, such as those in the Penn TreeBank  , 141 ROOT PROT PROT NN PEBP2 PROT NN alpha NN A1 , , PROT NN alpha NN B1 , , CC and PROT NN alpha NN B2 NNS proteins VBD bound DT the DNA PROT NN PEBP2 NN site IN within DT the DNA NN mouse PROT NN GM-CSF NN promoter . . Figure 1: An example of our tree representation over nested named entities.",0,original
"The annotation guidelines for the Penn Treebank flattened noun phrases to simplify annotation  , so there is no complex structure to NPs.",0,original
"Instead of directly minimizing error as in earlier work  , we decompose the decoding process into a sequence of local decision steps based on Eq.",0,original
"Second, McDonald and Satta   propose an O  algorithm for computing the marginals, as opposed to the O  matrix-inversion approach used by Smith and Smith   and ourselves.",0,original
It can be applied to complicated models such IBM Model-4  .,0,original
"1 Introduction Word alignmentdetection of corresponding words between two sentences that are translations of each otheris usually an intermediate step of statistical machine translation    , but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval.",0,original
"As suggested in  , we use the averaged perceptron when applying the model to held-out or test data.",0,original
"Even if the idea of using Wikipedia links for disambiguation is not novel  , it is applied for the first time to FrameNet lexical units, considering a frame as a sense definition.",0,original
"Following recent research about disambiguation models on linguistic grammars  , we apply a log-linear model or maximum entropy model   on HPSG derivations.",0,original
"We can use a linear-time algorithm   to detect non-ITG movement in our high-confidence links, and remove the offending sentence pairs from our training corpus.",0,original
"12 As such, we resort to an approximation: Voted Perceptron training  .",0,original
"This method is very similar to some ideas in domain adaptation  , but we argue that the underlying problems are quite different.",0,original
Similar observations have been made in the context of tagging problems using maximum-entropy models  .,0,original
intuition comes from an observation by Yarowsky   regarding multiple tokens of words in documents,0,original
"In many applications, it has been shown that sentences with subjective meanings are paid more attention than factual ones  .",0,original
"The first stage parser is a best-first PCFG parser trained on sections 2 through 22, and 24 of the Penn WSJ treebank  .",0,original
"In this work, model fit is reported in terms of the likelihood ratio statistic, G 2, and its significance  .",0,original
State-of-the-art statistical parsers trained on the Penn Treebank     proS a8a8 a8a8a8 a72a72 a72a72a72 NP-SBJ a16a16a16 a80a80a80the authority VP a16a16a16 a16a16a16a16 a0 a0a0 a64 a64a64 a80a80a80 a80a80a80a80 VBD dropped PP-TMP a8a8 a72a72IN at NP NN midnight NP-TMP NNP Tuesday PP-DIR a8a8 a72a72TO to NP QP a16a16a16 a80a80a80$ 2.80 trillion Figure 1: A sample syntactic structure with function labels.,0,original
"However, current statistical dependency parsers provide worse results if the dependency length becomes longer  .",0,original
"They used the Bleu evaluation metric  , but capped the n-gram precision at 4-grams.",0,original
"This strategy is commonly used in multi-document summarization  , where the combination step eliminates the redundancy across selected excerpts.",0,original
Table 6: Lexicalized Features for Joint Models aging of the weights suggested by  .,0,original
Our baseline method for ambiguity resolution is the Collins parser as implemented by Bikel  .,0,original
"The release has implementations for BLEU  , WER and PER error criteria and it has decoding interfaces for Phramer and Pharaoh.",0,original
"As far as the log-linear combination of float features is concerned, similar training procedures have been proposed in  .",0,original
The tree-based reranker includes the features described in   as well as features based on non-projective edge attributes explored in  .,0,original
"If POS denotes the POS of the English word, we can define the word-to-word distance measure   as POS POS   Ratnaparkhis POS tagger   was used to obtain POS tags for each word in the English sentence.",0,original
"The translation quality is evaluated by BLEU metric  , as calculated by mteval-v11b.pl 6 with case-sensitive matching of n-grams.",0,original
"But it makes obvious that   were tackling a problem different from   given the fact that their baseline was at 59% guessing noun attachment  .3 Of course, the baseline is not a direct indicator of the difficulty of the disambiguation task.",0,original
"3.2 Translation quality Table 2 presents the impact of parse quality on a treelet translation system, measured using BLEU  .",0,original
"All words occurring less than 3 times in the training data, and words in test data that were not seen in training, are unknown words and are replaced with the UNKNOWN token. Note this threshold is smaller than the one used in   since the corpora used in our experiments are smaller.",0,original
"In other words, learning with L1 regularization naturally has an intrinsic effect of feature selection, which results in an 97 efficient and interpretable inference with almost the same performance as L2 regularization  .",0,original
"4.3 Baseline We use a standard log-linear phrase-based statistical machine translation system as a baseline: GIZA++ implementation of IBM word alignment model 4  ,8 the refinement and phrase-extraction heuristics described in  , minimum-error-rate training 7More specifically, we choose the first English reference from the 7 references and the Chinese sentence to construct new sentence pairs.",0,original
"For the combined set  , we also show the 95% BLEU confidence interval computed using bootstrap resampling  .",0,original
4.1 Experimental Set-up We used two different corpora: PropBank   along with PennTree bank 2   and FrameNet.,0,original
.1 Linear Models for NLP We follow the framework outlined in Collins  ,0,original
"That is, phrases are heuristically extracted from word-level alignments produced by doing GIZA++ training on the corresponding parallel corpora  .",0,original
"We used a non-projective model, trained using an application of the matrix-tree theorem   for the first-order Czech models, and projective parsers for all other models.",0,original
"Besides continued research on improving MT techniques, one line of research is dedicated to better exploitation of existing methods for the combination of their respective advantages  .",0,original
"For English there are many POS taggers, employing machine learning techniques like transformation-based error-driven learning  , decision trees  , markov model  , maximum entropy methods   etc. There are also taggers which are hybrid using both stochastic and rule-based approaches, such as CLAWS  .",0,original
  represent chunking as tagging problem and the CoNLL2000 shared task   is now the standard evaluation task for chunking English.,0,original
4.5 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars    .,0,original
"Consequently, semi-supervised learning, which combines both labeled and unlabeled data, has been applied to some NLP tasks such as word sense disambiguation  , classification  , clustering  , named entity classification  , and parsing  .",0,original
"For example, the distancebased reordering model   allows a decoder to translate in non-monotonous order, under the constraint that the distance between two phrases translated consecutively does not exceed a limit known as distortion limit.",0,original
"4 POS Tagger and Named Entity Recognizer For the POS tagging task, the tagger is built based on the work of Ratnaparkhi   which was applied for English POS tagging.",0,original
The last two counts   were performed on a 29-million word parsed corpus  ).,0,original
"Once we obtain the augmented phrase table, we should run the minimum-error-rate training   with the augmented phrase table such that the model parameters are properly adjusted.",0,original
"It is interesting to constrast this method with the """"parse-parse-match"""" approaches that have been reported recently for producing parallel bracketed corpora  .",0,original
" ) or Wikipedia  , and the contextual role played by an NP  ).",0,original
The {ij}j=1m weights are estimated during the training phase to maximize the likelihood of the data  .,0,original
"Thus, Nakagawa   and Hall   both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme.",0,original
It also shows that DOP's frontier lexicalization is a viable alternative to constituent lexicalization  .,0,original
"As has been pointed out by Dunning  , the calculation of log  assumes a binomial distribution.",0,original
"For these experiments, we have implemented an alignment package for IBM Model 4 using a hillclimbing search and Viterbi training as described in  , and extended this to use new submodels.",0,original
"Schtze, 1993) is not suited to highly skewed distributions omni-present in natural language.",0,original
"Unlike with factored models   or additional translation lexicons  , we do not generate the surface form back from the lemma translation, which means that tense, gender and number information are 151 news-dev2009a representation OOV % METEOR BLEU NIST baseline surface form only 2.24 49.05 20.45 6.135 decoding lemma backoff 2.13 49.12 20.44 6.143 word alignment lemma+POS for all 2.24 48.87 20.36 6.145 lemma+POS for adj 2.25 48.94 20.46 6.131 lemma+POS for verbs 2.21 49.05 20.47 6.137 decoding + alignment backoff + all 2.10 48.97 20.36 6.147 backoff + adj 2.12 49.05 20.48 6.140 backoff + verbs 2.08 49.15 20.50 6.148 news-dev2009b representation OOV % METEOR BLEU NIST baseline surface form only 2.52 49.60 21.10 6.211 decoding lemma backoff 2.43 49.66 21.02 6.210 word alignment lemma+POS for all 2.53 49.56 21.03 6.199 lemma+POS for adj 2.52 49.74 21.00 6.213 lemma+POS for verbs 2.47 49.73 21.10 6.217 decoding+alignment backoff + all 2.44 49.59 20.92 6.194 backoff + adj 2.43 49.80 21.03 6.217 backoff + verbs 2.39 49.80 21.03 6.217 Table 2: Evaluation of the decoding backoff strategy, the modified word alignment strategy and their combination Input Meme sil demissionnait, la situation ne changerait pas.",0,original
  The heuristics in Section 6 are designed specifically to find the interesting features in that featureless desert.,0,original
"The TRIPS structure generally has more levels of structure   than the Penn Treebank analyses  , in particular for base noun phrases.",0,original
"To determine the target distribution we classified 171   randomly selected utterances from the TownInfo data, that were used as a development set.2 In Table 1 we can see that 15.2 % of the trees in the artificial corpus will be NP NSUs.3 4 Data generation We constructed our artificial corpus from sections 2 to 21 of the Wall Street Journal   section of the Penn Treebank corpus   2We discarded very short utterances   since they dont need parsing.",0,original
"2 Statistical Machine Translation We use a log-linear approach   in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: e = argmax e wT h    where h  is a large-dimension feature vector.",0,original
Similar techniques are used in   for socalled direct translation models instead of those proposed in  .,0,original
"Recent work has explored two-stage decoding, which explicitly decouples decoding into a source parsing stage and a target language model integration stage  .",0,original
urney   used collocation with excellent or poor to obtain positive and negative clues for document classification,0,original
Context extraction begins with a Maximum Entropy POS tagger and chunker  .,0,original
Finally we use Minimum Error Training     to train log-linear scaling factors that are applied to the WFSTs in Equation 1.,0,original
The standard method to overcome this problem to use the model in both directions   and applying heuristic-based combination techniques to produce a refined alignment  henceforth referred to as RA. Several researchers have proposed algorithms for improving word alignment systems by injecting additional knowledge or combining different alignment models.,0,original
"So far, this approach has been taken by a lot of researchers  .",0,original
"In  , these forbidden subsequences are called inside-out transpositions.",0,original
"We evaluate translation output using case-insensitive BLEU  , as provided by NIST, and METEOR  , version 0.6, with Porter stemming and WordNet synonym matching.",0,original
"Furthermore, they extended WSD to phrase sense disambiguation    .",0,original
4.1 Translation Modeling We can test our models utility for translation by transforming its parameters into a phrase table for the phrasal decoder Pharaoh  .,0,original
"The query tions, the syntax, semantics, and abstract knowledge representation have type declarations   which help to detect malformed representations.",0,original
"The sequential classi cation approach can handle many correlated features, as demonstrated in work on maximum-entropy   and a variety of other linear classi ers, including winnow  , AdaBoost  , and support-vector machines  .",0,original
The latter problem of developing methods that can work with incomplete supervisory information is addressed in a subsequent effort  .,0,original
"In the general language UPenn annotation efforts for the WSJ sections of the Penn Treebank  , sentences are annotated with POS tags, parse trees, as well as discourse annotation from the Penn Discourse Treebank  , while verbs and verb arguments are annotated with Propbank rolesets  .",0,original
"Word alignments are provided by GIZA++   with grow-diag-final combination, with infrastructure for alignment combination and phrase extraction provided by the shared task.",0,original
"Therefore, including a model based on surface forms, as suggested  , is also necessary.",0,original
"Partitioning 2: Medium and low frequency words As noted in  , log-likelihood statistics are able to capture word bi-gram regularities.",0,original
"Importantly, this Bayesian approach facilitates the incorporation of sparse priors that result in a more practical distribution of tokens to lexical categories  .",0,original
We could also use the value of semantic similarity and relatedness measures   or the existence of hypernym or hyponym relations as features.,0,original
"Although the parser is not yet complete, we expect that its breath of coverage of the language will be substantially larger than that of other Government-binding parsers recently reported in the literature  , Kuhns  , Sharp  , and Wehrli  ).",0,original
ean and Riloff   proposed the use of caseframe networks as a kind of contextual role knoweldge for anaphora resolution,0,original
We used GIZA++ package   to train IBM translation models.,0,original
"We present a new implication of Wus   Inversion Transduction Grammar   Hypothesis, on the problem of retrieving truly parallel sentence translations from large collections of highly non-parallel documents.",0,original
"The acquisition of clues is a key technology in these research efforts, as seen in learning methods for document-level SA   and for phraselevel SA  .",0,original
"Second, phrase translation pairs are extracted from the word alignment corpus  .",0,original
The structure of the graphical model resembles IBM Model 1   in which each target   word is assigned one or more source   words.,0,original
In Section 3 we then describe the probabilistic taxonomy learning model introduced by  .,0,original
section 20 Majority voting         accuracy precision O:98.10% C:98.29% 93.63% O:98.1% C:98.2% 93.1% 97.58% 92.50% 97.37% 91.80% 91.6% recall FZ=I 92.89% 93.26 92.4% 92.8 92.25% 92.37 92.27% 92.03 91.6% 91.6 section 00 accuracy precision Majority voting 0:98.59% C:98.65% 95.04% r   98.04% 93.71%   97.8% 93.1% recall FB=I 94.75% 94.90 93.90% 93.81 93.5% 93.3 Table 3: The results of majority voting of different data representations applied to the two standard data sets put forward by   compared with earlier work.,0,original
"Words surrounding the current word have been occasionally used in taggers, such as  , Brills transformation based tagger  , and the HMM model of Lee et al.",0,original
"First, two maximum entropy classifiers   are applied, where the first predicts clause start labels and the second predicts clause end labels.",0,original
"We selected 580 short sentences of length at most 50 characters from the 2002 NIST MT Evaluation test set as our development corpus and used it to tune s by maximizing the BLEU score  , and used the 2005 NIST MT Evaluation test set as our test corpus.",0,original
ntroduction Translation of two languages with highly different morphological structures as exemplified by Arabic and English poses a challenge to successful implementation of statistical machine translation models  ,0,original
"2.2 Closed Challenge Setting The organization provided training, development and test sets derived from the standard sections of the Penn TreeBank   and PropBank   corpora.",0,original
"At the sentence level,   employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora.",0,original
This is the strategy that is usually adopted in other phrase-based MT approaches  .,0,original
The idea of word class   gives a general solution to this problem.,0,original
"Furthermore, statistical generation systems   could use  as a means of directly optimizing information ordering, much in the same way MT systems optimize model parameters using BLEU as a measure of translation quality  .",0,original
methods for syntactic SMT held to this assumption in its entirety  .,0,original
Adaptations to the algorithms in the presence of ngram LMs are discussed in  .,0,original
"4 Experiments We evaluated our classifier-based best-first parser on the Wall Street Journal corpus of the Penn Treebank   using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.",0,original
"As an example, consider the fiat NP structures that are in the Penn Treebank  .",0,original
"Originally introduced as a byproduct of training statistical translation models in  , word alignment has become the first step in training most statistical translation systems, and alignments are useful to a host of other tasks.",0,original
Moses used the development data for minimum error-rate training   of its small number of parameters.,0,original
The class based disambiguation operator is the Mutual Conditioned Plausibility    .,0,original
"The way a decoder constructs translation hypotheses is directly related to the weights for different model features in a SMT system, which are usually optimized for a given set of models with minimum error rate training     to achieve better translation performance.",0,original
We performed feature selection by incrementally growing a log-linear model with order0 features f  using a forward feature selection procedure similar to  .,0,original
Networks   97.24 SVM   97.05 ME based a bidirectional inference   97.15 Guided learning for bidirectional sequence classification   97.33 AdaBoost.SDF with candidate features   97.32 AdaBoost.SDF with candidate features   97.32 SVM with candidate features   97.32 Text Chunking F=1 Regularized Winnow + full parser output   94.17 SVM-voting   93.91 ASO + unlabeled data   94.39 CRF+Reranking  94.12 ME based a bidirectional inference   93.70 LaSo     94.4 HySOL   94.36 AdaBoost.SDF with candidate featuers   94.32 AdaBoost.SDF with candidate featuers   94.30 SVM with candidate features   94.31 One of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.,0,original
The comparison phrasal system was const ructed using the same GIZA++ alignments and the heuristic combination described in  .,0,original
"For our experiments we used the following features, analogous to Pharaohs default feature set:  P  and P , the latter of which is not found in the noisy-channel model, but has been previously found to be a helpful feature  ;  the lexical weights Pw  and Pw   , which estimate how well the words in  translate the words in ;2  a phrase penalty exp , which allows the model to learn a preference for longer or shorter derivations, analogous to Koehns phrase penalty  .",0,original
"The modify features involve the dependency parse tree for the sentence, obtained by first parsing the sentence   and then converting the tree into its dependency representation  .",0,original
"This increase of probabilities is defined as multiplicative change   as follows:   = P /P    The main innovation of the model in   is the possibility of adding at each step the best relation N = {Ri,j}as well as N = I  that is Ri,j with all the relations by the existing taxonomy.",0,original
"The simple model 1   for the translation of a SL sentence d = dldt in a TL sentence e = el em assumes that every TL word is generated independently as a mixture of the SL words: m l P ,,~ H ~ t    j=l i=O In the equation above t  stands for the probability that ej is generated by di.",0,original
"2 Related Work Question Answering has attracted much attention from the areas of Natural Language Processing, Information Retrieval and Data Mining  .",0,original
"First, a parsing-based approach attempts to recover partial parses from the parse chart when the input cannot be parsed in its entirety due to noise, in order to construct a   semantic representation  .",0,original
One of the applications is in automatic summarization in order to compress sentences extracted for the summary  .,0,original
"This allows us to compute the conditional probability as follows  : P  = ~i~ '    Z~  Z~  = ~I~I~ '    ff i The maximum entropy estimation technique guarantees that for every feature gi, the expected value of gi according to the M.E. model will equal the empirical expectation of gi in the training corpus.",0,original
"Following   and other work on general-purpose generators, we adopt BLEU score  , average simple string accuracy   and percentage of exactly matched sentences for accuracy evaluation.6 For coverage evaluation, we measure the percentage of input fstructures that generate a sentence.",0,original
The rationale for using Kappa is explained in  .,0,original
The task originally emerged as an intermediate result of training the IBM translation models  .,0,original
POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit  ; both were trained from the annotated Penn Treebank corpus  .,0,original
This example is adapted from Resnik  ,0,original
The learning algorithm used for each stage of the classification task is a regularized variant of the structured Perceptron  .,0,original
"Salience Feature Pronoun Name Nominal TOP 0.75 0.17 0.08 HIGH 0.55 0.28 0.17 MID 0.39 0.40 0.21 LOW 0.20 0.45 0.35 NONE 0.00 0.88 0.12 Table 2: Posterior distribution of mention type given salience  ) 3.3 Modifications to the H&K Model Next, we discuss the potential weaknesses of H&Ks model and propose three modifications to it.",0,original
"Instead of using the NP bracketing information present in the tagged Treebank data, Ramshaw and Marcus modified the data so as to include bracketing information related only to the non-recursive, base NPs present in each sentence while the subject verb phrases were taken as is. The data sets include POS tag information generated by Ramshaw and Marcus using Brill's transformational part-of-speech tagger  .",0,original
"To analyze our methods on IV and OOV words, we use a detailed evaluation metric than Bakeoff 2006   which includes Foov and Fiv.",0,original
"In  , the authors proposed a method to integrate the IBM translation model 2   with an ASR system.",0,original
"5 Related Work There has not been much previous work on graphical models for full parsing, although recently several latent variable models for parsing have been proposed  .",0,original
"Section 3 describes two standard lexicalized models  , as well as an unlexicalized baseline model.",0,original
"Wu  s Inversion Transduction Grammar, as well as tree-transformation models of translation such as Yamada and Knight  , Galley et al.",0,original
"These heuristics define a phrase pair to consist of a source and target ngrams of a word-aligned source-target sentence pair such that if one end of an alignment is in the one ngram, the other end is in the other ngram    .",0,original
Mihalcea   shows that Wikipedia can indeed be used as a sense inventory for sense disambiguation,0,original
"Different approaches have been proposed for modeling Pr  in Equation  : Zero-order models such as model 1, model 2,andmodel 3   and the rstorder models such as model 4, model 5  , hidden Markov model  , and model 6  .",0,original
"Finally, it would be nice to merge some of the approaches by   and   with the ideas of semi-supervised learning introduced here, since they seem orthogonal in at least some aspects  .",0,original
1 Introduction and Motivation Parse selection constitutes an important part of many parsing systems  .,0,original
The translations are evaluated in terms of BLEU score  .,0,original
all-Street Journal   Sections 15-18 and 20 were used by Ramshaw and Marcus   as training and test data respectively for evaluating their base-NP chunker,0,original
"In Turneys work, the co-occurrence is considered as the appearance in the same window  .",0,original
"Binarizing the grammars   further increases the size of these sets, due to the introduction of virtual nonterminals.",0,original
"We use the by now standard a0 statistic   to quantify the degree of above-chance agreement between multiple annotators, and the a1 statistic for analysis of sources of unreliability  .",0,original
"Various learning models have been studied such as Hidden Markov models    , decision trees   and maximum entropy models  .",0,original
"We follow the approach of bootstrapping from a model with a narrower parameter space as is done in, e.g. Och and Ney   and Fraser and Marcu  .",0,original
"Many reordering constraints have been used for word reorderings, such as ITG constraints  , IBM constraints   and local constraints  .",0,original
"Test and training materials were derived from the Brown corpus of American English, all of which has been parsed and manually verified by the Penn T~eebank project   and parts of which have been manually sense-tagged by the WordNet group  .",0,original
"Four alternatives are proposed in these special issues:   Brent  ,   Briscoe and Carroll  ,   Hindle and Rooth  , and   Weischedel et al.",0,original
u   introduced constraints on alignments using a probabilistic synchronous context-free grammar restricted to Chomskynormal form,0,original
"Under certain precise conditions, as described in  , we can analyze Algorithm 1 as minimizing the entropy of the distribution over translations of U. However, this is true only when the functions Estimate, Score and Select have very prescribed definitions.",0,original
A constituent-based system using Collins parser  .,0,original
"Let W1,W2 be the vocabulary sizes of the two languages, and N = {A1,,AN} be the set of nonterminals with indices 1,,N. Wu   also showed that ITGs can be equivalently be defined in two other ways.",0,original
"2 Overview 2.1 The word segmentation problem As statistical machine translation systems basically rely on the notion of words through their lexicon models  , they are usually capable of outputting sentences already segmented into words when they translate into languages like Chinese or Japanese.",0,original
"More specialized methods also exist, for example for support vector machines   and for conditional random fields  .",0,original
"This model can be seen as an extension of the standard Maximum Entropy Markov Model  ) with an extra dependency on the predicate label, we will henceforth refer to this model as MEMM+pred.",0,original
Research on the automatic classification of movie or product reviews as positive or negative  ) is perhaps the most similar to our work.,0,original
We made use of the same data set as introduced in  .,0,original
arzilay & Lee   also identify paraphrases in their paraphrased sentence generation system,0,original
In our experiments we use the same definition of structural locality as was proposed for the ISBN dependency parser in  .,0,original
"Three recent papers in this area are Church and Hanks  , Hindle  , and Smadja and McKeown  .",0,original
"Some o1' l;his research has treated the sentenees as unstructured word sequences to be aligned; this work has primarily involved the acquisition of bilingual lexical correspondences  , although there has also been a,n attempt to create a full MT system based on such trcat, ment  .",0,original
"However, there is little agreement on what types of knowledge are helpful: Some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in Meteor   or MaxSim  .",0,original
Then the word alignment is refined by performing growdiag-final method  .,0,original
arletta   deserves the credit for bringing  to the attention of computational linguists,0,original
"Its still possible to use MSA if, for example, the input is pre-clustered to have the same constituent ordering  ).",0,original
"For example, the words test and exam are similar because both of them can follow verbs such as administer, cancel, cheat on, conduct, etc. Many methods have been proposed to compute distributional similarity between words, e.g.,  .",0,original
"Recently, severalmethods  have been proposed with similar motivation to ours.",0,original
"1 Introduction Since the introduction of the BLEU metric  , statistical MT systems have moved away from human evaluation of their performance and towards rapid evaluation using automatic metrics.",0,original
  and   use syntactic markers to increase the significance of the data.,0,original
"In this paper, we modify the method in Albrecht and Hwa   to only prepare human reference translations for the training examples, and then evaluate the translations produced by the subject systems against the references using BLEU score  .",0,original
We used the implementation of MaxEnt classifier described in  .,0,original
"A variety of other measures of semantic relatedness have been proposed, including distributional similarity measures based on co-occurrence in a body of text see   for a survey.",0,original
A totally different approach to improving the accuracy of our parser is to use the idea of selftraining described in  .,0,original
"Unlike our technique, in most cases researchers have focused on the scenario where labeled training data is available in both the source and the target domain  ).",0,original
"A comparison of the two approaches can be found in Koehn, Och, and Marcu  .",0,original
The feature weights were optimized against the BLEU scores  .,0,original
1 Introduction A number of empirical studies have found bracketing to be a useful type of corpus annotation  .,0,original
"Recently, Snow, Jurafsky and Ng   generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet  .",0,original
We employ loglinear models   for the disambiguation.,0,original
"Each i is a weight associated with feature i, and these weights are typically optimized using minimum error rate training  .",0,original
"There are also automatic methods for summary evaluation, such as ROUGE  , which gives a score based on the similarity in the sequences of words between a human-written model summary  and  the  machine  summary.",0,original
The frequency counts of dependency relationships are filtered with the loglikelihood ratio  .,0,original
"As in tile HMM we easily can extend the dependencies in the alignment model of Model 4 easily using the word class of the previous English word E = G , or the word class of the French word F = G   .",0,original
"Related to this issue, we note that the head rules, which were nearly identical to those used in  , have not been tuned at all to this task.",0,original
"5 Related Work As discussed in footnote 3, Collins   and McDonald et al.",0,original
The information content of this set is defined as mutual information I )  .,0,original
"The lexicalized PCFG that sits behind Model 2 of   has rules of the form P ~ LnLn-I""""'"""" LIHRI"""""""".Rn-IRn   S  NP  VP  NNP I Apple MD VP   VB PRT  NP  I \[ I buy RP NNP I I out Microsoft Figure 1: A sample sentence with parse tree.",0,original
e follow Collins   and Sha and Pereira   in using section 21 as a heldout set,0,original
A CYK-style decoder has to rely on binarization to preprocess the grammar as did in   to handle multi-nonterminal rules.,0,original
"The word alignments were created with Giza++   applied to a parallel corpus containing the complete Europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.",0,original
1 Introduction A recent development in data-driven parsing is the use of discriminative training methods  .,0,original
"Agglomerative clustering   iteratively merges the most similar clusters into bigger clusters, which need to be labeled.",0,original
We attribute the difference in M3/4 scores to the fact we use a Viterbi-like training procedure   while GIZA uses pegging   to sum over a set of likely hidden variable configurations in EM.,0,original
"Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model    , tree-to-string model    , string-totree model    , tree-to-tree model     and so on.",0,original
"In this paper, a new part-of-speech tagging method hased on neural networks   is presented and its performance is compared to that of a llMM-tagger   and a trigrambased tagger  .",0,original
"3.5 Adding Context to the Model Next, we added of a stochastic POS tagger   to provide a model of context.",0,original
"MTTK provides implementations of various alignment, models including IBM Model-1, Model-2  , HMM-based word-to-word alignment model   and HMM-based word-to-phrase alignment model  .",0,original
Our model improves the baseline provided by  :   accuracy is increased by creating a lexicalised PCFG grammar and enriching conditioning context with parent f-structure features; and   coverage is increased by providing lexical smoothing and fuzzy matching techniques for rule smoothing.,0,original
"Alignment spaces can emerge from generative stories  , from syntactic notions  , or they can be imposed to create competition between links  .",0,original
he usefulness of likelihood ratios for collocation detection has been made explicit by Dunning   and has been confirmed by an evaluation of various collocation detection methods carried out by Evert and Krenn  ,0,original
"Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER  , which employs a version of edit distance for word substitution and reordering; METEOR  , which uses stemming and WordNet synonymy; and a linear regression model developed by  , which makes use of stemming, WordNet synonymy, verb class synonymy, matching noun phrase heads, and proper name matching.",0,original
During training each example is broken into elementary trees using head rules and argument/adjunct rules similar to those of  .,0,original
Kanayama and Nasukawa used both intraand inter-sentential co-occurrence to learn polarity of words and phrases  .,0,original
"So unlike some other studies  , we used manually annotated alignments instead of automatically generated ones.",0,original
"Nevertheless, as   and others have argued, semantic representations for natural language need not be higher-order in that ontological promiscuity can solve the problem.",0,original
"  provide four sets of annotation principles, one for non-coordinate configurations, one for coordinate configurations, one for traces   and a final catch all and clean up phase.",0,original
Our baseline model follows Chiangs hierarchical model   in conjunction with additional features:  conditional probabilities in both directions: P  and P ;  lexical weights   in both directions: Pw  and Pw ; 21  word counts |e|;  rule counts |D|;  target n-gram language model PLM ;  glue rule penalty to learn preference of nonterminal rewriting over serial combination through Eq.,0,original
"Wu   proposes Inversion Transduction Grammars, treating translation as a process of parallel parsing of the source and target language via a synchronized grammar.",0,original
A perceptron algorithm gives 97.11%  .,0,original
"Following Ramshaw and Marcus  , the current dominant approach is formulating chunking as a classification task, in which each word is classified as the  eginning,  nside or  outside of a chunk.",0,original
6 Experiments 6.1 Data preparation Our experiments were conducted with data made available through the Penn Treebank annotation effort  .,0,original
"Considerations of sentence fluency are also key in sentence simplification  , sentence compression  , text re-generation for summarization   and headline generation  .",0,original
"Turney   applied an internet-based technique to the semantic orientation classification of phrases, whichhadoriginallybeendevelopedforwordsentiment classification.",0,original
"If e has length l and f has length m, there are possible 2lm alignments between e and f  .",0,original
"For example, in the WSJ corpus, part of the Penn Treebank 3 release  , the string in   is a variation 12-gram since off is a variation nucleus that is tagged preposition   in one corpus occurrence and particle   in another.1 Dickinson   shows that examining those cases with identical local contextin this case, lookingat ward off aresultsinanestimated error detection precision of 92.5%.",0,original
"model reranking has also been established, both for synchronous binarization   and for target-only binarization  .",0,original
" , Pereira and Tishby  , and Pereira, Tishby, and Lee   propose methods that derive classes from the distributional properties of the corpus itself, while other authors use external information sources to define classes: Resnik   uses the taxonomy of WordNet; Yarowsky   uses the categories of Roget's Thesaurus, Slator   and Liddy and Paik   use the subject codes in the LDOCE; Luk   uses conceptual sets built from the LDOCE definitions.",0,original
"Daume allows an extra degree of freedom among the features of his domains, implicitly creating a two-level feature hierarchy with one branch for general features, and another for domain specific ones, but does not extend his hierarchy further  ).",0,original
This is the traditional approach for glass-box smoothing  .,0,original
"Sentence-level approximations to B exist  , but we found it most effective to perform B computations in the context of a setOof previously-translated sentences, following Watanabe et al.",0,original
"The statistical approach involves the following: alignment of bilingual texts at the sentence level nsing statistical techniques  , Gale and Church  , Chen  , and Kay and RSscheisen  ), statistical machine translation models (e.g. Brown, Cooke, Pietra, Pietra et al.",0,original
"It was first cast as a classification problem by Ramshaw and Marcus  , as a problem of NP chunking.",0,original
"Currently, the scheme supports PhraseChunks with subtypes such as NP, VP, PP, or ADJP  .",0,original
This was overcome by a probabilistic model which provides probabilities of discriminating a correct parse tree among candidates of parse trees in a log-linear model or maximum entropy model   with many features for parse trees  .,0,original
"To counteract this, we introduce two brevity penalty measures   inspired by BLEU   which we incorporate into the loss function, using a product, loss = 1PrecBP: BP1 = exp )   BP2 = exp ) where r is the reference length and c is the candidate length.",0,original
The sequence Ws is thought as a noisy version of WT and the best guess I)d~ is then computed as ^ W~ = argmax P  wT = argmax P P    wT In   they propose a method for maximizing P  by estimating P  and P  and solving the problem in equation 1.,0,original
he feature weights for the overall translation models were trained using Och?s   minimum-error-rate training procedure,0,original
"  a. Please move your car Her sadness moves him b. John enjoys the book John enjoys reading the book e. The two alibis do not accord They accorded him a warm welcome d. John swam for hours John swam across the channel Although the precise nrechanisms which govern lexical knowledge are still largely unknown, there is strong evidence that word sense extensibi\[ity is not arbitrary  .",0,original
"In this work, we focus on learning bilingual word phrases by using Stochastic Inversion Transduction Grammars    .",0,original
A possible solution to this problem is to directly estimate p  by applying a maximum entropy model  .,0,original
"Early experiments with syntactically-informed phrases  , and syntactic reranking of K-best lists   produced mostly negative results.",0,original
"Instead of using Inversion Transduction Grammar     directly, we will discuss an ITG extension to accommodate gapping.",0,original
"Then, those structurally matched parallel sentences are used as a source for acquiring lexical knowledge snch as verbal case frames  .",0,original
"3 Experiments We built baseline systems using GIZA++  , Moses phrase extraction with grow-diag-finalend heuristic  , a standard phrasebased decoder  , the SRI LM toolkit  , the suffix-array language model  , a distance-based word reordering model Algorithm 5 Rich Interruption Constraints   Input: Source tree T, previous phrase fh, current phrase fh+1, coverage vector HC 1: Interruption  False 2: ICount,VerbCount,NounCount  0 3: F  the left and right-most tokens of fh 4: for each of f  F do 5: Climb the dependency tree from f until you reach the highest node n such that fh+1 / T .",0,original
It uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories   and the forward backward algorithm efficiently sums over all histories to give a distibution for each word.,0,original
"Consequently, the mainstream research in the literature has been focused on the modeling and utilization of local and sentential contexts, either linguistically in a rule-based framework or statistically in a searching and optimization set-up  .",0,original
"For the factored language models, a feature-based word representation was obtained by tagging the text with Rathnaparkis maximum-entropy tagger   and by stemming words using the Porter stemmer  .",0,original
"Maximum Entropy Modeling As previously indicated, the weight-based scheme of L&L suggests MaxEnt modeling   as a particularly natural choice for a machine learning approach.",0,original
Such methods were presented in  .,0,original
"Word association norms, mutual information, and lexicography, Computational Linguistics, 16 : 22-29 Marcus, M. et al. 1993.",0,original
The model cleanly incorporates both syntax and lexical semantics using quasi-synchronous dependency grammars  .,0,original
ALM does this by using alignment models from the statistical machine translation literature  .,0,original
"In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores   are above a threshold.",0,original
"For instance, the HALOGEN statistical realizer  , converting them into its input formalism, and then producing output strings.",0,original
"For English, we have used sections 03-06 of the WSJ portion of the Penn Treebank   distributed by the Linguistic Data Consortium  , which have frequently been used to evaluate sentence boundary detection systems before; compare Section 7.",0,original
"5 Experimental Evaluation To perform empirical evaluations of the proposed methods, we considered the task of parsing the Penn Treebank Wall Street Journal corpus  .",0,original
2.2 Maximum Entropy Our next approach is the Maximum Entropy   classification approach.,0,original
"2.4 Reordering Reordering features take many forms in MT. In phrase-based systems, reordering is accomplished both within phrase pairs   as well as through distance-based distortion models   and lexicalized reordering models  .",0,original
"Cutting et al. 1992), local rules   and neural networks  .",0,original
"Grammar rules were induced with the syntaxbased SMT system SAMT described in  , which requires initial phrase alignments that we generated with GIZA++  , and syntactic parse trees of the target training sentences, generated by the Stanford Parser   pre-trained on the Penn Treebank.",0,original
Phrases are then extracted from the word alignments using the method described in  .,0,original
"To support distributed computation  , we further split the N-gram data into shards by hash values of the first bigram.",0,original
"Breidt  alsopointedouta coupleof problemsthatmakes extractionfor Germanmoredifficultthanfor English: the stronginflectionfor verbs,the variable word-order,andthepositionalambiguityofthearguments.Sheshowsthatevendistinguishingsubjectsfromobjectsisverydifficultwithoutparsing.",0,original
arowsky   has used a few seeds and untagged sentences in a bootstrapping algorithm based on decision lists,0,original
The model scaling factors are optimized on the development corpus with respect to mWER similar to  .,0,original
We automatically measure performance by comparing the produced headlines against one reference headline produced by a human using ROUGEa129  .,0,original
"3 MaxEnt Model and Features 3.1 MaxEnt Model for NOR The principle of maximum entropy   model is that given a collection of facts, choose a model consistent with all the facts, but otherwise as uniform as possible  .",0,original
OUGE-LCS calculated the longest common 2 Details of our official DUC 2004 headline generation system can be found in Doran et al,0,original
"It is also related to  linear models described in Berger, Della Pietra, and Della Pietra  , Xue  ; Och  , and Peng, Feng, and McCallum  .",0,original
"There are rules, though rare, that cannot be binarized synchronously at all  , but can be incorporated in two-stage decoding with asynchronous binarization.",0,original
"For example, aspects of a digital camera could include picture quality, battery life, size, color, value, etc. Finding such aspects is a challenging research problem that has been addressed in a number of ways  .",0,original
"On the other end of the spectrum, character-based bitext mapping algorithms   are limited to language pairs where cognates are common; in addition, they may easily be misled by superficial differences in formatting and page layout and must sacrifice precision to be computationally tractable.",0,original
"Prominent among these properties is the semi-free Language Size LR LP Source English 40,000 87.4% 88.1%   Chinese 3,484 69.0% 74.8%   Czech 19,000 80.0%   Table 1: Results for the Collins   model for various languages   wordorder, i.e., German wordorder is fixed in some respects, but variable in others.",0,original
"Most existing methods treat word tokens as basic alignment units  , however, many languages have no explicit word boundary markers, such as Chinese and Japanese.",0,original
"4.3 Experiments results Our evaluation metric is BLEU  , which are to perform case-insensitive matching of n-grams up to n = 4.",0,original
"Our method is based on the ones described in  , The objective of this paper is to dynamically rank speakers or participants in a discussion.",0,original
"We retrained the parser on lowercased Penn Treebank II  , to match the lowercased output of the MT decoder.",0,original
he algorithm we implemented is inspired by the work of Yarowsky   on word sense disambiguation,0,original
Methods that use bigrams   or trigrams   cluster words considering as a word's context the one or two immediately adjacent words and employ as clustering criteria the minimal loss of average 836 nmtual information and the perplexity improvement respectively.,0,original
"Phrase pairs are extracted up to a fixed maximum length, since very long phrases rarely have a tangible impact during translation  .",0,original
"To solve the problem, Cahill and van Genabith   apply an automatic generation grammar transformation to their training data: they automatically label CFG nodes with additional case information and the model now learns the new improved generation rules of Tables 4 and 5.",0,original
"is the previous BIO tag, S is the target sentence, and fj and lj are feature functions and parameters of a log-linear model  .",0,original
We computed the LCS and WLCS-based F-measure following   using both the query pool and the sentence pool as in the previous section.,0,original
"Named entities also pose another problem with the Haghighi and Klein   coreference model; since it models only the heads of NPs, it will fail to resolve some references to named entities:  , while erroneously merging others:  .",0,original
"For example, it has been observed that texts often contain multiple opinions on different topics  , which makes assignment of the overall sentiment to the whole document problematic.",0,original
This way of creating classified data is similar to that in  .,0,original
"The progression in the probabilistic parsing literature has been to start with lexical head-head dependencies   and then add non-lexical sis2 This result generalizes to Ss, which are also flat in Negra  .",0,original
"3.2 System Combination Scheme In our work, we use a sentence-level system combination model to select best translation hypothesis from the candidate pool     . This method can also be viewed to be a hypotheses reranking model since we only use the existing translations instead of performing decoding over a confusion network as done in the word-level combination method  .",0,original
Feature selection Berger et al   proposed an iterative procedure of adding news features to feature set driven by data,0,original
"To perform code generalization, Li adopted to Smadjas work   and defined the code strength using a code frequency and a standard deviation in each level of the concept hierarchy.",0,original
"605 ROUGE-S   Skip-bigram is any pair of words in their sentence order, allowing for arbitrary gaps.",0,original
"Note that generative hybrids are the norm in SMT, where translation scores are provided by a discriminative combination of generative models  .",0,original
Regression has also been used to order sentences in extractive summarization  .,0,original
"This may stem from the differences between the two models' feature templates, thresholds, and approximations of the expected values for the features, as discussed in the beginning of the section, or may just reflect differences in the choice of training and test sets  ).",0,original
"We envision the use of a clever datastructure would reduce the complexity, but leave this to future work, as the experiments   show that 5Our definition implies that we only consider faithful spans to be contiguous  .",0,original
"2 Three New Features for MT Evaluation Since our source-sentence constrained n-gram precision and discriminative unigram precision are both derived from the normal n-gram precision, it is worth describing the original n-gram precision metric, BLEU  .",0,original
"The problem of choosing an appropria.te level in the h.ierarchy at which to represent a particular noun sense   has been investigated by Resnik  , Li and Abe   and ll,iba,s  .",0,original
1 Introduction Word alignments were first introduced as an intermediate result of statistical machine translation systems  .,0,original
"The standard split of the corpus into training  , validation  , and testing   was performed.2 As in   we used a publicly available tagger   to provide the part-of-speech tag for each word in the sentence.",0,original
This is the same separation of arguments and adjuncts as that employed by  .,0,original
"Many methods have been proposed to measure the co-occurrence relation between two words such as  2   , mutual information  , t-test  , and loglikelihood  .",0,original
"2.3 Forest minimum error training To tune the feature weights of our system, we used a variant of the minimum error training algorithm   that computes the error statistics from the target sentences from the translation search space   that are exactly those that are minimally discriminable by changing the feature weights along a single vector in the dimensions of the feature space  .",0,original
We shall take HMM-based word alignment model   as an example and follow the notation of  .,0,original
"3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank  , converted to dependency format.",0,original
Other recent work has incorporated constituent and dependency subtrees into the translation rules used by phrase-based systems  .,0,original
"The only requirement will be that a parallel corpus exist for the language under consideration and one or more other languages.2 Induction of grammars from parallel corpora is rarely viewed as a promising task in its own right; in work that has addressed the issue directly  , the synchronous grammar is mainly viewed as instrumental in the process of improving the translation model in a noisy channel approach to statistical MT.3 In the present paper, we provide an important prerequisite for parallel corpus-based grammar induction work: an efficient algorithm for synchronous parsing of sentence pairs, given a word alignment.",0,original
"Most previous work on paraphrase has focused on high quality rather than coverage  , but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications.",0,original
"Several non-linear objective functions, such as F-score for text classification  , and BLEU-score and some other evaluation measures for statistical machine translation  , have been introduced with reference to the framework of MCE criterion training.",0,original
An alternative representation for baseNPs has been put forward by  .,0,original
"Hockenmaier et al  , although to some extent following the approach of Xia   where LTAGs are extracted, have pursued an alternative by extracting Combinatory Categorial Grammar     lexicons from the Penn Treebank.",0,original
"As two examples,   and   give good overviews of the techniques and equations used for Markov models and part-ofspeech tagging, but they are not very explicit in the details that are needed for their application.",0,original
"While it was initially believed that lexicalization of PCFG parsers   is crucial for obtaining good parsing results, Gildea   demonstrated that the lexicalized Model-1 parser of Collins   does not benefit from bilexical information when tested on a new text domain, and only marginally benefits from such information when tested on the same text domain as the training corpora.",0,original
"While early machine learning approaches for the task relied on local, discriminative classifiers  , more recent approaches use joint and/or global models  .",0,original
"Finally, other approaches rely on reviews with numeric ratings from websites   and train  supervised learning algorithms to classify reviews as positive or negative, or in more fine-grained scales  .",0,original
The algorithm is exactly the same as the one described in   to find the most probable part-of-speech sequence.,0,original
"Given a set of terms with unknown sentiment orientation, Turney   then uses the PMI-IR algorithm   to issue queries to the web and determine, for each of these terms, its pointwise mutual information   with the two seed words across a large set of documents.",0,original
"Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons   to semi-automated approaches  , and even an almost fully automated approach  .",0,original
"In this paper, we present Phramer, an open-source system that embeds a phrase-based decoder, a minimum error rate training   module and various tools related to Machine Translation  .",0,original
"Note that, since the FrameNet data does not include deep syntactic tree annotation, we processed the FrameNet data with Collins parser  , consequently, the experiments on FrameNet relate to automatic syntactic parse trees.",0,original
"We can stipulate the time line to be linearly ordered   nor in approaches employing branching futures  ), and we can stipulate it to be dense  .",0,original
"The class labeling system in our experiment is IOB2  , which is a variation of IOB  .",0,original
The underlying translation model is Model 2 from  .,0,original
"This generates tens of millions features, so we prune those features that occur fewer than 10 total times, as in  .",0,original
Official DUC scoring utilizes the jackknife procedure and assesses significance using bootstrapping resampling  .,0,original
"Specifically, the following information can be either automatically identified or manually annotated:  Syntactic structures automatically identified from a parser  ;  Semantic roles of entities in the question  ;  Discourse roles either manually annotated or identified by rules that map directly from semantic roles to discourse roles.",0,original
"We used four different system summaries for each of the 6 meetings: one based on the MMR method in MEAD  , the other three are the system output from  .",0,original
"For instance, Hughes and Ramage   constructed a graph which represented various types of word relations from WordNet, and compared random-walk similarity to similarity assessments from humansubject trials.",0,original
"3 Implementation 3.1 Feature Structure To implement the twin model, we adopt the log linear or maximum entropy   model   for its flexibility of combining diverse sources of information.",0,original
4.3 Scoring All-N Rules We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them  ).,0,original
"Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees: Head/argument/modifier distinctions are made for each node in the tree based on Magerman   and Collins  ; 336 ODonovan et al. Large-Scale Induction and Evaluation of Lexical Resources the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the treebank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category.",0,original
Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other  .,0,original
"A few researchers have focused on other aspects of summarization, including single sentence  , paragraph or short document  , query-focused  , or speech  .",0,original
he extraction procedure utilizes a head percolation table as introduced by Magerman   in combination with a variation of Collinss   approach to the differentiation between complement and adjunct,0,original
"The work reported in this paper is most closely related to work on statistical machine translation, particularly the IBM-style work on CANDIDE  .",0,original
Previous work from   showed improvements in perplexity-oriented measures using mixture-based translation lexicon  .,0,original
e adopted the stop condition suggested in Berger et al. 1996 the maximization of the likelihood on a cross-validation set of samples which is unseen at the parameter esti~_tion,0,original
"Previous research has focused on classifying subjective-versus-objective expressions  , and also on accurate sentiment polarity assignment  .",0,original
The traditional estimation method for word 98 alignment models is the EM algorithm   which iteratively updates parameters to maximize the likelihood of the data.,0,original
We use a standard maximum entropy classifier   implemented as part of MALLET  .,0,original
"However, in experiments in unsupervised POS tag learning using HMM structured models, Johnson   shows that VB is more effective than Gibbs sampling in approaching distributions that agree with the Zipfs law, which is prominent in natural languages.",0,original
a list of pilot terms ranked from the most representative of the corpus to the least thanks to the Loglikelihood coefficient introduced by  .,0,original
"In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K. We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization  .",0,original
"Church, K. and Hanks, P. ,   """"Word Association Norms, Mutual Information, and Lexicography,"""" Computational Linguistics Vol.",0,original
"4 Features For our experiments we use the features proposed, motivated and described in detail by  .",0,original
"In  , the authors use the transcripts of debates from the US Congress to automatically classify speeches as supporting or opposing a given topic by taking advantage of the voting records of the speakers.",0,original
We took part the Multilingual Track of all ten languages provided by the CoNLL-2007 shared task organizers .,0,original
5.2 Translation In order to test the translation performance of the grammars induced by our model and the GHKM method6 we report BLEU   scores on sentences of up to twenty words in length from the MT03 NIST evaluation.,0,original
"As described in Section 4, we define the problem of term variation identifica1484 tion as a binary classification task, and build two types of classifiers according to the maximum entropy model   and the MART algorithm  , where all term similarity metrics are incorporated as features and are jointly optimized.",0,original
"We use the same preprocessing steps as Turian and Melamed  : during both training and testing, the parser is given text POS-tagged by the tagger of Ratnaparkhi  , with capitalization stripped and outermost punctuation removed.",0,original
"In addition to portability experiments with the parsing model of  ,   provided a comprehensive analysis of parser portability.",0,original
"In the following, ROUGE-SN denotes ROUGE-S with maximum skip distance N. ROUGE-SU   This measure is an extension of ROUGE-S; it adds a unigram as a counting unit.",0,original
"Note, that for our example the effect of the uniform additional conditioning on mother grammatical function has the same effect as the generation grammar transform of  , but without the need for the gramF-Struct Feats Grammar Rules {PRED=PRO,NUM=SG PER=3, GEN=FEM, SUBJ} PRP   she {PRED=PRO,NUM=SG PER=3, GEN=FEM, OBJ} PRP   her Table 7: Lexical item rules.",0,original
3 Surface Realisation from f-Structures Cahill and van Genabith   present a probabilistic surface generation model for LFG  .,0,original
"We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged  ).",0,original
"Modeling reordering as the inversion in order of two adjacent blocks is similar to the approach taken by the Inverse Transduction Model    , except that here we are not limited to a binary tree.",0,original
"For handling word identities, one could follow the approach used for handling the POS tags   and view the POS tags and word identities as two separate sources of information.",0,original
"Conjunctions are a major source of errors for English chunking as well  9, and we plan to address them in future work.",0,original
"This sequential property is well suited to HMMs  , in which the jumps from the current aligned position can only be forward.",0,original
"2.2 Creation of a Coarse-Grained Sense Inventory To tackle the granularity issue, we produced a coarser-grained version of the WordNet sense inventory3 based on the procedure described by Navigli  .",0,original
"Instead of using a single system output as the skeleton, we employ a minimum Bayes-risk decoder to select the best single system output from the merged N-best list by minimizing the BLEU   loss.",0,original
"For example, the HMM aligner achieves an AER of 20.7 when using the competitive thresholding heuristic of DeNero and Klein  .",0,original
Ourmodelisthusa form of quasi-synchronous grammar    .,0,original
"For example, incremental CFG parsing algorithms can be used with the CFGs produced by this transform, as can the Inside-Outside estimation algorithm   and more exotic methods such as estimating adjoined hidden states  .",0,original
"To combine the many differently-conditioned features into a single model, we provide them as features to the linear model   and use minimum error-rate training   to obtain interpolation weights m. This is similar to an interpolation of backed-off estimates, if we imagine that all of the different contextsaredifferently-backedoffestimatesofthe complete context.",0,original
"Evaluation Metrics We evaluated the generated translations using three different evaluation metrics: BLEU score  , mWER  , and mPER    .",0,original
They developed a simple heuristic function for Model 2 from   which was non admissible.,0,original
"For example, in machine translation, BLEU score   is developed to assess the quality of machine translated sentences.",0,original
"This paper demonstrates several of the characteristics and benefits of SemFrame  , a system that produces such a resource.",0,original
It has been argued that METEOR correlates better with human judgment due to higher weight on recall than precision  .,0,original
"As referring dataset, we used the PropBank corpora available at www.cis.upenn.edu/ace, along with the Penn TreeBank 2    .",0,original
Works on word similarity and word sense disambiguation are generally based on statistical methods designed for large or even very large corpora  .,0,original
Joint parsing with a simplest synchronous context-free grammar   is O  as opposed to the monolingual O  time.,0,original
"In  , automatically extracted collocations are judged by a lexicographer.",0,original
"This differs from typical generative settings for IR and MT  , where all conditioned events are disjoint by construction.",0,original
ch and Ney   state that AER is derived from F-Measure,0,original
"This situation is very similar to that involved in training HMM text taggers, where joint probabilities are computed that a particular word corresponds to a particular part-ofspeech, and the rest of the words in the sentence are also generated  .",0,original
"Daume III   divided features into three classes: domainindependent features, source-domain features and target-domain features.",0,original
"For Japanese sentences, instead of using full parse trees, existing sentence compression methods trim dependency trees by the discriminative model   through the use of simple linear combined features  .",0,original
"However, if we are willing to accept that occasionally our model will be unable to distinguish between distinct n-grams, then it is possible to store each parameter in constant space independent of both n and the vocabulary size  ,  .",0,original
"The part of speech tags for the development and test data were automatically assigned by MXPOST  , where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus  , which contains roughly 43 million words of Wall Street Journal text.9 The Czech experiments were performed on the Prague Dependency Treebank 1.0  , which is directly annotated with dependency structures.",0,original
Movie-review dataset consists of positive and negative reviews from the Internet Movie Database   archive  .,0,original
"Most of them were developed for exhaustive parsing, i.e., producing all parse results that are given by the grammar  .",0,original
"2.1 The Standard Machine Learning Approach We use maximum entropy   classification   in conjunction with the 33 features described in Ng   to acquire a model, PC, for determining the probability that two mentions, mi and mj, are coreferent.",0,original
"To evaluate sentence automatically generated with taking consideration word concatenation into by using references varied among humans, various metrics using n-gram precision and word accuracy have been proposed: word string precision   for summarization through word extraction, ROUGE   for abstracts, and BLEU   for machine translation.",0,original
"Supervised methods include hidden Markov model  , maximum entropy, conditional random fields  , and support vector machines    .",0,original
"There are many different similarity measures, which variously use taxonomic lexical hierarchies or lexical-semantic networks, large text corpora, word definitions in machine-readable dictionaries or other semantic formalisms, or a combination of these  .",0,original
The IBM models   search a version of permutation space with a one-to-many constraint.,0,original
"In addition, many more sophisticated parsing models are elaborations of such PCFG models, so understanding the properties of PCFGs is likely to be useful  .",0,original
"For example,   developed a system to identify inflammatory texts and   developed methods for classifying reviews as positive or negative.",0,original
arletta   argues that the kappa statistic   should be adopted to judge annotator consistency for classification tasks in the area of discourse and dialogue analysis,0,original
We utilise the automatic annotation algorithm of   to derive a version of Penn-II where each node in each tree is annotated with an LFG functional annotation  .,0,original
"Finally, we would like to investigate the incorporation of unsupervised methods for WSD, such as the heuristically-based methods of   and  , and the theoretically purer bootstrapping method of  .",0,original
"For example, in phrase-based SMT systems  , distortion model is used, in which reordering probabilities depend on relative positions of target side phrases between adjacent blocks.",0,original
A number of systems for automatically learning semantic parsers have been proposed  .,0,original
"One approach here is that of Wu  , in which word-movement is modeled by rotations at unlabeled, binary-branching nodes.",0,original
"Collocation Dictionary of Modern Chinese Lexical Words, Business Publisher, China Yuan Liu, et al. 1993.",0,original
This statistical technique of labeling predicate argument operates on the output of the probabilistic parser reported in  .,0,original
"6 Related Work In machine translation, the concept of packed forest is first used by Huang and Chiang   to characterize the search space of decoding with language models.",0,original
"Solving this first methodological issue, has led to solutions dubbed hereafter as unlexicalized statistical parsing  .",0,original
"Most previous work on compositionality of MWEs either treat them as collocations  , or examine the distributional similarity between the expression and its constituents  .",0,original
"Prior to running the parsers, we trained the POS tagger described in  .",0,original
"For example, in the WSJ corpus, part of the Penn Treebank 3 release  , the string in   is a variation 12-gram since off is a variation nucleus that in one corpus occurrence is tagged as a preposition  , while in another it is tagged as a particle  .",0,original
"Reliability metrics   are designed to give a robust measure of how well distinct sets of data agree with, or replicate, one another.",0,original
"Intuitively, if we are able to find good correspondences among features, then the augmented labeled source domain data should transfer better to a target domain    .",0,original
he tag propagation/elimination scheme is adopted from  ,0,original
"4.3 Baselines 4.3.1 Word Alignment We used the GIZA++ implementation of IBM word alignment model 4   for word alignment, and the heuristics described in   to derive the intersection and refined alignment.",0,original
"Much work has gone into methods for measuring synset similarity; early work in this direction includes  , which attempted to discover sense similarities between dictionary senses.",0,original
We held out 300 sentences for minimum error rate training     and optimised the parameters of the feature functions of the decoder for each experimental run.,0,original
Gibbs sampling is not new to the natural language processing community  .,0,original
Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by a conventional phrase-based approach  .,0,original
"Each linked fragment pair consists of a source-language side and a target-language side, similar to  .",0,original
"Thus, Collins   also proposed an averaged perceptron, where the nal weight vector is 1Collins alsoprovidedproofthatguaranteedgood learning for the non-separable case.",0,original
"Roughly in keeping with  , we hereby regard paradigmatic assocations as those based largely on word similarity  , whereas syntagmatic associations are all those words which strongly invoke one another yet which cannot readily be said to be similar.",0,original
"Following the setup in Johnson  , we initialize the transition and emission distributions to be uniform with a small amount of noise, and run EM and VB for 1000 iterations.",0,original
"Polarity orientation identification has many useful applications, including opinion summarization   and sentiment retrieval  .",0,original
The traditional framework presented in   assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence.,0,original
ollocation map that is first suggested in   is a sigmoid belief network with words as probabilistic variables,0,original
"3.3 Features Similar to the default features in Pharaoh  , we used following features to estimate the weight of our grammar rules.",0,original
"Another application of hard clustering methods   is that they can also produce a binary tree, which can be used for decision-tree based systems such as the SPATTER parser   or the ATR Decision-Tree Part-OfSpeech Tagger  .",0,original
"Recently, there have been several discriminative approaches at training large parameter sets including   and  .",0,original
"BLEU score In order to measure the extent to which whole chunks of text from the prompt are reproduced in the student essays, we used the BLEU score, known from studies of machine translation  .",0,original
"For instance, the Penn Treebank policy   is to annotate the lowest node that is unfinished with an -UNF tag as in Figure 4 .",0,original
"Thus, the WSJ+NANC model has better oracle rates than the WSJ model   for both the WSJ and BROWN domains.",0,original
"We tagged all the sentences in the training and devset3 using a maximum entropy-based POS tagger MXPOST  , trained on the Penn English and Chinese Treebanks.",0,original
"This is well illustrated by the Collins parser  , scrutinized by Bikel  , where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation.",0,original
A third of this is syntactically parsed as part of the Penn Treebank   and has dialog act annotation  .,0,original
4 Architecture of the SMT system The goal of statistical machine translation   is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units   and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp  = argmaxe {exp )}   The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set  .,0,original
"As such, discourse markers play an important role in the parsing of natural language discourse  , and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations  .",0,original
"Strube and Ponzetto explored the use of Wikipedia for measuring Semantic Relatedness between two concepts  , and for Coreference Resolution  .",0,original
An additional translation set called the Maximum BLEU set is employed by the SMT system to train the weights associated with the components of its log-linear model  .,0,original
Collins and Roark   used the averaged perceptron  .,0,original
"For each co-occurring pair of word types u and v, these likelihoods are initially set proportional to their co-occurrence frequency n  and inversely proportional to their marginal frequencies n  and n  z, following   2.",0,original
Riloff and Jones 1999) note that the bootstrapping algorithm works well but its performance can deteriorate rapidly when non-coreferring data enter as candidate heuristics,0,original
There are two tasks  for the domain adaptation problem.,0,original
"3.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy   model.",0,original
"Table 1 reports values for the Kappa   coefficient of agreement   for Forward and Backward Functions .6 The columns in the tables read as follows: if utterance Ui has tag X, do coders agree on the subtag?",0,original
"Because it is not feasible here to have humans judge the quality of many sets of translated data, we rely on an array of well known automatic evaluation measures to estimate translation quality :  BLEU   is the geometric mean of the n-gram precisions in the output with respect to a set of reference translations.",0,original
"During training, the early update strategy of Collins and Roark   is used: when the correct state item falls out of the beam at any stage, parsing is stopped immediately, and the model is updated using the current best partial item.",0,original
he translations were generated by the alignment template system of Och  ,0,original
"Most of this prior work deals with supervised transfer learning, and thus requires labeled source domain data, though there are examples of unsupervised  , semi-supervised  , and transductive approaches  .",0,original
"In recent years, many researchers build alignment links with bilingual corpora  .",0,original
We take the generator of   as our baseline generator.,0,original
"However, in the Grammar Association context, when developing   the basic equations of the system presented in  , it is said that the reverse model for a28 a13a37a3a38a5a39a32a21a0a35a7 does not seem to admit a simple factorization which is also correct and convenient, so crude heuristics were adopted in the mathematical development of the expression to be maximized.",0,original
We selected four binary NLP datasets for evaluation: 20 Newsgroups1 and Reuters     and sentiment classification   and spam  .,0,original
ll our MT systems were trained using a variant of the alignment template model described in  ,0,original
2 Word Alignment algorithm We use IBM Model 4   as a basis for our word alignment system.,0,original
A word link extension algorithm similar to the one presented in this paper is given in  .,0,original
"Statistical Model In SIFTs statistical model, augmented parse trees are generated according to a process similar to that described in Collins  .",0,original
"Furthermore, as pointed out in Dolan  , the sense division in an MRD is frequently too fine-grained for the purpose of WSD.",0,original
unning 1993) or else   eschew significance testing in favor of a generic information-theoretic approach,0,original
"One of the first large scale hand tagging efforts is reported in  , where a subset of the Brown corpus was tagged with WordNet July 2002, pp.",0,original
"  describes how the voted perceptron can be used to train maximum-entropy style taggers, and also gives a more thorough discussion of the theory behind the perceptron algorithm applied to ranking tasks.",0,original
"Document level sentiment classification is mostly applied to reviews, where systems assign a positive or negative sentiment for a whole review document  .",0,original
"Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval  , cross-language text classification  , lexical choice in machine translation  , induction of translation lexicons  , cross-language annotation and resource projections to a second language  .",0,original
"Others have introduced alternative discriminative training methods  , in which a recurring challenge is scalability: to train many features, we need many train218 ing examples, and to train discriminatively, we need to search through all possible translations of each training example.",0,original
"3 The data 3.1 The supervised data For English, we use the same data division of Penn Treebank   parsed section   as all of  ,  ,   and   do; for details, see Table 1.",0,original
A large database of human judgments might also be useful as an objective function for minimum error rate training   or in other system development tasks.,0,original
"The first step is to label each node as either a head, complement, or adjunct based on the approaches of Magerman   and Collins  .",0,original
"Recently, Yarowsky   combined an MRD and a corpus in a bootstrapping process.",0,original
There are many method proposed to extract rigid expressions from corpora such as a method of focusing on the binding strength of two words  ; the distance between words  ; and the number of combined words and frequency of appearance  .,0,original
"Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++   for word alignments and SRILM for language modeling.",0,original
"Reported work includes improved model variants   and applications such as web data extraction  , scientific citation extraction  , word alignment  , and discourselevel chunking  .",0,original
Much of the recent work in word alignment has focussed on improving the word alignment quality through better modeling   or alternative approaches to training  .,0,original
"To perform minimum error rate training   to tune the feature weights to maximize the systems BLEU score on development set, we used the script optimizeV5IBMBLEU.m  .",0,original
orest reranking with a language model can be performed over this n-ary forest using the cube growing algorithm of Huang and Chiang  ,0,original
Collins et al.  proposed two algorithms for NER by modifying Yarowskys method   and the framework suggested by  .,0,original
"Their approaches include the use of a vector-based information retrieval technique   /bin/bash: line 1: a: command not found Our do- mains are more varied, which may results in more recognition errors.",0,original
"6 Evaluation 6.1 Data The data used for our comparison experiments were developed as part of the OntoNotes project  , which uses the WSJ part of the Penn Treebank  .",0,original
"We describe a new sequence alignment model based on the averaged perceptron  , which shares with the above approaches the ability to exploit arbitrary features of the input sequences, but is distinguished from them by its relative simplicity and the incremental character of its training procedure.",0,original
Concrete similarity measures compare a pair of weighted context feature vectors that characterize two words  .,0,original
"4 Semi-Supervised Training for Word Alignments Intuitively, in approximate EM training for Model 4  , the E-step corresponds to calculating the probability of all alignments according to the current model estimate, while the M-step is the creation of a new model estimate given a probability distribution over alignments  .",0,original
"The words we want to aggregate for text analysis are not rigorous synonyms, but the role is the same, so we have to consider the syntactic relation based on the assumptions that words with the same role tend to modify or be modified by similar words  .",0,original
2.3 Experiment The training set for these experiments was sections 01-21 of the Penn Treebank  .,0,original
"While in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types  .",0,original
he most direct comparison is between our system and those presented in Cahill and van Genabith   and Hogan et al,0,original
5 Results We present results that compare our system against the baseline Pharaoh implementation   and MER training scripts provided for this workshop.,0,original
"Indeed, the result of Collins   that including low support features helps a voted perceptron model but harms a maximum entropy model is undone once the weights of the maximum entropy model are regularized.",0,original
"Like Collins  , the decoder is the same for both the perceptron and the log-linear parsing models; the only change is the method for setting the weights.",0,original
It is shown that  -BRCGs induce inside-out alignments   and cross-serial discontinuous translation units  ; both phenomena can be shown to occur frequently in many hand-aligned parallel corpora.,0,original
"This includes the automatic generation of sense-tagged data using monosemous relatives  , automatically bootstrapped disambiguation patterns  , parallel texts as a way to point out word senses bearing different translations in a second language  , and the use of volunteer contributions over the Web  .",0,original
"For instance, the resulting word graph can be used in the prediction engine of a CAT system  .",0,original
Agglomerative clustering  ) can produce hierarchical word categories from an unannotated corpus.,0,original
"To contrast,   concentrated on analyzing human-written summaries in order to determine how professionals construct summaries.",0,original
"4.1 The test environment For our experiments, we used a manually corrected version of the Air Travel Information System   spoken language corpus   annotated in the Pennsylvania Treebank  .",0,original
"Previous authors have used numerous HMM-based models   and other types of networks including maximum entropy models  , conditional Markov models  , conditional random elds    , and cyclic dependency networks  .",0,original
"Table 2 shows the total space and number of bytes required per n-gram to encode the model under different schemes: LDC gzipd is the size of the files as delivered by LDC; Trie uses a compact trie representation  ) with 3 byte word ids, 1 byte values, and 3 byte indices; Block encoding is the encoding used in  ; and randomized uses our novel randomized scheme with 12 error bits.",0,original
"After that, several million instances of people, locations, and other facts were added  .",0,original
"When evaluated against the state-of-the-art, phrase-based decoder Pharaoh  , using the same experimental conditions  translation table trained on the FBIS corpus  , trigram language model trained on 155M words of English newswire, interpolation weights a65   trained using discriminative training    , probabilistic beam a90 set to 0.01, histogram beam a58 set to 10  and BLEU   as our metric, the WIDL-NGLM-Aa86 a129 algorithm produces translations that have a BLEU score of 0.2570, while Pharaoh translations have a BLEU score of 0.2635.",0,original
"Unsupervised Learning: Results To test the effectiveness of the above unsupervised learning algorithm, we ran a number of experiments using two different corpora and part of speech tag sets: the Penn Treebank Wall Street Journal Corpus \ .",0,original
"2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy  , synonymy   and meronymy  .",0,original
"  invented heuristic symmetriza57 FRENCH/ENGLISH ARABIC/ENGLISH SYSTEM F-MEASURE   BLEU F-MEASURE   BLEU GIZA++ 73.5 30.63 75.8 51.55   74.1 31.40 79.1 52.89 LEAF UNSUPERVISED 74.5 72.3 LEAF SEMI-SUPERVISED 76.3 31.86 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in  .",0,original
"159 2.1 Baseline System The baseline system is a phrase-based SMT system  , built almost entirely using freely available components.",0,original
"This is also true for reranking and discriminative training, where the k-best list of candidates serves as an approximation of the full set  .",0,original
Unconstrained CL corresponds exactly to a conditional maximum entropy model  .,0,original
"However, another approach is to train a separate out-of-domain parser, and use this to generate additional features on the supervised and unsupervised in-domain data  .",0,original
ollins   falls back to the POS tagging of Ratnaparkhi   for words seen fewer than 5 times in the training corpus,0,original
Concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information  .,0,original
he outcomes of CW resemble those of MinCut  : Dense regions in the graph are grouped into one cluster while sparsely connected regions are separated,0,original
"Collins   reports 88% labeled precision and recall on individual parse constituents on data from the Penn Treebank, roughly consistent with our finding of at least 13% error.",0,original
"The supervised methods are based on Maximum Entropy    , neural network using the Learning Vector Quantization algorithm   and Specialized Hidden Markov Models  .",0,original
"A path in a translation hypergraph induces a translation hypothesis E along with its sequence of SCFG rules D = r1,r2,,rK which, if applied to the start symbol, derives E. The sequence of SCFG rules induced by a path is also called a derivation tree for E. 3 Minimum Error Rate Training Given a set of source sentences FS1 with corresponding reference translations RS1, the objective of MERT is to find a parameter set M1 which minimizes an automated evaluation criterion under a linear model: M1 = argmin M1  SX s=1 Err`Rs, E  ff E  = argmax E  SX s=1 mhm  ff . In the context of statistical machine translation, the optimization procedure was first described in Och   for N-best lists and later extended to phrase-lattices in Macherey et al.",0,original
"A number of alignment techniques have been proposed, varying from statistical methods   to lexical methods  .",0,original
"For comparing the sentence generator sample to the English sample, we compute log-likelihood statistics   on neighboring words that at least co-occur twice.",0,original
Semantic  : The named entity   tag of wi obtained using the Stanford CRF-based NE recognizer  .,0,original
"These lists are rescored with the different models described above, a character penalty, and three different features based on IBM Models 1 and 2   calculated in both translation directions.",0,original
"The separation of these two requirements 7 A more precise account of what it means to be able to identify an object is beyond the scope of this paper; for further details, see the discussions by Hobbs  , Appelt  , Kronfeld  , and Morgenstern  .",0,original
Our use of Gibbs sampling follows from its increasing use in Bayesian inference problems in NLP  .,0,original
There have been a number of methods proposed in the literature to address the word clustering problem  ).,0,original
"Mihalcea   demonstrates that manual mappings can be created for a small number of words with relative ease, but for a very large number of words the e ort involved in mapping would approach presented involves no be considerable.",0,original
"We can incorporate each model into the system in turn, and rank the results on a test corpus using BLEU  .",0,original
"The proposed approach follows the same principle as  , which tried to determine the appropriate word sense according to one relevant context word.",0,original
"Again the best result was obtained with IOB1   which is an imI)rovement of the best reported F,~=1 rate for this data set  : 92.03).",0,original
1 is based on several realvalued feature functions fi . Their computation is based on the so-called IBM Model-1  .,0,original
.1 The gender/animaticity statistics After we have identified the correct antecedents it is a simple counting procedure to compute P  where wa is in the correct antecedent for the pronoun p  : \[ wain the antecedent for p \[ P  = When there are multiple relevant words in the antecedent we apply the likelihood test designed by Dunning   on all the words in the candidate NP,0,original
Several automatic sentence alignment approaches have been proposed based on sentence length   and lexical information  .,0,original
"Recently, it has gained renewed attention as empirical methods in parsing have emphasized the importance of relations between words  ), which is what dependency grammars model explicitly, but context-free phrase-structure grammars do not.",0,original
"a65 The rest of the factors denote distorsion probabilities  , which capture the probability that words change their position when translated from one language into another; the probability of some French words being generated from an invisible English NULL element  , etc. See   or   for a detailed discussion of this translation model and a description of its parameters.",0,original
"In agreement with recent resuits on parsing with lexicalised probabilistic grammars  , we find that statistics over lexical, as opposed to structural, features best correspond to human intuitive.judgments and to experimental findings.",0,original
"Co-selection measures include precision and recall of co-selected sentences, relative utility  , and Kappa  .",0,original
"Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT  , operating on characters rather than words.",0,original
urney   suggested comparing the frequency of phrase co-occurrences with words predetermined by the sentiment lexicon,0,original
"2 The IBM Model 4 For the work described in this paper we used a modified version of the statistical machine translation tool developed in the context of the 1999 Johns HopkinsSummer Workshop  , which implements IBM translation model 4  .",0,original
"A variety of algorithms  , co-training  , alternating structure optimization  , etc).",0,original
"The relatedness between two word senses is computed using a measure of semantic relatedness defined in the WordNet::Similarity software package  , which is a suite of Perl modules implementing a number WordNet-based measures of semantic relatedness.",0,original
The model we use is similar to that of  .,0,original
"The POS disambiguation has usually been performed by statistical approaches mainly using hidden markov model   (Cutting et al. , 1992; Kupiec.",0,original
For a detailed description for Model 4 the reader is referred to  .,0,original
"2 Data Sets for the Experiments 2.1 Coordination Annotation in the PENN TREEBANK For our experiments, we used the WSJ part of the PENN TREEBANK  .",0,original
1 Introduction Decoding is one of the three fundamental problems in classical SMT   as proposed by IBM in the early 1990s  .,0,original
"Marcu and Echihabi   use a pattern-based approach in mining instances of RSRs such as Contrast and Elaboration from large, unannotated corpora.",0,original
"The generator used in our experiments is an instance of the second type, using a probability model defined over Lexical Functional Grammar c-structure and f-structure annotations  .",0,original
  and   utilized bootstrapping for word sense disambiguation.,0,original
"1 Empty categories however seem different, in that, for the most part, their location and existence is determined, not by observable data, but by explicitly constructed linguistic principles, which 1 Both Collins   and Higgins   are explicit about this predisposition.",0,original
"  Och   provides evidence that  should be chosen by optimizing an objective function basd on the evaluation metric of interest, rather than likelihood.",0,original
Collocations were extracted according to the method described in   by moving a window on texts.,0,original
"Then, we used the refinement technique grow-diag-final-and   to all 50  50 bidirectional alignment pairs.",0,original
"3 Methodology Similar to  , we use comparison to human assocation datasets as a test bed for the scores produced by computational association measures.",0,original
"Since an existing study incorporates these relations ad hoc  , they are apparently crucial in accurate disambiguation.",0,original
"Bean and Riloff   extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases.",0,original
"The more recent set of techniques includes mult iplicative weightupdate algorithms  , latent semantic analysis  , transformation-based learning  , differential grammars  , decision lists  , and a variety of Bayesian classifiers  .",0,original
"The implementation is similar to the idea of lexical weight in  : all points in the alignment matrices of the entire training corpus are collected to calculate the probabilistic distribution, P , of some TL word 3Some readers may prefer the expression the subtree rooted at node N to node N. The latter term is used in this paper for simplicity.",0,original
The notion of incrementally merging classes of lexical items is intuitively satisfying and is explored in detail in  .,0,original
"Our MT experiments use a re-implementation of Moses   called Phrasal, which provides an easier API for adding features.",0,original
This model is similar in spirit to IBM model 1  .,0,original
The probability distributions of these binary classifiers are learnt using maximum entropy model  .,0,original
This is con rmed by the translation experiments in which the evaluation data sets were translated using the servers translation engines and the translation quality was evaluated using the standard automatic evaluation metrics BLEU   and METEOR   where scores range between 0   and 1  .,0,original
"Perhaps this was not observed earlier since   studied only base NPs, most of which are short.",0,original
"The most important tree-bank transformation in the literature is lexicalization: Each node in a tree is labeled with its head word, the most important word of the constituent under the node  , Collins  , Charniak  , Collins  , Carroll and Rooth  , etc.).",0,original
" .5 6.2 Results We performed experiments using three training algorithms: the averaged perceptron  , log-linear training  , and max-margin training  .",0,original
"Note that the minimum error rate training   uses only the target sentence with the maximum posterior probability whereas, here, the whole probability distribution is taken into account.",0,original
"This can be done in a supervised  , a semi-supervised   or a fully unsupervised way  .",0,original
Related Work 2.1 Translation with Non-parallel Corpora A straightforward approach to word or phrase translation is to perform the task by using parallel bilingual corpora  .,0,original
The data was segmented into baseNP parts and nonbaseNP parts in a similar fashion as the data used by  .,0,original
Most of them rely on the concept of alignment: a mapping from words or groups of words in a sentence into words or groups in the other   the mapping goes from rules in a grammar for a language into rules of a grammar for the other language).,0,original
This paper presents an empirical study measuring the effectiveness of our evaluation functions at selecting training sentences from the Wall Street Journal   corpus   for inducing grammars.,0,original
"The most common answer is component testing, where the component is compared against a standard of goodness, usually the Penn Treebank for English  , allowing a numerical score of precision and recall  .",0,original
"In future work we plan to experiment with richer representations, e.g. including long-range n-grams  , class n-grams  , grammatical features  , etc'.",0,original
2 Word Alignment Framework A statistical translation model   describes the relationship between a pair of sentences in the source and target languages   using a translation probability P .,0,original
"For MCE learning, we selected the reference compression that maximize the BLEU score    ) from the set of reference compressions and used it as correct data for training.",0,original
"Then, it models the correlations between the pivot features and all other features by training linear pivot predictors to predict occurrences of each pivot in the unlabeled data from both domains  .",0,original
"The results of these studies have important applications in lexicography, to detect lexicosyntactic regularities  , such as, for example~ support verbs   prepositional verbs   idioms, semantic relations   and fixed expressions  .",0,original
"Much work has been performed on learning to identify and classify polarity terms   or a negative sentiment  ) and exploiting them to do polarity classification  , Turney  , Kim and Hovy  , Whitelaw et al.",0,original
"In several papers  , selection criteria for single word trigger pairs were studied.",0,original
"3 OverviewofExtractionWork 3.1 English As one mightexpect,the bulk of the collocation extractionwork concernsthe English language:  , amongmany others1.",0,original
"4 Evaluation As our algorithm works in open domains, we were able to perform a corpus-based evaluation using the Penn WSJ Treebank  .",0,original
"Cucerzan  , by contrast to the above, used Wikipedia primarily for Named Entity Disambiguation, following the path of Bunescu and Paca  .",0,original
"Following  , we used the version 11a NIST BLEU script with its default settings to calculate the BLEU scores   based on case-insensitive ngram matching, where n is up to 4.",0,original
"2 Background 2.1 Hybrid Logic Dependency Semantics Hybrid Logic Dependency Semantics   is an ontologically promiscuous   framework for representing the propositional content   of an expression as an ontologically richly sorted, relational structure.",0,original
Parse selection constitutes an important part of many parsing systems  .,0,original
three models in   are susceptible to the method.,0,original
Dependency relations are produced using a version of the Collins parser   that has been adapted for building dependencies.,0,original
The algorithm of   translates the traces into corresponding re-entrancies in the f-structure representation  .,0,original
It is an important and growing field of natural language processing with applications in areas such as transferbased machine translation   and sentence condensation  .,0,original
A conditional maximum entropy model q  for p has the parametric form  : q  = exp T f   y2Y  exp )   where  is a d-dimensional parameter vector and T f   is the inner product of the parameter vector and a feature vector.,0,original
The parameters of the MT system were optimized on MTEval02 data using minimum error rate training  .,0,original
"Entropy, used in some part-of-speech tagging systems  , is a measure of how much information is necessary to separate data.",0,original
ur work in sentence reformulation is different from cut-and-paste summarization   in many ways,0,original
The other intriguing issue is how our anchor-based method for shared argument identification can benefit from recent advances in coreference and zero-anaphora resolution  .,0,original
"Such a lexicon can be used, e.g., to classify individual sentences or phrases as subjective or not, and as bearing positive or negative sentiments  .",0,original
One attempt to implement this idea is lexicalization: increasing the information in the POS tag by adding the lemma to it  .,0,original
"P  =producttextiP    The actions are also sometimes split into a sequence of elementary decisions Di = di1,,din, as discussed in  .",0,original
"The surface heuristic can define consistency according to any word alignment; but most often, the alignment is provided by GIZA++  .",0,original
"Examples are Andersen  , Okanohara and Tsujii  , Sun et al.",0,original
"In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus  .",0,original
"The modified version of the Roark parser, trained on the Brown Corpus section of the Penn Treebank  , was used to parse the different narratives and produce the word by word measures.",0,original
"The model weights of the transducer are tuned based on the development set using a grid-based line search, and the translation results are evaluated based on a single Chinese reference6 using BLEU-4  .",0,original
"4.1 The base line For our base line parse accuracy, we used the now standard division of the WSJ   with sections 2 through 21 for training (approx.",0,original
"3.2 Results and Discussion The BLEU scores   for 10 direct translations and 4 sets of heuristic selections 4Admittedly, in typical instances of such chains, English would appear earlier.",0,original
"3.2.2 Alignment Error Rate Since MT systems are usually built on the union of the two sets of alignments  , we consider the union of alignments in the two directions as well as those in each direction.",0,original
3.2 Compound Noun Interpretation The task of interpreting the semantics of noun compounds is one which has recently received considerable attention  .,0,original
" ), less prior work exists for bilingual acquisition of domain-specific translations.",0,original
ord Alignment Quality Metrics 3.1 Alignment Error Rate is Not a Useful Measure We begin our study of metrics for word alignment quality by testing AER  ,0,original
A few exceptions are the hierarchical   transduction models   and the string transduction models  .,0,original
"This is a particularly exciting area in computational linguistics as evidenced by the large number of contributions in these special issues: Biber  , Brent  , Hindle and Rooth  , Pustejovsky et al.",0,original
"So far, most previous work on domain adaptation for parsing has focused on data-driven systems  , i.e. systems employing   treebank grammars  .",0,original
The current approach does not use specialized probability features as in   in any stage during decoder parameter training.,0,original
"In this paper, we bring forward the first idea by studying the issue of how to utilize structured syntactic features for phrase reordering in a phrase-based SMT system with BTG   constraints  .",0,original
We evaluate the summaries using the automatic evaluation tool ROUGE     and the ROUGE value works as the feedback to our learning loop.,0,original
"We base our work partly on previous work done by Bagga and Baldwin  , which has also been used in later work  .",0,original
We implemented this model within an ME modeling framework  .,0,original
"Table 1 shows theresultsalongwithB andthethreemetricsthat achieved higher correlations than B: semantic role overlap  , ParaEval recall  , and METEOR  .",0,original
"Our hierarchical system is Hiero  , modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez  .",0,original
translation lexicon entries were scored according to the log likelihood ratio   (cf.,0,original
5 Experimental Data The sense-tagged text and feature set used in these experiments are the same as in  .,0,original
In this work we use the following contextual information: a3 Target context: As in   we consider a window of 3 words to the left and to the right of the target word considered.,0,original
"First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++  , in both directions and by combining the results based on a heuristic  .",0,original
Recent research in open information extraction   has shown that we can extract large amounts of relational data from open-domain text with high accuracy.,0,original
"In our SRL system, we select maximum entropy   as a classi er to implement the semantic role labeling system.",0,original
"In Table 10, Baseline gives the results of the generation algorithm of  .",0,original
"Ramshaw and Marcus   state that a baseNP aims to identify essentially the initial portions of nonrecursive noun phrases up to the head, including determiners but not including postmodifying prepositional phrases or clauses . However, work on baseNPs has essentially always proceeded via algorithmic extraction from fully parsed corpora such as the Penn Treebank.",0,original
"  The syntactic annotation task consists of marking constituent boundaries, inserting empty categories  , showing the relationships between constituents  , and specifying a particular subset of adverbial roles.",0,original
"The measure simHinate is the same as the similarity measure proposed in  , except that it does not use dependency triples with negative mutual information.",0,original
"2 System Description 2.1 Data Representation In this paper, we change the representation of the original data as follows: Bracketed representation of roles is converted into IOB2 representation   Word tokens are collapsed into base phrase   tokens.",0,original
"1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention  .",0,original
"According to one account   the majority of errors arise because of the statistical filtering process, which is reported to be particularly unreliable for low frequency SCFs  .",0,original
"A total of 216 collocations were extracted, shown in Appendix A. We compared the collocations in Appendix A with the entries for the above 10 words in the NTC's English Idioms Dictionary    , which contains approximately 6000 definitions of idioms.",0,original
"In the proposed method, the statistical machine translation     is deeply incorporated into the question answering process, instead of using the SMT as the preprocessing before the mono-lingual QA process as in the previous work.",0,original
The translation models and lexical scores were estimated on the training corpus whichwasautomaticallyalignedusingGiza++  in both directions between source and target and symmetrised using the growing heuristic  .,0,original
"The parser expresses distinctions that are especially important for a predicate-argument based deep syntactic representation, as far as they are expressed in the training data generated from the Penn Treebank  .",0,original
We also do not require a newly added feature to be either atomic or a collocation of an atomic feature with a feature already included into the model as it was proposed in    .,0,original
  present a probabilistic model for pronoun resolution trained on a small subset of the Penn Treebank Wall Street Journal corpus  .,0,original
"However, our system is the unsupervised learning with small POS-tagged corpus,and we do not restrict the word's sense set within either binary senses  or dictionary's homograph level .",0,original
In   it was observed that a significant percent of the queries made by a user in a search engine are associated to a repeated search.,0,original
Part-of-Speech   annotation for example can be seen as the task of choosing the appropriate tag for a word from an ontology of word categories  ).,0,original
"In the first set of experiments, we compare two settings of our UALIGN system with other aligners, GIZA++     and LEAF    .",0,original
"Therefore, to make the phrase-based SMT system robust against data sparseness for the ranking task, we also make use of the IBM Model 4   in both directions.",0,original
" , and others identifying non-anaphoric definite descriptions  ] and unsupervised techniques  ).",0,original
"6 Training Similar to most state-of-the-art phrase-based SMT systems, we use the SRI toolkit   for language model training and Giza++ toolkit   for word alignment.",0,original
Automatic Creation of WIDL-expressions for MT. We generate WIDL-expressions from Chinese strings by exploiting a phrase-based translation table  .,0,original
"Yarowsky   proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples.",0,original
The leader of the pack is the MXPOST tagger  .,0,original
"The mapping of answer terms to question terms is modeled using Black et al.s   simplest model, called IBM Model 1.",0,original
"They are part of an effort to better integrate a linguistic, rule-based system and the statistical correcting layer also illustrated in  .",0,original
Two main approaches have generally been considered: rule-based   probabilistic  .,0,original
"Table 1 shows a summary of the results of our experiments with SVMpar and MBLpar, and also results obtained with the Charniak   parser, the Bikel   implementation of the Collins   parser, and the Ratnaparkhi   parser.",0,original
"Applications have included the categorization of documents by topic  , language  , genre  , author  , sentiment  , and desirability  .",0,original
"Since we approach decoding as xR transduction, the process is identical to that of constituencybased algorithms  .",0,original
These categories were automatically generated using the labeled parses in Penn Treebank   and the labeled semantic roles of PropBank  .,0,original
An analysis of the alignments shows that smoothing the fertility probabilities significantly reduces the frequently occurring problem of rare words forming garbage collectors in that they tend to align with too many words in the other language  .,0,original
We use MER   to tune the decoders parameters using a development data set.,0,original
"In Section 3, we will present a Perceptron like algorithm   to obtain the parameters.",0,original
"The future score is based on the source-language words that are still to be translatedthis can be directly inferred from the items bit-stringthis is similar to the use of future scores in Pharoah  , and in fact we use Pharoahs future scores in our model.",0,original
We use the n-best generation scheme interleaved with  optimization as described in  .,0,original
"2.2 Evaluation of Acquisition Algorithms Many methods for automatic acquisition of rules have been suggested in recent years, ranging from distributional similarity to finding shared contexts  .",0,original
"3.1 Golden-standard-based criteria In the domain of machine translation systems, an increasingly accepted way to measure the quality of a system is to compare the outputs it produces with a set of reference translations, considered as an approximation of a golden standard  .",0,original
"2.2 Generalization pseudocode In order to identify the portions in common between the patterns, and to generalize them, we apply the following pseudocode  : 1All the PoS examples in this paper are done with Penn Treebank labels  .",0,original
"1 Introduction In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types  .",0,original
"For example, the Penn Treebank   was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus.",0,original
"We used the Wall Street Journal   part of the Penn Treebank  , where extraction is represented by co-indexing an empty terminal element   to its antecedent.",0,original
4.2 Models with Prior Distributions Minimum discrimination information models   are exponential models with a prior distribution q : p  = q exp ) Z    The central issue in performance prediction for MDI models is whether q  needs to be accounted for.,0,original
"Though our motivation is similar to that of Koehn and Hoang  , we chose to build an independent component for inflection prediction in isolation rather than folding morphological information into the main translation model.",0,original
Machine Translation using Inversion Transduction Grammar The Inversion Transduction Grammar   of Wu   is a type of context-free grammar   for generating two languages synchronously,0,original
"From the same treebank, Cahill and van Genabith   automatically extracted wide-coverage LFG approximations for a PCFG-based generation model.",0,original
5 Reliability of Annotations 5.1 The Kappa Statistic To measure the reliability of annotations we used the Kappa statistic  .,0,original
"We build sentencespecific zero-cutoff stupid-backoff   5-gram language models, estimated using 4.7B words of English newswire text, and apply them to rescore each 10000-best list.",0,original
Word alignment models were first introduced in statistical machine translation  .,0,original
"2 Baseline DP Decoder The translation model used in this paper is a phrasebased model  , where the translation units are so-called blocks: a block b is a pair consisting of a source phrase s and a target phrase t which are translations of each other.",0,original
Sang used the IOB tagging method proposed by Ramshow  and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the Penn Treebank corpus.,0,original
"Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package  .1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/a0 tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce.",0,original
1 Introduction Statistical machine translation   was originally focused on word to word translation and was based on the noisy channel approach  .,0,original
Thenthewordalignment is refined by performing grow-diag-final method  .,0,original
Dredze et al. yielded the second highest score1 in the domain adaptation track  .,0,original
Our method is thus related to previous work based on Harris  s distributional hypothesis.2 It has been used to determine both word and syntactic path similarity  .,0,original
WSD that use information gathered from raw corpora      .,0,original
"We use the maximum entropy tagging method described in   for the experiments, which is a variant of   modified to use HMM state features.",0,original
he output of GIZA++ is then post-processed using the three symmetrization heuristics described in Och and Ney  ,0,original
"3.1 Word Sequence Classification Similar to English text chunking  , the word sequence classification model aims to classify each word via encoding its context features.",0,original
"Most of the annotation approaches tackling these issues, however, are aimed at performing classifications at either the document level  , or the sentence or word level  .",0,original
"The tagger is a Hidden Markov Model trained with the perceptron algorithm introduced in  , which applies Viterbi decoding and is regularized using averaging.",0,original
"2.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy   model.",0,original
The supertagger uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories   and the forward backward algorithm efficiently sums over all histories to give a distribution for each word.,0,original
"The cohesion between words has been evaluated with the mutual information measure, as in  .",0,original
"Word alignment and phrase extraction We used the GIZA++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source French file and the English reference file, and the refined word alignment strategy of   to obtain improved word and phrase alignments.",0,original
Use of probability estimates is not a serious limitation of this approach because in practice candidates are normally provided by some probabilistic model and its probability estimates are used as additional features in the reranker  .,0,original
4.1 Extraction from Definition Sentences Definition sentences in the Wikipedia article were used for acquiring hyponymy relations by   for named entity recognition.,0,original
"Since then this idea has been applied to several tasks, including word sense disambiguation   and named-entity recognition  .",0,original
"Unfortunately, as shown in  , with the represetation of sentences that we use, linear classifiers cannot discriminate real sentences from sentences sampled from a trigram, which is the model we use as a baseline, so here we resort to a non-linear large-margin classifier  .",0,original
"For this work, an off-the-shelf maximum entropy tagger 10   was used.",0,original
"Expansion of the equivalent sentence set can be applied to automatic evaluation of machine translation quality  , for example.",0,original
"In fact, when the perceptron update rule of    which modifies the weights of every divergent node along the predicted and true paths  is used in the ranking framework, it becomes virtually identical with the standard, flat, ranking perceptron of Collins  .5 In contrast, our approach shares the idea of   that if a parent class has been predicted wrongly, then errors in the children should not be taken into account. We also view this as one of the key ideas of the incremental perceptron algorithm of  , which searches through a complex decision space step-by-step and is immediately updated at the first wrong move.",0,original
6 Comparison With Previous Work The two parsers which have previously reported the best accuracies on the Penn Treebank Wall St. Journal are the bigram parser described in   and the SPATTER parser described in  .,0,original
Mean number of instances of paraphrase phenomena per sentence  .,0,original
"For comparison to previous results, table 2 lists the results on the testing set for our best model   and several other statistical parsers  .",0,original
Optimization and measurement were done with the NIST implementation of case-insensitive BLEU 4n4r  .4 4.1 Baseline We compared translation by pattern matching with a conventional exact model representation using external prefix trees  .,0,original
"Figures 1 and 2 present best results in the learning experiments for the complete set of patterns used in the collocation approach, over two of our evaluation corpora.11 Type Positions Tags/Words Features Accuracy Precision Recall GIS 1 W 1254 0.97 0.96 0.98 IIS 1 T 136 0.95 0.96 0.94 NB 1 T 136 0.88 0.97 0.84 9 see Rish, 2001, Ratnaparkhi, 1997 and Berger et al, 1996 for a formal description of these algorithms.",0,original
"Collins   gives convergence proofs for the methods; Collins   directly compares the boosting and perceptron approaches on a named entity task; and Collins and Duffy   use a reranking approach with kernels, which allow representations of parse trees or labeled sequences in very-high-dimensional spaces.",0,original
"By comparing derivation trees for parallel sentences in two languages, instances of structural divergences   can be automatically detected.",0,original
"For each feature function, there is a model parameter  i . The best word segmentation W * is determined by the decision rule as  = == M i ii W M W WSfWSScoreW 0 0 * ), ,,  Below we describe how to optimize  s. Our method is a discriminative approach inspired by the Minimum Error Rate Training method proposed in Och  .",0,original
Both techniques implement variations on the approaches of   and   for the purpose of differentiating between complement and adjunct.,0,original
"In order to extract the linguistic features necessary for the models, all sentences containing the target word were automatically part-of-speech-tagged using a maximum entropy tagger   and parsed using the Collins parser  .",0,original
"First, we extend the mechanism of adding gap variables for nodes dominating a site of discontinuity  .",0,original
"5.5 Applying F-score Optimization Technique In addition, we can simply apply the F-score optimization technique for the sequence labeling tasks proposed in   to boost the HySOL performance since the base discriminative models pD  and discriminative combination, namely Equation  , in our hybrid model basically uses the same optimization procedure as CRFs.",0,original
"While Kazama and Torisawa used a chunker, we parsed the definition sentence using Minipar  .",0,original
The normalization is visualized as a translation problem where messages in the SMS language are to be translated to normal English using a similar phrase-based statistical MT method  .,0,original
" ,  ,  ,  ,  ,  ), and to pick those ingredients which are known to be con~i)utationally 'tractable' in some sense.",0,original
"With this model, we can provide not only qualitative textual summarization such as good food and bad service, but also a numerical scoring of sentiment, i.e., how good the food is and how bad the service is. 2 Related Work There have been many studies on sentiment classification and opinion summarization  .",0,original
"The problem is typically presented in log-space, which simplifies computations, but otherwise does not change the problem due to the monotonicity of the log function   log p  = summationdisplay m m hm    Phrase-based models   are limited to the mapping of small contiguous chunks of text.",0,original
"These later inductive phases may rely on some level of a priori knowledge, like for example the naive case relations used in the ARIOSTO_LEX system  .",0,original
"Thus, it may not suffer from the issues of non-isomorphic structure alignment and non-syntactic phrase usage heavily  .",0,original
Evaluation metrics such as BLEU   have a built-in preference for shorter translations.,0,original
"To test whether a better set of initial parameter estimates can improve Model 1 alignment accuracy, we use a heuristic model based on the loglikelihood-ratio   statistic recommended by Dunning  .",0,original
"Researchers extracted opinions from words, sentences, and documents, and both rule-based and statistical models are investigated  .",0,original
he input is POS-tagged using the tagger of Ratnaparkhi  ,0,original
"We observe that AER is loosely correlated to BLEU   though the relation is weak, as observed earlier by Fraser and Marcu  .",0,original
These belong to two main categories based on machine learning   and language or domain specific rules  .,0,original
"Some researchers have concentrated on producing WSD systems that base results on a limited number of words, for example Yarowsky   and Schtitze   who quoted results for 12 words, and a second group, including Leacock, Towell, and Voorhees   and Bruce and Wiebe  , who gave results for just one, namely interest.",0,original
"Thus, an orthogonal line of research can involve inducing classes for words which are more general than single categories, i.e., something akin to ambiguity classes  .",0,original
Translation performance was measured using the automatic BLEU evaluation metric   on four reference translations,0,original
"Maximum Entropy models have been used to express the interactions among multiple feature variables  ), but within this framework no systematic study of interactions has been proposed.",0,original
"Seen from Table 2, our result about SCL is in accord with that in   on the whole.",0,original
he weights of the models are computed automatically using a variant of the Maximum Bleu training procedure proposed by Och  ,0,original
"By labelling Treeb~n~ nodes with Gr~ramar rule names, and not with phrasal and clausal n~raes, as in other   treebanks'  , we gain access to all information provided by the Grammar regarding each ~reebank node.",0,original
"1 Introduction In statistical machine translation, output translations are evaluated by their similarity to human reference translations, where similarity is most often measured by BLEU  .",0,original
"1 Introduction In the part-of-speech hterature, whether taggers are based on a rule-based approach  ,  ,  , or on a statistical one  ,  ,  ,  ,  ,  , there is a debate as to whether more attention should be paid to lexical probabilities rather than contextual ones.",0,original
"4This was a straightforward task; two annotators annotated independently, with very high agreementkappa score of over 0.95  .",0,original
"Typically, a phrase-based SMT system includes a feature that scores phrase pairs using lexical weights   which are computed for two directions: source to target and target to source.",0,original
PropBank encodes propositional information by adding a layer of argument structure annotation to the syntactic structures of the Penn Treebank  .,0,original
"Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus  , and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al.",0,original
Examples of such early work include  .,0,original
"Practically, the grammar relaxation is done via the introduction of non-standard CCG rules  .",0,original
"6 Related Work The most relevant previous works include word sense translation and translation disambiguation  , frame semantic induction  , and bilingual semantic mapping  .",0,original
"The typical practice of preprocessing distributional data is to remove rare word co-occurrences, thus aiming to reduce noise from idiosyncratic word uses and linguistic processing errors and at the same time form more compact word representations  .",0,original
"The algorithm is slightly different from other online training algorithms   in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, i.e. BLEU  .",0,original
"We evaluate accuracy performance using two automatic metrics: an identity metric, ID, which measures the percent of sentences recreated exactly, and BLEU  , which gives the geometric average of the number of uni-, bi-, tri-, and four-grams recreated exactly.",0,original
"Zens and Ney   explore the re-orderings allowed by ITGs, and provide a formulation for the number of structures that can be built for a sentence pair of size n. ITGs explore almost all of permutation space when n is small, but their coverage of permutation space falls off quickly for n > 5  .",0,original
"To evaluate the polarity and strength of opinions, most of the existing approaches rely either on training from human-annotated data  , or use linguistic resources   like WordNet, or rely on co-occurrence statistics   between words that are unambiguously positive   and unambiguously negative  .",0,original
"Instead, researchers routinely use automatic metrics like Bleu   as the sole evidence of improvement to translation quality.",0,original
"By no means an exhaustive list, the most commonly cited ranking and scoring algorithms are HITS   and PageRank  , which rank hyperlinked documents using the concepts of hubs and authorities.",0,original
"Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model  , flat reordering model  , lexicalized reordering model  , to hierarchical phrase-based model   and classifier-based reordering model with linear features  .",0,original
"As a baseline, we use an IBM Model 4   system3 with a greedy decoder4  .",0,original
"In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in  .",0,original
"  Merkel, Nilsson, & Ahrenberg   have constructed a system that uses frequency of recurrent segments to determine long phrases.",0,original
"In  , target trees were employed to improve the scoring of translation theories.",0,original
"There are several basic methods for evaluating associations between words: based on frequency counts  , information theoretic   and statistical significance  .",0,original
"Head word   of the constituent  After POS tagging, a syntactic parser   was then used to obtain the parse tree for the sentence.",0,original
unning   reports that we should not rely on the assumption of a normal distribution when performing statistical text analysis and suggests that parametric analysis based on the binomial or multinomial distributions is a better alternative for smaller texts,0,original
"1 Introduction Parsers have been developed for a variety of grammar formalisms, for example HPSG  , LFG  , TAG  , CCG  , and variants of phrase-structure grammar  , including the phrase-structure grammar implicit in the Penn Treebank  .",0,original
"The quality of the translation output is mainly evaluated using BLEU, with NIST   and METEOR   as complementary metrics.",0,original
"For our studies here, the parser employed was that of Collins   applied to the sentences of the British National Corpus  .",0,original
"We employ a robust statistical parser   to determine the constituent structure for each sentence, from which subjects  , objects  , and relations other than subject or object   are identified.",0,original
The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse  .,0,original
"These results were achieved using the statistical alignments provided by model 5   and smoothed 11-grams and 6-grams, respectively.",0,original
"Instead of analyzing sentences directly, AUCONTRAIRE relies on the TEXTRUNNER Open Information Extraction system   to map each sentence to one or more tuples that represent the entities in the sentences and the relationships between them  ).",0,original
"HMMs have been used many times for POS tagging and chunking, in supervised, semisupervised, and in unsupervised settings  .",0,original
The Chinese text was tagged using the MXPOST maximum-entropy part of speech tagging tool   trained on the Penn Chinese Treebank 5.1; the English text was tagged using the TnT part of speech tagger   trained on the Wall Street Journal portion of the English Penn treebank.,0,original
"The trees may be learned directly from parallel corpora  , or provided by a parser trained on hand-annotated treebanks  .",0,original
It is today common practice to use phrases as translation units   instead of the original word-based approach.,0,original
"2.1 EM parameter estimation We train using Expectation Maximisation  , optimising the log probability of the training setfe ,f gSs=1  .",0,original
"We then tested the best models for each vocabulary size on the testing set.4 Standard measures of performance are shown in table 1.5 3We used a publicly available tagger   to provide the tags used in these experiments, rather than the handcorrected tags which come with the corpus.",0,original
The significance values are obtained using the loglikelihood measure assuming a binomial distribution for the unrelatedness hypothesis  .,0,original
"3.4 Learning algorithm Maximum entropy   models  , also known as log-linear and exponential learning models, has been adopted in the SC classification task.",0,original
"2 The METEOR Metric 2.1 Weaknesses in BLEU Addressed in METEOR The main principle behind IBMs BLEU metric   is the measurement of the 66 overlap in unigrams   and higher order n-grams of words, between a translation being evaluated and a set of one or more reference translations.",0,original
Unsupervised systems   are based on generative models trained with the EM algorithm.,0,original
1 Introduction Previous work on sentiment categorization makes an implicit assumption that a single score can express the polarity of an opinion text  .,0,original
"Vilain and Day   identify   name phrases such as company names, locations, etc. Ramshaw and Marcus   detect noun phrases, by classifying each word as being inside a phrase, outside or on the boundary between phrases.",0,original
Sentiment classification at the document level investigates ways to classify each evaluative document   as positive or negative  .,0,original
"We could also introduce new variables, e.g., nonterminal refinements  , or secondary linksMij   that augment the parse with representations of control, binding, etc.",0,original
"This fact is being seriously challenged by current research  , and might not be true in the near future  .",0,original
We also employ the voted perceptron algorithm   and the early update technique as in  .,0,original
2.5 Evaluation Minnen and Carroll   report an evaluation of the accuracy of the morphological generator with respect to the CELEX lexical database  .,0,original
"Wu   demonstrates the case of binary SCFG parsing, where six string boundary variables, three for each language as in monolingual CFG parsing, interact with each other, yielding an O  dynamic programming algorithm, where N is the string length, assuming the two paired strings are comparable in length.",0,original
"Because their joint distributions have such closed-form expressions, the parameters can be estimated directly from the training data without the need for an iterative fitting procedure  ).",0,original
  proposed a method to retrieve collocations by combining bigrams whose cooccurrences are greater than a given threshold 3.,0,original
  present a chart generator using wide-coverage PCFG-based LFG approximations automatically acquired from treebanks  .,0,original
"For the classifier, we used the OpenNLP MaxEnt implementation   of the maximum entropy classification algorithm  .",0,original
"A number of bootstrapping methods have been proposed for NLP tasks  , Collins and Singer  , Riloff and Jones  ).",0,original
"Similarly, Smadja   uses a six content word window to extract significant collocations.",0,original
"Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate   training  .",0,original
his tagging scheme is the IOB scheme originally put forward by Ramshaw and Marcus  ,0,original
"5 Results The model summaries were compared against 24 summaries generated automatically using SUMMA by calculating ROUGE-1 to ROUGE4, ROUGE-L and ROUGE-W-1.2 recall metrics  .",0,original
"For a full description of the algorithm, see  .",0,original
"5 Datasets and Evaluation We train our models with verb instances extracted from three parsed corpora:   the Wall Street Journal section of the Penn Treebank  , which was parsed by human annotators  ,   the Brown Laboratory for Linguistic Information Processing corpus of Wall Street Journal text  , which was parsed automatically by the Charniak parser  , and   the Gigaword corpus of raw newswire text  , which we parsed ourselves with the Stanford parser.",0,original
"Additionally, automatic evaluation of content coverage using ROUGE   was explored in 2004.",0,original
"Of these, only feature weights can be trained, for which we used minimum error rate training with version 1.04 of IBM-style BLEU   in case-insensitive mode.",0,original
Incremental Sigmoid Belief Networks   differ from simple dynamic SBNs in that they allow the model structure to depend on the output variable values.,0,original
The model scaling factors are optimized with respect to some evaluation criterion  .,0,original
"Finally, following Haghighi and Klein   and Johnson   we can instead insist that at most one HMM state can be mapped to any part-of-speech tag.",0,original
Although the training algorithm can handle realvalued features as used in   the current paper intentionally excludes them.,0,original
"This con rms Liu and Gildea  s nding that in sentence level evaluation, long n-grams in BLEU are not bene cial.",0,original
"We trained and tested the parser on the Wall Street Journal corpus of the Penn Treebank   using the standard split: sections 2-21 were used for training, section 22 was used for development and tuning of parameters and features, and section 23 was used for testing.",0,original
"First, we can let the number of nonterminals grow unboundedly, as in the Infinite PCFG, where the nonterminals of the grammar can be indefinitely refined versions of a base PCFG  .",0,original
"For tuning of decoder parameters, we conducted minimum error training   with respect to the BLEU score using 916 development sentence pairs.",0,original
"For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words  .",0,original
"By analyzing rhetorical discourse structure of aim, background, solution, etc. or citation context, we can obtain appropriate abstracts and the most influential contents from scientific articles  .",0,original
"  Here, the candidate generator gen  enumerates candidates of destination   strings, and the scorer P  denotes the conditional probability of the string t for the given s. The scorer was modeled by a noisy-channel model   and maximum entropy framework  .",0,original
The approach is evaluated by cross-validation on the WSJ treebank corpus.,0,original
"Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger  , the YamCha chunker   and the Stanford Named Entity Recognizer  , the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser   to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors.",0,original
We use the IBM Model 1   and the Hidden Markov Model  ) to estimate the alignment model.,0,original
The minimum error training   was used on the development data for parameter estimation.,0,original
"Recently,   introduced an approach for incorporating a dependency-based language model into SMT.",0,original
"We then built separate directed word alignments for EnglishX andXEnglish   using IBM model 4  , combined them using the intersect+grow heuristic  , and extracted phrase-level translation pairs of maximum length seven using the alignment template approach  .",0,original
ur statistical tagging model is modified from the standard bigrams   using Viterbi search plus onthe-fly extra computing of lexical probabilities for unknown morphemes,0,original
The next section briefly reviews the word alignment based statistical machine translation  .,0,original
These records are also known as field books and reference sets in literature  .,0,original
"Parse Parse score from Model 2 of the statistical parser  , normalized by the number of words.",0,original
"After building the chunker, students were asked to 4 choose a verb and then analyze verb-argument structure  ).",0,original
"Bean and Riloff   used bootstrapping to extend their semantic compatibility model, which they called contextual-role knowledge, by identifying certain cases of easily-resolved anaphors and antecedents.",0,original
"In our own work on document compression models  , both of which extend the sentence compression model of Knight and Marcu  , we assume that sentences and documents can be summarized exclusively through deletion of contiguous text segments.",0,original
"where mk is one mention in entity e, and the basic model building block PL  is an exponential or maximum entropy model  .",0,original
3.1 System Tuning Minimum error training   under BLEU   was used to optimise the feature weights of the decoder with respect to the dev2006 development set.,0,original
"We use   and  for straight and inverted combinations respectively, following the ITG notation  .",0,original
3.3 BLEU Score The BLEU score   measures the agreement between a hypothesiseI1 generated by the MT system and a reference translation eI1.,0,original
in   and Lin and Och   proposed an LCS-based automatic evaluation measure called ROUGE-L,0,original
"Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing  .",0,original
"Nevertheless, the generated rules are strictly required to be derived from the contiguous translational equivalences  .",0,original
ollins   proposed a Perceptron like learning algorithm to solve sequence classification in the traditional left-to-right order,0,original
"For the efficiency of minimum-errorrate training  , we built our development set   using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data.",0,original
"The other approach is to estimate a single score or likelihood of a translation with rich features, for example, with the maximum entropy   method as in  .",0,original
"models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible  .",0,original
"Speaker ranking accuracy Table 2 summarizes the accuracy of our statistical ranker on the test data with different feature sets: the performance is 89.39% when using all feature sets, and reaches 90.2% after applying Gaussian smoothing and using incremental feature selection as described in   and implemented in the yasmetFS package.6 Note that restricting ourselves to only backward looking features decreases the performance significantly, as we can see in Table 2.",0,original
"1 Introduction Empty categories   are used in the annotation of the PENN treebank   in order to represent syntactic phenomena like constituent movement  , discontinuous constituents, and missing elements  .",0,original
"Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu   which use multiple reference translations.",0,original
"Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval   and Machine Translation   .",0,original
arowsky   used the one sense per collocation property as an essential ingredient for an unsupervised Word-SenseDisambiguationalgorithm,0,original
"The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in  ; phrase translation model probabilities; and trigram language model probabilities logp , using Kneser-Ney smoothing as implemented in the SRILM toolkit  .",0,original
The empirical probability for each sentence pair is estimated by maximum likelihood estimation over the training data  .,0,original
"2.2 Statistical Approaches with a grmnnmr There have been nlally l)rOl)osals tbr statistical t'rameworks particularly designed tbr 1)arsers with hand-crafted grmnmars  es, 1992; Briscoe and Carroll, 1993; Abney, 1996; Inui et al. , 1!)97).",0,original
"The experiment used all 578 sentences in the ATIS corpus with a parse tree, in the Penn Treebank  .",0,original
"On the other hand, other authors  ) do use the expression phrase-based models.",0,original
Our evaluation metrics is casesensitive BLEU-4  .,0,original
"There is a vast literature on language modeling; see, e.g.,  .",0,original
There has been recent work on discovering allomorphic phenomena automatically  .,0,original
"For example, the sentence I went to California last May would be marked for base NPs as: I went to California last May I 0 0 I B I indicating that the NPs are I, California and last May. This approach has been studied in  .",0,original
"In Ratnaparkhi  , a maximum entropy tagger is presented.",0,original
Our test set is 3718 sentences from the English Penn treebank   which were translated into German.,0,original
"Finally, our modeling approaches follow the recent work on both local classifier-based modeling of complex learning problems  , as well as global discriminative approaches based on CRFs  , SVM  , and the Perceptron algorithm   that we used in our experiments.",0,original
Model 1 is the word-pair translation model used in simple machine translation and understanding models  .,0,original
"However, the fact that the DGSSN uses a large-vocabulary tagger   as a preprocessing stage may compensate for its smaller vocabulary.",0,original
"Given sentence-aligned bi-lingual training data, we first use GIZA++   to generate word level alignment.",0,original
"There are more sophisticated surface generation packages, such as FUF/SURGE  , KPML  , MUMBLE  , and RealPro  , which produce natural language text from an abstract semantic representation.",0,original
"3.3 System evaluation Since both the system translations and the reference translations are available for the tuning 43 set, we first compare each output to the reference translation using BLEU   and METEOR   and a combined scoring scheme provided by the ULC toolkit  .",0,original
"For example,   collected reviews from a movie database and rated them as positive, negative, or neutral based on the rating   given by the reviewer.",0,original
his upper bound is consistent with the upper limit of 50% found by Daume III and Marcu   which takes into account stemming differences,0,original
"The performance of tl,e presented tagger is measured and compared to that of two other taggers  .",0,original
"We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown  .",0,original
"A variety of synset similarity measures based on properties of WordNet itself have been proposed; nine such measures are discussed in  , including gloss-based heuristics  , information-content based measures  , and others.",0,original
The system is tested on base noun-phrase   chunking using the Wall Street Journal corpus  .,0,original
"We generated for each phrase pair in the translation table 5 features: phrase translation probability  , lexical weighting     and phrase penalty  .",0,original
"2 Background Several graph-based learning techniques have recently been developed and applied to NLP problems: minimum cuts  , random walks  , graph matching  , and label propagation  .",0,original
"The phrase translation table is learnt in the following manner: The parallel corpus is word-aligned bidirectionally, and using various heuristics   for details) phrase correspondences are established.",0,original
"As an alternative, Huang and Chiang   describes a forest-based reranking algorithm called cube growing, which also employs beam search, but focuses computation only where necessary in a top-down pass through a parse forest.",0,original
"For example, researchers   have identified semantic correlation between words and views: positive words tend to appear more frequently in positive movie and product reviews and newswire article sentences that have a positive semantic orientation and vice versa for negative reviews or sentences with a negative semantic orientation.",0,original
"We viewed the seed word as a classified sentence, following a similar proposal in Yarowsky  .",0,original
"Finally, we plan to apply the model to other paraphrasing tasks including fully abstractive document summarisation  .",0,original
"129 5 Active learning Whereas a passive supervised learning algorithm is provided with a collection of training examples that are typically drawn at random, an active learner has control over the labelled data that it obtains  .",0,original
"In modern lexicalized parsers, POS tagging is often interleaved with parsing proper instead of being a separate preprocessing module  .",0,original
1 Introduction Many different statistical tests have been proposed to measure the strength of word similarity or word association in natural language texts  .,0,original
"Clustering algorithms have been previously shown to work fairly well for the classification of words into syntactic and semantic classes  , but determining the optimum number of classes for a hierarchical cluster tree is an ongoing difficult problem, particularly without prior knowledge of the item classification.",0,original
The other 5 have been suggested for Dutch by  .,0,original
"The model is defined mathematically   as following: p  = 1Zexp nsummationdisplay i=1 ihi    where i is a vector of weights determined during a tuning process, and hi is the feature function.",0,original
"In this respect, it resembles bilingual bracketing  , but our model has more lexical items in the blocks with many-to-many word alignment freedom in both inner and outer parts.",0,original
"Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction  , phrasal translation  , target word selection  , domain word translation  , sense disambiguation  , and even recently for query translation in cross-language IR as well  .",0,original
"We carefully implemented the original Grammar Association system described in  , tuned empirically a couple of smoothing parameters, trained the models and, finally, obtained an a119a21a120 a100 a104a122a121 of correct translations.9 Then, we studied the impact of:   sorting, as proposed in Section 3, the set of sentences presented to ECGI;   making language models deterministic and minimum;   constraining the best translation search to those sentences whose lengths have been seen, in the training set, related to the length of the input sentence.",0,original
"Using a variant of the voted perceptron  , we discriminatively trained our parser in an on-line fashion.",0,original
"This improvement is close to that of one sense per discourse    , which seems to be a sensible upper bound of the proposed method.",0,original
his therefore suggests that better parameters are likely to be learned in the 2Haghighi and Kleins   generative coreference model mirrors this in the posterior distribution which it assigns to mention types given their salience  ,0,original
Reranking methods have also been proposed as a method for using syntactic information  .,0,original
We measure translation performance by the BLEU score   with one reference for each hypothesis.,0,original
  applied iterative refinement algorithms to sentence level alignment tasks.,0,original
4 Pattern switching The compositional translation presents problems which have been reported by  : Fertility SWTs and MWTs are not translated by a term of a same length.,0,original
"Note that it is straightforward to calculate these expected counts using a variant of the inside-outside algorithm   applied to the   dependency-parsing data structures   for projective dependency structures, or the matrix-tree theorem   for nonprojective dependency structures.",0,original
2 F 1 -score Maximization Training of LRM We first review the F 1 -score maximization training method for linear models using a logistic function described in  .,0,original
"The domain axioms will bind the body variables to their most likely referents during unification with facts, and previously assumed and proven propositions similarly to  .",0,original
2 This problem is also a central concern in the work by Bean and Riloff  ,0,original
4.2 Impact of Paraphrases on Machine Translation Evaluation The standard way to analyze the performance of an evaluation metric in machine translation is to compute the Pearson correlation between the automatic metric and human scores  .,0,original
"MAXENT, Zhang Les C++ implementation 8 of maximum entropy modelling  .",0,original
"Many approaches have been proposed for semisupervised learning in the past, including: generative models  , self-learning  , cotraining  , informationtheoretic regularization  , and graphbased transductive methods  .",0,original
ts distribution is asymptotic to a  2 distribution and can hence be used as a test statistic  ,0,original
This is similar to results in the literature  .,0,original
The principle of our approach is more similar to  .,0,original
"In comparison with shallow semantic analysis tasks, such as wordsense disambiguation   and semantic role labeling  , which only partially tackle this problem by identifying the meanings of target words or finding semantic roles of predicates, semantic parsing   pursues a more ambitious goal  mapping natural language sentences to complete formal meaning representations  , where the meaning of each part of a sentence is analyzed, including noun phrases, verb phrases, negation, quantifiers and so on.",0,original
We also report the result of our translation quality in terms of both BLEU   and TER   against four human reference translations.,0,original
"It has been noticed, for example that capitalized and hyphenated words have a different distribution from other words.",0,original
"The data consist of sections of the Wall Street Journal   part of the Penn TreeBank  , with information on predicate-argument structures extracted from the PropBank corpus  .",0,original
The Bloomier filter LM   has a precomputed matching of keys shared between a constant number of cells in the filter array.,0,original
"Following  , we call the first the source domain, and the second the target domain.",0,original
Both models are based on IBM translation model 2   which has the 49 property that it generates tokens independently.,0,original
We propose a corpus-based method   which generates Noun Classifier Associations   to overcome the problems in classifier assignment and semantic construction of noun phrase.,0,original
"We tested several measures, such as ROUGE   and the cosine distance.",0,original
We also compare our algorithm to Structural Correspondence Learning    .,0,original
opSense is tested on 20 words extensively investigated in recent WSD literature  ,0,original
"6 Penn Discourse Treebank   The Penn Discourse TreeBank   annotates discourse relations over the Wall Street Journal corpus  , in terms of discourse connectives and their arguments.",0,original
A model was trained using Maximum Likelihood from the UPenn Treebank  .,0,original
"2 Problem Setting In the multi-class setting, instances from an input spaceX take labels from a finite setY,|Y| = K. 496 We use a standard approach   for generalizing binary classification and assume a feature function f  Rd mapping instances xX and labels yY into a common space.",0,original
The Pearson correlation is calculated over these ten pairs  .,0,original
"We used the NP data prepared by Ramshaw and Marcus  , hereafter RM95.",0,original
"Firstly, they classify all the GHKM2 rules   into two categories: lexical rules and non-lexical rules.",0,original
"A more optimistic view can be found in  ; they argue that a near-100% interjudge agreement is possible, provided the part-of-speech annotation is done carefully by experts.",0,original
2.3.4 Word Translation Probability Estimation Many methods are used to estimate word translation probabilities from unparallel or parallel bilingual corpora  .,0,original
"An alternative method we considered was to estimate certain conditional probabilities, similarly to the formula used in  : SW  log P  f f  = ~ log   P  f f  Here f  is   the probability that any given candidate phrase will be accepted by the spotter, and f  is the probability that this phrase is rejected, i.e., f  = l-f  .",0,original
We use the discriminative perceptron learning algorithm   to train the values of vectorw.,0,original
"Different methods have been proposed to reduce error propagation between pipelined tasks, both in general   and for specific problems such as language modeling and utterance classification   and labeling and chunking  .",0,original
It consists of sections 15-18 of the Wall Street Journal part of the Penn Treebank II   as training data   and section 20 as test data  .,0,original
2 Statistical Translation Engine A word-based translation engine is used based on the so-called IBM-4 model  .,0,original
This is known as cost-based abduction  .,0,original
he existing work most similar to ours is Collins and Roark  ,0,original
"Traditionally, such unsupervised EM-trained HMM taggers are thought to be inaccurate, but   showed that by feeding the EM process with sufficiently good initial probabilities, accurate taggers   can be learned for both English and Hebrew, based on a   lexicon and large amount of raw text.",0,original
"More recently, Ramshaw & Marcus   apply transformation-based learning   to the problem.",0,original
e collected training samples from the Brown Corpus distributed with the Penn Treebank  ,0,original
Both data were extracted from the Penn Treebank Wall Street Journal   Corpus  .,0,original
3.5 Domain adaptation in Machine Translation Within MT there has been a variety of approaches dealing with domain adaption  .,0,original
"As Carletta   notes, many tasks in computational linguistics are simply more difficult than the content analysis classifications addressed by Krippendorff, and according to Fleiss  , kappa values between .4 and .75 indicate fair to good agreement anyhow.",0,original
"  also uses wide context, but incorporates the one-senseper-discourse and one-sense-per-collocation constraints, using an unsupervised learning technique.",0,original
"Answer Extraction: We select the top 5 ranked sentences and return them as Collins, 1997, can be used to capture the binary dependencies between the head of each phrase.",0,original
"The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For   linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank  , or semantic annotations, such as the one underlying ACE  , are increasingly being used in a quasi standard way.",0,original
"We use the Europarl corpus  , and the statistical word alignment was performed with the GIZA++ toolkit  .1 For the current experiments we assume no preexisting parser for any of the languages, contrary to the information projection scenario.",0,original
he last line shows the results of Ramshaw and Marcus     with the same train/test data,0,original
We also implemented an averaged perceptron system     for comparison.,0,original
  established that it is important to tune    to maximize performance.,0,original
"Finally, the loglikelihood ratios test     is applied on each set of pairs.",0,original
"However, as   do not propose any evaluation of which clustering algorithm should be used, we experiment a set of clustering algorithms and present the comparative results.",0,original
"In this case, one is often required to find the translation  in the hypergraph that are most similar to the desired translations, with similarity computed via some automatic metric such as BLEU  .",0,original
The f-structures are created automatically by annotating nodes in the gold standard WSJ trees with LFG functional equations and then passing these equations through a constraint solver  .,0,original
"In the thriving area of research on automatic analysis and processing of product reviews  , little attention has been paid to the important task studied here  assessing review helpfulness.",0,original
"As pointed out by Johnson  , in effect this expression adds to c a small value that asymptotically approaches  0.5 as c approaches , and 0 as c approaches 0.",0,original
"Pattern-based approaches are known for their high accuracy in recognizing instances of relations if the patterns are carefully chosen, either manually   or via automatic bootstrapping  .",0,original
"It is an implementation of Models 1-4 of Brown et al. \ , where each of these models produces a Viterbi alignment.",0,original
For every class the weights of the active features are combined and the best scoring class is chosen  .,0,original
"3.3 Language Model We estimate P  using n-gram LMs trained on data from the Web, using Stupid Backoff  .",0,original
"For  , the morphemes and labels for our task are:   kita NEG tINC inE1S chabe VT -j SC laj PREP inA1S yol S -j SC iin PRON We also consider POS-tagging for Danish, Dutch, English, and Swedish; the English is from sections 00-05   and 19-21   of the Penn Treebank  , and the other languages are from the CoNLL-X dependency parsing shared task  .1 We split the original training data into training and development sets.",0,original
3 The Learning Architecture The synchronous derivations described above are modelled with an Incremental Sigmoid Belief Network    .,0,original
"Dunning   has called attention to the log-likelihood ratio, G 2, as appropriate for the analysis of such contingency tables, especially when such contingency tables concern very low frequency words.",0,original
"The automatic assessment of the translation quality has been carried out using the BiLingual Evaluation Understudy    , and the Translation Error Rate    .",0,original
The bigram translation probability t2  specifies the likelihood that target word f is to follow f in a phrase generated by source word e. 170 2.1 Properties of the Model and Prior Work The formulation of the WtoP alignment model was motivated by both the HMM word alignment model   and IBM Model-4 with the goal of building on the strengths of each.,0,original
"In general, they can be divided into two major categories, namely lexicalized models   and un-lexicalized models  .",0,original
"Previous workonsentimentanalysishascoveredawiderange of tasks, including polarity classification  , opinion extraction  , and opinion source assignment  .",0,original
The recent emphasis on improving these components of a translation system   is likely due in part to the widespread availability of NLP tools for the language that is most frequently the target: English.,0,original
"3.4 Feature Representation Ranking Models Following previous work on sentiment classi cation  , we represent each review as a vector of lexical features.",0,original
"Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, e.g.,    , or require human-annotated training data with relation information for each domain  .",0,original
"Secondly, while all taggers use lexical information, and, indeed, it is well-known that lexical probabilities are much more revealing than tag sequence probabilities  , most taggers make quite limited use of lexical probabilities  .",0,original
"Dependency representation has been used for language modeling, textual entailment and machine translation  , to name a few tasks.",0,original
8 Related Research Class-based LMs   or factored LMs   are very similar to our T+C scenario.,0,original
"Since this trade-off is also affected by the settings of various pruning parameters, we compared decoding time and translation quality, as measured by BLEU score  , for the two models on our first test set over a broad range of settings for the decoder pruning parameters.",0,original
"Applying the projection WTx   would give us m new features, however, for both computational and statistical reasons   a low-dimensional approximation of the original feature space is computed by applying Singular Value Decomposition   on W  .",0,original
"BLEU For all translation tasks, we report caseinsensitive NIST BLEU scores   using 4 references per sentence.",0,original
"Statistical Phrase-based Translation  : Here phrase-based means subsequence-based, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases.",0,original
t is a variant of the batch-based Bloomier filter LM of Talbot and Brants   which we refer to as the TB-LM henceforth,0,original
":~ The difl'erent kinds of noun chunks covered by our grmnmar are listed below and illustrated with exmnples:  a combination of a non-obligatory deternfiner, optional adjectives or cardinals and the noun 1Other types of lexicalised PCFGs have been  ,  ,  ,  a and .lelinek, 1998) mid  .",0,original
"The parser has been trained, developed and tested on a large collection of syntactically analyzed sentences, the Penn Treebank  .",0,original
We compare our methods with both the averaged perceptron   and conditional random fields   using identical predicate sets.,0,original
These fourteen scores are weighted and linearly combined  ; their respective weights are learned on development data so as to maximize the BLEU score.,0,original
"Since parsing is just an initial stage of natural language understanding, the project was focused not just on obtaining syntactic trees alone   or Tiger  ).",0,original
"We have adopted the evaluation method of Snow et al  : compare the generated hypernyms with hypernyms present in a lexical resource, in our case the Dutch part of EuroWordNet  .",0,original
This criticism leads us to automatic approaches for building thesauri from large corpora \ .,0,original
"Class-based methods   cluster words into classes of similar words, so that one can base the estimate of a word pair's probability on the averaged cooccurrence probability of the classes to which the two words belong.",0,original
distance   and the maximum swap segment size   ranging from 0 to 10 and evaluated the translations with the BLEU7 metric  .,0,original
The reliability for the two annotation tasks  ) was of 0.94 and 0.90 respectively.,0,original
"Deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models  , heuristic-based models   and even for syntactically motivated models such as ITG  .",0,original
"A problem mentioned in   is that the algorithm that computes the compressed representation might need to retain the entire database in memory; in their paper, they design strategies to work around this problem.",0,original
"Grefenstette   studied two context delineation methods of English nouns: the window-based and the syntactic, whereby all the different types of syntactic dependencies of the nouns were used in the same feature space.",0,original
"They use a conditional model, based on Collins  , which, as the authors acknowledge, has a number of theoretical deficiencies; thus the results of Clark et al. provide a useful baseline for the new models presented here.",0,original
3 Stochastic Inversion Transduction Grammars Stochastic Inversion Transduction Grammars     can be viewed as a restricted subset of Stochastic Syntax-Directed Transduction Grammars.,0,original
"2 Related Work There has been extensive research in opinion mining at the document level, for example on product and movie reviews  .",0,original
"The first is to align the words using a standard word alignement technique, such as the Refined Method described in     and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences.",0,original
"1 minority report 2 box office 3 scooby doo 4 sixth sense 5 national guard 6 bourne identity 7 air national guard 8 united states 9 phantom menace 10 special effects 11 hotel room 12 comic book 13 blair witch project 14 short story 15 real life 16 jude law 17 iron giant 18 bin laden 19 black people 20 opening weekend 21 bad guy 22 country bears 23 mans man 24 long time 25 spoiler space 26 empire strikes back 27 top ten 28 politically correct 29 white people 30 tv show 31 bad guys 32 freddie prinze jr 33 monsters ball 34 good thing 35 evil minions 36 big screen 37 political correctness 38 martial arts 39 supreme court 40 beautiful mind Figure 7: Result of re-ranking output from the phrase extension module 6.4 Revisiting unigram informativeness An alternative approach to calculate informativeness from the foreground LM and the background LM is just to take the ratio of likelihood scores, a11 fga9a54a86 a15 a23 a11 bga9a54a86 a15 . This is a smoothed version of relative frequency ratio which is commonly used to find subject-specific terms  .",0,original
SR thus adopts the method proposed by Och  ,0,original
The recall problem is usually addressed by increasing the amount of text data for extraction  ) or by developing more surface patterns  .,0,original
"The group of collocations and compounds should be delimited using statistical approaches, such as Xtract   or LocalMax  , so that only the most relevantthose of higher frequency are included in the database.",0,original
"There has of course been a large amount of work on the more general problem of word-sense disambiguation, e.g.,    .",0,original
"Pereira  , Curran   and Lin   use syntactic features in the vector definition.",0,original
"We report BLEU scores   on untokenized, recapitalized output.",0,original
We use as our English corpus the Wall Street Journal   portion of the Penn Treebank  .,0,original
"Many adaptation methods operate by simple augmentations of the target feature space, as we have donehere .",0,original
"The Xerox experiments   correspond to something between D1 and D2, and between TO and T1, in that there is some initial biasing of the probabilities.",0,original
2 Related Work Two different approaches have been proposed for Sentence Compression: purely statistical methodologies   and hybrid linguistic/statistic methodologies  .,0,original
"Turney   applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification.",0,original
"For example, Och   shows how to train a log-linear translation model not by maximizing the likelihood of training data, but maximizing the BLEU score   of the model on 53 the data.",0,original
"Previous approaches for training CRFs have either   opted for a training method that no longer maximizes the likelihood,  , Roth and Yih  ) 1, or   opted for a 1 Both McCallum and Wellner   and Roth and Yih   used the voted perceptron algorithm   to train intractable CRFs.",0,original
  used transformation based learning using a large annotated corpus for English.,0,original
"In  , different word orderings are taken into account by training alignment models by considering all hypothesis pairs as a parallel corpus using GIZA++  .",0,original
"  In this example, we can see that after compression the lead sentence reads 156 more like a headline.",0,original
"This wrong translation of content words is similar to the incorrect omission reported in  , which both hurt translation adequacy.",0,original
"They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.11 Weighted Fully-Connected F-Measure Given a hypothesized set of alignment links H and a goldstandard set of alignment links G, we define H+ = fullyConnect  and G+ = fullyConnect , and then compute: f-measure  = 1 precision  + 1 recall  For phrase-based Chinese-English and ArabicEnglish translation tasks,   obtain the closest correlation between weighted fully-connected alignment f-measure and BLEU score using =0.5 and =0.1, respectively.",0,original
"Still, it is in our next plans and part of our future work to embed in our model some of the interesting WSD approaches, like knowledgebased  , corpus-based  , or combinations with very high accuracy  .",0,original
e set our space usage to match the 3.08 bytes per n-gram reported in Talbot and Brants   and held out just over 1M unseen n-grams to test the error rates of our models,0,original
hese tables were computed from a small fragment of the Canadian Hansards that has been used in a number of other studies: Church   and Simard et al  ,0,original
"Indeed, only few earlier works reported inter-judge agreement level, and those that did reported rather low Kappa values, such as 0.54   and 0.55 0.63  .",0,original
"Previous uses of this model include language modeling , machine translation , prepositional phrase attachment , and word morphology .",0,original
"To set the weights, m, we performed minimum error rate training   on the development set using Bleu   as the objective function.",0,original
"In most statistical machine translation   models  , some of measure words can be generated without modification or additional processing.",0,original
This kind of synchronizer stands in contrast to more ad-hoc approaches  .,0,original
"5.3 Performance of Taxonomy Induction In this section, we compare the following automatic taxonomy induction systems: HE, the system by Hearst   with 6 hypernym patterns; GI, the system by Girju et al.",0,original
"In the field of parsing, McDonald and Nivre   compared parsing errors between graphbased and transition-based parsers.",0,original
"5.1 Evaluation of Translation Translations are evaluated on two automatic metrics: Bleu   and PER, position independent error-rate  .",0,original
"In parsing, the most relevant previous work is due to Collins  , who considered three binary features of the intervening material: did it contain   any word tokens at all,   any verbs,   any commas or colons?",0,original
"We adopted the chunk representation proposed by Ramshaw and Marcus   and used four different tags: B-NUC and B-SAT for nucleus and satellite-initial tokens, and I-NUC and I-SAT for non-initial tokens, i.e., tokens inside a nucleus and satellite span.",0,original
bney   presented a thorough discussion on the Yarowsky algorithm,0,original
Early examples of this work include  ; more recent models include  .,0,original
We have achieved average results in the CoNLL domain adaptation track open submission  .,0,original
It has also obtained competitive scores on general GR evaluation corpora  .,0,original
"Unlike a full blown machine translation task  , annotators and systems will not be required to translate the whole context but just the target word.",0,original
"4.2 Experiments To build all alignment systems, we start with 5 iterations of Model 1 followed by 4 iterations of HMM  , as implemented in GIZA++  .",0,original
A class of training criteria that provides a tighter connection between the decision rule and the final error metric is known as Minimum Error Rate Training   and has been suggested for SMT in  .,0,original
Of the several slightly different definitions of a base NP in the literature we use for the purposes of this work the definition presented in   and used also by  and others.,0,original
5 Related Work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective  ) and adjacency pair information has been used to predict congressional votes  .,0,original
1 Introduction Recent research on statistical machine translation   has lead to the development of phrasebased systems  .,0,original
"While error-driven training techniques are commonly used to improve the performance of phrasebased translation systems  , this paper presents a novel block sequence translation approach to SMT that is similar to sequential natural language annotation problems 727 such as part-of-speech tagging or shallow parsing, both in modeling and parameter training.",0,original
"scored with lowercased, tokenized NIST BLEU, and exact match METEOR  .",0,original
"The last issue is how our binarization performs on a lexicalized parser, like Collins  .",0,original
"To tune the decoder parameters, we conducted minimum error rate training   with respect to the word BLEU score   using 2.0K development sentence pairs.",0,original
"2.1.3 Correlation analysis As a correlation measure between terms, we use mutual information  .",0,original
"4.3 Corpora The evaluations of the different models were carried out on the Penn Wall Street Journal corpus   for English, and the Tiger treebank   for German.",0,original
"We rerank derivations with cube growing, a lazy beam search algorithm  .",0,original
"4 Semantic Class Induction from Wikipedia Wikipedia has recently been used as a knowledge source for various language processing tasks, including taxonomy construction  , coreference resolution  , and English NER  , Cucerzan  , Kazama and Torisawa  , Watanabe et al.",0,original
This helps solve the sparse data problem since the number of classes is usually much smaller than the number of words.,0,original
More rare words rather than common words are found even in standard dictionaries  .,0,original
e propose a method similar to Yarowsky   to generalize beyond the training set,0,original
"In paraphrase generation, a text unit that matches a pattern P can be rewritten using the paraphrase patterns of P. Avarietyofmethodshavebeenproposedonparaphrase patterns extraction  .",0,original
"This incremental process can be iterated to the point that the system 1 It is not just a matter of time, but also of required linguistic skills  ).",0,original
"Wed like to learn the number of paradigm classes from the data, but doing this would probably require extending adaptor grammars to incorporate the kind of adaptive statesplitting found in the iHMM and iPCFG  .",0,original
The tree is produced by a state-of-the-art dependency parser   trained on the Wall Street Journal Penn Treebank  .,0,original
We train our feature weights using max-BLEU   and decode with a CKY-based decoder that supports language model scoring directly integrated into the search.,0,original
"We use the log-likelihood X ~ statistic, rather than the Pearson's X 2 statistic, as this is thought to be more appropriate when the counts in the contingency table are low  .",0,original
"The simplest one is the BIO representation scheme  , where a B denotes the first item of an element and an I any non-initial item, and a syllable with tag O is not a part of any element.",0,original
"However, the aforementioned SDT techniques require word classes  to help prevent data fragmentation, and a sophisticated smoothing algorithm to mitigate the effects of any fragmentation that occurs.",0,original
"A Broad-Coverage Word Sense Tagger Dekang Lin Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada R3T 2N2 lindek@cs.umanitoba.ca Previous corpus-based Word Sense Disambiguation   algorithms   determine the meanings of polysemous words by exploiting their local contexts.",0,original
Another current topic of machine translation is automatic evaluation of MT quality  .,0,original
"Our story makes use of a weighted formalism known as quasi-synchronous grammar  , originally developed by D. Smith and Eisner   for machine translation.",0,original
"Following the framework of global linear models in  , we cast this task as learning a mapping F from input verses x  X to a text-reuse hypothesis y  Y  {epsilon1}.",0,original
Automatically creating or extending taxonomies for specific domains is then a very interesting area of research  .,0,original
illmann and Zhang   describe a perceptron style algorithm for training millions of features,0,original
"In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney  , could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space.",0,original
"As mentioned earlier, both of these methods are based on Collinss averaged-perceptron algorithm for sequence labeling  .",0,original
"There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number  , or contextual role-knowledge  .",0,original
"If the alignments are not available, they can be automatically generated; e.g., using GIZA++  .",0,original
"Since so many concepts used in discourse are $q'aindependent, a theory of granularity is also fundamental  .",0,original
"The features used are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in  ; phrase translation model probabilities; and 4-gram language model probabilities logp , using Kneser-Ney smoothing as implemented in the SRILM toolkit  .",0,original
Mathematical details are fully described in  .,0,original
REALM uses an HMM trained on a large corpus to help determine whether the arguments of a candidate relation are of the appropriate type  .,0,original
"In a test set of 756 utterances containing 26 repairs  , they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a precision rate of 62%.",0,original
"For each word in the LDV, we consulted three existing thesauri: Rogets Thesaurus  , Collins COBUILD Thesaurus  , and WordNet  .",0,original
"In our search procedure, we use a mixture-based alignment model that slightly differs from the model introduced as Model 2 in  .",0,original
"In contrast, semi-supervised domain adaptation   is the scenario in which, in addition to the labeled source data, we only have unlabeled and no labeled target domain data.",0,original
"The word-based edit distance heuristic yields pairs that are relatively clean but offer relatively minor rewrites in generation, especially when compared to the MSA model of  .",0,original
"In the following experiments, we run two machine learning classifiers: Bayes Point Machines    , and the maximum entropy model    .",0,original
The maximum entropy classier   used is Le Zhang's Maximum Entropy Modeling Toolkit and the L-BFGS parameter estimation algorithm with gaussian prior smoothing  .,0,original
The model scaling factors M1 are trained on a development corpus according to the final recognition quality measured by the word error rate   .,0,original
"Lastly, collocations are domain-dependent   and language-dependent.",0,original
The parser is coupled with an on-line averaged perceptron   as the learning method.,0,original
"Furthermore, recent studies revealed that word clustering is useful for semi-supervised learning in NLP  .",0,original
This alignment representation is a generalization of the baseline alignments described in   and allows for many-to-many alignments.,0,original
"Uses for k-best lists include minimum Bayes risk decoding  , discriminative reranking  , and discriminative training  .",0,original
"In the usual case considered by Dunning   and discussed by Manning and Sch utze  , the right-hand side of the equation is larger than the left-hand side.",0,original
This is in contrast to standard summarization models that look to promote sentence diversity in order to cover as many important topics as possible  .,0,original
"4.2 Data The data comes from the CoNLL 2000 shared task  , which consists of sentences from the Penn Treebank Wall Street Journal corpus  .",0,original
"The result in Wu   implies that for the special case of Bracketing ITGs, the time complexity of the algorithm is parenleftbigT3V 3parenrightbig where T and V are the lengths of the two sentences.",0,original
"3.1 Results for English We used sections 0 to 12 of the WSJ part of the Penn Treebank   with a total of 24,618 sentences for our experiments.",0,original
We use evaluations similar to those used before  .,0,original
"The block set is generated using a phrase-pair selection algorithm similar to  , which includes some heuristic filtering to mal statement here.",0,original
"A possible solution to his problem might be the use of more general morphological rules like those used in part-of-speech tagging models  ), where all suffixes up to a certain length are included.",0,original
"Some stem from work on graphical models,includingloopybeliefpropagation , Gibbs sampling  , sequential Monte Carlo methods such as particle filtering  , and variational inference  .",0,original
"In comparison, most corpus-based algorithms employ substantially larger corpora  , 2.5 million words  , 6 million words  , 13 million words  ).",0,original
"While the need for annotation by multiple raters has been well established in NLP tasks  , most previous work in error detection has surprisingly relied on only one rater to either create an annotated corpus of learner errors, or to check the systems output.",0,original
"The algorithms were trained and tested using version 3 of the Penn Treebank, using the training, development, and test split described in Collins   and also employed by Toutanova et al.",0,original
"Next, we learn our polarity classifier using positive and negative reviews taken from two movie 611 review datasets, one assembled by Pang and Lee   and the other by ourselves.",0,original
"Three K-means algorithms using different distributional similarity or dissimilarity measures: cosine, -skew divergence   4 , and Lins similarity  .",0,original
"In this paper, sentence pairs are extracted by a simple model that is based on the so-called IBM Model1  .",0,original
"However, feature/class functions are traditionally deflned as binary  ; hence, explicitly incorporating frequencies would require difierent functions for each count  , making training impractical.",0,original
"The models in the comparative study by Klein and Manning   did not include such features, and so, again for consistency of comparison, we experimentally verified that our maximum entropy model   consistently yielded higher scores than when the features were not used, and   consistently yielded higher scores than nave Bayes using the same features, in agreement with Klein and Manning  .",0,original
Both calculate the precision of a translation by comparing it to a reference translation and incorporating a length penalty  .],0,original
"We use the averaged perceptron algorithm, as presented in Collins  , to train the parser.",0,original
This second source of evidence is sometimes referred to as distributional similarity  .,0,original
The weights for the various components of the model   are set by minimum error rate training  .,0,original
.1 Likelihood Ratios in the Type-based Stage The log-likelihood ratio by Dunning   tests whether the probability of a word is dependent on the occurrence of the preceding word type,0,original
"The row labelled Precision shows the precision of the extracted information   estimated by random sampling and manual evaluation of 1% of the data for each table, similar to  .",0,original
Performance of Alternative Models 157 5 Related Work Previous parsing models   maximize the joint probability P  of a sentence S and its parse tree T. We maximize the conditional probability P .,0,original
6 Discourse Context   pointed out that the sense of a target word is highly consistent within any given document  .,0,original
"We estimated the probabilities P  and P  similarly to Resnik   by using relative frequencies from the BNC, together with WordNet   as a source of taxonomic semantic class information.",0,original
Other systems   also look at Web product reviews but they do not extract 345 opinions about particular product features.,0,original
"The other is the self-training   which first parses and reranks the NANC corpus, and then use them as additional training data to retrain the model.",0,original
"Furthermore, WASP1++ employs minimum error rate training   to directly optimize the evaluation metrics.",0,original
High quality word alignments can yield more accurate phrase-pairs which improve quality of a phrase-based SMT system  .,0,original
"Moreover, the inference procedure for each sentence pair is non-trivial, proving NP-complete for learning phrase based models   or a high order polynomial  )1 for a sub-class of weighted synchronous context free grammars  .",0,original
Our conception of the task is inspired by Ramshaw and Marcus representation of text chunking as a tagging problem   . The information that can be used to train the system appears in columns 1 to 8 of Table 1.,0,original
The reader is referred to   for detailed information about phrase-based statistical machine translation.,0,original
"  that draws on a stochastic tagger   for details) as well as the SPECIALIST Lexicon5, a large syntactic lexicon of both general and medical English that is distributed with the UMLS.",0,original
"There are many POS taggers developed using different techniques for many major languages such as transformation-based error-driven learning  , decision trees  , Markov model  , maximum entropy methods   etc for English.",0,original
"Online baselines include Top-1 Perceptron  , Top-1 Passive-Aggressive  , and k-best PA  .",0,original
6.1 Evaluation of Translation Performance We use the BLEU score   to evaluate our systems.,0,original
"To avoid this problem, we adopt cross-validation training as used in Collins  .",0,original
"One can imagine the same techniques coupled with more informative probability distributions, such as lexicalized PCFGs  , or even grammars not based upon literal rules, but probability distributions that describe how rules are built up from smaller components  .",0,original
"While recent proposals for evaluation of MT systems have involved multi-parallel corpora  , statistical MT algorithms typically only use one-parallel data.",0,original
"3 Hebrew Simple NP Chunks The standard definition of English base-NPs is any noun phrase that does not contain another noun phrase, with possessives treated as a special case, viewing the possessive marker as the first word of a new base-NP  .",0,original
"Most current approaches emphasize within-sentence dependencies such as the distortion in  , the dependency of alignment in HMM  , and syntax mappings in  .",0,original
urney   used a corpus-based algorithm,0,original
After each step the annotations were compared using the ~ statistic as reliability measure for all classification tasks  .,0,original
" ), in which translation and language models are trainable separately too.",0,original
In line with the reports in   we do observe the performance improvement against the baseline   for all the domains.,0,original
"The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in  ; phrase translation model probabilities; and 4-gram language model probabilities logp , using Kneser-Ney smoothing as implemented in the SRILM toolkit.",0,original
"In this work, we employ a syntax-based model that applies a series of tree/string   rules   to a source language string to produce a target language phrase structure tree.",0,original
"3 Experimental Results and Discussion We test our parsing models on the CONLL-2007   data set on various languages including Arabic, Basque, Catalan, Chinese, English, Italian, Hungarian, and Turkish.",0,original
7 Related Work There has been a recent interest in training methods that enable the use of first-order features  .,0,original
"The resolution of alignment can vat3, from low to high: section, paragraph, sentence, phrase, and word  .",0,original
This tolerant search uses the well known concept of Levenshtein distance in order to obtain the most similar string for the given prefix   for more details).,0,original
"This is one manifestation of what is commonly referred to as the data sparseness problem, and was discussed by Rapp   as a side-effect of specificity.",0,original
"1 Introduction Word alignment, which can be defined as an object for indicating the corresponding words in a parallel text, was first introduced as an intermediate result of statistical translation models  .",0,original
"For instance, BLEU and ROUGE   are based on n-gram precisions, METEOR   and STM   use word-class or structural information, Kauchak   leverages on paraphrases, and TER   uses edit-distances.",0,original
"There are several distance measures suitable for this purpose, such as the mutual information , the dice coefficient , the phi coefficient , the cosine measure  and the confidence .",0,original
"Accordingly, in this section we describe a set of experiments which extends the work of   by evaluating the Marker-based EBMT system of   against a phrase-based SMT system built using the following components:  Giza++, to extract the word-level correspondences;  The Giza++ word alignments are then refined and used to extract phrasal alignments  ; or   for a more recent implementation);  Probabilities of the extracted phrases are calculated from relative frequencies;  The resulting phrase translation table is passed to the Pharaoh phrase-based SMT decoder which along with SRI language modelling toolkit5 performs translation.",0,original
The highest BLEU score   was chosen as the optimization criterion.,0,original
"Despite the above differences, since the theorems of convergence and their proof   are only dependent on the feature vectors, and not on the source of the feature definitions, the perceptron algorithm is applicable to the training of our CWS model.",0,original
"These findings are somehow surprising since it was eventually believed by the community that adding large amounts of bitexts should improve the translation model, as it is usually observed for the language model  .",0,original
A more recent bootstrapping approach is described in  .,0,original
A large corpus is vahmble as a source of such nouns  .,0,original
"Machine translation has code-like characteristics, and indeed, the initial models of   took a word-substitution/transposition approach, trained on a parallel text.",0,original
The results are comparable to other results reported using the Inside/Outside method   (see Table 7.,0,original
"Also, we chose to average each individual perceptron   prior to Bayesian averaging.",0,original
"Corpora in various languages, such as the English Penn Treebank corpus  , the Swedish Stockholm-Ume corpus  , and the Icelandic Frequency Dictionary   corpus  , have been used to train   and develop   different taggers, and to evaluate their accuracy, e.g.",0,original
"Candidate translations are scored by a linear combination of models, weighted according to Minimum Error Rate Training or MERT  .",0,original
Mostcommonlyvariational   or sampling techniques are applied  .,0,original
"The POS data set and the CTS data set have previously been used for testing other adaptation methods  , though the setup there is different from ours.",0,original
"Proceedings of the 40th Annual Meeting of the Association for In a key step for locating important sentences, NeATS computes the likelihood ratio    to identify key concepts in unigrams, bigrams, and trigrams1, using the ontopic document collection as the relevant set and the off-topic document collection as the irrelevant set.",0,original
"Most related to our approach, Wu   used inversion transduction grammarsa synchronous context-free formalism  for this task.",0,original
"After the parser produces a semantic feature structure representation of the sentence, predicate mapping rules then match against that representation in order to produce a predicate language representation in the style of Davidsonian event based semantics  , as mentioned above.",0,original
"This set of context vectors is then clustered into a predetermined number of coherent clusters or context groups using Buckshot  , a combination of the EM algorithm and agglomerative clustering.",0,original
"This approach builds a subjectivity-annotated corpus for the target language through projection, and then trains a statistical classifier on the resulting corpus  ).",0,original
"Previous approaches include supervised learning  ,  , vectorial similarity computed between an initial abstract and sentences in the given document, intradocument similarities  , or graph algorithms  ,  ,  .",0,original
"Like the data used by Ramshaw and Marcus  , this data was retagged by the Brill tagger in order to obtain realistic part-of speech   tags 5.",0,original
"These findings are in line with Collins & Roarks   results with incremental parsing with perceptrons, where it is suggested that a generative baseline feature provides the perceptron algorithm with a much better starting point for learning.",0,original
"The per-state models in this paper are log-linear models, building upon the models in   and  , though some models are in fact strictly simpler.",0,original
"We computed precision, recall and error rate on the entire set of sentence pairs for each data set.5 To evaluate NeurAlign, we used GIZA++ in both directions   or Spanish  ) as input and a refined alignment approach   that uses a heuristic combination method called grow-diagfinal   for comparison.",0,original
"1 Word associations   have a wide range of applications including: speech recognition, optical character recognition, and information retrieval    .",0,original
Research in the field of unsupervised and weakly supervised parsing ranges from various forms of EM training   over bootstrapping approaches like selftraining   to feature-based enhancements of discriminative reranking models   and the application of semisupervised SVMs  .,0,original
  observe that their predominant sense method is not performing as well for 3We use the Lesk   similarity as implemented by the WordNet::similarity package  .,0,original
"Ultinmtely, however, it seems that a more complex ai)t)roach incorporating back-off and smoothing is necessary ill order to achieve the parsing accuracy achieved by Charniak   and Collins  .",0,original
"Examples of such affinities include synonyms  , verb similarities   and word associations  .",0,original
"Therefore, the base forms have been introduced manually and the POS tags have been provided partly manually and partly automatically using a statistical maximum-entropy based POS tagger similar to the one described in  .",0,original
"To this end we follow the method introduced by  , i.e. by sliding a window of a given size over some texts.",0,original
"For example, since the Collins parser depends on a prior part-of-speech tagger  , we included the time for POS tagging in our Collins measurements.",0,original
"Haghighi and Klein   develop a prototype-driven approach, which requires just a few prototype examples for each POS tag and exploits these labeled words to constrain the labels of their distributionally similar words.",0,original
"Second, we follow Snow et al.s work   on taxonomy induction in incorporating transitive closure constraints in our probability calculations, as explained below.",0,original
"Many methods have been proposed to compute distributional similarity between words, e.g.,  ,  ,   and  .",0,original
"  Hindi is a verb final, flexible word order language and therefore, has frequent occurrences of non-projectivity in its dependency structures.",0,original
.2 Inversion Transduction Grammar Wu  s inversion transduction grammar   is a synchronous grammar formalism in which derivations of sentence pairs correspond to alignments,0,original
"First, we adopt an ONTOLOGICALLY PROMISCUOUS representation   that includes a wide variety of types of entities.",0,original
"5 Discussion As stated above, we aim to build an unsupervised generative model for named entity clustering, since such a model could be integrated with unsupervised coreference models like Haghighi and Klein   for joint inference.",0,original
"These range from twoword to multi-word, with or without syntactic structure  .",0,original
"3 Formulation Following Klein and Manning  , we use weighted directed hypergraphs   as an abstraction of the probabilistic parsing problem.",0,original
4.1 Applications to phrase-based SMT Aphrase-basedtranslationmodelcanbeestimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted  .,0,original
"Turney   is the first, to the best of our knowledge, to raise the issue of a unified approach.",0,original
One possible strategy is to exploit a widecoverage realizer that aims for applicability in multiple application domains  .,0,original
Previous publications on Meteor   have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics.,0,original
More details about the re-ranking algorithm are presented in  .,0,original
Talbot and Brants   show that Bloomier filters   can be used to create perfect hash functions for language models.,0,original
Neither   with 67% nor   with 59% noun attachment were anywhere close to this figure.,0,original
"In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology  .",0,original
"However, to be more expressive and flexible, it is often easier to start with a general SCFG or tree-transducer  .",0,original
"As a result, we can use collocation measures like point-wise mutual information   or the log-likelihood ratio   to predict the strong association for a given cue.",0,original
"For all non-LEAF systems, we take the best performing of the union, refined and intersection symmetrization heuristics   to combine the 1-to-N and M-to-1 directions resulting in a M-to-N alignment.",0,original
"Alternatively, order is modelled in terms of movement of automatically induced hierarchical structure of sentences  .",0,original
"The de-facto answer came during the 1990s from the research community on Statistical Machine Translation, who made use of statistical tools based on a noisy channel model originally developed for speech recognition  .",0,original
8.1 The Averaged Perceptron Algorithm with Separating Plane The averaged perceptron algorithm   has previously been applied to various NLP tasks   for discriminative reranking.,0,original
"2 Bidirectional Dependency Networks When building probabilistic models for tag sequences, we often decompose the global probability of sequences using a directed graphical model   or a conditional Markov model    ).",0,original
The recurrence property had been utilized to extract keywords or key-phrases from text  .,0,original
"As other researchers pursued efficient default unification  , we also propose another definition of default unification, which we call lenient default unification.",0,original
"Multiple translations of the same text  , corresponding articles from multiple news sources  , and bilingual corpus   have been utilized.",0,original
nd Semantic Knowledge Sources for Coreference Resolution Ponzetto & Strube   and Strube & Ponzetto   aimed at showing that the encyclopedia that anyone can edit can be indeed used as a semantic resource for research in NLP,0,original
"Sometimes, the notion of collocation is defined in terms of syntax   or in terms of semantics    .",0,original
"In the multilingual parsing track, participants train dependency parsers using treebanks provided for ten languages: Arabic  , Basque  , Catalan  , Chinese  , Czech  , English  , Greek  , Hungarian  , Italian  , and Turkish  .",0,original
"Therefore, we also carried out evaluations using the NIST  , METEOR  , WER  , PER   and TER   machine translation evaluation techniques.",0,original
Statistics on co-occurrence of words in a local context were used recently for monolingual word sense disambiguation    .,0,original
aume III   further augments the feature space on the instances of both domains,0,original
.1 NP Our NP chunks are very similar to the ones of Ramshaw and Marcus  ,0,original
The feature weights are tuned using minimum error rate training   to optimize BLEU score on a held-out development set.,0,original
Movie and product reviews have been the main focus of many of the recent studies in this area  .,0,original
arowsky   presented an approach that significantly reduces the amount of labeled data needed for word sense disambiguation,0,original
"According to the document, it is the output of Ratnaparkhis tagger  .",0,original
Alignment is often used in training both generative and discriminative models  .,0,original
This has been now an active research area for a couple of decades  .,0,original
We were given around 15K sentences of labeled text from the Wall Street Journal     as well as 200K unlabeled sentences.,0,original
"The importance of including single nonheadwords is now also uncontroversial  , and the current paper has shown the importance of including two and more nonheadwords.",0,original
in   proposed a word similarity measure based on the distributio nal pattern of words which allows to construct a thesaurus using a parsed corpus,0,original
1999) O:98.1% C:98.2% 92.4% 93.1% Ramshaw and Marcus   IOB1:97.37% 91.80% 92.27% Argamon et al,0,original
Parameters were tuned with minimum error-rate training   on the NIST evaluation set of 2006   for both C-E and A-E.,0,original
There are many choices for modeling co-occurrence data  .,0,original
"During evaluation two performance metrics, BLEU   and NIST, were computed.",0,original
in   defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept,0,original
  looked at Golomb Coding and Brants et al,0,original
The PT grammar 2 was extracted from the Penn Treebank  .,0,original
hang and Clark     generated CTB 3.0 from CTB 4.0,0,original
"Finally, Zhang and Clark   achieve an SF of 95.90% and a TF of 91.34% by 10-fold cross validation using CTB data.",0,original
The translation quality is evaluated by case-sensitive NIST   and BLEU  2.,0,original
"The NIST MT03 set is used to tune model weights  ) and the scaling factor 17We have also experimented with MERT  , and found that the deterministic annealing gave results that were more consistent across runs and often better.",0,original
"SMT Team   also used minimum error training as in Och  , but used a large number of feature functions.",0,original
he principal training method is an adaptation of averaged perceptron learning as described by Collins  ,0,original
3.3 Language Model   As a second baseline we use the classification based on the language model using overlapping ngram sequences   as suggested by Pang & Lee   for the English language.,0,original
"Such transformations are typically denoted as paraphrases in the literature, where a wealth of methods for their automatic acquisition were proposed  .",0,original
In the last few years there has been an increasing interest in applying MaxEnt models for NLP applications  .,0,original
The model scaling factors M1 are optimized with respect to the BLEU score as described in  .,0,original
ntroduction Automatic word alignment   is a vital component of all statistical machine translation   approaches,0,original
"However, we do not rely on linguistic resources   or on search engines   to determine the semantic orientation, but rather rely on econometrics for this task.",0,original
"There are other approaches in which the generation grammars are extracted semiautomatically   or automatically  , LFG   and CCG  ).",0,original
"Inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection  , text summarization  , word sense disambiguation  , sentiment analysis  , and sentence retrieval for question answering  .",0,original
mith and Eisner   apply entropy regularization to dependency parsing,0,original
Our baseline uses Giza++ alignments   symmetrized with the grow-diag-final-and heuristic  .,0,original
It is also possible to train statistical models using unlabeled data with the expectation maximization algorithm  .,0,original
"Indeed, our methods were inspired by past work on variational decoding for DOP   and for latent-variable parsing  .",0,original
"The set of such ITG alignments,AITG, are a strict subset of A1-1  .",0,original
"5 Conclusions and Future Work The results of the evaluation are exlremely encouraging, especially considering that disambiguating word senses to the level of fine-grainedness found in WordNet is quite a bit more difficult than disambiguation to the level of homographs  .",0,original
"Hence our classifier evaluation omits those two word positions, leading to n2 classifications for a string of length n. Table 1 shows statistics from sections 2-21 of the Penn WSJ Treebank  .",0,original
he use of such relations   for various purposes has received growing attention in recent research  ,0,original
The starting point is the log likelihood ratio  .,0,original
"2 Statistical Word Alignment Model According to the IBM models  , the statistical word alignment model can be generally represented as in equation  .",0,original
4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework  .,0,original
"Uses Maximum Entropy   classification, trained on JNLPBA    .",0,original
"We use three different kinds of metrics: DR-STM Semantic Tree Matching, a la Liu and Gildea  , but over DRS instead of over constituency trees.",0,original
"In our experiments, we used a dependency parser only in English   that has been adapted for building dependencies) but not in the other language.",0,original
"For instance, some approaches coarsely discriminate between biographical and non-biographical information  ,whileothersgobeyondbinary distinction by identifying atomic events  e.g., occupation and marital status  that are typically included in a biography  .",0,original
"As shown by McDonald and Nivre  , the Single Malt parser tends to suffer from two problems: error propagation due to the deterministic parsing strategy, typicallyaffectinglongdependenciesmorethan short ones, and low precision on dependencies originating in the artificial root node due to fragmented parses.9 The question is which of these problems is alleviatedbythemultipleviewsgivenbythecomponent parsers in the Blended system.",0,original
This amounts to performing binary text categorization under categories Objective and Subjective  ; 2.,0,original
.1 Background Smith and Eisner   introduced the quasisynchronous grammar formalism,0,original
"In addition to individual seed words, Kanayama and Nasukawa   used more complicated syntactic patterns that were manually created.",0,original
EMD training   combines generative and discriminative elements.,0,original
"2  also presents the method using the averaged perceptron   3For re-ranking problems, Shen and Joshi   proposed a perceptron algorithm that also uses margins.",0,original
"These methods are based on IBM statistical translation Model 2  , but take advantage of certain characteristics of the segments of text that can typically be extracted from translation memories.",0,original
"To obtain their corresponding weights, we adapted the minimum-error-rate training algorithm   to train the outside-layer model.",0,original
"For Penn Treebank II style annotation  , in which a nonterminal symbol is a category together with zero or more functional tags, we adopt the following scheme: the atomic pattern a matches any label with category a or functional tag a; moreover, we define Boolean operators^,_, and:.",0,original
any 412 Turney Similarity of Semantic Relations researchers have argued that metaphor is the heart of human thinking  ,0,original
"Its applications range from sentence boundary disambiguation   to part-of-speech tagging  , parsing   and machine translation  .",0,original
"Decoding weights are optimized using Ochs algorithm   to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature.",0,original
"  and Pang and Lee   in merely using binary unigram features, corresponding to the 17,744 unstemmed word or punctuation types with count  4 in the full 2000-document corpus.",0,original
"We use data from the CoNLL-2004 shared taskthe PropBank   annotations of the Penn Treebank  , with sections 1518 as the training set and section 20 as the development set.",0,original
The Log-Likelihood-Ratio Association Measure We base all our association-based word-alignment methods on the log-likelihood-ratio   statistic introduced to the NLP community by Dunning  ,0,original
The noun phrase chunking   module uses the basic NP chunker software from 483   to recognize the noun phrases in the question.,0,original
"3 Margin Perceptron Algorithm for Sequence Labeling Weextendedaperceptronwithamargin  to sequence labeling in this study, as Collins   extended the perceptron algorithm to sequence labeling.",0,original
"context-free rules Charniak   Collins  , Eisner   context-free rules, headwords Charniak   context-free rules, headwords, grandparent nodes Collins   context-free rules, headwords, grandparent nodes/rules, bigrams, two-level rules, two-level bigrams, nonheadwords Bod   all fragments within parse trees Scope of Statistical Dependencies Model Figure 4.",0,original
"For a sequential learning algorithm, we make use of the Collins Perceptron Learner  .",0,original
"The WSJNPVP set consists of part-of speech tagged Wall Street Journal material  , supplemented with syntactic tags indicating noun phrase and verb phrase boundaries  .",0,original
The huge increase in computational and storage cost of including longer phrases does not provide a signi cant improvement in quality   as the probability of reappearance of larger phrases decreases.,0,original
The component features are weighted to minimize a translation error criterion on a development set  .,0,original
"4.1.3 Letter Lexical Transliteration Similar to IBM Model-1  , we use a bag-of-letter generative model within a block to approximate the lexical transliteration equivalence: P = j+lproductdisplay jprime=j i+ksummationdisplay iprime=i P P ,   where P  similarequal 1/  is approximated by a bagof-word unigram.",0,original
"Thus, we used the five taggers, MBL  , MXPOST  , fnTBL  , TnT, and IceTagger3, in the same manner as described in  , but with the following minor changes.",0,original
"A pipage approach   has been proposed for MCKP, but we do not use this algorithm, since it requires costly partial enumeration and solutions to many linear relaxation problems.",0,original
2 We used the Collins parser   to generate the constituency parse and a dependency converter   to obtain the dependency parse of English sentences.,0,original
A number of other re532 searchers   have described previous work on preprocessing methods.,0,original
"First, splitting and merging of sentences  , which seems related to content planning and aggregation.",0,original
"Some of the differences between our approach and those of Turney   are mentioned below: ??objectives: Turney   aims at binary text classification, while our objective is six class classification of one-liner headlines.",0,original
Such a technique has been used with TER to combine the output of multiple translation systems  .,0,original
The probabilities of derivation decisions are modelled using the neural network approximation   to a type of dynamic Bayesian Network called an Incremental Sigmoid Belief Network    .,0,original
"Additionally, some research has explored cutting and pasting segments of text from the full document to generate a summary  .",0,original
"These wordbased models are used to find the latent wordalignments between bilingual sentence pairs, from which a weighted string transducer can be induced   or synchronous context free grammar  ).",0,original
"Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by Riezler and Maxwell  .",0,original
"In previous research on splitting sentences, many methods have been based on word-sequence characteristics like N-gram  .",0,original
"In the BB.N model, as with Model 2 of  , modifying nonterminals are generated conditioning both on the parent P and its head child H. Unlike Model 2 of  , they are also generated conditioning on the previously generated modifying nonterminal, L/-1 or Pq-1, and there is no subcat frame or distance feature.",0,original
ustejovsky confronted with the problem of automatic acquisition more extensively in \ ,0,original
The original IBM Models   learn word-to-word alignment probabilities which makes it computationally feasible to estimate model parameters from large amounts of training data.,0,original
"Second, we will discuss the work done by   who use clustering of paraphrases to induce rewriting rules.",0,original
"4.1 Data Preparation NP chunking results have been reported on two slightly different data sets: the original RM data set of Ramshaw and Marcus  , and the modi ed CoNLL-2000 version of Tjong Kim Sang and Buchholz  .",0,original
"We have implemented a parallel version of our GIS code using the MPICH library  , an open-source implementation of the Message Passing Interface   standard.",0,original
"Och   introduced minimum error rate training  , a technique for optimizing log-linear modelparametersrelativetoameasureoftranslation quality.",0,original
"In this paper, Stanford Named Entity Recognizer   is used to classify noun phrases into four semantic categories: PERSON, LOCATION, ORGANIZARION and MISC.",0,original
"Wordalignment, however, isalmost exclusively done using statistics  .",0,original
We perform minimum-error-rate training   to tune the feature weights of the translation model to maximize the BLEU score on development set.,0,original
he weights of these models are determined using the max-BLEU method described in Och  ,0,original
"This is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in Collins  , using the same data splits, and a larger error reduction of 12.1% from the more similar best previous loglinear model in Toutanova and Manning  .",0,original
"In contrast, the latter computes four definite probabilities  which are included as features within a machine-learning classifier  from the Web in an attempt to overcome Bean and Riloffs   data sparseness problem.",0,original
his model is very similar to the markovized rule models in Collins  ,0,original
or colnparison~ we refer here to Smadja's method   because this method and the proposed method have much in connnon,0,original
"The model is composed of three parts  : a set of candidate SAPTs GEN, which is the top n SAPTs of a sentence from SCISSOR; a function  that maps a sentence Inputs: A set of training examples  , i = 1n, where xi is a sentence, and yi is a candidate SAPT that has the highest similarity score with the gold-standard SAPT Initialization: Set W = 0 Algorithm: For t = 1T,i = 1n Calculate yi = argmaxyGEN     W If   then W = W +     Output: The parameter vector W Figure 2: The perceptron training algorithm.",0,original
6.4 Feature Selection Methods A number of previous papers   describe feature selection approaches for log-linear models applied to NLP problems.,0,original
It has been further observed that simply compressing sentences individually and concatenating the results leads to suboptimal summaries  .,0,original
"According to this model, when translating a stringf in the source language into the target language, a string e is chosen out of all target language strings e if it has the maximal probability given f  : e = arg maxe {Pr } = arg maxe {Pr Pr } where Pr  is the translation model and Pr  is the target language model.",0,original
"When updating model parameters, we employ a memorizationvariant of a local updating strategy   in which parameters are optimized toward a set of good translations found in the k-best list across iterations.",0,original
"what does student want to write your Figure 3: A derivation tree of lexicalized parse trees, such as the distinction of arguments/modifiers and unbounded dependencies  , are elegantly represented in derivation trees.",0,original
Parse each sentence using a Treebank-trained parser  .,0,original
"For the first set of experiments, we divide all inputs based on the mean value of the average system scores as in  .",0,original
"Previous approaches, e.g.,   and  , have all used the Brown algorithm for clustering  .",0,original
"This can either be semi-supervised parsing, using both annotated and unannotated data   or unsupervised parsing, training entirely on unannotated text.",0,original
"Recently, in the area of parsers based oll a. stochastic context-fi:ee grammar  , some researchers have pointed out the importance of t.he lexicon and proposed lexiealized models  .",0,original
Such coarse-grained inventories can be produced manually from scratch   or by automatically relating   or clustering   existing word senses.,0,original
We run the decoder with its default settings and then use Koehn's implementation of minimum error rate training   to tune the feature weights on the development set.,0,original
ilingual Bracketing   is one of the bilingual shallow parsing approaches studied for Chinese-English word alignment,0,original
The HWC metrics compare dependency and constituency trees for both reference and machine translations  .,0,original
"This set of words   corresponds to the   Characterize  , Declare  , Admire  , and Judgment verbs   and hence may have particular syntactic and semantic patterning.",0,original
The PropBank superimposes an annotation of semantic predicate-argument structures on top of the Penn Treebank    .,0,original
"The agreement on identifying the boundaries of units, using the  statistic discussed in  , was  =.9  ; the agreement on features   was as follows: UTYPE: =.76; VERBED: =.9; FINITE: =.81.",0,original
SMT has evolved from the original word-based approach   into phrase-based approaches   and syntax-based approaches  .,0,original
"4.5 Consistency of Annotations In order to assess the consistency of annotation, we follow Carletta   in using Cohen's ~, a chancecorrected measure of inter-rater agreement.",0,original
"The hierarchical phrase translation pairs are extracted in a standard way  : First, the bilingual data are word alignment annotated by running GIZA++   in two directions.",0,original
"Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases  .",0,original
"In fact, we found that it doesnt do so badly at all: the bitag HMM estimated by EM achieves a mean 1-to1 tagging accuracy of 40%, which is approximately the same as the 41.3% reported by   for their sophisticated MRF model.",0,original
5.1 Experimental setup The baseline model was Hiero with the following baseline features  :  two language models  phrase translation probabilities p  and p   lexical weighting in both directions    word penalty  penalties for:  automatically extracted rules  identity rules    two classes of number/name translation rules  glue rules The probability features are base-100 logprobabilities.,0,original
his algorithm can thus be viewed as a large-margin version of the perceptron algorithm for structured outputs Collins  ,0,original
The phrases in the translations were located using standard phrase extraction techniques  .,0,original
The weights are trained using minimum error rate training   with BLEU score as the objective function.,0,original
"We use the union, re ned and intersection heuristics de ned in   which are used in conjunction with IBM Model 4 as the baseline in virtually all recent work on word alignment.",0,original
"All 8,907 articles were tagged by the Xerox Part-ofSpeech Tagger   4.",0,original
Consider the following example  : This film should be brilliant.,0,original
"5.2 Pseudo-Disambiguation Task Pseudo-disambiguation tasks have become a standard evaluation technique   and, in the current setting, we may use a nouns neighbors to decide which of two co-occurrences is the most likely.",0,original
Evaluating the algorithm on the output of Charniaks parser   and the Penn treebank   shows that the patternmatching algorithm does surprisingly well on the most frequently occuring types of empty nodes given its simplicity.,0,original
"2.2 Implementation of GIZA++ GIZA++ is an implementation of ML estimators for several statistical alignment models, including IBM Model 1 through 5  , HMM   and Model 6  .",0,original
"Syntax based statistical MT approaches began with  , who introduced a polynomial-time solution for the alignment problem based on synchronous binary trees.",0,original
"Both the global models   use fairly small training sets, and there is no evidence that their techniques will scale to larger data sets.",0,original
"3 The Effect of Training Corpus Size A number of past research work on WSD, such as  , were tested on a small number of words like """"line"""" and """"interest"""".",0,original
The published F score for voted perceptron is 93.53% with a different feature set  .,0,original
"Similarly,   propose a relative distortion model to be used with a phrase decoder.",0,original
albot and Brants   used a Bloomier filter to encode a LM,0,original
"We trained IBM Translation Model 4   both on our corpus alone and on the augmented corpus, using the EGYPT toolkit  , and then translated a number of texts using different translation models and different transfer methods, namely glossing   and Model 4 decoding  .",0,original
"It has been difficult to identify all and only those cases where a token functions as a discourse connective, and in many cases, the syntactic analysis in the Penn TreeBank   provides no help.",0,original
"There are good reasons for using such a hand-crafted, genre-specific verb lexicon instead of a general resource such as WordNet or Levins   classes: Many verbs used in the domain of scientific argumentation have assumed a specialized meaning, which our lexicon readily encodes.",0,original
"The heuristic estimator employs word-alignment     and a few thumb rules for defining phrase pairs, and then extracts a multi-set of phrase pairs and estimates their conditional probabilities based on the counts in the multi-set.",0,original
"POS tagger: The maximum entropy POS tagger developed by Ratnaparkhi   and the rule-based POS tagger developed by Brill   are trained with 1200 abstracts extracted from the GENIA corpus, which achieve accuracies of 97.97% and 98.06% respectively, when testing on the rest 800 abstract of the GENIA corpus.",0,original
"Moreover, for reasons discussed by Wu  , ITGs possess an interesting intrinsic combinatorial property of permitting roughly up to four arguments of any frame to be transposed freely, but not more.",0,original
In this years shared task we evaluated a number of different automatic metrics:  Bleu  Bleu remains the de facto standard in machine translation evaluation.,0,original
1 Introduction Word alignment is an important step of most modern approaches to statistical machine translation  .,0,original
The evaluation metric is case-sensitive BLEU-4  .,0,original
"The overall POS tag distribution learnt by EM is relatively uniform, as noted by Johnson  , and it tends to assign equal number of tokens to each tag label whereas the real tag distribution is highly skewed.",0,original
"Given a sentence-pair  , the most likely   word alignment is found as  : a = argmaxa P .",0,original
The wn::similarity package   to compute the Jiang&Conrath   distance   as in  .,0,original
"Table 2 shows the unknown word tags for chunking, which are known as the IOB2 model  .",0,original
"When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfitting on the training set  .",0,original
Our appoach is based on Maximum Entropy   technique  .,0,original
hese include the bootstrapping approach   and the context clustering approach  ,0,original
"The approach is in the spirit of Smadja   on retrieving collocations from text corpora, but is more integrated with parsing.",0,original
"The other main difference is the apparently nonlocal nature of the problem, which motivates our choice of a Maximum Entropy   model for the tagging task  .",0,original
The final model V uses the weight vector w = summationtextk j=1  Tn  .,0,original
"Introduction Since Eric Brill first introduced the method of Transformation-Based Learning   it has been used to learn rules for many natural language processing tasks, such as part-of-speech tagging \ .",0,original
"The sentences included in the gold standard were chosen at random from the BNC, subject to the condition that they contain a verb which does not occur in the training sections of the WSJ section of the PTB  .",0,original
The models are trained using the Margin Infused Relaxed Algorithm or MIRA   instead of the standard minimum-error-rate training or MERT algorithm  .,0,original
Our results on Chinese data confirm previous findings on English data shown in  .,0,original
"In training process, we use GIZA++ 4 toolkit for word alignment in both translation directions, and apply grow-diag-final method to refine it  .",0,original
"The reason may be that shorter dependencies are often modifier of nouns such as determiners or adjectives or pronouns modifying their direct neighbors, while longer dependencies typically represent modifiers of the root or the main verb in a sentence .",0,original
"1 Specifically, MIMIC uses an n-dimensional call router front-end  , which is a generalization of the vector-based call-routing paradigm of semantic interpretation  ; that is, instead of detecting one concept per utterance, MIMIC's semantic interpretation engine detects multiple   concepts or classes conveyed by a single utterance, by using n call touters in parallel.",0,original
We compute log-likelihood significance between features and target nouns  ) and keep only the most significant 200 features per target word.,0,original
"Dependency Treebank  , and in Figure 2, for an English sentence taken from the Penn Treebank  .",0,original
"In the tagging domain, Collins   compared log-linear and perceptron training for HMM-style tagging based on dynamic programming.",0,original
The training data is aligned using the LEAF technique  .,0,original
We used the preprocessed data to train the phrase-based translation model by using GIZA++   and the Pharaoh tool kit  .,0,original
lmost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging  ,0,original
"1 Motivation Question Answering has emerged as a key area in natural language processing   to apply question parsing, information extraction, summarization, and language generation techniques  .",0,original
"This finding has been previously reported, among others, in Liu and Gildea  .",0,original
"3 Previous Work on Subjectivity Tagging In previous work  , a corpus of sentences from the Wall Street Journal Treebank Corpus   was manually annotated with subjectivity classi cations bymultiplejudges.",0,original
urney   describes a method of sentiment classification using two human-selected seed words   in conjunction with a very large text corpus; the semantic orientation of phrases is computed as their association with the seed words  ,0,original
"Work in this area includes that of Lin and Hovy   and Pastra and Saggion  , both of whom inspect the use of Bleu-like metrics   in summarization.",0,original
"They roughly fall into three categories according to what is used for supervision in learning process:   using external resources, e.g., thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus,  ,   exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora    ,   bootstrapping sensetagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data  .",0,original
We demonstrate that allowing different values for these hyperparameters significantly improves performance over both a strong baseline and   within both a conditional random field sequence model for named entity recognition and a discriminatively trained dependency parser.,0,original
"These rules can be learned from a parallel corpus using English parsetrees, Chinese strings, and word alignment  .",0,original
"Table 2: Corpora and Modalities CORPUS MODALITY ACE asserted, or other TIMEML must, may, should, would, or could Prasad et al., 2006 assertion, belief, facts or eventualities Saur et al., 2007 certain, probable, possible, or other Inui et al., 2008 affirm, infer, doubt, hear, intend, ask, recommend, hypothesize, or other THIS STUDY S/O, necessity, hope, possible, recommend, intend   Table 3: Markup Scheme   Tag Definition   R Remedy, Medical operation   T Medical test, Medical examination   D Deasese, Symptom   M Medication, administration of a drug   A patient action   V Other verb     2 Related Works 2.1 Previous Markup Schemes In the NLP field, fact identification has not been studied well to date.",0,original
"For example, in John saw Mary yesterday at the station, only John and Mary are required arguments while the other constituents are optional  .3 The problem of SF identification using statistical methods has had a rich discussion in the literature    ).",0,original
2004) use an information extraction engine to extract linguistic features from documents relevant to the target term,0,original
"Additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential CRF; in contrast, approaches like Gibbs Sampling that model the dependencies directly can increase inference time by a factor of 30  .",0,original
"c2007 Association for Computational Linguistics Structural Correspondence Learning for Dependency Parsing Nobuyuki Shimizu Information Technology Center University of Tokyo Tokyo, Japan shimizu@r.dl.itc.u-tokyo.ac.jp Hiroshi Nakagawa Information Technology Center University of Tokyo Tokyo, Japan nakagawa@dl.itc.u-tokyo.ac.jp Abstract Following  , we present an application of structural correspondence learning to non-projective dependency parsing  .",0,original
Collocation: Collocations were extracted from a seven million word sample of the Longman English Language Corpus using the association ratio   and outputted to a lexicon.,0,original
This approach is also used in base-NP chunking   and named entity recognition   as well as word segmentation.,0,original
"However for remedy, many of the current word alignment methods combine the results of both alignment directions, via intersection or 249 grow-diag-final heuristic, to improve the alignment reliability  .",0,original
"Therefore, whenever we have access to a large amount of labeled data from some source  , but we would like a model that performs well on some new target domain  , we face the problem of domain adaptation.",0,original
"To model p , we use a standard loglinear approach: p   exp bracketleftBiggsummationdisplay i ifi  bracketrightBigg where each fi  is a feature function, and weights i are set using Ochs algorithm   to maximize the systems BLEU score   on a development corpus.",0,original
"The table also shows the -score, which is another commonly used measure for inter-annotator agreement  .",0,original
"Alignment, whether for training a translation model using EM or for nding the Viterbi alignment of test data, is O   , while translation   is O  using a bigram language model, and O  with trigrams.",0,original
"Any encoding scheme, such as the packed representation of Talbot and Brants  , is viable here.",0,original
"The bracketed portions of Figure 1, for example, show the base NPs in one sentence from the Penn Treebank Wall Street Journal   corpus  .",0,original
Previous studies called the class of algorithms illustrated in Figure 2 cautious or sequential because in each iteration they acquire 1 or a small set of rules  .,0,original
Task Description 2.1 Data Representation Ramshaw and Marcus   gave mainly two kinds of base NPs representation  the open/close bracketing and IOB tagging,0,original
"For each training data size, we report the size of the resulting language model, the fraction of 5-grams from the test data that is present in the language model, and the BLEU score   obtained by the machine translation system.",0,original
"Table 6 shows 3An exception is Golding  , who uses the entire Brown corpus for training   and 3/4 of the Wall Street Journal corpus   for testing.",0,original
"6 Phrase Recognition with a Maximum Entropy Classifier For the candidates which are not filtered out in the above two phases, we perform classification with maximum entropy classifiers  .",0,original
Introduction Bilingual word alignment is first introduced as an intermediate result in statistical machine translation    ,0,original
"To summarize, we can describe our system as follows: it is based on  s implementation of  , which has been fed at each iteration by a different dataset consisting of the supervised and unsupervised part: precisely, by a concatenation of the manually tagged training data   and a chunk of automatically tagged unsupervised data.",0,original
2 Bilingual Bracketing In     A ! < AA >   A ! f=e   A ! f=null   A ! null=e   Where f and e are words in the target vocabulary Vf and source vocabulary Ve respectively.,0,original
"However, the maximum entropy   was found to yield higher accuracy than nave Bayes in a subsequent comparison by Klein and Manning  , who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data.",0,original
"  makes a similar point, noting that for reviews, \the whole is not necessarily the sum of the parts"""").",0,original
"In  , an undirected graphical model for constituent parse reranking uses dependency relations to define the edges.",0,original
Both systems are built around from the maximum-entropy technique  .,0,original
dditional evidence for this distinction is given in Pustejovsky and Anick   and Briscoe et al,0,original
"3.1 Exhaustive search by tree fragments This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts   of translation rules to extract the useful rules  .",0,original
"We show that the method of  , which was presented as a simple preprocessing step, is actually equivalent, except our representation explicitly separates hyperparameters which were tied in his work.",0,original
We then tagged the search queries using a maximum entropy part-of-speech tagger  .,0,original
"Pooling the sets to form two large CE and AE test sets, the AE system improvements are significant at a 95% level  ; the CE systems are only equivalent.",0,original
Thus we rank each sense wsi WSw using Prevalence Score wsi =    njNw dssnj  wnss  wsiWSw wnss  where the WordNet similarity score   is defined as: wnss = max nsxNSnj  ) 2.2 Building the Thesaurus The thesaurus was acquired using the method described by Lin  .,0,original
"Models of translational equivalence that are ignorant of indirect associations have """"a tendency  to be confused by collocates""""  .",0,original
"Rather than explicit annotation, we could use latent annotations to split the POS tags, similarly to the introduction of latent annotations to PCFG grammars  .",0,original
"We adopt the approach of Marcu and Echihabi  , using a small set of patterns to build relation models, and extend their work by re ning the training and classi cation process using parameter optimization, topic segmentation and syntactic parsing.",0,original
Weights on the loglinear features are set using Och's algorithm   to maximize the system's BLEU score on a development corpus.,0,original
"The upper envelope is a convex hull and can be inscribed with a convex polygon whose edges are the segments of a piecewise linear function in   : EnvD4fD5 AG max eC8C AWa D4e,fD5 A0  A4 bD4e,fD5 :  C8 RB4   726 Score  Error count  0 0 e1 e2 e5 e6 e8 e1e 2 e3 e4 e5e6e 7 e8 Figure 1: The upper envelope   for a set of lines is the convex hull which consists of the topmost line segments.",0,original
"In the work of Smadja   on extracting collocations, preference was given to constructions whose constituents appear in a fixed order, a similar   version of our assumption here that asymmetric constructions are more idiomatic than symmetric ones.",0,original
"We can find some other machine-learning approaches that use more sophisticated LMs, such as Decision Trees   , memory-based approaclms to learn special decision trees  , maximmn entropy approaches that combine statistical information from different sources  , finite state autonmt2 inferred using Grammatical Inference  , etc. The comparison among different al)t)roaches is dif ficult due to the nmltiple factors that can be eonsid614 ered: tile languagK, tile mmfl)er and tyt)e of the tags, the size of tilt vocabulary, thK ambiguity, the diiticulty of the test ski, Kte.",0,original
"Thus, conventional methods had to introduce some kinds of restrictions such as the limitation of the kind of chains or the length of chains to be extracted  .",0,original
"  and Lee  ) can be generally divided into three types: discounting  , class-based smoothing  , and distance-weighted averaging  .",0,original
An example set of tags can be found in the Penn Treebank project  .,0,original
"From   9 Combined metric BY BP B4AC BE B7BDB5C8CABPB4AC BE C8 B7 CAB5, from  , AC BPBD.",0,original
"Further, it has been shown   that performance of Lins distributional similarity score decreases more significantly than other measures for low frequency nouns.",0,original
"The model can be seen as a bootstrapping learning process tbr disambiguation, where the information gained from one part   is used to improve tile other   and vice versa, reminiscent of the work by Riloff and Jones   and Yarowsky  .",0,original
We assign tags of part-of-speech   to the words with MXPOST that adopts the Penn Treebank tag set  .,0,original
We prepare the corpus by passing it through Adwait Ratnaparkhis part-of-speech tagger     and then running Steve Abneys chunker   over the entire text.,0,original
"The results have demonstrated the existence of priming effects in corpus data: they occur for specific syntactic constructions  , consistent with the experimental literature, but also generalize to syntactic rules across the board, which repeated more often than expected by chance  .",0,original
"A key example is that of class-based language models   where clustering approaches are used in order to partition words, determined to be similar, into sets.",0,original
Learning We model the problem of selecting the best derivation as a structured prediction problem  .,0,original
The named-entity features are generated by the freely available Stanford NER tagger  .,0,original
Correlation Coefficient with Human Judgement   Human-Likeness Classifier Accuracy   Figure 1: This scatter plot compares classifiers accuracy with their corresponding metrics correlations with human assessments been previously observed by Liu and Gildea  ,0,original
"Because of this, Wu   and Zens and Ney   introduced a normal form ITG which avoids this over-counting.",0,original
"Snow etal   use known hypernym/hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns.",0,original
3 Bilingual Task: An Application for Word Alignment 3.1 Sentence and word alignment Bilingual alignment methods  .,0,original
"7Following Carletta  , we measure agreement in Kappa, which follows the formula K = P P 1P  where P  is observed, and P  expected agreement.",0,original
"For example it has been used to measure centrality in hyperlinked web pages networks  , lexical networks  , and semantic networks  .",0,original
he patterns will be manually constructed following the approach of Hearst   and Nakov and Hearst  .6 The example collection for each relation R will be passed to two independent annotators,0,original
Much previous work on unsupervised grammar induction has used gold-standard partof-speech tags  .,0,original
2008a; 2008b) on CTB 5.0 and Zhang and Clark   on CTB 4.0 since they reported the best performances on joint word segmentation and POS tagging using the training materials only derived from the corpora,0,original
The f are trained using a held-out corpus using maximum BLEU training  .,0,original
6.1.1 Nugget-Based Pyramid Evaluation For our first approach we used a nugget-based evaluation methodology  .,0,original
Our statistical tagging model is adjusted from standard bi-grams using the Viterbi-search   plus on-the-fly extra computing of lexical probabilities for unknown morphemes.,0,original
The annotation can be considered reliable   with 95% agreement and a kappa   of.88.,0,original
"Before parsing, POS tags are assigned to the input sentence using our reimplementation of the POStagger from Collins  .",0,original
3.1 The Corpus The systems are applied to examples from the Penn Treebank   a corpus of over 4.5 million words of American English annotated with both part-of-speech and syntactic tree information.,0,original
Its previous applications   demonstrated that cooccurrence statistics on a target word is often sufficient for its automatical classification into one of numerous classes such as synsets of WordNet.,0,original
Previous studies   defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model  .,0,original
everal artificial techniques have been used so that classifiers can be developed and tested without having to invest in manually tagging the data: Yarowsky   and Sch/itze   have acquired training and testing materials by creating pseudowords from existing nonhomographic forms,0,original
"Similarly,   and   learn sentence level paraphrase templates from a corpus of news articles stemming from different news source.",0,original
e measured associations using the log-likelihood measure   for each combination of target category and semantic class by converting each cell of the contingency into a 22 contingency table,0,original
iezler and Maxwell   describe a method for learning a probabilistic model that maps LFG parse structures in German into LFG parse structures in English,0,original
"Because of its central role in building machine translation systems and because of the complexity of the task, sub-sentential alignment of parallel corpora continues to be an active area of research  , and this implies a continuing demand for manually created or human-verified gold standard alignments for development and evaluation purposes.",0,original
1 Introduction Conditional Maximum Entropy   modeling has received a great amount of attention within natural language processing community for the past decade  .,0,original
t also has close links with theoretical work in situation semantics  ,0,original
The score combination weights are trained by a minimum error rate training procedure similar to  .,0,original
"We used a maximummatching algorithm and a dictionary compiled from the CTB   to do segmentation, and trained a maximum entropy part-ofspeech tagger   and TAG-based parser   on the CTB to do tagging and parsing.4 Then the same feature extraction and model-training was done for the PDN corpus as for the CTB.",0,original
"Disambiguation of a limited number of words is not hard, and necessary context information can be carefully collected and hand-crafted to achieve high disambiguation accuracy as shown in  .",0,original
"There are studies on learning subjective language  , identifying opinionated documents   and sentences  , and discriminating between positive and negative language  .",0,original
"The most relevant to our work are Kazama and Torisawa  , Toral and Muoz  , and Cucerzan  .",0,original
"1510 5 Related Work In recent years, many research has been done on extracting relations from free text  ); however, almost all of them require some language-dependent parsers or taggers for English, which restrict the language of their extractions to English only  .",0,original
We distinguish two main approaches to domain adaptation that have been addressed in the literature  : supervised and semi-supervised.,0,original
"Shen et al.,   report an accuracy of 97.33% on the same data set using a perceptron-based bidirectional tagging model.",0,original
All reviews were automatically preprocessed to remove both explicit rating indicators and objective sentences; the motivation for the latter step is that it has previously aided positive vs. negative classi cation  .,0,original
e used the Ramshaw and Marcus   representation as well  ,0,original
"109 machine translation evaluation  ,paraphraserecognition  , and automatic grading  .",0,original
This procedure uses the head finding rules of  .,0,original
"The reader is referred to   and   for details of MI clustering, but we will first briefly summarize the MI clustering and then describe our hierarchical clustering algorithm.",0,original
"1 Introduction The importance of learning to manipulate monolingual paraphrase relationships for applications like summarization, search, and dialog has been highlighted by a number of recent efforts  .",0,original
"Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals  , or, given a constraining parse tree, to flatten it  .",0,original
"In previous work  , we developed an unsupervised learning algorithm that automatically recognizes definite NPs that are existential without syntactic modification because their meaning is universally understood.",0,original
"For this we aligned 170,863 pairs of Arabic/English newswire sentences from LDC, trained a state-of-the-art syntax-based statistical machine translation system   on these sentences and alignments, and measured BLEU scores   on a separate set of 1298 newswire test sentences.",0,original
To regularize the model we take as the final model the average of all weight vectors posited during training  .,0,original
n alternative representation for baseNPs has been put tbrward by Ramshaw and Marcus  ,0,original
We measure translation performance by the BLEU score   and Translation Error Rate     with one reference for each hypothesis.,0,original
"Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase    .",0,original
This text was part-of-speech tagged using the Xerox HMM tagger  .,0,original
"Moses provides BLEU   and NIST  , but Meteor   and TER   can easily be used instead.",0,original
"The data used for all our experiments is extracted from the PENN"""" WSJ Treebank   by the program provided by Sabine Buchholz from Tilbug University.",0,original
"Yarowsky  , Mihalcea and Moldovan  , and Mihalcea   have made further research to obtain large corpus of higher quality from an initial seed corpus.",0,original
1 Introduction Supervised statistical parsers attempt to capture patterns of syntactic structure from a labeled set of examples for the purpose of annotating new sentences with their structure  .,0,original
"Alternatively, one can train them with respect to the final translation quality measured by some error criterion  .",0,original
"To address this issue, many syntax-based approaches   tend to integrate more syntactic information to enhance the non-contiguous phrase modeling.",0,original
"In order to estimate the conditional distributions shown in Table 1, we use the general technique of choosing the MaxEnt distribution that properly estimates the average of each feature over the training data  .",0,original
Our evaluation metric is BLEU   with caseinsensitive matching from unigram to four-gram.,0,original
"Computing the phrase translation probability is trivial in the training corpora, but lexical weighting   needs lexical-level alignment.",0,original
The notation will assume ChineseEnglish word alignment and ChineseEnglish MT. Here we adopt a notation similar to  .,0,original
4 Experiments Our experiments were conducted on CoNLL-2007 shared task domain adaptation track   using treebanks  .,0,original
"Agreement is sometimes measured as percentage of the cases on which the annotators agree, but more often expected agreement is taken into account in using the kappa statistic  , which is given by:  = po  pe1  p e   where po is the observed proportion of agreement and pe is the proportion of agreement expected by chance.",0,original
"corpora and corpus query tools has been particularly significant in the area of compiling and developing lexicographic materials   and in the area of creating various kinds of lexical resources, such as WordNet   and FrameNet  .",0,original
We tested the techniques described above with the previous Bakeoffs data5  .,0,original
"We then compute the weight of a context word w in context c, W , using mutual information and t-test, which were reported by Weeds and Weir   to perform the best on a pseudo-disambiguation task.",0,original
"Consequently, we abstract away from specifying a distribution by allowing the user to assign labels to features   , Druck et al.",0,original
We measure semantic similarity using the shortest path length in WordNet   as implemented in the WordNet Similarity package  .,0,original
"Precursors to this work include  ,  ,  ,  , and   and, as applied to child language acquisition,  .",0,original
"2 Previous Work Other researchers have investigated the topic of automatic generation of abstracts, but the focus has been different, e.g., sentence extraction  , processing of structured templates  , sentence compression  , and generation of abstracts from multiple sources  .",0,original
"Therefore, estimating a natural language model based on the maximum entropy   method   has been highlighted recently.",0,original
" , or in more recent implementation, the MOSES MT system1  .",0,original
"The NP chunks in the shared task data are base-NP chunks  which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus  .",0,original
"272 Similarity-based estimation was first used for language modeling in the cooccurrence smoothing method of Essen and Steinbiss  , derived from work on acoustic model smoothing by Sugawara et al.",0,original
"In this framework, the source language, let-s say English, is assumed to be generated by a noisy probabilistic source.1 Most of the current statistical MT systems treat this source as a sequence of words  .",0,original
Feature weights vector are trained discriminatively in concert with the language model weight to maximize the BLEU   automatic evaluation metric via Minimum Error Rate Training    .,0,original
Most of researchers focus on how to extract useful textual features   for determining the semantic orientation of the sentences using machine learning algorithm  .,0,original
"Tagging can also be done using maximum entropy modeling  : a maximum entropy tagger, called MXPOST, was developed by Ratnaparkhi    .",0,original
ntroduction The automated analysis of large corpora has many useful applications  ,0,original
Inversion Transduction Grammar     and Syntax-Directed Translation Schema     lack both of these properties.,0,original
"In order to be able to compare the edit distance with the other metrics, we have used the following formula whichnormalisesthe minimum edit distance by the length of the longest questionand transformsit into a similaritymetric: normalisededitdistance = 1 edit dist max  Word Ngram Overlap This metric compares the word n-gramsin both questions: ngramoverlap = 1N Nsummationdisplay n=1 | Gn   Gn  | min  |,| Gn  |) where Gn  is the set of n-grams of length n in question q and N usually equals 4  .",0,original
"4.2 Translation Results The evaluation metrics used in our experiments are WER  , PER   and BLEU    .",0,original
The detailed algorithm can be found in  .,0,original
"Several teams had approaches that relied   on an IBM model of statistical machine translation  , with different improvements brought by different teams, consisting of new submodels, improvements in the HMM model, model combination for optimal alignment, etc. Se-veral teams used symmetrization metrics, as introduced in    , most of the times applied on the alignments produced for the two directions sourcetarget and targetsource, but also as a way to combine different word alignment systems.",0,original
"It seems nevertheless that all 2Church and Hanks  , Smadja   use statistics in their algorithms to extract collocations from texts.",0,original
The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1   with an additional trigger.,0,original
"Since this relation can often be determined automatically for a given text  , we can readily use it to improve rank prediction.",0,original
"While we can only compare class models with word models on the largest training set, for this training set model M outperforms the baseline Katzsmoothed word trigram model by 1.9% absolute.6 4 Domain Adaptation In this section, we introduce another heuristic for improving exponential models and show how this heuristic can be used to motivate a regularized version of minimum discrimination information   models  .",0,original
Our corpora were automatically aligned with Giza++   in both directions between source and target and symmetrised using the intersection heuristic  .,0,original
"Our approach to inducing syntactic clusters is closely related to that described in Brown, et al,   which is one of the earliest papers on the subject.",0,original
"Setting the gradient to zero yields the usual maximum entropy constraints  , except that in this case the empirical values are themselves expectations  .",0,original
Feature function scaling factors m are optimized based on a maximum likely approach   or on a direct error minimization approach  .,0,original
"For evaluation, we use IBMs BLEU score   to measure the performance of the SMS normalization.",0,original
  proposes two approximate models based on the variational approach.,0,original
"We also test our language model using leave-one-out cross-validation on the Penn Treebank    , giving us 86.74% accuracy  .",0,original
HockenmaierandSteedman showedthat a CCG corpus could be created by adapting the Penn Treebank  .,0,original
Pivots are features occurring frequently and behaving similarly in both domains  .,0,original
"For instance, we may find metrics based on full constituent parsing  , and on dependency parsing  .",0,original
"Some adopt a pipeline approach  , which works by first extracting candidate affixes and stems, and then segmenting the words based on the candidates.",0,original
"1 Introduction Conditional Maximum Entropy models have been used for a variety of natural language tasks, including Language Modeling  , partof-speech tagging, prepositional phrase attachment, and parsing  , word selection for machine translation  , and finding sentence boundaries  .",0,original
"Roget's has been used as the sense division in two recent WSD works   more or less as is, except for a small number of senses added to fill gaps.",0,original
We use these tuples to calculate a balanced f-score against the gold alignment tuples.4 Method Dict size f-score Gold 28 100.0 Monotone 39 68.9 IBM-1   30 80.3 IBM-4   29 86.9 IP 28 95.9 The last line shows an average f-score over the 8 tied IP solutions.,0,original
We determined appropriate training parameters and network size based on intermediate validation 1We used a publicly available tagger   to provide the tags.,0,original
"SCL for Discriminative Parse Selection So far, pivot features on the word level were used  .",0,original
"In a next step, chunk information was added by a rule-based language-independent chunker   that contains distituency rules, which implies that chunk boundaries are added between two PoS codes that cannot occur in the same constituent.",0,original
"82 Chen and Chang Topical Clustering Dolan   maintains the position that intersense relations are mostly idiosyncratical, thereby making it difficult to characterize them in a general way so as to identify them.",0,original
"3.2 Domain Adaptation Track As mentioned previously, the source data is drawn from a corpus of news, specifically the Wall Street Journal section of the Penn Treebank  .",0,original
"3 The M&E Framework We model two RSRs, Cause and Contrast, adopting the de nitions of Marcu and Echihabi     for their Cause-ExplanationEvidence and Contrast relations, respectively.",0,original
he above observations can be stated formally from the perspective of Brown et al.'s   Model 2,0,original
"In our experiments, we will use 4 different kinds of feature combinations: a157 Baseline: The 6 baseline features used in  , such as cost of word penalty, cost of aligned template penalty.",0,original
"This method uses mutual information and loglikelihood, which Dunning   used to calculate the dependency value between words.",0,original
"220  ; they can overlap.5 Additionally, since phrase features can be any function of words and alignments, we permit features that consider phrase pairs in which a target word outside the target phrase aligns to a source word inside the source phrase, as well as phrase pairs with gaps  .",0,original
"  2.3 Reliability To evaluate the reliability of the annotation, we use the kappa coe cient    , which measures pairwise agreement between a set of coders making category judgements, correcting for expected chance agreement.",0,original
"This paper continues a line of research on online discriminative training  , extending that of Watanabe et al.",0,original
ollins and Roark   present an incremental perceptron algorithm for parsing that uses early update to update the parameters when an error is encountered,0,original
"A Greek model was trained on 440,082 aligned sentences of Europarl v.3, tuned with Minimum Error Training  .",0,original
The pchemtb-closed shared task   is used to illustrate our models.,0,original
"In summary, the strength of our approach is to exploit extremely precise structural clues, and to use 5 Semantic Orientation in  .",0,original
A summary of the differences between our proposed approach and that of   would include:  The reliance of BLEU on the diversity of multiple reference translations in order to capture some of the acceptable alternatives in both word choice and word ordering that we have shown above.,0,original
The weights for these models are determined using the method described in  .,0,original
production rules are typically learned from alignment structures   or from alignment structures and derivation trees for the source string  .,0,original
"The table also shows Cohen's to, an agreement measure that corrects for chance agreement  ; the most important t value in the table is the value of 0.7 for the two human judges, which can be interpreted as sufficiently high to indicate that the task is reasonably well defined.",0,original
"2 Evaluating Heterogeneous Parser Output Two commonly reported shallow parsing tasks are Noun-Phrase   Chunking   and the CoNLL-2000 Chunking task  , which extends the NPChunking task to recognition of 11 phrase types1 annotated in the Penn Treebank.",0,original
"  So far, none of the studies in sentiment detection   or opinion extraction   have specifically looked at the role of superlatives in these areas.",0,original
"We use binary Synchronous ContextFree Grammar  , based on Inversion Transduction Grammar    , to define the set of eligible segmentations for an aligned sentence pair.",0,original
"We show that link 1For a complete discussion of alignment symmetrization heuristics, including union, intersection, and refined, refer to  .",0,original
"Previous studies have shed light on the predictability of the next unix command that a user will enter  , the next keystrokes on a small input device such as a PDA  , and of the translation that a human translator will choose for a given foreign sentence  .",0,original
"We use the likelihood ratio for a binomial distribution  , which tests the hypothesis whether the term occurs independently in texts of biographical nature given a large corpus of biographical and non-biographical texts.",0,original
"We parsed the TimeEval data using MSTParser v0.2  , which is trained with all Penn Treebank   without dependency label.",0,original
"In particular, ROUGE-2 is the recall in bigrams with a set of human-written abstractive summaries  .",0,original
3 Method 3.1 Standard text classication approach We take our starting point from topic-based text classication   and sentiment classication  .,0,original
"For example, minimum entropy regularization  , aims to maximize the conditional likelihood of labeled data while minimizing the conditional entropy of unlabeled data: summationdisplay i logp |x ) 122bardblbardbl2H    This approach generally would result in sharper models which can be data-sensitive in practice.",0,original
"Many 649 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include Lee  , Curran   and Weeds and Weir  .",0,original
Previous SMT systems   used a word-based translation model which assumes that a sentence can be translated into other languages by translating each word into one or more words in the target language.,0,original
"As the baseline standard, we took the ending-guessing rule set supplied with the Xerox tagger  .",0,original
Examples include Wus   ITG and Chiangs hierarchical models  .,0,original
We follow IBM Model 1   and assume that each word in an utterance is generated by exactly one role in the parallel frame Using standard EM to learn the role to word mapping is only sufficient if one knows to which level in the tree the utterance should be mapped.,0,original
"In our experiments, we used the full parse output from Collins parser  , in which every non-terminal node is already annotated with head information.",0,original
"Following  , we do not distinguish rare words.",0,original
Our methods are most influenced by IBMs Model 1  .,0,original
"Sometimes, due to data sparseness and/or limitations in the machine learning paradigm used, we need to extract features from the available representation in a manner that profoundly changes the representation  ).",0,original
"Since it is not feasible to maximise the likelihood of the observations directly, we maximise the expected log likelihood by considering the EM auxiliary function, in a similar manner to that used for modelling contextual variations of phones for ASR  .",0,original
  also worked on one of our data sets.,0,original
"240 2 Motivation Many approaches to identifying base noun phrases have been explored as part of chunking  , but determining sub-NP structure is rarely addressed.",0,original
"In fact, a limitation of the experiments described in this paper is that the loglinear weights for the glass-box techniques were optimized for BLEU using Ochs algorithm  , while the linear weights for 55 black-box techniques were set heuristically.",0,original
In most recent parsing work the history consists of a small number of manually selected features  .,0,original
Other similar work includes the mention detection   task   and joint probabilistic model of coreference  .,0,original
4 The Dependency Labeler 4.1 Classifier We used a maximum entropy classifier   to assign labels to the unlabeled dependencies produced by the Bayes Point Machine.,0,original
"RIDF is like MI, but different References Church, K. and P. Hanks  Word association norms, mutual information, and lexicography Computational Linguistics, 16:1, pp.",0,original
"Dagan, Church, and Gale   expanded on this idea by replacing Brown et al.'s   word alignment parameters, which were based on absolute word positions in aligned segments, with a much smaller set of relative offset parameters.",0,original
"Research prototypes exist for applications such as personal email and calendars, travel and restaurant information, and personal banking   inter alia.",0,original
"The current release of PDTB2.0 contains the annotations of 1,808 Wall Street Journal articles   from the Penn TreeBank   II distribution and a total of 40,600 discourse connective tokens  .",0,original
"As a side product, we find empirical evidence to suggest that the effectiveness of rule lexicalization techniques   and parent annotation techniques   is due to the fact that both lead to a reduction in perplexity in the automata induced from training corpora.",0,original
We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy  .,0,original
  introduced a polynomial-time solution for the alignment problem based on synchronous binary trees.,0,original
Our chunks and functions are based on the annotations in the third release of the Penn Treebank  .,0,original
"Atthefinestlevel, thisinvolvesthealignment of words and phrases within two sentences that are known to be translations  .",0,original
"4.1 Variational Bayes Beal   and Johnson   describe variational Bayes for hidden Markov model in detail, which can be directly applied to our bilingual model.",0,original
"They first extract English collocations using the Xtract systetn  , and theu look for French coutlterparts.",0,original
"3.2 Questions and Corpus To get a clear picture of the impact of using different information extraction methods for the offline construction of knowledge bases, similarly to  , we focused only on questions about persons, taken from the TREC8 through TREC 2003 question sets.",0,original
"4.1 Overview In this work, factored models   are experimented with three factors : the surface form, the lemma and the part of speech  .",0,original
The translation model is estimated via the EM algorithm or approximations that are bootstrapped from the previous model in the sequence as introduced in  .,0,original
Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation   and to develop lexical resources from corpora  .,0,original
he work most similar in spirit to ours that of Turney  ,0,original
"In Englishto-German, this result produces results very comparable to a phrasal SMT system   trained on the same data.",0,original
Our learning algorithm stems from Perceptron training in  .,0,original
"This approach was subsequently extended to other languages including German  , Chinese  ,  , Spanish  ,   and French  .",0,original
Decoding used beam search with the cube pruning algorithm  .,0,original
" , Yarowsky  , and Karol & Edelman   where strong reliance on statistical techniques for the calculation of word and context similarity commands large source corpora.",0,original
"However, based on annotation differences in the datasets   and a bug in their system  , their results are inconclusive.1 Thus, the effectiveness of SCL is rather unexplored for parsing.",0,original
We use a standard data set   consisting of sections 15-19 of the WSJ corpus as training and section 20 as testing.,0,original
"Preparing an aligned abbreviation corpus, we obtain the optimal combination of the features by using the maximum entropy framework  .",0,original
iebe   uses Lin   style distributionally similar adjectives in a cluster-and-label process to generate sentiment lexicon of adjectives,0,original
"Independently, in artificial intelligence an effort arose to encode large amounts of commonsense knowledge  .",0,original
C function is a derivative of Fano's mutual information formula recently used by Church and Hanks   to compute word co-occurrence patterns in a 44 million word corpus of Associated Press news stories,0,original
"The terms graph-based and transition-based were used by McDonald and Nivre   to describe the difference between MSTParser  , which is a graph-based parser with an exhaustive search decoder, and MaltParser  , which is a transition-based parser with a greedy search decoder.",0,original
"We use Entropy Regularization     to leverage unlabeled instances.7 We weight the ER term by choosing the best8 weight in {103,102,101,1,10} multiplied by #labeled#unlabeled for each data set and query selection method.",0,original
Parameter Optimization We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins  ,0,original
"The translation quality is measured by three MT evaluation metrics: TER  , BLEU  , and METEOR  .",0,original
.3 Model Construction The head transducer model was trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus  ,0,original
"According to the statistical machine translation formalism  , the translation process is to search for the best sentence bE such that bE = arg max E P  = arg maxE P P  where P  is a translation model characterizing the correspondence between E and J; P , the English language model probability.",0,original
"Recall that the log likelihood of our model is:  d parenleftBigg Lorig  i  2 2 2d parenrightBigg  i  2 2 2 We now introduce a new variable d = d , and plug it into the equation for log likelihood:  d parenleftBigg Lorig  i  2 2 2d parenrightBigg  i  2 2 2 The result is the model of  , where the d are the domain-specific feature weights, and d are the domain-independent feature weights.",0,original
"Hidden Markov models   are one of the earliest structured learning algorithms, which have recently been followedbydiscriminativelearningapproachessuch as conditional random fields    , the structured perceptron   and its large-margin variants  .",0,original
"Many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of constituents  , leaving it as an open question whether there exist important statistical dependencies that go beyond linguistically motivated dependencies.",0,original
"We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al  , and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision  .",0,original
"We employ the phrase-based SMT framework  , and use the Moses toolkit  , and the SRILM language modelling toolkit  , and evaluate our decoded translations using the BLEU measure  , using a single reference translation.",0,original
Some methods parse two flat strings at once using a bitext grammar  .,0,original
"Building heavily on the ideas of History-based parsing  , training the parser means essentially running the parsing algorithms in a learning mode on the data in order to gather training instances for the memory-based learner.",0,original
"Given a wordq, its set of featuresFq and feature weightswq  for f Fq, a common symmetric similarity measure is Lin similarity  : Lin  = summationtext fFuFv .",0,original
Nonparametricmodels   may be appropriate.,0,original
"For comparison purposes, we consider two different algorithms for our AnswerExtraction module: one that does not bridge the lexical chasm, based on N-gram cooccurrences between the question terms and the answer terms; and one that attempts to bridge the lexical chasm using Statistical Machine Translation inspired techniques   in order to find the best answer for a given question.",0,original
The piecewise linearity observation made in   is no longer applicable since we cannot move the log operation into the expected value.,0,original
Many of the current approaches of domain modeling collapse together different instances and make the decision on what information is important for a domain based on this generalized corpus  .,0,original
We measure this association using pointwise Mutual Information    .,0,original
"For English, we used the Penn Treebank   in our experiments and the tool Penn2Malt7 to convert the data into dependency structures using a standard set of head rules  .",0,original
Relative frequency ratio   of terms between two different corpora can also be used to discover domain-oriented multi-word terms that are characteristic of a corpus when compared with another  .,0,original
"Words are encoded through an automatic clustering algorithm   while tags, labels and extensions are normally encoded using diagonal bits.",0,original
" , it is much higher than the 2.6% unknown word rate in the test set for Ratnaparkhis   English POS tagging experiments.",0,original
he idea of tracing polarity through adjective cooccurrence is adopted by Turney   for the binary   classification of text reviews,0,original
"We were already using a generative statistical model for part-of-speech tagging  , and more recently, had begun using a generative statistical model for name finding  .",0,original
"In addition, Wu   used a stochastic inversion transduction grammar to simultaneously parse the sentence pairs to get the word or phrase alignments.",0,original
Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging \ .,0,original
3.3 Syntax based approach An alternative to the Window and Document-oriented approach is to use syntactical information  .,0,original
"It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation  ,  , (Koehn et al. , 2003, sec.",0,original
"We used GIZA++   to align approximately 751,000 sentences from the German-English portion of the Europarl corpus  , in both the German-to-English and English-to-German directions.",0,original
Both left-corner strategy   and head-corner strategy   were employed in incremental parsing.,0,original
"Also, the aspect of generalizing features across different products is closely related to fully supervised domain adaptation  , and we plan to combine our approach with the idea from Daume III   to gain insights into whether the composite back-off features exhibit different behavior in domain-general versus domain-specific feature sub-spaces.",0,original
"Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation  , synonym extraction  , and automatic thesauri generation  .",0,original
"Using an Maximum Entropy approach to POS tagging, Ratnaparkhi   reports a tagging accuracy of 96.6% on the Wall Street Journal.",0,original
"  describe the voted perceptron applied to the named-entity data in this paper, but using kernel-based features rather than the explicit features described in this paper.",0,original
"Many grammars, such as finite-state grammars  , bracket/inversion transduction grammars    , context-free grammar  , tree substitution grammar     and their synchronous versions, have been explored in SMT.",0,original
"Most current SMT systems   use a generative model for word alignment such as the freely available GIZA++  , an implementation of the IBM alignment models  .",0,original
In our experiments we use standard methods in phrase-based systems   to define the set of phrase entries for each sentence in training data.,0,original
"This merging of contexts is different than clustering words  , but is applicable, as word clustering relies on knowing which contexts identify the same category.",0,original
"Proceedings of EACL '99 Determinants of Adjective-Noun Plausibility Maria Lapata and Scott McDonald and Frank Keller School of Cognitive Science Division of Informatics, University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW, UK {mlap, scottm, keller} @cogsci.ed.ac.uk Abstract This paper explores the determinants of adjective-noun plausibility by using correlation analysis to compare judgements elicited from human subjects with five corpus-based variables: co-occurrence frequency of the adjective-noun pair, noun frequency, conditional probability of the noun given the adjective, the log-likelihood ratio, and Resnik's   selectional association measure.",0,original
We then parse both sides of the corpus with syntactic parsers  .,0,original
"To prune away those pairs, we used the log-likelihood-ratio algorithm   to compute the degree of association between the verb and the noun in each pair.",0,original
"Previous attempts have used, for instance, the similarities between case frames  , anchor words  , and a web-based method .",0,original
"Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases  .",0,original
"PB, available at www.cis.upenn.edu/ace, is used along with the Penn TreeBank 2    .",0,original
"Translation rules can:  look like phrase pairs with syntax decoration: NPB  NNP  NNP  NNP ) BUFDFKEUBWAZ  carry extra contextual constraints: VP  x0:SBAR-C) DKx0    be non-constituent phrases: VP  SBAR-C  x0:S-C)) DKx0 VP  PRT ) x0:SBAR-C) DXGPx0  contain non-contiguous phrases, effectively phrases with holes: PP  NP-C  x0:NNP)) NN ))) GRx0 EVABG6 PP  NP-C  NN ) x0:PP)) GRx0 EVEVABABG6  be purely structural  : S x0 x1  re-order their children: NP-C  x0:NN) PP  x1:NP-C)) x1 DFx0 Decoding with this model produces a tree in the target language, bottom-up, by parsing the foreign string using a CYK parser and a binarized rule set  .",0,original
"It is known that PMI gives undue importance to low frequency events  , therefore the evaluation considers only pairs of genes that occur at least 5 times in the whole corpus.",0,original
"The suffixes C* and V* denote the models using incomplete skip-chain edges and vertical sequential edges proposed in  , as shown in Figures 2  and 2 .",0,original
84 5.2 Machine translation on Europarl corpus We further tested our WDHMM on a phrase-based machine translation system to see whether our improvement on word alignment can also improve MT accuracy measured by BLEU score  .,0,original
"the syntax-based system, we ran a reimplementation of the Collins parser   on the English half of the bitext to produce parse trees, then restructured and relabeled them as described in Section 3.2.",0,original
"For the efficiency of minimum-error-rate training  , we built our development set   using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data.",0,original
"Although ITA rates and system performance both significantly improve with coarse-grained senses  , the question about what level of granularity is needed remains.",0,original
The superiority of discriminative models has been shown on many tasks when the discriminative and generative models use exactly the same model structure  .,0,original
"We extract a phrase table using the Moses pipeline, based on Model 4 word alignments generated from GIZA++  .",0,original
"In the early statistical translation model work at IBM, these representations were called cepts, short for concepts  .",0,original
"This approach will generally take advantage of language-specific  ) and domain-specific knowledge, of any external resources  , and of any information about the entities to process, e.g. their type  , or internal structure  ).",0,original
"Similarly to classical NLP tasks such as base noun phrase chunking  , text chunking   or named entity recognition  , we formulate the mention detection problem as a classification problem, by assigning to each token in the text a label, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.",0,original
"Although a large number of studies have been made on learning paraphrases, for example  , there are only a few studies which address the connotational difference of paraphrases.",0,original
We are also interested in examining the approach within a standard phrase-based decoder such as Moses   or a hierarchical phrase system  .,0,original
"We compare those algorithms to generalized iterative scaling    , non-preconditioned CG, and voted perceptron training  .",0,original
period should therefore be interpreted as an abbreviation marker and not as a sentence boundary marker if the two tokens surrounding it can indeed be considered as a collocation according to Dunnings   original log-likelihood ratio amended with the one-sidedness constraint introduced in Section 2.2,0,original
11 This low agreement ratio is also re ected in a measure called the  statistic  .,0,original
"In addition, their system does not classify non-anaphoric pronouns, A third paper that has significantly influenced our work is that of  .",0,original
"They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers   have used their class scheme and data set.",0,original
"The second baseline is our implementation of the relevant part of the Wikipedia extraction in  , taking the first noun after a be verb in the definition sentence, denoted as WikiBL.",0,original
"The current version of the dataset gives semantic tags for the same sentencesas inthe PennTreebank  , whichareexcerptsfromtheWallStreetJournal.",0,original
"2.2 Brown clustering algorithm In order to provide word clusters for our experiments, we used the Brown clustering algorithm  .",0,original
Recentworkconsidersadamagedtagdictionary by assuming that tags are known only for words that occur more than once or twice  .,0,original
N-gram language models have also been used in Statistical Machine Translation   as proposed by  .,0,original
"The Stanford parser is representative of a large number of PTB parsers, exemplified by Collins   and Charniak  .",0,original
Pure statistical machine translation   mltst in principle recover the most probable alignment out of all possible alignments between the input and a translation.,0,original
imilar adaptations of the Matrix-Tree Theorem have been developed independently and simultaneouslybySmithandSmith andMcDonaldand Satta  ; see Section 5 for more discussion,0,original
achine translation   but also in other applications such as word sense disanabiguation   and bilingnal lexicography  ,0,original
"They are most commonly used for parsing and linguistic analysis  , but are now commonly seen in applications like machine translation   and question answering  .",0,original
"The remaining six entries were all fully automatic machine translation systems; in fact, they were all phrase-based statistical machine translation system that had been trained on the same parallel corpus and most used Bleubased minimum error rate training   to optimize the weights of their log linear models feature functions  .",0,original
Step 2 involves extracting minimal xRS rules   from the set of string/tree/alignments triplets.,0,original
"We compare TERp with BLEU  , METEOR  , and TER  .",0,original
These tasks are generally treated as sequential labeling problems incorporating the IOB tagging scheme  .,0,original
"When we run a phrase-based system, Pharaoh  , on this sentence  , we get the following phrases with translations:     [dipl.",0,original
"1 Introduction During the last decade, statistical machine translation   systems have evolved from the original word-based approach   into phrase-based translation systems  .",0,original
Previous work on POS tagging of unknown words has proposed a number of features based on prefixes and suffixes and spelling cues like capitalization  .,0,original
"A recent trend is to store the LM in a distributed cluster of machines, which are queried via network requests  .",0,original
It has been shown that both Nave Bayes and SVMs perform with similar accuracy on different sentiment tagging tasks  .,0,original
cDonald and Nivre   showed that the MSTParser and MaltParser produce different errors,0,original
"In addition to reducing the original sentences, Jing and McKeown   use a number of manually compiled rules to aggregate reduced sentences; for example, reduced clauses might be conjoined with and.",0,original
"This leads to a good amount of work in this area   In the most basic approach, such as Ratnaparkhi et al.",0,original
"In our decoder, we incorporate two pruning techniques described by  .",0,original
"A simpler, related idea of penalizing distortion from some ideal matching pattern can be found in the statistical translation   and word alignment   models.",0,original
"Far from full syntactic complexity, we suggest to go back to the simpler alignment methods first described by  .",0,original
"One important application of bitext maps is the construction of translation lexicons   and, as discussed, translation lexicons are an important information source for bitext mapping.",0,original
The Duluth Word Alignment System is a Perl implementation of IBM Model 2  .,0,original
"In particular, since we treat each individual speech within a debate as a single document, we are considering a version of document-level sentiment-polarity classification, namely, automatically distinguishing between positive and negative documents  .",0,original
"While we have shown an increase in performance over a purely syntactic baseline model  ), there are a number of avenues to pursue in extending this work.",0,original
6.1.2 ROUGE evaluation Table 4 presents ROUGE scores   of each of human-generated 250-word surveys against each other.,0,original
aghighi and Klein   ask the user to suggest a few prototypes   for each class and use those as features,0,original
"Much of the work in sentiment analysis in the computational linguistics domain has focused either on short segments, such as sentences  , or on longer documents with an explicit polarity orientation like movie or product reviews  .",0,original
We use 3500 sentences from CoNLL   as the NER data and section 20-23 of the WSJ   as the POS/chunk data  .,0,original
"To estimate combination weights, we extend the F 1 -score maximization training algorithm for LRM described in  .",0,original
4 Structural Correspondence Learning SCL     is a recently proposed domain adaptation technique which uses unlabeled data from both source and target domain to learn correspondences between features from different domains.,0,original
he models were originally introduced in Collins  ; the current article 1 gives considerably more detail about the models and discusses them in greater depth,0,original
"2.2 Automatic evaluation metric Since the official evaluation criterion for WMT09 is human sentence ranking, we chose to minimize a linear combination of two common evaluation metrics, BLEU and TER  , during system development and tuning: TERBLEU 2 Although we are not aware of any work demonstrating that this combination of metrics correlates better than either individually in sentence ranking, Yaser Al-Onaizan   reports that it correlates well with the human evaluation metric HTER.",0,original
"In our implementation, the IBM Model 1   is used.",0,original
"Features For each frame element, features are extracted from the surface text of the sentence and from an automatically generated syntactic parse tree  .",0,original
"Related Work The recent availability of large amounts of bilingual data has attracted interest in several areas, including sentence alignment  , word alignment  , alignment of groups of words  , and statistical translation  .",0,original
"Furthermore, I plan to apply my parsers in other domains     besides treebank data, to investigate the effectiveness and generality of my approaches.",0,original
P-STM -l This metric corresponds to the STM metric presented by Liu and Gildea  ,0,original
"We use MXPOST tagger   for POS tagging, Charniak parser   for extracting syntactic relations, and David Blei?s version of LDA1 for LDA training and inference.",0,original
"Even for semantically predictable phrases, the fact that the words occur in fixed patterns can be very useful for the purposes of disambiguation, as demonstrated by  .",0,original
"We can mentionhere only part of this work:   for monolingualextraction, and (Kupiec, 1993; Wu,1994;Smadjaetal.",0,original
amshaw and Marcus   first introduced the machine learning techniques to chunking problem,0,original
"Treebank  , six of which are errors.",0,original
  have proposed an algorithm for doing word alignment which applies a discriminative step at every iteration of the traditional Expectation-Maximization algorithm used in IBM models.,0,original
"2.1 Conditional Maximum Entropy Model The goal of CME is to find the most uniform conditional distribution of y given observation x,  xyp, subject to constraints specified by a set of features  yxf i,, where features typically take the value of either 0 or 1  .",0,original
"Statistical Model In SIFT's statistical model, augmented parse trees are generated according to a process similar to that described in Collins  .",0,original
The topic signatures are automatically generated for each specific term by computing the likelihood ratio   between two hypotheses  .,0,original
Many statistical translation models   try to model word-toword correspondences between source and target words.,0,original
"It has been shown that the methods can be ported to other languages and treebanks  , including Cast3LB  .",0,original
"A structured perceptron   learns weights for our transliteration features, which are drawn from two broad classes: indicator and hybrid generative features.",0,original
"Furthermore, these systems have tackled the problem at different levels of granularity, from the document level  , sentence level  , phrase level  , as well as the speaker level in debates  .",0,original
The phrasebased machine translation   uses the grow-diag-final heuristic to extend the word alignment to phrase alignment by using the intersection result.,0,original
"3 The Framework 3.1 The Algorithm Our transductive learning algorithm, Algorithm 1, is inspired by the Yarowsky algorithm  .",0,original
"Second, we discuss the work done by   who use clustering of paraphrases to induce rewriting rules.",0,original
"The PCFG is a Markov grammar  , i.e. the production probabilities are estimated by decomposing the joint probability of the categories on the right-hand side into a product of conditionals via the chain rule, and making a Markov assumption.",0,original
"This operation can be used in applications like Minimum Error Rate Training  , or optimizing system combination as described by Hillard et al.",0,original
Weischedel's group   examines unknown words in the context of part-of-speech tagging.,0,original
2 Decoding The decoding problem in SMT is one of finding the most probable translation e in the target language of a given source language sentence f in accordance with the Fundamental Equation of SMT  : e = argmaxe Pr Pr .,0,original
Four teams had approaches that relied   on an IBM model of statistical machine translation  .,0,original
"Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content  , or not at all  .",0,original
"Thus, our generative model is a quasi-synchronous grammar, exactly as in  .3 When training on target sentences w, therefore, we tune the model parameters to maximize notsummationtextt p  as in ordinary EM, but rather 3Our task here is new; they used it for alignment.",0,original
The Attr cells summarize the performance of the 6 models on the wiki table that are based on attributional similarity only  .,0,original
"3.2  -cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts  .",0,original
"Approaches include word substitution systems  , phrase substitution systems  , and synchronous context-free grammar systems  , all of which train on string pairs and seek to establish connections between source and target strings.",0,original
"It is for all three reasons, i.e. translation, induction from alignment structures and induction of alignment structures, important that the synchronous grammars are expressive enough to induce all the alignment structures found in hand-aligned gold standard parallel corpora  .",0,original
"3.1 Selecting Coreference Systems A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set 2Examples of such scoring functions include the DempsterShafer rule   and Bean and Riloff  ) and its variants (see Harabagiu et al.",0,original
An open question in SMT is whether there existsclosed formexpressions   for P   and the counts in the EM iterations for models 3-5  .,0,original
"Since one of these filters restricts the number of nonterminal symbols to two, our extracted grammar is equivalent to an inversion transduction grammar  .",0,original
The statistical machine translation community relies on the Bleu metric for the purposes of evaluating incremental system changes and optimizing systems through minimum error rate training  .,0,original
"For ROUGE-S and ROUGE-SU, we use three variations following  : the maximum skip distances are 4, 9 and infinity 7.",0,original
This model shares some similarities with the stochastic inversion transduction grammars   presented by Wu in  .,0,original
"3.2 Conversion to Dependencies 3.2.1 Syntactic Dependencies There exists no large-scale dependency treebank for English, and we thus had to construct a dependency-annotated corpus automatically from the Penn Treebank  .",0,original
"From the above discussion, we can see that traditional tree sequence-based method uses single tree as translation input while the forestbased model uses single sub-tree as the basic translation unit that can only learn tree-to-string   rules.",0,original
"??word class: Turney   measures polarity using only adjectives, however in our approach we consider the noun, the verb, the adverb and the adjective content words.",0,original
In   non-terminals in a standard PCFG model are augmented with latent variables.,0,original
Machine translation based on a deeper analysis of the syntactic structure of a sentence has long been identified as a desirable objective in principle  ).,0,original
Parameter tuning is done with Minimum Error Rate Training    .,0,original
"BLEU Score: BLEU is an automatic metric designed by IBM, which uses several references  .",0,original
"Typically, a small set of seed polar phrases are prepared, and new polar phrases are detected based on the strength of co-occurrence with the seeds  .",0,original
1 Introduction The research presented in this paper forms part of an ongoing effort to develop methods to induce wide-coverage multilingual LexicalFunctional Grammar     resources from treebanks by means of automatically associating LFG f-structure information with constituency trees produced by probabilistic parsers  .,0,original
"It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation   system  , or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework.",0,original
"As, from a linguistic perspective, it is the modifier 2We use a mechanism similar to   but adapted to Chinese data to find lexical heads in the treebank data.",0,original
"While earlier approaches for text compression were based on symbolic reduction rules  , more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced  .",0,original
"Since the texts in the RST Treebank are taken from the syntactically annotated Penn Treebank  , it is natural to ask what the relation is between the discourse structures in the RST Treebank and the syntactic structures of the Penn Treebank.",0,original
These alignment models stem from the source-channel approach to statistical machine translation  .,0,original
"SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, conducted three prior word segmentation bakeoffs, in 2003, 2005 and 2006 , which established benchmarks for word segmentation and named entity recognition.",0,original
"However, they do not elaborate on how the comparisons are done, or on how effective the program is. Dolan   describes a heuristic approach to forming unlabeled clusters of closely related senses in an MRD.",0,original
A few unsupervised metrics have been applied to automatic paraphrase identification and extraction  .,0,original
Rule-based taggers   use POS-dependent constraints defined by experienced linguists.,0,original
"Probabilistic models where probabilities are assigned to the CFG backbone of the unification-based grammar have been developed  , and the most probable parse is found by PCFG parsing.",0,original
"We performed a comparison between the existing CFG filtering techniques for LTAG   and HPSG  , using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank   into HPSG-style.",0,original
"For example, given that each semantic class exhibits a particular syntactic behaviour, information on the semantic class should improve POStagging for adjective-noun and adjective-participle ambiguities, probably the most difficult distinctions both for humans and computers  .",0,original
"The original training set   consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods  .",0,original
"For the English experiments, we use the now-standard training and test sets that were introduced in  2.",0,original
he fact that different authors use different versions of the same gold standard to evaluate similar experiments   versus Johnson  ) supports this claim,0,original
"In Kanayamas method, the co-occurrence is considered as the appearance in intraor inter-sentential context  .",0,original
The weights of feature functions are optimized to maximize the scoring measure  .,0,original
"1 Introduction Most recent approaches in SMT, eg  , use a log-linear model to combine probabilistic features.",0,original
"The second method considers the means and variance of the distance between two words, and can compute flexible collocations  .",0,original
Hw6: Implement beam search and reduplicate the POS tagger described in  .,0,original
Tag sets for English are derived from the Penn Treebank  .,0,original
The corresponding unlabeled figures are 73.3 and 33.4.3 This confirms the results of previous studies showing that the pseudo-projective parsing technique used by MaltParser tends to give high precision  given that non-projective dependencies are among the most difficult to parse correctly  but rather low recall  .,0,original
"Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni   showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score   of at best 69%and that only when restricted to keep most words very close to their source positions.",0,original
"As comparison, Turney and Littman   used seed sets consisting of 7 words in their word valence annotation experiments, while Turney   used minimal seed sets consisting of only one positive and one negative word   in his experiments on review classification.",0,original
"If human-aligned data is available, the EMD algorithm provides higher baseline alignments than GIZA++ that have led to better MT performance  .",0,original
"1 Introduction The Inversion Transduction Grammar or ITG formalism, which historically was developed in the context of translation and alignment, hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments  .",0,original
The POS tag features were produced by rst predicting the tags with Ratnaparkhis Maximum Entropy Tagger   and then clustered by hand into a smaller number of groups based on their syntactic role.,0,original
Work on learning with hidden variables can be used for both CRFs   and for inference based learning algorithms like those used in this work  .,0,original
"One such approach is maximum entropy classification  , which we use in the form of a library implemented by Tsuruoka1 and used in his classifier-based parser  .",0,original
"Moreover, our approach integrates the abbreviation translation component into the baseline system in a natural way, and thus is able to make use of the minimum-error-rate training   to automatically adjust the model parameters to reflect the change of the integrated system over the baseline system.",0,original
Their weights are optimized w.r.t. BLEU score using the algorithm described in  .,0,original
"Hobbs, Jerry   """"Ontological Promiscuity"""", Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, Chicago, Illinois, pp.",0,original
Our scores fall within the range of previous researchers  .,0,original
These instances can be retagged with their countability by using the proposed method and some kind of bootstrapping  .,0,original
"Narrative retellings provide a natural, conversational speech sample that can be analyzed for many of the characteristics of speech and language that have been shown to discriminate between healthy and impaired subjects, including syntactic complexity   and mean pause duration  .",0,original
The baseline hierarchical phrase-based system is trained using standard max-BLEU training   without sparse features  .,0,original
We chose to train maximum entropy models  .,0,original
"Work focusses on analysing subjective features of text or speech, such as sentiment, opinion, emotion or point of view  .",0,original
Table 2 summarizes the characteristics of the training corpus used for training the parameters of Model 4 proposed in  .,0,original
"In designing LEAF, we were also inspired by dependency-based alignment models  .",0,original
Our proposal is a first order linear model that relies on an online averaged Perceptron for learning   and an extended Eisner algorithm for the joint parsing inference.,0,original
"This characteristic of our corpus is similar to problems with noisy and comparable corpora  , and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as  .",0,original
"A maximum entropy approach has been applied to partof-speech tagging before  , but the approach's ability to incorporate nonlocal and non-HMM-tagger-type evidence has not been fully explored.",0,original
2 Related Work A number of researchers   have described approaches that preprocess the source language input in SMT systems.,0,original
5.1 CoNLL named entities presence feature We use Stanford named entity recognizer     to identify CoNLL style NEs7 as possible answer strings in a candidate sentence for a given type of question.,0,original
"When we have a junction tree for each document, we can efficiently perform belief propagation in order to compute argmax in Equation  , or the marginal probabilities of cliques and labels, necessary for the parameter estimation of machine learning classifiers, including perceptrons  , and maximum entropy models  .",0,original
"More recently, Haffari and Sarkar   have extended the work of Abney   and given a better mathematical understanding of self-training algorithms.",0,original
"Afterwards, we select and remove a subset of highly informative sentences from U, and add those sentences together with their human-provided translations to L. This process is continued iteratively until a certain level of translation quality is met    .",0,original
1418 examples of structures of the kind 'VB N1 PREP N2' were extracted from the Penn-TreeBank Wall Street Journal  ,0,original
"We rst recast the problem of estimating the IBM models   in a discriminative framework, which leads to an initial increase in word-alignment accuracy.",0,original
"2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone  , but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text.",0,original
The syntactic parameters are the same as in Section 5.1 and are smoothed as in  .,0,original
We used an implementation of McDonald  forcomparisonofresults .,0,original
"While studies have shown that ratings of MT systems by BLEU and similar metrics correlate well with human judgments  , we are not aware of any studies that have shown that corpus-based evaluation metrics of NLG systems are correlated with human judgments; correlation studies have been made of individual components  , but not of systems.",0,original
"In this work, we use the GIZA++ implementation   of IBM Model 5  .",0,original
5.3   Snow   has extended the WordNet 2.1 by adding thousands of entries   at a relatively high precision.,0,original
1 Introduction In phrase-based statistical machine translation   phrases extracted from word-aligned parallel data are the fundamental unit of translation.,0,original
"Using Maximum Entropy   classifiers I built a parser that achieves a throughput of over 200 sentences per second, with a small loss in accuracy of about 23 %.",0,original
The 1000-best lists are augmented with IBM Model-1   scores and then rescored with a second set of MET parameters.,0,original
"Each token is labelled with a class using the IOB type of segmentation coding as introduced by Ramshaw and Marcus  , marking whether the middle word is inside  , outside  , or at the beginning   of a chunk, or named entity.",0,original
One is distortion model   which penalizes translations according to their jump distance instead of their content.,0,original
"We report case-insensitive scores on version 0.6 of METEOR   with all modules enabled, version 1.04 of IBM-style BLEU  , and version 5 of TER  .",0,original
"To optimize the system towards a maximal BLEU or NIST score, we use Minimum Error Rate   Training as described in  .",0,original
"In addition, explicitly using the left context symbols allows easy use of smoothing techniques, such as deleted interpolation  , clustering techniques  , and model refinement techniques   to estimate the probabilities more reliably by changing the window sizes of the context and weighting the various estimates dynamically.",0,original
Our features were based on those in  .,0,original
"In practice, texts contain an enormous number of word sequences  , only a tiny fraction of which are NCCs, and it takes considerable computational effort to induce each translation model.",0,original
"In this article, we used the algorithm of   to initialize the model.",0,original
.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus's base NP chunker  ,0,original
" , a robust risk minimization classifier, based on a regularized winnow method     and a maximum entropy classifier    .",0,original
  can be used to motivate a novel class-based language model and a regularized version of minimum discrimination information   models  .,0,original
"3 Inversion Transduction Grammars While our approach applies in principle to a variety of machine translation systems  , we will use the inversion transduction grammar   approach of Wu   to facilitate comparison with previous work  aswellastofocuson language model complexity.",0,original
"The complexities of 15 restricted alignment problems in two very different synchronous grammar formalisms of syntax-based machine translation, inversion transduction grammars     and a restricted form of range concatenation grammars  -BRCGs)  , are investigated.",0,original
"We use the GIZA toolkit  , a suffix-array architecture  , the SRILM toolkit  , and minimum error rate training   to obtain wordalignments, a translation model, language models, and the optimal weights for combining these models, respectively.",0,original
"Due to the lack of a good Arabic parser compatible with the Sakhr tokenization that we used on the source side, we did not test the source dependency LM for Arabic-to-English MT. When extracting rules with source dependency structures, we applied the same well-formedness constraint on the source side as we did on the target side, using a procedure described by  .",0,original
"Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts  , as well as in similar predicateargument structure contexts  .",0,original
2.2 Word Alignment Aligning below the sentence level is usually done using statistical models for machine translation   where any word of the targetlanguageistakentobeapossibletranslation for each source language word.,0,original
"4.1 Judging Rule Correctness Following the spirit of the fine-grained human evaluation in  , we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above.",0,original
" , is to translate dependency parses into neo-Davidsonian-style quasilogical forms, and to perform weighted abductive theorem proving in the tradition of  .",0,original
"Similarly to  , the tree-to-string alignment templates discussed in this paper are actually transformation rules.",0,original
"Ramshaw and Marcus  used transformation-based learning, an error-driven learning technique introduced by Eric Bn11 , to locate chunks in the tagged corpus.",0,original
"We trained a Chinese Treebank-style tokenizer and partof-speech tagger, both using a tagging model based on a perceptron learning algorithm  .",0,original
"For testing purposes, we used the Wall Street Journal part of the Penn Treebank corpus  .",0,original
"One way around this dif culty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar     and the binary synchronous context-free grammar   employed by the Hiero system   to model the hierarchical phrases.",0,original
"Furthermore, training corpora for information extraction are typically annotated with domain-specific tags, in contrast to general-purpose annotations such as part-of-speech tags or noun-phrase bracketing  .",0,original
2 Related Work The most commonly used similarity measures are based on the WordNet lexical database   and a number of such measures have been made publicly available  .,0,original
Some of the early statistical terminology translation methods are  .,0,original
"Second, phrase translation pairs are extracted from the word aligned corpus  .",0,original
"Most existing work to capture labelconsistency, has attempted to create all parenleftbign2parenrightbig pairwise dependencies between the different occurrences of an entity,  , where n is the number of occurrences of the given entity.",0,original
"We report precision, recall and balanced F-measure  .",0,original
"GIZA++  , an implementation of the IBM   and HMM  ",0,original
LW was originally used to validate the quality of a phrase translation pair in MT  .,0,original
"Adapting a vectorbased approach reported by Chu-Carroll and Carpenter  , the Task ID Frame Agent is domain-independent and automatically trained.",0,original
"4 Sub Translation Combining For sub translation combining, we mainly use the best-first expansion idea from cube pruning   to combine subtranslations and generate the whole k-best translations.",0,original
"To support a more rigorous analysis, however, wc have followed Carletta's suggestion   of using the K coettMcnt   as a measure of coder agreement.",0,original
"In particular, we use a randomly-selected corpus the first five columns as information-like. consisting of a 6.7 million word subset of the TREC Similarly, since the last four columns share databases  .",0,original
"Inversion Transduction Grammar   is the model of Wu  , Tree-to-String is the model of Yamada and Knight  , and Tree-to-String, Clone allows the node cloning operation described above.",0,original
"In  , finite-state machine translation is based on   and is used for decoding the target language string.",0,original
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment  , or extraction of syntactic constructions from online dictionaries and corpora  .",0,original
.2 Data sparseness Another facet of the general trade-off identified by Rapp   pertains to how limitations in862 herent in the combination of data and cooccurrence retrieval method are manifest,0,original
"5.1 The baseline System used for comparison was Pharaoh  , which uses a beam search algorithm for decoding.",0,original
"Moreover, as P-DOP is formulated as an enrichment of the treebank Probabilistic Context-free Grammar  , it allows for much easier comparison to alternative approaches to statistical parsing  .",0,original
"3 MaltParser MaltParser   is a languageindependent system for data-driven dependency parsing, based on a transition-based parsing model  .",0,original
Syntactic Score   Some erroneous sentences often contain words and concepts that are locally correct but cannot form coherent sentences  .,0,original
2004) and Barzilay and Lee   used comparable news articles to obtain sentence level paraphrases,0,original
"For example, the entry about the Microsoft in Wikipedia has the following categories: Companies listed on NASDAQ; Cloud computing vendors; etc. Both   and   used the free-text description of the Wikipedia entity to reason about the entity type.",0,original
"Following Smith and Eisner  , we adopt the view that the syntactic structure of sentences paraphrasing some sentence s should be inspired by the structure of s. Because dependency syntax is still only a crude approximation to semantic structure, we augment the model with a lexical semantics component, based on WordNet  , that models how words are probabilistically altered in generating a paraphrase.",0,original
  propose a MaxEnt-based reordering model for BTG   while Setiawan et al.,0,original
Parameters were tuned with MERT algorithm   on the NIST evaluation set of 2003   for both the baseline systems and the system combination model.,0,original
503 Bikel Intricacies of Collins Parsing Model Table 4 Overall parsing results using only details found in Collins  .,0,original
"To make sense tagging more precise, it is advisable to place constraint on the translation counterpart c of w. SWAT considers only those translations c that has been linked with w based the Competitive Linking Algorithm   and logarithmic likelihood ratio  .",0,original
"This method was preferred against other related methods, like the one introduced in  , since it embeds all the available semantic information existing in WordNet, even edges that cross POS, thus offering a richer semantic representation.",0,original
"Among various language modeling approaches, ngram modeling has been widely used in many applications, such as speech recognition, machine translation  .",0,original
"We also show that the domain adaptation work of  , which is presented as an ad-hoc preprocessing step, is actually equivalent to our formal model.",0,original
"The computation mechanism of GP and LP bears a resemblance to the EM algorithm , which iteratively computes maximum likelihood estimates from incomplete data.",0,original
"There has been considerable use in the NLP community of both WordNet   and LDOCE  , but no one has merged the two in order to combine their strengths.",0,original
"2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based  , statistics-based   and learning-based  .",0,original
he samplers that Goldwater and Griffiths   and Johnson   describe are pointwise collapsed Gibbs samplers,0,original
Similarity-based smoothing   is an intuitively appealing approach to this problem where probabilities of unseen co-occurrences are estimated from probabilities of seen co-occurrences of distributionally similar events.,0,original
"In Yarowsky's experiment  , an average of 3936 examples were used to disambiguate between two senses.",0,original
"Output sequence optimization Rather than basing classifications only on model parameters estimated from co-occurrences between input and output symbols employed for maximizing the likelihood of point-wise single-label predictions at the output level, classifier output may be augmented by an optimization over the output sequence as a whole using optimization techniques such as beam searching in the space of a conditional markov models output   or hidden markov models  .",0,original
"The COlllillOil poini;s regarding collocations appear to be, as   suggestsl: they are m'bil;rary  , th , t;hey are recurrenl; and cohesive lo~xical clusters: the presence of one of the.",0,original
The same probabilities are also included using 50 hard word classes derived from the parallel corpus using the GIZA++ mkcls utility  .,0,original
"It is an extension of Pharaoh  , and supports factor training and decoding.",0,original
Some approaches have used syntax at the core   while others have integrated syntax into existing phrase-based frameworks  .,0,original
"7 Related Work Much work on sentiment analysis classifies documents by their overall sentiment, for example determining whether a review is positive or negative  ).",0,original
"The common types of features include contextual  , co-occurrence  , and syntactic dependency  .",0,original
his feature is implemented by using the IBM-1 lexical parameters  ,0,original
aghighi and Klein   showed that adding a small set of prototypes to the unlabeled data can improve tagging accuracy significantly,0,original
"Related work includes Wu  , Zens and Ney   and Wellington et al.",0,original
"  describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels.",0,original
PMI++ is an extended version of  s method for finding the SO label of a phrase  .,0,original
"Several approaches have been proposed in the context of word sense disambiguation  , named entity   classification  , patternacquisitionforIE , or dimensionality reduction for text categorization    .",0,original
  and   claim that fine-grained semantic distinctions are unlikely to be of practical value for many applications.,0,original
ur system assumes POS tags as input and uses the tagger of Ratnaparkhi   to provide tags for the development and evaluation sets,0,original
"Therefore, an increasing attention has been recently given to semi-supervised learning, where large amounts of unlabeled data are used to improve the models learned from a small training set  .",0,original
"Probabilities based on relative frequencies, or derived fl'om the measure defined in  , for example, allow to take this fact into account.",0,original
"The ITG we apply in our experiments has more structural labels than the primitive bracketing grammar: it has a start symbol S, a single preterminal C, and two intermediate nonterminals A and B used to ensure that only one parse can generate any given word-level alignment, as discussed by Wu   and Zens and Ney  .",0,original
"However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses  .",0,original
1 Introduction Inversion transduction grammar   constraints   provide coherent structural constraints on the relationship between a sentence and its translation.,0,original
The optimal weights for the different columns can then be assigned with the help of minimum error rate training  .,0,original
"Only recently have robust knowledge-based methods for some of these tasks begun to appear, and their performance is still not very good, as seen above in our discussion of using WordNet as a semantic network; 33 as for checking the plausibility of a hypothesis on the basis of causal knowledge about the world, we now have a much better theoretical grasp of how such inferences could be made  , but we are still quite a long way from a general inference engine.",0,original
We use the distributed training and application infrastructure described in   with modifications to allow the training of predictive class-based models and their application in the decoder of the machine translation system.,0,original
"Our approach is data-driven: following the methodology in  , we automatically convert the English PennII treebank and the Chinese Penn Treebank   into f-structure banks.",0,original
3.1 Conditional Random Field for Alignment Our conditional random field   for alignment has a graphical model structure that resembles that of IBM Model 1  .,0,original
"1.2.2 SPECIFIC SYNTACTIC AND SEMANTIC ASSUMPTIONS The basic scheme, or some not too distant relative, is the one used in many large-scale implemented systems; as examples, we can quote TEAM  , PUNDIT  , TACITUS  , MODL  , CLE  , and SNACK-85  .",0,original
"In particular, we use a feature augmentation technique recently introduced by Daume III  , and active learning   to perform domain adaptation of WSD systems.",0,original
"We use the Stanford parser   with its default Chinese grammar, the GIZA++   alignment package with its default settings, and the ME tool developed by  .",0,original
"73 ment and phrase-extraction heuristics described in  , minimum-error-rate training  , a trigram language model with KneserNey smoothing trained with SRILM   on the English side of the training data, and Moses   to decode.",0,original
This framework is 211 commonly used in generation and summarization applications where the selection process is driven by multiple constraints  .,0,original
"One such technique is bootstrapping, which was recently presented in  ,   as an ideal framework for text learning tasks that have knowledge seeds.",0,original
This can also be interpreted as a generalization of standard class-based models  .,0,original
"The inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance  .",0,original
"Inspired by the conjunction and appositive structures, Riloff and Shepherd  , Roark and Charniak   used cooccurrence statistics in local context to discover sibling relations.",0,original
"2 Inside-out alignments Wu   identified so-called inside-out alignments, two alignment configurations that cannot be induced by binary synchronous context-free grammars; these alignment configurations, while infrequent in language pairs such as EnglishFrench  , have been argued to be frequent in other language pairs, incl.",0,original
"To avoid this problem, generative models for NLP tasks have often been manually designed to achieve an appropriate representation of the joint distribution, such as in the parsing models of  .",0,original
"From a theoretical point of view, it is difficult to find motivation for the parameter estimation methods used by    see   for discussion.",0,original
"5.1 Baseline The baseline system we used for comparison was Pharaoh  , as publicly distributed.",0,original
Factored models are introduced in   for better integration of morphosyntactic information.,0,original
2 Background Default unification has been investigated by many researchers   in the context of developing lexical semantics.,0,original
"However, following the work of Yarowsky  , Yarowsky  , many supervised WSD systems use minimal information about syntactic structures, for the most part restricting the notion of context to topical and local features.",0,original
everal sentiment information retrieval models were proposed in the framework of probabilistic language models by Eguchi and Lavrenko  ,0,original
An acceptable agreement for most NLP classification tasks lies between 0.7 and 0.8  .,0,original
"The X 2 statistic is performing at least as well as G 2, and the results show that the average level of generalization is slightly higher for G 2 than X 2 . This suggests a possible explanation for the results presented here and those in Dunning  : that the X 2 statistic provides a less conservative test when counts in the contingency table are low.",0,original
We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank   and Prague Dependency Treebank    .,0,original
" ; later elaborations and refinements have been implemented in a number of systems, notably CHAT-80  , TEAM  , and CLE  .",0,original
"The features used by the POS tagger, some of which are different to those from Collins   and are specific to Chinese, are shown in Table 2.",0,original
3.1 Learning Chunk-based Translation We learn chunk alignments from a corpus that has been word-aligned by a training toolkit for wordbased translation models: the Giza++   toolkit for the IBM models  .,0,original
"In addition to sentence fusion, compression algorithms   and methods for expansion of a multiparallel corpus   are other instances of such methods.",0,original
"Statistical parsers have been developed for TAG  , LFG  , and HPSG  , among others.",0,original
1 Introduction Previous corpus-based sense disambiguation methods require substantial amounts of sense-tagged training data   or aligned bilingual corpora  .,0,original
ote that the algorithm from Collins   was designed for discriminatively training an HMM-style tagger,0,original
"stance, the IBM models   can be improved by adding more context dependencies into the translation model using a ME framework rather than using only p   .",0,original
Due to space we do not describe step 8 in detail  ).,0,original
"Charniak   and Johnson   annotated each node with its parent and grandparent nonterminals, to more precisely reflect its outside context.",0,original
4.2 Classifier and Features For our AL framework we decided to employ a Maximum Entropy   classifier  .,0,original
he only difference is that we 5See also work on partial parsing as a task in its own right: Hindle   inter alia,0,original
"This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences  .",0,original
"We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank   and Penn Chinese Treebank  , extracting wide-coverage, probabilistic LFG grammar 361 Computational Linguistics Volume 31, Number 3 approximations and lexical resources for German   and Chinese  .",0,original
"In addition, uniform conditioning on mother grammatical function is more general than the case-phenomena specific generation grammar transform of  , in that it applies to each and every sub-part of a recursive input f-structure driving generation, making available relevant generation history   to guide local generation decisions.",0,original
"From multilingual texts, translation lexica can be generated  .",0,original
6 Related work Evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective   and adjacency pair information has been used to predict congressional votes  .,0,original
"corpus  , the Penn Treebank  , the SUSANNE corpus  , the Spoken English Corpus  , the Oxford Psycholinguistic Database  , and the """"Computer-Usable"""" version of the Oxford Advanced Learner's Dictionary of Current English  .",0,original
"3 Schone & Jurafsky's results indicate similar results for log-likelihood & T-score, and strong parallelism among information-theoretic measures such as ChiSquared, Selectional Association  , Symmetric Conditional Probability   and the Z-Score  .",0,original
"For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system  .",0,original
im and Hovy   make a similar assumption,0,original
"In Turney  , features are selected according to part-of-speech labels.",0,original
"Smadja employsthez-scoreinconjunction with several heuristics andextractspredicativecollocations, 1E.g.,(Frantziet al. ,2000;Pearce,2001;Goldmanet al. , 2001;ZaiuInkpenandHirst,2002;Dias,2003;Seretanetal.",0,original
Feature function scaling factors m are optimized based on a maximum likelihood approach   or on a direct error minimization approach  .,0,original
"It is possible that there is a better automated method for finding such phrases, such as the methods in  .",0,original
The former extracts collocations within a fixed window  .,0,original
"3 We then run Collins parser  , using just the sentence pairs where parsing succeeds with a negative log likelihood below 200.",0,original
Ramshaw and Marcus used transformationbased learning   for developing two chunkers  .,0,original
"1 word w 2 word bigram w1w2 3 single-character word w 4 a word of length l with starting character c 5 a word of length l with ending character c 6 space-separated characters c1 and c2 7 character bigram c1c2 in any word 8 the first / last characters c1 / c2 of any word 9 word w immediately before character c 10 character c immediately before word w 11 the starting characters c1 and c2 of two consecutive words 12 the ending characters c1 and c2 of two consecutive words 13 a word of length l with previous word w 14 a word of length l with next word w Table 1: Feature templates for the baseline segmentor 2 The Baseline System We built a two-stage baseline system, using the perceptron segmentation model from our previous work   and the perceptron POS tagging model from Collins  .",0,original
A Head Percolation Table has previously been used in several statistical parsers   to find heads of phrases.,0,original
"See Collins   for an application of the boosting approach to named entity recognition, and Walker, Rambow, and Rogati   for the application of boosting techniques for ranking in the context of natural language generation.",0,original
"The algorithm to acquire the lexicon, implemented in the ARIOSTQLEX system, has been extensively described in \ .",0,original
TER-based: TER-based word alignment method   is an extension of multiple string matching algorithm based on Levenshtein edit distance  .,0,original
"5.1 Pharaoh The baseline system we used for comparison was Pharaoh  , a freely available decoder for phrase-based translation models: p  = p  pLM LM  pD D length W    We ran GIZA++   on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in   to obtain a single many-to-many word alignment for each sentence pair.",0,original
"4.1.3 Alternative Paraphrasing Techniques To investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: Latent Semantic Analysis  , and Brown clustering  .",0,original
As with other randomised models we construct queries with the appropriate sanity checks to lower the error rate efficiently  .,0,original
"To this extent, we cast the supersense tagging problem as a sequence labeling task and train a discriminative Hidden Markov Model  , based on that of Collins  , on the manually annotated Semcor corpus  .",0,original
ethod Number of frames Number of verbs Linguistic resources F-Score   Coverage on a corpus C. Manning   19 200 POS tagger + simple finite state parser 58 T. Briscoe & J. Carroll   161 14 Full parser 55 A. Sarkar & D. Zeman   137 914 Annotated treebank 88 D. Kawahara et al,0,original
5.2 Maximum Entropy Model We use the Maximum Entropy   Model   for our classification task.,0,original
"When an S alignment exists, there will always also exist a P alignment such that P a65 S. The English sentences were parsed using a state-of-the-art statistical parser   trained on the University of Pennsylvania Treebank  .",0,original
One possible use for this technique is for parser adaptation  initially training the parser on one type of data for which hand-labeled trees are available  ) and then self-training on a second type of data in order to adapt the parser to the second domain.,0,original
"To set the weight vector w, we train twenty averaged perceptrons   on different shuffles of data drawn from sections 0221 of the Penn Treebank.",0,original
Kupiec   has proposed an estimation method for the N-gram language model using the Baum-Welch reestimation algorithm   from an untagged corpus and Cutting et al.,0,original
"  and Chiang  , in terms of what alignments they induce, has been discussed in Wu   and Wellington et al.",0,original
Obtained percent agreement of 0.988 and  coefficient   of 0.975 suggest high convergence of both annotations.,0,original
"More recently, Clarke and Lapata   use Centering Theory   and Lexical Chains   to identify which information to prune.",0,original
  describe an approach that targets translation of French phrases of the form NOUN de NOUN  .,0,original
We evaluated annotation reliability by using the Kappa statistic  .,0,original
"The syntactic parser is the version that is selftrained using 2,500,000 sentences from NANC, and where the starting version is trained only on WSJ data  .",0,original
"Recognizing this, Dolan   proposes a method for """"ambiguating"""" dictionary senses by combining them to create grosser sense distinctions.",0,original
"Adopting the SCF acquisition system of Briscoe and Carroll, we have experimented with an alternative hypothesis test, the binomial log-likelihood ratio   test  .",0,original
"  1We follow the notations in   for English-French, i.e., e  f, although our models are tested, in this paper, for English-Chinese.",0,original
"As a result, they are being used in a variety of applications, such as question answering  , speech recognition  , language modeling  , language generation   and, most notably, machine translation  .",0,original
his hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation  ,0,original
"Stochastic taggers use both contextual and morphological information, and the model parameters are usually defined or updated automatically from tagged texts  , University of Patras, 265 00 Patras, Greece.",0,original
"Translation accuracy is measured in terms of the BLEU score  , which is computed here for translations generated by using the tuple n-gram model alone, in the case of Table 2, and by using the tuple n-gram model along with the additional four feature functions described in Section 3.2, in the case of Table 3.",0,original
The Penn Treebank documentation   defines a commonly used set of tags.,0,original
"Smadja   also detailed techniques for collocation extraction and developed a program called XTRACT, which is capable of computing flexible collocations based on elaborated statistical calculation.",0,original
"For both experiments, we used dependency trees extracted from the Penn Treebank   using the head rules and dependency extractor from Yamada and Matsumoto  .",0,original
"In order to objectively evaluate our representation, we derived it from two different sources: constituency parse trees  ) and dependency parse trees  )1.",0,original
"Semantic features are used for classifying entities into semantic types such as name of person, organization, or place, while syntactic features characterize the kinds of dependency 5It is worth noting that the present approach can be recast into one based on constraint relaxation  .",0,original
"Many systems   use these relationships as an intermediate, form when determining the semantics of syntactically parsed text.",0,original
"We use a bidirectional search strategy  , and our algorithm is based on Perceptron learning  .",0,original
"  binarize grammars into CNF normal form, while   allow only Griebach-Normal form grammars.",0,original
"However, they use the   data set in a different training-test division   which makes it (tifficult to compare their results with others.",0,original
"In addition, we use the measure from Resnik  , which is computed using an intrinsic information content measure relying on the hierarchical structure of the category tree  .",0,original
Practical Model 4 systems therefore make substantial search approximations  .,0,original
"Comparison With Previous Work Most of the recent corpus-based POS taggers in the literature are either statistically based, and use Markov Model  or Statistical Decision Tree   techniques, or are primarily rule based, such as Drill's Transformation Based Learner  .",0,original
7.1.3 Similarity via pagerank Pagerank   is the celebrated citation ranking algorithm that has been applied to several natural language problems from summarization   to opinion mining   to our task of lexical relatedness  .,0,original
"Performance is measured by computing the BLEU scores   of the systems translations, when compared against a single reference translation per sentence.",0,original
"To solve this problem, we will adapt the idea of null generated words from machine translation  .",0,original
No artificial glue-rules or rule span limits were employed.7 The parameters of the translation system were trained to maximize BLEU on the MT02 test set  .,0,original
"To optimize the parameters of the decoder, we performed minimum error rate training on IWSLT04 optimizing for the IBM-BLEU metric  .",0,original
"By using 8-bit floating point quantization 1 , N-gram language models are compressed into 10 GB, which is comparable to a lossy representation  .",0,original
"On the other hand, works done by   have proposed methodologies to automatically acquire these patterns mostly based on supervised learning to leverage manual work.",0,original
"Similar to BLEU score, we also use the similar Brevity Penalty BP   to penalize the short translations in computing RAcc.",0,original
"As discussed in  , undirected graphical models do not seem to be suitable for history-based parsing models.",0,original
"There are many possible methods for combining unlabeled and labeled data  , but we simply concatenate unlabeled data with labeled data to see the effectiveness of the selected reliable parses.",0,original
"As with many dependency parsers  , we handle non-projective   arcs by transforming them into noncrossing arcs with augmented labels.1 Because our syntactic derivations are equivalent to those of  , we use their HEAD methods to projectivise the syntactic dependencies.",0,original
Skipchain CRF model is applied for entity extraction and meeting summarization  .,0,original
t is known that ITGs do not induce the class of inside-out alignments discussed in Wu  ,0,original
6 Experiment 6.1 Setup The experiments we report were done on the Penn Treebank WSJ Corpus  .,0,original
"Table 3 shows the differences between the treebank~ utilized in   on the one hand, and in the work reported here, on the other, is Table 4 shows relevant lSFigures for Average Sentence Length   and Training Set Size, for the IBM ManuaLs Corpus, are approximate, and cz~e fzom  .",0,original
e also tested the flat syntactic feature set proposed in Luo and Zitouni  s work,0,original
The sentences were processed using Collins parser   to generate parse-trees automatically.,0,original
"3 Maximum Entropy Taggers The taggers are based on Maximum Entropy tagging methods  , and can all be trained on new annotated data, using either GIS or BFGS training code.",0,original
"More specifically, the latter system uses the IBM-1 lexical parameters   for computing the translation probabilities of two possible new tuples: the one resulting when the null-aligned-word is attached to Table 6 Evaluation results for experiments on n-gram size incidence.",0,original
Another WSD approach incorporating context-dependent phrasal translation lexicons is given in   and has been evaluated on several translation tasks.,0,original
"The distinction between lexical and relational similarity for word pair comparison is recognised byTurney  , though the methods he presents focus on relational similarity.",0,original
"More complete discussions of M.E. as applied to computational linguistics, including a description of the M.E. estimation procedure can be found in   and  .",0,original
"Brown et al. proposed a class-based n-gram model, which generalizes the n-gram model, to predict a word from previous words in a text  .",0,original
"For example, the coding manual for the Switchboard DAMSL dialogue act annotation scheme   states that kappa is used to assess labelling accuracy, and Di Eugenio and Glass   relate reliability to the objectivity of decisions, whereas Carletta   regards reliability as the degree to which we understand the judgments that annotators are asked to make.",0,original
"Collins  s parser and its reimplementation and extension by Bikel   have by now been applied to a variety of languages: English  , Czech  , German  , Spanish  , French  , Chinese   and, according to Dan Bikels web page, Arabic.",0,original
Prototype-drive learning   specifies prior knowledge by providing a few prototypes   for each label.,0,original
"Besides being used in SMT, it is also used in translation lexicon building  , transfer rule learning  , example-based machine translation  , etc. In previous alignment methods, some researches modeled the alignments as hidden parameters in a statistical translation model   or directly modeled them given the sentence pairs  .",0,original
"1 Introduction Several approaches including statistical techniques  , lexical techniques   and hybrid techniques  , have been pursued to design schemes for word alignment which aims at establishing links between words of a source language and a target language in a parallel corpus.",0,original
"This leads to 49 methods that use semi-supervised techniques on a treebank-infered grammar backbone, such as  .",0,original
"Although Phramer provides decoding functionality equivalent to Pharaohs, we preferred to use Pharaoh for this task because it is much faster than Phramer  between 2 and 15 times faster, depending on the configuration  and preliminary tests showed that there is no noticeable difference between the output of these two in terms of BLEU   score.",0,original
Existing statistical NLG   uses corpus statistics to inform heuristic decisions in what is otherwise symbolic generation  ;   applies n-gram models to select the overall most likely realisation after generation  ; or   reuses an existing parsing grammar or treebank for surface realisation  .,0,original
BLEU   was devised to provide automatic evaluation of MT output.,0,original
"Word-aligned corpora have been found to be an excellent source for translation-related knowledge, not only for phrase-based models  , but also for syntax-based models  ).",0,original
"The first is a baseline of sorts, our own version of the """"chunking as tagging"""" approach introduced by Ramshaw and Marcus  .",0,original
All model weights were trained on development sets via minimum-error rate training     with 200 unique n-best lists and optimizing toward BLEU.,0,original
Amount of works have been done on sentimental classification in different levels  .,0,original
"Independently, in AI an effort arose to encode large amounts of commonsense knowledge  .",0,original
"To be able identify that adjacent blocks   can be merged into larger blocks, our model infers binary   trees reminiscent of  .",0,original
"The approach combines statistical and knowledge-based methods, but unlike many recent corpus-based approaches to sense disambiguation  , it takes as its starting point the assumption that senseannotated training text is not available.",0,original
"To tackle this problem, we defined 2The best results of Collins and Roark     are achieved when the parser utilizes the information about the final punctuation and the look-ahead.",0,original
"Moreover, under this view, SMT becomes quite similar to sequential natural language annotation problems such as part-of-speech tagging and shallow parsing, and the novel training algorithm presented in this paper is actually most similar to work on training algorithms presented for these task, e.g. the on-line training algorithm presented in   and the perceptron training algorithm presented in  .",0,original
"Using alignment for grammar and lexicon induction has been an active area of research, both in monolingual settings   and in machine translation     | interestingly, statistical MT techniques have been used to derive lexico-semantic mappings in the \reverse"""" direction of language understanding rather than generation  .",0,original
"The idea of topic signature terms was introduced by Lin and Hovy   in the context of single document summarization, and was later used in several multi-document summarization systems  .",0,original
"The data consists of 2,544 main clauses from the Wall Street Journal Treebank corpus  .",0,original
"Performance also degrades when the domain of the test set differs from the domain of the training set, in part because the test set includes more OOV words and words that appear only a few times in the training set    .",0,original
"For example,   paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU  .",0,original
Some regarded Wikipedia as the corpora and applied hand-crafted or machine-learned rules to acquire semantic relations  .,0,original
"The features we use are shown in Table 2, which are based on the features used by Ratnaparkhi   and Uchimoto et al.",0,original
"However,   show that, in phrase-based translation, improvements in AER or f-measure do not necessarily correlate with improvements in BLEU score.",0,original
The ME Tagger The ME tagger is based on Ratnaparkhi  s POS tagger and is described in Curran and Clark  ,0,original
We utilize a maximum entropy   model   to design the basic classifier used in active learning for WSD.,0,original
The standard Minimum Error Rate training   was applied to tune the weights for all feature types.,0,original
The classifier consists of two components based on the averaged multiclass perceptron  .,0,original
Use of sententially aligned corpora for word alignment has already been recommended in  .,0,original
"Automatic identification of subjective content often relies on word indicators, such as unigrams   or predetermined sentiment lexica  .",0,original
These 30 questions are determined by growing a classification tree on the word vocabulary as described in  .,0,original
"4.4 Text chunking Next, a rule-based text chunker   is applied on the tagged sentences to further identify phrasal units, such as base noun phrases NP and verbal units VB.",0,original
Introduction There has been considerable recent interest in the use of statistical methods for grouping words in large on-line corpora into categories which capture some of our intuitions about the reference of the words we use and the relationships between them  .,0,original
"However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data  .",0,original
We augment Collins head-driven model 2   to incorporate a semantic label on each internal node.,0,original
urney   has presented an unsupervised opinion classification algorithm called SO-PMI  ,0,original
2 Literature Survey The task of sentiment analysis has evolved from document level analysis  ;  ) to sentence level analysis  ;  ;  ).,0,original
"It is available in several formats, and in this paper, we use the Penn Treebank   format of NEGRA.",0,original
The discriminative training regimen is otherwise similar to  .,0,original
2 Phrase-based statistical machine translation Phrase-based SMT uses a framework of log-linear models   to integrate multiple features.,0,original
"Due to the positive results in Ando  , Blitzer et al.",0,original
" , these models have non-uniform linguistically motivated structure, at present coded by hand.",0,original
"For example, the constrained optimization method of   relies on approximations of sensitivity   and specificity2  ; related techniques   rely on approximations of true positives, false positives, and false negatives, and, indirectly, recall and precision.",0,original
"In our experiments using BLEU   as the metric, the interpolated synthetic model achieves a relative improvement of 11.7% over the best RBMT system that is used to produce the synthetic bilingual corpora.",0,original
here are two necessary ingredients to implement Ochs   training procedure,0,original
"To compare the performance of system, we recorded the total training time and the BLEU score, which is a standard automatic measurement of the translation quality .",0,original
"Previous work has shown that high-quality unlexicalized PCFGs can be learned from a treebank, either by manual annotation   or automatic state splitting  .",0,original
"To make this paper comparable to  , we use English-French notation in this section.",0,original
he feasibility of such post-parse deepening   is demonstrated by Cahill et al  ,0,original
"F-Struct Feats Grammar Rules {PRED=PRO,NUM=SG PER=3, GEN=FEM} PRP-nom   she {PRED=PRO,NUM=SG PER=3, GEN=FEM} PRP-acc   her Table 5: Lexical item rules with case markings 4 A History-Based Generation Model The automatic generation grammar transform presented in   provides a solution to coarse-grained and   inappropriate independence assumptions in the basic generation model.",0,original
"For example,   have studied synchronous context free grammar.",0,original
"Therefore, other machine learning techniques such as perceptron   could also be applied for this problem.",0,original
"Finally, we compare against the mapping from WordNet to the Oxford English Dictionary constructed in  , equivalent to clustering based solely on the OED feature.",0,original
"Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. \ ).",0,original
"2 Related Work There has been a large and diverse body of research in opinion mining, with most research at the text  , sentence   or word   level.",0,original
The grow-diag-final   combination heuristic   adds links so that each new link connects a previously unlinked token.,0,original
" ), a binarizable segmentation/permutation can be recognized by a binarized Synchronous Context-Free Grammar  , i.e., an SCFG in which the right hand sides of all non-lexical rules constitute binarizable permutations.",0,original
mith and Eisner   used a quasisynchronous grammar to discover the correspondence between words implied by the correspondence between the trees,0,original
The features are the same as those in  .,0,original
"The NIST MT03 test set is used for development, particularly for optimizing the interpolation weights using Minimum Error Rate training  .",0,original
"The mixture coefficients are trained in the usual way  , so that the additional context is exploited when it is useful and ignored when it isnt. The paper proceeds as follows.",0,original
"Examples of this are bilexical grammars--such as Eisner and Satta  , Charniak  , Collins  --where the lexical heads of each constituent are annotated on both the rightand left-hand sides of the context-free rules, under the constraint that every constituent inherits the lexical head from exactly one of its children, and the lexical head of a POS is its terminal item.",0,original
"In the latter case, we use an unsupervised attachment disambiguation method, based on the log-likelihood ratio  ).",0,original
similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi  ,0,original
"We briefly describe the tagger   for more details), a Hidden Markov Model trained with the perceptron algorithm introduced in  .",0,original
"Decoding weights are optimized using Ochs algorithm   to set weights for the four components of the loglinear model: language model, phrase translation model, distortion model, and word-length feature.",0,original
"In one experiment, it has to be performed on the basis of the gold-standard, assumed-perfect POS taken directly from the training data, the Penn Treebank  , so as to abstract from a particular POS tagger and to provide an upper bound.",0,original
olan   described a heuristic approach to forming unlabeled clusters of closely related senses in a MRD,0,original
"More recently, Haghighi and Klein   use the distinction between pronouns, nominals and proper nouns 660 in their unsupervised, generative model for coreference resolution; for their model, this is absolutely critical for achieving better accuracy.",0,original
We use GIZA++   to train generative directed alignment models: HMM and IBM Model4   from training record-text pairs.,0,original
"It is difficult to compare these with previous work, but Haghighi and Klein   report that in a completely unsupervised setting, their MRF model, which uses a large set of additional features and a more complex estimation procedure, achieves an average 1-to-1 accuracy of 41.3%.",0,original
Automatically Learning Entailment Rules from the Web Many algorithms for automatically learning paraphrases and entailment rules have been explored in recent years  .,0,original
"  and Jansche  , who discuss maximum expected F-score training of decision trees and logistic regression models.",0,original
"Appendix A: Derivation of the Probability of RWE We take a noisy channel approach, which is a common technique in NLP  ), including spellchecking  .",0,original
"Detailed description of those models can be found in  ,   and  .",0,original
We follow the work of   and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk   decoding  .,0,original
"We are encoding the knowledge as axioms in what is for the most part  first-order logic, described in Hobbs  , although quantification over predicates is sometimes convenient.",0,original
The classifier uses mutual information   scores rather than the raw frequences of the occurring patterns  .,0,original
"Thus, a lot of alignment techniques have been suggested at; the sentence  , phrase  , nomt t)hrase  , word  , collocation   and terminology level.",0,original
"For our baseline, we have selected the method based on binomial loglikelihood ratio test   described in  .",0,original
"This approach attempts to improve translation quality by optimizing an automatic translation evaluation metric, such as the BLEU score  .",0,original
"In this paper, translation quality is evaluated according to   the BLEU metrics which calculates the geometric mean of ngram precision by the system output with respect to reference translations  , and   the METEOR metrics that calculates unigram overlaps between translations  .",0,original
"Such techniques are currently being applied in many areas, including language identification, authorship attribution  , text genre classification  , topic identification  , and subjective sentiment classification  .",0,original
"Johnson   reports results for different numbers of hidden states but it is unclear how to make this choice a priori, while Goldwater & Griffiths   leave this question as future work.",0,original
"Carletta   also states that in the behavioral sciences, K > .8 signals good replicability, and .67 < K < .8 allows tentative conclusions to be drawn.",0,original
"146 2.3 Approximating ISBNs   proposes two approximations for inference in ISBNs, both based on variational methods.",0,original
We tune all feature weights automatically   to maximize the BLEU   score on the dev set.,0,original
" , we are interested in applying alternative metrics such a Meteor  .",0,original
"To generate word alignments we use GIZA++  , which implements both the IBM Models of Brown et al.",0,original
Effectiveness Comparison 5.1 English-Chinese ATIS Models Both the transfer and transducer systems were trained and evaluated on English-to-Mandarin Chinese translation of transcribed utterances from the ATIS corpus  ,0,original
"The trends are the same as in  : Adding NANC data improves parsing performance on BROWN development considerably, improving the f-score from 83.9% to 86.4%.",0,original
"Following Wu  , the prevailing opinion in the research community has been that more complex patterns of word alignment in real bitexts are mostly attributable to alignment errors.",0,original
"In the literature on the kappa statistic, most authors address only category data; some can handle more general data, such as data in interval scales or ratio scales  .",0,original
"We tokenized sentences using the standard treebank tokenization script, and then we performed part-of-speech tagging using MXPOST tagger  .",0,original
Negation was processed in a similar way as previous works  .,0,original
"Yarowsky   proposes a method for word sense disambiguation, which is based on Monolingual Bootstrapping.",0,original
22 Table 5: Comparison with previous best results:   POS tagging F=1 Perceptron   97.11 Dep.,0,original
"Method dev test Finkel et al. , 2005   baseline CRF 85.51 + non-local features 86.86 Krishnan and Manning, 2006   baseline CRF 85.29 + non-local features 87.24 Table 5: Summary of performance with POS/chunk tags by TagChunk.",0,original
"Note that the results of MB-D here cannot be directly compared with those in Yarowsky  , because the data used are different.",0,original
"Similarly to classical NLP tasks such as text chunking   and named entity recognition  , we formulate mention detection as a sequence classification problem, by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.",0,original
"The four models we compare are a maximum a posteriori   method and three discriminative training methods, namely the boosting algorithm  , the average perceptron   and the minimum sample risk method  .",0,original
"If distributional similarity is conceived of as substitutability, as Weeds and Weir   and Lee   emphasize, then asymmetries arise when one word appears in a subset of the contexts in which the other appears; for example, the adjectives that typically modify apple are a subset of those that modify fruit,sofruit substitutes for apple better than apple substitutes for fruit.",0,original
"In this form, the distinction between our two models is sometimes referred to as \joint versus conditional""""   rather than \generative versus discriminative""""  .",0,original
"1 Introduction Most   statistical machine translation systems employ a word-based alignment model  , which treats words in a sentence as independent entities and ignores the structural relationship among them.",0,original
"The translation system is a factored phrasebased translation system that uses the Moses toolkit   for decoding and training, GIZA++ for word alignment  , and SRILM   for language models.",0,original
"Our method revises and considerably extends the approach of   originally designed for English, and, to the best of our knowledge, is the first NLD recovery algorithm for Chinese.",0,original
"To further emphasize the importance of morphology in MT to Czech, we compare the standard BLEU   of a baseline phrasebased translation with BLEU which disregards word forms  .",0,original
"There has also been previous work on determining whether a given text is factual or expresses opinion  ; again this work uses a binary distinction, and supervised rather than unsupervised approaches.",0,original
"Note that there are some similarities between our two-stage semi-supervised learning approach and the semi-supervised learning method introduced by  , which is an extension of the method described by  .",0,original
Previous work has shown that data collected through the Mechanical Turk service is reliable and comparable in quality with trusted sources  .,0,original
"Furthermore, it is not possible to apply the powerful """"one sense per discourse"""" property   because there is no discourse in dictionaries.",0,original
The quality of the translation output is evaluated using BLEU  .,0,original
We collect substring rationales for a sentiment classification task   and use them to obtain significant accuracy improvements for each annotator.,0,original
"We used Pharoah   as a baseline system for comparison; the s-phrases used in our system include all phrases, with the same scores, as those used by Pharoah, allowing a direct comparison.",0,original
"Table 1 shows the percentage of agreement in classifying words as compounds or non-compounds   for each language and the Kappa score   obtained from it, and the percentage of words for which also the decomposition provided was identical  .",0,original
"We want to avoid training a metric that as5Or, in a less adversarial setting, a system may be performing minimum error-rate training   signs a higher than deserving score to a sentence that just happens to have many n-gram matches against the target-language reference corpus.",0,original
"8 An alternative formula for G 2 is given in Dunning  , but the two are equivalent.",0,original
2 We illustrate the rule extraction with an example from the tree-to-tree translation model based on tree sequence alignment   without losing of generality to most syntactic tree based models.,0,original
"This problem has been considered for instance in   for his inversion transduction grammars and has applications in the support of several tasks of automatic annotation of parallel corpora, as for instance segmentation, bracketing, phrasal and word alignment.",0,original
"Firstly, there is also H  A  declined H  H  the dollar A  H  C  H  H  Figure 2: A tree with constituents marked the top-down method, which is a version of the algorithm described by Hockenmaier et al  , but used for translating into simple   CG rather than the Steedmans Combinatory Categorial Grammar    .",0,original
Semi-supervised conditional random fields   based on a minimum entropy regularizer   have been proposed in  .,0,original
"These algorithms are usually applied to sequential labeling or chunking, but have also been applied to parsing  , machine translation   and summarization  .",0,original
"Statistical techniques, both supervised learning from tagged corpora  ,  , and unsupervised learning  ,  , have been investigated.",0,original
"We used these weights in a beam search decoder to produce translations for the test sentences, which we compared to the WMT07 gold standard using Bleu  .",0,original
"In all of the cited approaches, the Penn Wall Street Journal Treebank   is used, the availability of whichobviates the standard eort required for treebank traininghandannotating large corpora of specic domains of specic languages with specic parse types.",0,original
arowsky   used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis,0,original
"More recently, other approaches have investigated the use of machine learning to nd patterns in documents  and the utility of parameterized modules so as to deal with dierent genres or corpora .",0,original
3.2 Mapping Mapping the identified units   to their equivalents in the other language was achieved by training a new translation model   using the EM algorithm as described in  .,0,original
Yarowsky proposed the unsupervised learning method for WSD .,0,original
"For each span in the chart, we get a weight factor that is multiplied with the parameter-based expectations.9 4 Experiments We applied GIZA++   to word-align parts of the Europarl corpus   for English and all other 10 languages.",0,original
"On a separate note, previous research has explicitly studied sentiment analysis as an application of transfer learning  .",0,original
3A hypergraph is analogous to a parse forest  .,0,original
"4.2 Base Model II Using the translation model II  , where alignments are dependent on word/entity positions and word/entity sequence lengths, we have p  = mproductdisplay j=1 lsummationdisplay i=0 p p    where aj = i means that wj is aligned with ei.",0,original
This set of 800 sentences was used for Minimum Error Rate Training   to tune the weights of our system with respect to BLEU score.,0,original
"Modulo more minor differences, these notions are close to the ideas of interpretation as abduction   and generation as abduction  , where we take abduction, in the former case for instance, to be a process returning a temporal-causal structure which can explain the utterance in context.",0,original
"In  , shallow syntactic analysis such as POS tagging and morphological analysis were incorporated in a phrasal decoder.",0,original
"First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy  .8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score  .",0,original
Model parameters are estimated using maximum entropy  .,0,original
The tagger from   first annotates sentences of raw text with a sequence of partof-speech tags.,0,original
ur approach is related to those of Collins and Roark   and Taskar et al,0,original
"Moreover, as Collins   mentions, some of the benefits of Model 2 are already captured by inclusion of the distance measure.",0,original
"Recently, methods from nonparametric Bayesian statistics have been gaining popularity as a way to approach unsupervised learning for a variety of tasks, including language modeling, word and morpheme segmentation, parsing, and machine translation  .",0,original
The third estimates the equivalence based on word alignment composed using templates or translation probabilities derived from a set of parallel text  .,0,original
"1 Introduction In this paper, we study the use of so-called word trigger pairs     to improve an existing language model, which is typically a trigram model in combination with a cache component  .",0,original
It is explored extensively in  .,0,original
Self-training is a commonly used technique for semi-supervised learning that has been ap532 plied to several natural language processing tasks  .,0,original
The parameters of the NIST systems were tuned using Ochs algorithm to maximize BLEU on the MT02 test set  .,0,original
There are several works that try to learn paraphrase pairs from parallel or comparable corpora  .,0,original
"+ truecase 20.7   27.8   Table 2: Impact of truecasing on case-sensitive BLEU In a more integrated approach, factored translation models   allow us to consider grammatical coherence in form of partof-speech language models.",0,original
2.1 BLEU is essentially a precision-based metric and is currently the standard metric for automatic evaluation of MT performance.,0,original
we use k = 50 and obtain our thesaurus using the distributional similarity metric described by Lin  ,0,original
avigli   has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource,0,original
"Formally, by distributional similarity   of two words w 1 and w 2 , we mean that they tend to occur in similar contexts, for some definition of context; or that the set of words that w 1 tends to co-occur with is similar to the set that w 2 tends to co-occur with; or that if w 1 is substituted for w 2 in a context, its plausibility   is unchanged.",0,original
"On the British National Corpus  , using Lins   similarity method, we retrieve the following neighbors for the first and second sense, respectively: 1.",0,original
"This is in sharp contrast to the smoothed fixed-word statistics in most lexicalized parsing models derived from sparse data  , Collins  , Charniak  , etc.).",0,original
ther background on this method of hypothesis testing the reader is referred to  .,0,original
"Though this model uses trees in the formal sense, it does not create Penn Treebank   style linguistic trees, but uses only one non-terminal label   to create those trees using six simple rule structures.",0,original
"298 within LFG includes the XLE,3 Cahill and van Genabith  , Hogan et al.",0,original
"As expected, Malt and MST have very similar accuracy for short sentences but Malt degrades more rapidly with increasing sentence length because of error propagation  .",0,original
"Recently, several solutions to the problem of tagging unknown words have been presented  .",0,original
  extends the dictionarybased approach to sequential labeling tasks by propagating the information given in the seeds with contextual word similarity.,0,original
1 Introduction and Previous Research It is by now commonplace knowledge that accurate syntactic parsing is not possible given only a context-free grammar with standard Penn Treebank   labels  .,0,original
"In practice, 7-/ is very large and the model's expectation Efj cannot be computed directly, so the following approximation  is used: n E fj,~ E15 p fj  i=1 where fi  is the observed probability of the history hi in the training set.",0,original
We use the neural network approximation   to perform inference in our model.,0,original
s a basis mapping function  we used a generalisation of the one used by Grefenstette   and Lin  ,0,original
"1 Introduction In a classical statistical machine translation, a foreign language sentence f J1 = f1, f2, fJ is translated into another language, i.e. English, eI1 = e1, e2,, eI by seeking a maximum likely solution of: eI1 = argmax eI1 Pr    = argmax eI1 Pr Pr    The source channel approach in Equation 2 independently decomposes translation knowledge into a translation model and a language model, respectively  .",0,original
The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal  .,0,original
"First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity  .",0,original
"Feature comparison measures: to convert two feature sets into a scalar value, several measures have been proposed, such as cosine, Lins measure  , Kullback-Leibler   divergence and its variants.",0,original
In this paper we apply perceptron trained HMMs originally proposed in  .,0,original
Word alignments were generated using GIZA++   over a stemmed version of the parallel text.,0,original
  who employ clusters of related words constructed by the Brown clustering algorithm   for syntactic processing of texts.,0,original
"In the future, we plan to explore our discriminative framework on a full distortion model   or even a hierarchical model  .",0,original
"In addition to collocation translation, there is also some related work in acquiring phrase or term translations from parallel corpus  .",0,original
"Sentence Compression takes an important place for Natural Language Processing   tasks where specific constraints must be satisfied, such as length in summarization  , style in text simplification   or sentence simplification for subtitling  .",0,original
to the pair-wise TER alignment described in  .,0,original
Previous research has addressed revision in single-document summaries   and has suggested that revising summaries can make them more informative and correct errors.,0,original
"For instance, both Pang and Lee   and Turney   consider the thumbs up/thumbs down decision: is a film review positive or negative?",0,original
"s To set weights on the components of the loglinear model, we implemented Ochs algorithm  .",0,original
"2.1.4 Model Features Our MST models are based on the features described in  ; specifically, we use features based on a dependency nodes form, lemma, coarse and fine part-of-speech tag, and morphologicalstring attributes.",0,original
"Obviously, all these semantic resources have been acquiredusing a very differentset of processes  , tools and corpora.",0,original
A few exceptions are the hierarchical   transduction models   and the string transduction models  .,0,original
"To measure interannotator agreement, we compute Cohens Kappa   from the two sets of annotations, obtaining a Kappa value of only 0.43.",0,original
"The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function  .",0,original
"To support this claim, first, we used the  coefficient   to assess the agreement between the classification made by FLSA and the classification from the corpora  see Table 8.",0,original
"Introduction Word sense disambiguation has long been one of the major concerns in natural language processing area  , whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus.",0,original
"Introduction Recently, there has been an increased interest in approaches to automatically learning to recognize shallow linguistic patterns in text \[Ramshaw and Marcus, 1995, Vilain and Day, 1996, Argamon et al. , 1998, Buchholz, 1998, Cardie and Pierce, 1998, Veenstra, 1998, Daelemans et aI.",0,original
"4 Method-2: Simple Chunk-based Extraction To overcome the shortcomings of the Brill tagger in identifying particles, we next look to full chunk 2Note, this is the same as the maximum span length of 5 used by Smadja  , and above the maximum attested NP length of 3 from our corpus study  .",0,original
Previous research has shown that RST trees can play a crucial role in building natural language generation systems   and text summarization systems  ; can be used to increase the naturalness of machine translation outputs  ; and can be used to build essayscoring systems that provide students with discourse-based feedback  .,0,original
"In all the experiments, our source side language is English, and the Stanford Named Entity Recognizer   was used to extract NEs from the source side article.",0,original
"Besides relative frequencies, lexical weights   are widely used to estimate how well the words in f translate the words in e. To do this, one needs first to estimate a lexical translation probability distribution w  by relative frequency from the same word alignments in the training corpus: w  = count summationtext e count    Note that a special source NULL token is added to each source sentence and aligned to each unaligned target word.",0,original
"For the evaluation of translation quality, we used the BLEU metric  , which measures the n-gram overlap between the translated output and one or more reference translations.",0,original
"The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score  , the X2, the log-likelihood   and Fishers exact test  .",0,original
"While we do not have a direct comparison, we note that Turney   performs worse on movie reviews than on his other datasets, the same type of data as the polarity dataset.",0,original
"The agreement on identifying the boundaries of units, using the AK statistic discussed in  , was AK BP BMBL  ; the agreement on features  was follows: Attribute AK Value utype .76 verbed .9 finite .81 subject .86 NPs Our instructions for identifying NP markables derive from those proposed in the MATE project scheme for annotating anaphoric relations  .",0,original
"However, this may still be too expensive as part of an MT model that directly optimizes some performance measure, e.g., minimum error rate training  .",0,original
"NeATS computes the likelihood ratio   to identify key concepts in unigrams, bigrams, and trigrams and clusters these concepts in order to identify major subtopics within the main topic.",0,original
Each element of the resulting vector was replaced with its log-likelihood value   which can be considered as an estimate of how surprising or distinctive a co-occurrence pair is  .,0,original
  described the use of a biased PageRank over the WordNet graph to compute word pair semantic relatedness using the divergence of the probability values over the graph created by each word.,0,original
"7 Experiments To show the effectiveness of cross-language mention propagation information in improving mention detection system performance in Arabic, Chinese and Spanish, we use three SMT systems with very competitive performance in terms of BLEU11  .",0,original
"899 To alleviate overfitting on the training examples, we use the refinement strategy called averaged parameters   to the algorithm in Algorithm 1.",0,original
Note that unlike the constructions in   and   no errors are possible for ngrams stored in the model.,0,original
e used the same 58 feature types as Ratnaparkhi  ,0,original
4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks  .,0,original
"We follow the approach by Turney  , who note that the semantic orientation of an adjective depends on the noun that it modifies and suggest using adjective-noun or adverb-verb pairs to extract semantic orientation.",0,original
Minimum error rate training was used to tune the model feature weights  .,0,original
"2.2.2 ENGLISH TRAINING DATA For training in the English experiments, we used WSJ  .",0,original
"This source is very important for repairs that do not have initial retracing, and is the mainstay of the """"parser-first"""" approach  --keep trying alternative corrections until one of them parses.",0,original
  show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only.,0,original
The thesaurus was produced using the metric described by Lin   with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus     using the RASP parser  .,0,original
Experimental results were only reported for the METEOR metric  .,0,original
"As an alternative to the often used sourcechannel approach  , we directly model the posterior probability Pr   .",0,original
We then used Cohens Kappa to determine the level of agreement  .,0,original
"In addition, a number of approaches have focused on developing discriminative approaches for unsupervised and semi-supervised tagging  .",0,original
"A monotonic segmentation copes with monotonic alignments, that is, j < k ??aj < ak following the notation of  .",0,original
"To reduce the knowledge engineering burden on the user in constructing and porting an IE system, unsupervised learning has been utilized, e.g. Riloff  , Yangarber et al.",0,original
Systems were optimized on the WMT08 French-English development data   using minimum error rate training   and tested on the WMT08 test data  .,0,original
We analyze our results using syntactic features extracted from a parse tree generated by Collins parser   and compare those to models built using features extracted from FrameNets human annotations.,0,original
The parameters of the models are estimated by iterative maximum-likelihood training on a large parallel corpus of natural language texts using the EM algorithm  .,0,original
We employ the loglikelihood ratio as a measure of the collocational status of the adjective-noun pair  .,0,original
"To this end, we adopt techniques from statistical machine translation   and use statistical alignment to learn the edit patterns.",0,original
  and Turney   classified sentiment polarity of reviews at the document level,0,original
"Because of this, it is generally accepted that some kind of postprocessing should be performed to improve the final result, by shortening, fusing, or otherwise revising the material  .",0,original
"As a common strategy, POS guessers examine the endings of unknown words   along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech  .",0,original
"A null Assuming that one SMS word is mapped exactly to one English word in the channel model under an alignment, we need to consider only two types of probabilities: the alignment probabilities denoted by Pm and the lexicon mapping probabilities denoted by  .",0,original
"The usefulness of prosody was found to be very limited by itself, if the effect of utterance length is not considered  .",0,original
"To overcome these limitations, many syntaxbased SMT models have been proposed  .",0,original
"The orientation model is related to the distortion model in  , but we do not compute a block alignment during training.",0,original
"For example, Church and Hanks   describe the use of the mutual information index for this purpose (cf.",0,original
"3 Related work Word collocation Various collocation metrics have been proposed, including mean and variance  , the t-test  , the chi-square test, pointwise mutual information    , and binomial loglikelihood ratio test    .",0,original
The methods for calculating relative frequencies   and lexical weights   are also adapted for the weighted matrix case.,0,original
We will employ the structural correspondence learning   domain adaption algorithm used in   for linking the translated text and the natural text.,0,original
"3 Incremental Parsing Method Based on Adjoining Operation In order to avoid the problem of infinite local ambiguity, the previous works have adopted the following approaches:   a beam search strategy  ,   limiting the allowable chains to those actually observed in the treebank  , and   transforming the parse trees with a selective left-corner transformation   before inducing the allowable chains and allowable triples  .",0,original
"One can also examine the distribution of character or word ngrams, e.g. Language Modeling  , phrases  , and so on.",0,original
"The model presented above is based on our previous work  , which bears the same spirit of some other recent work on multitask learning  .",0,original
"For instance, automatic summary can be seen as a particular paraphrasing task   with the aim of selecting the shortest paraphrase.",0,original
Similar ideas were explored in  .,0,original
"In future work, we will expand all of the above types of features and employ techniques to reduce dimensionality along the lines suggested in   and  .",0,original
"More recently, the integration of information sources, and the modeling of more complex language processing tasks in the statistical framework has increased the interest in smoothing methods  .",0,original
correspondence points associated with frequent token types   or by deleting frequent token types from the bitext altogether  .,0,original
"3 Data The data consists of six sections of the Wall Street Journal part of the Penn Treebank  , and follows the setting of past editions of the CoNLL shared task: training set  , development set   and test set  .",0,original
arowsky   dealt with this problem largely by producing an unsupervised learning algorithm that generates probabilistic decision list models of word senses from seed collocates,0,original
"In Section 2, we examine aggregate Markov models, or class-based bigram models   in which the mapping from words to classes 81 is probabilistic.",0,original
"We guess it is an acronym for the authors of  : Michel Galley, Mark Hopkins, Kevin Knight and Daniel Marcu.",0,original
  and compare with results reported by HK06   and CRR07  .,0,original
araphrases can also be automatically acquired using statistical methods as shown by Barzilay and Lee  ,0,original
"As in  , the parameter C8 D0 B4C4 CX B4D0D8 CX BND0DB CX B5CYC8BNC0BNDBBND8BNA1BNC4BVB5 is further smoothed as follows: C8 D0BD B4C4 CX CYC8BNC0BNDBBND8BNA1BNC4BVB5 A2 C8 D0BE B4D0D8 CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B5A2 C8 D0BF B4D0DB CX CYC8BNC0BNDBBND8BNA1BNC4BVBNC4 CX B4D0D8 CX B5B5 Note this smoothing is different from the syntactic counterpart.",0,original
We have used the optimal experiment configurations that we had obtained from the fourth experiment series for processing the complete   data set.,0,original
"2Note that sentence extraction does not solve the problem of selecting and ordering summary sentences to form a coherent There are several approaches to modeling document content: simple word frequency-based methods  , graph-based approaches  , as well as more linguistically motivated techniques  .",0,original
"For example, Weeds     took verbs as contexts for nouns in object position: so they regarded two nouns to be similar to the extent that they occur as direct objects of the same set of verbs.",0,original
"In 2004, Conroy   tested Maximal Marginal Relevance   as well as QR decomposition.",0,original
"Since there is no practical way of determining the classification a0 which maximizes this quantity for a given corpus,   use a greedy algorithm which proceeds from the initial classification, performing the merge which results in the least loss in mutual information at each stage.",0,original
8See formula in appendix B. We use   implementation with a minor alteration  see Beigman Klebanov  .,0,original
"Within the NLP community, n-best list ranking has been looked at carefully in parsing, extractive summarization  , and machine translation  , to name a few.",0,original
"In some recent grammar induction and MT work   it has been shown that even a small amount of knowledge about a language, in the form of grammar fragments, treelets or prototypes, can go a long way in helping with the induction of a grammar from raw text or with alignment of parallel corpora.",0,original
"Graph-based algorithms for classification into subjective/objective or positive/negative language units have been mostly used at the sentence and document level  , instead of aiming at dictionary annotation as we do.",0,original
"Recent work on reordering has been on trying to find smart ways to decide word order, using syntactic features such as POS tags   , parse trees   to name just a few, and synchronized CFG  , again to name just a few.",0,original
"As an example of it s application, N-gram co-occurrence is used for evaluating machine translations  .",0,original
"See   for additional work using perceptron algorithms to train tagging models, and a more thorough description of the theory underlying the perceptron algorithm applied to ranking problems.",0,original
Results are reported using lowercase BLEU  .,0,original
"4 Training This section discusses how to extract our translation rules given a triple nullnull,null null ,nullnull . As we know, the traditional tree-to-string rules can be easily extracted from nullnull,null null ,nullnull  using the algorithm of Mi and Huang   2 . We would like  2  Mi and Huang   extend the tree-based rule extraction algorithm   to forest-based by introducing non-deterministic mechanism.",0,original
"A quite different approach from our hypotheses testing implemented in the TREQ-AL aligner is taken by the model-estimating aligners, most of them relying on the IBM models   described in the   seminal paper.",0,original
"Five chunk tag sets, IOB1, IOB2, IOE1, IOE2   and SE  , are commonly used.",0,original
Another motivation to evaluate the performance of a phrase translation model that contains only syntactic phrases comes from recent efforts to built syntactic translation models  .,0,original
"Others, such as Turney  , Pang and Vaithyanathan  , have examined the positive or negative polarity, rather than presence or absence, of affective content in text.",0,original
"We use the default configuration of the measure in WordNet::Similarity-0.12 package  , and, with a single exception, the measure performed below Gic; see BP in table 1.",0,original
"  then extended their method and established a sound probabilistic model series, relying on different parameters describing how words within parallel sentences are aligned to each other.",0,original
7An alternative framework that formally describes some dependency parsers is that of transition systems  .,0,original
"Although some work has been done on syllabifying orthographic forms  , syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes.",0,original
"In the training phase, bilingual parallel sentences are preprocessed and aligned using alignment algorithms or tools such as GIZA++  .",0,original
"Within NLP, applications include sentiment-analysis problems   and content selection for text generation  .",0,original
"From the extracted n-grams, those with a flequc'ncy of 3 or more were kept  ).",0,original
3.2 Word Order Differences Another problem that has been noticed as early as 1993 with the first research on word alignment   concerns the differences in word order between source and target language.,0,original
"Based on this theoretical cornerstone, Cahill and van Genabith   presented a PCFG-based chart generator using wide-coverage LFG approximations automatically extracted from the Penn-II treebank.",0,original
" , and the phrase-based approach to Statistical Machine Translation   has led to the development of heuristics for obtaining alignments between phrases of any number of words.",0,original
In the literature approaches to construction of taxonomies of concepts have been proposed  .,0,original
  was proposed in the original work to solve the LMR Tagging problem.,0,original
Several techniques and results have been reported on learning subcategorization frames   from text corpora  .,0,original
"For our contrast submission, we rescore the first-pass translation lattices with a large zero-cutoff stupid-backoff   language model estimated over approximately five billion words of newswire text.",0,original
2 Related Work A large amount of previous research on clustering has been focused on how to find the best clusters  .,0,original
"Inter-annotator agreement was measured using the kappa   statistics   on 1,502 instances   marked by two annotators who followed specific written guidelines.",0,original
The candidates of unknown words can be generated by heuristic rules  or statistical word models which predict the probabilities for any strings to be unknown words  .,0,original
The ongoing evaluation literature is perhaps most obvious in the machine translation communitys efforts to better BLEU  .,0,original
5 Datasets For evaluation we selected two domain adaptation datasets: spam   and sentiment  .,0,original
"A systematic exploration of a set of such features for proteinprotein interaction extraction was recently provided by Jiang and Zhai  , who also used features derived from the Collins parser.",0,original
"1 Introduction B   was one of the first automatic evaluation metrics for machine translation  , and despite being challenged by a number of alternative metrics  , it remains the standard in the statistical MTliterature.Callison-Burchetal. havesubjected B to a searching criticism, with two realworld case studies of significant failures of correlation between B and human adequacy/fluency judgments.Bothcasesinvolvecomparisonsbetween statistical MT systems and other translation methods  , and they recommend that the use of B be restrictedtocomparisonsbetweenrelatedsystemsor different versions of the same systems.",0,original
"A token can be a word or a punctuation symbol, and each of these neighboring tokens must be in the same sentence as a2 . We use a sentence segmentation program   and a POS tagger   to segment the tokens surrounding a2 into sentences and assign POS tags to these tokens.",0,original
"This program differs from earlier work in its almost complete lack of hand-crafting, relying instead on a very small corpus of Penn Wall Street Journal Tree-bank text   that has been marked with co-reference information.",0,original
"We use a bootstrap approach in which we first extract 1-to-n word alignments using an existing word aligner, and then estimate the confidence of those alignments to decide whether or not the n words have to be grouped; if so, this group is conwould thus be completely driven by the bilingual alignment process   for related considerations).",0,original
"Unlabeled dependencies can be readily obtained by processing constituent trees, such as those in the Penn Treebank  , with a set of rules to determine the lexical heads of constituents.",0,original
"We are encoding the knowledge as axioms in what is for the most part a first-order logic, described by Hobbs  , although quantification over predicates is sometimes convenient.",0,original
"3.2 Maximum Entropy ME models implement the intuition that the best model will be the one that is consistent with the set of constrains imposed by the evidence, but otherwise is as uniform as possible  .",0,original
5 Related Work Dolan   describes a method for clustering word senses with the use of information provided in the electronic version of LDOCE  .,0,original
The parse trees on the English side of the bitexts were generated using a parser   implementing the Collins parsing models  .,0,original
"The model scaling factors 1,,5 and the word and phrase penalties are optimized with respect to some evaluation criterion  , e.g. BLEU score.",0,original
"Given a set of evidences E over all the relevant word pairs, in  , the probabilistic taxonomy learning task is defined as the problem of finding the taxonomy hatwideT that maximizes the 67 probability of having the evidences E, i.e.: hatwideT = arg max T P  In  , this maximization problem is solved with a local search.",0,original
"The interpolation weights a65   are trained using discriminative training   using ROUGEa129 as the objective function, on the development set.",0,original
"For Hw6, students compared their POS tagging results with the ones reported in  .",0,original
1A Normal Form for SITGs can be defined   by analogy to the Chomsky Normal Form for Stochastic ContextFree Grammars.,0,original
"Some of this work focuses on classifying the semantic orientation of individual words or phrases, using linguistic heuristics or a pre-selected set of seed words  .",0,original
"In experiments with the system of   we have found that in practice a large number of complete translations are completely monotonic  , suggesting that the system has difficulty learning exactly what points in the translation should allow reordering.",0,original
" ), concordancing for bilingual lexicography  , computerassisted language learning, corpus linguistics (Melby.",0,original
Phrase-pairs are then extracted from the word alignments  .,0,original
"The translation models they presented in various papers between 1988 and 1993   are commonly referred to as IBM models 15, based on the numbering in Brown, Della Pietra, Della Pietra, and Mercer  .",0,original
"In this method, each training sentence is decoded and weights are updated at every iteration  .",0,original
he formally syntax-based model for SMT was first advocated by Wu  ,0,original
"In order to generate a value for each target-side factor, we use a sequence of mapping steps similar to Koehn and Hoang  .",0,original
"We will briefly review the perceptron algorithm, and its convergence properties  see Collins   for a full description.",0,original
"In phrase-based SMT systems  , foreign sentences are firstly segmented into phrases which consists of adjacent words.",0,original
"Maximum entropy   models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation  , parsing, POS tagging and PP attachment  , machine translation  , and FrameNet classification  .",0,original
" , a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions  .",0,original
"In batch mode, OpinionFinder parses the data again, this time to obtain constituency parse trees  , which are then converted to dependency parse trees  .",0,original
The results were evaluated using the CoNLL shared task evaluation tools 5 . The approaches tested were Error Driven Pruning     and Transformational Based Learning of IOB tagging    .,0,original
Antonyms often indicate the discourse relation of contrast  .,0,original
"Besides the the case-sensitive BLEU-4   used in the two experiments, we design another evaluation metrics Reordering Accuracy   for forced decoding evaluation.",0,original
"Bilingual alignments have so far shown that they can play multiple roles in a wide range of linguistic applications, such as computer assisted translation  , terminology   lexicography  , and cross-language information retrieval  , via the Agence de la francophonie (http://~.",0,original
"For instance, Pang and Lee   train an independent subjectivity classifier to identify and remove objective sentences from a review prior to polarity classification.",0,original
"Once this is accomplished, a variant of Powells algorithm is used to find weights that optimize BLEU score   over these hypotheses, compared to reference translations.",0,original
The precision rate using the lexical statistics approach can reach around 60% if both word bi-gram extraction and n-gram extractions are taking into account  .,0,original
"Even though there are some studies that compare the results from statistically computed association measures with word association norms from psycholinguistic experiments   there has not been any research on the usage of a digital, network-based dictionary reflecting the organisation of the mental lexicon to our knowledge.",0,original
"As was demonstrated in  , even a minimal set of local explicit features achieves results which are non-significantly different from a carefully chosen set of explicit features, given the language independent definition of locality described in section 2.",0,original
History-based models for predicting the next parser action   3.,0,original
"Building upon the large body of research to improve tagging performance for various languages using various models  ) and the recent work on PCFG grammars with latent annotations  , we will investigate the use of fine-grained latent annotations for Chinese POS tagging.",0,original
"Finally, recent work has explored learning to map sentences to lambda-calculus meaning representations  .",0,original
"For instance, for Maximum Entropy, I picked   for the basic theory,   for an application  , and   for more advanced topics such as optimization and smoothing.",0,original
We apply a maximum entropy   model   to this task.,0,original
"As an additional baseline, we compare against a phrasal SMT decoder, Pharaoh  .",0,original
Minimum error-rate   training   was applied to obtain weights   for these features.,0,original
Domain adaptation deals with these feature distribution changes  .,0,original
"summarization  , paraphrasing  , natural language generation  , and language modeling  .",0,original
"Banko and Etzioni   studied open domain relation extraction, for which they manually identified several common relation patterns.",0,original
"However, few papers in the field of computational linguistics have focused on this approach  .",0,original
"80 8.0% Positive child education Positive cost Negative SUBJECT increase Figure 3: An example of a word-polarity lattice Various methods have already been proposed for sentiment polarity classification, ranging from the use of co-occurrence with typical positive and negative words   to bag of words   and dependency structure  .",0,original
"The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns  .",0,original
The clusters were found automatically by attempting to minimize perplexity  .,0,original
They can be seen as extensions of the simpler IBM models 1 and 2  .,0,original
"To date, researchers have harvested, with varying success, several resources, including concept lists  , topic signatures  , facts  , and word similarity lists  .",0,original
6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances  ; these methods do not address attributes directly.,0,original
The Decision List   algorithm is described in  .,0,original
"2.4 Formalization of   As mentioned earlier, our model is equivalent to that presented in  , and can be viewed as a formal version of his model.2 In his presentation, the adapation is done through feature augmentation.",0,original
"Related Works Generally speaking, approaches to MWE extraction proposed so far can be divided into three categories: a) statistical approaches based on frequency and co-occurrence affinity, b) knowledgebased or symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods  .",0,original
"Wu   modeled the reordering process with binary branching trees, where each production could be either in the same or in reverse order going from source to target language.",0,original
"2 Latent Variable Parsing In latent variable parsing  , we learn rule probabilities on latent annotations that, when marginalized out, maximize the likelihood of the unannotated training trees.",0,original
"One solution would be to apply the maximum entropy estimation technique  ) to all of the three components of the SLM, or at least to the CONSTRUCTOR.",0,original
"Given the probabilistic taxonomy learning model introduced by  , we leverage on the computation of logistic regression to exploit singular value decomposition   as unsupervised feature selection.",0,original
"However, Klein and Manning   showed that for natural language and text processing tasks, conditional models are usually better than joint likelihood models.",0,original
The L1 or L2 norm is commonly used in statistical natural language processing  .,0,original
"1 Introduction Aligning parallel text, i.e. automatically setting the sentences or words in one text into correspondence with their equivalents in a translation, is a very useful preprocessing step for a range of applications, including but not limited to machine translation  , cross-language information retrieval  , dictionary creation   and induction of NLP-tools  .",0,original
Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm  .,0,original
Close to the problem studied here is Jing and McKeowns   cut-and-paste method founded on EndresNiggemeyers observations.,0,original
"For getting the syntax trees, the latest version of Collins parser   was used.",0,original
O'Hara and Wiebe   make use of Penn Treebank   and FrameNet   to classify prepositions.,0,original
"An early exception to this was   itself, where Model 2 used function tags during the training process for heuristics to identify arguments  .",0,original
The disambiguation model of this parser is based on a maximum entropy model  .,0,original
"These dependencies differ from those used by Liu and Gildea  , in that they are extracted according to the rules of the LFG grammar and they are labelled with a type of grammatical relation that connects the head and the modifier, such as subject, determiner, etc. The presence of grammatical relation labels adds another layer of important linguistic information into the comparison and allows us to account for partial matches, for example when a lexical item finds itself in a correct relation but with an incorrect partner.",0,original
arletta   and Ros6   point out the importance of taking into account the expected chance agreement among judges when computing whether or not judges agree significantly,0,original
n alternative training criterion therefore directly optimizes translation quality as measured by an automatic evaluation criterion  ,0,original
The training is performed by a single generalized perceptron  .,0,original
Unknown words were not identified in   as a useful predictor for the benefit of self-training.,0,original
These probabilities are estimated with IBM model 1   on parallel corpora.,0,original
The alignment of sentences can be done sufficiently well using cues such as sentence length   or cognates  .,0,original
"Examples of this work include a system by Liu et al  , and experiments by Hindle and Rooth  , and Resnik and Hearst  .2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems.",0,original
here have been many approaches to compute the similarity between words based on their distribution in a corpus  ,0,original
Results for chunking Penn Treebank data were previously presented by several authors  .,0,original
"As Marcu and Echihabi   point out, WordNet does not encode antonymy across part-of-speech  .",0,original
The last row shows the results for the feature augmentation algorithm  .,0,original
"It has been shown repeatedly--e.g. , Briscoe and Carroll  , Charniak  , Collins  , Inui et al.",0,original
"In the results we describe here, we use mutual information   as the metric for neighbourhood pruning, pruning which occurs as the network is being generated.",0,original
"To set the weights, m, we carried out minimum error rate training   using BLEU   as the objective function.",0,original
"Tillmann and Zhang   used a different update style based on a convex loss function:  = L max parenleftBig 0, 1 parenleftBig si si  parenrightBigparenrightBig 768 Table 1: Experimental results obtained by varying normalized tokens used with surface form.",0,original
The loglinear model feature weights were learned using minimum error rate training     with BLEU score   as the objective function.,0,original
Maximum Entropy Modeling     and Support Vector Machine     were used to build the classifiers in our solution.,0,original
t also contains tools for tuning these models using minimum error rate training   and evaluating the resulting translations using the BLEU score  ,0,original
"For example, consider a case of observation bias   for a first-order left-toright CMM.",0,original
"This is based on the idea from   that rare words in the training set are similar to unknown words in the test set, and can be used to learn how to tag the unknown words that will be encountered during testing.",0,original
"We trained three Arabic-English syntax-based statistical MT systems   using max-B training  : one on a newswire development set, one on a weblog development set, and one on a combined development set containing documents from both genres.",0,original
"N-best results for phrasal alignment and ordering models in the decoder were optimized by lambda training via Maximum Bleu, along the lines described in  .",0,original
"Pearsons correlation coefficient is a standard measure of the correlation strength between two distributions; it can be calculated as follows:  = E  E E radicalbigE    2   where X =   and Y =   are vectors of numerical scores for each paraphrase provided by the humans and the competing systems, respectively, n is the number of paraphrases to score, and E  is the expectation of X. Cosine correlation coefficient is another popular alternative and was used by Nakov and Hearst  ; it can be seen as an uncentered version of Pearsons correlation coefficient:  = X.YbardblXbardblbardblYbardbl   Spearmans rank correlation coefficient is suitable for comparing rankings of sets of items; it is a special case of Pearsons correlation, derived by considering rank indices   as item scores . It is defined as follows:  = n summationtextx iyi    radicalBig nsummationtextx2i   2 radicalBig nsummationtexty2i   2   One problem with using Spearmans rank coefficient for the current task is the assumption that swapping any two ranks has the same effect.",0,original
"For example, the word alignment computed by GIZA++ and used as a basis to extract the TTS templates in most SSMT systems has been observed to be a problem for SSMT  , due to the fact that the word-based alignment models are not aware of the syntactic structure of the sentences and could produce many syntax-violating word alignments.",0,original
"Due to advances in statistical syntactic parsing techniques  , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences.",0,original
"However, in the experiments described here, we focus on alignment at the level of sentences, this for a number of reasons: First, sentence alignments have so far proven their usefulness in a number of applications, e.g. bilingual lexicography  , automatic translation verification   and the automatic acquisition of knowledge about translation  .",0,original
"Many studies and improvements have been conducted for  Presently with Service Media Laboratory, Corporate ResearchandDevelopmentCenter, OkiElectricIndustry Co. ,Ltd. POS tagging, and major methods of POS tagging achieve an accuracy of 9697% on the Penn Treebank WSJ corpus, but obtaining higher accuracies is difficult  .",0,original
"The learning algorithm used is the IB1 algorithm   with k = 5, i.e. classification based on 5 nearest neighbors.4 Distances are measured using the modified value difference metric     for instances with a frequency of at least 3  , and classification is based on distance weighted class voting with inverse distance weighting  .",0,original
TheChinesesentencefromtheselected pair is used as the single reference to tune and evaluate the MT system with word-based BLEU-4  .,0,original
"This fact, along with the observation that machine translation quality improves as the amount of monolingual training material increases, has lead to the introduction of randomised techniques for representing large LMs in small space  .",0,original
"1 Yarowsky   proposes a method for word sense   disambiguation that is based on a bootstrapping technique, which we refer to here as Monolingual Bootstrapping  .",0,original
4.2 Adaptation to Chinese  s algorithm   only resolves certain NLDs with known types of antecedents   at fstructures.,0,original
"In contrast to the opinion extracts produced by Pang and Lee  , our summaries are not text extracts, but rather explicitly identify and 337 characterize the relations between opinions and their sources.",0,original
"From this aligned training corpus, we extract the phrase pairs according to the heuristics in  .",0,original
urney   has recently proposed a simpler SVM-based algorithm for analogical classification called PairClass,0,original
"The need for some way to model aspects of syntactic behavior, such as the tendency of constituents to move together as a unit, is widely recognizedthe role of syntactic units is well attested in recent systematic studies of translation  , and their absence in phrase-based models is quite evident when looking at MT system output.",0,original
"Unfortunately, longer sentences  , longer phrases  , two LMs  , higher-order LMs  , multiple higher-order lexicalized re-ordering models  , etc. all contributed to increased system?s complexity, and, as a result, time limitations prevented us from performing minimum-error-rate training     for ucb3, ucb4 and ucb5.",0,original
e borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff  ,0,original
"These relations are then used for various tasks, ranging from the interpretation of a noun sequence   or a prepositional phrase  , to resolving structural ambiguity  , to merging dictionary senses for WSD  .",0,original
"5 Phrase Pair Induction A common approach to phrase-based translation is to extract an inventory of phrase pairs   from bitext  , For example, in the phraseextract algorithm  , a word alignment am1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : am1 : aj    .",0,original
It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values  .,0,original
For evaluation we use a state-of-the-art baseline system     which works with a log-linear interpolation of feature functions optimized by MERT  .,0,original
"This definition is similar to that of minimal translation units as described in Quirk and Menezes  , although they allow null words on either side.",0,original
indle   grouped nouns into thesaurus-like lists based on the similarity of their syntactic contexts,0,original
Some papers   based on Smadja's paradigm   learned an aided dictionary from a corpus to reduce the possibility of unknown words.,0,original
"In order to improve sentence-level evaluation performance, several metrics have been proposed, including ROUGE-W, ROUGE-S   and METEOR  .",0,original
"We observe that the tagging method exploits the one sense per collocation property  , which means that WSD based on collocations is probably finer than WSD based on simple words, since ambiguity is reduced  .",0,original
Feature-based methods   use pre-defined feature sets to extract features to train classification models.,0,original
"Expectation Maximization does surprisingly well on larger data sets and is competitive with the Bayesian estimators at least in terms of cross-validation accuracy, confirming the results reported by Johnson  .",0,original
"In a factored translation model other factors than surface form can be used, such as lemma or part-of-speech  .",0,original
"Finally, the fourth and fifth feature functions corresponded to two lexicon models based on IBM Model 1 lexical parameters p   .",0,original
"A hierarchical alignment algorithm is a type of synchronous parser where, instead of constraining inferences by the production rules of a grammar, the constraints come from word alignments and possibly other sources  .",0,original
"Using a vector-based topic identification process  , these keywords are used to determine a set of likely values   for that attribute.",0,original
"Like the data used by  , this data was retagged by the Brill tagger in order to obtain realistic part-of-speech   tags 3.",0,original
"Using the components of the row-vector bm as feature function values for the candidate translation em  , the system prior weights  can easily be trained using the Minimum Error Rate Training described in  .",0,original
"One option is what Johnson   calls many-to-one   accuracy, in which each induced tag is labeled with its most frequent gold tag.",0,original
  study the shortest hyperpath problem and Nielsen et al,0,original
"Given an input sentence x, the correct output segmentation F  satisfies: F  = argmax yGEN  Score  where GEN  denotes the set of possible segmentations for an input sentence x, consistent with notation from Collins  .",0,original
"Minimum-error-rate training   are conducted on dev-set to optimize feature weights maximizing the BLEU score up to 4grams, and the obtained feature weights are blindly applied on the test-set.",0,original
Several representations to encode region information are proposed and examined  .,0,original
"The text was split at the sentence level, tokenized and PoS tagged, in the style of the Wall Street Journal Penn TreeBank  .",0,original
"2 Background: Overview of BLEU This section briefly describes the original BLEU  1, which was designed for English translation evaluation, so English sentences are used as examples in this section.",0,original
"Similar to Goldwater and Griffiths   and Johnson  , Toutanova and Johnson   also use Bayesian inference for POS tagging.",0,original
"But Koehn, Och, and Marcu   find that phrases longer than three words improve performance little for training corpora of up to 20 million words, suggesting that the data may be too sparse to learn longer phrases.",0,original
The WordNet::Similarity package   implements this distance measure and was used by the authors.,0,original
"Furthermore, use of the self-training techniques described in   raise this to 87.8%   again without any use of labeled Brown data.",0,original
"In the context of statistical machine translation  , we may interpretE as an English sentence, F its translation in French, and A a representation of how the words correspond to each other in the two sentences.",0,original
"We use the finite-state parses of FaSTU$   for recognizing these entities, but the method extends to any basic phrasal parser 4.",0,original
dependency lengths: Long-distance dependencies exhibit bad performance  .,0,original
"4 Relation to Previous Work There is a significant volume of work exploring the use of CRFs for a variety of chunking tasks, including named-entity recognition, gene prediction, shallow parsing and others  .",0,original
"We build phrase translations by first acquiring bidirectional GIZA++   alignments, and using Moses grow-diag alignment symmetrization heuristic.1 We set the maximum phrase length to a large value  , because some segmenters described later in this paper will result in shorter 1In our experiments, this heuristic consistently performed better than the default, grow-diag-final.",0,original
This has been shown both in supervised settings   and unsupervised settings   in which constraints are used to bootstrap the model.,0,original
"Pereira et al. , Curran and Moens   and Lin   use syntactic features in the vector definition.",0,original
Note that all systems were optimized using a non-deterministic implementation of the Minimum Error Rate Training described in  .,0,original
"These forest rescoring algorithms have potential applications to other computationally intensive tasks involving combinations of different models, for example, head-lexicalized parsing  ; joint parsing and semantic role labeling  ; or tagging and parsing with nonlocal features.",0,original
We set all feature weights by optimizing Bleu   directly using minimum error rate training     on the tuning part of the development set  .,0,original
"For example, bilingual lexicographers can use bitexts to discover new cross-language lexicalization patterns  ; students of foreign languages can use one half of a bitext to practice their reading skills, referring to the other half for translation when they get stuck  .",0,original
"A related method is multi-category perceptron, which explicitly finds a weight vector that separates correct labels from the incorrect ones in a mistake driven fashion  .",0,original
"MXPOST  , and in order to discover more general patterns, we map the tag set down after tagging, e.g. NN, NNP, NNPS and NNS all map to NN.",0,original
"The 45 stochastic word mapping is trained on a FrenchEnglish parallel corpus containing 700,000 sentence pairs, and, following Liu and Gildea  , we only keep the top 100 most similar words for each English word.",0,original
"Wu and Weld   and Cucerzan   calculate the overlap between contexts of named entities and candidate articles from Wikipedia, using overlap ratios or similarity scores in a vector space model, respectively.",0,original
  proposed a new algorithm for parameter estimation as an alternate to CRF.,0,original
Alignment models to structure the translation model are introduced in  .,0,original
ence we use a beam-search decoder during training and testing; our idea is similar to that of Collins and Roark   who used a beam-search decoder as part of a perceptron parsing model,0,original
2 Experimental System and Data HMIHY is a spoken dialogue system based on the notion of call routing  .,0,original
Sentiment classification at the sentence-level has also been studied  .,0,original
"They are not used in LN, but they are known to be useful for WSD  .",0,original
" , Walker  , Fink and Biermann  , Mudler and Paulus  , Carbonell and Pierrel  , Young  , and Young et al.",0,original
"The first one, GIZA-Lex, is obtained by running the GIZA++2 implementation of the IBM word alignment models   on the initial parallel corpus.",0,original
EM-HMM tagger provided with good initial conditions   91.4*   Figure 1: Previous results on unsupervised POS tagging using a dictionary   on the full 45-tag set.,0,original
"Hence, either the best translation hypothesis is directly extracted from the word graph and output, or an N-best list of translations is computed  .",0,original
"We compared a baseline system, the state-of-the-art phrase-based system Pharaoh  , against our system.",0,original
"Of course, many applications require smoothing of the estimated distributionsthis problem also has known solutions in MapReduce  .",0,original
"Any linguistic annotation required during the extraction process, therefore, is produced through automatic means, and it is only for reasons of accessibility and comparability with other research that we choose to work over the Wall Street Journal section of the Penn Treebank  .",0,original
5 Related Work Automatically finding sentences with the same meaning has been extensively studied in the field of automatic paraphrasing using parallel corpora and corporawith multiple descriptionsof the same events  .,0,original
is a WordNet based relatedness measure  .,0,original
The maximum entropy models used here are similar in form to those in  .,0,original
"Some of these have been previously employed for various tasks by Gabrilovich and Markovitch,  ; Overell and Ruger  , Cucerzan  , and Suchanek et al.",0,original
"Most work on discriminative training for SMT has focussed on linear models, often with margin based algorithms  , or rescaling a product of sub-models  .",0,original
We would like to apply our learning approach to the large data set mentioned in  : Wall Street Journal corpus sections 2-21 as training material and section 0 as test material.,0,original
"7 Discussion As we mentioned, there are some algorithms similar to ours  .",0,original
6 The Experiments We used the Penn Treebank   to perform empirical experiments on the proposed parsing models.,0,original
"Our evaluation metrics are BLEU   and NIST, which are to perform caseinsensitive matching of n-grams up to n = 4.",0,original
"Our experience suggests that disjunctive LFs are an important capability, especially as one seeks to make grammars reusable across applications, and to employ domain-specific, sentence-level paraphrases  .",0,original
"As a final note, following Collins  , we used the averaged parameters from the training algorithm in decoding test examples in our experiments.",0,original
"1.2 Recent work A few publications, so far, deal with POS-tagging of Northern Sotho; most prominently, de Schryver and de Pauw   have presented the MaxTag method, a tagger based on Maximum Entropy 38 Learning   as implemented in the machine learning package Maxent  .",0,original
"Usually the IBM Model 1, developed in the statistical machine translation field  , is used to construct translation models for retrieval purposes in practice.",0,original
The WordNet::Similarity package provides a flexible implementation of many of these measures  .,0,original
We also compared the cluster gazetteers with the Wikipedia gazetteer constructed by following the method of  .,0,original
We describe the experiment in greater detail 2The particular verbs selected were looked up in   and the class for each verb in the classification system defined in   was selected with some discussion with linguists.,0,original
  proposed using GIZA++   to align words between the backbone and hypothesis.,0,original
"To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P , as in  , by using the same set of features as in ME. Table 3 shows precision, recall, and F1measure of each system for WordNet hypernyms  , WordNet meronyms   and ODP hypernyms  .",0,original
It is also related to loglinear models for machine translation  .,0,original
"To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank  , is annotated primarily with constituent analysis.",0,original
"At the same time, grammar theoreticians have proposed various generative synchronous grammar formalisms for MT, such as Synchronous Context Free Grammars     or Synchronous Tree Adjoining Grammars    .",0,original
"Alignment performance is measured by the Alignment Error Rate     AER  = 12|B B|/  where B is a set reference word links, and B are the word links generated automatically.",0,original
2.2 The Choice of Co-occurrence ~qeasure and Matrix Distance There :~:c many alternatives to measure cooccurrence between two words x and y  .,0,original
3.1.2 Kappa Kappa   is an evaluation measure which is increasingly used in NLP annotation work  .,0,original
"For a detailed description of each algorithm, readers are referred to Collins   for the boosting algorithm, Collins   for perceptron learning, and Gao et al.",0,original
P chunks   and technical terms   fall into this difficult-toassess category,0,original
The data for all our experiments was extracted from the Penn Treebank II Wall Street Journal   corpus  .,0,original
illmann and Zhang   present a procedure to directly optimize the global scoring function used by a phrasebased decoder on the accuracy of the translations,0,original
Our approach is based on earlier work on LFG semantic form extraction   and recent progress in automatically annotating the Penn-II and Penn-III Treebanks with LFG f-structures  .,0,original
" ; we also introduce an approach related to the conditional log-linear models of Ratnaparkhi, Roukos, and Ward  , Papineni, Roukos, and Ward  , Johnson et al.",0,original
"Set Test Set ENGLISH-WSJ Sections Section 22 Section 23   2-21 ENGLISH-BROWN see 10% of 10% of the   ENGLISH-WSJ the data6 the data6 FRENCH7 Sentences Sentences Sentences   1-18,609 18,610-19,609 19,609-20,610 GERMAN Sentences Sentences Sentences   1-18,602 18,603-19,602 19,603-20,602 Table 1: Corpora and standard experimental setups.",0,original
"2 Related Work There is a number of publications dealing with various automatic evaluation measures for machine translation output, some of them proposing new measures, some proposing improvements and extensions of the existing ones  .",0,original
"We are already using the extracted semantic forms in parsing new text with robust, wide-coverage PCFG-based LFG grammar approximations automatically acquired from the f-structure annotated Penn-II treebank  .",0,original
"The results were evaluated using the character/pinyin-based 4-gram BLEU score  , word error rate  , position independent word error rate  , and exact match  .",0,original
Work in   modeled the limited information available at phrase-boundaries.,0,original
"There have been considerable amount of efforts to improve the reordering model in SMT systems, ranging from the fundamental distance-based distortion model  , flat reordering model  , to lexicalized reordering model  , hierarchical phrase-based model  , and maximum entropy-based phrase reordering model  .",0,original
"In previous alignment methods, some researchers modeled the alignments with different statistical models  .",0,original
"Statistical machine translation is based on the noisy channel model, where the translation hypothesis is searched over the space defined by a translation model and a target language  .",0,original
"We evaluate the string chosen by the log-linear model against the original treebank string in terms of exact match and BLEU score   DEF ATTR ADJ definite descriptions with adjectival modifier DEF GENARG definite descriptions with a genitive argument DEF PPADJ definite descriptions with a PP adjunct DEF RELARG definite descriptions including a relative clause DEF APP definite descriptions including a title or job description as well as a proper name   Names PROPER combinations of position/title and proper name   BARE PROPER bare proper names Demonstrative descriptions SIMPLE DEMON simple demonstrative descriptions MOD DEMON adjectivally modified demonstrative descriptions Pronouns PERS PRON personal pronouns EXPL PRON expletive pronoun REFL PRON reflexive pronoun DEMON PRON demonstrative pronouns   GENERIC PRON generic pronoun   DA PRON da-pronouns   LOC ADV location-referring pronouns TEMP ADV,YEAR Dates and times Indefinites SIMPLE INDEF simple indefinites NEG INDEF negative indefinites INDEF ATTR indefinites with adjectival modifiers INDEF CONTRAST indefinites with contrastive modifiers   INDEF PPADJ indefinites with PP adjuncts INDEF REL indefinites with relative clause adjunct INDEF GEN indefinites with genitive adjuncts INDEF NUM measure/number phrases INDEF QUANT quantified indefinites Table 5: An inventory of interesting syntactic characteristics in IS phrases Label 1   Label 2   B/A Total D-GIVEN-PRONOUN INDEF-REL 0 19 PERS PRON 39 INDEF ATTR 23 DA PRON 25 SIMPLE INDEF 17 DEMON PRON 19 GENERIC PRON 11 D-GIVEN-PRONOUN D-GIVEN-CATAPHOR 0.1 11 PERS PRON 39 SIMPLE DEF 13 DA PRON 25 DA PRON 10 DEMON PRON 19 GENERIC PRON 11 D-GIVEN-REFLEXIVE NEW 0.11 31 REFL PRON 54 SIMPLE INDEF 113 INDEF ATTR 53 INDEF NUM 32 INDEF PPADJ 26 INDEF GEN 25  Table 6: IS asymmetric pairs augmented with syntactic characteristics 822 2002).",0,original
Much research has been carried out recently in this area  .,0,original
"Thus, one conclusion from that line of work is that as soon as there is a reasonable   amount of labeled target data, it is often more fruitful to either just use that, or to apply simple adaptation techniques  .",0,original
"Based on this assumption,   stored all bigrams of words along with their relative position.",0,original
"We build sentencespecific zero-cutoff stupid-backoff   5-gram language models, estimated using 4.7B words of English newswire text, and apply them to rescore either 10000-best lists generated by HCP or word lattices generated by HiFST.",0,original
"Unfortunately, as was shown by Fraser and Marcu   AER can have weak correlation with translation performance as measured by BLEU score  , when the alignments are used to train a phrase-based translation system.",0,original
he algorithm is similar to the perceptron algorithm described in Collins  ,0,original
BLEU   is one of the methods for automatic evaluation of translation quality.,0,original
Linear weights are assigned to each of the transducers features using an averaged perceptron for structure prediction  .,0,original
"2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh,  , which is based on a log-linear formulation  .",0,original
"It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance  .",0,original
"4.2 Building a Human Performance Model We adopt the evaluation approach that a good content selection strategy should perform similarly to humans, which is the view taken by existing summarization evaluation schemes such as ROUGE   and the Pyramid method  .",0,original
"These distributions are modeled using a maximum entropy formulation  , using training data which consists of human judgments of question answer pairs.",0,original
The likelihood ratio is obtained by treating word and Ic as a bigram and computed with the formula in  .,0,original
he basic phrase-based model is an instance of the noisy-channel approach  ,0,original
"Since the lexical translations and dependency paths are typically not labeled in the English corpus, a given pair must be counted fractionally according to its posterior probability of satisfying these conditions, given models of contextual translation and English parsing.3 3Similarly, Jansche   imputes missing trees by using comparable corpora.",0,original
"Our work so far has focused on data in the Penn Treebank  , particularly the Brown corpus and some examples from the Wall Street Journal corpus.",0,original
he Penn Wall Street Journal treebank   was used as training and test data,0,original
Sentiment classification is a well studied problem   and in many domains users explicitly 1We use the term aspect to denote properties of an object that can be rated by a user as in Snyder and Barzilay  .,0,original
"accuracy Training data Turney   66% unsupervised Pang & Lee   87.15% supervised Aue & Gamon   91.4% supervised SO 73.95% unsupervised SM+SO to increase seed words, then SO 74.85% weakly supervised Table 7: Classification accuracy on the movie review domain Turney   achieves 66% accuracy on the movie review domain using the PMI-IR algorithm to gather association scores from the web.",0,original
"The largest corpus that Goldwater and Griffiths   studied contained 96,000 words, while Johnson   used all of the 1,173,766 words in the full Penn WSJ treebank.",0,original
Six features from   were used as baseline features.,0,original
"PairClass is most similar to the algorithm of Turney  , but it differs in the following ways:  PairClass does not use a lexicon to find synonyms for the input word pairs.",0,original
"The latter group did an experiment early on in which they found that manual tagging took about twice as long as correcting  , with about twice the interannotator disagreement rate and an error rate that was about 50% higher  .",0,original
"Appendix B gives a sketch of one such approach, which is based on results from Collins, Schapire, and Singer  .",0,original
"In this paper it is shown that the synchronous grammars used in Wu  , Zhang et al.",0,original
"We design special inference algorithms, instead of general-purpose inference algorithms used in previous works  , by taking advantage of special properties of our task.",0,original
1.2 Decoding in Statistical Machine Translation   and   have discussed the first two of the three problems in statistical machine translation.,0,original
Other authors have applied this approach to language modeling  .,0,original
"Here, we train word alignments in both directions with GIZA++  .",0,original
"In fact, it has already been established that sentence level classification can improve document level analysis  .",0,original
" , who retrain the Ratnaparkhi   tagger and reach accuracies of 93% using CTB-I.",0,original
"Hindle   proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of """"similar"""" events that have been seen.",0,original
4 Using vector-based models of semantic representation to account for the systematic variances in neural activity 4.1 Lexical Semantic Representation Computational linguists have demonstrated that a words meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs  .,0,original
Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation  .,0,original
WSD has received increasing attention in recent literature on computational linguistics  .,0,original
"For our POS tagging experiments, we used the Wall Street Journal in PTB III   with the same data split as used in  .",0,original
"Additionally, we present results of the tagger on the NEGRA corpus   and the Penn Treebank  .",0,original
ujii and Ishikawa   also work with arguments,0,original
"  follow   in using the noisy channel model, by decomposing the translation decisions modeled by the translation model into different types, and inducing probability distributions via maximum likelihood estimation over each decision type.",0,original
"Some researchers   targeted nouns, noun phrases and verb phrases.",0,original
"Table 1 shows the impact of increasing reordering window length   on translation quality for the ?dev06??data.2 Increasing the reordering window past 2 has minimal impact on translation quality, implying that most of the reordering effects across Spanish and English are well modeled at the local or phrase level.",0,original
"The reordered sentence is then re-tokenized to be consistent with the baseline system, which uses a different tokenization scheme that is more friendly to the MT system.3 We use BLEU scores as the performance measure in our evaluation  .",0,original
"The concept of baseNP has undergone a number of revisions   but has previously always been tied to extraction from a more completely annotated treebank, whose annotations are subject to other pressures than just initial material up to the head . To our knowledge, our gures for inter-annotator agreement on the baseNP task itself 169   are the rst to be reported.",0,original
Doing joint inference instead of taking a pipeline approach has also been shown useful for other problems  ).,0,original
We then piped the text through a maximum entropy sentence boundary detector   and performed text normalization using NSW tools  .,0,original
"Proceedings of the 22nd International Conference on Computational Linguistics  , pages 585592 Manchester, August 2008 Random Restarts in Minimum Error Rate Training for Statistical Machine Translation Robert C. Moore and Chris Quirk Microsoft Research Redmond, WA 98052, USA bobmoore@microsoft.com, chrisq@microsoft.com Abstract Ochs   minimum error rate training   procedure is the most commonly used method for training feature weights in statistical machine translation   models.",0,original
"Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF  , mutual information    , conditional probabilities  , chi-square test, and the loglikelihood ratio  .",0,original
"We have used three different algorithms: the nearest neighbour algorithm IB1IG, which is part of the Timbl software package  , the decision tree learner IGTREE, also from Timbl, and C5.0, a commercial version of the decision tree learner C4.5  .",0,original
They can be used for discriminative training of reordering models  .,0,original
"However, because these estimates are too sparse to be relied upon, we use interpolated estimates consisting of mixtures of successively lowerorder estimates  .",0,original
"2.3 Perceptron Learning As learning algorithm, we use Perceptron tailored for structured scenarios, proposed by Collins  .",0,original
"Following Lin  , we use syntactic dependencies between words to model their semantic properties.",0,original
"Candidate term Segment result of GPWS for one sentence, in which term appears Table 2: Examples of candidates eliminated by GPWS 5 Relative frequency ratio against background corpus Relative frequency ratio   is a useful method to be used to discover characteristic linguistic phenomena of a corpus when compared with another  .",0,original
"Similar to WSD, Carpuat and Wu   used contextual information to solve the ambiguity problem for phrases.",0,original
Policy #Shift #Left #Right Start over 156545 26351 27918 Stay 117819 26351 27918 Step back 43374 26351 27918 Table 1: The number of actions required to build all the trees for the sentences in section 23 of Penn Treebank   as a function of the focus point placement policy.,0,original
"5 Related Work Although there have been many studies on collocation extraction and mining using only statistical approaches  , there has been much less work on collocation acquisition which takes into account the linguistic properties typically associated with collocations.",0,original
"These tags are drawn from a tagset which is constructed by 363 extending each argument label by three additional symbols a80a44a81a83a82a84a81a86a85, following  .",0,original
" , Ponzetto and Strube   and the exploitation of advanced techniques that involve joint learning  ) and joint inference  ) for coreference resolution and a related extraction task.",0,original
"  do not use a feature selection technique, employing instead an objective function which includes a Table 4 Values of Savings   for various values of a, b. ab Savings   1100,000 2,692.7 110 48.6 11100 83.5 1011,000 280.0 1,00110,000 1,263.9 10,00150,000 2,920.2 50,001100,000 4,229.8 Collins and Koo Discriminative Reranking for NLP Gaussian prior on the parameter values, thereby penalizing parameter values which become too large: a C3  arg min a  LogLossa X k0:::m a 2 k 7 2 k  28 Closed-form updates under iterative scaling are not possible with this objective function; instead, optimization algorithms such as gradient descent or conjugate gradient methods are used to estimate parameter values.",0,original
"The best prosodic label sequence is then, L = argmax L nproductdisplay i P    To estimate the conditional distribution P  we use the general technique of choosing the maximum entropy   distribution that estimates the average of each feature over the training data  .",0,original
u   and Jones and Havrilla   have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree constituents,0,original
"3 Previous Work on Subjectivity Tagging In previous work  , a corpus of sentences from the Wall Street Journal Treebank Corpus   was manually anno- tated with subjectivity classifications by multiple judges.",0,original
"3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure   Verb and Preposition Databases  , the Brown Corpus section of the Penn Treebank  , an English morphological analysis lexicon developed for PC-Kimmo    , NOMLEX  , Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmers errors, see  .",0,original
  approached chucking by using Transformation Based Learning .,0,original
"But if one limits the information used for disambiguation of the PPattachment to include only the verb, the noun representing its object, the preposition and the main noun in the PP, the accuracy for human decision degrades from 93.2% to 88.2%   on a dataset extracted from Penn Treebank  .",0,original
"Similar to  , each word in the confusion network is associated with a word posterior probability.",0,original
"Still, however, such techniques often require seeds, or prototypes  ) which are used to prune search spaces or direct learners.",0,original
"We directly model the conditional probability of the alignment a, given x and y, using the maximum entropy framework  , P  = exp{F }summationdisplay aC  exp{F } .",0,original
"We presented some theoretical arguments for not limiting extraction to minimal rules, validated them on concrete examples, and presented experiments showing that contextually richer rules provide a 3.63 BLEU point increase over the minimal rules of  .",0,original
"The evaluation results also confirm the argument of Dunning  , who suggested G2 as a more robust alternative to X2.",0,original
"First, we can construct an infinite number of more specialized PCFGs by splitting or refining the PCFGs nonterminals into increasingly finer states; this leads to the iPCFG or infinite PCFG  .",0,original
"Mutual Informatio n Church and Hanks   discussed the use of the mutual information statistics as a way to identify a variety of interesting linguistic phenomena, ranging from semanti c relations of the doctor/nurse type   to lexico-syntactic co-occurrence preferences between verbs and prepositions  .",0,original
"In our approach, we take into account both the relative positions of the nearby context words as well as the mutual information   associated with the occurrence of a particular context word.",0,original
"Various approaches to word sense division have been proposed in the literature on WSD, including   sense numbers in every-day dictionaries  ,   automatic or hand-crafted clusters of dictionary senses (Dolan 1994; Bruce and Wiebe 1995; Luk * Department of Computer Science, National Tsing Hua University, Hsinchu 30043, Taiwan, ROC.",0,original
ang and Lee   frame the problem of detecting subjective sentences as finding the minimum cut in a graph representation of the sentences,0,original
"First, hierarchical word clusters are derived from unlabeled data using the Brown et al. clustering algorithm  .",0,original
Each dataset consisted of a collection of flat rules such as Sput!NP put NP PP extracted from the Penn Treebank  .,0,original
"4 Dependency Parsing: Baseline 4.1 Learning Model and Features According to  , all data-driven models for dependency parsing that have been proposed in recent years can be described as either graph-based or transition-based.",0,original
"Inspired by previous work on syntax-driven semantic parsing  , and syntax-based machine translation  , we postulate that syntactically similar sentences with the same predicate also share similar semantic roles.",0,original
"Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval  .",0,original
"This obviously does not preclude using the audio-based system together with other features such as utterance position, length, speakers roles, and most others used in the literature  .",0,original
"Following  , the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside  .",0,original
"Here, we use the hidden Markov model   alignment model   and Model 4 of Brown et al.",0,original
"Model Overall Unknown Word Accuracy Accuracy Baseline, 96.72% 84.5% J Ratnaparkhi 96.63% 85.56%   Table 3 Baseline model performance This table also shows the results reported in Ratnaparkhi  for COnvenience.",0,original
"1 Introduction Bilingual data   are critical resources for building many applications, such as machine translation   and cross language information retrieval  .",0,original
"The learning algorithm, which is illustrated in Collins  , proceeds as follows.",0,original
"In the context of headline generation, simple statistical models are used for aligning documents and headlines  , based on IBM Model 1  .",0,original
"Suhm and Waibel   and Eckert, Gallwitz, and Niemann   each condition a recognizer LM on left-to-right DA predictions and are able to 366 Stolcke et al. Dialogue Act Modeling show reductions in word error rate of 1% on task-oriented corpora.",0,original
"a larger number of labeled documents, its performance on this corpus is comparable to that of Support Vector Machines and Maximum Entropy models  .",0,original
"AL has already been applied to several NLP tasks, such as document classification  , POS tagging  , chunking  , statistical parsing  , and information extraction  .",0,original
"Studies on self-training have focused mainly on generative, constituent based parsing  .",0,original
"For our out-of-domain training condition, the parser was trained on sections 2-21 of the Wall Street Journal   corpus  .",0,original
"As a unified approach, we augment the SDIG by adding all the possible word pairs   ji fe as a parallel ET pair and using the IBM Model 1   word to word translation probability as the ET translation probability.",0,original
he tagging scheme is a variant of the IOB scheme originally put forward by Ramshaw and Marcus  ,0,original
"It combines online Peceptron learning   with a parsing model based on the Eisner algorithm  , extended so as to jointly assign syntactic and semantic labels.",0,original
In this paper we use the so-called Model 4 from  .,0,original
"The idea is that the translation of a sentence x into a sentence y can be performed in the following steps1:   If x is small enough, IBMs model 1   is employed for the translation.",0,original
"\ ), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy \ .",0,original
erceptron Learning a discriminative structure prediction model with a perceptron update was first proposed by Collins  ,0,original
"Following previous work on using global features of candidate structures to learn a ranking model  , the global   features we consider here are simple functions of the local features that capture the relationship between NP pairs.",0,original
"1 Introduction The last few decades have seen the emergence of multiple treebanks annotated with different grammar formalisms, motivated by the diversity of languages and linguistic theories, which is crucial to the success of statistical parsing  .",0,original
"Identifying subjectivity helps separate opinions from fact, which may be useful in question answering, summarization, etc. Sentiment detection is the task of determining positive or negative sentiment of words  , phrases and sentences  , or documents  .",0,original
2 Phrasal Inversion Transduction Grammar We use a phrasal extension of Inversion Transduction Grammar   as the generative framework.,0,original
"Consequently, considerable effort has gone into devising and improving automatic word alignment algorithms, and into evaluating their performance  .",0,original
"Similarly,   tested his WSD algorithm on a dozen words.",0,original
Our approach differs in important ways from the use of hidden Markov models   for classbased language modeling  .,0,original
"The phrase-based decoder extracts phrases from the word alignments produced by GIZA++, and computes translation probabilities based on the frequency of one phrase being aligned with another  .",0,original
"For process  , machine-learning methods are usually used to classify subjective descriptions into bipolar categories   or multipoint scale categories  .",0,original
"Slightly differently from  , we use possible alignments in computing recall.",0,original
"Following Collins  , we used the averaged parameters from the training algorithm in decoding heldout and test examples in our experiments.",0,original
We used the Penn Treebank WSJ corpus   to perform the empirical evaluation of the considered approaches.,0,original
" , which is based on that of Och and Ney  .",0,original
"The intuition is that the produced clusters will be less sense-conflating than those produced by other graph-based approaches, since collocations provide strong and consistent clues to the senses of a target word  .",0,original
"Beyond WordNet  , a wide range of resources has been developed and utilized, including extensions to WordNet   and resources based on automatic distributional similarity methods  .",0,original
ohnson   and Gao & Johnson   assume that words are generated by a hidden Markov model and find that the resulting states strongly correlate with POS tags,0,original
"5 The SemCor collection   is a subset of the Brown Corpus and consists of 352 news articles distributed into three sets in which the nouns, verbs, adverbs, and adjectives have been manually tagged with their corresponding WordNet senses and part-of-speech tags using Brills tagger  .",0,original
"We first added sister-head dependencies for NPs   original proposal) and then for PPs, which are flat in Negra, and thus similar in structure to NPs  .",0,original
"5 The task: Base NP chunking The task is base NP chunking on section 20 of the Wall Street Journal corpus, using sections 15 to 18 of the corpus as training data as in  .",0,original
"The observation probabilities for a given state, representing a certain word class, are determined by the relative frequencies of words belonging to that class  ); the probabilities of other words are set to a small initial value.",0,original
"Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems  .",0,original
Another body of related work is the literature on word clustering in computational linguistics   and document clustering in information retrieval  .,0,original
  is one of the first works to use statistical methods of distributional analysis to induce clusters of words.,0,original
We symmetrized bidirectional alignments using the growdiag-final heuristic  .,0,original
We rescore the ASR N-best lists with the standard HMM   and IBM   MT models.,0,original
"1 Introduction Nowadays, statistical machine translation is mainly based on phrases  .",0,original
"Transformation-based error-driven learning has been applied to a number of natural language problems, including part of speech tagging, prepositional phrase attachment disambiguation, speech generation and syntactic parsing \ .",0,original
he problem is due to the assumption of normality in naive frequency based statistics according to Dunning  ,0,original
We follow   and approximate the metrics using the sigmoid function.,0,original
"Other metrics assess the impact of alignments externally, e.g., different alignments are tested by comparing the corresponding MT outputs using automated evaluation metrics   or METEOR  ).",0,original
"These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules  , or using machine-learning methods  .",0,original
"The performance of cross-language information retrieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often  .",0,original
"4 Data Collection We evaluated out method by running RASP over Brown Corpus and Wall Street Journal, as contained in the Penn Treebank  .",0,original
We perform minimum error rate training   to tune the feature weights for the log-linear modeltomaximizethesystemssBLEUscoreonthe development set.,0,original
The feature weights i are trained in concert with the LM weight via minimum error rate   training  .,0,original
"To simulate real world scenario, we use n-best lists from ISIs state-of-the-art statistical machine translation system, AlTemp  , and the 2002 NIST Chinese-English evaluation corpus as the test corpus.",0,original
"Similarlyto , we define the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y, estimated using Laplace smoothing: strength  = count  + epsilon1count  + kepsilon1   where count  is the number of documents labeled y containing pattern p, count  is the overall number of labeled documents containing p, and k is the number of domains.",0,original
"2 Data 2.1 The US Congressional Speech Corpus The text used in the experiments is from the United States Congressional Speech corpus  , which is an XML formatted version of the electronic United States Congressional Record from the Library of Congress1.",0,original
"In marked contrast to annotated training material for partof-speech tagging,   there is no coarse-level set of sense distinctions widely agreed upon  ;   sense annotation has a comparatively high error rate  ; and   no fully automatic method provides high enough quality output to support the """"annotate automatically, correct manually"""" methodology used to provide high volume annotation by data providers like the Penn Treebank project  .",0,original
"Doing inference with representations close to natural language has also been advocated by Jerry Hobbs, as in  .",0,original
"While movie reviews have been the most studied domain, sentiment analysis has extended to a number of new domains, ranging from stock message boards to congressional floor debates  .",0,original
Clustering can be done statistically by analyzing text corpora   and usually results in a set of words or word senses.,0,original
"Machine learning methods should be interchangeable: Transformation-based learning     and Memory-based learning     have been applied to many different problems, so a single interchangeable component should be used to represent each method.",0,original
Berger et al. 1996 presented a way of computing conditional maximum entropy models directly by modifying equation 6 as follows   ): i ~Cx~) = ~ f~  * ~  ~ ~ .~  * ~  * pCy I ~) = p    x6X yEY xEX yEY where ~  is an empirical probability of a joint configuration   of certain instantiated factor I variables with certain instantiated behavior variables.,0,original
Supervision for simple features has been explored in the literature  .,0,original
Treebanks have been used within the field of natural language processing as a source of training data for statistical part og speech taggers   and for statistical parsers  .,0,original
The tagger described in this paper is based on the standard Hidden Markov Model architecture  .,0,original
4 Experimental Work A part of the Wall Street Journal   which had been processed in the Penn Treebanck Project   was used in the experiments.,0,original
  and Smith and Smith   show how to employ the matrix-tree theorem,0,original
"Such a similarity is calculated by using the WordNet::Similarity tool  , and, concretely, the Wu-Palmer measure, as defined in Equation1  .",0,original
"The resulting corpus contains 385 documents of American English selected from the Penn Treebank  , annotated in the framework of Rhetorical Structure Theory.",0,original
"In such cases, additional information may be coded into the HMM model to achieve higher accuracy  .",0,original
"Translation qualities are measured by uncased BLEU   with 4 reference translations, sysids: ahb, ahc, ahd, ahe.",0,original
The first two phases are approached as straightforward classification in a maximum entropy framework  .,0,original
The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model   or edit distance alignments allowing shifts  .,0,original
"In this paper, we used CTB 5.0   as our main corpus, defined the training, development and test sets according to  , and designed our experiments to explore the impact of the training corpus size on our approach.",0,original
"Inside/Outside This representation was first introduced in  , and has been applied for base NP chunking.",0,original
"3 Language modelling with Bloom filters Recentwork presenteda scheme for associating static frequency information with a set of n-grams in a BF efficiently.1 3.1 Log-frequency Bloom filter The efficiency of the scheme for storing n-gram statistics within a BF presented in Talbot and Osborne   relies on the Zipf-like distribution of n-gramfrequencies: mosteventsoccuranextremely small number of times, while a small number are very frequent.",0,original
73 2.2.4 Minimum Error Rate Training A good way of training is to minimize empirical top-1 error on training data  .,0,original
"This system was worse than the baseline on Bleu  , but an error analysis showed some improvements.",0,original
"1 Introduction Word associations   have a wide range of applications including: Speech Recognition, Optical Character Recognition and Information Retrieval    .",0,original
The basic engine used to perform the tagging in these experiments is a direct descendent of the maximum entropy   tagger of   which in turn is related to the taggers of   and  .,0,original
"Training Set  : There are many labeled English corpora available on the Web and we used the corpus constructed for multi-domain sentiment classification   9 , because the corpus was large-scale and it was within similar domains as the test set.",0,original
Non-anaphoric definite descriptions have been detected using heuristics  ) and unsupervised methods  ).,0,original
The MSLR parser   performs syntactic analysis of the sentence.,0,original
"However, with the algorithms proposed in  , it is possible to develop a general-purpose decoder that can be used by all the parsing-based systems.",0,original
"As, Rapp   observes, choosing a window size involves making a trade-off between various qualities.",0,original
" , this model is symmetric, because both word bags are generated together from a joint probability distribution.",0,original
1 Introduction Text chunking has been one of the most interesting problems in natural language learning community since the first work of   using a machine learning method.,0,original
"Taking SIGHAN Bakeoff 2006   as an example, the recall is lower about 5% than the precision for each submitted system on MSRA and CityU closed track.",0,original
The publicly available Moses4 decoder is used for training and decoding  .,0,original
"1 Introduction This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus  .",0,original
ine 4 and 5 are similar to the phrase extraction algorithm by Och  ,0,original
"In particular, this method has been used for word sense disambiguation   and thesaurus construction  .",0,original
"In information retrieval, word similarity can be used to identify terms for pseudo-relevance feedback  .",0,original
"  To reduce the inference time, following  , we collapsed the 45 different POS labels contained in the original data.",0,original
"??queries: The queries of Turney   are made up of a pair of adjectives, and in our approach the query contains the content words of the headline and an emotion.",0,original
Then the alignments are symmetrized using a refined heuristic as described in  .,0,original
"On the other hand, Kazama and Torisawa   extracted hyponymy relations, which are independent of the NE categories, from Wikipedia and utilized it as a gazetteer.",0,original
37 3 Semi-supervised Domain Adaptation 3.1 Structural Correspondence Learning Structural Correspondence Learning   exploits unlabeled data from both source and target domain to find correspondences among features from different domains.,0,original
he algorithm proposed by Turney   is labeled as Turney-PairClass,0,original
"Another way of doing the parameter estimation for this matching task would have been to use an averaged perceptron method, as in Collins  .",0,original
We have used the Improved Iterative Scaling algorithm    .,0,original
"For the final ranking, we chose the log likelihood statistic outlined in Dunning  , which is based upon the co-occurrence counts of all nouns  .",0,original
"Looking rst at learning times, it is obvious that learning time depends primarily on the number of training instances, which is why we can observe a difference of several orders of magnitude in learning time between the biggest training set   and the smallest training set   14 This is shown by Nivre and Scholz   in comparison to the iterative, arc-standard algorithm of Yamada and Matsumoto   and by McDonald and Nivre   in comparison to the spanning tree algorithm of McDonald, Lerman, and Pereira  .",0,original
We discriminatively trained our parser in an on-line fashion using a variant of the voted perceptron  .,0,original
"2 The alignment Algorithm 2.1 Estimation of translation probabilities The translation probabilities are estimated using a method based on Brown et al.'s Model 2  , which is summarized in the following subsection, 2.1.1.",0,original
The proposed synchronous grammar is able to cover the previous proposed grammar based on tree   and tree sequence   alignment.,0,original
"We accordingly introduce approaches which attempt to include semantic information into the coreference models from a variety of knowledge sources, e.g. WordNet  , Wikipedia   and automatically harvested patterns  .",0,original
"Current work has been spurred by two papers,   and  .",0,original
4.2 Experiments on SRL dataset We used two different corpora: PropBank along with Penn Treebank 2   and FrameNet.,0,original
"In one set of experiments, we generated lexicons for PEOPLE and ORGANIZATIONS using 2500 Wall Street Journal articles from the Penn Treebank  .",0,original
"Following  , we only include features which occur 5 times or more in training data.",0,original
"Some of them use human reference translations, e.g., the BLEU method  , which is based on comparison of N-gram models in MT output and in a set of human reference translations.",0,original
"Weeds and Weir   discuss the influence of bias towards highor low-frequency items for different tasks  , and it would not be surprising if the different high-frequency bias were leading to different results.",0,original
2 Hierarchical Clustering of Words Several algorithms have been proposed for automatically clustering words based on a large corpus  .,0,original
Most current statistical models   treat the aligned sentences in the corpus as sequences of tokens that are meant to be words; the goal of the alignment process is to find links between source and target words.,0,original
We train IBM Model 4 with GIZA++   in both translation directions.,0,original
"We used MXPOST  , and in order to discover more general patterns, we map the tag set down after tagging, e.g. NN, NNP, NNPS and NNS all map to NN.",0,original
arcu and Echihabi   demonstrated that word pairs extracted from the respective text spans are a good signal of the discourse relation between arguments,0,original
"In particular, we use the name/instance lists described by   and available on Fleischmans web page to generate features between names and nominals  .",0,original
"1 Introduction The goal of this study has been to automatically extract a large set of hyponymy relations, which play a critical role in many NLP applications, such as Q&A systems  .",0,original
Subjective phrases are used by   and others in order to classify reviews or sentences as positive or negative.,0,original
"Among the chunk types, NP chunking is the first to receive the attention  , than other chunk types, such as VP and PP chunking  .",0,original
iscovering orientations of context dependent opinion comparative words is related to identifying domain opinion words  ,0,original
"In examining the combination of the two types of parsing, McDonald and Nivre   utilized similar approaches to our empirical analysis.",0,original
"We have found, however, that collocational evidence can be employed to suggest which noun compounds reflect taxonomic relationships, using a strategy similar to that employed by Hindle   for detecting synonyms.",0,original
"3 Implementation 3.1 Pronoun resolution model We built a machine learning based pronoun resolution engine using a Maximum Entropy ranker model  , similar with Denis and Baldridges model  .",0,original
"toilet/bathroom Since the word """"facility"""" is the subject of """"employ"""" and is modified by """"new"""" in  , we retrieve other words that appeared in the same contexts and obtain the following two groups of selectors   of these words in the local contexts):  Subjects of """"employ"""" with top-20 highest likelihood ratios: word freq, Iog,k word freq ORG"""" 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 537 *ORG includes all proper names recognized as organizations 18  Modifiees of """"new"""" with top-20 highest likelihood ratios: word freq log,k post 432 952.9 issue 805 902.8 product 675 888.6 rule 459 875.8 law 356 541.5 technology 237 382.7 generation 150 323.2 model 207 319.3 job 260 269.2 system 318 251.8 word freq log )~ bonds 223 245.4 capital 178 241.8 order 228 236.5 version 158 223.7 position 236 207.3 high 152 201.2 contract 279 198.1 bill 208 194.9 venture 123 193.7 program 283 183.8 Since the similarity between Sense 1 of """"facility"""" and the selectors is greater than that of other senses, the word """"facility"""" in   is tagged """"Sense The key innovation of our algorithm is that a polysemous word is disambiguated with past usages of other words.",0,original
"According to our experience, the best performance is achieved when the union of the source-to-target and target-to-source alignment sets   is used for tuple extraction  .",0,original
5.2 Bleu: Automatic Evaluation BLEU   is a system for automatic evaluation of machine translation.,0,original
"Huang and Chiang   searches with the full model, but makes assumptions about the the amount of reordering the language model can trigger in order to limit exploration.",0,original
"1   Introduction In the community of sentiment analysis  , transferring a sentiment classifier from one source domain to another target domain is still far from a trivial work, because sentiment expression often behaves with strong domain-specific nature.",0,original
"These joint counts are estimated using the phrase induction algorithm described in  , with symmetrized word alignments generated using IBM model 2  .",0,original
ore details about why heuristics are needed and the process used to map sources to NPs can be found in Stoyanov and Cardie  ,0,original
We should note from equation 4 that the neural network model is similar in functional form to the maximum entropy model   except that the neural network learns the feature functions by itself from the training data.,0,original
Accuracy on sentiment classification in other domains exceeds 80%  .,0,original
Most of the early work in this area was based on postulating generative probability models of language that included parse structure  .,0,original
This idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs has its roots in the BLEU metric for machine translation   and the ROUGE   metric for summarization.,0,original
"The first-sense heuristic can be thought of as striving for maximal specificity at the risk of precluding some admissible senses  , 7Allowing for multiple fine-grained senses to be judged as appropriate in a given context goes back at least to Sussna  ; discussed more recently by, e.g., Navigli  .",0,original
"On the other hand, purely statistical systems   extract discriminating MWUs from text corpora by means of association measure regularities.",0,original
"  applies this approach to the so-called IBM Candide system to build context dependent models, compute automatic sentence splitting and to improve word reordering in translation.",0,original
1 Introduction Several recent syntax-based models for machine translation   can be seen as instances of the general framework of synchronous grammars and tree transducers.,0,original
"3 Related Work Many methods have been developed for automatically identifying subjective   words, e.g.,  .",0,original
"In NLP, vector space models have featured most prominently in information retrieval  , but have also been used for ontology learning   and word sense-related tasks  .",0,original
"5.2 A data recovery task In the second evaluation, the estimation method had to distinguish between members of two sets of 8It should be emphasized that the TWS method uses only a monolingual target corpus, and not a bilingual corpus as in other methods  ).",0,original
"1 Introduction In this paper, we present an approach for extracting the named entities   of natural language inputs which uses the maximum entropy   framework  .",0,original
1 Introduction Summarizing spoken documents has been extensively studied over the past several years  .,0,original
"Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus  , GIZA++  , Moses  , and the SRI LM toolkit   to build 5-gram LMs.",0,original
"Since so many concepts used in discourse are graindependent, a theory of granularity is also fundamental  .",0,original
"Hindle, D. ,   """"Noun Classification from Predicate-Argument Structures,"""" Proceedings of the 28th Annual Meeting of the ACL, pp.",0,original
"For further information on these parameter settings, confer  .",0,original
"We use a simple, single parameter distribution, with  = 8.0 throughout P  = P   K Word-to-Phrase Alignment Alignment is a Markov process that specifies the lengths of phrases and their alignment with source words P  = Kproductdisplay k=1 P  = Kproductdisplay k=1 p d n  The actual word-to-phrase alignment   is a firstorder Markov process, as in HMM-based word-toword alignment  .",0,original
Generative methods   treat word alignment as a hidden process and maximize the likelihood of bilingual training corpus using the expectation maximization   algorithm.,0,original
"With the help of the kappa coefficient   proposes to represent the dialog success independently from the task intrinsic complexity, thus opening the way to task generic comparative evaluation.",0,original
"In the second experiment, the basic learning model is Collinss   Model 2 parser, which uses a history-based learning algorithm that takes statistics directly over the treebank.",0,original
"Unlike previous annotations of sentiment or subjectivity  , which typically relied on binary 0/1 annotations, we decided to use a finer-grained scale, hence allowing the annotators to select different degrees of emotional load.",0,original
"We used a bottom-up, CKY-style decoder that works with binary xRs rules obtained via a synchronous binarization procedure  .",0,original
"Selectional preferences are estimated using grammatical collocation information from the British National Corpus  , obtained with the Word Sketch Engine    .",0,original
"The token precision is higher than 90% in all of the corpora, including the movie domain, which is considered to be difficult for SA  .",0,original
"Not only many combinations are found in the corpus, many of them have very similar mutual information values to that of 318 Table 2: economic impact verb economic financial political social budgetary ecological economic economic economic economic economic economic economic economic economic object impact impact impact impact impact impact effect implication consequence significance fallout repercussion potential ramification risk mutual freq info 171 1.85 127 1.72 46 0.50 15 0.94 8 3.20 4 2.59 84 0.70 17 0.80 59 1.88 10 0.84 7 1.66 7 1.84 27 1.24 8 2.19 17 -0.33 nomial distribution can be accurately approximated by a normal distribution  .",0,original
"4.2 Smoothing: Gaussian Priors Since NLP maximum entropy models usually have lots of features and lots of sparseness  , smoothing is essential as a way to optimize the feature weights  .",0,original
hat some model structures work better than others at real NLP tasks was discussed by Johnson   and Klein and Manning  ,0,original
"Following the broad shift in the field from finite state transducers to grammar transducers  , recent approaches to phrase-based alignment have used synchronous grammar formalisms permitting polynomial time inference  .",0,original
"We use the adaptation of this algorithm to structure prediction, first proposed by  .",0,original
"I have made a preliminary analysis of the inventory of syntactic categories used in the tagging for labelling trees in the 18 Penn Treebank  , comparing them to the categories used in CGEL.",0,original
"With our best performing features, we get ROUGE-2   scores of 0.11 and 0.0925 on 2007 and 2006 5This threshold was derived experimentally with previous data.",0,original
"We obtained 47,025 50-dimensional reduced vectors from the SVD and clustered them into 200 classes using the fast clustering algorithm Buckshot    .",0,original
Abduction has been applied to the solution of local pragmatics problems   and to story understanding  .,0,original
"While   showed that this technique was effective when testing on WSJ, the true distribution was closer to WSJ so it made sense to emphasize it.",0,original
"Some of them have been fully tested in real size texts  ,  ,  , knowledge based methods  ,  , or mixed methods  ,  ).",0,original
"We report case-insensitive scores for version 0.6 of METEOR   with all modules enabled, version 1.04 of IBM-style BLEU  , and version 5 of TER  .",0,original
Many researchers  ;  ) have suggested that the informationtheoretic notion of mutual information score   directly captures the idea of context.,0,original
"2.3 ITG Constraints The Inversion Transduction Grammar    , a derivative of the Syntax Directed Transduction Grammars  , constrains the possible permutations of the input string by defining rewrite rules that indicate permutations of the string.",0,original
Standard SMT alignment models   are used to align letter-pairs within named entity pairs for transliteration.,0,original
"Statistic-based algorithms based on Belief Network  such as Hidden-MarkovModel   , Lexicalized HMM  and Maximal-Entropy model  use the statistical information of a manually tagged corpus as background knowledge to tag new sentences.",0,original
"In this paper, we propose an alignment algorithm between English and Korean conceptual units   in English-Korean technical term pairs based on IBM Model  .",0,original
"As a learning algorithm for our classification model, we used Maximum Entropy  .",0,original
"4.1 Data We used Penn-Treebank   data, presented in Table 1.",0,original
One judge annotated allarticles in four datasets of the Wall Street Journal Treebank corpus     as well as thecorpusofWall Street Journal articles used in    .,0,original
"3 Evaluation We trained our model parameters on a subset of the provided dev2006 development set, optimizing for case-insensitive IBM-style BLEU   with several iterations of minimum error rate training on n-best lists.",0,original
"Each model can represent an important feature for the translation, such as phrase-based, language, or lexical models  .",0,original
To reduce it we exploit the one sense per collocation property  .,0,original
"Within the machine learning paradigm, IL has been incorporated as a technique for bootstrapping an extensional learning algorithm, as in  .",0,original
"Alternatively, one can train them with respect to the final translation quality measured by an error criterion  .",0,original
"13Huang and Chiang   give an informal example, but do not elaborate on it.",0,original
"In this paper, we compare the performance of this system, HybridTrim, with the Topiary system and a number of other baseline gisting systems on a collection of news documents from the DUC 2004 corpus  .",0,original
  MEDLINE DT JJ VBN NNS IN DT NN NNS VBP The oncogenic mutated forms of the ras proteins are RB JJ CC VBP IN JJ NN NN . constitutively active and interfere with normal signal transduction . Figure 1: Part of speech-tagged sentences from both corpora we investigate its use in part of speech   tagging  .,0,original
"These were: BLEU  , NIST  , WER  , PER  , GTM  , and METEOR  .",0,original
"Using dictionaries as network of lexical items or senses has been quite popular for word sense disambiguation   before losing ground to statistical approaches, even though   tried a revival of such methods.",0,original
"4 Global Transliteration Modeling In global transliteration modeling, we directly model the agreement function between f and e. We follow   and consider the global feature representation : F * E *  R d . 613 Each global feature corresponds to a condition on the pair of strings.",0,original
"What, therefore, has to be explored are various similarity metrics, defining similarity in a concrete way and evaluate the results against human annotations  .",0,original
"In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation , large amount of human effort and time has been invested in collecting parallel corpora of translated texts.",0,original
"Using these patterns, we introduced verb form errors into AQUAINT, then re-parsed the corpus  , and compiled the changes in the disturbed trees into a catalog.",0,original
"3.1 Binarizable segmentations   Following  , every sequence of phrase alignments can be viewed 1For example, if the cut-off on phrase pairs is ten words, all sentence pairs smaller than ten words in the training data will be included as phrase pairs as well.",0,original
"This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation   and consists of the Pharaoh decoder  , SRILM  , GIZA++  , mkcls  , Carmel,1 and a phrase model training code.",0,original
"Motivation There have been quite a number of recent papers on parallel text: Brown et al  , Chen  , Church  , Church et al  , Dagan et al  , Gale and Church  , Isabelle  , Kay and Rgsenschein  , Klavans and Tzoukermann  , Kupiec  , Matsumoto  , Ogden and Gonzales  , Shemtov  , Simard et al  , WarwickArmstrong and Russell  , Wu  .",0,original
his model is related to the averaged perceptron algorithm of Collins  ,0,original
2.3 Probabilistic models for generation with HPSG Some existing studies on probabilistic models for HPSG parsing   adopted log-linear models  .,0,original
1 Introduction: Defining SCMs The work presented here was done in the context of phrase-based MT  .,0,original
"2.1 Baseline: IBM Model-1 The translation process can be viewed as operations of word substitutions, permutations, and insertions/deletions   in noisychannel modeling scheme at parallel sentence-pair level.",0,original
We use only the words that are content words   and not in the stopword list used in ROUGE  .,0,original
2 Architecture of the system The goal of statistical machine translation   is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units   and a log linear framework in order to introduce several models explaining the translation process: e??= argmaxp  = argmaxe {exp )}   The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set  .,0,original
  use the Learning as Search Optimization framework to take into account the non-locality behavior of the coreference features.,0,original
he features that define the constraints on the model are obtained by instantiation of feature templates as in Ratnaparkhi  ,0,original
McDonald et al 2007; Ivan et al 2008) proposed a structured model based on CRFs for jointly classifying the sentiment of text at varying levels of granularity,0,original
Only recently the issue has drawn attention:   present an initial analysis of the factors that influence system performance in content selection.,0,original
"Some other researchers also work on detecting negative cases, i.e. contradiction, instead of entailment  .",0,original
esearchers have mostly looked at representing words by their surrounding words   and by their syntactical contexts  ,0,original
It differs from the many approaches where   is defined by a stochastic synchronous grammar   and from transfer-based systems defined by context-free grammars  .,0,original
"This is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted Carletta   to recommend chance-corrected measures.",0,original
 ) and view the POS tags and word identities as two separate sources of information.,0,original
"Several models were introduced for these problems, for example, the Hidden Markov Model    , Maximum Entropy Model    , and Conditional Random Fields    .",0,original
"To evaluate the performance of a parser, NP chunks can usefully be evaluated by a gold standard; many systems   use the Penn Treebank for this type of evaluation.",0,original
"We use a hand-written competence grammar, combined with performance-driven disambiguation obtained from the Penn Treebank  .",0,original
"Then, we build a classier learned by training data, using a maximum entropy model   and the features related to spelling variations in Table 3.",0,original
"This can be done automatically with unparsed corpora  , from parsed corpora such as Marcus et al.'s   Treebank   or manually as was done for COMLEX  .",0,original
The task of classifying several different uses of definite descriptions   is somewhat analogous to that for bare nouns.,0,original
2 Phrase-based Statistical MT Our baseline is a standard phrase-based SMT system  .,0,original
"F-Measure with an appropriate setting of  will be useful during the development process of new alignment models, or as a maximization criterion for discriminative training of alignment models  .",0,original
  from the Penn Treebank   WSJ corpus.,0,original
utual infornaation involves a problem in that it is overestimated for low-frequency terms  unning 1993),0,original
"Whereas until recently the focus of research had been on sense disambiguation, papers like Pantel & Lin  , Neill  , and Rapp   give evidence that sense induction now also attracts attention.",0,original
"For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by   and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by  .",0,original
"Some authors have already designed similar matching techniques, such as the ones described in   and  .",0,original
"Deterministic Annealing: In this system, instead of using the regular MERT   whose training objective is to minimize the onebest error, we use the deterministic annealing training procedure described in Smith and Eisner  , whose objective is to minimize the expected error  .",0,original
The classical Bayes relation is used to introduce a target language model  : e = argmaxe Pr  = argmaxe Pr Pr  where Pr  is the translation model and Pr  is the target language model.,0,original
It is mentioned that the limitation is largely caused by inconsistencies in the corpus  .,0,original
"Estimated clues are derived from the parallel data using, for example, measures of co-occurrence  ), statistical alignment models  ), or string similarity measures  ).",0,original
"These methods have been used in machine translation  , terminology research and translation aids  , bilingual lexicography  , collocation studies  , word-sense disambiguation   and information retrieval in a multilingual environment  .",0,original
Experimental results are reported in Table 2: here cased BLEU results are reported on MT03 Arabic-English test set  .,0,original
"Hindle uses the observed frequencies within a specific syntactic pattern   to derive a cooccu,> rence score which is an estimate of mutual information  .",0,original
"Second, it can be applied to control the quality of parallel bilingual sentences mined from the Web, which are critical sources for a wide range of applications, such as statistical machine translation   and cross-lingual information retrieval  .",0,original
"ISBNs, originally proposed for constituent parsing in  , use vectors of binary latent variables to encode information about the parse history.",0,original
Collins head words finder rules have been modified to extract semantic head word  .,0,original
"Och and Ney   proposed Model 6, a log-linear combination of IBM translation models and HMM model.",0,original
Our results are similar to those for conventional phrase-based models  .,0,original
he benefits of using grammatical information for automatic WSD were first explored by Yarowsky   and Resnik   in unsupervised approaches to disambiguating single words in context,0,original
"The second type has clear interpretation as a probability model, but no criteria to determine the number of clusters  .",0,original
Our approach differs from the corpus-based surface generation approaches of   and  .,0,original
Previous work   has shown it to be appropriate to large-scale language modeling.,0,original
"For English, self-training contributes 0.83% absolute improvement to the PCFG-LA parser, which is comparable to the improvement obtained from using semi-supervised training with the twostage parser in  .",0,original
"11 However, modeling word order under translation is notoriously difficult  , and it is unclear how much improvement in accuracy a good model of word order would provide.",0,original
"A remedy is to aggressively limit the feature space, e.g. to syntactic labels or a small fraction of the bi-lingual features available, as in  , but that reduces the benefit of lexical features.",0,original
More details on these standard criteria can be found for instance in  .,0,original
In each case the input to the network is a sequence of tag-word pairs.5 5We used a publicly available tagger   to provide the tags.,0,original
"POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model   in English research communities  .",0,original
4.4 Related Work   implemented an MEMM model for supertagging which is analogous to the POS tagging model of  .,0,original
"Examples of such contexts are verb-object relations and noun-modifier relations, which were traditionally used in word similarity tasks from non-parallel corpora  .",0,original
  and section 23 for testing  ; we only tested on sentences _< 40 words  .,0,original
"The production rules in ITGs are of the following form  , with a notation similar to what is typically used for SDTSs and SCFGs in the right column: A    A  B1C2,B1C2 A  BC A  B1C2,C2B1 A  e | f A  e,f A  e |  A  e, A   | f A  ,f It is important to note that RHSs of production rules have at most one source-side and one targetside terminal symbol.",0,original
"Table 4 shows the linguistic features of the resulting model compared to the models of Carroll and Rooth  , Collins  , and Charniak  .",0,original
"Second, the automatic approach, in which the model is automatically obtained from corpora   1, and consists of n-grams  , rules   or neural nets  .",0,original
"  where K is the number of distinct nonternfinal symbols in the gramma.r G. We ca.n expect a. very etfide.nt pa.rser tbr our pa.tterns, r The input string ca.n a.lso be scanned to reduce the number of relewmt gramma.r rules before pa.rsing, e The combined process is a.lso known as offlineparsing in LTAC,.",0,original
"4 Experiment 4.1 Evaluation Method We evaluated each sentence compression method using word F-measures, bigram F-measures, and BLEU scores  .",0,original
"By contrast, in the training method proposed by  , the discriminative function f  is estimated to maximize the F 1 -score of training dataset D. This training method employs an approximate form of the F 1 -score obtained by using a logistic function.",0,original
"Proceedings of the 40th Annual Meeting of the Association for  , a number of other algorithms have been developed.",0,original
"One aspect of VPCs that makes them dicult to extract  ) is that the verb and particle can be non-contiguous, e.g. hand the paper in and battle right on.",0,original
We say that wv and nq are semantically related if w~i and nq are semantically related and   and   are semantically similar  .,0,original
"For automatic evaluation, we employed BLEU   by following  .",0,original
"3.1 A Note on State-Splits Recent studies   suggest that category-splits help in enhancing the performance of treebank grammars, and a previous study on MH   outlines specific POS-tags splits that improve MH parsing accuracy.",0,original
"3Huang and Chiang   describes the cube growing algorithm in further detail, including the precise form of the successor function for derivations.",0,original
"Different approaches have been proposed to measure matches using words or more meaningful semantic units, for example, ROUGE  , factoid analysis  , pyramid method  , and Basic Element    .",0,original
"SO can be used to classify reviews   as positive or negative  , and applied to subjectivity analysis such as recognizing hostile messages, classifying emails, mining reviews  .",0,original
This direction has been forming the mainstream of research on opinion-sensitive text processing  .,0,original
Of particular interest are lexicalized parsing models such as the ones developed by Collins   and Carroll and Rooth  .,0,original
The second one needs no labeled data for the new domain  .,0,original
"ProAlign models P  directly, using a different decomposition of terms than the model used by IBM  .",0,original
"As previously observed in the literature  , such components include a clause in the clause conjunction, relative clauses, and some elements within a clause  .",0,original
There are other approaches to statistical machine translation where translation is achieved through transduction of source language structure to target language structure  .,0,original
"However, the pb features yields no noticeable improvement unlike in prefect lexical choice scenario; this is similar to the findings in  .",0,original
"More recent papers Hindle  , Pereira and Tishby   proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts.",0,original
  of running GIZA++   in both directions and then merging the alignments using the grow-diag-final heuristic.,0,original
"The training samples are respectively used to create the models PT^G, PCHUNK, PBUILD, and PCMECK, all of which have the form: k p  = II _ij  j----1 where a is some action, b is some context, ~"""" is a nor4 Model Categories Description Templates Used TAG See   CHUNK chunkandpostag * BUILD CHECK chunkandpostag * cons  cons * cons  T punctuation checkcons * checkcons * production surround * The word, POS tag, and chunk tag of nth leaf.",0,original
"Until now, we have defined BestLossk, a to be the minimum of the loss given that the kth feature is updated an optimal amount: BestLossk, amin d LogLossUpda,k,d In this section we sketch a different approach, based on results from Collins, Schapire, and Singer  , which leads to an algorithm very similar to that for ExpLoss in Figures 3 and 4.",0,original
"In our approach, equation   is further normalized so that the probability for different lengths of F is comparable at the word level: m m j n i ijm eft l EFP /1 10 )| 1 |  The alignment models described in   are all based on the notion that an alignment aligns each source word to exactly one target word.",0,original
Trained and tested using the same technique as  .,0,original
Giving the increasing sophistication of probabilistic linguistic models   has a statistical approach to learning gap-threading rules) a probabilistic extension of our work is attractive--it will be interesting to see how far an integration of 'logical' and statistical can go.,0,original
"Unlike  , one interesting idea proposed by   is to cluster similar pairs of paraphrases to apply multiplesequence alignment.",0,original
"1 Introduction A number of wide-coverage TAG, CCG, LFG and HPSG grammars   have been extracted from the Penn Treebank  , and have enabled the creation of widecoverage parsers for English which recover local and non-local dependencies that approximate the underlying predicate-argument structure  .",0,original
This resembles the re-ranking approach  .,0,original
"Hierarchical rules were extracted from a subset which has about 35M/41M words5, and the rest of the training data were used to extract phrasal rules as in  .",0,original
"The measures are: word overlap, length difference  , BLEU  , dependency relation overlap  , and dependency tree edit distance.",0,original
"This iterative optimiser, derived from a word disambiguation technique  , finds the nearest local maximum in the lexical cooccurrence network from each concept seed.",0,original
One of the theoretical problems with phrase based SMT models is that they can not effectively model the discontiguous translations and numerous attempts have been made on this issue  .,0,original
"During the SRC stage, a Maximum entropy   classifier is used to predict the probabilities of a word in the sentence Language No-duplicated-roles Catalan arg0-agt, arg0-cau, arg1-pat, arg2-atr, arg2-loc Chinese A0, A1, A2, A3, A4, A5, Czech ACT, ADDR, CRIT, LOC, PAT, DIR3, COND English A0, A1, A2, A3, A4, A5, German A0, A1, A2, A3, A4, A5, Japanese DE, GA, TMP, WO Spanish arg0-agt, arg0-cau, arg1-pat, arg1-tem, arg2-atr, arg2-loc, arg2-null, arg4-des, argL-null, argMcau, argM-ext, argM-fin Table 1: No-duplicated-roles for different languages to be each semantic role.",0,original
All our experiments used the standard BIO encoding   with different feature sets and learning procedures.,0,original
n particular we work with dependency paths that can reach beyond direct dependencies as opposed to Lin   but in the line of Pado and Lapata  ,0,original
"7 For a more detailed discussion, see Berger, Della Pietra, and Della Pietra   and Ratnaparkhi  .",0,original
"  explored the use a formalism called quasisynchronous grammar   in order to find a more explicit model for matching the set of dependencies, and yet still allow for looseness in the matching.",0,original
"The approach presented here has some resemblance to the bracketing transduction grammars   of  , which have been applied to a phrase-based machine translation system in  .",0,original
"Using our WSD model to constrain the translation candidates given to the decoder hurts translation quality, as measured by the automated BLEU metric  .",0,original
6 Experiments We evaluated the translation quality of the system using the BLEU metric  .,0,original
he preci781 start Palestinian suicide bomberblew himself up in SLOT1 on SLOT2 killing SLOT3 other people and injuring wounding SLOT4 end detroit the *e* a s *e* building buildingin detroit flattened ground levelled to blasted leveled *e* was reduced razed leveled to down rubble into ashes *e* to *e*     Figure 1: Examples of paraphrase patterns extracted by Barzilay and Lee   and Pang et al,0,original
1As do constraint relaxation   and forest reranking  .,0,original
"2 2.1 Word Alignment Adaptation Bi-directional Word Alignment In statistical translation models  , only one-to-one and more-to-one word alignment links can be found.",0,original
"3 Probability Model This paper takes a """"history-based"""" approach   where each tree-building procedure uses a probability model p , derived from p , to weight any action a based on the available context, or history, b. First, we present a few simple categories of contextual predicates that capture any information in b that is useful for predicting a. Next, the predicates are used to extract a set of features from a corpus of manually parsed sentences.",0,original
"In our experiments we use a grammar with a start symbol S, a single preterminal C, and two nonterminals A and B used to ensure that only one parse can generate any given word-level alignment    .",0,original
he model of Haghighi and Klein   incorporated a latent variable for named entity class,0,original
Two major research topics in this field are Named Entity Recognition     and Word Sense Disambiguation    .,0,original
"The translation and reference files are analyzed by a treebank-based, probabilistic LFG parser  , which produces a set of dependency triples for each input.",0,original
We trained the parser on the Penn Treebank  .,0,original
"10Both Pharoah and our system have weights trained using MERT   on sentences of length 30 words or less, to ensure that training and test conditions are matched.",0,original
c2009 Association for Computational Linguistics Improving Mid-Range Reordering using Templates of Factors Hieu Hoang School of Informatics University of Edinburgh h.hoang@sms.ed.ac.uk Philipp Koehn School of Informatics University of Edinburgh pkoehn@inf.ed.ac.uk Abstract We extend the factored translation model   to allow translations of longer phrases composed of factors such as POS and morphological tags to act as templates for the selection and reordering of surface phrase translation.,0,original
"This paper, however, aims at the k-best tree algorithms whose packed representations are hypergraphs    , which includes most parsers and parsing-based MT decoders.",0,original
"Moreover, it was   the inference technique employed in  .",0,original
"This is related to the wellstudied problem of identifying paraphrases   and the more general variant of recognizing textual entailment, which explores whether information expressed in a hypothesis can be inferred from a given premise.",0,original
METEOR uses the Porter stemmer and synonymmatching via WordNet to calculate recall and precision more accurately  .,0,original
"Consequently, here we employ multiple references to evaluate MT systems like BLEU   and NIST  .",0,original
"Distributional measures of distance, such as those proposed by Lin  , quantify how similar the two sets of contexts of a target word pair are.",0,original
622 We also identified a length effect similar to that studied by   for self-training  .,0,original
"decades like n-gram back-off word models  , class models  , structured language models   or maximum entropy language models  .",0,original
"Systems based on word-to-word lexicons, such as the IBM systems  , incorporate further devices that allow reordering of words   and ranking of alternatives  .",0,original
"In the following section, we follow the notation in  .",0,original
Intercoder reliability was assessed using Cohen's Kappa statistic    .,0,original
"To find the optimal coefficients  for a loglinear combination of these experts, we use separate development data, using the following procedure due to Och  : 1.",0,original
This simplified version does not take word classes into account as described in  .,0,original
A synchronous 363 binarization method is proposed in   whose basic idea is to build a left-heavy binary synchronous tree   with a left-to-right shift-reduce algorithm.,0,original
"We still use complex structures to represent the partial analyses, so as to employ both top-down and bottom-up information as in  .",0,original
"In fact, the largest source of English dependency trees is automatically generated from the Penn Treebank   and is by convention exclusively projective.",0,original
"Finally, inducing lexical semantics from distributional data  ) is also a form of surface cueing.",0,original
"However, as also pointed out by Yarowsky  , this observation does not hold uniformly over all possible co-occurrences of two words.",0,original
"It is dubious whether SWD is useful regarding recall-oriented metrics like METEOR  , since SWD removes information in source sentences.",0,original
We use the Penn Treebank Wall Street Journal corpus as the large corpus and individual sections of the Brown corpus as the target corpora  .,0,original
"Fortunately, Wu   provides a method to have an ITG respect a known partial structure.",0,original
"3 Quasi-Synchronous Grammar For a formal description of QG, we recommend Smith and Eisner  .",0,original
And we consider that word pairs that have a small distance between vectors also have similar word neighboring characteristics    .,0,original
"OHara and Wiebe   also make use of high level features, in their case the Penn Treebank   and FrameNet   to classify prepositions.",0,original
The experiments were performed using the Wall Street Journal   corpus of the University of Pennsylvania   modified as described in   and  .,0,original
dwait Ratnaparkhi   estimates a probability distribution for tagging using a maximum entropy approach,0,original
"2 Summary of approaches Given a source language sentence f, statistical machine translation defines the translation task as selecting the most likely target translation e under a model P , i.e.: e  = argmax e P  = argmax e msummationdisplay i=1 hi i where the argmax operation denotes a search through a structured space of translation ouputs in the target language, hi  are bilingual features of e and f and monolingual features of e, and weights i are trained discriminitively to maximize translation quality   on held out data  .",0,original
"Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment   or extraction of syntactic constructions from online dictionaries and corpora  .",0,original
"Fortunately, there is a straightforward parallel between our object recognition formulation and the statistical machine translation problem of building a lexicon from an aligned bitext  .",0,original
" , we used the MXPOST   tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10way jackknifing to generate tags for the training set.",0,original
Word correspondence was further developed in IBM Model-1   for statistical machine translation.,0,original
"The accuracy of the generator outputs was evaluated by the BLEU score  , which is commonly used for the evaluation of machine translation and recently used for the evaluation of generation  .",0,original
"Some of them are based upon syntactic structure, with PropBank   being one of the most relevant, building the annotation upon the syntactic representation of the TreeBank corpus  .",0,original
"Statistical approaches, which depend on a set of unknown parameters that are learned from training data, try to describe the relationship between a bilingual sentence pair  .",0,original
Another line of research closely related to our work is the recognition of semantic orientation and sentiment analysis  .,0,original
The approach made use of a maximum entropy model   formulated from frequency information for various combinations of the observed features.,0,original
"Probabilistic generative models like IBM 1-5  , HMM  , ITG  , and LEAF   define formulas for P  or P , with ok-voon ororok sprok at-voon bichat dat erok sprok izok hihok ghirok totat dat arrat vat hilat ok-drubel ok-voon anok plok sprok at-drubel at-voon pippat rrat dat ok-voon anok drok brok jok at-voon krat pippat sat lat wiwok farok izok stok totat jjat quat cat lalok sprok izok jok stok wat dat krat quat cat lalok farok ororok lalok sprok izok enemok wat jjat bichat wat dat vat eneat lalok brok anok plok nok iat lat pippat rrat nnat wiwok nok izok kantok ok-yurp totat nnat quat oloat at-yurp lalok mok nok yorok ghirok clok wat nnat gat mat bat hilat lalok nok crrrok hihok yorok zanzanok wat nnat arrat mat zanzanat lalok rarok nok izok hihok mok wat nnat forat arrat vat gat Figure 1: Word alignment exercise  .",0,original
"So far, these techniques have focused on phrasebased models using contiguous phrases  .",0,original
"sentence length: The longer the sentence is, the poorer the parser performs  .",0,original
It has been argued that the reliability of a coding schema can be assessed only on the basis of judgments made by naive coders  .,0,original
"We split the treebank into training  , development   and test   as in  .",0,original
"Intuitively speaking, the gaps on the target-side will lead to exponential complexity in decoding with integrated language models  , as well as synchronous parsing  .",0,original
"This segmentation task can be achieved by assigning words in a sentence to one of three tokens: B for Begin-NP, I for Inside-NP, or O for OutsideNP  .",0,original
he fact that information consisting of nothing more than bigrams can capture syntactic information about English has already been noted by  ,0,original
We evaluate the system generated summaries using the automatic evaluation toolkit ROUGE  .,0,original
The lexical scores are computed as the   log probability of the Viterbi alignment for a phrase pair under IBM word-translation Model 1  .,0,original
"Various machine learning strategies have been proposed to address this problem, including semi-supervised learning  , domain adaptation  , multi-task learning  , self-taught learning  , etc. A commonality among these methods is that they all require the training data and test data to be in the same feature space.",0,original
"The training data for the French/English data set is taken from the LDC Canadian Hansard data set, from which the word aligned data   was also taken.",0,original
"With hand-labeled data, {m} can be learnt via generalized iterative scaling algorithm     or improved iterative scaling    .",0,original
"Similar to  , each word in the hypothesis is assigned with a rank-based score of 1/ r+ , where r is the rank of the hypothesis.",0,original
In our experiments these were obtained automatically using MXPOST   and BBNs Identifinder  .,0,original
"In this paper, we give an overview of NLPWin, a multi-application natural language analysis and generation system under development at Microsoft Research  , incorporating analysis systems for 7 languages  .",0,original
"A more fine-grained distinction is made by Bean and Riloff   and Vieira and Poesio   to distinguish restrictive from non-restrictive postmodification by ommitting those modifiers that occur between commas, which should not be classified as chain starting.",0,original
"The lexical acquisition phase uses the GIZA++ word-alignment tool, an implementation   of IBM Model 5   to construct an alignment of MRs with NL strings.",0,original
"Each item is associated with a stack whose signa12Specifically a B-hypergraph, equivalent to an and-or graph   or context-free grammar  .",0,original
"Apart from this, the module is a straightforward implementation of  , which in turn adapts   for syntactic chunking.",0,original
It is therefore desirable to have dedicated servers to load parts of the LM3  an idea that has been exploited by  .,0,original
"The scores were then weighted by the inverse of their height in the tree and then summed together, similarly to the procedure in  .",0,original
Translation quality is automatically evaluated by the IBM-BLEU metric     on the following publicly 1148 Ch.-En.,0,original
Pang et al. proposed a method of classifying movie reviews into positive and negative ones  .,0,original
"eBonsai first performs syntactic analysis of a sentence using a parser based on GLR algorithm    , and provides candidates of its syntactic structure.",0,original
where they are expected to be maximally discriminative  .,0,original
"One sees this clear trend in the supervised NLP literature examples include the Perceptron algorithm for tagging  , MIRA for dependency parsing  , exponentiated gradient algorithms  , stochastic gradient for constituency parsing  , just to name a few.",0,original
"First, we show how one can use an existing statistical translation model   in order to automatically derive a statistical TMEM.",0,original
Then the two models and a search module are used to decode the best translation  .,0,original
ur approach thus provides an even more extreme version of automatic con rmation generation than that used byChu-Carroll and Carpenter   where only a small eort is required by the developer,0,original
We use the perceptron algorithm for sequence tagging  .,0,original
"This could, for example, aid machine-translation evaluation, where it has become common to evaluate systems by comparing their output against a bank of several reference translations for the same sentences  .",0,original
We use a tagger based on Adwait Ratnaparkhi's method  .,0,original
"Since  , numerous works have used patterns for discovery and identification of instances of semantic relationships  ).",0,original
"This is similar to work by several other groups which aims to induce semantic classes through syntactic co-occurrence analysis  , although in .our case the contexts are limited to selected patterns, relevant to the scenario.",0,original
"To use the data from NANC, we use self-training  .",0,original
"While the research in statistical machine translation   has made significant progress, most SMT systems   relyonparallel corpora toextract translation entries.",0,original
"For a full discussion of previous work, please see  , or see   for work relating to synonym resolution.",0,original
4.3 Adaptation for unknown word2 The unknown word problem is an important issue for domain adaptation .,0,original
"It assumes that the distance of the positions relative to the diagonal of the   plane is the dominating factor: r  p  =  , Ei,=l r  As described in  , the EM algorithm can be used to estimate the parameters of the model.",0,original
"We do not use particular lexicosyntactic patterns, as previous attempts have  .",0,original
"In the context of part-of-speech tagging, Klein and Manning   argue for the same distinctions made here between discriminative models and discriminative training criteria, and come to the same conclusions.",0,original
" ,   In addition to the usual issues involved with the complex annotation of data, we have come to terms with a number of issues that are specific to a highly inflected language with a rich history of traditional grammar.",0,original
using Spearmans rank correlation coefficient and Pearsons rank correlation coefficient  .,0,original
The tags sets we shall examine are the set used in the Penn Tree Bank     and the C5 tag-set used by the CLAWS part-of-speech tagger  .,0,original
"Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms  , information retrieval  , determining semantic orientation  , grading student essays  , measuring textual cohesion  , and word sense disambiguation  .",0,original
"The IBM models, together with a Hidden Markov Model  , form a class of generative models that are based on a lexical translation model P  where each word fj in the foreign sentence fm1 is generated by precisely one word ei in the sentence el1, independently of the other translation decisions  .",0,original
"In this paper, we implement the SDB model in a state-of-the-art phrase-based system which adapts a binary bracketing transduction grammar     to phrase translation and reordering, described in  .",0,original
"It is possible to prove that, provided the training set   is separable with margin > 0, the algorithm is assured to converge after a finite number of iterations to a model with zero training errors  .",0,original
"2.2 The Crossing Constraint According to  , crossing constraint can be defined in the following.",0,original
2 WordNet-based semantic relatedness measures 2.1 Basic measures Two similarity/distance measures from the Perl package WordNet-Similarity written by   are used.,0,original
"In general, previous work in opinion mining includes document level sentiment classification using supervised   and unsupervised methods  , machine learning techniques and sentiment classification considering rating scales  , and scoring of features  .",0,original
"Wu   investigated the use of concurrent parsing of parallel corpora in a transduction inversion framework, helping to resolve attachment ambiguities in one language by the coupled parsing state in the second language.",0,original
"In this paper we report case-insensitive Bleu scores  , unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet  .",0,original
"Discriminative training has been used mainly for translation model combination   and with the exception of  , has not been used to directly train parameters of a translation model.",0,original
"Despite these difficulties, some work has shown it worthwhile to minimize error directly  .",0,original
e also experimented with a method suggested by Brent   which applies the binomial test on frame frequency data,0,original
"Many of these tasks have been addressed in other fields, for example, hypothesis verification in the field of machine translation  , sense disambiguation in speech synthesis  , and relation tagging in information retrieval  .",0,original
"For example, the lexicalized grammars of Collins   and Charniak   and the statesplit grammars of Petrov et al.",0,original
We then train IBM models   using the GIZA++ package  .,0,original
"Within this class would fall the Lexical Implication Rules   of Ostler and Atkins  , the lexical rules of Copestake and Briscoe  , the Generative Lexicon of Pustejovsky  , and the ellipsis recovery procedUres of Viegas and Nirenburg  .",0,original
Results in terms of word-error-rate   and BLEU score   are reported in Table 4 for those sentences that contain at least one unknown word.,0,original
"5.1 Agreement between translators In an attempt to quantify the agreement between the two groups of translators, we computed the Kappa coefficient for annotation tasks, as defined by Carletta  .",0,original
"We will do this by examining how humans perform on summary extraction and evaluating the reliability of their performance, using the kappa statistic, a metric standardly used in the behavioral sciences  .",0,original
An automatic metric which uses base forms and synonyms of the words in order to correlate better to human judgements has been 1 proposed in  .,0,original
"Since word senses are often associated with domains  , word senses can be consequently distinguished by way of determining the domain of each description.",0,original
"57 Given a pair of English sentences to be compared  , we perform tokenization2, lemmatization using WordNet3, and part-of-speech   tagging with the MXPOST tagger  .",0,original
"My guess is that the features used in e.g., the Collins   or Charniak   parsers are probably close to optimal for English Penn Treebank parsing  , but that other features might improve parsing of other languages or even other English genres.",0,original
"For example, both Haghighi and Klein   and Mann and McCallum   have demonstrated results better than 66.1% on the apartments task described above using only a list of 33 highly discriminative features and the labels they indicate.",0,original
Our model uses an exemplar memory that consists of 133566 verb-role-noun triples extracted from the Wall Street Journal and Brown parts of the Penn Treebank  .,0,original
"The process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed  , but it is not obvious which one should be chosen for a given language pair.",0,original
"We use the same alignment data for the five language pairs Chinese/English, Romanian/English, Hindi/English, Spanish/English, and French/English  .",0,original
"Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files  , we have counted the occurrences of content words which previously appear in the same discourse file.",0,original
xperimentation The corpus used in shallow parsing is extracted from the PENN TreeBank   of 1 million words   by a program provided by Sabine Buchholz from Tilburg University,0,original
"1 Introduction Since their appearance, BLEU   and NIST   have been the standard tools used for evaluating the quality of machine translation.",0,original
madja  finds significant bigrams using an estimate of z-score  ,0,original
The IBM translation models   describe word reordering via a distortion model defined over word positions within sentence pairs.,0,original
"Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation   systems to form a consensus output  .",0,original
"Stage 2 processing is then free to assign to the compound any bracketing for which it 3The design of this level of Lucy is influenced by Hobbs  , which advocates a level of """"surfaey"""" logical form with predicates close to actual English words and a structure similar to the syntactic structure of the sentence.",0,original
"4.2 Further practical issues of SCL In practice, there are more free parameters and model choices   besides the ones discussed above.",0,original
Either pruning   or lossy randomizing approaches   may result in a compact representation for the application run-time.,0,original
"Thus, GCNF is a more restrictive normal form than those used by Wu   and Melamed  .",0,original
"The original Ramshaw and Marcus   publication evaluated their NP chunker on two data sets, the second holding a larger amount of training data   while using 00 as test data.",0,original
"He uses a specic reliability statistic, , for his measurements, but Carletta   implicitly assumes kappa-like metrics are similar enough in practice for the rule of thumb to apply to them as well.A detailed discussion on the differences and similarities of these, and other, measures is provided by Krippendorff  ; in this article we will use Cohens    to investigate the value of the 0.8 reliability cut-off for computational linguistics.",0,original
Pattern-based IE approaches employ seed data to learn useful patterns to pinpoint required fields values  .,0,original
"A generative parsing model can be used on its own, and it was shown in Collins and Roark   that a discriminative parsing model can be used on its own.",0,original
"Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words  .",0,original
tandard data sets for machine learning approaches to this task were put forward by Ramshaw and Marcus  ,0,original
"The straight-forward way is to first generate the best BTG tree for each sentence pair using the way of  , then annotate each BTG node with linguistic elements by projecting source-side syntax tree to BTG tree, and finally extract rules from these annotated BTG trees.",0,original
"Such studies follow the empiricist approach to word meaning summarized best in the famous dictum of the British 3 linguist J.R. Firth: You shall know a word by the company it keeps.   Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks   and by Dunning  , of identifying word senses, e.g. by Yarowski   and by Schutze  , of clustering verb classes, e.g. by Schulte im Walde  , and of inducing selectional restrictions of verbs, e.g. by Resnik  , by Abe & Li  , by Rooth et al.",0,original
One is the longest common subsequence   based approach  .,0,original
"Motivated by the fact that non-syntactic phrases make non-trivial contribution to phrase-based SMT, the tree sequencebased translation model is proposed   that uses tree sequence as the basic translation unit, rather than using single sub-tree as in the STSG.",0,original
ur technique of generating negative examples is similar to the approach of Okanohara and Tsujii  ,0,original
he translation probability can also be discriminatively trained such as in Tillmann and Zhang  ,0,original
"Other factors that distinguish us from previous work are the use of all phrases proposed by a phrase-based system, and the use of a dependency language model that also incorporates constituent information   for related approaches).",0,original
Our evaluation metric is BLEU  .,0,original
This approach allows to combine strengths of generality of context attributes as in n-gram models   with their specificity as for binary features in MaxEnt taggers  .,0,original
"This includes both the parsers that attach probabilities to parser moves  , but also those of the lexicalized PCFG variety  .",0,original
Several approaches for learning from both labeled and unlabeled data have been proposed   where the unlabeled data is utilised to boost the performance of the algorithm.,0,original
"We use a program to label syntactic arguments with the roles they are playing  , and the rules for complement/adjunct distinction given by   to never allow deletion of the complement.",0,original
"At the end we ran our models once on TEST to get final numbers.2 4 Models Our experiments used phrase-based models  , which require a translation table and language model for decoding and feature computation.",0,original
"Attempts to alleviate this tagbottleneck i~lude tmotstr~ias   and unsupervised algorith~   Dictionary-based approaches rely on linguistic knowledge sources such as ma~l~i,~e-readable dictionaries   and WordNet   and e0(ploit these for word sense disaznbiguation.",0,original
"Experimental Comparison 4.1 Experiments on the ATIS corpus For our first comparison, we used I0 splits from the Penn ATIS corpus   into training sets of 675 sentences and test sets of 75 sentences.",0,original
uo and Zitouni   proposed a coreference resolution approach which also explores the information from the syntactic parse trees,0,original
But the lack of corpora has led to a situation where much of the current work on parsing is performed on a single domain using training data from that domain  the Wall Street Journal   section of the Penn Treebank  .,0,original
A similar view underlies the class-based methods cited in Section 2.4.3  .,0,original
1 A cept is defined as the set of target words connected to a source word  .,0,original
There are five different IBM translation models  .,0,original
"For symmetrization, we found that Och and Neys refined technique described in   produced the best AER for this data set under all experimental conditions.",0,original
Model weights were trained separately for all 3 systems using minimum error rate training to maximize BLEU   on the development set  .,0,original
kanohara and Tsujii   generate ill-formed sentences by sampling a probabilistic language model and end up with pseudo-negative examples which resemble machine translation output more than they do learner texts,0,original
Self-training   is a form of semi-supervised learning.,0,original
"1 Introduction Conditional Maximum Entropy   models have been widely used for a variety of tasks, including language modeling  , part-of-speech tagging, prepositional phrase attachment, and parsing  , word selection for machine translation  , and finding sentence boundaries  .",0,original
"At the present time, given the key role of window size in determining the selection and apparent strength of associations under the conventional co-occurrence model highlighted here and in the works of Church et al  , Rapp  , Wang  , and Schulte im Walde & Melinger   we would urge that this is an issue which window-driven studies continue to conscientiously address; at the very least, scale is a parameter which findings dependent on distributional phenomena must be qualified in light of.",0,original
"Among the several proposals, we mention here the models presented in  ,  ,  ,   and  .",0,original
"For instance, in Pang and Lee  , yd would be the polarity of the document and ysi would indicate whether sentence si is subjective or objective.",0,original
"Specifically, stochastic translation lexicons estimated using the IBM method   from a fairly large sentence-aligned Chinese-English parallel corpus are used in their approach  a considerable demand for a resourcedeficient language.",0,original
arowsky   used this method for word sense disambiguation,0,original
"1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews  .",0,original
"Distributional approaches, on the other hand, rely on text corpora, and model relatedness by comparing the contexts in which two words occur, assuming that related words occur in similar context  , Lin  , Mohammad and Hirst  ).",0,original
"In contrast, approaches to WSD attempt to take advantage of many different sources of information  ); it seems possible to obtain benefit from sources ranging from local collocational clues   to membership in semantically or topically related word classes   to consistency of word usages within a discourse  ; and disambignation seems highly lexically sensitive, in effect requiring specialized disamhignators for each polysemous word.",0,original
"Another technique used was to filter sentences of the out-of-domain corpus based on their similarity to the target domain, as predicted by a classifier  .",0,original
"The training set is extracted from TreeBank   section 1518, the development set, used in tuning parameters of the system, from section 20, and the test set from section 21.",0,original
"This shows that hypothesis features are either not discriminative enough, or that the reranking model is too weak This performance gap can be mainly attributed to two problems: optimization error and modeling error  .1 Much work has focused on developing better algorithms to tackle the optimization problem  ), since MT evaluation metrics such as BLEU and PER are riddled with local minima and are difficult to differentiate with respect to re-ranker parameters.",0,original
"The difference in accuracy between a SVM model applied to RRR dataset   and the same experiment applied to TB2 dataset   88.2 RRR Average human, whole sentence   93.2 RRR Maximum Likelihood-based   79.7 AP Maximum entropy, words   77.7 RRR Maximum entropy, words & classes   81.6 RRR Decision trees   77.7 RRR Transformation-Based Learning   81.8 WordNet Maximum-Likelihood based   84.5 RRR Maximum-Likelihood based   86.1 TB2 Decision trees & WSD   88.1 RRR WordNet Memory-based Learning   84.4 RRR LexSpace Maximum entropy, unsupervised   81.9 Maximum entropy, supervised   83.7 RRR Neural Nets   86.0 RRR WordNet Boosting   84.4 RRR Semi-probabilistic   84.31 RRR Maximum entropy, ensemble   85.5 RRR LSA SVM   84.8 RRR Nearest-neighbor   86.5 RRR DWS FN dataset, w/o semantic features   91.79 FN PR-WWW FN dataset, w/ semantic features   92.85 FN PR-WWW TB2 dataset, best feature set   93.62 TB2 PR-WWW Table 5: Accuracy of PP-attachment ambiguity resolution   basic experiment) is 2.9%.",0,original
"Co-Training has been used before in applications like word-sense disambiguation  , web-page classification   and namedentity identification  .",0,original
"As the third test set we selected all tokens of the Brown corpus part of the Penn Treebank  , a selected portion of the original one-million word Brown corpus  , a collection of samples of American English in many different genres, from sources printed in 1961; we refer to this test set as BROWN.",0,original
hen and Martin   explored the use of a range of syntactic and semantic features in unsupervised clustering of documents,0,original
"As our approach for incorporating unlabeled data, we basically follow the idea proposed in  .",0,original
"This method is described hereafter, while the subsequent steps, that use deeper   levels of knowledge, are implemented into the ARIOSTO_LEX lexical learning system, described in  .",0,original
We calculated the translation quality using Bleus modified n-gram precision metric   for n-grams of up to length four.,0,original
hunks as a separate level have also been used in Collins   and Ratnaparkhi  ,0,original
We concatenate the lists and we learn a new combination of weights that maximizes the Bleu score of the combined nbest list using the same development corpus we used for tuning the individual systems  .,0,original
"Haghighi and Klein   do the reverse: for each class label y, they ask the annotators to propose a few prototypical featuresf such thatp  is as high as possible.",0,original
"As in  , confusion networks built around all skeletons are joined into a lattice which is expanded and rescored with language models.",0,original
"We split the returned documents into classes encompassing n-grams  , adjectives  ) and noun phrases  ).",0,original
1 Introduction Sentiment detection and classification has received considerable attention recently  .,0,original
he later IBM models are formulated to prefer collocations  ,0,original
"Iterating between these two 1 Note that these problems are associated with corpus-based approaches in general, and have been identified by a number of researchers  .",0,original
"On one hand, as   evidence, clusters of paraphrases can lead to better learning of text-totext rewriting rules compared to just pairs of paraphrases.",0,original
"Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by a synchronous grammar  , and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string  .",0,original
4.2 Word alignment We have used IBM models proposed by Brown   for word aligning the parallel corpus.,0,original
Our method does not suppose a uniform distribution over all possible phrase segmentationsas   since each phrase tree has a probability.,0,original
"Using linguistic principles to recover empty categories Richard CAMPBELL Microsoft Research One Microsoft Way Redmond, WA 98052 USA richcamp@microsoft.com Abstract This paper describes an algorithm for detecting empty nodes in the Penn Treebank  , finding their antecedents, and assigning them function tags, without access to lexical information such as valency.",0,original
"In both cases there 1Alternatively, decisions from the sentence classifier can guide which input is seen by the document level classifier  .",0,original
The Spanish corpus was parsed using the MST dependency parser   trained using dependency trees generated from the the English Penn Treebank   and Spanish CoNLL-X data  .,0,original
" , Johnson  --that conditioning the probabilities of structures on the context within which they appear, for example on the lexical head of a constituent  , on the label of its parent nonterrninal  , or, ideally, on both and many other things besides, leads to a much better parsing model and results in higher parsing accuracies.",0,original
1 Introduction Aligning parallel texts has recently received considerable attention  .,0,original
In the first of our methods we align manual transcripts and ASR sentences using the IBM translation model   to obtain a probabilistic dictionary.,0,original
"By building the entire system on the derivation level, we side-step issues that can occur when perceptron training with hidden derivations  , but we also introduce the need to transform our training source-target pairs into training derivations.",0,original
"The tree-to-string model   views the translation as a structure mapping process, which first breaks the source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence.",0,original
4 Optimizing Metric Parameters The original version of Meteor   has instantiated values for three parameters in the metric: one for controlling the relative weight of precision and recall in computing the Fmean score  ; one governing the shape of the penalty as a function of fragmentation   and one for the relative weight assigned to the fragmentation penalty  .,0,original
The feature weights were tuned on a heldout development set so as to maximize an equally weighted linear combination of BLEU and 1-TER   using the minimum error training algorithm on a packed forest representation of the decoders hypothesis space  .,0,original
"In our experiments, we used the Hidden Markov Model   tagging method described in \ .",0,original
"Ordinary Prologstyle, backchaining deduction is augmented with the capability of making assumptions and of factoring two goal literals that are unifiable  .",0,original
"Decoding Conditions For tuning of the decoder's parameters, minimum error training   with respect to the BLEU score using was conducted using the respective development corpus.",0,original
204 4.2.2 Correlation between TREC nuggets and non-text features Analyzing the features used could let us understand summarization better  .,0,original
6 Related Work and Discussion There are several studies that used automatically extracted gazetteers for NER  .,0,original
"While bound compositions are not predictable, i.e., their reasonableness cannot be derived from the syntactic and semantic properties of the words in them .",0,original
"4.2 Support Vector Machines We chose to adopt a tagging perspective for the Simple NP chunking task, in which each word is to be tagged as either B, I or O depending on wether it is in the Beginning, Inside, or Outside of the given chunk, an approach first taken by Ramshaw and Marcus  , and which has become the de-facto standard for this task.",0,original
A few studies   addressed this defect by selecting the appropriate translation rules for an input span based on its context in the input sentence.,0,original
"The word alignment is computed using GIZA++2 for the selected 73,597 sentence pairs in the FBIS corpus in both directions and then combined using union and heuristic diagonal growing  .",0,original
"173 The standard features for genre classification models include words, part-of-speech   tags, and punctuation  , but constituent-based syntactic categories have also been explored  .",0,original
"Alternatively we could have simply incorporated the DIVERSITY measure into the objective function or used an inference algorithm that specifically accounts for redundancy, e.g., maximal marginal relevance  .",0,original
1 Introduction The task of sentence compression   can be defined as summarizing a single sentence by removing information from it  .,0,original
"Inter-annotator agreement was determined for six pairs of two annotators each, resulting in kappa values  ) ranging from 0.62 to 0.82 for the whole database (Carlson et al.",0,original
The weighting parameters of these features were optimized in terms of BLEU by the approach of minimum error rate training  .,0,original
"Most current transliteration systems use a generative model for transliteration such as freely available GIZA++1  ,an implementation of the IBM alignment models  .",0,original
"As noted in Talbot and Osborne  , errors for this log-frequency BF scheme are one-sided: frequencies will never be underestimated.",0,original
Minimum Error Rate Training     under BLEU criterion is used to estimate 20 feature function weights over the larger development set  .,0,original
"Specifically, Kim and Hovy   identify which political candidate is predicted to win by an opinion posted on a message board and aggregate opinions to correctly predict an election result.",0,original
The left-to-right parser would likely improve if we were to use a left-corner transform  .,0,original
arzilay and Lee   also used newspaper articles on the same event as comparable corpora to acquire paraphrases,0,original
"It has been shown by Shapiro and Stephens   and Wu (1997, Sec.",0,original
"4.1 Part-of-speech tagging experiments We split the Penn Treebank corpus   into training, development and test sets as in  .",0,original
  described symmetrized training of a 1-toN log-linear model and a M-to-1 log-linear model.,0,original
Algorithms for the more difficult task of word alignment were proposed in   and were applied for parameter estimation in the IBM statistical machine translation system  .,0,original
"This is contrastive to the one dimensional models used by Collinss perceptronbased sequence method   which our algorithms are based upon, and by the linear-chain CRFs.",0,original
Our baseline is the phrase-based MT system of  .,0,original
"In the following, we summarize the optimization algorithm for the unsmoothed error counts presented in   and the implementation detailed in  .",0,original
"This source of overcounting is considered and fixed by Wu   and Zens and Ney  , which we briefly review here.",0,original
"The approach is based on the hypothesis that positive words co-occur more than expected by chance, and so do negative words; this hypothesis was validated, at least for strong positive/negative words, in  .",0,original
These were combined using the Grow Diag Final And symmetrization heuristic  .,0,original
irst as the configuration space we can use only the reference nodes   from the lattice which makes it similar to the method of Berger et al. 1996 described in section 2.1,0,original
"Jiang and Zhai   then systematically explored a large space of features and evaluated the effectiveness of different feature subspaces corresponding to sequence, syntactic parse tree and dependency parse tree.",0,original
"Dunning   argues for the use of G 2 rather than X 2, based on an analysis of the sampling distributions of G 2 and X 2, and results obtained when using the statistics to acquire highly associated bigrams.",0,original
" , and Magerman   can suffer from very similar problems to the label bias or observation bias problem observed in tagging models, as described in Lafferty, McCallum, and Pereira   and Klein and Manning  .",0,original
he first is a novel stochastic search strategy that appears to make better use of Och  s algorithm for finding the global minimum along any given search direction than either coordinate descent or Powells method,0,original
"To examine the effects of including some known AMs on the performance, the following AMs had a 50% chance of being included in the initial population: pointwise mutual information  , the Dice coefficient, and the heuristic measure defined in  : H  =    2log f f f  if POS  = X, log f f f f  otherwise.",0,original
Related Work One of the first works that use statistical methods to detect implicit discourse relations is that of Marcu and Echihabi  ,0,original
.4 Related work and issues for future research Smadja   and van der Eijk   describe term translation methods that use bilingual texts that were aligned at the sentence level,0,original
Existing automatic evaluation measures such as BLEU   and ROUGE (Lin 2The collections are available.,0,original
"Jiang & Zhai   gave a systematic examination of the efficacy of unigram, bigram and trigram features drawn from different representations  surface text, constituency parse tree and dependency parse tree.",0,original
"Other commonly used measures include kappa   and relative utility  , both of which take into account the performance of a summarizer that randomly picks passages from the original document to produce an extract.",0,original
These domains have been commonly used in prior work on summarization  .,0,original
"When the value of Ilw, r,w'll is unknown, we assume that A and C are conditionally independent given B. The probability of A, B and C cooccurring is estimated by PMLE  PMLE  PMLE , where PMLE is the maximum likelihood estimation of a probability distribution and P.LE  = II*,*,*ll' P. ,~E  = II*,~,*ll ' P, LE  = When the value of Hw, r, w~H is known, we can obtain PMLE  directly: PMLE  = \ =c. Its value can be corn769 simgindZe  = ~'~ eTCwl)NTCw2)Aresubj.of.obj-of} min , I  ) simHindte,   = ~, eT nT  min , I ) \]T NT I simcosine  = x/IZ llZ l 2x IT nZ l simDice  = iT l+lT  I simJacard   = T OT l T  + T l-IT rlT l Figure 1: Other Similarity Measures puted as follows: I  = _ Iog PMLE PMLE ) -- ) log IIw,r,wflll*,r,*ll -IIw,r,*ll xll*,r,w'll It is worth noting that I  is equal to the mutual information between w and w'  .",0,original
2.1 Minimum Error Rate Training The predominant approach to reconciling the mismatch between the MAP decision rule and the evaluation metric has been to train the parameters  of the exponential model to correlate the MAP choice with the maximum score as indicated by the evaluation metric on a development set with known references  .,0,original
"4 Experimental Set-up For the experiments, we use the WSJ portion of the Penn tree bank  , using the standard train/development/test splits, viz 39,832 sentences from 2-21 sections, 2416 sentences from section 23 for testing and 1,700 sentences from section 22 for development.",0,original
"3.1 Maximum Entropy This section presents a brief description of ME. A more detailed and informative description can be found in Berger   4, Ratnaparkhi  , Manning and Shutze   to name just a few.",0,original
"They constructed word clusters by using HMMs or Browns clustering algorithm  , which utilize only information from neighboring words.",0,original
"Let us now compare our results to those obtained using shallow parsing, as previously done by Grefenstette  .",0,original
"In the following experiments, the NIST BLEU score is used as the evaluation metric  , which is reported as a percentage in the following sections.",0,original
"4.2 Binarization Schemes Besides the baseline   and iterative cost reduction binarization methods, we also perform right-heavy and random synchronous binarizations for comparison.",0,original
4.1 Training and Translation Setup Our decoder is a phrase-based multi-stack implementation of the log-linear model similar to Pharaoh  .,0,original
"The search also uses a Tag Dictionary constructed from training data, described in  , that reduces the number of actions explored by the tagging model.",0,original
Portage is a statistical phrase-based SMT system similar to Pharaoh  .,0,original
hurch and Hanks   employed mutual information to extract both adjacent and distant bi-grams that tend to co-occur within a fixed-size window,0,original
"A second pass aligns the sentences in a way similar1 to the algorithm described by Gale and Church  , but where the search space is constrained to be close to the one delimited by the word alignment.",0,original
"1 perform the following maximization: eI1 = argmax eI1 fPr Pr g   This approach is referred to as source-channel approach to statistical MT. Sometimes, it is also referred to as the fundamental equation of statistical MT  .",0,original
"Here, we extract part-of-speech tags from the Collins parsers output   for section 23 instead of reinventing a tagger.",0,original
ag test data using the POS-tagger described in Ratnaparkhi  ,0,original
"The two annotators agreed on the annotations of 385/453 turns, achieving 84.99% agreement  ).",0,original
e propose Smith and Eisners   quasi-synchronous grammar   as a general solution and the Jeopardy model   as a specific instance,0,original
"In the field of statistical analysis of natural language data, it is common to use measures of lexical association, such as the informationtheoretic measure of mutual information, to extract useful relationships between words  ).",0,original
"For the MER training  , we modify Koehns MER trainer   to train our system.",0,original
"In addition to the block sampler used by Bhattacharya and Getoor  , we are investigating general-purpose splitmerge samplers   and the permutation sampler  .",0,original
There is also work on grouping senses of other inventories using information in the inventory   along with information retrieval techniques  .,0,original
"2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news  , review classification  , mining opinions from product reviews  , automatic expressive text-to-speech synthesis  , text semantic analysis  , and question answering  .",0,original
"It is often argued that the ability to translate discontiguous phrases is important to modeling translation  , and it may be that this explains the results.",0,original
A later study   found that performance increased to 87.2% when considering only those portions of the text deemed to be subjective.,0,original
"The small differences from their work are:   We used characters as the unit as we described above,   While Kazama and Torisawa   checked only the word sequences that start with a capitalized word and thus exploitedthecharacteristicsofEnglishlanguage, we checked the matching at every character,   We used a TRIE to make the look-up efcient.",0,original
2.4 Factor Model Decomposition Factored translation models   extend the phrase-based model by integrating word level factors into the decoding process.,0,original
Pharaoh also includes lexical weighting parameters that are derived from the alignments used to induce its phrase pairs  .,0,original
urran   and Lin   use syntactic features in the vector definition,0,original
"Amazon Reviews: The dataset contains product reviews taken from Amazon.com from 4 product types: Kitchen, Books, DVDs, and Electronics  .",0,original
aume III   proposed a simple feature augmentation method to achieve domain adaptation,0,original
are equivalent to a maximum entropy variant of the phrase sense disambiguation approach studied by Carpuat & Wu  ,0,original
Both taggers used the Penn Treebank tagset and were trained on the Wall Street Journal corpus  .,0,original
"The association relationship between two words can be indicated by their mutual information, which can be further used to discover phrases \ .",0,original
"Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees  , or on incorporating nonlocal dependency information in nonterminal categories in constituency representations   or in the categories used to label arcs in dependency representations  .",0,original
"These problems include collocation discovery  , smoothing and estimation   and question answering  .",0,original
These estimates are usually heuristic and inconsistent  .,0,original
"Even before the 2006 shared task, the parsers of Collins   and Charniak  , originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto   and Yamada and Matsumoto   had been evaluated on both Japanese and English.",0,original
This negation handling is similar to that used in  .,0,original
"203 Estimating the parameters for these models is more difficult   than with the models considered in the previous section: rather than simply being able to count the word pairs and alignment relationships and estimate the models directly, we must use an existing model to compute the expected counts for all possible alignments, and then use these counts to update the new model.7 This training strategy is referred to as expectationmaximization   and is guaranteed to always improve the quality of the prior model at each iteration  .",0,original
"When different decoder settings are applied to the same model, MERT weights   from the unprojected single pass setup are used and are kept constant across runs.",0,original
"9 The definition of BLEU used in this training was the original IBM definition  , which defines the effective reference length as the reference length that is closest to the test sentence length.",0,original
ur method uses assumptions similar to Berger et al. 1996 but is naturally suitable for distributed parallel computations,0,original
"1 Introduction In this paper, we show how discriminative training with averaged perceptron models   can be used to substantially improve surface realization with Combinatory Categorial Grammar  .",0,original
Others proposed distributional similarity measures between words  .,0,original
"2 Extracting paraphrases Much previous work on extracting paraphrases   has focused on finding identifying contexts within aligned monolingual sentences from which divergent text can be extracted, and treated as paraphrases.",0,original
"However, searching the space of all possible alignments is intractable for EM, so in practice the procedure is bootstrapped by models with narrower search space such as IBM Model 1   or Aachen HMM  .",0,original
Perceptron Training We optimize feature weights using a modification of averaged perceptron learning as described by Collins  ,0,original
"1 Introduction Hyponymy relations can play a crucial role in various NLP systems, and there have been many attempts to develop automatic methods to acquire hyponymy relations from text corpora  .",0,original
The hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder  .,0,original
"After line 17, we can employ the one-sense-per-discourse heuristic to further classify unclassified data, as proposed in Yarowsky  .",0,original
We argue that linguistic knowledge could not only improve results   but is essential when extracting collocations from certain languages: this knowledge provides other applications   with a ne-grained description of how the extracted collocations are to be used in context.,0,original
"In this paper we will compare and evaluate several aspects of these techniques, focusing on Minimum Error Rate   training   and Minimum Bayes Risk   decision rules, within a novel training environment that isolates the impact of each component of these methods.",0,original
"The difficulty of this task is that the standard method for converting NER to a sequence tagging problem with BIOencoding  , where each 1http://www.nist.gov/speech/tests/ace/ index.htm token is assigned a tag to indicate whether it is at the beginning  , inside  , or outside   of an entity, is not directly applicable when tokens belong to more than one entity.",0,original
"1 Introduction Word compositions have long been a concern in lexicography , and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, e.g., parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etc. .",0,original
"Yarowsky   describes a 'semi-unsupervised' approach to the problem of sense disambiguation of words, also using a set of initial seeds, in this case a few high quality sense annotations.",0,original
Various corpus-based approaches to word sense disambiguation have been proposed  .,0,original
"Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues    , sense preference  , acquisition of selectional restrictions  , lexical preference in generation  , word clustering  , etc. In the majority of these papers, even though the   statistical processing reduces the number of accidental associations, very large corpora   are necessary to obtain reliable data on a """"large enough"""" number of words.",0,original
"First, we considered single sentences as documents, and tokens as sentences   but also a cognate-based one similar to  .",0,original
"3.1 Translation Model Form We first assume the general hypergraph setting of Huang and Chiang  , namely, that derivations under our translation model form a hypergraph.",0,original
.2.1 Proxy items There is a potential risk of redundancy if we represent related statistics using the log-frequency BF scheme presented in Talbot and Osborne  ,0,original
"Our system attempts to recognize these syntactic patterus; in addition, it considers as unfamiliar some definites occurring in 4This list was developed by hand; more recently, Bean and Riloff   proposed methods for autolnatically extracting fl'om a corpus such special predicates, i.e., heads that correlate well with discourse novelty.",0,original
The techniques examined are Structural Correspondence Learning     and Self-training  .,0,original
3 GM Representation of IBM MT Models In this section we present a GM representation for IBM model 3   in fig.,0,original
The production weights are estimated either by heuristic counting   or using the EM algorithm.,0,original
"  proposed sentence alignment techniques based on dynamic programming, using sentence length and lexical mapping information.",0,original
Further details are in the original paper  .,0,original
The model was trained on sections 221 from the English Penn Treebank  .,0,original
We use Minimal Error Rate Training   to maximize BLEU on the complete development data.,0,original
"Under a phrase based translation model  , this distinction is important and will be discussed in more detail.",0,original
"On the positive side, recent work exploring the automaticbinarizationofsynchronousgrammars  has indicated that non-binarizable constructions seem to be relatively rare in practice.",0,original
"The principle of maximum entropy states that when one searches among probability distributions that model the observed data  , the preferred one is the one that maximizes the entropy    .",0,original
"Following  , we used sections 0-18 of the Wall Street Journal   corpus for training, sections 19-21 for development, and sections 22-24 for final evaluation.",0,original
"1 Introduction Motivation: Sharing basic intuitions and longterm goals with other tasks within the area of Webbased information extraction  , the task of acquiring class attributes relies on unstructured text available on the Web, as a data source for extracting generally-useful knowledge.",0,original
"One other published model for grouping semantically related words  , is based on a statistical model of bigrams and trigrams and produces word groups using no linguistic knowledge, but no evaluation of the results is reported.",0,original
"3.2 Results In line with previous work  , we first compare Naive Bayes and Logistic regression on the two NLP tasks.",0,original
"Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments  .",0,original
"For extrinsic evaluation of machine translation, we use the BLEU metric  .",0,original
"While other systems, such as  , have addressed these tasks to some degree, OPINE is the first to report results.",0,original
We implemented these models within an maximum entropy framework  .,0,original
1 Introduction Syntax-based translation models   are usually built directly from Penn Treebank     style parse trees by composing treebank grammar rules.,0,original
"We have   Hypernym Patterns based on patterns proposed by   and  ,   Sibling Patterns which are basically conjunctions, and   Part-of Patterns based on patterns proposed by   and  .",0,original
2 Architecture of the system The goal of statistical machine translation   is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units   and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp  = argmaxe {exp )}   The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set  .,0,original
he use of structured prediction to SMT is also investigated by  ,0,original
"Usually in 1 In our experiments, we set negative PMI values to 0, because Church and Hanks  , in their seminal paper on word association ratio, show that negative PMI values are not expected to be accurate unless co-occurrence counts are made from an extremely large corpus.",0,original
"3.3 Corpora Our labeled data comes from the Penn Treebank   and consists of about 40,000 sentences from Wall Street Journal   articles 153 annotated with syntactic information.",0,original
Previous Work There have been several approaches to automatically discovering lexico-semantic information from text  ,0,original
"Feature weights of both systems are tuned on the same data set.3 For Pharaoh, we use the standard minimum error-rate training  ; and for our system, since there are only two independent features  , we use a simple grid-based line-optimization along the language-model weight axis.",0,original
"This involves running GIZA++   on the corpus in both directions, and applying renement rules   to obtain a single many-tomany word alignment for each sentence.",0,original
4.2 Automatic Evaluation We first present our soft cohesion constraints effect on BLEU score   for both our dev-test and test sets.,0,original
e adopt a similar approach to the one used in Turney   and consider each question as a separate binary classification problem with one positive training instance and 5 unknown pairs,0,original
  show that treating U+ as a source for a new feature function in a loglinear model for SMT   allows us to maximally take advantage of unlabeled data by finding a weight for this feature using minimum error-rate training    .,0,original
"7 In the models described in Collins  , there was a third question concerning punctuation:   Does the string contain 0, 1, 2 or more than 2 commas?",0,original
ord association norms based on co-occurrence information have been proposed by  ,0,original
"1993; Chang et al. , 1992; Collins and Brooks, 1995; Fujisaki, 1989; Hindle and Rooth, 1991; Hindle and Rooth, 1993; Jelinek et al. , 1990; Magerman and Marcus, 1991; Magerman, 1995; Ratnaparkhi et al. , 1994; Resnik, 1993; Su and Chang, 1988).",0,original
"In this paper we focus on the second issue, constraining the grammar to the binary-branching Inversion Transduction Grammar of Wu  .",0,original
Such linguistic-preprocessing techniques could 1Various models have been constructed by the IBM team  .,0,original
5 SMT Experiments 5.1 Experimental Setup We used publicly available resources for all our tests: for decoding we used Moses   and our parallel data was taken from the Spanish-English section of Europarl.,0,original
"Church and Hanks 1990; Klavans, Chodorow, and Wacholder 1990; Wilks et al. 1993; Smadja 1991a, 1991b; Calzolari and Bindi 1990).",0,original
We then proceed to split the data into smaller sentences and tag them using Ratnaparkhis Maximum Entropy Tagger  .,0,original
avid Yarowsky   showed it was accurate in the word sense disambiguation,0,original
"Examples of such methods are the introduction of information weights as in the NIST measure or the comparison of stems or synonyms, as in METEOR  .",0,original
"Aware of this problem, Resnik and Yarowsky suggest creating the sense distance matrix based on results in experimental psychology such as Miller and Charles   or Resnik  .",0,original
Classes can be induced directly from the corpus using distributional clustering   or taken from a manually crafted taxonomy  .,0,original
"A related example would be a version of synchronous CFG that allows only one pair of linked nonterminals and any number of unlinked nonterminals, which could be bitextparsed in O  time, whereas inversion transduction grammar   takes O .",0,original
"However, due to the computational issues with the voted perceptron, the averaged perceptron algorithm   is used instead.",0,original
"They train from the Penn Treebank  ; a collection of 40,000 sentences that are labeled with corrected parse trees  .",0,original
"We hence chose transformation-based learning to create this   segmentation grammar, converting the segmentation task into a tagging task  , inter alia).",0,original
"This situation is very similar to the training process of translation models in statistical machine translation  , where parallel corpus is used to find the mappings between words from different languages by exploiting their co-occurrence patterns.",0,original
"It will also be relevant to apply advanced statistical models that can incorporate various useful information to this task, e.g., the maximum entropy model  .",0,original
84.12 only PTB   83.58 1st   83.42 2nd   83.38 3rd   83.08 third row lists the three highest scores of the domain adaptation track of the CoNLL 2007 shared task.,0,original
"l lhmsetsu ideni,illcation is a ln'oblem similar to ohm,king   in other l;mguages.",0,original
In this paper we use the phrase-based system of   as our underlying model.,0,original
"For these first SMT systems, translation-model probabilities at the sentence level were approximated from word-based translation models that were trained by using bilingual corpora  .",0,original
"We ran GIZA++   on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in   to obtain a many-to-many word alignment for each sentence pair.",0,original
"Note that the results of MB-D here cannot be directly compared with those in  , mainly because the data used are different.",0,original
4.1 Experimental Setup We use the whole Penn Treebank corpus   as our data set.,0,original
"4 Experiments and Results 4.1 Set up We parsed the 3 GB AQUAINT corpus   using Minipar  , and collected verb-object and verb-subject frequencies, building an empirical MI model from this data.",0,original
"Barzilay and Lee   proposed to apply multiple-sequence alignment   for traditional, sentence-level PR.",0,original
"3.3 Voted Perceptron Unlike other methods discussed so far, voted perceptron training   attempts to minimize the difference between the global feature vector for a training instance and the same feature vector for the best-scoring labeling of that instance according to the current model.",0,original
We are currently investigating more challenging problems like multiple category classification using the Reuters-21578 data set   and subjective sentiment classification  .,0,original
Feature weights were set with minimum error rate training   on a development set using BLEU   as the objective function.,0,original
"The data set consisting of 249,994 TFSs was generated by parsing the Figure 3: The size of Dpi; for the size of the data set 800 bracketed sentences in the Wall Street Journal corpus   in the Penn Treebank   with the XHPSG grammar  .",0,original
"2.1 Word Sequence Classification Similar to English text chunking  , the word sequence classification model aims to classify each word via encoding its context features.",0,original
"For the Penn Treebank, our research and the work of others   have shown that such a correspondence exists in most cases.",0,original
Part-of-speech tags are assigned by the MXPOST maximum-entropy based part-of-speech tagger  .,0,original
"For this study, we used the same 6 test meetings as in  .",0,original
"By treating a letter/character as a word and a group of letters/characters as a phrase or token unit in SMT, one can easily apply the traditional SMT models, such as the IBM generative model   or the phrase-based translation model   to transliteration.",0,original
"For example, in this work we use loglikelihood ratio   to determine the SoA between a word sense and co-occurring words, and cosine to determine the distance between two DPWSs log likelihood vectors  .",0,original
"Finally, in order to formally evaluate the method and the different heuristics, a large-scale evaluation on the BioMed Corpus is under way, based on computing the ROUGE measures  .",0,original
"We obtain aligned parallel sentences and the phrase table after the training of Moses, which includes running GIZA++  , grow-diagonal-final symmetrization and phrase extraction  .",0,original
"  applied to the output of the reranking parser of Charniak and Johnson  , whereas in BE   dependencies are generated by the Minipar parser  .",0,original
"  compare two tagging frameworks for tagging French, one that is statistical, built upon the Xerox tagger  , and another based on linguistic constraints only.",0,original
2.5 Model Training We adapt the Minimum Error Rate Training     algorithm to estimate parameters for each member model in co-decoding.,0,original
"1 Introduction There has been a great deal of recent interest in the unsupervised discovery of syntactic structure from text, both parts-of-speech   and deeper grammatical structure like constituency and dependency trees  .",0,original
"2.2 Perceptron algorithm Our discriminative n-gram model training approach uses the perceptron algorithm, as presented in  , which follows the general approach presented in  .",0,original
"For the evaluation of translation quality, we applied standard automatic evaluation metrics, i.e., BLEU   and METEOR  .",0,original
"Note that this early discarding is related to ideas behind cube pruning  , which generates the top n most promising hypotheses, but in our method the decision not to generate hypotheses is guided by the quality of hypotheses on the result stack.",0,original
"Thus, we propose a bootstrapping approach   to train the stochastic transducer iteratively as it extracts transliterations from a bitext.",0,original
Note that apart from previous work   we use complete skip-chain   edges in hc .,0,original
"The first approach is to reuse the components of a generative model, but tune their relative weights in a discriminative fashion  .",0,original
"The term global feature vector is used by Collins   to distinguish between feature count vectors for whole sequences and the local feature vectors in ME tagging models, which are Boolean valued vectors containing the indicator features for one element in the sequence.",0,original
This formula follows the convention of   in letting so designate the null state.,0,original
"However, in yet unpublished work we found that at least for the computation of synonyms and related words neither syntactical analysis nor singular value decomposition lead to significantly better results than the approach described here when applied to the monolingual case  , so we did not try to include these methods in our system.",0,original
"Likelihood ratios are particularly useful when comparing common and rare events  , making them natural here given the rareness of most question categories and the frequency of contributions.",0,original
"4.6 Weakly-constrained algorithms In evaluation with ROUGE  , summaries are truncated to a target length K. Yih et al. usedastackdecodingwithaslightmodication, which allows the last sentence in a summary to be truncated to a target length.",0,original
"In order to minimize the number of decision errors at the sentence level, we have to choose the sequence of target words eI1 according to the equation  : eI1 = argmax eI1 n Pr  o = argmax eI1 n Pr Pr  o : Here, the posterior probability Pr  is decomposed into the language model probability Pr  and the string translation probability Pr .",0,original
"2.1 Training the model As with  , we train the language model on the Penn Treebank  .",0,original
"The perceptron has been used in many NLP tasks, such as POS tagging  , Chinese word segmentation   and so on.",0,original
"Examples of statistical and machine learning approaches that have been used for tagging include transformation based learning  , memory based learning  , and maximum entropy models  .",0,original
"So far research in automatic opinion recognition has primarily addressed learning subjective language  , identifying opinionated documents   and sentences  , and discriminating between positive and negative language  .",0,original
"In this paper we present a novel PCFG-based architecture for probabilistic generation based on wide-coverage, robust Lexical Functional Grammar   approximations automatically extracted from treebanks  .",0,original
"Alternatively, one can view   as inducing an alignment between terms in the h to the terms in the t, somewhat similar to alignment models in statistical MT  .",0,original
These alignments can be obtained from single-word models   using the available public software GIZA++  .,0,original
This preprocessing step can be accomplished by applying the GIZA++ toolkit   that provides Viterbi alignments based on IBM Model-4.,0,original
he distortion probabilities are class-based: They depend on the word class F  of a covered source word f as well as on the word class E  of the previously generated target word e. The classes are automatically trained  ,0,original
2 Related Research Several researchers   have already proposed methods for binarizing synchronous grammars in the context of machine translation.,0,original
"Also, PMI-IR is useful for calculating semantic orientation and rating reviews  .",0,original
"In Brown et al  , the authors provide some sample subtrees resulting from such a 1,000-word clustering.",0,original
"For example, sentence alignment of bilingual texts are performed just by measuring sentence lengths in words or in characters  , or by statistically estimating word level correspondences  .",0,original
"  showed how to use the Voted Perceptron algorithm for learning W, and we use it for learning the global transliteration model.",0,original
"Some researchers then tried to automatically extract paraphrase rules  , which facilitates the rule-based PG methods.",0,original
Various clustering techniques have been proposed   which perform automatic word clustering optimizing a maximum-likelihood criterion with iterative clustering algorithms.,0,original
We extract the named entities from the web pages using the Stanford Named Entity Recognizer  .,0,original
One option would be to leverage unannotated text  .,0,original
"There exist many different string similarity measures: word overlap  , longest common subsequence  , Levenshteinedit distance  , word n-gramoverlap   etc. Semantic similarity measures are obtained by first computing the semantic similarity of the words containedin the sentencesbeing compared.",0,original
"In this paper, we employed the Chinese word segmentation tool   that achieved about 0.93-0.96 recall/precision rates in the SIGHAN-3 word segmentation task  .",0,original
"  describe how to learn hundreds of millions of treetransformation rules from a parsed, aligned Chinese/English corpus, and Galley et al.",0,original
"Two are conditionalized phrasal models, each EM trained until performance degrades:  C-JPTM3 as described in    Phrasal ITG as described in Section 4.1 Three provide alignments for the surface heuristic:  GIZA++ with grow-diag-final    Viterbi Phrasal ITG with and without the noncompositional constraint We use the Pharaoh decoder   with the SMT Shared Task baseline system  .",0,original
"Specifically, we explore the statistical term weighting features of the word generation model with Support Vector machine  , faithfully reproducing previous work as closely as possible  .",0,original
The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in  .,0,original
"Riezler and Maxwell   combine transfer-based and statistical MT; they back off to the SMT translation when the grammar is inadequate, analysing the grammar to determine this.",0,original
OS tag the text using Ratnaparkhi  ,0,original
he lexicalized model proposed by Collins     was re-implemented by one of the authors,0,original
"FollowingtheworkofKooetal. andSmith and Smith  , it is possible to compute all expectations in O  through matrix inversion.",0,original
  was an implicit or selforganizing syntax model as it did not use a Treebank.,0,original
We augment each labeled target instance xj with the label assigned by the source domain classifier  .,0,original
We then examined the inter-annotator reliability of the annotation by calculating the  score  .,0,original
This method has the advantage that it is not limited to the model scaling factors as the method described in  .,0,original
" , sometimes augmented by an HMM-based model or Och and Neys Model 6  .",0,original
"However, our representation of the model conceptually separates some of the hyperparameters which are not separated in  , and we found that setting these hyperparameters with different values from one another was critical for improving performance.",0,original
Our approach to statistical machine translation differs from the model proposed in   in that:  We compute the joint model P  from the bilanguage corpus to account for the direct mapping of the source sentence Ws into the target sentence I?VT that is ordered according to the  source language word order.,0,original
"6 Related Work Other work combining supervised and unsupervised learning for parsing includes  ,  , and  .",0,original
"Between them, the phrase-based approach   allows local reordering and contiguous phrase translation.",0,original
Most of the early work in this area was based on postulating generative probability models of language that included parse structures  .,0,original
"These include scripts for creating alignments from a parallel corpus, creating phrase tables and language models, binarizing phrase tables, scripts for weight optimization using MERT  , and testing scripts.",0,original
" ), the tagger for grammatical functions works with lexical and contextual probability measures Pq .",0,original
"Obviously, these productions are not in the normal form of an ITG, but with the method described in  , they can be normalized.",0,original
"However, the learning curve for Negra   indicates that the performance of the Collins   model is stable, even for small training sets.",0,original
"The implementation includes path-length  , information-content   and text-overlap   measures, as described in Strube & Ponzetto  .",0,original
"This is similar to Model 3 of  , but without null-generated elements or re-ordering.",0,original
"Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools  ,  ,  , or for automatic thesaurus generation  .",0,original
"In earlier IBM translation systems   each English word would be generated by, or """"aligned to"""", exactly one formal language word.",0,original
"On the contrary, a string-to-tree decoder  ) is a parser that applies string-to-tree rules to obtain a target parse for the source string.",0,original
"The features we used are as follows:  word posterior probability  ;  3, 4-gram target language model;  word length penalty;  Null word length penalty; Also, we use MERT   to tune the weights of confusion network.",0,original
"Therefore, Lin and Och   introduced skip-bigram statistics for the evaluation of machine translation.",0,original
"In addition, IC is stable even for relatively low frequency words, which can be contrasted with Fano's mutual information formula recently used by Church and Hanks   to compute word cooccurrence patterns in a 44 million word corpus of Associated Press news stories.",0,original
"Furthermore, we use averaged weights   in Algorithm 1.",0,original
Precision and recall rates were 92.4% on the same data used in  .,0,original
"Becausesuchapproachesdirectly learn a generative model over phrase pairs, they are theoretically preferable to the standard heuristics for extracting the phrase pairs from the many-to-one word-level alignments produced by the IBM series models   or the Hidden Markov Model    .",0,original
"The phrase bilexicon is derived from the intersection of bidirectional IBM Model 4 alignments, obtained with GIZA++  , augmented to improve recall using the grow-diag-final heuristic.",0,original
4.1 NER features We used the features generated by the CRF package  .,0,original
"Syntactic criteria are relevant, but clearly not decisive, as can be observed in  .",0,original
The XEROX tagger comes with a list of built-in ending guessing rules  .,0,original
"Other classes, such as the ones below can be extracted using lexico-statistical tools, such as in  , and then checked by a human.",0,original
"405 PRF 1 proposed .383 .437 .408 multinomial mixture .360 .374 .367 Newman   .318 .353 .334 cosine .603 .114 .192 -skew divergence   .730 .155 .255 Lins similarity   .691 .096 .169 CBC   .981 .060 .114 Table 3: Precision, recall, and F-measure.",0,original
"1 Introduction Word Sense Disambiguation   competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions  .",0,original
It has been used for diverse problems such as machine translation and sense disambiguation \ .,0,original
There has been a sizable amount of research on structure induction ranging fromlinearsegmentation tocontent modeling  .,0,original
Note that the predicate language representation utilized by Carmel-Tools is in the style of Davidsonian event based semantics  .,0,original
"And again, we see this insight informing statistical machine translation systems, for instance, in the phrase-based approaches of Och   and Koehn et al.",0,original
"Relatedness scores are computed for each pair of senses of the grammatically linked pair of words  , using the WordNet-Similarity-1.03 package and the lesk 759 option  .",0,original
he prevalent use of this criterion despite repeated advice that it is unlikely to be suitable for all studies   is probably due to a desire for a simple system that can be easily applied to a scheme,0,original
"303 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures  , we are able to identify higher-precision collocations by including placeholders for unique words  .",0,original
"In an attempt to provide a quantitative evaluation of our results, for each of the 12 ambiguous words shown in table 1 we manually assigned the top 30 first-order associations to one of the two senses provided by Yarowsky  .",0,original
"At one extreme are those, exemplified by that of Wu  , that have no dependence on syntactic theory beyond the idea that natural language is hierarchical.",0,original
"The simplest version, called Dependency Model with Valence  , has been used in isolation and in combination with other models  .",0,original
"With automatic refinement it is harder to guarantee improved performance than with manual refinements   or with refinements based on direct lexicalization  , Collins  , Charniak  , etc.).",0,original
"In supervised domain adaptation  , besides the labeled source data, we have access to a comparably small, but labeled amount of target data.",0,original
"Since then, supervised learning from sense-tagged corpora has since been used by several researchers: Zernik  , Hearst  , Leacock, Towell, and Voorhees  , Gale, Church, and Yarowsky  , Bruce and Wiebe  , Miller et al.",0,original
"In particular, previous work   has investigated the use of Markov random fields   or log-linear models as probabilistic models with global features for parsing and other NLP tasks.",0,original
"In his Xtract system, Smadja   first extracted significant pairs of words that consistently co-occur within a single syntactic structure using statistical scores called distance, strength and spread, and then examined concordances of the bi-grams to find longer frequent multiword units.",0,original
"The dependency trees induced when each rewrite rule in an i-th order LCFRS distinguish a unique head can similarly be characterized by being of gap-degree i, so that i is the maximum number of gaps that may appear between contiguous substrings of any subtree in the dependency tree  .",0,original
"The idea caught on very quickly: Suhm and Waibel  , Mast et aL  , Warnke et al.",0,original
"The WSJ corpus is based on the WSJ part of the PENN TREEBANK  ; we used the first 10,000 sentences of section 2-21 as the pool set, and section 00 as evaluation set  .",0,original
These methods often involve using a statistic such as 2   or the log likelihood ratio   to create a score to measure the strength of correlation between source and target words.,0,original
"This setting is reminiscent of the problem of optimizing feature weights for reranking of candidate machine translation outputs, and we employ an optimization technique similar to that used by Och   for machine translation.",0,original
Discriminatively trained parsers that score entire trees for a given sentence have only recently been investigated  .,0,original
"The Collins   model does not use context-free rules, but generates the next category using zeroth order Markov chains  , hence no information about the previous sisters is included.",0,original
The reported results for the full parse tree   are recall/precision of 88.1/87.5  .,0,original
"After maximum BLEU tuning   on a held-out tuning set, we evaluate translation quality on a held-out test set.",0,original
"Thelistsmaybeused withannotation and a tuning process, such as in  , to iteratively alter feature weights and improve results.",0,original
Most approaches   inherently extract semantic knowledge in the abstracted form of semantic clusters.,0,original
"??word proximity: For the web searches, Turney   uses the NEAR operator and considers only those documents that contain the adjectives within a specific proximity.",0,original
Our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation  .,0,original
1 Introduction Most empirical work in translation analyzes models and algorithms using BLEU   and related metrics.,0,original
"In shift-reduce parsing, further mistakes are often caused by previous ones, so only the first mistake in each sentence   is easily identifiable;7 this is also the argument for early update in applying perceptron learning to these incremental parsing algorithms    .",0,original
"c2008 Association for Computational Linguistics Refining Event Extraction through Cross-document Inference   Heng Ji Ralph Grishman Computer Science Department New York University New York, NY 10003, USA  @cs.nyu.edu       Abstract We apply the hypothesis of One Sense Per Discourse   to information extraction  , and extend the scope of discourse from one single document to a cluster of topically-related documents.",0,original
he third function is an original variant of the second; the fourth is original; and the fifth is prompted by the arguments of Dunning  ,0,original
"Then, we run GIZA++   on the corpus to obtain word alignments in both directions.",0,original
McArthur 1992; Mei et al. 1993) Classification allows a word to align with a target word using the collective translation tendency of words in the same class,0,original
"When the data has distinct sub-structures, models that exploit hidden state variables are advantageous in learning  .",0,original
"This is a problem with other direct translation models, such as IBM model 1 used as a direct model rather than a channel model  .",0,original
2A maximum-entropy-based part of speech tagger was used   without the adaptation to the biomedical domain.,0,original
The toolkit also implements suffix-array grammar extraction   and minimum error rate training  .,0,original
"Turney   argues that many NLP tasks can be formulated in terms of analogical reasoning, and he applies his PairClass algorithm to a number of problems including SAT verbal analogy tests, synonym/antonym classification and distinction between semantically similar and semantically associated words.",0,original
MET   iterative parameter estimation under IBM BLEU is performed on the development set.,0,original
It acquires a set of synchronous lexical entries by running the IBM alignment model   and learns a log-linear model to weight parses.,0,original
"The most similar work to ours is  , in which two most common synsets from WordNet for all words in an NP and their hypernyms are extracted as features.",0,original
Paraphrasesofthiskind have been shown to be useful in applications such as machine translation   and as an intermediate step in inventory-based classification of abstract relations  .,0,original
"In general the training set is the parsed Wall Street Journal  , with few exceptions, and the size of the training samples is around 10-20,000 test cases.",0,original
"1 Data Data for 64 verbs   was collected from three corpora; The British National Corpus    , the Penn Treehank parsed version of the Brown Corpus  , and the Penn Treebank Wall Street Journal corpas    .",0,original
"They have been employed in word sense disambiguation  , automatic construction of bilingual dictionaries  , and inducing statistical machine translation models  .",0,original
"Syntax-based MT approaches began with Wu  , who introduced the Inversion Transduction Grammars.",0,original
Wu   shows that parsing a binary SCFG is in O  while parsing SCFG is NP-hard in general  .,0,original
"For example, the Penn Treebank   provides a large corpus of syntactically annotated examples mostly from the Wall Street Journal.",0,original
We referred to the studies of  .,0,original
"After that, we used three types of methods for performing a symmetrization of IBM models: intersection, union, and refined methods  .",0,original
"6.3 Unsupervised sentiment classification Turney proposed the unsupervised method for sentiment classification  , and similar method is utilized by many other researchers  .",0,original
"Our work builds upon Turneys work on semantic orientation   and synonym learning  , in which he used a PMI-IR algorithm to measure the similarity of words and phrases based on Web queries.",0,original
"To our knowledge no systems directly address Problem 1, instead choosing to ignore the problem by using one or a small handful of reference derivations in an n-best list  , or else making local independence assumptions which side-step the issue  .",0,original
"Following Collins and Roark   we also use the early-update strategy, where an update happens whenever the goldstandard action-sequence falls off the beam, with the rest of the sequence neglected.",0,original
"By core phrases, we mean the kind of nonrecursive simplifications of the NP and VP that in the literature go by names such as noun/verb groups   or chunks, and base NPs  .",0,original
"With the exception of Fraser and Marcu  , these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features.",0,original
"We tune using Ochs algorithm   to optimize weights for the distortion model, language model, phrase translation model and word penalty over the BLEU metric  .",0,original
"Goodman, 2004) and lscript22 regularization  .",0,original
"Finally, knowledge of polarity can be combined with corpus-based collocation extraction methods   to automatically produce entries for the lexical functions used in MeaningText Theory   for text generation.",0,original
A similar observation was made in  .,0,original
"4 Phrase-Based Translation In phrase-based translation, the translation process is modeled by splitting the source sentence into phrases   and translating the phrases as a unit  .",0,original
"1 To train their system, R&M used a 200k-word chunk of the Penn Treebank Parsed Wall Street Journal   tagged using a transformation-based tagger   and extracted base noun phrases from its parses by selecting noun phrases that contained no nested noun phrases and further processing the data with some heuristics   to flatten the recursive structure of the parse.",0,original
3.1 Agreement for Emotion Classes The kappa coefficient of agreement is a statistic adopted by the Computational Linguistics community as a standard measure for this purpose  .,0,original
"2 Linguistic and Context Features 2.1 Non-terminal Labels In the original string-to-dependency model  , a translation rule is composed of a string of words and non-terminals on the source side and a well-formed dependency structure on the target side.",0,original
We only describe these models briefly since full details are presented elsewhere .,0,original
"Similarly, Murdock and Croft   adopted a simple translation model from IBM model 1   and applied it to QA.",0,original
The focus of much of the automatic sentiment analysis research is on identifying the affect bearing words   and on measurement approaches for sentiment  .,0,original
"Co-training   is related to self-training, in that an algorithm is trained on its own predictions.",0,original
That is obtained using the Viterbi alignment provided by a translation model as described in  .,0,original
Introduction Verb subcategorizafion probabilities play an important role in both computational linguistic applications   and psycholinguisfic models of language processing  .,0,original
"In Table 6 we report our results, together with the state-of-the-art from the ACL wiki5 and the scores of Turney     and from Amac Herdagdelens PairSpace system, that was trained on ukWaC.",0,original
"1 Introduction ROUGE   and its linguisticallymotivated descendent, Basic Elements    , evaluate a summary by computing its overlap with a set of model   summaries; ROUGE considers lexical n-grams as the unit for comparing the overlap between summaries, while Basic Elements uses larger units of comparison based on the output of syntactic parsers.",0,original
"As a solution, a given amount of labeled training data is divided into two distinct sets, i.e., 4/5 for estimating , and the 667 remaining 1/5 for estimating   .",0,original
An alternative is to create an automatic system that uses a set of training question-answer pairs to learn the appropriate question-answer matching algorithm  .,0,original
"Yarowsky   proposed such a method for word sense disambiguation, which we refer to as monolingual bootstrapping.",0,original
"Further, we can learn the channel probabilities in an unsupervised manner using a variant of the EM algorithm similar to machine translation  , and statistical language understanding  .",0,original
"Unlike stochastic approaches to part-of-speech tagging  , up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired.",0,original
"The mutual information of a cooccurrence pair, which measures the degree of association between the two words  , is defined as  : P  I  -log 2 P  _ log 2   P P  P  = log 2 P  P  where P  and P  are the probabilities of the events x and y   and P  is the probability of the joint event  .",0,original
"MET   was carried out using a development set, and the BLEU score evaluated on two test sets.",0,original
4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis  .,0,original
Perhaps the most related is 86 learning as search optimization    .,0,original
ne approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus  ,0,original
ROUGE-L and ROUGE-1 are supposed to be appropriate for the headline gener853 ation task  .,0,original
"7 Independently, Cutting et aL   quote a performance of 800 words per second for their part-of-speech tagger based on hidden Markov models.",0,original
"First, we trained a finitestate shallow parser on base phrases extracted from the Penn Wall St. Journal   Treebank  .",0,original
The Inversion Transduction Grammar The Inversion Transduction Grammar of Wu   can be thought as a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar productions,0,original
"We just assign these rules a constant score trained using our implementation of Minimum Error Rate Training  , which is 0.7 in our system.",0,original
"This is in contrast to purely statistical systems  , which are difficult to inspect and modify.",0,original
"determining document orientation  , as in deciding if a given Subjective text expresses a Positive or a Negative opinion on its subject matter  ; 3.",0,original
"We use the log-likelihood ratio for determining significance as in  , but other measures are possible as well.",0,original
"The tensor has been adapted with a straightforward extension of pointwise mutual information   for three-way cooccurrences, following equation 4.",0,original
"3.2 Training Algorithm We adopt the perceptron training algorithm of Collins   to learn a discriminative model mapping from inputs xX to outputs yY , where X is the set of sentences in the training corpus and Y is the set of corresponding labelled results.",0,original
The pervading method for estimating these probabilities is a simple heuristic based on the relative frequency of the phrase pair in the multi-set of the phrase pairs extracted from the word-aligned corpus  .,0,original
"The main application of these techniques to written input has been in the robust, lexical tagging of corpora with part-of-speech labels  .",0,original
Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning:   propose one such framework for boosting logistic regression;   build a modi ed SVM and   use a combination of clustering and EM based methods to instantiate similar frameworks.,0,original
"It is worth noting, however, that even in Turney   the choice of seed words is explicitly motivated by domain properties of movie reviews.",0,original
"Figure 1  shows several orders of the sentence which violate this constraint.1 Previous studies have shown that if both the source and target dependency trees represent linguistic constituency, the alignment between subtrees in the two languages is very complex  .",0,original
"These results confirm the observed figures in the previous subsection and reinforce the sight that clustering is a worthless effort for automatic paraphrase corpora construction, contrarily to what   suggest.",0,original
"A quick search in the Penn Treebank   shows that about 17% of all sentences contain parentheticals or other sentence fragments, interjections, or unbracketable constituents.",0,original
"Labelling was carried out by three computational linguistics graduate students with 89% agreement resulting in a Kappa statistic of 0.87, which is a satisfactory indication that our corpus can be labelled with high reliability using our tag set  .",0,original
" , is not very useful for applications like statistical machine translation,  , for which an accurate word-to-word alignment between the source and the target languages is critical for high quality translations.",0,original
"The RST-DT consists of 385 documents from the Wall Street Journal, about 176,000 words, which overlaps with the Penn Wall St. Journal   Treebank  .",0,original
"The other recipe that is currently used on a large scale is to measure the performance of a parser on existing treebanks, such as WSJ  , and assume that the accuracy measure will carry over to the domains of interest.",0,original
"As the most concise definition we take the first sentence of each article, following  .",0,original
Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system   or a hierarchical phrase system  .,0,original
"Most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into a vector-space representation of the contexts that each target term appears in  .",0,original
"  are appealing, as they have rather simple structure, modeling only NP, VP and LCP via one-level sub-tree structure with two children, in the source parse-tree  ).",0,original
"Another consequence of not generating posthead conjunctions and punctuation as first-class words is that they 19 In fact, if punctuation occurs before the head, it is not generated at alla deficiency in the parsing model that appears to be a holdover from the deficient punctuation handling in the model of Collins  .",0,original
"For transfer-learning baseline, we implement traditional SCL model    .",0,original
"Therefore, the Viterbi alignment is comlmted only approximately using the method described in  .",0,original
The initial vectors to be clustered are adapted with pointwise mutual information  .,0,original
"Word-based features are used as well, e.g. feature a75 a11a39a99a78a99a18a11 captures word-to-word translation de4On our test set,   reports a BLEU score of a100a63a101a63a102a43a103 and   reports a BLEU score of a104a89a103a63a102 a105 . pendencies similar to the use of Model a98 probabilities in  .",0,original
"This decomposition applies both to discriminative linear models and to generative models such as HMMs and CRFs, in which case the linear sum corresponds to log likelihood assigned to the input/output pair by the model   for the classi cation case and   for the structured case).",0,original
ethod Correlation Edge-counting 0.664 Jiang & Conrath   0.848 Lin   0.822 Resnik   0.745 Li et al,0,original
"5.2 Evaluation Criteria For the automatic evaluation, we used the criteria from the IWSLT evaluation campaign  , namely word error rate  , positionindependent word error rate  , and the BLEU and NIST scores  .",0,original
"2 The Data Our experiments on joint syntactic and semantic parsing use data that is produced automatically by merging the Penn Treebank   with PropBank    , as shown in Figure 1.",0,original
"When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc. , the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by   of 49.7%.",0,original
"Most probabilistic parsing research  including, for example, work by by Collins  , and Charniak    is based on branching process models  .",0,original
"Furthermore, I based training on maximizing the conditional probability of a parse tree given a sentence, unlike most previous generative models  , which focus on maximizing the joint probability of the parse tree and the sentence.",0,original
The parameters for each phrase table were tuned separately using minimum error rate training  .,0,original
"Instead, and as suggested by Och  , we chose to maximize directly the quality of the translations produced by the system, as measured with a machine translation evaluation metric.",0,original
"This corpus of 29 million words was provided to us by Michael Collins, and was automatically parsed with the parser described in Collins  .",0,original
"For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging  .",0,original
"Bilingual configurations that condition on tprime,wprime   are incorporated into the generative process as in Smith and Eisner  .",0,original
2 Perceptron Algorithm for Sequence Labeling Collins   proposed an extension of the perceptron algorithm   to sequence labeling.,0,original
All corpora are formatted in the IOB sequence representation  .,0,original
The sentences were processed with the Collins parser   to generate automatic parse trees.,0,original
"Many researchers have focused the related problem of predicting sentiment and opinion in text  , sometimes connected to extrinsic values like prediction markets  .",0,original
Training Data Our source for syntactically annotated training data was the Penn Treebank  .,0,original
"Similarly, prototype-driven learning     optimizes the joint marginal likelihood of data labeled with prototype input features for each label.",0,original
"A tree sequence to string rule  174 A tree-sequence to string translation rule in a forest is a triple <L, R, A>, where L is the tree sequence in source language, R is the string containing words and variables in target language, and A is the alignment between the leaf nodes of L and R. This definition is similar to that of   except our treesequence is defined in forest.",0,original
2 Related Works Some of the most common measures of unithood include pointwise mutual information     and log-likelihood ratio  .,0,original
  0.19-0.48 Leacock & Chodrow   0.36 Lin   0.36 Resnik   0.37 Proposed 0.504 7 Conclusion We proposed a relational model to measure the semantic similarity between two words.,0,original
"is relevant to finite-state phrase-based models that use no parse trees  , tree-tostring models that rely on one parse tree  , and tree-to-tree models that rely on two parse trees  .",0,original
2We use a POS tagger   trained on switchboard data with the additional tags of FP   and FRAG  .,0,original
1 Motivation Most of the noisy-channel-based models used in statistical machine translation     are conditional probability models.,0,original
"We computed precision, recall and error rate on the entire set for each data set.6 For an initial alignment, we used GIZA++ in both directions   or Spanish  ), and also two different combined alignments: intersection of E-to-F and F-to-E; and RA using a heuristic combination approach called grow-diag-final  .",0,original
"In order to prove this induction step, we use the concept of order annotations  , which are strings that lexicalise the precedence relation between the nodes of a dependency tree.",0,original
"On the machine-learning side, it would be interesting to generalize the ideas of large-margin classi cation to sequence models, strengthening the results of Collins   and leading to new optimal training algorithms with stronger guarantees against over tting.",0,original
"Lexical collocation functions, especially those determined statistically, have recently attracted considerable attention in computational linguistics   mainly, though not exclusively, for use in disambiguation.",0,original
"Unlexicalized methods refine the grammar in a more conservative fashion, splitting each non-terminal or pre-terminal symbol into a much smaller number of subsymbols  .",0,original
The model parameters are trained using minimum error-rate training  .,0,original
6.2 Experimental Settings We utilize a maximum entropy   model   to design the basic classifier for WSD and TC tasks.,0,original
"In practice, when training the parameters of an SMT system, for example using the discriminative methods of  , the cost for skips of this kind is typically set to a very high value.",0,original
"For word alignment accuracy, F-measure is reported, i.e., the harmonic mean of precision and recall against a gold-standard reference set; for translation quality, Bleu   and its variation of NIST scores are reported.",0,original
  BLEU-4   is used as the evaluation metric.,0,original
Some researchers   classify terms by similarities based on their distributional syntactic patterns.,0,original
Translation quality is reported using case-insensitive BLEU  .,0,original
of Words Person names 803 1749 Organization names 312 867 Location names 345 614 The BLEU score   with a single reference translation was deployed for evaluation.,0,original
Initial estimates of lexical translation probabilities came from the IBM Model 4 translation tables produced by GIZA++  .,0,original
"Gildea and Jurafsky   used a supervised learning method to learn both the identifier of the semantic roles defined in FrameNet such as theme, target, goal, and the boundaries of the roles  .",0,original
"Consider the lexical model pw , defined following Koehn et al  , with a denoting the most frequent word alignment observed for the rule in the training set.",0,original
"1 Introduction and Motivation Detecting contradictory statements is an important and challenging NLP task with a wide range of potential applications including analysis of political discourse, of scientific literature, and more  .",0,original
Most clustering schemes   use the average entropy reduction to decide when two words fall into the same cluster.,0,original
Default parameters were used for all experiments except for the numberofiterationsforGIZA++ .,0,original
1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation    .,0,original
"2.3 Online Learning Again following  , we have used the single best MIRA  , which is a margin aware variant of perceptron   for structured prediction.",0,original
The third column reports the BLEU score   along with 95% confidence interval.,0,original
"Recent work on the automatic acquisition of multilingual LFG resources from treebanks for Chinese, German and Spanish   has shown that given a suitable treebank, it is possible to automatically acquire high quality LFG resources in a very short space of time.",0,original
"In NLP community, it has been shown that having more data results in better performance  .",0,original
"3.2 Translation Scores The translation scores for four different systems are reported in Table 1.5 Baseline: In this system, we use the GIZA++ toolkit  , a suffix-array architecture  , the SRILM toolkit  , and minimum error rate training   to obtain word-alignments, a translation model, language models, and the optimal weights for combining these models, respectively.",0,original
"Word alignments were produced by GIZA++   with a standard training regimen of five iterations of Model 1, five iterations of the HMM Model, and five iterations of Model 4, in both directions.",0,original
"In our future work we plan to investigate the effect of more sophisticated and, probably, more accurate filtering methods   on the QA results.",0,original
"For our POS tagging experiments, we use 561 MEDLINE sentences   from the Penn BioIE project  , a test set previously used by Blitzer et al. .",0,original
"The agreement on identifying the boundaries of units, using the kappa statistic discussed in Carletta  , was  = .9  ; the agreement on features   was as follows: utype:  = .76; verbed:  = .9; nite:  = .81.",0,original
"It is interesting to note that, while the study of how the granularity of context-free grammars   affects the performance of a parser  = = =f1  = =f2  = =f3  =f4 Figure 1: Cand f-structures with  links for the sentence GSC4ESESDOAIC1D3D2 of grammar transforms   and lexicalisation  ) has attracted substantial attention, to our knowledge, there has been a lot less research on this subject for surface realisation, a process that is generally regarded as the reverse process of parsing.",0,original
We used minimum error rate training   and the A* beam search decoder implemented by Koehn  .,0,original
Our learning method is an extension of Collinss perceptron-based method for sequence labeling  .,0,original
"Dunning   argues for the use of G 2 rather than X 2, based on the claim that the sampling distribution of G 2 approaches the true chi-square distribution quicker than the sampling distribution of X 2 . However, Agresti   makes the opposite claim: The sampling distributions of X 2 and G 2 get closer to chi-squared as the sample size n increasesThe convergence is quicker for X 2 than G 2 . In addition, Pedersen   questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read  , who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic.",0,original
3.1 Data and Experimental Setup The data set by Pang and Lee   consists of 2000 movie reviews   from the IMDb review archive.,0,original
"For comparison purposes, we also computed the value of R 2 for fluency using the BLEU score formula given in  , for the 7 systems using the same one reference, and we obtained a similar value, 78.52%; computing the value of R 2 for fluency using the BLEU scores computed with all 4 references available yielded a lower value for R 2, 64.96%, although BLEU scores obtained with multiple references are usually considered more reliable.",0,original
"We compare against several competing systems, the first of which is based on the original IBM Model 4 for machine translation   and the HMM machine translation alignment model   as implemented in the GIZA++ package  .",0,original
"Though inter-rater reliability using the kappa statistic   may be calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion.",0,original
"They were based on mutual information  , conditional probabilities  , or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio  .",0,original
"  and   do worse on the English test data than they do on German, Dutch, or French.",0,original
"It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes  .",0,original
Church and Hanks   thus emphasize the importance of human judgment used in conjunction with these tools,0,original
The idea of bidirectional parsing is related to the bidirectional sequential classification method described in  .,0,original
"7 This discussion could also be cast in an information theoretic framework using the notion of """"mutual information""""  , estimating the variance of the degree of match in order to find a frequency-threshold  .",0,original
"3 Tagging 3.1 Corpus To facilitate comparison with previous results, we used the UPenn Treebank corpus  .",0,original
"Themodeling approachhere describedis discriminative, and is based on maximum entropy   models, firstly applied to natural language problems in  .",0,original
Then we use both Moses decoder and its suppo We run the decoder with its d then use Moses' implementation of minimum error rate training   to tune the feature weights on the development set.,0,original
"For each word pair from the antonym set, we calculated the distributional distance between each of their senses using Mohammad and Hirsts   method of concept distance along with the modified form of Lins   distributional measure  .",0,original
"This conclusion is supported by the fact that true IMT is not, to our knowledge, used in most modern translator's support environments, eg  .",0,original
"Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi   in two important ways.",0,original
"The measures vary from simple edge-counting to attempt to factor in peculiarities of the network structure by considering link direction, relative path, and density, such as vector, lesk, hso, lch, wup, path, res, lin and jcn  .",0,original
ang and Lee   report 87.15% accuracy using a unigram-based SVM classifier combined with subjectivity detection,0,original
5 Previous Work The LEAF model is inspired by the literature on generative modeling for statistical word alignment and particularly by Model 4  .,0,original
"Although bi-alignments are known to exhibit high precision  , in the face of sparse annotations we use unidirectional alignments as a fallback, as has been proposed in the context of phrase-based machine translation  .",0,original
As machine learners we used SVM-light1   and the MaxEnt decider from the Stanford Classifier2  .,0,original
"Improvements are obtained  , showing that a reranker is necessary for successful self-training in such a high-resource scenario.",0,original
"This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation  , lexicon construction for information extraction  , and named entity classification  .",0,original
Some work has been done on adding new terms and relations to WordNet   and FACTOTUM  .,0,original
"For more information on these models, please refer to Brown et al.  .",0,original
"Language modeling  , noun-clustering  , constructing syntactic rules for SMT  , and finding analogies   are examples of some of the problems where we need to compute relative frequencies.",0,original
Semantic DSN: The construction of this network is inspired by  .,0,original
MT output is evaluated using the standard MT evaluation metric BLEU  .,0,original
"To compare the performance of different taggers learned by different mechanisms, one can measure the precision, recall and F-measure, given by precision = # correct predictions# predicted gene mentions recall = # correct predictions# true gene mentions F-measure = a96a15a14 precision a14 recallprecision a44 recall In our evaluation, we compared the proposed semi-supervised learning approach to the state of the art supervised CRF of McDonald and Pereira  , and also to self-training  , using the same feature set as  .",0,original
nline discriminative training has already been studied by Tillmann and Zhang   and Liang et al,0,original
Responsiveness differs from other measures of summary content such as SEE coverage   and Pyramid scores   in that it does not compare a peer summary against a set of known human summaries.,0,original
"Congress of the Italian Association for Artificial Intelligence, Palermo, 1991 B. Boguraev, Building a Lexicon: the Contribution of Computers, IBM Report, T.J. Watson Research Center, 1991 M. Brent, Automatic Aquisition of Subcategorization frames from Untagged Texts, in   N. Calzolari, R. Bindi, Acquisition of Lexical Information from Corpus, in   K. W. Church, P. Hanks, Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, vol.",0,original
The kappa statistic   has become the de facto standard to assess inter-annotator agreement.,0,original
2.1 Alignment Sentences from different systems are aligned in pairs using a modified version of the METEOR   matcher.,0,original
3.1 Paraphrase Identification A few unsupervised metrics have been applied to automatic paraphrase identification and extraction  .,0,original
"Labeled data for one domain might be used to train a initial classifier for another   domain, and then bootstrapping can be employed to learn new knowledge from the new domain  .",0,original
A re nement of this model is the class-based n-gram where the words are partitioned into equivalence classes  .,0,original
"Ours is 772 similar to   in the use of dependency relationship as the word features, based on which word similarities are computed.",0,original
"Many existing systems for statistical machine translation   implement models presented by Brown, Della Pietra, Della Pietra, and Mercer  : The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position.",0,original
In this paper we use a non-projective dependency tree CRF  .,0,original
"2 Related Work Recently, several studies have reported about dialog systems that are capable of classifying emotions in a human-computer dialog  .",0,original
"Carpuat and Wu   integrated a WSD system into a phrase-based SMT system, Pharaoh  .",0,original
4 Experiments Our experiments involve data from two treebanks: the Wall Street Journal Penn treebank   and the Chinese treebank  .,0,original
"As is common  , the treebank is first transformed in various ways, in order to give an accurate PCFG.",0,original
The up-arrows and down-arrows are shorthand for  ) =   where ni is the c-structure node annotated with the equation.2 Treebest := argmaxTreeP    P  := productdisplay X  Y in Tree Feats = {ai|vj )ai = vj} P    The generation model of   maximises the probability of a tree given an f-structure (Eqn.,0,original
"Different optimization techniques are available, like the Simplex algorithm or the special Minimum Error Training as described in  .",0,original
"2 Baseline Coreference Resolution System Our baseline coreference system implements the standard machine learning approach to coreference resolution  , Ponzetto and Strube  , Yang and Su  , for instance), which consists of probabilistic classification and clustering, as described below.",0,original
"tile data put tbrward by ll,amshaw and Marcus  .",0,original
" , in which we translate a source-language sentence f into the target-language sentence e that maximizes a linear combination of features and weights:1 e,a = argmax e,a score    = argmax e,a Msummationdisplay m=1 mhm    where a represents the segmentation of e and f into phrases and a correspondence between phrases, and each hm is a R-valued feature with learned weight m. The translation is typically found using beam search  .",0,original
his results also agree with Dunning's argument about overestimation on the infrequent occurrences in which many infrequent pairs tend to get higher estimation  ,0,original
"Part-of-speech features Based on the lexical categories produced by GATE  , each token xi is classified into one of a set of coarse part-of-speech tags: noun, verb, adverb, wh-word, determiner, punctuation, etc. We do the same for neighboring words in a   window in order to assist noun phrase segmentation.",0,original
he description of the minimum cut framework in Section 4.1 was inspired by Pang and Lee  ,0,original
The automatic alignments were extracted by appending the manually aligned sentences on to the respective Europarl v3 corpora and aligning them using GIZA++   and the growfinal-diag algorithm  .,0,original
Recently several latent variable models for constituent parsing have been proposed  .,0,original
"In order to calculate a global score or probability for a transition sequence, two systems used a Markov chain approach  .",0,original
"It is true that various term extraction systems have been developed, such as Xtract  , Termight  , and TERMS   among others (cf.",0,original
"or cooking, which agrees with the knowledge presented in previous work  .",0,original
"A variety of unsupervised WSD methods, which use a machinereadable dictionary or thesaurus in addition to a corpus, have also been proposed  .",0,original
The Brill tagger comes with an English default version also trained on general-purpose language corpora like the PENN TREEBANK  .,0,original
234 ADV Non-specific adverbial BNF Benefemtive CLF It-cleft CLR 'Closely related' DIR Direction DTV Dative EXT Extent HLN Headline LGS Logical subject L0C Location MNI~ Manner N0M Nominal PRD Predicate PRP Purpose PUT Locative complement of 'put' SBJ Subject TMP Temporal TPC Topic TTL Title V0C Vocative Grammatical DTV 0.48% LGS 3.0% PRD 18.% PUT 0.26% SBJ 78.% v0c 0.025% Figure 1: Penn treebank function tags 53.% Form/Function 37.% Topicalisation 2.2% 0.25% NOM 6.8% 2.5% TPC 100% 2.2% 1.5% ADV 11.% 4.2% 9.3% BN'F 0.072% 0.026% 0.13% DIR 8.3% 3.0% 41.% EXT 3.2% 1.2% 0.013% LOC 25.% 9.2% MNR 6.2% 2.3% PI~ 5.2% 1.9% 33.% 12.% Miscellaneous 9.5% CLR 94.% 8.8% CLF 0.34% 0.03% HLN 2.6% 0.25% TTL 3.1% 0.29% Figure 2: Categories of function tags and their relative frequencies one project that used them at all:   defines certain constituents as complements based on a combination of label and function tag information.,0,original
utomatic segmentation of spontaneous speech is an open research problem in its own right  ,0,original
"The resulting intercoder reliability, measured with the Kappa statistic , is considered excellent  .",0,original
"To train models, we used projectivized versions of the training dependency trees.2 1We are grateful to the providers of the treebanks that constituted the data for the shared task  .",0,original
"In this paper, we investigate the effectiveness of structural correspondence learning     in the domain adaptation task given by the CoNLL 2007.",0,original
"Recently, various approaches   to word sense division have been used in WSD research.",0,original
Past work   has examined the use of monolingual parallel corpora for paraphrase extraction.,0,original
"4.3 Using Unlabeled Data for Parsing Recent studies on parsing indicate that the use of unlabeled data by self-training can help parsing on the WSJ data, even when labeled data is relatively large  .",0,original
Weights on the components were assigned using the   method for max-BLEU training on the development set.,0,original
"One such relational reasoning task is the problem of compound noun interpretation, which has received a great deal of attention in recent years  .",0,original
One of the simplest models in the context of lexical triggers is the IBM model 1   which captures lexical dependencies between source and target words.,0,original
Semantic classification programs   use statistical information based on cooccurrence with appropriate marker words to partition a set of words into semantic groups or classes.,0,original
"To compute the degree of interaction between two proteins D4 BD and D4 BE, we use the information-theoretic measure of pointwise mutual information  , which is computed based on the following quantities: 1.",0,original
"4.2 Features For our experiments, we use a feature set analogous to the default feature set of Pharaoh  .",0,original
This technique is called system combination  .,0,original
"For instance, the most relaxed IBM Model-1, which assumes that any source word can be generated by any target word equally regardless of distance, can be improved by demanding a Markov process of alignments as in HMM-based models  , or implementing a distribution of number of target words linked to a source word as in IBM fertility-based models  .",0,original
"In order to capture the dependency relationship between lexcial heads Collins   breaks down the rules from head outwards, which prevents us from factorizing them in other ways.",0,original
"This is the same complexity as the ITG alignment algorithm used by Wu   and others, meaning complete Viterbi decoding is possible without pruning for realistic-length sentences.",0,original
otice that most in-context and dictionary translations of source words are bounded within the same category in a typical thesaurus such as the LLOCE   and CILIN  ,0,original
Classi er Training Set Precision Recall F-Measure Linear 10K pairs 0.837 0.774 0.804 Maximum Entropy 10K pairs 0.881 0.851 0.866 Maximum Entropy 450K pairs 0.902 0.944 0.922 Table 4: Performance of Alignment Classi er 3.2 Paraphrase Acquisition Much recent work on automatic paraphrasing   has used relatively simple statistical techniques to identify text passages that contain the same information from parallel corpora.,0,original
"Feature weight tuning was carried out using minimum error rate training, maximizing BLEU scores on a held-out development set  .",0,original
"The coreference resolution system employs a variety of lexical, semantic, distance and syntactic features .",0,original
Aggregate models based on higher-order n-grams   might be able to capture multi-word structures such as noun phrases.,0,original
These IBM models and more recent refinements   as well as algorithms that bootstrap from these models like the HMM algorithm described in   are unsupervised algorithms.,0,original
An important aspect of web search is to be able to narrow down search results by distinguishing among people with the same name leading to multiple efforts focusing on web person name disambiguation in the literature  .,0,original
"Models that support non-monotonic decoding generally include a distortion cost, such as|aibi11|where ai is the starting position of the foreign phrasefi andbi1 is the ending position of phrase fi1  .",0,original
"Monotone Nonmonotone Target B A Positions C D Source Positions Figure 1: Two Types of Alignment The IBM model 1     assumes that all alignments have the same probability by using a uniform distribution: p  = 1IJ  Jproductdisplay j=1 Isummationdisplay i=1 p    We use the IBM-1 to train the lexicon parameters p , the training software is GIZA++  .",0,original
"Actually, it is defined similarly to the translation model in SMT  .",0,original
In order to avoid this problem we implemented a simple bootstrapping procedure in which a seed data set of 100 instances of each of the eight categories was hand tagged and used to generate a decision list classifier using the C4.5 algorithm   with the word frequency and topic signature features described below.,0,original
"Alternative Class-Based Estimation Methods The approaches used for comparison are that of Resnik  , subsequently developed by Ribas  , and that of Li and Abe  , which has been adopted by McCarthy  .",0,original
Feature function weights in the loglinear model are set using Ochs minium error rate algorithm  .,0,original
There have been many studies on POS guessing of unknown words  .,0,original
138 2 Rule Generation We start with phrase translations on the parallel training data using the techniques and implementation described in  .,0,original
"8 Conclusions In this paper, we developed probability models for the multi-level transfer rules presented in  , showed how to acquire larger rules that crucially condition on more syntactic context, and how to pack multiple derivations, including interpretations of unaligned words, into derivation forests.",0,original
"The search is based on the property that when computing sim , words that have high mutual information values 5The nominator in our metric resembles the similarity metric in  .",0,original
"4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool   and the grow-diag-final-and heuristics described in   on 948,507 sentences of the French-English part of the Europarl corpus   and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation.",0,original
These texts were not seen at the training phase which means that neither the 6Since Brill's tagger was trained on the Penn tag-set   we provided an additional mapping.,0,original
Estimation of the parameters has been described elsewhere  .,0,original
We also report on applying Factored Translation Models   for English-to-Arabic translation.,0,original
  have introduced a convenient data representation for chunking by converting it to a tagging task.,0,original
The labeled corpus is the Penn Wall Street Journal treebank  .,0,original
"Recent work by Koehn and Hoang   pro514 poses factored translation models that combine feature functions to handle syntactic, morphological, and other linguistic information in a log-linear model.",0,original
"2.1 Synchronous derivations The derivations for syntactic dependency trees are the same as specified in  , which are based on the shift-reduce style parser of  .",0,original
"Motivated by our goal of representing syntax, we used part-of-speech   tags as labeled by a maximum entropy tagger  .",0,original
"In this paper, two synchronous grammar formalisms are discussed, inversion transduction grammars     and two-variable binary bottom-up non-erasing range concatenation grammars  -BRCGs)  .",0,original
"The second model is a maximum entropy model  , since Klein and Manning   found that this model yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance.",0,original
"4 Related Work 4.1 Acquisition of Classes of Instances Although some researchers focus on re-organizing or extending classes of instances already available explicitly within manually-built resources such as Wikipedia   or WordNet   or both  , a large body of previous work focuses on compiling sets of instances, not necessarily labeled, from unstructured text.",0,original
"The number of weights wi is 3 plus the number of source languages, and they are trained using minimum error-rate training   to maximize the BLEU score   on a development set.",0,original
"The senses are: 1 material from cellulose 2 report 3 publication 4 medium for writing 5 scientific 6 publishing firm 7 physical object inventory is suitable for which application, other than cross-lingual applications where the inventory can be determined from parallel data  .",0,original
"This probability is computed using IBMs Model 1  : P  = productdisplay qQ P    P  =  Pml +Pml    Pml  = summationdisplay aA  Pml )   where the probability that the question term q is generated from answer A, P , is smoothed using the prior probability that the term q is generated from the entire collection of answers C, Pml .",0,original
"For the statistics-based approaches, Bean and Riloff   developed a statistics-based method for automatically identifying existential definite NPs which are non-anaphoric.",0,original
"Thus, we obtain the following second-order model: a36a39a38a41a40 a17 a5a7 a42a4 a5a7 a44 a8 a5a57 a15a27a58 a7 a36a39a38a41a40 a17a20a15a59a42a17 a15a41a49 a7 a7 a60 a4 a5a7 a44 a8 ma61a63a62a65a64a33a66 a5a57 a15a27a58 a7a68a67 a40 a17 a15 a42a17 a15a50a49 a7 a15a50a49a51a48 a60 a4 a15a27a47a55a48 a15a50a49a54a48 a44 a11 A well-founded framework for directly modeling the posterior probability a67 a40 a17 a15 a42a17 a15a50a49 a7 a15a50a49a54a48 a60 a4 a15a12a47a55a48 a15a50a49a54a48 a44 is maximum entropy  .",0,original
Bilingual lexicographers can work with bilingual concordancing software that can point them to instances of any link type induced from a bitext and display these instances sorted by their contexts  .,0,original
"Without removing them, extracted rules cannot be triggered until when completely the same strings appear in a text.4 6 Performance Evaluation We measured the performance of our robust parsing algorithm by measuring coverage and degree of overgeneration for the Wall Street Journal in the Penn Treebank  .",0,original
Figure 1 exhibits this scenario with a typical IE system such as SRI's FASTUS system  .,0,original
"There has been a growing interest in corpus-based approaches which retrieve collocations from large corpora  ,    ,  ,  ,  ,  ,  .",0,original
"We set all weights by optimizing Bleu   using minimum error rate training     on a separate development set of 2,000 sentences  , and we used them in a beam search decoder   to translate 2,000 test sentences   into English.",0,original
irect feedback loops that copy a predicted output label to the input representation of the next example have been used in symbolic machine-learning architectures such as the the maximum-entropy tagger described by Ratnaparkhi   and the memory-based tagger   proposed by Daelemans et al,0,original
"Such metrics have been introduced in other fields, including PARADISE   for spoken dialogue systems, BLEU   for machine translation,1 and ROUGE   for summarisation.",0,original
"Data and Parameters To facilitate comparison with previous work, we trained our models on sections 2-21 of the WSJ section of the Penn tree-bank  .",0,original
"In the recent years, there have been a number of papers considering this or similar problems:  ,  ,  ,  .",0,original
veraged Perceptron Algorithm 5 Experiments We evaluate our method on both Chinese and English syntactic parsing task with the standard division on Chinese Penn Treebank Version 5.0 and WSJ English Treebank 3.0   as shown in Table 1,0,original
"Finally, we are investigating several avenues for using this system output for Machine Translation   including:   aiding word alignment for other MT system  ; and   aiding the creation various MT models involving analyzed text, e.g.,  .",0,original
"The training methods of LRM-F and SVM-F were useful to improve the F M -scores of LRM and SVM, as reported in  .",0,original
"With this constraint, each of these binary trees is unique and equivalent to a parse tree of the canonical-form grammar in  .",0,original
"In none of these cases did we repeat minimum-error-rate training; all these systems were trained using max-B. The metrics we tested were:  METEOR  , version 0.6,usingtheexact,Porter-stemmer,andWordNet synonmy stages, and the optimized parameters  = 0.81,  = 0.83,  = 0.28 as reported in  .",0,original
"Various methods are based on Mutual Information between classes, see  .",0,original
This is referred to as an IOB representation  .,0,original
"In the future, we will experiment with semantic   clustering of premoditiers, using techniques such as those proposed in \ .",0,original
"To measure the coherence of sentences, we use a statistical parser Toolkit   to assign each sentence a parsers score that is the related log probability of parsing.",0,original
"One of the most relevant work is  , which proposed to integrate various patterns in order to measure semantic similarity between words.",0,original
Generation of paraphrase examples was also investigated  .,0,original
1 Introduction Translational equivalence is a mathematical relation that holds between linguistic expressions with the same meaning  .,0,original
This is concordant with the usage in the maximum entropy literature  .,0,original
This second point is emphasized by the second paper on self-training for adaptation  .,0,original
"9  report that, for translation reranking, such local updates   outperform bold updates  .",0,original
"2 Background 2.1 Phrase Table Extraction Phrasal decoders require a phrase table  , which contains bilingual phrase pairs and 17 scores indicating their utility.",0,original
1 Introduction Machine translation systems based on probabilistic translation models   are generally trained using sentence-aligned parallel corpora.,0,original
"It forms a baseline for performance evaluations, but is prone to sparse data problems  .",0,original
"The method uses a translation model based on IBM Model 1  , in which translation candidates of a phrase are generated by combining translations and transliterations of the phrase components, and matching the result against a large corpus.",0,original
"Determining the sense of an ambiguous word, using bootstrapping and texts from a different language was done by Yarowsky  , Hearst  , Diab  , and Li and Li  .",0,original
"First, as originally advocated by Hobbs  , we adopt an ONTOLOGICALLY PROMISCUOUS representation that includes a wide variety of types of entities.",0,original
There has thus been a trend recently towards robust wide-coverage semantic construction  ).,0,original
Two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to  .,0,original
This was a difcult challenge as many participants in the task failed to obtain any meaningful gains from unlabeled data  .,0,original
"At this point, one can imagine estimating a linear matching model in multiple ways, including using conditional likelihood estimation, an averaged perceptron update  ), or in large-margin fashion.",0,original
"Phrases of up to 10 in length on the French side were extracted from the parallel text, and minimum-error-rate training   was 8 We can train on the full training data shown if tighter constraints are placed on rule extraction for the United Nations data.",0,original
"Our observation is that this situation is ideal for so-called bootstrapping, co-training, or minimally supervised learning methods  .",0,original
"Many NLP systems use the output of supervised parsers   for QA,   for IE,   for SRL,   for Textual Inference and   for MT).",0,original
"As multiple derivations are used for finding optimal translations, we extend the minimum error rate training   algorithm   to tune feature weights with respect to BLEU score for max-translation decoding  .",0,original
"The second voting model, a maximum entropy model  , was built as Klein and Manning   found that it yielded higher accuracy than nave Bayes in a subsequent comparison of WSD performance.",0,original
The chunking classification was made by   based on the parsing information in the WSJ corpus.,0,original
2005 Association for Computational Linguistics Automatic identification of sentiment vocabulary: exploiting low association with known sentiment terms Michael Gamon Anthony Aue Natural Language Processing Group Natural Language Processing Group Microsoft Research Microsoft Research mgamon@microsoft.com anthaue@microsoft.com Abstract We describe an extension to the technique for the automatic identification and labeling of sentiment terms described in Turney   and Turney and Littman  ,0,original
"Such techniques include Gibbs sampling  , a general-purpose Monte Carlo method, and integer linear programming  ,  , a general-purpose exact framework for NP-complete problems.",0,original
"Och   observed, however, that the piecewiseconstant property could be exploited to characterize the function exhaustively along any line in parameter space, and hence to minimize it globally along that line.",0,original
2This can explain why previous attempts to use WordNet for generating sentence-level paraphrases   were unsuccessful.,0,original
The output by each approach will be evaluated using benchmark data sets of Bakeoff-32  .,0,original
"Since manual word alignment is an ambiguous task, we also explicitly allow for ambiguous alignments, i.e. the links are marked as sure   or possible    .",0,original
"In general, Agold / Acandidates; following   and   for parse reranking and   for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight i as follows: i = i + hAoraclei hA1-besti .9 Following  , after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights.",0,original
We used the MXPOST tagger   for POS annotation.,0,original
The f are optimized by Minimum-Error Training    .,0,original
Tuning was done using Maximum BLEU hill-climbing  .,0,original
"Clark   reports results on a corpus containing 12 million terms, Schcurrency1utze   on one containing 25 million terms, and Brown, et al,   on one containing 365 million terms.",0,original
"A very common case of this in the CoNLL dataset is that of documents containing references to both The China Daily, a newspaper, and China, the country  .",0,original
"so they conform to the Penn Treebank corpus   annotation style, and then do experiments using models built with Treebank data.",0,original
"4 Comparison to Related Work Previous work has compared generative and discriminative models having the same structure, such as the Naive Bayes and Logistic regression models   and other models  .",0,original
"For example, if the lexicon contains an adjective excellent, it matches every adjective phrase that includes excellent such as view-excellent etc. As a baseline, we built lexicon similarly by using polarity value of  .",0,original
In   cooccurrence analyses augmented with syntactic parsing is used for the purpose of word classification.,0,original
"The parsing algorithm was CKY-style parsing with beam thresholding, which was similar to ones used in  .",0,original
We perform term disambiguation on each document using an entity extractor  .,0,original
"In class-based n-gram modeling   for example, classbased n-grams are used to determine the probability of occurrence of a POS class, given its preceding classes, and the probability of a particular word, given its own POS class.",0,original
Other statistical systems that address word classification probleans do not emphasize the use of linguistic knowledge and do not deal with a specific word class\ .,0,original
We benchmark our results against a model   which was directly trained to optimise BLEUNIST using the standard MERT algorithm   and the full set of translation and lexical weight features described for the Hiero model  .,0,original
Our approach is closely related to previous CoTraining methods  .,0,original
"Based on the data seen, a maximum entropy model   offers an expression   for the probability that there exists coreference C between a mention mi and a mention mj.",0,original
"Recently, some generic methods were proposed to handle context-sensitive inference  , but these usually treat only a single aspect of context matching  .",0,original
"Previous approaches to the problem   have all been learning-based; the primary difference between the present algorithm and earlier ones is that it is not learned, but explicitly incorporates principles of GovernmentBinding theory  , since that theory underlies the annotation.",0,original
"Penn Treebank corpus   sections 0-20 were used for training, sections 2124 for testing.",0,original
"However, most of them do not build a NEs resource but exploit external gazetteers  ,  .",0,original
"We build a subset S C ~"""" incrementally by iterating to adjoin a feature f E ~"""" which maximizes loglikelihood of the model to S. This algorithm is called the Basic Feature Selection  .",0,original
"One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity  .",0,original
ing and McKeown   and Jing   propose a cut-and-paste strategy as a computational process of automatic abstracting and a sentence reduction strategy to produce concise sentences,0,original
"It is a reimplementation of the averaged perceptron described in  , which uses such features that it behaves like an HMM tagger and thus the standard Viterbi decoding is possible.",0,original
"A similar approach was taken in   where an unknown word was guessed given the probabilities for an unknown word to be of a particular POS, its capitalisation feature and its ending.",0,original
The MBT   180 Tagger Type Standard Trigram   MBT   Rule-based   Maximum-Entropy   Full Second-Order HMM SNOW   Voting Constraints   Full Second-Order HMM Known Unknown Overall Open/Closed Lexicon?,0,original
"We use the same feature processing as Haghighi and Klein  , with the addition of context features in a window of3.",0,original
"Similarly to MERT, Tillmann and Zhang estimate the parameters of a weight vector on a linear combination of   features using a global objective function correlated with BLEU  .",0,original
  first introduced an iterative method for increasing a small set of seed data used to disambiguate dual word senses by exploiting the constraint that in a segment of discourse only one sense of a word is used.,0,original
"We chose this inverse direction since it can be integrated directly into the decoder and, thus, does not rely on a two-pass approach using reranking, as it is the case for  .",0,original
"aoife.cahill@ims.uni-stuttgart.de and van Genabith  , which do not rely on handcrafted grammars and thus can easily be ported to new languages.",0,original
"Parsing research has also begun to adopt discriminative methods from the Machine Learning literature, such as the perceptron   and the largemargin methods underlying Support Vector Machines  .",0,original
"Neural networks have been used in NLP in the past, e.g. for machine translation   and constituent parsing  .",0,original
2.3 Feature Functions Our phrase-based model uses a standard pharaoh feature functions listed as follows  :  Relative-count based phrase translation probabilities in both directions.,0,original
"Similarly, the sense disambiguation problem is typically attacked by comparing the distribution of the neighbors of a word's occurrence to prototypical distributions associated with each of the word's senses \ .",0,original
  use HMM-based similarity for the same purpose.,0,original
"As with the graph-based parser, we use the discriminative perceptron   to train the transition-based model  .",0,original
Their systems output was an ordered list of possible parts according to some statistical metrics  ).,0,original
.3 Systematic Sense Shift Ostler and Atkins   contend that there is strong evidence to suggest that a large part of word sense ambiguity is not arbitrary but follows regular patterns,0,original
"We believe the benefit to limiting the size of n is connected to Brown et al.s   observation that as n increases, the accuracy of an n-gram model increases, but the reliability of our parameter estimates, drawn as they must be from a limited training text, decreases.",0,original
" , extracts uninterrupted as well as interrupted collocations  .",0,original
"Researchers have focused on learning adjectives or adjectival phrases   and verbs  , but no previous work has focused on learning nouns.",0,original
"However, as Categorial Grammar formalisms do not usually change the lexical entries of words to deal with movement, but use further rules  , the lexicons learned here will be valid over corpora with movement.",0,original
"The features used in NLG2 are described in the next section, and the feature weights aj, obtained from the Improved Iterative Scaling algorithm  , are set to maximize the likelihood of the training data.",0,original
"3 Domain Adaptation Following  , we present an application of structural correspondence learning   to non-projective dependency parsing  .",0,original
"Based on the observations in  , we also limited the phrase length to 3 for computational reasons.",0,original
"Furthermore, Bikel   provides evidence that lexical information   only makes a small contribution to the performance of parsing models such as Collinss  .",0,original
"1 Introduction Co-training  , and several variants of co-training, have been applied to a number of NLP problems, including word sense disambiguation  , named entity recognition  , noun phrase bracketing   and statistical parsing  .",0,original
"However, since we are interested in the word counts that correlate to w, we adopt the concept of the translation model proposed by Brown et al  .",0,original
"Following  , we describe the original parsing architecture and our modifications to it as a Dynamic Bayesian network.",0,original
2.2 STT: A Statistical Tree-based Tagger The aim of statistical or probabilistic tagging   is to assign the most likely sequence of tags given the observed sequence of words.,0,original
3.3 Tree Transducer Grammars Syntactic machine translation   uses tree transducer grammars to translate sentences.,0,original
"In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well  .",0,original
This sort of problem can be solved in principle by conditional variants of the Expectation-Maximization algorithm  .,0,original
"For each differently tokenized corpus, we computed word alignments by a HMM translation model   and by a word alignment refinement heuristic of grow-diagfinal  .",0,original
"In this vein, the CoNLL 2008 shared task sets the challenge of learning jointly both syntactic dependencies   ) and semantic dependencies   c2008.",0,original
"Examples are the Penn Treebank   for American English annotated at the University of Pennsylvania, the French treebank   developed in Paris, the TIGER Corpus   for German annotated at the Universities of Saarbrcurrency1ucken and This research was funded by a German Science Foundation grant  .",0,original
5 Related work Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters   . Schmid used tile equivaleuce classes for smoothing.,0,original
"One of the main directions is sentiment classification, which classifies the whole opinion document   as positive or negative  .",0,original
eNero and Klein   use a syntaxbased distance in an HMM word alignment model to favor syntax-friendly alignments,0,original
"In WASP, GIZA++   is used to obtain the best alignments from the training examples.",0,original
"On the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in  , alignment templates are used in  , and the alignment template approach is re-framed into the so-called phrase based translation   in  .",0,original
"Haghighi and Klein s   prototype-driven approach requires just a few prototype examples for each POS tag, exploiting these labeled words to constrain the labels of their distributionally similar words when training a generative log-linear model for POS tagging.",0,original
"Our next steps will be to take a closer look at the following work: clustering of similar words  , topic signatures   and Kilgariffs sketch engine  .",0,original
"For example,   suggested two different methods: using only the alignment with the maximum probability, the so-called Viterbi alignment, or generating a set of alignments by starting from the Viterbi alignment and making changes, which keep the alignment probability high.",0,original
"1 Introduction Parsing sentences using statistical information gathered from a treebank was first examined a decade ago in   and is by now a fairly well-studied problem  ,  ,  ).",0,original
.1 Global linear models We follow the framework outlined in Collins  ,0,original
For the former we made use Decision Lists similar to Yarowskys method for Word Sense Disambiguation    .,0,original
"There are cases, though, where the labels consist of several related, but not entirely correlated, properties; examples include mention detectionthe task we are interested in, syntactic parsing with functional tag assignment  ), and, to a lesser extent, part-of-speech tagging in highly inflected languages.4 The particular type of mention detection that we are examining in this paper follows the ACE general definition: each mention in the text   is assigned three types of information:5  An entity type, describing the type of the entity it points to    An entity subtype, further detailing the type    A mention type, specifying the way the entity is realized  a mention can be named  , nominal  , or pronominal  .",0,original
"Many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms  , weakly supervised learning algorithms  , unsupervised learning algorithms    , and knowledge based algorithms  .",0,original
"Co-occurrence statistics is collected from either bilingual parallel and 334 non-parallel corpora  , or monolingual corpora  .",0,original
"Similar to work in image retrieval  , we cast the problem in terms of Machine Translation: given a paired corpus of words and a set of video event representations to which they refer, we make the IBM Model 1 assumption and use the expectation-maximization method to estimate the parameters  :  =+ = m j ajm jvideowordpl Cvideowordp 1 )| 1 |  This paired corpus is created from a corpus of raw video by first abstracting each video into the feature streams described above.",0,original
Both training and testing sentences were processed using Collins parser   to generate parse-tree automatically.,0,original
e adopt the similarity score proposed by Lin   as the distributional similarity score and use 50 nearest neighbours in line with McCarthy et al. For the random baseline we select one word sense at random for each word token and average the precision over 100 trials,0,original
"In our SMT system implementation, this optimization procedure is performed by using a tool developed in-house, which is based on a simplex method  , and the BLEU score   is used as a translation quality measurement.",0,original
To avoid this problem we use the concept of class proposed for a word n-gram model  .,0,original
"While Liu and Gildea   calculate n-gram matches on non-labelled head-modifier sequences derived by head-extraction rules from syntactic trees, we automatically evaluate the quality of translation by calculating an f-score on labelled dependency structures produced by a LexicalFunctional Grammar   parser.",0,original
"Our work expands on the general approach taken by   but arrives at insights similar to those of the most recent work  , albeit in a completely different manner.",0,original
"Recently, some work has been done on corpusbased paraphrase extraction  .",0,original
Previous work in statistical synchronous grammars has been limited to forms of synchronous context-free grammar  .,0,original
"As noted in Dolan  , it is possible to run a sense-clustering algorithm on several MRDs to build an integrated lexical database with more complete coverage of word senses.",0,original
"  used the Base-NP tag set as presented in  : I for inside a Base-NP, O for outside a Base-NP, and B for the first word in a Base-NP following another Base-NP.",0,original
"To perform minimum error rate training   to tune the feature weights to maximize the systems BLEU score on development set, we used optimizeV5IBMBLEU.m  .",0,original
Letter successor variety   models   use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries.,0,original
aume III & Marcu   argue that generic sentence fusion is an ill-defined task,0,original
"One of our goals was to use for this study only information that could be annotated reliably  , as we believe this will make our results easier to replicate.",0,original
"Starting from the parallel training corpus, provided with direct and inverted alignments, the socalled union alignment   is computed.",0,original
"Similarly, Kazama and Torisawa   used Wikipedia, particularly the first sentence of each article, to create lists of entities.",0,original
1 Introduction Bilingual word alignment is first introduced as an intermediate result in statistical machine translation    .,0,original
The corpus was aligned with GIZA++   and symmetrized with the grow-diag-finaland heuristic  .,0,original
"  and Ponzetto and Strube  ), we generate training instances as follows: a positive instance is created for each anaphoric NP, NPj, and its closest antecedent, NPi; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+1, NPi+2, . . ., NPj1.",0,original
"Rapp  , Dunning  ) but using cosine rather than cityblock distance to measure profile similarity.",0,original
"They mention that the resulting shallow parse tags are somewhat different than those used by Ramshaw and Marcus  , but that they found no significant accuracy differences in training on either set.",0,original
"In this paper, we take the framework for acquiring multi-level syntactic translation rules of   from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we construct a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words.",0,original
The results we obtained on the CoNLL03 test set were consistent with what was reported in  .,0,original
"it constitutes a bijection between source and target sentence positions, since the intersecting alignments are functions according to their definition in   3.",0,original
"Both were 5gram models with modified Kneser-Ney smoothing, lossily compressed using a perfect-hashing scheme similar to that of Talbot and Brants   but using minimal perfect hashing  .",0,original
Its rule binarization is described in  .,0,original
It achieves 90.1% average precision/recall for sentences with maximum length 40 and 89.5% for sentences with maximum length 100 when trained and tested on the standard sections of the Wall Street Journal Treebank  .,0,original
"Wu   has been unable to find real examples of cases where hierarchical alignment would fail under these conditions, at least in fixed-word-order languages that are lightly inflected, such as English and Chinese.  .",0,original
Word alignments were generated using Model 4   using the multi-threaded implementation of GIZA++  .,0,original
See Hobbs   for explanation of this notation for events,0,original
"ROUGE has been used in meeting summarization evaluation  , yet the question remained whether ROUGE is a good metric for the meeting domain.",0,original
However there has recently been much work drawing connections between the two methods  ; in this section we review this work.,0,original
"However, most of the existing models have been developed for English and trained on the Penn Treebank  , which raises the question whether these models generalize to other languages, and to annotation schemes that differ from the Penn Treebank markup.",0,original
ing and McKeown   found that human summarization can be traced back to six cut-andpaste operations of a text and proposed a revision method consisting of sentence reduction and combination modules with a sentence extraction part,0,original
"We measured inter-annotator agreement with the Kappa statistic   using the 1,391 items that two annotators scored in common.",0,original
"In particular, most of the work on parsing with kernel methods has focussed on kernels over parse trees  .",0,original
"For BPM, we run 100 averaged perceptrons   with 10 iterations for each.",0,original
It is believed that improvement can be achieved by training the generative model based on a discriminative optimization criteria   in which the training procedure is designed to maximize the conditional probability of the parses given the sentences in the training corpus.,0,original
"Then, by using evaluations similar to those described in   and by Rapp  , we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations  , and that they also serve as better predictors of the strongest human associations  .",0,original
"3ThePOS taggers The two POS taggers used in the experiments are TNT, a publicly available Markov model tagger  , and a reimplementation of the maximum entropy   tagger MXPOST  .",0,original
"For the constituent-based models, constituent information was obtained from the output of Collins parser   for English and Dubeys parser   for German.",0,original
"Two more recent investigations are by Yarowsky,  , and later, Mihalcea,  .",0,original
"As to analysis of NPs, there have been a lot of work on statistical techniques for lexical dependency parsing of sentences  , and these techniques potentially can be used for analysis of NPs if appropriate resources for NPs are available.",0,original
5.3 Evaluation Metric This paper focuses on the BLEU metric as presented in  .,0,original
"1 Introduction Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation  , and many other multi-lingual natural language processing applications.",0,original
rown et al   put forward and discussed n-gram models based on classes of words,0,original
"The supervised component is Collins parser  , trained on the Wall Street Journal.",0,original
"We experimented with two independent, arguably complementary techniques for clustering and aligning  a predicate argument based approach that extracts more general templates containing one predicate and a ROUGE   based 265 approach that can extract templates containing multiple verbs.",0,original
"Traditionally, maximum-likelihood estimation from relative frequencies is used to obtain conditional probabilities  , eg, p  = c /summationtexts c    and p  are symmetrical, we will usually refer only to p  for brevity).",0,original
hese are most directly presented in Ostler and Atkins  ,0,original
"Nakagawa   and Hall   also showed the effectiveness of global features in improving the accuracy of graph-based parsing, using the approximate Gibbs sampling method and a reranking approach, respectively.",0,original
omokiyo and Hurst   use pointwise KLdivergence between multiple language models for scoring both phraseness and informativeness of phrases,0,original
"So far, pivot features on the word level were used  , e.g. Does the bigram not buy occur in this document?  .",0,original
Ramshaw and Marcus  first represented base noun phrase recognition as a machine learning problem.,0,original
"In this paper, we adopt Stanford Maximum Entropy   implementation in our experiments.",0,original
The model employs a stochastic version of an inversion transduction grammar or ITG  .,0,original
"NeATS computes the likelihood ratio    to identify key concepts in unigrams, bigrams, and trigrams, and clusters these concepts in order to identify major subtopics within the main topic.",0,original
"Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate     training, proposes directions to search for a better weight-vector  to combine feature functions.",0,original
"4 Methodology 4.1 Data In order to be able to compare our results with the results obtained by other researchers, we worked with the same data sets already used by   for NP and SV detection.",0,original
"We propose a probabilistic quasi-synchronous grammar, inspired by one proposed for machine translation  , and parameterized by mixtures of a robust nonlexical syntax/alignment model with a lexical-semantics-drivenlog-linear model.",0,original
3 Automatic Evaluation of MT Quality We utilize BLEU   for the automatic evaluation of MT quality in this paper.,0,original
"In the domain adaptation track, participants were provided with English training data from the Wall Street Journal portion of the Penn Treebank   converted to dependencies   to train parsers to be evaluated on material in the biological   and chemical   domains  , and optionally on text from the CHILDES database  .",0,original
Please note that our approach is very different from other approaches to context dependent rule selection such as   and  .,0,original
"One of our goals was to use for our study only information that could be annotated reliably  , as we believe this will make our results easier to replicate.",0,original
"The order of constituents, for instance, can be used to inform prototype-driven learning strategies  , which can then be applied to raw corpora.",0,original
"This alignment system is powered by the IBM translation models  , in which one sentence generates the other.",0,original
"To accommodate multiple overlapping features on observations, some other approaches view the sequence labeling problem as a sequence of classification problems, including support vector machines     and a variety of other classifiers  .",0,original
A Viterbi alignment computed from an IBM model 4   was computed for each translation direction.,0,original
We implemented an N-gram indexer/estimator using MPI inspired by the MapReduce implementation of N-gram language model indexing/estimation pipeline  .,0,original
"4.1 Experimental Setup Like several previous work  , Pang and Lee  , Whitelaw et al.",0,original
"We used sections 220 of the Penn Treebank 2 Wall Street Journal corpus   for training, section 22 as development set and section 23 for testing.",0,original
"In the past two or three years, this kind of verification has been attempted for other aspects of semantic interpretation: by Passonneau and Litman   for segmentation and by Kowtko, Isard, and Doherty   and Carletta et al.",0,original
"Distance measures for CCG Our distance measures are related to those proposed by Goodman  , which are appropriate for binary trees  ).",0,original
"This permits us to make exact comparisons with the parser of Yamada and Matsumoto  , but also the parsers of Collins   and Charniak  , which are evaluated on the same data set in Yamada and Matsumoto  .",0,original
"For the WMT 2009 Workshop, we selected a linear combination of BLEU   and TER   as optimization criterion,  := argmax{ TER}, based on previous experience  .",0,original
We also cannot use prior graph construction methods for the document level  ) at the word sense level.,0,original
The experimental results in   show a negative impact on the parsing accuracy from too long dependency relation.,0,original
The parser induction algorithm used in all of the experiments in this paper was a distribution of Collins's model 2 parser  .,0,original
"For practical reasons, the maximum size of a token was set at three for Chinese, andfour forKorean.2 Minimum error rate training   was run on each system afterwardsand BLEU score   was calculated on the test sets.",0,original
"In cases where the number of gold tags is different than the number of induced tags, some must necessarily remain unassigned  .",0,original
"We parsed a 125-million word newspaper corpus with Minipar, 1 a descendent of Principar  , and extracted dependency relationships from the parsed corpus.",0,original
Example of such algorithms are   and   that use syntactic features in the vector definition.,0,original
"In this work, we use the prototype lists originally defined by Haghighi and Klein     and subsequently used by Chang et al.",0,original
"However, Dunning   pointed out that for the purpose of corpus statistics, where the sparseness of data is an important issue, it is better to use the log-likelihood ratio.",0,original
"Since adjectives have been a focus of previous work in sentiment detection  13, we looked at the performance of using adjectives alone.",0,original
We use SUMMA   to generate generic and query-based multi-document summaries and evaluate them using ROUGE evaluation metrics   relative to human generated summaries.,0,original
"For this reason, paraphrase poses a great challenge for many Natural Language Processing   tasks, just as ambiguity does, notably in text summarization and NL generation  .",0,original
"On the other hand, both BLEU   and NIST   scores are higher for the baseline system  .",0,original
"Thus, equation   can be rewritten as  = i p i iii i i eppfef )| | |  4.2 Lexical Weight Given a phrase pair ), .",0,original
TheData For our experiments we used a version of the British National Corpus parsed with the statistical parser of Collins  ,0,original
"The MLFs use reification to achieve flat expressions, very much in the line of Davidson  , Hobbs  , and Copestake et al.",0,original
INTRODUCTION Class-based language models  have been proposed for dealing with two problems confronted by the well-known word n-gram language models   data sparseness: the amount of training data is insufficient for estimating the huge number of parameters; and   domain robustness: the model is not adaptable to new application domains.,0,original
"1984), written discourse  , and conversational data  .",0,original
"2 Statistical Word Alignment According to the IBM models  , the statistical word alignment model can be generally represented as in Equation  .",0,original
  from Sections 2-21 of the Wall Street Journal   in the Penn Treebank   and its subsets.3 We then converted them into strongly equivalent HPSG-style grammars using the grammar conversion described in Section 2.1.,0,original
"On the other hand, the thesaurus-based method of Yarowsky   may suffer from loss of information   as well as data sparseness   are based on the WordNet taxonomy while classes of Brown et al.",0,original
ahill and van Genabith   attain 98.2% coverage and a BLEU score of 0.6652 on the standard WSJ test set  ,0,original
The algorithm is essentially the same as the one introduced in  .,0,original
"Abney   notes important problems with the soundness of the approach when a unification-based grammar is actually determining the derivations, motivating the use of log-linear models   for parse ranking that Johnson and colleagues further developed  .",0,original
There are multiple studies   showing that the agreement between two   native speakers is about upper a15 a12a14a7 to lower a0a4a12a14a7.,0,original
he other approach selected was Yarowsky's unsupervised algorithm  ,0,original
"Firstly, we run GIZA++   on the training corpus in both directions and then apply the ogrow-diag-finalprefinement rule   to obtain many-to-many word alignments.",0,original
Ontologies are formal specifications of a conceptualization   so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat   for the purpose of linguistic annotation.,0,original
"To enable such techniques, we bring the cohesion constraint inside the ITG framework  .",0,original
"Many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++  , in both directions and by combining the results based on a heuristic  .",0,original
"2.6 Tuning procedure The Moses-based systems were tuned using the implementation of minimum error rate training     distributed with the Moses decoder, using the development corpus  .",0,original
"For example, in the context of syntactic disambiguation, Black   and Magerman   proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees.",0,original
"Since the DUC 2004 evaluation, Lin   has concluded that certain ROUGE metrics correlate better with human judgments than others, depending on the summarisation task being evaluated, i.e. single document, headline, or multi-document summarisation.",0,original
"According to the Bayes Rule, the problem is transformed into the noisy channel model paradigm, where the translation is the maximum a posteriori solution of a distribution for a channel target text given a channel source text and a prior distribution for the channel source text  .",0,original
"Previous research in automatic acquisition focuscs primarily on the use of statistical techniques, such as bilingual alignment  , or extraction of syntactic constructions from online dictionaries and corpora  .",0,original
5 Augmenting the corpus with an extracted dictionary Previous research   has shown that including word aligned data during training can improve translation results.,0,original
A single translation is then selected by finding the candidate that yields the best overall score   or by cotraining  .,0,original
5.3 Related works and discussion Our two-step model essentially belongs to the same category as the works of   and  .,0,original
"A second example of subtle language dependence comes from Dasgupta and Ng  , who present an unsupervised morphological segmentation algorithm meant to be language-independent.",0,original
"Researchers such as   and   have applied robust grammars and statistical techniques over large corpora to extract interesting noun phrases and subject-verb, verb-object pairs.",0,original
We utilize the OpenNLP MaxEnt implementation2 of the maximum entropy classification algorithm   to train classification models for each lemma and part-of-speech combination in the training corpus.,0,original
There are also research work on automatically classifying movie or product reviews as positive or negative  .,0,original
"2 Models, Search Spaces, and Errors A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization  .",0,original
his further supports the claim by Dunning   that loglikelihood ratio is much less sensitive than pmi to low counts,0,original
The first LR model for each language uses maximum entropy classification   to determine possible parser actions and their probabilities4.,0,original
The techniques used to solve this problem can be roughly classified into two main categories: those relying on pre-existing knowledge resources     and those inducing distributional properties of words from corpora  .,0,original
"In this respect it resembles Wus 264 bilingual bracketer  , but ours uses a different extraction method that allows more than one lexical item in a rule, in keeping with the phrasebased philosophy.",0,original
"Indeed, as Sinopalnikova and Pavel   note, Deese   was the first to conduct linguistic analyses of word association norms, such as measurements of semantic similarity based on his convictions that similar words evoke similar word association responsesan approach that is somewhat reminiscent of Church and Hanks   notion of mutual information.",0,original
"Methods 4.1 Experiment 1: Held out data To examine the generalizability of classifiers trained on the automatically generated data, a C4.5 decision tree classifier   was trained and tested on the held out test set described above.",0,original
"Here, ppicker shows the accuracy when phrases are extracted by using the N-best phrase alignment method described in Section 4.1, while growdiag-final shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in  .",0,original
"Following the perspective of  , a minimal set of phrase blocks with lengths   where either m or n must be greater than zero results in the following types of blocks: 1.",0,original
The first one makes use of the advances in the parsing technology or on the availability of large parsed corpora  ) to produce algorithms inspired by Hobbs' baseline method  .,0,original
"In order to determine inter-annotator agreement for the database of annotated texts, we computed kappa statistics  .",0,original
"But in fact, the issue of editing in text summarization has usually been neglected, notable exceptions being the works by Jing and McKeown   and Mani, Gates, and Bloedorn  .",0,original
Standard MET   iterative parameter estimation under IBM BLEU   is performed on the corresponding development set.,0,original
Our approach is based on earlier work on LFG semantic form extraction   and recent progress in automatically annotating the Penn-II treebank with LFG f-structures  .,0,original
"1 Introduction A """"pain in the neck""""   for NLP in languages of the Indo-Aryan family   is the fact that most verbs   occur as complex predicates multi-word complexes which function as a single verbal unit in terms of argument and event structure  .",0,original
"In the English all-words task of the previous SENSEVAL evaluations  , the best performing English all-words task systems with the highest WSD accuracy were trained on SEMCOR  .",0,original
"We view L2P as a tagging task that can be performed with a discriminative learning method, such as the Perceptron HMM  .",0,original
"MT output was evaluated using the standard evaluation metric BLEU  .2 The parameters of the MT System were optimized for BLEU metric on NIST MTEval2002 test sets using minimum error rate training  , and the systems were tested on NIST MTEval2003 test sets for both languages.",0,original
"Formally, the approach we take can be thought of as a noisier channel, where an observed signal o gives rise to a set of source-language strings fprime  F  and we seek e = arg maxe max fprimeF  Pr    = arg maxe max fprimeF  Pr Pr    = arg maxe max fprimeF  Pr Pr Pr .  Following Och and Ney  , we use the maximum entropy framework   to directly model the posterior Pr  with parameters tuned to minimize a loss function representing 1012 the quality only of the resulting translations.",0,original
The models are based on a maximum entropy framework  .,0,original
"In all experiments, word alignment was obtained using the grow-diag-final heuristic for symmetrizing GIZA++   alignments.",0,original
  use hand-coded slot-filling rules to determine the semantic roles of the arguments of a nominalization.,0,original
"Most of the previous work on statistical machine translation, as exemplified in  , employs word-alignment algorithm  ) that provides local associations between source and target words.",0,original
.1 Collocation Features The collocation features were inspired by the one-sense-per-collocation heuristic proposed by Yarowsky  ,0,original
Section 3 describes previous work   that derives connections between boosting and maximum-entropy models for the simpler case of classification problems; this work forms the basis for the reranking methods.,0,original
"Table 3 compares precision, recall, and F scores for our system with CoNLL-2001 results training on sections 15-18 of the Penn Treebank and testing on section 21  .",0,original
A natural fit to the existing statistical machine translation framework  A metric that ranks a good translation high in an nbest list could be easily integrated in a minimal error rate statistical machine translation training framework  ,0,original
"But because we want the insertion state a1a16a20 to model digressions or unseen topics, we take the novel step of forcing its language model to be complementary to those of the other states by setting a2 a3a27a38 a21 a8 a8 a4 a8 a24 a26a11a28a30a29a6 a39a41a40a43a42a45a44a16a46 a1a48a47a1a50a49 a20 a2 a3 a26a17a21 a8a9a8 a4 a8 a24 a51a53a52a55a54a57a56 a21 a39a58a40a43a42a45a44a16a46 a1a59a47a1a50a49 a20 a2 a3a27a26a11a21a50a60 a4 a8 a24a30a24 a17 4Following Barzilay and Lee  , proper names, numbers and dates are   replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event.",0,original
"Thus, we can compute the source dependency LM score in the same way we compute the target side score, using a procedure described in  .",0,original
Ramshaw and Marcus   views chunking as a tagging problem.,0,original
We compared our system Lynx against a freely available phrase-based decoder Pharaoh  .,0,original
"Each element in vectorw gives a weight to its corresponding element in  , which is the count of a particular feature over the whole sentence y. We calculate the vectorw value by supervised learning, using the averaged perceptron algorithm  , given in Figure 1.",0,original
"For the Brown corpus, we based our division on  .",0,original
2 Related work Our work is closest in spirit to the two papers that inspired us   and  .,0,original
"Large treebanks are available for major languages, however these are often based on a speci c text type or genre, e.g. nancial newspaper text  ).",0,original
"Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSPcooc on the verb join,3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch   1.18, work at 1.14 give a better SIMS  for Equation   than the top similarities returned by  : participate 0.164, lead 0.150, return to 0.148, say 0.143, rejoin 0.142, sign 0.142, meet 0.142, include 0.141, leave 0.140, work 0.137 Other features are also weighted intuitively.",0,original
"From this data, we use the the GHKM minimal-rule extraction algorithm of   to yield rules like: NP-C )$x1 de x0 Though this rule can be used in either direction, here we use it right-to-left  .",0,original
"The weights of the different knowledge sources in the log-linear model used by our system are trained using Maximum BLEU  , which we run for 25 iterations individually for each system.",0,original
We perform a statistical analysis that provides information that complements the information provided by Cohen's Kappa  .,0,original
The methodology used   is based on the definition of a function Pr  that returns the probability that tI1 is a 835 source Transferir documentos explorados a otro directorio interaction-0 Move documents scanned to other directory interaction-1 Move s canned documents to other directory interaction-2 Move scanned documents to a nother directory interaction-3 Move scanned documents to another f older acceptance Move scanned documents to another folder Figure 1: Example of CAT system interactions to translate the Spanish source sentence into English.,0,original
"OpenCCG   and XLE  , or created semi-automatically  , or fully automatically extracted from annotated corpora, like the HPSG  , LFG   and CCG   resources derived from the Penn-II Treebank    .",0,original
Computational linguists have demonstrated that a words meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs  .,0,original
type system F1% D Collins   89.7 Henderson   90.1 Charniak and Johnson   91.0 updated   91.4 this work 91.7 G Bod   90.7Petrov and Klein   90.1 S McClosky et al.,0,original
"Oncetraininghastakenplace,minimumerrorrate training   is used to tune the parameters i. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores  .",0,original
"Methods for doing so, for stochastic parser output, are described by Johnson   and Cahill et al  .",0,original
"3.2 The parsers The parsers that we chose to evaluate are the C&C CCG parser  , the Enju HPSG parser  , the RASP parser  , the Stanford parser  , and the DCU postprocessor of PTB parsers  , based on LFG and applied to the output of the Charniak and Johnson reranking parser.",0,original
We evaluated the translation quality using case-insensitive BLEU metric  .,0,original
ahill and van Genabith   note that conditioning f-structure annotated generation rules on local features (Eqn,0,original
"5.3 Experimental setup We used the Stanford Parser   for both languages, Penn English Treebank   and Penn Arabic Treebank set  .",0,original
In   the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU.,0,original
"To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures  , response time to associate synonyms and antonyms in psychological experiments  , or extracting related words automatically from corpora  .",0,original
Most previous work exploiting unsupervised training data for inferring POS tagging models has focused on semi-supervised methods in the in which the learner is provided with a lexicon specifying the possible tags for each word   or a small number of prototypes for each POS  .,0,original
"In contrast, the C&C tagger, which is based on that of Ratnaparkhi  , utilizes a wide range of features and a larger contextual window including the previous two tags and the two previous and two following words.",0,original
A number of researchers have explored learning words and phrases with prior positive or negative polarity    ).,0,original
"Lin  s similar word list for eat misses these but includes sleep   and sit  , because these have similar subjects to eat.",0,original
"One way of obtaining a suitable granularity of nodes is to introduce latent classes, such as the Semi-Markov class model  .",0,original
"It is a natural extension of the Viteri>i algorithm for those languages that do not have delimiters between words, and it can generate N-best morphological analysis hypotheses, like tree trellis search.",0,original
"Except where noted, each system was trained on 27 million words of newswire data, aligned with GIZA++   and symmetrized with the grow-diag-final-and heuristic  .",0,original
"Our system is a re-implementation of the phrase-based system described in Koehn  , and uses publicly available components for word alignment  1, decoding  2, language modeling  3 and finite-state processing  4.",0,original
"As in the work of  , each word or punctuation mark within a sentence is labeled with IOB tag together with its function type.",0,original
"Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic  .",0,original
"D. Hindle, Noun classification from predicate argument structures, in  .",0,original
"We used a loglinear model with no Markov dependency between adjacent tags,3 and trained the parameters of the model with the perceptron algorithm, with averaging to control for over-training  .",0,original
1087 Model 3 of   is a zero-order alignment model like Model 2 including in addition fertility paranmters.,0,original
Yarowsky   has proposed automatically augmenting a small set of experimenter-supplied seed collocations   into a much larger set of training materials.,0,original
"In addition to this phrase translation probability feature, Hieros feature set includes the inverse phrase translation probability log p , lexical weights lexwt  and lexwt , which are estimates of translation quality based on word-level correspondences  , and a rule penalty allowing the model to learn a preference for longer or shorter derivations; see   for details.",0,original
Since the introduction of BLEU   the basic n-gram precision idea has been augmented in a number of ways.,0,original
"The theory has been applied in probabilistic language modeling  , natural language processing  , as well as computational vision  .",0,original
"A variety of approaches have been investigated for speech summarization, for example, maximum entropy, conditional random fields, latent semantic analysis, support vector machines, maximum marginal relevance  .",0,original
"Following our previous work  , we extract features from a sequence representation and a parse tree representation of each relation instance.",0,original
"For each, we give case-insensitive scores on version 0.6 of METEOR   with all modules enabled, version 1.04 of IBMstyle BLEU  , and version 5 of TER  .",0,original
We ran the decoder with its default settings and then used Moses implementation of minimum error rate training   to tune the feature weights on the development set.,0,original
For a more detailed introduction to maximum entropy estimation see  .,0,original
2 Block Orientation Bigrams This section describes a phrase-based model for SMT similar to the models presented in  .,0,original
"Because our system uses a synchronous CFG, it could be thought of as an example of syntax-based statistical machine translation  , joining a line of research   that has been fruitful but has not previously produced systems that can compete with phrase-based systems in large-scale translation tasks such as the evaluations held by NIST.",0,original
"Furthermore, the underlying decoding strategies are too time consuming for our application We therefore use a translation model based on the simple linear interpolation given in equation 2 which combines predictions of two translation models -Ms and M~ -both based on IBM-like model 2 .",0,original
"While we have observed reasonable results with both G 2 and Fisher's exact test, we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information   measure  : I  --log 2 P    P P  In  , y is the seed term and x a potential target word.",0,original
"  simplify these probability distributions, as given in Equations 9 and 10.",0,original
"Recent lexicalized stochastic parsers such as Collins  , Charniak  , and others add additional features to each constituent, the most important being the head word of the parse constituent.",0,original
"The English experiments were performed on the Penn Treebank  , using a standard set of head-selection rules   to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set  , a development set  , and several test sets  .",0,original
"In fact, many attempts have recently been made to develop semi-supervised SOL methods  .",0,original
"In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical   and global levels  , while preserving regularities recognized by classic discourse theories  .",0,original
"  show that this model is a member of an exponential family with one parameter for each constraint, specifically a model of the form 1 ~ I~   p  = E' in which z  = eZ, Y The parameters A1,  , An are Lagrange multipliers that impose the constraints corresponding to the chosen features fl, -,fnThe term Z  normalizes the probabilities by summing over all possible outcomes y. Berger et al.",0,original
guchi & Lavrenko   propose the use of probabilistic language models for ranking the results not only by sentiment but also by the topic relevancy,0,original
Rulesize and lexicalization affect parsing complexity whether the grammar is binarized explicitly   or implicitly binarized using Early-style intermediate symbols  .,0,original
Finally we trained model weights by maximizing BLEU   and set decoder optimization parameters   on a development test set of 200 held-out sentences each with a single reference translation.,0,original
This result supports the intuition in   that correlation at segment level is necessary to ensure the reliability of metrics in different situations.,0,original
"A CHECK move requests the partner to confirm information that the speaker has some reason to believe, but is not entirely sure about \ .",0,original
"The data set is same as in Section 5.1, except that we also parsed the English-side using a variant of the Collins   parser, and then extracted 24.7M tree-to-string rules using the algorithm of  .",0,original
"Among them,   have proposed a way to exploit bilingual dictionnaries at training time.",0,original
"Given a set of features and a training corpus, the MaxEnt estimation process produces a model in which every feature fi has a weight i. We can compute the conditional probability as  : p  = 1Z  productdisplay i ifi    Z  = summationdisplay o productdisplay i ifi    The conditional probability of the outcome is the product of the weights of all active features, normalized over the products of all the features.",0,original
"McClosky et al   use sections 2-21 of the WSJ PennTreebank as seed data and between 50K to 2,500K unlabeled NANC corpus sentences as self-training data.",0,original
"From this point of view, some of the measures used in the evaluation of Machine Translation systems, such as BLEU  , have been imported into the summarization task.",0,original
"Another alternative for future work is to compare the dynamic programming approach taken here with the beam-search approach of Collins and Roark  , which allows more global features.",0,original
4 Filtering with the CFG Rule Dictionary We use an idea that is similar to the method proposed by Ratnaparkhi   for partof-speech tagging.,0,original
"We removed all but the first two characters of each POS tag, resulting in a set of 57 tags which more closely resembles that of the Penn TreeBank  .",0,original
"Based on annotation differences in the datasets   and a bug in their system  , their results are inconclusive.",0,original
The baseline score using all phrase pairs was 59.11   with a 95% confidence interval of  .,0,original
"6 Parameter Estimation From the duality of ME and maximum likelihood  , optimal parameters  for model   can be found by maximizing the log-likelihood function over a training sample {  : t = 1,,N}, i.e.:  = argmax  Nsummationdisplay t=1 logp .",0,original
SGD was recently used for NLP tasks including machine translation   and syntactic parsing  .,0,original
"There have been many statistical measures which estimate co-occurrence and the degree of association in previous researches, such as mutual information  , t-score  , dice matrix  .",0,original
Dynamic programming is applied to bilingual sentence alignment in most of previous works  .,0,original
"Different models have been presented in the literature, see for instance  .",0,original
The average senior high school student achieves 57% correct  .,0,original
"For instance, instead of representing the polarity of a term using a binary value, Mullen and Collier   use Turneys   method to assign a real value to represent term polarity and introduce a variety of numerical features that are aggregate measures of the polarity values of terms selected from the document under consideration.",0,original
Parameters  used to calculate P  are trained using MER training   on development data.,0,original
"Our named entity recognizer used a maximum entropy model, built with Adwait Ratnaparkhi's tools   to label word sequences as either person, place, company or none of the above based on local cues including the surrounding words and whether honorifics  .",0,original
"  produced a corpus of 4,000 questions annotated with syntactic trees, and obtained an improvement in parsing accuracy for Bikels reimplementation of the Collins parser   by training a new parser model with a combination of newspaper and question data.",0,original
"The state of a left-corner parser does capture some linguistic generalizations  , but one might still expect sparse-data problems.",0,original
enkova and Louis   investigate how summary length and the characteristics of the input influence the summary quality in multi-document summarization,0,original
"1998; Goldman and Zhou, 2000) that has been used previously to train classifiers in applications like word-sense disambiguation  , document classification   and named-entity recognition   and apply this method to the more complex domain of statistical parsing.",0,original
294 Fraser and Marcu Measuring Word Alignment Quality for Statistical Machine Translation 2.2 Measuring Translation Performance Changes Caused By Alignment In phrased-based SMT   the knowledge sources which vary with the word alignment are the phrase translation lexicon   and some of the word level translation parameters  .,0,original
"Similar to bidirectional labelling in  , there are two learning tasking in this model.",0,original
These models can be tuned using minimum error rate training  .,0,original
he novel idea presented in Strube & Ponzetto   was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness,0,original
"Dependency models   use the parsed dependency structure of sentences to build the language model as in grammatical trigrams  , structured language models  , and dependency language models  .",0,original
In this paper we present MapReduce implementations of training algorithms for two kinds of models commonly used in statistical MT today: a phrasebased translation model   and word alignment models based on pairwise lexical translation trained using expectation maximization  .,0,original
Metrics based on syntactic similarities such as the head-word chain metric    .,0,original
" , and component weights are adjusted by minimum error rate training  .",0,original
"For a comparison, we also include the ROUGE-1 Fscores   of each system output against the human compressed sentences.",0,original
One interesting approach to extending the current system is to introduce a statistical translation model   to filter out irrelevant translation candidates and to extract the most appropriate subpart from a long English sequence as the translation by locally aligning the Japanese and English sequences.,0,original
They are also used for inducing alignments  .,0,original
"The chunker is trained on the answer side of the Training corpus in order to learn 2 and 3word collocations, defined using the likelihood ratio of Dunning  .",0,original
"Starting from the list of 12 ambiguous words provided by Yarowsky   which is shown in table 2, we created a concordance for each word, with the lines in the concordances each relating to a context window of 20 words.",0,original
We would expect better performance with the more accurate approximation based on variational inference proposed and evaluated in  .,0,original
"This paper is heavily indebted to prior work on unsupervised learning of position categories such as Brown et al 1992, Schtze 1997, Higgins 2002, and others cited there.",0,original
"In a different work, Banerjee and Lavie   argued that the measured reliability of metrics can be due to averaging effects but might not be robust across translations.",0,original
"For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by Lin  .",0,original
"sister head tag X Table 4: Linguistic features in the current model compared to the models of Carroll and Rooth  , Collins  , and Charniak   Negra, based on Collinss   model for nonrecursive NPs in the Penn Treebank  .",0,original
These feature vectors and the associated parser actions are used to train maximum entropy models  .,0,original
"3.1 Experiments The model described in section 2 has been tested on the Brown corpus  , tagged with the 45 tags of the Penn treebank tagset  , which constitute the initial tagset T0.",0,original
"The output of a contextfree parser, such as that of Collins   or Charniak  , can be transformed into a sequence of shallow constituents for comparison with the output of a shallow parser.",0,original
ang and Lee   applied two different classifiers to perform sentiment annotation in two sequential steps: the first classifier separated subjective   texts from objective   ones and then they used the second classifier to classify the subjective texts into positive and negative,0,original
"Bilexical CFG is at the heart of most modern statistical parsers  , because the statistics associated with word-specific rules are more informative for disambiguation purposes.",0,original
"Class based models   distinguish between unobserved cooccurrences using classes of """"similar"""" words.",0,original
"We can then use this newly identified set to:   use Turneys method to find the orientation for the terms and employ the terms and their scores in a classifier, and   use Turneys method to find the orientation for the terms and add the new terms as additional seed terms for a second iteration As opposed to Turney  , we do not use the web as a resource to find associations, rather we apply the method directly to in-domain data.",0,original
"We report that our parsing framework achieved high accuracy   in dependency analysis of Japanese with a combination of an underspecified HPSG-based Japanese grammar, SLUNG   and the maximum entropy method  .",0,original
"In each iteration of local search, we look in the neighborhood of the current best alignment for a better alignment  .",0,original
  BLEU-4   is used as the evaluation metric.,0,original
"Computational linguistics research generally attaches great value to high kappa measures  , which indicate high human agreement on a particular task.",0,original
"Like the models of Goodman  , the additional features in our model are generated probabilistically, whereas in the parser of Collins   distance measures are assumed to be a function of the already generated structure and are not generated explicitly.",0,original
"While this approach exploits only syntactic and lexical information, Jing and McKeown   also rely on cohesion information, derived from word distribution in a text: Phrases that are linked to a local context are retained, while phrases that have no such links are dropped.",0,original
"We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and Hindles   and Lins   mutual information-based metrics.",0,original
"While Galley   describes extracting treeto-string rules from 1-best trees, Mi and Huang et al.",0,original
5.2 Assigning complex ambiguity tags In the tagging literature  ) an ambiguity class is often composed of the set of every possible tag for a word.,0,original
"The method described by Kazama and Torisawa   is to rst extract the rst   noun phrase after the rst is, was, are, or were in the rst sentence of a Wikipedia article.",0,original
"Chen & Martin   introduced one of those similarity schemes, ?two-level SoftTFIDF??",0,original
"  94.17 Li and Roth   93.02 94.64 Table 2: Baseline results on three shallow parsing tasks: the NP-Chunking task  ; the CoNLL-2000 Chunking task  ; and the Li & Roth task  , which is the same as CoNLL-2000 but with more training data and a different test section.",0,original
ascaded models for fine-to-coarse sentiment analysis were studied by Pang and Lee  ,0,original
"Translation performance was measured using the BLEU score  , which measures n-gram overlap with a reference translation.",0,original
"Therefore, domain adaptation methods have recently been proposed in several NLP areas, e.g., word sense disambiguation  , statistical parsing  , and lexicalized-grammar parsing  .",0,original
"the Wall Street Journal   sections of the Penn Treebank   as training set, tests on BROWN Sections typically result in a 6-8% drop in labeled attachment scores, although the average sentence length is much shorter in BROWN than that in WSJ.",0,original
"Construct a parse chart with a CKY parser simultaneously constrained on the foreign string and English tree, similar to the bilingual parsing of Wu   1.",0,original
Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences  .,0,original
"To find these pairs automatically, wetrainedanon-sequentiallog-linearmodel that achieves a .902 accuracy  .",0,original
"Standard CI Model 1 training, initialised with a uniform translation table so that t  is constant for all source/target word pairs  , was run on untagged data for 10 iterations in each direction  .",0,original
"5.3 Comparison with SS-CRF-MER When we consider semi-supervised SOL methods, SS-CRF-MER   is the most competitive with HySOL, since both methods are defined based on CRFs.",0,original
"Galley   used skip-chain Conditional Random Fields to model pragmatic dependencies between paired meeting utterances  , and used a combination of lexical, prosodic, structural and discourse features to rank utterances by importance.",0,original
The model scaling factors are optimized using minimum error rate training  .,0,original
"Experiments We have conducted a series of lexical acquisition experiments with the above algorithm on largescale English corpora, e.g., the Brown corpus \ .",0,original
  always predicts a flat NP for such configurations).,0,original
unning   used a likelihood ratio to test word similarity under the assumption that the words in text have a binomial distribution,0,original
"This knowledge is represented in axiomatic form, using the notation proposed in   and previously implemented in TACITUS.",0,original
OS tag the text using the tagger of Ratnaparkhi  ,0,original
"For more detail, explanations and experiments see  .",0,original
"6 Conclusions In this paper, we showed that it is sometimes possible indeed, preferableto eliminate the initial bit of supervision in bootstrapping algorithms such as the Yarowsky   algorithm for word sense disambiguation.",0,original
Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community  .,0,original
The model is often further restricted so that each source word is assigned to exactly one target word  .,0,original
Distance from a target word is used for this purpose and it is calculated by the assumption that the target words in the context window have the same sense  .,0,original
"The window size may vary, Church and Hanks   used windows of size 2 and 5.",0,original
"They can be roughly divided into three categories: string-to-tree models  ), tree-to-string models  ), and tree-totree models  ).",0,original
"Instead, we opt to utilize the Stanford NER tagger   over the sentences in a document and annotate each NP with the NER label assigned to that mention head.",0,original
"Apart from BLEU, a standard automatic measure METEOR   was used for evaluation.",0,original
"We worked with an implementation of the log likelihood ratio   as proposed by Dunning   and two variants of the t-score, one considering all values   and one where only positive values   are kept following the results of Curran and Moens  .",0,original
2.1 Data representation We have compared four complete and three partial data representation formats for the baseNP recognition task presented in  .,0,original
"Ramshaw and Marcus   first assigned a chunk tag to each word in the sentence: I for inside a chunk, O for outside a chunk, and 240 type precision B tbr inside a chunk, but tile preceding word is in another chunk.",0,original
"Graphically speaking, parsing amounts to identifying rectangular crosslinguistic constituents  by assembling smaller rectangles that will together cover the full string spans in both dimensions  ).",0,original
  and Magerman   used the clustering algorithm of Brown et al,0,original
"We also trained a baseline model with GIZA++   following a regimen of 5 iterations of Model 1, 5 iterations of HMM, and 5 iterations of Model 4.",0,original
"Moore and Quirk   share the goal underlying our own research: improving, rather than replacing, Ochs MERT procedure.",0,original
Of particular relevance are class-based language models  ).,0,original
sing thesaurus categories directly as a coarse sense division may seem to be a viable alternative  ,0,original
"Brown,   uses the same bigrams and by means of a greedy algorithm forms the hierarchical clusters of words.",0,original
"Model 4 of   is also a first-order alignment model   like the HMM, trot includes also fertilities.",0,original
"For this paper, we train the parameter vector  using the perceptron algorithm  .",0,original
"Rules have the form X  e, f, where e and f are phrases containing terminal symbols   and possibly co-indexed instances of the nonterminal symbol X.2 Associated with each rule is a set of translation model features, i ; for example, one intuitively natural feature of a rule is the phrase translation  probability   = log p  , directly analogous to the corresponding feature in non-hierarchical phrase-based models like Pharaoh  .",0,original
"This curve plots the average labeled attachment score over Basque, Chinese, English, and Turkish as a function of parsing time per token.4 Accuracy of only 1% below the maximum can be achieved with average processing time of 17 ms per token, or 60 tokens per second.5 We also refer the reader to   for more detailed analysis of the ISBN dependency parser results, where, among other things, it was shown that the ISBN model is especially accurate at modeling long dependencies.",0,original
"Typically, the local context around the 215 word to be sense-tagged is used to disambiguate the sense  , and it is common for linguistic resources such as WordNet  , or bilingual data   to be employed as well as more longrange context.",0,original
he SENSEVAL '~tan    and Schiitze    ,0,original
"A growing body of recent research has focused on the problems of identifying and generating paraphrases, e.g., Barzilay & McKeown  , Lin & Pantel  , Shinyama et al,  , Barzilay & Lee  , and Pang et al.",0,original
"Automatic subjectivity analysis would also be useful to perform flame recognition  , e-mail classification  , intellectual attribution in text  , recognition of speaker role in radio broadcasts  , review mining  , review classification  , style in generation  , and clustering documents by ideological point of view  .",0,original
ps  is increased by 1110 1/  if the hypothesis ranking k in the system s contains the arc  .,0,original
ughes and Ramage   present a lexical similarity model based on random walks on graphs derived from WordNet; Rao et al,0,original
"Training of the phrase translation model builds on top of a standard statistical word alignment over the training corpus of parallel text   for identifying corresponding word blocks, assuming no further linguistic analysis of the source or target language.",0,original
"Dunning 1993), make use of both positive and negative instances of performing a task.",0,original
"The second uses the decoder to search for the highest-B translation  , which Arun and Koehn   call max-B updating.",0,original
"1 Introduction Current methods for large-scale information extraction take advantage of unstructured text available from either Web documents   or, more recently, logs of Web search queries   to acquire useful knowledge with minimal supervision.",0,original
"Methods such as  ,   and   employ a synchronous parsing procedure to constrain a statistical alignment.",0,original
"IBM constraints  , lexical word reordering model  , and inversion transduction grammar   constraints   belong to this type of approach.",0,original
"For details on these feature functions, please refer to  .",0,original
"We also record for each token its derivational root, using the CELEX  database.",0,original
phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation  .,0,original
"5.2 Evaluation Metrics The commonly used criteria to evaluate the translation results in the machine translation community are: WER  , PER  , BLEU  , and NIST  .",0,original
"Even a length limit of 3, as proposed by  , would result in almost optimal translation quality.",0,original
"The closest work is that of Jing and McKeown   and Daume III and Marcu  , in which multiple sentences are processed, with fragments within them being recycled to generate the novel generated text.",0,original
The K&M model creates a packed parse forest of all possible compressions that are grammatical with respect to the Penn Treebank  .,0,original
"Note that our use of cepts differs slightly from that of  , inasmuch cepts may not overlap, according to our definition.",0,original
Two other groups of authors have independently and simultaneously proposed adaptations of the Matrix-Tree Theorem for structured inference on directed spanning trees  .,0,original
We obtained word alignments of training data by first running GIZA++   and then applying the refinement rule grow-diag-final-and  .,0,original
2 The Penn Discourse TreeBank   The PDTB contains annotations of discourse relations and their arguments on the Wall Street Journal corpus  .,0,original
Word alignment is also a required first step in other algorithms such as for learning sub-sentential phrase pairs   or the generation of parallel treebanks  .,0,original
Jiao et al. propose semi-supervised conditional random fields   that try to maximize the conditional log-likelihood on the training data and simultaneously minimize the conditional entropy of the class labels on the unlabeled data.,0,original
The learning algorithm follows the global strategy introduced in   and adapted in   for partial parsing tasks.,0,original
"Recently, many works combined a MRD and a corpus for word sense disambiguation .",0,original
"For more detail, see Chen & Martin  .",0,original
"Syntactic context information is used   to compute term similarities, based on which similar words to a particular word can directly be returned.",0,original
"For classi cation, we use a maximum entropy model  , from the logistic regression package in Weka  , with all default parameter settings.",0,original
"  presented results suggesting that the additional parameters required to ensure that a model is not deficient result in inferior performance, but we plan to study whether this is the case for our generative model in future work.",0,original
"Concluding Remarks Formalisms for finite-state and context-free transduction have a long history  , and such formalisms have been applied to the machine translation problem, both in the finite-state case   and the context-free case  .",0,original
"There has been considerable skepticism over whether WSD will actually improve performance of applications, but we are now starting to see improvement in performance due to WSD in cross-lingual information retrieval   and machine translation   and we hope that other applications such as question-answering, text simplication and summarisation might also benet as WSD methods improve.",0,original
"2.1 Keywords As our starting point, we calculated the keywords of the Belgian corpus with respect to the Netherlandic corpus, both on the basis of a chi-square test     and the log-likelihood ratio  .",0,original
"2.4 Comparison with Hybrid Model SSL based on a hybrid generative/discriminative approach proposed in   has been defined as a log-linear model that discriminatively combines several discriminative models, pDi , and generative models, pGj , such that: R  = producttext i p Di  i producttext j p Gj  j summationtext y producttext i p Di  i producttext j p Gj  j , where ={i}Ii=1, and ={{i}Ii=1,{j}I+Jj=I+1}.",0,original
"The rules extracted from the training bitext have the following features: a114 P andP , the latter of which is not found in the noisy-channel model, but has been previously found to be a helpful feature  ; 210 Chiang Hierarchical Phrase-Based Translation a114 the lexical weights P w  andP w  , which estimate how well the words in  translate the words in   ; 4 a114 a penalty exp  for extracted rules, analogous to Koehns phrase penalty  , which allows the model to learn a preference for longer or shorter derivations.",0,original
Some examples of POS taggers that perform reasonably well on monolingual text of each language can be found in  .,0,original
"6.2 Translation Results For the translation experiments, we report the two accuracy measures BLEU   and NIST   as well as the two error rates word error rate   and positionindependent word error rate  .",0,original
"We also compared the MSR algorithm to two of the state-of-the-art discriminative training methods: Boosting in Row 3 is an implementation of the improved algorithm for the boosting loss function proposed in  , and Perceptron in Row 4 is an implementation of the averaged perceptron algorithm described in  .",0,original
This can be seen as a simplified version of  .,0,original
"Much previous work has been done on this problem and many different methods have been used: Church's PARTS   program uses a Markov model; Bourigault   uses heuristics along with a grammar; Voutilainen's NPTool   uses a lexicon combined with a constraint grammar; Juteson and Katz   use repeated phrases; Veenstra  , Argamon, Dagan & Krymolowski  and Daelemaus, van den Bosch & Zavrel   use memory-based systems; Ramshaw & Marcus   and Cardie & Pierce   use rule-based systems.",0,original
See Collins   and Collins and Duffy   for applications of the perceptron algorithm.,0,original
"The list is obtained by first extracting the phrases with -TMP function tags from the PennTree bank, and taking the words in these phrases  .",0,original
"The problem is that with such a definition of collocations, even when improved, one identifies not only collocations but freecombining pairs frequently appearing together such as lawyer-client; doctor-hospital, as pointed out by Smadja  .",0,original
Texts are represented by dependency parse trees  ) and templates by parse sub-trees.,0,original
he line search is an extension of that described in (Och 2003; Quirk et al. 2005,0,original
"In the SUMMAC experiments, the Kappa score   for interannotator agreement was reported to be 0.38  .",0,original
"We used the procedure described in Rapp  , with the only modification being the multiplication of the loglikelihood values with a triangular function that depends on the logarithm of a words frequency.",0,original
"108 To follow related work and to focus on the effects of the language model, we present translation resultsunderaninversiontransductiongrammar  translation model   trained on the Europarl corpus  , described in detail in Section 3, and using a trigram language model.",0,original
5 The Experimental Results We used the Penn Treebank WSJ corpus   to perform empirical experiments on the proposed parsing models.,0,original
he cube-pruning by Chiang   and the lazy cube-pruning of Huang and Chiang   turn the computation of beam pruning of CYK decoders into a top-k selection problem given two columns of translation hypotheses that need to be combined,0,original
"For example, the topics Sport and Education are important cues for differentiating mentions of Michael Jordan, which may refer to a basketball player, a computer science professor, etc. Second, as noted in the top WePS run  , feature development is important in achieving good coreference performance.",0,original
here has been a large interest in recognizing non-overlapping noun phrases   and follow-up papers) but relatively little has been written about identifying phrases of other syntactic categories,0,original
"We can then state the following theorem   for a proof): Theorem 1 For any training sequence   that is separable with margin, for any value of T, then for the perceptron algorithm in figure 1 Ne R 2 2 where R is a constant such that 8i;8z 2 GEN  jj    jj R. This theorem implies that if there is a parameter vector U which makes zero errors on the training set, then after a finite number of iterations the training algorithm will converge to parameter values with zero training error.",0,original
291 3.1 Level of Analysis Research on sentiment annotation is usually conducted at the text   or at the sentence levels  .,0,original
We have also used ROUGE evaluation approach   which is based on n-gram co-occurrences between machine summaries and ideal human summaries.,0,original
"The modifications are made to deal with the efficiency issue due to the fact that there is a very large number of features and training samples in our task, compared to only 8 features used in  .",0,original
"L1 or Lasso regularization of linear models, introduced by Tibshirani  , embeds feature selection into regularization so that both an assessment of the reliability of a feature and the decision about whether to remove it are done in the same framework, and has generated a large amount of interest in the NLP community recently  .",0,original
"The tools used are the Moses toolkit   for decoding and training, GIZA++ for word alignment  , and SRILM   for language models.",0,original
"In  , the definition words were used as initial sense indicators, automatically tagging the target word examples containing them.",0,original
"Log-likelihood ratio     with respect to a large reference corpus, Web 1T 5-gram Corpus  , is used to capture the contextually relevant nouns.",0,original
2 Word-to-Word Bitext Alignment We will study the problem of aligning an English sentence to a French sentence and we will use the word alignment of the IBM statistical translation models  .,0,original
"In Hirschberg and Nakatani  , average reliability   of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is.8 or above for both read and spontaneous speech; values of at least .8 are typically viewed as representing high reliability  .",0,original
he idea of synchronous SSMT can be traced back to Wu  s Stochastic Inversion Transduction Grammars,0,original
"We then built separate English-to-Spanish and Spanish-to-English directed word alignments using IBM model 4  , combined them using the intersect+grow heuristic  , and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach  .",0,original
uch tasks will require an extension of the current framework of Turney   beyond evidence from the direct cooccurrence of target word pairs,0,original
"Kim and Hovy   proposed a method for extracting opinion holders, topics and opinion words, in which they use semantic role labeling as an intermediate step to label opinion holders and topics.",0,original
"Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN  ) or WN in other languages  ).",0,original
"Following Zhang and Clark  , we first generated CTB 3.0 from CTB 4.0 using sentence IDs 110364.",0,original
"BLEU: BLEU score, which computes the ratio of n-gram for the translation results found in reference translations  .",0,original
"579 The MaxEnt algorithm associates a set of weights  i=1nj=1m with the features, which are estimated during the training phase to maximize the likelihood of the data  .",0,original
arowsky   studied a method for word sense disambiguation using unlabeled data,0,original
"As a result, the string translation probability can be decomposed into a lexicon probability and an alignment probability  .",0,original
The Kappa statistic   is typically used to measure the human interrater agreement.,0,original
"In comparison, we deployed the GIZA++ MT modeling tool kit, which is an implementation of the IBM Models 1 to 4  .",0,original
This implies that the complexity of structure divergence between two languages is higher than suggested in literature  .,0,original
"This problem will be solved by incorporating other resources such as thesaurus or a dictionary,orcombiningourmethodwithothermethods using external wider contexts  .",0,original
" , Pedersen  , Yarowsky and Florian  ) as well as maximum entropy models  , Klein and Manning  ).",0,original
"The features we used are as follows:  Direct and inverse IBM model;  3, 4-gram target language model;  3, 4, 5-gram POS language model  ; 96  Sentence length posterior probability  ;  N-gram posterior probabilities within the NBest list  ;  Minimum Bayes Risk probability;  Length ratio between source and target sentence; The weights are optimized via MERT algorithm.",0,original
791 and score the alignment template models phrases  .,0,original
"In Machine Translation, for example, sentences are produced using application-specific decoders, inspired by work on speech recognition  , whereas in Summarization, summaries are produced as either extracts or using task-specific strategies  .",0,original
"Numerous approaches have been explored for exploiting situations where some amount of annotated data is available and a much larger amount of data exists unannotated, e.g. Marialdo's HMM part-of-speech tagger training  , Charniak's parser retraining experiment  , Yarowsky's seeds for word sense disambiguation   and Nigam et al's   topic classifier learned in part from unlabelled documents.",0,original
ollins   proposed the perceptron as an alternative to the CRF method for HMM-style taggers,0,original
To cope with this problem we 898 use the concept of class proposed for a word n-gram model  .,0,original
"High values of  fall into the minimal entropy trap, while low values ofhave no effect on the model   for an example).",0,original
A contrasting approach   relies only upon documents whose labels are unknown.,0,original
"Building on the annotations from the Wall Street Journal   portion of the Penn Treebank  , the project added several new layers of semantic annotations, such as coreference information, word senses, etc. In its first release   through the Linguistic Data Consortium  , the project manually sense-tagged more than 40,000 examples belonging to hundreds of noun and verb types with an ITA of 90%, based on a coarse-grained sense inventory, where each word has an average of only 3.2 senses.",0,original
"For METEOR, when used with its originally proposed parameter values of  , which the METEOR researchers mentioned were based on some early experimental work  , we obtain an average correlation value of 0.915, as shown in the row METEOR.",0,original
"The percentage agreement for each of the features is shown in the following table: feature percent agreement form 100% intentionality 74.9% awareness 93.5% safety 90.7% As advocated by Carletta  , we have used the Kappa coefficient   as a measure of coder agreement.",0,original
I Various models have been constructed by the IBM team  .,0,original
"Evaluation 8.1 Effects of Unpublished Details In this section we present the results of effectively doing a clean-room implementation of Collins parsing model, that is, using only information available in  , as shown in Table 4.",0,original
  reports a success rate of 96% disambiguating twelve words with two clear sense distinctions each one.,0,original
Statistical parsers trained on the Penn Treebank     produce trees annotated with bare phrase structure labels  .,0,original
"Some of these methods make use of prior knowledge in the form of an existing thesaurus  , while others do not rely on any prior knowledge  .",0,original
We use the GIZA++ implementation of IBM Model 4   coupled with the phrase extraction heuristics of Koehn et al.,0,original
"2 Related Work Automatic Paraphrasing and Entailment Our work is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing  .",0,original
"5 Evaluation 5.1 Datasets We used two datasets, customer reviews 1   and movie reviews 2   to evaluate sentiment classification of sentences.",0,original
It is promising to optimize the model parameters directly with respect to AER as suggested in statistical machine translation  .,0,original
"More recently, the problem has been tackled using unsupervised  ) and supervised  , Ng and Cardie  ) approaches.",0,original
"When labeled training data is available, we can use the Maximum Entropy principle   to optimize the  weights.",0,original
"Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see  .",0,original
We thus propose to adapt the statistical machine translation model   for SMS text normalization.,0,original
"As our basic data source, we use 500 000 sentences from the Wikipedia XML corpus  ; this is the corpus used by Akhmatova and Dras  , and related to one used in one set of experiments by Snow et al.",0,original
Tile full description of Model 4   is rather complica.ted as there have to be considered tile cases that English words have fertility larger than one and that English words have fertility zero.,0,original
ur method was applied to 23 million words of the WSJ that were automatically tagged with Ratnaparkhi's maximum entropy tagger   and chunked with the partial parser CASS  ,0,original
"For a full derivation of the modified updates and for quite technical convergence proofs, see Collins, Schapire and Singer  .",0,original
"Given a collection of facts, ME chooses a model consistent with all the facts, but otherwise as uniform as possible  .",0,original
ichman and Schone   used a method similar to Nothman et al,0,original
Automatically determining the degree of antonymy between words has many uses including detecting and generating paraphrases   and detecting contradictions    .,0,original
  managed to extract LFG subcategorisation frames and paths linking long distance dependencies reentrancies from f-structures generated automatically for the PennII treebank trees and used them in an long distance dependency resolution algorithm to parse new text.,0,original
"For the future, the joint model would benefit from lexical weighting like that used in the standard model  .",0,original
"However, we believe this passage is in error: such an estimate is ineffective in the iterative scaling algorithm.",0,original
"Since these morphological generalizations are based on the initial categorization provided by the algorithm of  , we hope that they will foster speedy convergence of HNN training.",0,original
"16In fact, we have experimented with other tagger combinations and configurations as wellwith the TnT  , MaxEnt   and TreeTagger  , with or without the Morce tagger in the pack; see below for the winning combination.",0,original
"The usual Chinese NLP architecture first preprocesses input text through a word segmentation module  , but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English sentence.",0,original
"For example, in the IBM Models  , each word ti independently generates 0, 1, or more 2Note that we refer to t as the target sentence, even though in the source-channel model, t is the source sentence which goes through the channel model P  to produce the observed sentence s. words in the source language.",0,original
"We report results on the Boston University   Radio Speech Corpus   and Boston Directions Corpus    , two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling.",0,original
We utilize a maximum entropy   model   to design the basic classifier used in active learning for WSD.,0,original
Sum of logarithms of source-to-target lexical weighting  .,0,original
"2.2 Xerox Tagger The Xerox Tagger 1, XT,   is a statistical tagger made by Doug Cutting, Julian Kupiec, Jan Pedersen and Penelope Sibun in Xerox PARC.",0,original
"216 The Maximum Entropy Principle   is to nd a model p = argmax pC H , which means a probability model p  that maximizes entropy H .",0,original
"4.1 Corpora Sentence compression systems have been tested on product review data from the Ziff-Davis   Corpus by Knight and Marcu  , general news articles by Clarke and Lapata   corpus   and biomedical articles  .",0,original
"In the iNeast system  , the identification of relevant terms is oriented towards multi-document summarization, and they use a likelihood ratio   which favours terms which are representative of the set of documents as opposed to the full collection.",0,original
"Denote the global feature vector for segmented sentence y with    Rd, where d is the total number of features in the model; then Score  is computed by the dot product of vector   and a parameter vector   Rd, where i is the weight for the ith feature: Score  =   841 Inputs: training examples   Initialization: set  = 0 Algorithm: for t = 1T, i = 1N calculate zi = argmaxyGEN    if zi negationslash= yi  =  +    Outputs:  Figure 1: the perceptron learning algorithm, adapted from Collins   The perceptron training algorithm is used to determine the weight values .",0,original
The boosting approach to ranking has been applied to named entity segmentation   and natural language generation  .,0,original
"This operation does not change the collection of phrases or rules extracted from a hypothesized alignment, see, for instance,  .",0,original
he optimal bilingual parsing tree for a given sentence-pair can be computed using dynamic programming   algorithm ,0,original
Baron and Hirst   extracted collocations with Xtract   and classified the collocations using the orientations of the words in the neighboring sentences.,0,original
"3 Results and Analysis Hall   shows that the oracle parsing accuracy of a k-best edge-factored MST parser is considerably higher than the one-best score of the same parser, even when k is small.",0,original
"The corpus was automatically derived from the Penn Treebank II corpus  , by means of the script chunklink.pl   that we modified to fit our purposes.",0,original
As described in Section 3 we retrieved neighbors using Lins   similarity measure on a RASP parsed   version of the BNC.,0,original
For detailed descriptions of SMT models see for example  .,0,original
"Liu and Gildea   also pointed out that due to the limited references for every MT output, using the overlapping ratio of n-grams longer than 2 did not improve sentence level evaluation performance of BLEU.",0,original
"First, word frequencies, context word frequencies in surrounding positions   are computed following a statistics-based metrics, the log-likelihood ratio  .",0,original
"Word alignment was carried out by running Giza++ implementation of IBM Model 4 initialized with 5 iterations of Model 1, 5 of the HMM aligner, and 3 iterations of Model 4   in both directions and then symmetrizing using the grow-diag-final-and heuristic  .",0,original
"2 Learning algorithm The translation model is a standard linear model  , which we train using MIRA  , following Watanabe et al.",0,original
"7Our decoder lacks certain features shown to be beneficial to synchronous grammar decoding, in particular rule binarisation  .",0,original
"We thus introduce a multiplier  to form the actual objective function that we minimize with respect to :4 summationdisplay iL logp,i  +  Nsummationdisplay inegationslashL H    One may regard  as a Lagrange multiplier that is used to constrain the classifiers uncertainty H to be low, as presented in the work on entropy regularization  .",0,original
"  considered some location constrains in meeting summarization evaluation, which utilizes speaker information to some extent.",0,original
"For all performance metrics, we show the 70% confidence interval with respect to the MAP baseline computed using bootstrap resampling  .",0,original
"2.2 Global Linear Models We follow the framework of Collins  , recently applied to language modeling in Roark et al.",0,original
"415-458, Wu, Dekai   Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.",0,original
he linear kernel derived from the L1 distance is the same as the difference-weighted token-based similarity measure of Weeds and Weir  ,0,original
"The approach is related, but not identical, to distributional similarity   and  ).",0,original
"Also, we used Adwait Ratnaparkhis part-of-speech tagger   to tag unknown words in the test data.",0,original
"  argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models   with phonemebased alignments using direct probabilities.",0,original
Our approach permits an alternative to minimum error-rate training  ; it is discriminativebuthandleslatentstructureandregularization in more principled ways.,0,original
"Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative  .",0,original
ch   developed a training procedure that incorporates various MT evaluation criteria in the training procedure of log-linear MT models,0,original
"Text similarity has been also used for relevance feedback and text classification  , word sense disambiguation  , and more recently for extractive summarization  , and methods for automatic evaluation of machine translation   or text summarization  .",0,original
"A first family of libraries was based on a word alignment A, produced using the Refined method described in    : we call these the A libraries.",0,original
Automatic measures like BLEU   or NIST   do so by counting sequences of words in such paraphrases.,0,original
7.3 EM algorithm The only other application of the EM algorithm to word-sense disambiguation is described in  .,0,original
"757 hbps strong tendency to overestimate the probability of rare bi-phrases; it is computed as in equation  , except that bi-phrase probabilities are computed based on individual word translation probabilities, somewhat as in IBM model 1  : Pr  = 1|s||t| productdisplay tt summationdisplay ss Pr   The target language feature function htl: this is based on a N-gram language model of the target language.",0,original
"Manual processes, such as lexicon development could be automated in the future using standard contextbased, word distribution methods  , or other corpus-based techniques.",0,original
Methods have been proposed for automatic evaluation in MT  ).,0,original
"More recently, the problem has been tackled using statistics-based   and learning-based   methods.",0,original
ne example of the 450 latter problem is the following: in   the nature of a syntactic link between two associated words is detected a posteriori,0,original
"For this purpose, we present a data-driven beam search algorithm similar to the one used in speech recognition search algorithms  .",0,original
"task  , and reported errors in the range of 26% are common.",0,original
e have begun experimenting with log likelihood ratio   as a thresholding technique,0,original
"1 Introduction Estimating the degree of semantic relatedness between words in a text is deemed important in numerous applications: word-sense disambiguation  , story segmentation  , error correction  , summarization  .",0,original
his implementation is exactly the one proposed in Yarowsky  ,0,original
"They are generated from the training corpus via the ?diag-and??method   and smoothed using Kneser-Ney smoothing  , ??one or several n-gram language model  trained with the SRILM toolkit  ; in the baseline experiments reported here, we used a trigram model, ??a distortion model which assigns a penalty based on the number of source words which are skipped when generating a new target phrase, ??a word penalty.",0,original
"The differences between a k-best and a beam-search parser   make a running time difference unsur17 Our score of 85.8 average labeled precision and recall for sentences less than or equal to 100 on Section 23 compares to: 86.7 in Charniak  , 86.9 in Ratnaparkhi  , 88.2 in Collins  , 89.6 in Charniak  , and 89.75 in Collins  .",0,original
This is most prominently evidenced by the PENN TREEBANK  .,0,original
"Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER  , which employs a version of edit distance for word substitution and reordering; or METEOR  , which uses stemming and WordNet synonymy.",0,original
illmann and Zhang   use a BLEU oracle decoder for discriminative training of a local reordering model,0,original
We compare an ordinary PCFG estimated with maximum likelihood   and the HDP-PCFG estimated using the variational inference algorithm described in Section 2.6.,0,original
"1 Introduction Despite a surge in research using parallel corpora for various machine translation tasks  ,(Brown et al. 1991; Gale & Church 1993; Church 1993; Dagan & Church 1994; Simard et al. 1992; Chen 1993; Melamed 1995; Wu & Xia 1994; Wu 1994; Smadja et aI.",0,original
"Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category  , lemma of the word  , phrasal information  ), and subject-predicate identification  .",0,original
"3 Parse Tree Features We tagged each candidate transcription with   part-of-speech tags, using the tagger documented in Collins  ; and   a full parse tree, using the parser documented in Collins  .",0,original
"These transtbr rules are pairs of corresponding rooted substructures, where a substructure   is a connected set of arcs and nodes.",0,original
"The IBM models   benefit from a one-tomany constraint, where each target word has ex105 the tax causes unrest l' impt cause le malaise Figure 1: A cohesion constraint violation.",0,original
he algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm   to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs,0,original
53 2 Bilexicalization of Inversion Transduction Grammar The Inversion Transduction Grammar of Wu   models word alignment between a translation pair of sentences by assuming a binary synchronous tree on top of both sides,0,original
"4.2 Interpreting reliability results It has been argued elsewhere   that since the amount of agreement one would expect by chance depends on the number and relative frequencies of the categories under test, reliability for category classifications should be measured using the kappa coefficient.",0,original
"Turneys   work on classiflcation of reviews is perhaps the closest to ours.2 He applied a speciflc unsupervised learning technique based on the mutual information between document phrases and the words \excellent"""" and \poor"""", where the mutual information is computed using statistics gathered by a search engine.",0,original
"This paper explores an alternative approach to parsing, based on the perceptron training algorithm introduced in Collins  .",0,original
Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment   andsubjectivityanalysis(Wiebeetal.,0,original
"6 Concluding remarks Our work presents a set of improvements on previous state of the art of Grammar Association: first, by providing better language models to the original system described in  ; second, by setting the technique into a rigorous statistical framework, clarifying which kind of probabilities have to be estimated by association models; third, by developing a novel and especially adequate association model: Loco C. On the other hand, though experimental results are quite good, we find them particularly relevant for pointing out directions to follow for further improvement of the Grammar Association technique.",0,original
"Model performance is evaluated using the standard BLEU metric   which measures average n-gram precision, n 4, and we use the NIST definition of the brevity penalty for multiple reference test sets.",0,original
One is to use a stochastic gradient descent   or Perceptron like online learning algorithm to optimize the weights of these features directly for MT  .,0,original
  develop a bottom-up decoder for BTG   that uses only phrase pairs.,0,original
"The progress in parsing technology are noteworthy, and in particular, various statistical dependency models have been proposed ,,  ,  .",0,original
"Here, it might be useful to relax the strict linear control regime by exploring beam search strategies, e.g. along the lines of Collins and Roark  .",0,original
"However, more recent work   has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank  , containing more than 1,000,000 words and 49,000 sentences.",0,original
"In prior research, ILP was used as a postprocessing step to remove redundancy and make other global decisions about parameters  .",0,original
"The LFG annotation algorithm of   was used to produce the f-structures for development, test and training sets.",0,original
"Several frameworks for finding translation equivalents or translation units in machine translation, such as \  and other example-based MT approaches, might be used to select the preferred mapping.",0,original
Various methods   of automatically acquiring synonyms have been proposed.,0,original
"For instance, the to-PP frame is poorly' represented in the syntactically annotated version of the Penn Treebank  .",0,original
his second expression is similar to that used in  ,0,original
This corpus contains annotations of semantic PASs superimposed on the Penn Treebank    .,0,original
"Since there is no well-agreed to definition of what an utterance is, we instead focus on intonational phrases  , which end with an acoustically signaled boundary lone.",0,original
"Many methods have been proposed to deal with this problem, including supervised learning algorithms  , semi-supervised learning algorithms  , and unsupervised learning algorithms  .",0,original
"Also in the Penn Treebank  ,  ) a limited set of relations is placed over the constituencybased annotation in order to make explicit the   roles that the constituents play.",0,original
"We do not completely rule out the possibility that some more sophisticated, ontologically promiscuous, first-order analysis  ) might account for these kinds of monotonicity inferences.",0,original
"Comparatively,   propose to use the N-gram Overlap metric to capture similarities between sentences and automatically create paraphrase corpora.",0,original
he SPECIALIST minimal commitment parser relies on the SPECIALIST Lexicon as well as the Xerox stochastic tagger  ,0,original
"To achieve robust training, Daume III and Marcu   employed the averaged perceptron   and ALMA  .",0,original
"Instances of this work include information extraction, ontology induction and resource acquisition  .",0,original
"Many statistical metrics have been proposed, including pointwise mutual information    , mean and variance, hypothesis testing  , log-likelihood ratio    , statistic language model  , and so on.",0,original
IBM Model 4 parameters are then estimated over this partial search space as an approximation to EM  .,0,original
"Koehn and Hoang   propose Factored Translation Models, which extend phrase-based statistical machine translation by allowing the integration of additional morphological features at the word level.",0,original
"Our work is most similar to work using discriminative log-linear models for alignment, which is similar to discriminative log-linear models used for the SMT decoding   problem  .",0,original
"For phrase-based translation model training, we used the GIZA++ toolkit  .",0,original
"Recently, specific probabilistic tree-based models have been proposed not only for machine translation  , but also for This work was supported by DARPA contract F49620-001-0337 and ARDA contract MDA904-02-C-0450.",0,original
"These heuristics are extensions of those developed for phrase-based models  , and involve symmetrising two directional word alignments followed by a projection step which uses the alignments to find a mapping between source words and nodes in the target parse trees  .",0,original
"Specifically, three features are used to instantiate the templates:  POS tags on both sides: We assign POS tags using the MXPOST tagger   for English and Chinese, and Connexor for Spanish.",0,original
"Ever since its introduction in general   and in computational linguistics  , many researchers have pointed out that there are quite some problems in using  (e.g.",0,original
Typicality was measured using the log-likelihood ratio test  .,0,original
Classes can be induced directly from the corpus   or taken from a manually crafted taxonomy  .,0,original
"We tuned Pharaohs four parameters using minimum error rate training   on DEV.12 We obtained an increase of 0.8 9As in the POS features, we map each phrase pair to its majority constellation.",0,original
"We participated in the multilingual track of the CoNLL 2007 shared task  , and evaluated the system on data sets of 10 languages  .",0,original
"3.3 Unknown word features Most of the models presented here use a set of unknown word features basically inherited from  , which include using character n-gram prefixes and suffixes  , and detectors for a few other prominent features of words, such as capitalization, hyphens, and numbers.",0,original
"In addition, corpus-based stochastic modelling of lexical patterns   may provide information about word sense frequency of the kind advocated since  .",0,original
"2.2 A Perceptron-Based Edit Model In this section we present a general-purpose extension of perceptron training for sequence labeling, due to Collins  , to the problem of sequence alignment.",0,original
"These measures have, in fact, been used previously in measuring term recognition  .",0,original
"Turney   predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method.",0,original
t is worth noting that we observed the same relation between subjectivity detection and polarity classification accuracy as described by Pang and Lee   and Eriksson  ,0,original
"All submitted runs were evaluated with the automatic metrics: ROUGE  , which calculates the proportion of n-grams shared between the candidate summary and the reference summaries, and Basic Elements  , which compares the candidate to the models in terms of head-modifier pairs.",0,original
"2 Maximum Entropy In this bakeoff, our basic model is based on the framework described in the work of Ratnaparkhi   which was applied for English POS tagging.",0,original
"In cut-and-paste summarization  , sentence combination operations were implemented manually following the study of a set of professionally written abstracts; however the particular pasting operation presented here was not implemented.",0,original
u   adopted chammls that eliminate syntactically unlikely alignments and Wang et al,0,original
These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus  .,0,original
"The usual recall and precision metrics   require either a test corpus previously annotated with the required information, or manual evaluation  .",0,original
"2 Disperp and Distortion Corpora 2.1 Defining Disperp The ultimate reason for choosing one SCM over another will be the performance of an MT system containing it, as measured by a metric like BLEU  .",0,original
"Following the evaluation methodology of Wong and Mooney  , we performed 4 runs of the standard 10-fold cross validation and report the averaged performance in this section using the standard automatic evaluation metric BLEU   and NIST  2.",0,original
"We have computed the BLEU score    , the NIST score    , the General Text Matching   F-measure    , and the METEOR measure  .",0,original
ROUGE   is a set of recall-based criteria that is mainly used for evaluating summarization tasks.,0,original
  discuss three approaches: hand-crafted rules; grammatical inference of subsequential transducers; and log-linear classifiers with bigram and trigram features used as taggers  .,0,original
"Given a manually compiled lexicon containing words and their relative frequencies Ps , the best segmentationfJ1 is the one that maximizes the joint probability of all words in the sentence, with the assumption that words are independent of each other1: fJ1 = argmax fprimeJprime1 Pr   argmax fprimeJprime1 Jprimeproductdisplay j=1 Ps , where the maximization is taken over Chinese word sequences whose character sequence is cK1 . 2.2 Translation system Once we have segmented the Chinese sentences into words, we train standard alignment models in both directions with GIZA++   using models of IBM-1  , HMM   and IBM-4  .",0,original
e used Collins   statistical parser trained on examples from the Penn Treebank to generate parses of the same format for the sentences in our data,0,original
"However, with their system trained on the medical corpus and then tested on the Wall Street Journal corpus  , they achieve an overall prediction accuracy of only 54%.",0,original
gain we used Mohammad and Hirsts   method along with Lins   distributional measure to determine the distributional closeness of two thesaurus concepts,0,original
"In comparison we introduce 28 several metrics coefficients reported in Albrecht and Hwa   including smoothed BLEU  , METEOR  , HWCM  , and the metric proposed in Albrecht and Hwa   using the full feature set.",0,original
1 Introduction The dominance of traditional phrase-based statistical machine translation   models   has recently been challenged by the development and improvement of a number of new models that explicity take into account the syntax of the sentences being translated.,0,original
"Averaging parameters is a way to reduce overfitting for perceptron training  , and is applied to all our experiments.",0,original
"We adopted IOB   labeling  , where the rst word of an entity of class C is labeled B-C, the words in the entity are labeled I-C, and other words are labeled O.",0,original
"Table 1 shows the LP and LR scores obtained with our base line subtree set, and compares these scores with those of previous stochastic parsers tested on the WSJ  .",0,original
"Dependency Analyzer PP-Attachment Resolver Root-Node Finder Base NP Chunker   = SVM, = Preference Learning Figure 2: Module layers in the system That is, we use Penn Treebanks Wall Street Journal data  .",0,original
"A la Ramshaw and Marcus  , and Kudo and Matsumato  , we use the IOB tagging style for modeling and classification.",0,original
"For an alignment model, most of these use the Aachen HMM approach  , the implementation of IBM Model 4 in GIZA++   or, more recently, the semi-supervised EMD algorithm  .",0,original
We implement some global constraints and include unary constraints which were largely imported from the list of seed words used in  .,0,original
"Using the ME principle, we can combine information from a variety of sources into the same language model  .",0,original
"We ran the baseline semisupervised system for two iterations  , and in contrast with   we found that the best symmetrization heuristic for this system was union, which is most likely due to our use of fully linked alignments which was discussed at the end of Section 3.",0,original
"Assuming that the parameters P  are known, the most likely alignment is computed by a simple dynamic-programming algorithm.1 Instead of using an Expectation-Maximization algorithm to estimate these parameters, as commonly done when performing word alignment  , we directly compute these parameters by relying on the information contained within the chunks.",0,original
"Although the BLEU   score from Finnish to English is 21.8, the score in the reverse direction is reported as 13.0 which is one of the lowest scores in 11 European languages scores  .",0,original
"Hypotheses for unknown words, both stochastic  , and connectionist   have been applied to unlimited vocabulary taggers.",0,original
"In natural language processing, recent years have seen ME techniques used for sentence boundary detection, part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just a few applications  .",0,original
"During training, the baseline POS tagger stores special word-tag pairs into a tag dictionary  .",0,original
"To implement this method, we rst use the Stanford Named Entity Recognizer4  toidentifythesetofpersonandorganisation entities, E, from each article in the corpus.",0,original
"Once the set of features functions are selected, algorithm such as improved iterative scaling   or sequential conditional generalized iterative scaling   can be used to find the optimal parameter values of fkg and fig.",0,original
"We use eight similarity measures implemented within the WordNet::Similarity package5, described in  ; these include three measures derived from the paths between the synsets in WordNet: HSO  , LCH  , and WUP  ; three measures based on information content: RES  , LIN  , and JCN  ; the gloss-based Extended Lesk Measure LESK,  , and finally the gloss vector similarity measure VECTOR  .",0,original
"3.1 Definition The following set-up, adapted from Collins  , was used for all three discriminative training methods: 266  Training data is a set of input-output pairs.",0,original
"Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions  : supervised systems attain results on the high 80s and beat the most frequent baseline by a large margin for lexical-sample datasets, but results on the all-words datasets were much more modest, on the low 70s, and a few points above the most frequent baseline.",0,original
"4.5 Hindles Measure Hindle   proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences.",0,original
"Other languagesfor which this is the case include English  , the Susanne Corpus  , and the British section of the ICE Corpus  ) and Italian   and TUT  ).",0,original
A third of the corpus is syntactically parsed as part of the Penn Treebank   2This type corresponds to Princes   inferrables.,0,original
"5.2 Impact on translation quality As reported in Table 3, small increases in METEOR  , BLEU   and NIST scores   suggest that SMT output matches the references better after postprocessing or decoding with the suggested lemma translations.",0,original
"DeNero and Klein   focus on alignment and do not present MT results, while May and Knight   takesthesyntacticre-alignmentasaninputtoanEM algorithm where the unaligned target words are insertedintothetemplatesandminimumtemplatesare combinedintobiggertemplates .",0,original
ohnson   considers conversion to a number of different representations and discusses how this influences accuracy for nonlexicalized PCFGs,0,original
"This makes it suitable for discriminative SMT training, which is still a challenge for large parameter sets  .",0,original
Related work Turney   recently advocated the need for a uniform approach to corpus-based semantic tasks,0,original
"The statistical methods are based on distributional analysis  , and cluster analysis  .",0,original
Note that using stems and their synonyms as used in METEOR   could also be considered for word similarity.,0,original
"For this experiment, we used sections 02 21 of the Penn Treebank     as the training data and section 23   for evaluation, as is now standard.",0,original
The flow using non-local features in two-stage architecture 2.4 Results We employ BIOE1 label scheme for the NER task because we found it performs better than IOB2 on Bakeoff 2006   NER MSRA and CityU corpora.,0,original
Dubey et al. proposed an unlexicalized PCFG parser that modied PCFG probabilities to condition the existence of syntactic parallelism  .,0,original
Most of the work focused on seeking better word alignment for consensus-based confusion network decoding   or word-level system combination  .,0,original
"For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc. Many methods have been proposed to compute distributional similarity between words, e.g.,  ,  ,   and  .",0,original
"2.4 GermanEnglish For GermanEnglish, we additionally incorporated rule-based reordering  We parse the input using the Collins parser   and apply a set of reordering rules to re-arrange the German sentence so that it corresponds more closely English word order  .",0,original
"The details of the algorithm can be found in the literature for statistical translation models, such as  .",0,original
"All the enumerated segment pairs are listed in the following table: Feature x,y Feature x,y AM1+1 c1, c0 AM2+1 c2c1, c0 AM1+2 c1, c0c1 AM2+2 c2c1, c0c1 AM1+3 c1, c0c1c2 AM3+1 c3c2c1, c0 We use Dunnings method   because it does not depend on the assumption of normality and it allows comparisons to be made between the signiflcance of the occurrences of both rare and common phenomenon.",0,original
4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text  .,0,original
The original formulation of statistical machine translation   was defined as a word-based operation.,0,original
PMI   between two phrases is de ned as: log2 prob prob   prob  PMI is positive when two phrases tend to co-occur and negative when they tend to be in a complementary distribution.,0,original
Resources specifying the relations among lexical items such as WordNet   and HowNet     have inspired the work of many researchers in NLP  .,0,original
"2 Syntactic-oriented evaluation metrics We investigated the following metrics oriented on the syntactic structure of a translation output:  POSBLEU The standard BLEU score   calculated on POS tags instead of words;  POSP POS n-gram precision: percentage of POS ngrams in the hypothesis which have a counterpart in the reference;  POSR Recall measure based on POS n-grams: percentage of POS n-grams in the reference which are also present in the hypothesis;  POSF POS n-gram based F-measure: takes into account all POS n-grams which have a counter29 part, both in the reference and in the hypothesis.",0,original
"The probabilities are ordered according to, at least my, intuition with pronoun being the most likely  , followed by proper nouns  , followed by common nouns  , a fact also noted by  .",0,original
The second attempts to instill knowledge of collocations in the data; we use the technique described by   to compute multi-word expressions and then mark words that are commonly used as such with a feature that expresses this fact.,0,original
"Conditional probability, the log-likelihood ratio, and Resnik's   selectional association measure were also significantly correlated with plausibility ratings.",0,original
"We evaluate its performance on the standard Penn English Treebank   dependency parsing task, i.e., train on sections 02-21 and test on section 23 with automatically assigned POS tags   using a tagger similar to Collins  , and using the headrules of Yamada and Matsumoto   for conversion into dependency trees.",0,original
"Inspired by  s methodology which was originally designed for English and Penn-II treebank, our approach to Chinese non-local dependency recovery is based on Lexical-Functional Grammar  , a formalism that involves both phrase structure trees and predicate-argument structures.",0,original
"To quickly   evaluate this phenomenon, we trained the statistical IBM wordalignment model 4  ,1 using the GIZA++ software   for the following language pairs: ChineseEnglish, Italian English, and DutchEnglish, using the IWSLT-2006 corpus   for the first two language pairs, and the Europarl corpus   for the last one.",0,original
"We consider three learning algorithms, namely, the C4.5 decision tree induction system  , the RIPPER rule learning algorithm  , and maximum entropy classification  .",0,original
1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation  .,0,original
"Chunks can be represented with bracket structures but alternatively one can use a tagging representation which classifies words as being inside a chunk  , outside a chunk   or at a chunk boundary    .",0,original
"3.2 ITG Constraints In this section, we describe the ITG constraints  .",0,original
"Collocations have been widely used for tasks such as word sense disambiguation    , information extraction    , and named-entity recognition  .",0,original
"In our case, we computed a likelihood ratio score   for all pairs of English tokens and Inuktitut substrings of length ranging from 3 to 10 characters.",0,original
he collocations have been calculated according to the method described in Church and Hanks   by moving a window on the texts,0,original
"These lists are rescored with the following models:   the different models used in the decoder which are described above,   two different features based on IBM Model 1  ,   posterior probabilities for words, phrases, n-grams, and sentence length  , all calculated over the Nbest list and using the sentence probabilities which the baseline system assigns to the translation hypotheses.",0,original
"  defined two local search operations for their 1-to-N alignment models 3, 4 and 5.",0,original
"Since most phrases appear only a few times in training data, a phrase pair translation is also evaluated by lexical weights   or term weighting   as additional features to avoid overestimation.",0,original
"Since this transform takes a probabilistic grammar as input, it can also easily accommodate horizontal and vertical Markovisation   as described by Collins   and subsequently.",0,original
"We use the following features for our rules:  sourceand target-conditioned neg-log lexical weights as described in    neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned  Counters: n.o. rule applications, n.o. target words  Flags: IsPurelyLexical  , IsPurelyAbstract  , IsXRule  , IsGlueRule 139  Penalties: rareness penalty exp ; unbalancedness penalty |MeanTargetSourceRatio  n.o. source words n.o. target words| 4 Parsing Our SynCFG rules are equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing.",0,original
"As reported previously, the standard left-corner grmninar embeds sufficient non-local infornlation in its productions to significantly improve the labelled precision and recall of its MLPs with respect to MLPs of the PCFG estimated from the untransfornmd trees  .",0,original
Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called invertedtranslationmodels  .,0,original
"For the first two tasks, all heuristics of the Pharaoh-Toolkit   as well as the refined heuristic   to combine both IBM4-alignments were tested and the best ones are shown in the tables.",0,original
"The kappa statistic   for identifying question segments is 0.68, and for linking question and answer segments given a question segment is 0.81.",0,original
7 Automated Sense Labelling of Discourse Connectives The focus here is on automated sense labelling of discourse connectives   438   151   SUMMARIES 2118 275 0.130 166   99   10   LETTERS 739 200 0.271 126   56   18   NEWS 40095 9336 0.233 5514   3015   807   Figure 4: Distribution of Explicit Intra-Sentential Connectives.,0,original
"Movie-domainSubjectivityDataSet : Pang and Lee   used a collection of labeled subjective and objective sentences in their work on review classification.5 The data set contains 5000 subjective sentences, extracted from movie reviews collected from the Rotten Tomatoes web formed best.",0,original
The value of fj is calculated by Mutual Information   between xi and fj.,0,original
indle   classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs,0,original
"Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT  .",0,original
"The mapping typically is made to try to give the most favorable mapping in terms of accuracy, typically using a greedy assignment  .",0,original
"The first, Powells method, was advocated by Och   when MERT was first introduced for statistical machine translation.",0,original
"This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied  .",0,original
"Examples have been class-based D2-gram models  , smoothing techniques for structural disambiguation   and word sense disambiguation  .",0,original
1 Introduction Word alignment is an important component of a complete statistical machine translation pipeline  .,0,original
"For each word in LDV, three existing thesauri are consulted: Rogets Thesaurus  , Collins COBUILD Thesaurus  , and WordNet  .",0,original
ll of the convergence and generalization results in Collins   depend on notions of separability rather than the size of GEN. Two questions come to mind,0,original
The next two methods are heuristic   in   and grow-diagonal   proposed in  .,0,original
"In order to get a better understanding of these matters, we replicate parts of the error analysis presented by McDonald and Nivre  , where parsing errors are related to different structural properties of sentences and their dependency graphs.",0,original
3 Bi-Stream HMMs for Transliteration Standard IBM translation models   can be used to obtain letter-to-letter translations.,0,original
This linear model is learned using a variant of the incremental perceptron algorithm  .,0,original
"Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules   and by computing statistical measures of lexical association  .",0,original
Our strategy for choosing heads is similar to the one in  .,0,original
"Some improvements on BOW are given by the use of dependency trees and syntactic parse trees  ,  ,  , but these, too are not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs.",0,original
We evaluate this method over the part of speech tagged portion of the Penn Treebank corpus  .,0,original
"However, CHECK moves are almost always about some information which the speaker has been told \  -a description that models the backward looking functionality of a dialogue act.",0,original
For extracting simple noun phrases we first used Ramshaw and Marcuss base NP chunker  .,0,original
"Meanwhile, it is common for NP chunking tasks to represent a chunk   with two labels, the begin   and inside   of a chunk  .",0,original
Bikel and Chiang   in fact contains two parsers: one is a lexicalized probabilistic contextfree grammar   similar to  ; the other is based on statistical TAG  .,0,original
oward a Task-based Gold Standard for Evaluation of NP Chunks and Technical Terms Nina Wacholder Rutgers University nina@scils.rutgers.edu Peng Song Rutgers University psong@paul.rutgers.edu Abstract We propose a gold standard for evaluating two types of information extraction output -noun phrase   chunks   and technical terms  ,0,original
"The weights are then averaged across all iterations of the perceptron, as in  .",0,original
"This dependency graph is partitioned into treelets; like  , we assume a uniform probability distribution over all partitions.",0,original
"Since the word support model and triple context matching model have been proposed in our previous work   at the SIGHAN bakeoff 2005   and 2006  , the major descriptions of this paper is on the WBT model.",0,original
Background The natural language generator used in our experiments is the WSJ-trained system described in Cahill and van Genabith   and Hogan et al,0,original
"The second voting model is a maximum entropy model  , since Klein and Manning   found that this model yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance.",0,original
Much research is also being directed at acquiring affect lexica automatically  .,0,original
larke and Lapata   included discourse level features in their framework to leverage context for enhancing coherence,0,original
"2.2 Automatic metrics Similarly to the Pyramid method, ROUGE   and Basic Elements   require multiple topics and model summaries to produce optimal results.",0,original
"These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following  .",0,original
"We generate POS tags using the MXPOST tagger   for English and Chinese, and Connexor for Spanish.",0,original
urney   later addressed the same problem using 8000 automatically generated patterns,0,original
"Although the above statement was made about translation problems faced by human translators, recent research   suggests that it also applies to problems in machine translation.",0,original
or placing the head the center function center    is used: the average position of the source words with which the target word e i1 is aligned,0,original
6 Related Work A description of the IBM models for statistical machine translation can be found in  .,0,original
"Unlike Choueka  , Church and Hanks   identify as collocations both interrupted and uninterrupted sequences of words.",0,original
"Computational approaches to prosodic modeling of DAs have aimed to automatically extract various prosodic parameters--such as duration, pitch, and energy patterns--from the speech signal  .",0,original
"2.4 METEOR Given a pair of strings to compare  , METEOR   first creates a word alignment between the two strings.",0,original
The parser is trained on dependencies extracted from the English Penn Treebank version 3.0   by using the head-percolation rules of  .,0,original
The Baseline Maximum Entropy Model We started with a maximum entropy based tagger that uses features very similar to the ones proposed in Ratnaparkhi  ,0,original
"The second alternative used BerkeleyAligner  , which shares information between the two alignment directions to improve alignment quality.",0,original
"  used patterns representing part-of-speech sequences,   recognized adjectival phrases, and   learned N-grams.",0,original
Automated evaluation will utilize the standard DUC evaluation metric ROUGE   which representsrecallovervariousn-gramsstatisticsfrom asystem-generatedsummaryagainstasetofhumangenerated peer summaries.5 We compute ROUGE scores with and without stop words removed from peer and proposed summaries.,0,original
This is exactly the standard lexicon probability a27a28a18a26a4 a20a12 a22 employed in the translation model described in   and in Section 2.,0,original
Pointwise mutual information   was used to measure strength of selection restrictions for instance by Church and Hanks  .,0,original
"consistency among raters who may have different levels of fluency in the source language, raters are not shown the original French or Spanish sentence  .",0,original
ch   found that such smoothing during training gives almost identical results on translation metrics,0,original
"More specifically, the work on optimizing preference factors and semantic collocations was done as part of a project on spoken language translation in which the CLE was used for analysis and generation of both English and Swedish  .",0,original
"So fitr, we have implemented the following,: sentence ~dignment btLsed-on word correspondence information, word correspondence estimation by cooccnl'rence-ffequency-based methods in GMe mid Church   and Kay and R6scheisen  , structured Imttehlng of parallel sentences  , and case Dame acquisition of Japanese verbs  .",0,original
"For instance, we may find metrics which compute similarities over shallow syntactic structures/sequences  , constituency trees   and dependency trees  .",0,original
"The first solution might also introduce errors elsewhere As Ramshaw and Marcus   already noted: """"While this automatic derivation process introduced a small percentage of errors on its own, it was the only practical way both to provide the amount of training data required and to allow for fully-automatic testing"""".",0,original
"Applications of word clustering include language modeling  , text classification  , thesaurus construction   and so on.",0,original
All the feature weights   were trained using our implementation of Minimum Error Rate Training  .,0,original
"145 2 The Latent Variable Architecture In this section we will begin by briefly introducing the class of graphical models we will be using, Incremental Sigmoid Belief Networks  .",0,original
Our approach is to use maximum entropy models   to learn a suitable mapping from features derived from the words in the ASR output to semantic frames.,0,original
"The research of opinion mining began in 1997, the early research results mainly focused on the polarity of opinion words   and treated the text-level opinion mining as a classification of either positive or negative on the number of positive or negative opinion words in one text  .",0,original
"When we trained external Chinese models, we used the same unlabeled data set as DeNero and Klein  , including the bilingual dictionary.",0,original
The tagger was tested on two corpora-the Brown corpus  ) and the Wall Street Journal corpus  .,0,original
"Proceedings of the 40th Annual Meeting of the Association for cently, semantic resources have also been used in collocation discovery  , smoothing and model estimation   and text classi cation  .",0,original
ROUGE   is an evaluation metric designed to evaluate automatically generated summaries.,0,original
