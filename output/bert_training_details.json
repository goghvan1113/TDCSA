[
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.07669952511787415,
            "eval_Accuracy": 0.9118993135011442,
            "eval_Precision": 0.729477523477254,
            "eval_Recall": 0.6525630701047966,
            "eval_F1": 0.6815506849025604,
            "eval_runtime": 2.2455,
            "eval_samples_per_second": 389.226,
            "eval_steps_per_second": 12.469,
            "epoch": 3.0
        },
        "train_time": 207,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.01,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08371549844741821,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6839950490336095,
            "eval_Recall": 0.6393542716080575,
            "eval_F1": 0.659770947828556,
            "eval_runtime": 2.3481,
            "eval_samples_per_second": 372.21,
            "eval_steps_per_second": 11.924,
            "epoch": 3.0
        },
        "train_time": 204,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.0,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08267292380332947,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6816163832836745,
            "eval_Recall": 0.6128392995310206,
            "eval_F1": 0.6424373640826525,
            "eval_runtime": 2.2013,
            "eval_samples_per_second": 397.041,
            "eval_steps_per_second": 12.72,
            "epoch": 3.0
        },
        "train_time": 207,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08074919134378433,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6759441276736959,
            "eval_Recall": 0.6679878096922421,
            "eval_F1": 0.6713676970943032,
            "eval_runtime": 2.8827,
            "eval_samples_per_second": 303.185,
            "eval_steps_per_second": 6.591,
            "epoch": 3.0
        },
        "train_time": 883,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 48,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.0,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.09739118814468384,
            "eval_Accuracy": 0.9107551487414187,
            "eval_Precision": 0.6965966403425958,
            "eval_Recall": 0.7345199934732376,
            "eval_F1": 0.7137520612460446,
            "eval_runtime": 2.2507,
            "eval_samples_per_second": 388.318,
            "eval_steps_per_second": 12.44,
            "epoch": 5.0
        },
        "train_time": 339,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 5,
        "learning_rate": 2e-05,
        "weight_decay": 0.0,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.09092157334089279,
            "eval_Accuracy": 0.8947368421052632,
            "eval_Precision": 0.6966042806901157,
            "eval_Recall": 0.610876007305763,
            "eval_F1": 0.6209406336941329,
            "eval_runtime": 2.2031,
            "eval_samples_per_second": 396.718,
            "eval_steps_per_second": 12.71,
            "epoch": 3.0
        },
        "train_time": 199,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 0.0001,
        "weight_decay": 0.0,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.07622544467449188,
            "eval_Accuracy": 0.8935926773455377,
            "eval_Precision": 0.6557346437672983,
            "eval_Recall": 0.5832662234784486,
            "eval_F1": 0.6125750256185039,
            "eval_runtime": 2.3811,
            "eval_samples_per_second": 367.064,
            "eval_steps_per_second": 11.759,
            "epoch": 3.0
        },
        "train_time": 201,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 1e-05,
        "weight_decay": 0.0,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.07351981103420258,
            "eval_Accuracy": 0.8924485125858124,
            "eval_Precision": 0.6409481304035781,
            "eval_Recall": 0.7619337112539278,
            "eval_F1": 0.6835031203609478,
            "eval_runtime": 2.3802,
            "eval_samples_per_second": 367.195,
            "eval_steps_per_second": 15.545,
            "epoch": 3.0
        },
        "train_time": 216,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 24,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.0,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.07500700652599335,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6667492216404699,
            "eval_Recall": 0.6486312221362515,
            "eval_F1": 0.6554918873886231,
            "eval_runtime": 2.5518,
            "eval_samples_per_second": 342.503,
            "eval_steps_per_second": 10.973,
            "epoch": 2.9863013698630136
        },
        "train_time": 182,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.0,
        "accumulation_steps": 2,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.07500110566616058,
            "eval_Accuracy": 0.9038901601830663,
            "eval_Precision": 0.6776629841055577,
            "eval_Recall": 0.7283195692336845,
            "eval_F1": 0.7004246469028562,
            "eval_runtime": 2.562,
            "eval_samples_per_second": 341.136,
            "eval_steps_per_second": 10.929,
            "epoch": 2.9863013698630136
        },
        "train_time": 181,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 0.0001,
        "weight_decay": 0.0,
        "accumulation_steps": 2,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.10857710242271423,
            "eval_Accuracy": 0.8947368421052632,
            "eval_Precision": 0.6344588654038124,
            "eval_Recall": 0.6732552753609458,
            "eval_F1": 0.6515769484808455,
            "eval_runtime": 2.36,
            "eval_samples_per_second": 370.343,
            "eval_steps_per_second": 11.865,
            "epoch": 4.9771689497716896
        },
        "train_time": 300,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 5,
        "learning_rate": 0.0001,
        "weight_decay": 0.0,
        "accumulation_steps": 2,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.10108382254838943,
            "eval_Accuracy": 0.897025171624714,
            "eval_Precision": 0.656443022281325,
            "eval_Recall": 0.7078023759520388,
            "eval_F1": 0.6796294676148696,
            "eval_runtime": 2.374,
            "eval_samples_per_second": 368.155,
            "eval_steps_per_second": 11.794,
            "epoch": 4.9771689497716896
        },
        "train_time": 300,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 5,
        "learning_rate": 0.0001,
        "weight_decay": 0.05,
        "accumulation_steps": 2,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08267292380332947,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6816163832836745,
            "eval_Recall": 0.6128392995310206,
            "eval_F1": 0.6424373640826525,
            "eval_runtime": 2.349,
            "eval_samples_per_second": 372.071,
            "eval_steps_per_second": 11.92,
            "epoch": 3.0
        },
        "train_time": 201,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.14178086817264557,
            "eval_Accuracy": 0.8684470820969338,
            "eval_Precision": 0.8713347496687645,
            "eval_Recall": 0.8748922304094214,
            "eval_F1": 0.8694585370582136,
            "eval_runtime": 2.5847,
            "eval_samples_per_second": 391.147,
            "eval_steps_per_second": 12.381,
            "epoch": 3.0
        },
        "train_time": 240,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.14178086817264557,
            "eval_Accuracy": 0.8684470820969338,
            "eval_Precision": 0.8713347496687645,
            "eval_Recall": 0.8748922304094214,
            "eval_F1": 0.8694585370582136,
            "eval_runtime": 2.5519,
            "eval_samples_per_second": 396.183,
            "eval_steps_per_second": 12.54,
            "epoch": 3.0
        },
        "train_time": 239,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08267292380332947,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6816163832836745,
            "eval_Recall": 0.6128392995310206,
            "eval_F1": 0.6424373640826525,
            "eval_runtime": 2.1948,
            "eval_samples_per_second": 398.209,
            "eval_steps_per_second": 12.757,
            "epoch": 3.0
        },
        "train_time": 203,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08267292380332947,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6816163832836745,
            "eval_Recall": 0.6128392995310206,
            "eval_F1": 0.6424373640826525,
            "eval_runtime": 2.197,
            "eval_samples_per_second": 397.812,
            "eval_steps_per_second": 12.745,
            "epoch": 3.0
        },
        "train_time": 204,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.08267292380332947,
            "eval_Accuracy": 0.9016018306636155,
            "eval_Precision": 0.6816163832836745,
            "eval_Recall": 0.6128392995310206,
            "eval_F1": 0.6424373640826525,
            "eval_runtime": 2.1908,
            "eval_samples_per_second": 398.94,
            "eval_steps_per_second": 12.781,
            "epoch": 3.0
        },
        "train_time": 214,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    },
    {
        "cls": "sentiment",
        "seed": 42,
        "eval_result": {
            "eval_loss": 0.049745991826057434,
            "eval_Accuracy": 0.95,
            "eval_Precision": 0.9443472255584148,
            "eval_Recall": 0.950007610492889,
            "eval_F1": 0.9467908229087234,
            "eval_runtime": 2.5773,
            "eval_samples_per_second": 349.204,
            "eval_steps_per_second": 11.252,
            "epoch": 3.0
        },
        "train_time": 234,
        "model_name": "roberta-llama3.1405B-twitter-sentiment",
        "batch_size": 32,
        "epochs": 3,
        "learning_rate": 2e-05,
        "weight_decay": 0.05,
        "accumulation_steps": 1,
        "warmup_steps": 100,
        "warmup_ratio": 0.1,
        "loss_type": "focal_loss",
        "lr_scheduler_type": "cosine"
    }
]